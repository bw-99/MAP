{"Semantic Codebook Learning for Dynamic Recommendation Models": "Zheqi Lv Zhejiang University Hangzhou, China zheqilv@zju.edu.cn Shengyu Zhang \u2217 Zhejiang University Hangzhou, China Shanghai Institute for Advanced Study, Zhejiang University Shanghai, China sy_zhang@zju.edu.cn", "Shaoxuan He": "Zhejiang University Hangzhou, China shxhe@zju.edu.cn Tianyu Zhan Zhejiang University Hangzhou, China yuzt@zju.edu.cn Wenqiao Zhang Zhejiang University Hangzhou, China wenqiaozhang@zju.edu.cn Jingyuan Chen Zhejiang University Hangzhou, China jingyuanchen@zju.edu.cn Zhou Zhao \u2217 Zhejiang University Hangzhou, China zhaozhou@zju.edu.cn", "ABSTRACT": "Dynamic sequential recommendation (DSR) can generate model parameters based on user behavior to improve the personalization of sequential recommendation under various user preferences. However, it faces the challenges of large parameter search space and sparse and noisy user-item interactions, which reduces the applicability of the generated model parameters. The Semantic Codebook Learning for Dynamic Recommendation Models (SOLID) framework presents a significant advancement in DSR by effectively tackling these challenges. By transforming item sequences into semantic sequences and employing a dual parameter model, SOLID compresses the parameter generation search space and leverages homogeneity within the recommendation system. The introduction of the semantic metacode and semantic codebook, which stores disentangled item representations, ensures robust and accurate parameter generation. Extensive experiments demonstrates that SOLID consistently outperforms existing DSR, delivering more accurate, stable, and robust recommendations.", "CCS CONCEPTS": "\u00b7 Information systems \u2192 Personalization ; Multimedia and multimodal retrieval . \u2217 Corresponding authors. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. MM'24, October 28-November 1, 2024, Melbourne, VIC, Australia \u00a9 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0686-8/24/10 https://doi.org/10.1145/3664647.3680574 Fei Wu Zhejiang University Hangzhou, China wufei@zju.edu.cn", "KEYWORDS": "Semenatic Codebook, Dynamic Model, Disentangle, Sequential Recommendation, Multimodal, Personalization", "ACMReference Format:": "Zheqi Lv, Shaoxuan He, Tianyu Zhan, Shengyu Zhang, Wenqiao Zhang, Jingyuan Chen, Zhou Zhao, and Fei Wu. 2024. Semantic Codebook Learning for Dynamic Recommendation Models. In Proceedings of the 32nd ACM International Conference on Multimedia (MM '24), October 28-November 1, 2024, Melbourne, VIC, AustraliaProceedings of the 32nd ACM International Conference on Multimedia (MM'24), October 28-November 1, 2024, Melbourne, Australia. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/ 3664647.3680574", "1 INTRODUCTION": "Nowadays, as an important branch of recommendation systems, sequential recommendation has emerged, including DIN [60], GRU4Rec [12], SASRec [17], BERT4Rec [34] and other models that are crucial in the field of recommendation systems. However, the behavior logic of most users is not universally applicable, and as interests can change, it necessitates that sequence recommendation models be able to adjust their parameters in real-time according to the user's current interest preferences. Consequently, dynamic sequential recommendation models (DSR) like DUET [29] and APG [48] have been developed. The DSR paradigm consists of two parts: (1) The primary model. This model has a structure similar to conventional sequential recommendation models like SASRec, but it is divided into a static layer and a dynamic layer. The parameters of the static layer remain unchanged after pre-training, whereas the parameters of the dynamic layer change with the user's behavior. (2) The parameter generation model. This is mainly used to sparse user behavior and generate the parameters for the dynamic layer of the primary model based on this behavior. The DSR paradigm enables traditional static sequential recommendation models to quickly adjust MM'24, October 28-November 1, 2024, Melbourne, VIC, Australia author name and author name, et al. Figure 1: (a) describes multimodal user behavior data that includes images, text, and IDs. (b) describes the forward propagation of DSR, which is divided into two pathways: the first pathway processes user behavior data composed of IDs through a parameter generator to produce the parameters for the dynamic layers of the primary model. The second pathway processes the same ID-based user behavior data through the primary model's static layer, then through the dynamic layer, resulting in the prediction output. (c) and (d) compare the parameter generation patterns of existing DSR and SOLID. (e) compares the performance of our method and SR models and DSR Models on four multi modal recommendation datasets and four single modal recommendation datasets. The results show that our method significantly enhances performance on extensive datasets. Global Data Personal Data (a) Data (d) SOLID (e) Performance Comparison 3215 2067 7981 Pro Hoops Classic: Versatile Basketball for Any Court High-Top Slam: Elite Men's Basketball Sneakers Global Kick: Match-Grade Soccer Ball for Elite Play Image ID Text (b) Forward Propagation of DSR Recommendation Model \ud835\udeaf Parameter Generation Input Output ! \ud835\udc66 ID Image ID Text Static Layers \ud835\udeaf \ud835\udc94 Dynamic Layers \ud835\udeaf \ud835\udc85 (c) DSR Parameter Generator ID Dynamic Layers \ud835\udeaf \ud835\udc85 Branch Generator Trunk Generator Dynamic Layers \ud835\udeaf \ud835\udc85 \ud835\udeaf \ud835\udc85 \ud835\udc7b \ud835\udeaf \ud835\udc85 \ud835\udc69 Merge Parameter Generation Parameter Generation UAUC Recall@10 \u2026 Codebook Semantic Metacode Oflice Instuuments DIN SASRec APG Music Electronic DUET Ours Oftice Scientific Instruments Book DIN GRU4Rec SASRec BERTARec APG Music Elcctronic DUET Ours their parameters according to the potential shift of interests and intentions reflected in user behaviors, thus dynamically obtaining more interest-aligned models in real time. Despite the promising potential of Dynamic Sequential Recommendation (DSR) systems, they face significant challenges, primarily stemming from the item-to-parameter modeling scheme: (1) A large number of items result in a vast search space for the parameter generation model. Slight variations in user behavior sequences, such as \"shirt, tie, suit\" versus \"tie, shirt, suit, \" which suggest similar preferences, can unpredictably alter the item-to-parameter modeling, introducing complexity and potential instability. (2) The interaction between users and items is generally sparse and potentially noisy ( e.g. , the notorious implicit feedback issue), leading to heterogeneous behavior sequences that complicate the learning of accurate item representations. This results in inaccurate item representation learning, weakening the precision of model parameter customization based on item sequence features, and further exacerbating the inaccuracy of generated parameters. behavior space modeling in the parameter generator. Moreover, SOLID shifts from a traditional item sequence-based parameter generation mode to a dual (item sequence + semantic sequence) \u2192 model parameter generation mode, effectively merging both uniform and diverse information in a structured manner. Uniform information derived from the semantic-to-parameter part is utilized to develop parameters that generalize across certain user behaviors, while diverse information allows for the crafting of specific parameters tailored to individual behavioral nuances. Crucially, by aligning the dimensions of the codebook with those of the semantic encoder, we transform the semantic encoder into a meta-code that serves as an initial state for the codebook, further easing the modeling of parameter generation. To address these issues, we propose the S emantic C o debook L earning for Dynam i c Recommen d ation Models (SOLID). The core objective of SOLID is to compress the search space of the parameter generation model, promoting homogeneity signals utilization within the recommendation system. We construct a semantic codebook that better utilizes these homogeneity signals. In the codebook, item representations are disentangled into semantics that are learned to be absorbed in the codebook elements, such that the homogeneity between items in the disentangled latent space can be established. The user-item interactions are transformed into density-enriched user-semantic interactions in the latent space. The enriched density reduces the heterogeneity and complexity of user Specifically, to reduce the search space of the parameter generation model through the semantic codebook, SOLID involves three main modules. Initially, SOLID employs a pretrained model to extract semantic components from item, image, and text features. This disentanglement transitions the focus from item sequences to semantic sequences, shifting the modeling approach from itembased to semantics-based parameter generation. This design results in trunk parameters that generalize behaviors from the entire user base to specific groups, and branch parameters that cater to individual user behaviors, both derived from semantic and item sequences respectively. Parameters derived from items are tightly controlled (e.g., \u00b10.01) before their integration into the dynamic layer of the primary model, ensuring a responsive and adaptive system based on real-time user activity. Despite this, branch parameters still adhere to an item-centric approach, necessitating the use of a Semantic Codebook (SC) to maintain personalization and stability in representation. This codebook stores semantic vectors of behavior, Semantic Codebook Learning for Dynamic Recommendation Models MM'24, October 28-November 1, 2024, Melbourne, VIC, Australia progressively aligned with the nearest matches during learning. The weights of the semantic encoder are used to initialize the SC, easing the semantic codebook learning. As shown in Figure 1, SOLID is designed to pursue the precision, stability, and clarity of model parameter generation, trying to promote the dynamic recommendation model's response to sparse, heterogeneous, and potentially noisy user behaviors. Our contributions can be summarized as: \u00b7 We pointed the limitations of the existing DSR paradigm and designed the SOLID framework to address these deficiencies. \u00b7 Wefirst learned to disentangle the parameter generation mode, which ensures that the generated model parameters contain both common and personalized knowledge. \u00b7 We transformed the semantic encoder into a semantic metacode to enhance the semantic codebook learning. \u00b7 We conducted extensive experiments on multiple datasets, which demonstrates the rationality and efficacy of SOLID.", "2 RELATED WORK": "", "2.1 Sequential Recommendation": "Recommendation system predicts user preferences based on user behavior history [7, 19, 20, 22-25, 32, 33, 47, 51, 52, 56, 57]. Sequential recommendation, as an important branch of the recommendation system, arranges users' recent historical behaviors in chronological order to more accurately capture users' recent preferences. Recent advancements [4, 12, 17, 26, 27, 29, 34, 45, 48, 60] have shifted towards deep learning-based sequential recommendation systems. For instance, GRU4Rec [12] employs Gated Recurrent Units to effectively model sequential behavior, demonstrating impressive results. Additionally, DIN [60] and SASRec [17] incorporate attention mechanisms and transformers, respectively. BERT4Rec [34] further applies BERT for superior outcomes in recommendation task. The models have significantly impacted academic research and industry practices. However, these SR Models struggle to achieve optimal performance across every data distribution when dealing with users' real-time changing behaviors and interest preferences.", "2.2 Disentangled Representation Learning": "The goal of disentangled representation learning is to parse the data into distinct, interpretable components by identifying different underlying latent factors [2, 3]. Variational autoencoders (VAE) [5] and \ud835\udefd -VAE [13] provide more possibilities for disentangled learning by adjusting the balance between the model's disentanglement ability and its ability to represent information. By incorporating multiinterest methods [18, 30] along with disentangled representation learning, several studies [41-44, 58] have demonstrated significant advancements in recommendation tasks. We draw on the idea of disentangling and apply it to dynamic model parameter generation to reduce the parameter search space and leverage the homogeneous information of user behavior.", "2.3 Dynamic Neural Network": "Research in dynamic neural networks focuses on HyperNetworks [11] and Dynamic Filter Networks [16], which have better ability to adapt to distribution deviations than traditional static model learning or other efficient fine-tuning strategies [6, 9, 14, 15, 21, 36, 38, 39, 55, 59, 63, 65]. Similar situations also exist in the study of large models [53, 61, 62, 64]. HyperNetworks, introduced by Ha et al. [11], use one neural network to dynamically generate parameters for another, reducing the number of parameters needed and achieving model compression. This concept has led to extensive exploration and enhancements in various applications [1, 8, 10, 31, 35, 37, 46, 50, 53, 54]. Some recent research includes: HyperInverter [8], HyperStyle [1], Detective [54] introduces dynamic neural networks into multiple computer vision tasks to improve the model's personalization capabilities under various data distributions. IntellectReq [28] detects when such dynamic networks need to modify parameters to adapt to samples, thereby achieving better performance with fewer parameter modifier calls. APG[48] and DUET [29] are the latest and state-of-the-art examples of using dynamic neural networks for sequence recommendation. However, existing DSR models are affected by the heterogeneity of user behavior, the sparsity of user-item interactions, etc., leading to drawbacks such as an overly large parameter search space and inaccurate parameter generation. Our method effectively addresses these shortcomings.", "3 METHODOLOGY": "", "3.1 Notations and Problem Formulation": "First, we introduce the notation in sequential recommendations. 3.1.1 Data. We use X ori = { \ud835\udc62, \ud835\udc63, \ud835\udc60 \ud835\udc63 } to represent a piece of data, X dec = { \ud835\udc62, \ud835\udc50, \ud835\udc60 \ud835\udc50 } to represent a piece of disentangled data, X mm = { \ud835\udc56, \ud835\udc61 } to represent multimodal information, and Y = { \ud835\udc66 } to represent the label indicating whether the user will interact with the item. In brief, X = X ori \u222a X dec \u222a X mm = { \ud835\udc62, \ud835\udc63, \ud835\udc60 \ud835\udc63 , \ud835\udc50, \ud835\udc60 \ud835\udc50 , \ud835\udc56, \ud835\udc61 } , where \ud835\udc62, \ud835\udc63, \ud835\udc50, \ud835\udc60 \ud835\udc63 , \ud835\udc60 \ud835\udc50 , \ud835\udc56, \ud835\udc61 represent user ID, item ID, category ID, user's click sequence consists of item ID, user's click sequence consists of category ID, the image of the item, and the title of the item respectively. We represent the dataset as D , where D = { \ud835\udc4b,\ud835\udc4c } . More specifically, we use D Train to represent the training set and D Test to represent the test set. Roughly speaking, let L be the loss obtained from training on dataset D Train . For simplicity, we simplify the symbol D Train to D . Then, the model parameters \ud835\udc4a can be obtained through the optimization function arg min L . The sequence length inputted into the model is set to \ud835\udc3f \ud835\udc60 , so the lengths of both \ud835\udc60 \ud835\udc63 and \ud835\udc60 \ud835\udc50 in a sample are \ud835\udc3f \ud835\udc60 . 3.1.2 Model. The recommendation model is represented by M and the parameters of the M is \u0398 , where \u0398 = \u0398 \ud835\udc60 , \u0398 \ud835\udc51 . The model M \ud835\udc63 is utilized to generate the \u0398 \ud835\udc51 according to the item id sequence \ud835\udc60 \ud835\udc63 , M \ud835\udc50 is utilized to generate the \u0398 \ud835\udc51 according to the category id sequence \ud835\udc60 \ud835\udc50 , M(\u00b7) and M \ud835\udc63 (\u00b7) represent the forward propagation processes of two models, where \u00b7 denotes the input. 3.1.3 Feature. We use Ev and Ec to represent the item feature set and semantic feature set extracted from \ud835\udc60 \ud835\udc63 and \ud835\udc60 \ud835\udc50 respectively. Specifically, Ev = { \ud835\udc52 1 \ud835\udc63 , \ud835\udc52 2 \ud835\udc63 , ..., \ud835\udc52 \ud835\udc3f \ud835\udc60 \ud835\udc63 } , Ec = { \ud835\udc52 1 \ud835\udc50 , \ud835\udc52 2 \ud835\udc50 , ..., \ud835\udc52 \ud835\udc3f \ud835\udc60 \ud835\udc50 } . ev and ec are the sequence features obtained through sequence feature extraction models such as Transformer or GRU, via Ev and Ec , respectively. The length of an item representation or a semantic representation is set to \ud835\udc3f \ud835\udc5f . MM'24, October 28-November 1, 2024, Melbourne, VIC, Australia author name and author name, et al. Data Inject Figure 2: The framework of the SOLID, which consists of three main modules: Semantic Parameter Generation (SPG), Semantic Metacode Learning (SML), and Semantic Codebook Learning (SCL). SPG first converts item representations into semantics and constructs a semantic sequence to generate parameters in a structured manner. Subsequently, SML generates model parameters based on both the item sequence and the semantic sequence, and it jointly trains the model, accommodating both homogeneous and heterogeneous information. More importantly, the semantic encoder it learns can be transformed into metacode, which then provides a good initial value for the codebook. Finally, SCL learns a semantic codebook to improve the process of the parameter generation. Among them, L Rec = \ud835\udc59 CE ( \ud835\udc66, \u02c6 \ud835\udc66 ) , L Con = \ud835\udc59 MSE ( E \ud835\udc63 , E \u2032 \ud835\udc63 ) . SOLID Framework Item Sequence \ud835\udc52 & \u2717 Item-based Prediction \u2026 \u2026 Semantic Metacode Semantic Codebook Learning Semantic Codebook Initial Retrieve Nearest Code Replace \u2112 $%& Semantic Codebook \ud835\udc52 & # \ud835\udc52 & % \ud835\udc52 & \" \ud835\udc52 & # \ud835\udc52 & % \ud835\udc52 & \" \ud835\udc52 & # \ud835\udc52 & % \ud835\udc52 & \" \ud835\udc52 & (# \ud835\udc52 & (% \ud835\udc52 & (\" ID \u2112 '(! \ud835\udc52 ) \ud835\udc52 & Semantic Metacode Learning Semantic Sequence Item Sequence \u2112 '(! \u2717 Ground- Truth Encoder to Metacode Semantic Encoder Item Encoder Semantic Parameters Generation \ud835\udc52 & Item Sequence Joint Generation Image ID Text Semantic Sequence Item Encoder In the training stage, the loss can be calculated to optimize the sequential recommendation models as follows, \ud835\udc52 Image Text Semantic Sequence \ud835\udc52 ! \" \ud835\udc52 ! # \ud835\udc52 $ % \ud835\udc52 $ Semantic Metacode Learning Trunk 3.1.4 Formula. Sequential Recommendation Models (SR), Dynamic Sequential Recommendation Models (DSR), and Disentangled Multimodal Dynamic Sequential Recommendation Models (SOLID) can be formalized as follows: $ ID     In the aforementioned formula, \ud835\udc4e \u2192 \ud835\udc4f indicates indicates information transfer from \ud835\udc4e to \ud835\udc4f , with the text next to it representing the content of the transfer. \ud835\udc4e \u21a6\u2192 \ud835\udc4f signifies that \ud835\udc4f is derived from \ud835\udc4e .", "3.2 Preliminary": "3.2.1 Sequential Recommendation Models. Here we first retrospect the paradigm of sequential recommendation. \ud835\udc67 ' & Transformation Layers The loss function can set to CE (Cross Entropy) loss and MSE (Mean Squared Error) loss, etc. However, since sequential recommendation often focuses more on CTR (Click-Through Rate) prediction tasks, and this paper is also focused on CTR prediction, the recommendation loss in this paper is CE loss and represented by \ud835\udc59 CE. \ud835\udc52 3.2.2 Dynamic Sequential Recommendation Models. DSR generate model parameters based on users' real-time user behaviors. Then the updated model is used for current recommendations. In this paper, the network layer that can adjust model parameters as the data distribution changes is called an adaptive layer. DSR treat the parameters of one of the adaptive layers as a matrix \ud835\udc3e \u2208 R \ud835\udc41 \ud835\udc56\ud835\udc5b \u00d7 \ud835\udc41 \ud835\udc5c\ud835\udc62\ud835\udc61 , where \ud835\udc41 \ud835\udc56\ud835\udc5b and \ud835\udc41 \ud835\udc5c\ud835\udc62\ud835\udc61 represent the number of input neurons and output neurons of a fully connected layer (FCL), respectively. DSR utilize a encoder \ud835\udc38 \ud835\udc63 to extract the sequence feature \ud835\udc86 \ud835\udc63 from the user's behavior sequence \ud835\udc60 \ud835\udc63 to generate the parameters of the model's adaptive layers.  After parameter generation, the parameters of the model will be reshaped into the shape of \ud835\udc3e . Semantic Codebook Learning for Dynamic Recommendation Models MM'24, October 28-November 1, 2024, Melbourne, VIC, Australia During training, all layers of the M \ud835\udc63 are optimized together with the static layers of the M . The loss function L is defined as follows:  Although the Item-based Dynamic Recommendation Model can obtain personalized model parameters based on users' real-time behavior and achieve superior performance, it also faces multiple challenges. 1) The user-item interaction is extremely sparse, leading to inaccurate item representation learning, making the model parameters customized based on item-based features inaccurate. 2) The personalized model parameters obtained by this strategy are highly mixed. 3) The generated parameters are not subject to any constraints, which poses challenges to the stability of the generated model. So we design the novel methods to address the challenges mentioned above.", "3.3 SOLID Framework": "The architecture of our proposed SOLID is shown in the Figure 2. 3.3.1 Semantic Parameter Generation. Transforming the Item-based Dynamic Recommendation Model into a Semantic-based Dynamic Recommendation Model is an important step in disentangling personalized model parameters. First, items need to be transformed into semantics. For data without category labels, clustering can be directly applied to obtain semantics, i.e.,  For data with category labels, since the same item often belongs to multiple categories, we select a primary category as semantic it. First, we define the centroid \ud835\udc5a \ud835\udc50 of each category \ud835\udc50 , which is the average of embeddings \ud835\udc52 for all items belonging to category \ud835\udc50 . Assuming \ud835\udc5b \ud835\udc50 is the number of items belonging to category \ud835\udc50 , the centroid \ud835\udc5a \ud835\udc50 for category \ud835\udc50 can be represented as:  where \ud835\udc52 \ud835\udc63 , \ud835\udc52 \ud835\udc56 , \ud835\udc52 \ud835\udc61 are the representation of item ID \ud835\udc63 , item image \ud835\udc56 , item title \ud835\udc61 , respectively. Next, we compute its distance to each category center \ud835\udc5a \ud835\udc50 . Assuming we use the Euclidean distance, it can be represented as,  where \u2225 \u00b7 \u2225 denotes the norm of the vector, typically the Euclidean norm. Finally, we select the closest category as the semantic for item \ud835\udc63 . That is, the semantic \ud835\udc50 \ud835\udc5d for item \ud835\udc63 can be represented as:  After converting items into semantics, a semantic-to-parameter model can be trained. The training process is similar to that of the item-to-parameter model. The only differences are that the input for the item-to-parameter model is an item sequence, whereas for the semantic-to-parameter model, it is a semantic sequence; similarly, the outputs are the target item and target semantic, respectively.  \uf8f3 In the above equation, \ud835\udc38 \ud835\udc50 represents the semantic encoder, which is similar to the item encoder \ud835\udc38 \ud835\udc63 . 3.3.2 Semantic Metacode Learning. To balance the use of personalized user behavior information and homogeneous information from similar user behaviors, we combine the item-to-parameter and semantic-to-parameter models for the parameter generation process. The former's advantage lies in providing personalized information, but its disadvantage is the inaccuracy in parameter generation due to strong data heterogeneity and sparse user-item interactions. The latter's advantage is providing homogeneous information from similar user behaviors, and dense user-item interactions make the parameter generation process more robust. However, its disadvantage is that the semantic sequence is less personalized compared to the item sequence. Therefore, our approach primarily uses the semantic-to-parameter method to generate the main part of the model parameters. Since similar semantic sequences are easier to obtain than similar item sequences, the parameters derived from the semantic sequence can be viewed as a user group model. Then, the item-to-parameter method is used as a branch, with parameters generated from item sequences being constrained within a smaller threshold and merged with the parameters obtained from the semantic sequence. This merging process is seen as a transition from a user group model to an individual user model, thus balancing homogeneous information and personalized information. Therefore, the training process can be formulated as the following optimization problem,  \uf8f3 where T is a hyperparameter used to control the threshold for parameter deviation, thereby also controlling the impact of personalized information on the model parameters. Semantic Encoder can be transformed into a Semantic Metacode(SM), which can be used to further enhance the initialization of the Semantic Codebook for the item-to-parameter process. The Semantic Metacode can be effectively learned through the above process. 3.3.3 Semantic Codebook Learning. Even if the model parameter generation process is disentangled, the item-to-parameter mode is still needed because it is the source of personalized information. Therefore, to further improve the accuracy of the item-to-parameter mapping, we design a Semantic Codebook (SC). Upon obtaining the semantic metacode, we initialize the semantic codebook with it. Subsequently, we continue using the trunk and branch method of parameter generation, specifically semantic-to-parameter and item-to-parameter, to derive the parameters for the adaptive layer of the model. In the branch branch, the item representations are replaced with semantic codes from the codebook, which are then used to further predict model parameters. The generated model parameters are used for click prediction on item sequences, just as before, ultimately allowing for the training of the semantic codebook. The specific method for computing the loss is described below. SC is denoted as \ud835\udc37 , and \ud835\udc37 \u2208 R N \ud835\udc50 \u00d7 \ud835\udc3f \ud835\udc5f . Specifically, we first use the weights of the semantic encoder in the semantic-to-parameter to initialize the item representation, as their dimensions are the same. MM'24, October 28-November 1, 2024, Melbourne, VIC, Australia author name and author name, et al. Then, we encode the user's item representation. For a piece of data, as introduced in the notation description section, its item representation is E \ud835\udc63 = { \ud835\udc52 1 \ud835\udc63 , \ud835\udc52 2 \ud835\udc63 , ..., \ud835\udc52 \ud835\udc3f \ud835\udc60 \ud835\udc63 } . Afterward, we find the closest feature in the SC to replace each item representation in the set E \ud835\udc63 , obtaining E \u2032 \ud835\udc63 = { \ud835\udc52 \u2032 1 \ud835\udc63 , \ud835\udc52 \u2032 2 \ud835\udc63 , ..., \ud835\udc52 \u2032 \ud835\udc3f \ud835\udc60 \ud835\udc63 } , and the sequence feature obtained from E \u2032 \ud835\udc63 is \ud835\udc52 \u2032 \ud835\udc63 . Subsequently, we compute the MSE loss between the item representation set E \u2032 \ud835\udc63 obtained from the SC and the original set E \ud835\udc63 , and incorporate it into the training process as follows,  \uf8f3 where \ud835\udc59 MSE represents the MSE loss, and the \ud835\udf06 is a hyperparameter. 3.3.4 Pseudo Code of SOLID. Algorithm 1 shows the pseudo code of SOLID. ( \ud835\udc65 ) represents that \ud835\udc65 is a intermediate variable.", "4 EXPERIMENTS": "", "4.1 Experimental Setup": "4.1.1 Datasets and Preprocessing. We evaluate SOLID and baselines on eight datasets. Amazon Arts (Arts) , Amazon Instruments (Instruments) , Amazon Office (Office) , Amazon Scientific (Scientific) , which are four benchmarks that was recently released but has been widely used in the multimodal recommendation tasks [40]. Amazon CDs (CDs) , Amazon Electronic (Electronic) , Douban Book (Book) , and Douban Music (Music) , which are four widely used public benchmarks in the recommendation tasks. We choose the leave-one-out approach to process the dataset, taking the last action of each user for testing and all previous actions for training and validation. Our task is CTR (Clickthrough Rate) prediction, so we process these datasets into CTR prediction datasets. These datasets consist of user rating datasets with complete reviews. We treat all user-item interactions in the dataset as positive samples because having a rating implies that the user clicked on the item. Further, to ensure the training process goes smoothly with both positive and negative samples, we sample 4 negative samples for each positive sample in the training set and 99 negative samples for each positive sample in the test set. 4.1.2 Baselines. The baselines we select are as follows: \u00b7 Static Recommendation Models. DIN [60], GRU4Rec [12], SASRec [17], and BERT4Rec [34] are all highly prevalent sequential recommendation methods in both academic research and the industry. They each incorporate different techniques, such as Attention, GRU (Gated Recurrent Unit), and SelfAttention, to enhance the recommendation process. \u00b7 Dynamic Recommendation Models. DUET [29] and APG [48] consists of two parts: a parameter generation model and a primary model. The primary model refers to the aforementioned models like DIN, GRU4Rec, SASRec, BERT4Rec, etc. After pre-training, the parameter generation model can generate model parameters for the primary model during inference based on the samples. 4.1.3 Evaluation Metrics. We use the widely adopted AUC , UAUC , NDCG , and Recall as the metrics to evaluate model performance. Algorithm 1: Pseudo code of SOLID", "Module 1: \u25b7 Item to Semantic": "Target : Item Sequence \ud835\udc60 \ud835\udc63 \u21a6\u2192 Semantic Sequence \ud835\udc60 \ud835\udc50 Input : Item Sequence \ud835\udc60 \ud835\udc63 Output : Semantic Sequence \ud835\udc60 \ud835\udc50", "Module 2: \u25b7 Semantic Parameter Generation": "Target : Semantic Sequence \ud835\udc60 \ud835\udc50 \u21a6\u2192 Semantic Parameter Generator M \ud835\udc50 and Semantic Encoder \ud835\udc38 \ud835\udc50 Input : Semantic Sequence \ud835\udc60 \ud835\udc50 Output : (Parameter \u0398 \ud835\udc51 ), Prediction \u02c6 \ud835\udc66", "Module 3: \u25b7 Semantic Metacode Learning": "Target : Item Sequence \ud835\udc60 \ud835\udc63 , Semantic Sequence \ud835\udc60 \ud835\udc50 \u21a6\u2192 Item Pa- rameter Generator M \ud835\udc63 , Item Encoder \ud835\udc38 \ud835\udc63 , Semantic Parameter Generator M \ud835\udc50 , and Semantic Encoder \ud835\udc38 \ud835\udc50 Input : Item Sequence \ud835\udc60 \ud835\udc63 , Semantic Sequence \ud835\udc60 \ud835\udc50 Output : (Parameter \u0398 \ud835\udc51 ), Prediction \u02c6 \ud835\udc66", "Module 4: \u25b7 Semantic Codebook Learning": "Target : Item Sequence \ud835\udc60 \ud835\udc63 , Semantic Sequence \ud835\udc60 \ud835\udc50 , Semantic Encoder \ud835\udc38 \ud835\udc50 \u21a6\u2192 Codebook \ud835\udc37 Input : Item Sequence \ud835\udc60 \ud835\udc63 , Semantic Sequence \ud835\udc60 \ud835\udc50 , (Semantic Encoder \ud835\udc38 \ud835\udc50 ) Output : (Parameter \u0398 \ud835\udc51 ), Prediction \u02c6 \ud835\udc66 Overview: \u25b7 Training Procedure Input : Item Sequence \ud835\udc60 \ud835\udc63 , Semantic Sequence \ud835\udc60 \ud835\udc50 . Output : (Parameters \u0398 \ud835\udc51 ), Prediction \u02c6 \ud835\udc66 . Initialization : Randomly initialize the models M , M \ud835\udc50 , M \ud835\udc63 with parameters \u0398 \ud835\udc60 , \u0398 \ud835\udc50 , \u0398 \ud835\udc63 respectively. Item Sequence \ud835\udc60 \ud835\udc63 \u21a6\u2192 Semantic Sequence \ud835\udc60 \ud835\udc50", "repeat": "if M \ud835\udc50 and \ud835\udc38 \ud835\udc50 have not yet been well-trained then Train as Eq.12 end until Convergence ; Initialization : Initialize \ud835\udc37 via pretrained \ud835\udc38 \ud835\udc50 repeat if M \ud835\udc50 and \ud835\udc38 \ud835\udc50 have not yet been well-trained then Train as Eq.13 end until Convergence ; return M \ud835\udc50 , M \ud835\udc63 , \ud835\udc37 .", "4.2 Overall Results": "As shown in Table 1, we evaluate the overall performance across four multimodal datasets: Arts, Instruments, Office, and Scientific. For each dataset, we test the performance of four SR Models: DIN, GRU4Rec, SASRec, and BERT4Rec. We evaluate performance via AUC, UAUC, NDCG@10, Recall@10, NDCG@20, and Recall@20. For each SR Model, there are five options for DSR Models: None ('-'), APG, Ours (APG), DUET, and Ours (DUET), where '-' indicates no DSR Model usage, i.e., the inherent performance of the SR Model itself. Since the '-' option consistently performs worse than using a DSR Model, our comparison primarily focuses on the performance of APG vs. Ours (APG) and DUET vs. Ours (DUET) Semantic Codebook Learning for Dynamic Recommendation Models MM'24, October 28-November 1, 2024, Melbourne, VIC, Australia Table 1: Performance comparison of the proposed method and baselines. The best results is in bold. for each SR Model. Across all datasets, all SR Models, and all metrics, our proposed methods significantly outperform both APG and DUET. We conducted experiments on four other commonly used recommendation datasets and compared the UAUC metric in Figures 3 and 4. Our method ({SR=SASRec, DSR=DUET}) significantly outperforms other SR and DSR Models across all the datasets. Figure 3: UAUC comparison of the proposed method and baseline on the CDs and Electronic datasets. (a) Amazon CDs (b) Amazon Electronic Figure 4: UAUC comparison of the proposed method and baseline on the Book and Music datasets. DIN GRU4Rec SASRec BERT4Rec APG DUET Ours Models 0.85 0.86 0.87 0.88 0.89 UAUC 0.8709 0.8718 0.8784 0.8673 0.8809 0.8826 0.8851 (a) Douban Book (b) Douban Music", "4.3 Ablation Study": "We conduct ablation studies on each dataset, each SR and each DSR to further analyze the impact of modules and modalities. The ablation results on each dataset, DR, and DSR combinations are similar, so we only show the results under the condition {Dataset=Arts, SR=SASRec, DSR=DUET}. Each row's ! and % respectively indicate with and without the module/modality. MM'24, October 28-November 1, 2024, Melbourne, VIC, Australia author name and author name, et al. 4.3.1 Ablation Study on Modules. As shown in Table 2, we conduct an ablation study on each module proposed in our method, SPG stands for Semantic Parameter Generation, SML stands for Semantic Metacode Learning, and SCL stands for Semancic Codebook Learning. Since SPG is a prerequisite for SML, SML cannot exist independently of SPG; therefore, there is no separate performance data for SML alone in the table. The first line represents the traditional DSR model where parameters are generated using an item sequence. The second line represents generating parameters using a semantic sequence. The third line represents the joint generation of parameters using both item sequence and semantic sequence, with joint training. The fourth line represents using semantic codebook learning without using semantic information. The fifth line represents our complete method. The experiments show that the model performs best when all three modules are used. In terms of individual modules, SCL has the greatest impact on performance. Table 2: Results of the ablation study over our proposed methods with respect to the modules. The best results is in bold. 4.3.2 Ablation Study on Modalities. As shown in Table 3, we conduct ablation study on each modality. The experimental results show that the fusion of three modalities-ID, Image, and Text-is not necessarily the best option. In terms of the impact on performance for individual modalities, Text > Image > ID. For the fusion of two modalities, in terms of impact on performance, ID + Text > Image + Text > ID + Image. Table 3: Results of the ablation study over our proposed methods with respect to the modalities. The best results is in bold.", "4.4 Depth Analysis": "We further conduct depth analysis to demonstrate the effectiveness. Unless otherwise specified, the dataset, SR, and DSR default to Arts, SASRec, and DUET, respectively. Note that we get similar results for all settings, but only a subset of them are shown here. 4.4.1 Stability and Robustness. Wetested the variance of the UAUC for SOLID and DUET on each user in the Arts dataset when faced with similar user behaviors. Specifically, we added one user behavior at a time for each user behavior and calculated the performance variance. We then aggregated the variances for all users to obtain the median, mean, minimum, and maximum of these variances. Table 4 shows that SOLID has stronger stability and robustness compared to DUET. Table 4: Variance comparison. 4.4.2 Cost Comparison. In Table 5, we do analysis based on the BERT4Rec (the biggest SR in our paper), the increased memory and time are not important because the increase is slight and does not affect real-time performance [29, 49]. Table 5: Cost of our method. 4.4.3 Hyperparameter Analysis. To analyze the impace of the main hyperparameters \ud835\udf06 and T , we conduct grid search experiment. As shown in Figure 5, the horizontal axis represents \ud835\udf06 , and the vertical axis represents T . The depth of the color and the radius of the circle represent the magnitude of the value; the larger the value, the deeper the color and the larger the circle (i.e., the larger the radius). Blue, green, and orange represent the metrics UAUC, NDCG@10, and Recall@10, respectively. The results show that the best performance is achieved when \ud835\udf06 = 0 . 1 and T = 0 . 01. Figure 5: Hyperparameter Grid Search. 10 2 10 0 10 3 10 2 10 1 10 0 10 1 10 3 0.7867 UAUC NDCG@10 Recall@10 0.3560 0.1792 0.7115 0.3022 0.5216", "5 CONCLUSION": "In this paper, we have presented the Semantic Codebook Learning for Dynamic Recommendation Models (SOLID) as a solution to the limitations faced by existing dynamic sequence recommendation systems (DSR). Our framework integrates multimodal information, including images and text, with user-item interactions to enhance recommendation accuracy and adaptability. By disentangling model parameters into trunk parameters capturing generalized user behavior trends and branch parameters tailored to individual user actions, SOLID offers a more efficient and effective recommendation system. Through extensive experimentation across multiple datasets, we have demonstrated that SOLID significantly outperforms previous DSR models, with an significant improvement on extensive datasets and models. These results underscore the potential of leveraging multimodal information to advance the capabilities of dynamic recommendation systems, paving the way for more personalized and responsive user experiences in the era of digital personalization. Semantic Codebook Learning for Dynamic Recommendation Models MM'24, October 28-November 1, 2024, Melbourne, VIC, Australia", "ACKNOWLEDGEMENTS": "National Science and Technology Major Project (2022ZD0119100), Scientific Research Fund of Zhejiang Provincial Education Department (Y202353679), Key Research and Development Program of Zhejiang Province (No. 2024C03270), National Natural Science Foundation of China (No. 62441605), the StarryNight Science Fund of Zhejiang University Shanghai Institute for Advanced Study (SNZJU-SIAS-0010).", "REFERENCES": "[1] Yuval Alaluf, Omer Tov, Ron Mokady, Rinon Gal, and Amit Bermano. 2022. Hyperstyle: Stylegan inversion with hypernetworks for real image editing. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 18511-18521. [2] Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2013. Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence 35, 8 (2013), 1798-1828. [3] Yukuo Cen, Jianwei Zhang, Xu Zou, Chang Zhou, Hongxia Yang, and Jie Tang. 2020. Controllable multi-interest framework for recommendation. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 2942-2951. [4] Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song, Depeng Jin, and Yong Li. 2021. Sequential recommendation with graph neural networks. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval . 378-387. [5] Yongjun Chen, Zhiwei Liu, Jia Li, Julian McAuley, and Caiming Xiong. 2022. Intent contrastive learning for sequential recommendation. In Proceedings of the ACM Web Conference 2022 . 2172-2182. [6] Zhengyu Chen, Teng Xiao, Kun Kuang, Zheqi Lv, Min Zhang, Jinluan Yang, Chengqiang Lu, Hongxia Yang, and Fei Wu. 2024. Learning to Reweight for Generalizable Graph Neural Network. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 38. 8320-8328. [7] Zhengyu Chen, Ziqing Xu, and Donglin Wang. 2021. Deep transfer tensor decomposition with orthogonal constraint for recommender systems. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 35. 4010-4018. [8] Tan M Dinh, Anh Tuan Tran, Rang Nguyen, and Binh-Son Hua. 2022. Hyperinverter: Improving stylegan inversion via hypernetwork. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 11389-11398. [9] Junhao Feng, Guohua Wang, Changmeng Zheng, Yi Cai, Ze Fu, Yaowei Wang, Xiao-Yong Wei, and Qing Li. 2023. Towards bridged vision and language: Learning cross-modal knowledge representation for relation extraction. IEEE Transactions on Circuits and Systems for Video Technology 34, 1 (2023), 561-575. [10] Kairui Fu, Shengyu Zhang, Zheqi Lv, Jingyuan Chen, and Jiwei Li. 2024. DIET: Customized Slimming for Incompatible Networks in Sequential Recommendation. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . [11] David Ha, Andrew M. Dai, and Quoc V. Le. 2017. HyperNetworks. In 5th International Conference on Learning Representations, ICLR 2017 . [12] Bal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based recommendations with recurrent neural networks. International Conference on Learning Representations 2016 (2016). [13] Irina Higgins, Loic Matthey, Arka Pal, Christopher P Burgess, Xavier Glorot, Matthew M Botvinick, Shakir Mohamed, and Alexander Lerchner. 2017. beta-vae: Learning basic visual concepts with a constrained variational framework. ICLR (Poster) 3 (2017). [14] Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang Yin, and Zhou Zhao. 2023. Make-an-audio: Textto-audio generation with prompt-enhanced diffusion models. In International Conference on Machine Learning . PMLR, 13916-13932. [15] Rongjie Huang, Max WY Lam, Jun Wang, Dan Su, Dong Yu, Yi Ren, and Zhou Zhao. 2022. Fastdiff: A fast conditional diffusion model for high-quality speech synthesis. arXiv preprint arXiv:2204.09934 (2022). [16] Xu Jia, Bert De Brabandere, Tinne Tuytelaars, and Luc V Gool. 2016. Dynamic filter networks. Advances in neural information processing systems 29 (2016). [17] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In 2018 IEEE International Conference on Data Mining (ICDM) . IEEE, 197-206. [18] Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013). [19] Haoxuan Li, Chunyuan Zheng, Yixiao Cao, Zhi Geng, Yue Liu, and Peng Wu. 2023. Trustworthy policy learning under the counterfactual no-harm criterion. In International Conference on Machine Learning . PMLR, 20575-20598. [20] Haoxuan Li, Chunyuan Zheng, Peng Wu, Kun Kuang, Yue Liu, and Peng Cui. 2023. Who should be given incentives? counterfactual optimal treatment regimes learning for recommendation. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 1235-1247. [21] Juncheng Li, Xin He, Longhui Wei, Long Qian, Linchao Zhu, Lingxi Xie, Yueting Zhuang, Qi Tian, and Siliang Tang. 2022. Fine-grained semantically aligned vision-language pre-training. Advances in neural information processing systems 35 (2022), 7290-7303. [22] Xinting Liao, Weiming Liu, Xiaolin Zheng, Binhui Yao, and Chaochao Chen. 2023. Ppgencdr: A stable and robust framework for privacy-preserving cross-domain recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 37. 4453-4461. [23] Xinyu Lin, Wenjie Wang, Yongqi Li, Shuo Yang, Fuli Feng, Yinwei Wei, and TatSeng Chua. 2024. Data-efficient Fine-tuning for LLM-based Recommendation. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval . 365-374. [24] Xinyu Lin, Wenjie Wang, Jujia Zhao, Yongqi Li, Fuli Feng, and Tat-Seng Chua. 2024. Temporally and distributionally robust optimization for cold-start recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 38. 8750-8758. [25] Weiming Liu, Chaochao Chen, Xinting Liao, Mengling Hu, Yanchao Tan, Fan Wang, Xiaolin Zheng, and Yew Soon Ong. 2024. Learning Accurate and Bidirectional Transformation via Dynamic Embedding Transportation for Cross-Domain Recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 38. 8815-8823. [26] Weiming Liu, Xiaolin Zheng, Chaochao Chen, Jiajie Su, Xinting Liao, Mengling Hu, and Yanchao Tan. 2023. Joint internal multi-interest exploration and external domain alignment for cross domain sequential recommendation. In Proceedings of the ACM Web Conference 2023 . 383-394. [27] Zheqi Lv, Feng Wang, Shengyu Zhang, Wenqiao Zhang, Kun Kuang, and Fei Wu. 2023. Parameters Efficient Fine-Tuning for Long-Tailed Sequential Recommendation. In CAAI International Conference on Artificial Intelligence . Springer, 442-459. [28] Zheqi Lv, Wenqiao Zhang, Zhengyu Chen, Shengyu Zhang, and Kun Kuang. 2024. Intelligent model update strategy for sequential recommendation. In Proceedings of the ACM on Web Conference 2024 . 3117-3128. [29] Zheqi Lv, Wenqiao Zhang, Shengyu Zhang, Kun Kuang, Feng Wang, Yongwei Wang, Zhengyu Chen, Tao Shen, Hongxia Yang, Beng Chin Ooi, and Fei Wu. 2023. DUET: A Tuning-Free Device-Cloud Collaborative Parameters Generation Framework for Efficient Device Model Generalization. In Proceedings of the ACM Web Conference 2023 . [30] Jianxin Ma, Chang Zhou, Hongxia Yang, Peng Cui, Xin Wang, and Wenwu Zhu. 2020. Disentangled self-supervision in sequential recommenders. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 483-491. [31] Aviv Shamsian, Aviv Navon, Ethan Fetaya, and Gal Chechik. 2021. Personalized federated learning using hypernetworks. In International Conference on Machine Learning . PMLR, 9489-9502. [32] Jiajie Su, Chaochao Chen, Zibin Lin, Xi Li, Weiming Liu, and Xiaolin Zheng. 2023. Personalized behavior-aware transformer for multi-behavior sequential recommendation. In Proceedings of the 31st ACM International Conference on Multimedia . 6321-6331. [33] Jiajie Su, Chaochao Chen, Weiming Liu, Fei Wu, Xiaolin Zheng, and Haoming Lyu. 2023. Enhancing hierarchy-aware graph networks with deep dual clustering for session-based recommendation. In Proceedings of the ACM Web Conference 2023 . 165-176. [34] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM international conference on information and knowledge management . 1441-1450. [35] Zihao Tang, Zheqi Lv, Shengyu Zhang, Fei Wu, and Kun Kuang. 2024. ModelGPT: Unleashing LLM's Capabilities for Tailored Model Generation. arXiv preprint arXiv:2402.12408 (2024). [36] Zihao Tang, Shengyu Zhang, Zheqi Lv, Yifan Zhou, Xinyu Duan, Kun Kuang, and Fei Wu. 2024. AuG-KD: Anchor-Based Mixup Generation for Out-ofDomain Knowledge Distillation. In 12th International Conference on Learning Representations, ICLR 2024, Vienna Austria, May 7-11, 2024 . OpenReview.net. https://openreview.net/forum?id=fcqWJ8JgMR [37] Johannes von Oswald, Christian Henning, Jo\u00e3o Sacramento, and Benjamin F. Grewe. 2020. Continual learning with hypernetworks. In 8th International Conference on Learning Representations, ICLR 2020 . [38] Jiawei Wang, Yuquan Le, Da Cao, Shaofei Lu, Zhe Quan, and Meng Wang. 2024. Graph Reasoning With Supervised Contrastive Learning for Legal Judgment Prediction. IEEE Transactions on Neural Networks and Learning Systems (2024). [39] Jiawei Wang, Zhanchang Ma, Da Cao, Yuquan Le, Junbin Xiao, and Tat-Seng Chua. 2023. Deconfounded Multimodal Learning for Spatio-temporal Video Grounding. In Proceedings of the 31st ACM International Conference on Multimedia . 7521-7529. [40] Jinpeng Wang, Ziyun Zeng, Yunxiao Wang, Yuting Wang, Xingyu Lu, Tianxiang Li, Jun Yuan, Rui Zhang, Hai-Tao Zheng, and Shu-Tao Xia. 2023. Missrec: Pretraining and transferring multi-modal interest-aware sequence representation MM'24, October 28-November 1, 2024, Melbourne, VIC, Australia author name and author name, et al. for recommendation. In Proceedings of the 31st ACM International Conference on Multimedia . 6548-6557. [41] Xin Wang, Hong Chen, Si'ao Tang, Zihao Wu, and Wenwu Zhu. 2022. Disentangled representation learning. arXiv preprint arXiv:2211.11695 (2022). [42] Xin Wang, Hong Chen, Yuwei Zhou, Jianxin Ma, and Wenwu Zhu. 2022. Disentangled representation learning for recommendation. IEEE Transactions on Pattern Analysis and Machine Intelligence 45, 1 (2022), 408-424. [43] Xin Wang, Hong Chen, and Wenwu Zhu. 2021. Multimodal disentangled representation for recommendation. In 2021 IEEE International Conference on Multimedia and Expo (ICME) . IEEE, 1-6. [44] Xin Wang, Zirui Pan, Yuwei Zhou, Hong Chen, Chendi Ge, and Wenwu Zhu. 2023. Curriculum co-disentangled representation learning across multiple environments for social recommendation. In International Conference on Machine Learning . PMLR, 36174-36192. [45] Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-based recommendation with graph neural networks. In Proceedings of the AAAI conference on artificial intelligence , Vol. 33. 346-353. [46] Zhou Xian, Shamit Lal, Hsiao-Yu Tung, Emmanouil Antonios Platanios, and Katerina Fragkiadaki. 2021. HyperDynamics: Meta-Learning Object and Agent Dynamics with Hypernetworks. In 9th International Conference on Learning Representations, ICLR 2021 . [47] Teng Xiao, Zhengyu Chen, and Suhang Wang. 2023. Reconsidering Learning Objectives in Unbiased Recommendation: A Distribution Shift Perspective. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 2764-2775. [48] Bencheng Yan, Pengjie Wang, Kai Zhang, Feng Li, Jian Xu, and Bo Zheng. 2022. APG: Adaptive Parameter Generation Network for Click-Through Rate Prediction. In Advances in Neural Information Processing Systems . [49] Jiangchao Yao, Feng Wang, Xichen Ding, Shaohu Chen, Bo Han, Jingren Zhou, and Hongxia Yang. 2022. Device-cloud Collaborative Recommendation via Meta Controller. In KDD'22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022 . 4353-4362. [50] Chris Zhang, Mengye Ren, and Raquel Urtasun. 2019. Graph HyperNetworks for Neural Architecture Search. In 7th International Conference on Learning Representations, ICLR 2019 . [51] Jinghao Zhang, Yanqiao Zhu, Qiang Liu, Shu Wu, Shuhui Wang, and Liang Wang. 2021. Mining latent structures for multimedia recommendation. In Proceedings of the 29th ACM international conference on multimedia . 3872-3880. [52] Jinghao Zhang, Yanqiao Zhu, Qiang Liu, Mengqi Zhang, Shu Wu, and Liang Wang. 2022. Latent structure mining with contrastive modality fusion for multimedia recommendation. IEEE Transactions on Knowledge and Data Engineering 35, 9 (2022), 9154-9167. [53] Wenqiao Zhang, Tianwei Lin, Jiang Liu, Fangxun Shu, Haoyuan Li, Lei Zhang, He Wanggui, Hao Zhou, Zheqi Lv, Hao Jiang, et al. 2024. HyperLLaVA: Dynamic Visual and Language Expert Tuning for Multimodal Large Language Models. arXiv preprint arXiv:2403.13447 (2024). [54] Wenqiao Zhang and Zheqi Lv. 2024. Revisiting the domain shift and sample uncertainty in multi-source active domain transfer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 16751-16761. [55] Wenqiao Zhang, Haochen Shi, Siliang Tang, Jun Xiao, Qiang Yu, and Yueting Zhuang. 2021. Consensus graph representation learning for better grounded image captioning. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 35. 3394-3402. [56] Yang Zhang, Fuli Feng, Xiangnan He, Tianxin Wei, Chonggang Song, Guohui Ling, and Yongdong Zhang. 2021. Causal intervention for leveraging popularity bias in recommendation. In Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval . 11-20. [57] Yang Zhang, Tianhao Shi, Fuli Feng, Wenjie Wang, Dingxian Wang, Xiangnan He, and Yongdong Zhang. 2023. Reformulating CTR Prediction: Learning Invariant Feature Interactions for Recommendation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1386-1395. [58] Yin Zhang, Ziwei Zhu, Yun He, and James Caverlee. 2020. Content-collaborative disentanglement representation learning for enhanced recommendation. In Proceedings of the 14th ACM Conference on Recommender Systems . 43-52. [59] Changmeng Zheng, Junhao Feng, Yi Cai, Xiaoyong Wei, and Qing Li. 2023. Rethinking Multimodal Entity and Relation Extraction from a Translation Point of View. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) . 6810-6824. [60] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 1059-1068. [61] Didi Zhu, Yinchuan Li, Min Zhang, Junkun Yuan, Jiashuo Liu, Kun Kuang, and Chao Wu. 2023. Bridging the gap: neural collapse inspired prompt tuning for generalization under class imbalance. arXiv preprint arXiv:2306.15955 (2023). [62] Didi Zhu, Zhongyi Sun, Zexi Li, Tao Shen, Ke Yan, Shouhong Ding, Kun Kuang, and Chao Wu. 2024. Model Tailor: Mitigating Catastrophic Forgetting in Multimodal Large Language Models. arXiv preprint arXiv:2402.12048 (2024). [63] Yun Zhu, Haizhou Shi, Zhenshuo Zhang, and Siliang Tang. 2024. Mario: Model agnostic recipe for improving ood generalization of graph contrastive learning. In Proceedings of the ACM on Web Conference 2024 . 300-311. [64] Yun Zhu, Yaoke Wang, Haizhou Shi, and Siliang Tang. 2024. Efficient tuning and inference for large language models on textual graphs. arXiv preprint arXiv:2401.15569 (2024). [65] Yun Zhu, Yaoke Wang, Haizhou Shi, Zhenshuo Zhang, Dian Jiao, and Siliang Tang. 2024. GraphControl: Adding Conditional Control to Universal Graph Pretrained Models for Graph Domain Transfer Learning. In Proceedings of the ACM on Web Conference 2024 . 539-550.", "A APPENDIX": "This is the Appendix for 'Semantic Codebook Learning for Dynamic Recommendation Models'.", "A.1 Supplementary Experiments": "A.1.1 Datasets. The statistics of the datasets used in the experiments is shown in Table 6.", "Table 6: Statistics of Datasets.": "A.1.2 Hyperparameters and Training Schedules. Wesummarize the hyperparameters and training schedules of the datasets used in the experiments in Table 7. Table 7: Hyperparameters and training schedules of SOLID."}
