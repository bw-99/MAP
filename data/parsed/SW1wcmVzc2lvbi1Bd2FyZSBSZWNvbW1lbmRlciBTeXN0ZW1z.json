{"Impression-Aware Recommender Systems": "FERNANDO B. P\u00c9REZ MAURERA, Politecnico di Milano, Italy and ContentWise, Italy MAURIZIO FERRARI DACREMA, Politecnico di Milano, Italy PABLO CASTELLS, Universidad Aut\u00f3noma de Madrid, Spain and Amazon, Spain Politecnico di Milano, Italy PAOLO CREMONESI, Novel data sources bring new opportunities to improve the quality of recommender systems and serve as a catalyst for the creation of new paradigms on personalized recommendations. Impressions are a novel data source containing the items shown to users on their screens. Past research focused on providing personalized recommendations using interactions, and occasionally using impressions when such a data source was available. Interest in impressions has increased due to their potential to provide more accurate recommendations. Despite this increased interest, research in recommender systems using impressions is still dispersed. Many works have distinct interpretations of impressions and use impressions in recommender systems in numerous different manners. To unify those interpretations into a single framework, we present a systematic literature review on recommender systems using impressions, focusing on three fundamental perspectives: recommendation models , datasets , and evaluation methodologies . We define a theoretical framework to delimit recommender systems using impressions and a novel paradigm for personalized recommendations, called impression-aware recommender systems. We propose a classification system for recommenders in this paradigm, which we use to categorize the recommendation models, datasets, and evaluation methodologies used in past research. Lastly, we identify open questions and future directions, highlighting missing aspects in the reviewed literature. CCSConcepts: \u00b7 Information systems \u2192 Recommendersystems ; Relevance assessment ; Collaborative filtering ; \u00b7 Computing methodologies \u2192 Learning from implicit feedback ; Ranking ; \u00b7 General and reference \u2192 Surveys and overviews . Additional Key Words and Phrases: Recommender Systems, Impression, Slate, Exposure, Dataset, Evaluation", "ACMReference Format:": "Fernando B. P\u00e9rez Maurera, Maurizio Ferrari Dacrema, Pablo Castells, and Paolo Cremonesi. 2024. Impression-Aware Recommender Systems. ACM Trans. Recomm. Syst. 1, 1, Article 1 (December 2024), 44 pages. https://doi.org/10.1145/1122445.1122456", "1 Introduction": "Collaborative filtering can be seen as a paradigmatic approach to personalized recommendations, where the system tracks the interactions with the available options and predicts good choices for individuals by cross-examining the activity of all users. Examples of interactions are the purchase of products (termed implicit interactions) or ratings that users emit to convey their level of satisfaction with products (termed explicit interactions). Despite the success of collaborative filtering models, they present several limitations [7, 58, 104]. For instance, they tend to recommend popular items, create filter bubbles, or fail to recommend relevant items to cold users. Previous research works [3, 97] Authors' Contact Information: Fernando B. P\u00e9rez Maurera, Politecnico di Milano, Milan, Italy and ContentWise, Milan, Italy, fernandobenjamin.perez@ polimi.it; Maurizio Ferrari Dacrema, Politecnico di Milano, Milan, Italy, maurizio.ferrari@polimi.it; Pablo Castells, Universidad Aut\u00f3noma de Madrid, Madrid, Spain and Amazon, Madrid, Spain, pablo.castells@uam.es; Paolo Cremonesi, Politecnico di Milano, Milan, Italy, paolo.cremonesi@polimi.it. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \u00a9 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. Manuscript submitted to ACM Manuscript submitted to ACM 1 A B C D E A: Catalog B: Impressions C: Interactions D: Non-impressions E: Non-interactions Fig. 1. Categorization of items in a recommender system using impressions. Catalog are all items (solid line). Impressions are shown items (dashed line). Interactions are shown and interacted items (dotted line). Non-impressions are not shown items ( \ud835\udc37 = \ud835\udc34 -\ud835\udc35 , i.e., between solid and dashed lines). Non-interactions are not interacted items ( \ud835\udc38 = \ud835\udc34 -\ud835\udc36 , i.e., between solid and dotted lines). propose partial solutions to those limitations using additional data sources, e.g., metadata of products, location of users, social connections between users, among others. Past research [74] has shown that using additional data sources beyond interactions may improve the quality of collaborative filtering recommenders. In this work, we survey the type of recommender systems using impressions as an additional data source. An impression is a collection of items shown on-screen to a given user at a particular time. A user is said to be impressed to each item inside the impression. In the literature, impressions are also called past recommendations [89], previous recommendations [9], exposures [60, 93], or slates [27, 28, 111]. Certain data sources may serve as catalysts to accelerate the creation of novel paradigmatic approaches to personalized recommendations. Impressions are a data source that fosters the creation and research of a novel learning paradigm for personalized recommendations. We call such a paradigm impression-aware recommender systems (IARS). It encapsulates those recommender systems that leverage impressions and interactions to learn users' preferences, regardless of the system's complexity or how they process such data sources. In this learning paradigm, impressions provide many benefits and innovation potential compared to interactions alone in at least three aspects. First, impressions allow the exploration of characteristics of recommender systems that are often unexplored: the items shown on-screen to users, their arrangement, and how users interact with them. Second, impressions enable a refined modeling of users' preferences due to the signals impressions carry. Third, impressions partition the user feedback into further granular levels of users, as shown in Figure 1. The literature contains studies about the new capabilities and opportunities available when using impressions. For instance, Zhao et al. [124] study why users interact with some impressions and not others, while other authors propose methods to learn whether users value impressions positively or negatively [78, 79], and others have researched whether users' perception of impressions change after repeated exposures to the same item [8, 55]. To the best of our knowledge, this work is the first systematic literature review of impressions in recommender systems. Other papers [34, 112] review impressions on non-personalized services focused on click-through rate (ratio between interactions and impressions) prediction, while some reviews study impressions in other types of non-personalized services, e.g., online advertisements [53, 87], search engines [37, 51], social media [56], and others [10, 62]. Manuscript submitted to ACM Despite existing many research works on impressions in recommender systems in the literature, e.g., the papers of Lee et al. [55], Wu et al. [106], or Zhao et al. [124], existing research is dispersed, presents different terminology, and covers distinct and unrelated topics. Moreover, the effective use of impressions in recommender systems is still in a nascent state, leading to the under-utilization of this data source. This work proactively introduces and defines the IARS learning paradigm, i.e., a paradigm that covers all those recommendation models that leverage impressions to produce relevant and personalized recommendations to users. Such a proactive approach reduces the friction existing nowadays and provides a comprehensive framework to classify and study impressions in recommender systems for the future. Consequently, this work aims at unifying the existing research into a single document by reviewing and analyzing IARS under three fundamental topics in recommender systems: recommendation models, public datasets, and evaluation methodologies.", "1.1 Organization": "As previously mentioned, we study recommendation models , datasets with impressions , and evaluation methodologies of IARS. We first define a mathematical framework to describe this type of recommenders in Section 2. Then, we state the similarities and differences of IARS with related types of recommenders under the framework. Lastly, we describe our proposed taxonomies to categorize the literature in this area. Each taxonomy classifies papers based on different aspects. Wecategorize the relevant literature according to the taxonomies and describe each work in Section 3. For this purpose, we discuss each work in six dimensions, each corresponding to one category of one of the proposed taxonomies. In doing so, we first identify and describe common patterns in papers, e.g., whether several papers use the same recommender or technique. Then, we describe each contribution in more detail regarding those patterns. We present and classify the datasets with impressions in Section 4. In particular, the section emphasizes the discussion upon public datasets: published datasets accessible via the Internet or by request to publishers. We propose a categorization of public datasets based on their type of impressions. We briefly present other types of datasets, e.g., those used in competitions or never published. We analyze the challenges, opportunities, and special considerations when evaluating IARS in Section 5. In particular, we focus on the most common research goals and provide guidelines to ensure the evaluation of IARS is executed correctly in the published research. We describe the two most common research goals followed by the reviewed publications. Our discussion includes guidelines for future works to ensure evaluation methodologies are consistent with the research goals. We close the section with descriptions of several challenges contended when using impressions. In Section 6, we present open research questions and future research directions. We describe how impressions enable us to pursue novel directions in recommender system research. Notably, with impressions, we have access to items exposed to users, their frequency, and, in some situations, their arrangement on-screen. This information is crucial in recommender systems, as it alleviates particular roadblocks in the literature.", "1.2 Contributions": "Weundertake a systematic literature review on IARS, collecting, discussing, and analyzing relevant work in this area. We identify recurrent topics in the reviewed literature and discuss future research directions. Specific sought contributions in this work include: \u00b7 A theoretical framework of IARS aiming to unify diverse conceptual representations existing in prior works. Manuscript submitted to ACM Fig. 2. Number of papers reviewed in this work by their publication year (left) and venue (right). 0 2 4 6 8 10 12 2 009 2 010 2 011 2 012 2 013 2 014 2 015 2 016 2 017 2 018 2 019 2 020 2 021 2 022 2 023 1 0 0 0 0 3 0 5 3 2 5 1 1 10 12 Number of papers Publication year 0 2 4 6 8 10 12 KDD WSDM SIGIR RecSys CIKM WWW J. Scheduling CSCW IJCAI TOIS Information Sciences 11 7 6 5 5 4 1 1 1 1 1 Number of papers Venue \u00b7 A comprehensive characterization of IARS under different perspectives. Those perspectives include the design of recommenders, handling of impressions, or users' preferences toward impressions. \u00b7 A review of topics to improve the research quality in future works. Those topics include current public datasets with impressions and evaluation methodologies. \u00b7 A thorough analysis of current trends and open research questions. Those illustrate the short and long-term topics of interest for future research.", "1.3 Paper Selection Criteria": "The selected IARS papers in this literature review conform to the following selection criteria: papers are peer-reviewed, of regular conference or journal types, and published in top-tier venues. For our purpose, we select top-tier A* and A conferences in the CORE 2021 ranking, 1 and Q1 journals in the Scimago 2021 ranking in computer science. 2 Wequeried five popular academic search engines to retrieve candidate papers related to IARS. Specifically, we queried the ACM DL, IEEE Xplore, ScienceDirect, SpringerLink, and Google Scholar. For each search engine, We built a search query matching the keyword recommender system with keywords related to impressions, namely impression, exposure, slate, past recommendation , or previous recommendation . 3 When possible, we instructed the search engine to match such keywords in the papers' titles, abstracts, or contents. When retrieving papers, we applied the selection criteria to keep those papers conforming to them. Lastly, we manually inspected the remaining papers to ensure they were relevant to this work. The manual inspection discarded most papers as the keywords have several meanings in recommender systems, i.e., they are used to represent other topics or concepts. For instance, one paper [16] has the exposure and recommender system keywords in its text. Still, the paper does not publish a dataset with impressions or describe an IARS. Instead, the paper uses the keyword exposure to indicate the number of interactions of items. 1 The Computing Research and Education Association of Australasia (CORE) 2021 ranking is available at: https://portal.core.edu.au/conf-ranks/ 2 The Scimago 2021 ranking in computer science is available at: https://www.scimagojr.com/journalrank.php?area=1700 3 The specific search query is: recommender system AND (impression OR exposure OR slate OR past recommendation OR previous recommendation) Manuscript submitted to ACM Overall, we collected 1351 unique papers from all search engines. After applying the selection criteria, we kept 352 papers. Lastly, after manually selecting relevant papers, we kept 43 papers. This work reviews and discusses those 43 papers. In Figure 2, we show the distribution of selected papers by their publication year and venue.", "2 Impression-Aware Recommender Systems": "This section presents impression-aware recommender systems (IARS), a novel learning paradigm for personalized recommendations. The first part of the section focuses on the definition and comparison of IARS to other paradigms. Particularly, we propose a theoretical framework to define IARS and unify the different interpretations existing in the literature. Later, we use the same framework to identify and describe the similarities and differences of this paradigm with others. Then, we present a unique and novel classification system for recommender systems using impressions. In such a classification system, we categorize papers describing IARS under three properties: the design of recommendation models, how they use impressions data, and their stance on impressions. We close the section by presenting the classification of reviewed papers according to our classification system.", "2.1 Theoretical Framework": "A recommender system is a collection of software tools providing personalized selections of items to users based on their past preferences [86], e.g., recommendations based on previously listened songs. In this work, we focus on the task of top-N recommendations : a scenario where the goal of the recommender system is to generate a selection of \ud835\udc41 relevant items to the user. Such selection of items is referred to as recommendation , and having as synonyms in the literature as impression [55, 89], exposure [60, 93], or slate [27, 28, 111]. The recommender system generates the impression, sends it to the user's device, and the device arranges the impression on its screen. This work assumes an impression is presented as a list: an ordered selection of items sorted by decreasing user relevance. However, we identify the existence of other arrangements for impressions, e.g., a single item or a grid. 2.1.1 Relevant Terms. An impression is a single selection of N items; hence, the term impressions refers to several selections of N items. The term impressed item refers to a single item inside an impression. The term interaction is any action users perform on impressed items, e.g., playing songs or purchasing products. As users may decide to interact with none, some, or all impressed items inside an impression, we use the terms interacted impression and non-interacted impression to denote whether the user has interacted with an item in the impression. 4 Due to different logging policies, recommender systems may record their impressions and user interactions using various granularity levels. We use the term impressions type to classify impressions into two groups: contextual and global impressions. Both groups contain impressions and interactions, where contextual impressions contain the connections between an impression and the interactions its item receives, and global impressions do not. We use the term impressions signals to categorize users' preferences on non-interacted impressions in two levels: negative , neutral , or positive . A negative signal indicates the user dislikes a non-interacted impression, A neutral signal indicates the user has no positive or negative preference for the impressed item. A positive signal indicates the user likes a non-interacted impression but does not interact with it. In the literature, interactions (hence, interacted impressions) are already considered positive signals. For instance, the most common assumption of missing as negatives in the literature deems interactions as positive and non-interacted items as negative signals. The literature does not agree on 4 The term interacted impression refers to the same concept as the term interaction traditionally used in the literature. Manuscript submitted to ACM the signal of non-interacted impressions. In this work, we do not assume a particular signal for them; instead, we study how reviewed papers deem them. We use the term recommender type to classify recommenders into three groups based on how they generate an impression: end-to-end , plug-in , and re-ranking . End-to-end recommenders generate an impression themselves. Plug-in recommenders generate an impression by transforming the relevance of items created by another recommender (or a search engine or an editor). 5 Re-ranking recommenders generate a permutation of an impression generated by another recommender (or entity). The difference between the plug-in and re-ranking recommenders is the content and order of items in the impression they generate. 2.1.2 Mathematical Notation. Throughout this work, we use several mathematical variables. We define \ud835\udc5b\ud835\udc52 and \ud835\udc5b\ud835\udc5d as the total number of impressed items and the total number of interacted items in a system, respectively. We use subscripts to refine sets, functions, and variables according to a specific user or item. When referring to a given user, we use the subscript \ud835\udc62 , e.g., \ud835\udc5b\ud835\udc52 \ud835\udc62 is the number of impressed items for the user \ud835\udc62 . Similarly, the subscript \ud835\udc56 refers to a given item. Lastly, the subscript \ud835\udc62, \ud835\udc56 refers to a given user and item, e.g., \ud835\udc5b\ud835\udc52 \ud835\udc62,\ud835\udc56 is the number of times \ud835\udc62 has been impressed with \ud835\udc56 . 2.1.3 Formal Definition. Recommender systems define one set containing all users of the system termed the users' set and denoted as U , another set containing all items in the catalog termed the items' set and denoted as I , and another set containing users' past preferences called users' profiles and denoted as H . The set of users' profiles contains events , denoted as fi \ud835\udc5d , i.e., mathematical structures representing behaviors of users with the system, e.g., interactions or impressions. The module of a recommender system generating an impression is called the recommendation model; this module is also known in the literature as the recommendation algorithm, technique, or method. Each recommendation model defines a function, termed prediction function and denoted as \ud835\udc53 : U\u00d7I\u00d7H \u2192 R , mapping users, items, and users' profiles into real values. For a given user \ud835\udc62 and item \ud835\udc56 , such real values are called the predicted relevance , denoted as \u02dc \ud835\udc5f \ud835\udc62,\ud835\udc56 , and represent the expected preference of \ud835\udc62 over \ud835\udc56 . To generate an impression to a given user, the recommendation model computes the predicted relevance of the user to all items in the catalog and selects those with the highest score. IARS are a recommendation paradigm leveraging impressions to learn users' preferences on items. In other words, and different from traditional recommender systems, IARS use impressions and collaborative data as their primary data sources (input) rather than the exclusive use of collaborative data or other data sources. Still, the product (output) of IARS, similar to most recommender systems, are impressions. In IARS, the definitions and notations of the set of users, set of items, set of users' profiles, and prediction function are the same as above (denoted as U , I , H , and \ud835\udc53 , respectively). IARS define events, denoted as fi \ud835\udc5d = GLYPH<0> \ud835\udc62, \ud835\udc56, \u02dc \ud835\udc5f \ud835\udc62,\ud835\udc56 , fi \ud835\udc52 \ud835\udc62,\ud835\udc56 GLYPH<1> , as a quadruplet composed of the identifier of a user, the identifier of an item, the user-item predicted relevance and a vector of item identifiers. The item's identifier represents the interacted item, while the vector of item identifiers represents the impression. Several constraints exist when defining events depending on the impression type and user feedback. For a contextual impression, the item must be in the impression; for a global impression, either the item or the impression must be empty. For an interacted impression, the item and the relevance scores are not empty; for a non-interacted impression, the item and the relevance score are empty. The definition of events allows for multiple interactions between users and items, e.g., with different predicted relevance or impressions. When duplicated interactions are not allowed or needed, then the definition of an event is a 5 Plug-in recommenders are not exclusive of IARS. They are commonly used in context-aware recommenders and are called contextual post-filtering [3]. Manuscript submitted to ACM Fig. 3. The three phases of any given IARS for generating recommendations to a given user. (a) illustrates the first phase ( learning ), where the IARS creates a prediction function ( \ud835\udc53 ) using the set of users profiles ( H ). (b) illustrates the second phase ( prediction ), where the IARS uses \ud835\udc53 to predict the relevance score ( \u02dc \ud835\udc5f \ud835\udc62,\ud835\udc56 ) of any given user-item-profile triplet. (c) illustrates the third phase ( recommendation ), where the IARS generates an impression (recommendation list) to a given user ( \ud835\udc62 ) by selecting their N-most relevant items based on their predicted relevance scores. (a) Learning phase Users profiles ( H) Impression-aware recommender system Prediction function ( \ud835\udc53 ) (b) Prediction phase User-item-profiles triplet ( \ud835\udc62,\ud835\udc56, H) Prediction function ( \ud835\udc53 ) User-item predicted relevance GLYPH<0> \u02dc \ud835\udc5f \ud835\udc62,\ud835\udc56 GLYPH<1> (c) Recommendation phase User-specific predicted relevances (fi \ud835\udc5f \ud835\udc62 ) Top-N ranking relevance (highest to lowest) Impression for user ( fi \ud835\udc52 \ud835\udc62 ) tuple of a predicted relevance and a vector of item identifiers, denoted as fi \ud835\udc5d \ud835\udc62,\ud835\udc56 = GLYPH<0> \u02dc \ud835\udc5f \ud835\udc62,\ud835\udc56 , fi \ud835\udc52 \ud835\udc62,\ud835\udc56 GLYPH<1> . The same constraints apply to this definition of events.", "2.2 Recommendation Phases": "As Ricci et al. [86] states, any kind of recommender system must perform different computations in phases to be able to generate relevant personalized recommendations to a given user. In particular, Ricci et al. [86] identify two stages: prediction and recommendation . In the prediction stage, the recommender selects all items of the catalog (or a subset of them) and predicts their relevance to any given user \ud835\udc62 . Formally, as indicated in Section 2.1, for any given user \ud835\udc62 and item \ud835\udc56 , the recommender predicts \u02dc \ud835\udc5f \ud835\udc62,\ud835\udc56 . In the second stage, instead, the recommender takes the computed relevances and selects the top-N items with the highest relevance for any given user. As mentioned in Section 2.1, this vector of N-most relevant items is called an impression . Based on the theoretical framework described in Section 2.1, recommenders have to go through a further phase prior to the ones identified by Ricci et al. [86]. We call such a stage training where the recommender takes the set of user profiles ( H ) and creates the prediction function used in the prediction phase. In other words, this is the stage where the recommender learns users' preferences according to the data contained in the users' profiles. We illustrate the specifics of these three phases for IARS in Figure 3. As seen in the figure, any IARS shares the same three phases, differing only in the data sources used in each of them. As the figure shows, IARS leverage past impressions inside the set of users' profiles, i.e., H , both in the learning and prediction phases. However, the figure also shows that IARS only use past impressions in all of the three phases. It is important to stress that impressions are generated as the result of the recommendation phase, which means that those new impressions cannot be available either at learning or prediction. Hence IARS can exclusively leverage previously-generated impressions to learn and predict users' preferences. In other words, using an impression outside the set of users' profiles is not possible because the recommender has not generated any new impression and shown it to the user prior to the end of the third phase.", "2.3 Related Recommendation Paradigms": "Collaborative filtering (CF) is the paradigm where recommender systems generate recommendations using interactions. Collaborative filtering with side information (CF-SI) is an extension of CF that uses interactions and additional data Manuscript submitted to ACM Fig. 4. Hierarchy of four learning paradigms, from top to bottom and left to right: collaborative filtering with side information (CF-SI), impression-aware recommender systems (IARS), context-aware recommender systems, and hybrid content-based collaborative filtering. As illustrated, the last three belong to CF-SI. IARS is not equivalent to its sibling paradigms due to the theoretical and practical differences between them, differences that we analyze in Section 2.3. Additionally, the diagram places our proposed taxonomies for IARS, namely model-centric, data-centric, and signal-centric taxonomies; also presented and discussed in Section 2.4. Collaborative filtering with side information Impression-aware recommender systems Model-centric taxonomy Data-centric taxonomy Signal-centric taxonomy Context-aware recommender systems Hybrid content-based collaborative filtering sources to generate personalized recommendations [74, 122]. Several paradigms exist within CF-SI, e.g., contextaware [3, 97] or hybrid content-based collaborative filtering [45], as illustrated in Figure 4. IARS is considered a learning paradigm within CF-SI. In this section, we analyze why IARS is a unique paradigm. While, at the same time, how it is compatible with other paradigms. 2.3.1 Comparison With Similar Paradigms. For a learning paradigm to be equivalent to IARS, it is required that such a paradigm share characteristics that can be bijectively projected between IARS and such a learning paradigm. Under our theoretical formulation, this requires that a given learning paradigm shares an equivalent definition of events, the set of user profiles, and the prediction function. In addition to those, it is also required that the learning paradigm performs equivalent phases when generating recommendations to those performed by IARS, as seen in Section 2.2. After inspecting existing learning paradigms in the recommender systems field, especially those listed by Burke [14] and Ricci et al. [86], we identify one learning paradigm that is similar but not equivalent to IARS, namely: Context-aware recommender systems (CARS). In particular, CARS [3, 97] are those recommender systems learning from interactions and contextual attributes. Examples of contextual attributes are users' geographical locations or the day and time users access the recommender system [3]. At a first glance, IARS may seem equivalent to CARS where the impressions are the context of the interactions, but this is not the case. Despite their similarities, both paradigms have theoretical and foundational differences that break a possible equivalence between them, causing IARS to be a novel and unique learning paradigm. In Table 1, we list the definitions of events, the set of user profiles, and the prediction function of different recommendation paradigms, including IARS and CARS. From the Table, we can observe the similarities and differences between both recommendation paradigms. In particular, in terms of their definitions of events, both paradigms share similar but not equivalent definitions, both being quadruplets holding the users and items identifiers, the predicted user-item relevance score, and a vector. They differ in the contents of the vector, where IARS hold an impression, while CARS hold contextual attributes. An impression contains a fixed number of item identifiers, while contextual attributes may contain a varying number of features and data types. In terms of their definitions of prediction function, the differences between their definitions are crucial to establishing the non-equivalence between both paradigms. As seen in the table, the prediction function of IARS predicts the relevance score of any user-item pair by taking a user identifier, an item identifier, and the set of user profiles as input. Instead, Manuscript submitted to ACM Table 1. Comparison of the definitions of an event, the users' profile, and the prediction function between IARS and similar types of recommenders. \ud835\udc62 is a user, \ud835\udc56 is an item, \u02dc \ud835\udc5f \ud835\udc62,\ud835\udc56 is a real number, fi \ud835\udc60 \ud835\udc62,\ud835\udc56 is side information as a vector of features, fi \ud835\udc52 \ud835\udc62,\ud835\udc56 is an impression as a vector of item identifiers, and fi \ud835\udc50 \ud835\udc62,\ud835\udc56 and fi \ud835\udc50 \u2217 \ud835\udc62,\ud835\udc56 are two different vectors of contextual features. the prediction function of CARS takes an additional argument, a vector of contextual features computed on the user-item pair before predicting its relevance. In other words, this vector is outside the set of user profiles and is computed and used at the prediction phase of the recommender. In contrast, as seen in Figure 3, IARS compute a new impression after predicting the relevance scores of user-item pairs; thus, it is impossible to use such new impressions when predicting the relevance scores associated to them because they are not known yet. 6 2.3.2 Compatibility With Other Paradigms. Despite their uniqueness, IARS are compatible with other paradigms, e.g., sequence-aware or session-based recommenders. In this context, compatibility indicates that a recommender system may be from any given paradigm and include impressions in any of their phases to produce relevant recommendations. Essentially, such a recommender system would retain its learning paradigm and become impression-aware as well. The compatibility of impressions as a data source with other learning paradigms is possible due to the broad definitions of events in IARS: they require impressions, regardless of their representation, e.g., whether the recommender uses contextual or global impressions. 7 In fact, recommenders incorporating impressions may benefit from this additional data source without deviating from their original goal. An example of these recommenders using impressions while being designed from another paradigm exists in the reviewed literature. For instance, Gong and Zhu [35] describe a session-based recommender using impressions.", "2.4 Classification of Impression-Aware Recommender Systems": "In this section, we present and describe our novel classification system for IARS. This classification system is composed of three taxonomies, each analyzing recommendation models in different dimensions. We use these three taxonomies of the classification system to analyze recommendation models in the literature, complementing our analyses by also inspecting the previously defined properties of impression-aware recommendation models, i.e., the impression's type, impression's signal, and recommender's type. 8 In our analyses, we are able to capture finer nuances in proposed recommendation models when using these properties and taxonomies in conjunction. Consequently, we assemble a comprehensive picture of the recommendation models in the literature in terms of their design and functioning. 2.4.1 Model-centric Taxonomy. The model-centric taxonomy classifies papers based on the design of their proposed recommendation model, i.e., the module of the recommender system in charge of generating impressions. In particular, the taxonomy inspects the model's learning technique. We identify five categories of recommenders from the reviewed papers in the literature. The definition of each category is: 6 See Section 2.2 for a description of recommender's phases and Figure 3 for an illustration of all phases. 7 We define contextual and global impressions in Section 2.1. 8 See Section 2.1 for the definition of these properties. Manuscript submitted to ACM Fig. 5. Types of inputs received by recommendation models from the reviewed literature according to the three categories within the data-centric taxonomy. (a) illustrates the first category ( features ), where recommendation models receive statistical features computed from impressions as part of their input. (b) illustrates the second category ( learn ), where recommendation models receive an impression; partially or fully, as part of their input. (c) illustrates the third category ( sample ), where recommendation models receive a vector containing sampled items from the catalog; each item from a possibly different part of the catalog, i.e., interacted, solely impressed, or non-impressed. The data-centric taxonomy allows for a recommendation model to belong to one or more categories within it. (a) Category: Features Statistical features Recommendation model (b) Category: Learn Impression Recommendation model (c) Category: Sample Sampled items Recommendation model \u00b7 Heuristics recommenders using ad-hoc rules and techniques. \u00b7 Statistical: recommenders using probabilistic distributions or statistical properties of users' behavior. \u00b7 Machine learning: recommenders using machine learning techniques. \u00b7 Deep learning: recommenders using deep neural networks. \u00b7 Reinforcement learning: recommenders using a Markov decision process to model users' preferences. 2.4.2 Data-centric Taxonomy. The data-centric taxonomy classifies papers based on how they process and provide impressions as input for the recommendation model. One of the main characteristics of the taxonomy, as opposed to the others, is that its categories are non-mutually exclusive, meaning papers may belong to one or more categories. For instance, six papers are classified into two categories ( features and learn ) as seen on Table 2. From the reviewed papers, we identify three categories of papers, which we illustrate in Figure 5. The definition of each category and the number of papers included in the category are: \u00b7 Features: papers computing features from impressions and receiving such features as input. In this context, a feature is a quantitative property of impressions, e.g., the number of times an item has been impressed to a specific user. \u00b7 Learn: papers handing impressions as input to their recommendation model. This category covers those papers using any impression type and the user feedback on impressed items. \u00b7 Sample: papers sampling items from the catalog, where at least one sampled item is an impression. 2.4.3 Signal-centric Taxonomy. The signal-centric taxonomy classifies papers based on how they process users' preferences for non-interacted impressions. This taxonomy focuses explicitly on non-interacted impressions because the recommender systems literature already assumes the preference of users toward interacted impressions (i.e., interactions) as positives; such an assumption is called missing as negatives . From the reviewed papers, we identify two categories of papers. The definition of each category and the number of papers included in the category are: \u00b7 Assume: papers assuming users' preference to non-interacted impressions. \u00b7 Learn: papers learning users' preference to non-interacted impressions. Manuscript submitted to ACM Table 2. Classification of reviewed papers according to the taxonomies and properties defined in this work. Count tells the number of papers belonging to a given taxonomy or property. Percentage tells the percentage of papers belonging to the classification inside a taxonomy or property. 2.4.4 Distribution of Papers. The three taxonomies included in our classification system let us inspect and analyze recommendation models from the literature in a comprehensive manner. As a reference, in Table 2, we show the distribution of papers when grouped according to each of our proposed taxonomies and properties of recommendation models. The distribution of papers shows both the number and percentage of papers that belong to each group. From the table, we observe that in most taxonomies and properties, the distribution of papers falls into one or two categories over the others within the same group. This behavior is mostly observed in the signal-centric taxonomy and the three properties we analyze, i.e., impression's type , impressions signals , and recommender's type . These skewed distributions of papers show that the literature leans its efforts toward specific approaches or topics while others remain less explored. For instance, in the former, most papers (close to 64 %) simply assume a signal to items impressions based on their received (or lack of) user feedback. Similarly, in the other groups, around 66 % of papers use global impressions, give negative signals to non-interacted but impressed items, and use end-to-end recommenders, respectively. Manuscript submitted to ACM The remaining taxonomies, i.e., the model-centric and data-centric taxonomies, show a less skewed distribution of papers. In particular, according to the model-centric taxonomy, papers mostly describe recommendation models using deep learning or reinforcement learning; a considerable number of papers use other techniques as well. According to the data-centric taxonomy, papers extract features from impressions, pass an impression as input to the recommender, or combine both approaches. In contrast to the previous taxonomy, according to the data-centric taxonomy, a limited number of papers sample items from the catalog or do not describe how they process impressions in recommendation models.", "3 Reviewed Papers": "This section presents the selected IARS papers alongside the recommendation models they describe; for a total of 43 papers. 9 Whendescribing papers, we present their recommendation models and other aspects, e.g., their recommendation domain, complexity, how they use impressions, among others. We organize this section using the categories of the model-centric taxonomy. This means that we present papers in the same order as we present the categories inside that taxonomy, i.e., heuristics, statistical, machine learning, deep learning, and reinforcement learning. Due to the varying levels of detail provided by reviewed papers, their different evaluation strategies, and the complexity in fairly evaluating recommendation models, it is beyond the scope of this work to compare the recommendation quality of the recommendation models presented in this section.", "3.1 Heuristics": "In this section, we present five papers describing recommenders using ad-hoc techniques to learn users' preferences. Four in this category apply frequency capping , a technique designed to limit or discourage the selection of an item in a future impression after its number of impressions exceeds a threshold. Those papers employ two types of frequency capping approaches, namely: hard and soft frequency capping. Two papers [13, 123] employ the hard version, meaning their recommenders encode such threshold. Two papers [6, 55] employ the soft version, meaning their recommenders apply data mining techniques to learn the threshold from user feedback. The remaining paper [63] does not apply frequency capping. Instead, it focuses on recommending items with the highest click-through rate (CTR), i.e., the ratio between the number of interactions and the number of impressions. 3.1.1 Hard Frequency Capping. Two papers [13, 123] use hard frequency capping. Buchbinder et al. [13] describe two recommenders in the domain of online advertisements termed \ud835\udc3a\ud835\udc45\ud835\udc38\ud835\udc38\ud835\udc37\ud835\udc4c \ud835\udc37 and \ud835\udc3a\ud835\udc45\ud835\udc38\ud835\udc38\ud835\udc37\ud835\udc4c \ud835\udc49 . In the paper, items are advertisements published in an online advertisement system and served by the systems' recommender. Each item is associated with a payoff (the amount of money the advertiser pays for each user-item impression) and two constraints (a maximum number of global impressions and a maximum number of user-item impressions). Both recommenders aim to obtain the highest payoff while respecting the items' constraints. For a given user, \ud835\udc3a\ud835\udc45\ud835\udc38\ud835\udc38\ud835\udc37\ud835\udc4c \ud835\udc49 recommends items with the highest payoffs. Instead, \ud835\udc3a\ud835\udc45\ud835\udc38\ud835\udc38\ud835\udc37\ud835\udc4c \ud835\udc37 recommends those items with the highest number of global impressions and the highest number of user-item impressions. Zhao et al. [123] describe a session-based re-ranking recommender termed cycling in the media domain. The goal of the recommender is to re-arrange an impression to favor less impressed items over highly impressed items. The paper defines the relevance score of the cycling recommender as a tuple containing a 9 We describe the selection criteria of IARS papers in Section 1.3. Manuscript submitted to ACM presentation score (denoted as \u02dc \ud835\udc5d \ud835\udc62,\ud835\udc56 ) and the relevance score of another recommender (denoted as \u02c6 \ud835\udc5f \ud835\udc62,\ud835\udc56 ):  where \ud835\udc5b\ud835\udc52 \ud835\udc62,\ud835\udc56 is the number of impressions of a given item \ud835\udc56 on user \ud835\udc62 , and \u230a \ud835\udc65 \u230b rounds \ud835\udc65 to the lowest integer. The paper states the recommender re-ranks an impression by selecting the items with the lowest presentation score and solving ties by selecting the items with the highest recommender's score. 3.1.2 Soft Frequency Capping. Two papers [6, 55] use soft frequency capping. Lee et al. [55] describe a plug-in recommender termed impressions discounting framework (IDF) in the job and online advertisement domains. The goal of the recommender is to adjust the relevance of items based on their historical user-item interactions and impressions. For a given-user item pair, the paper defines the relevance score of its recommender as the product between a discounting factor (denoted as \ud835\udc51 \ud835\udc62,\ud835\udc56 ) and the relevance score of another recommender (denoted as \u02c6 \ud835\udc5f \ud835\udc62,\ud835\udc56 ):  where \ud835\udc51 \ud835\udc62,\ud835\udc56 is a normalized linear aggregation of several features computed on impressions: the number of days elapsed since the same user-item impression, the number of user-item impressions, and the position on-screen of the last impression. Agarwal et al. [6] use the IDF in an industrial recommender in the jobs domain; however, the paper does not provide details of the recommender's implementation, deployment, or other properties. For instance, the paper does not state which features from impressions the recommender computes. 3.1.3 CTR Prediction. Liu et al. [63] does not describe a recommender employing a frequency capping technique. Instead, the paper describes a non-personalized recommender to predict the ratio between interactions and impressions for a given query and item. The recommender is deployed in an image-sharing service in the social media domain, where items are images, and users search for images by providing a 'search query' (denoted as \ud835\udc5e ). The recommender memorizes the best images given a search query based on the number of interactions and impressions each image received. For a given query-item pair, the recommender's relevance score (denoted as \u02dc \ud835\udc5f \ud835\udc5e,\ud835\udc56 ) is:  where \ud835\udc5b\ud835\udc5d \ud835\udc5e,\ud835\udc56 and \ud835\udc5b\ud835\udc52 \ud835\udc5e,\ud835\udc56 are the number of interactions and impressions of query \ud835\udc5e on item \ud835\udc56 , respectively. \ud835\udc36\ud835\udc47\ud835\udc45 is the ratio between the number of interactions and impressions across all queries and items. \ud835\udefc is a hyper-parameter.", "3.2 Statistical": "In this section, we present five papers describing recommenders using probabilistic distributions or statistical properties to model users' preferences. Two papers model user preferences by accounting for user fatigue, i.e., modeling the user dissatisfaction with the recommender system upon repeated items in impressions. Specifically, those papers define user fatigue as a function of the number of impressions. One paper learns user preferences using logistic regression, while two papers model features from impressions, e.g., the future number of interactions and impressions. 3.2.1 User Fatigue. Two papers [5, 106] model user fatigue. Agarwal et al. [5] describe a recommender in the news domain. The goal of the recommender is to predict the ratio between the number of interactions and the number of impressions (CTR) by incorporating a factor to account for user fatigue. The recommender uses impressions, the Manuscript submitted to ACM current time, and the position of items on-screen to build the model of users' preferences. A simplified version of the recommender's relevance score function is:  where \ud835\udf03 \ud835\udc56 is the CTR in its first global impression. \ud835\udc5b\ud835\udc5d \ud835\udc56 and \ud835\udc5b\ud835\udc52 \ud835\udc56 are the numbers of interactions and impressions of a given item, respectively. Lastly, \ud835\udefc and \ud835\udefe are hyper-parameters. Wu et al. [106] describe a recommender in the media domain. The goal of the recommender is to provide personalized recommendations on a two-dimensional layout - a similar scenario to the one described by Ferrari Dacrema et al. [30]. The paper defines user fatigue as a piece-wise linear function dependent on the number of user-item impressions:  \uf8f3 where \ud835\udc5b\ud835\udc52 \ud835\udc62,\ud835\udc56 is the number of impressions of a given user with a given item; \ud835\udc4e 1 , \ud835\udc4e 2 , \ud835\udc4e 3 \u2208 R are the control slope, offset, and secondary slope of the users' fatigue function, respectively; and \ud835\udc58 \u2208 Z + is a threshold parameter. The paper states the function benefits less-popular items since they are associated, on average, with lower fatigue, while it penalizes popular items as they tend to be recommended often and to cause higher fatigue. The paper trains the recommender using the expectation-maximization algorithm [26]. 3.2.2 Logistic Regression. Zhang et al. [120] learn user preferences using logistic regression. The paper describes a recommender in the jobs domain, termed GLMix . The goal of the recommender is to classify impressions as interacted or non-interacted impressions using contextual features, e.g., time of the day and geographical position of items. For any user-item pair, the recommender learns the user feedback such pair will receive using logistic regression. The recommender selects those items with the highest likelihood of becoming interacted impressions. Consequently, the paper considers interacted impressions as positive signals while non-interacted impressions as negative ones. 3.2.3 Prediction of Features from Impressions. Borisyuk et al. [12] model the future number of interactions and impressions any item will receive during a given period. The paper describes a non-personalized plug-in recommender in the jobs domain. In the paper, items are job postings associated with a 'recommendation window' (a period where they can be recommended) and two constraints (a minimum and a maximum number of interactions they can receive during the recommendation window). The goal of the recommender is to maximize the number of interactions within each item's recommendation window while respecting the item's constraints. For a given item, the recommender builds three statistical models: \u00b7 A confidence interval for the item's number of future interactions. \u00b7 The item's expected number of impressions. \u00b7 The item's expected number of interactions. The paper states the expected number of impressions follows a negative binomial distribution. In contrast, the expected number of interactions is conditioned on the previous but has no closed form. Lin et al. [61] predict the watch time of items in the media domain, where the watch time is the period users spend actively watching videos. The paper describes a tree-based approach, termed 'tree-based progressive regression,' to predict a specific range in which the watch time falls. Then, the paper partitions the watch time into \ud835\udc5b ranges and assigns each range to a leaf node. Then, it Manuscript submitted to ACM creates a parent node for every two leaf nodes with consecutive ranges. Every parent node holds a classifier predicting whether the watch time falls in any of the ranges held by its children. With the paper's approach, the watch time follows a multinomial distribution dependent on the depth of the tree and the path from the root to any leaf node.", "3.3 Machine Learning": "In this section, we present four papers describing recommenders using shallow machine learning techniques to model users' preferences. Two papers describe recommenders using Gradient Boosting Decision Trees (GBDT) [47]: an ensemble of decision trees. Two papers describe modified versions of the traditional matrix factorization technique [52]. 3.3.1 Gradient Boosting Decision Trees. Two papers [63, 66] use GBDT in their recommenders. Liu et al. [63] describe a GBDT recommender in the media domain. The recommender aims to classify user-item pairs as future interacted or non-interacted impressions. For a given user, the recommender generates an impression by selecting those items it classifies as interacted impressions with higher confidence. Consequently, the recommender considers non-interacted impressions negative signals while interacted impressions positive ones. The paper does not provide further details of the recommender. Ma et al. [66] describe a LambdaMART recommender in the news domain. The goal of the recommender is to predict the ratio between the number of interactions and impressions while considering user fatigue (see Section 3.2) on repeated impressions. The paper models user fatigue by computing four features from impressions and interactions related to user feedback. Apart from those features, the paper computes eleven more features from impressions. All the seventeen features computed from impressions by the paper are: \u00b7 CTR : the ratio between the number of interactions and the number of impressions of a user (one feature). \u00b7 Same item fatigue : the number of interactions and impressions of a user with the same item (two features). \u00b7 Same category fatigue : the number of interactions and impressions of a user with a category of item (two features). \u00b7 Positional : first, average, and last position of an item in impressions for a user (three features). \u00b7 Temporal : number of user-item impressions in the past 3, 10, 30, 120, and 1440 minutes. Also, the elapsed time since the first and last user-item impression. Lastly, the elapsed time since the first and last pair of user and category of item impression (nine features). The paper's results show the recommendation quality increases when including all those features and when compared to the same recommender without such features. Moreover, the same item fatigue and the temporal features provide the greatest relative improvement. 3.3.2 Matrix Factorization. Two papers [8, 80] use matrix factorization. Aharon et al. [8] describe a recommender in the online advertisements domain. The goal of the recommender is to predict the ratio between the number of interactions and the number of impressions. The recommender is a matrix factorization model incorporating a learned bias as a soft frequency capping term (see Section 3) on the number of repeated user-item impressions. A simplified version of the relevance score of the recommender is:  where \ud835\udc5d \ud835\udc47 \ud835\udc62 , \ud835\udc5e \ud835\udc56 , and \ud835\udc4f are the traditional user latent factors, item latent factors, and bias terms present in traditional matrix factorization recommenders, respectively. w is the impressions frequency bias, the learned personalized bias on the user fatigue. The recommender learns those factors and biases using SGD, where the expected score of a non-interacted impression is 0, while the expected score of an interacted impression is 1. Hence, the paper considers non-interacted Manuscript submitted to ACM impressions as negative signals, while interacted impressions are positive ones. P\u00e9rez Maurera et al. [80] describe two recommenders using global impressions in the media domain. Both recommenders are the traditional matrix factorization model optimized using the BPR criterion [85]. As such, the recommender samples a user, a positive item, and a negative item. The paper samples positive items from interacted impressions, while negative items are non-interacted impressions or non-impressed items. Consequently, the paper deems interacted impressions as positive signals, while non-interacted impressions and non-impressed items are considered negative signals.", "3.4 Deep Learning": "In this section, we present seventeen papers describing recommenders using deep neural networks to model users' preferences. Five papers use the multilayer perceptrons (MLP) architecture: a feed-forward neural network with activation functions in its layers. Two papers use the encoder-decoder [82] architecture: a composition of two neural networks called encoder and decoder, where the encoder transforms its input into a latent representation, and the decoder recomposes the input from the latent representation. Three papers use the two-tower framework [113]: an architecture consisting of two neural networks, where one tower generates user embeddings and the other generates item embeddings. Five papers use a multi-gate mixture-of-experts (MMoE): a gated ensemble of neural networks for multi-task recommendation. One paper uses knowledge distillation (KD) [41]: transferring the knowledge of a large recommendation model into a smaller deep learning recommendation model. Lastly, one paper uses a pre-trained language model (PLM) [70, 101]: a deep neural network that may be fine-tuned to a specific task. 10 3.4.1 Multilayer Perceptron Architecture. Five papers [11, 24, 116, 121, 127] use MLP. Covington et al. [24] describe a recommender in the media domain. The recommender is a composition of several dense feed-forward layers with ReLU activations. The goal of the recommender is to estimate the 'expected watch time per impression', i.e., the time users spend watching an item. The recommender is a re-ranking one: it receives as input an impression (generated by another recommender) and features of items inside the impressions, while its output is a permutation of the impression. As per the features from impressions, the recommender computes the number of user-item impressions. The recommender considers interacted impressions as positive signals, while non-interacted impressions as negative signals. Zhan et al. [116] describe a recommender with residual layers in the media domain. The paper introduces the term 'watch time' to measure the time users spend watching videos. The goal of the recommender is to learn user preferences for videos using their watch time. Unlike other papers, the paper does not distinguish positive or negative signals using user feedback; instead, it uses the watch time. Hence, the paper introduces a threshold value to classify user-item pairs as positive or negative signals. Negative signals are user-item pairs with a watch time lower than the threshold, while positive signals are user-item pairs on the opposite side. For a given item, the recommender computes two features: its number of impressions and its average watch time. For a given user and item, the recommender encodes both features alongside the identifiers of the user and the item into a ResNet predicting the watch time the user will have on the item. The recommender generates an impression containing those items with the highest predicted watch time. Zhu et al. [127] describe a recommender with attention layers in the fashion domain. In the paper, an item combines two fashion garments: top and bottom. The goal of the recommender is to predict user preferences while accounting for which items receive more interactions than others. In particular, the paper uses impressions to compute the ratio between the number of interactions and impressions (CTR). For a given user, the paper creates two sets (termed positive 10 MMoE and KD are architectures that allow the use of various kinds of recommendation models, not only deep learning ones. When a paper uses at least one deep neural network inside MMoE or KD, we classify the paper as belonging to the deep learning category. Manuscript submitted to ACM and negative combinations) containing those items with the highest and lowest CTR, respectively. The input of the recommender is a sextuplet composed of a user, an item, a label, the user's set of positive combinations, the user's set of negative combinations, and a vector of contextual features. The label indicates whether the user-item pair is an interacted or non-interacted impression. The paper does not detail which contextual features they compute. Zhang et al. [121] describe a recommender in the e-commerce domain. For a given user-item pair, the recommender has three goals: predicting user-item interactions, purchases, and 'add-to-cart'; the latter meaning the user performed a specific type of interaction in the system. The paper focuses on cross-domain recommendation, i.e., the recommender is trained on e-commerce data. Then, the learned preferences are used by another recommender deployed in the online advertisement domain. The paper only uses impressions in the former recommender. Furthermore, the paper only uses global impressions to train the recommender in the first task, i.e., predicting a user-item pair as an interacted or non-interacted impression. Hence, the paper deems non-interacted impressions as negative user feedback. For the remaining tasks, the paper trains the recommender using interactions. Bied et al. [11] describe a recommender in the jobs domain. In the paper, a user is a person registered in an online job-seeking platform, while items are job advertisements. The paper proposes a MLP, called MUSE, consisting of three modules and designed to predict two tasks: hiring and applications. The first module, called MUSE.0, provides a score for a given user-item pair based on contextual and content features. The second module, called MUSE.1, uses such a score alongside additional features to predict whether a user-item pair will result in the user being hired. The third module, called MUSE.2, instead, uses the previous features and predicts whether a user-item pair will result in the user applying for a job. To train the recommender, the paper uses non-impressed items as negative signals; while it uses impressions as positive signals. 3.4.2 Encoder-Decoder Architecture. Two papers [83, 111] describe recommenders using the encoder-decoder architecture. Ren et al. [83] describe a recommender in the media and news domains. When training the recommender, for every user-item pair, it receives as inputs a triplet composed of a vector of features of the item, features of the user, and an impression as a vector of impressed items. The paper describes the recommender as capable of multi-objective learning. In the paper's experiments, for a given user-item pair, the recommender is tasked to classify the pair as an interacted or non-interacted impression and to predict the users' watch time. Hence, the paper considers non-interacted impressions as negative signals. Xin et al. [111] describe a technique using the encoder-decoder architecture. The paper does not describe a recommender using impressions but a technique learning from impressions generated by a recommender to derive user feedback. The paper terms such a model as attack model , where the goal of the model is predicting, for a given impression, which items are interacted or non-interacted impressions. The encoder and decoder networks use a MLP architecture with several layers, such as attention or GRU layers. The paper's results suggest predicting which items in an impression the user will interact with is possible. 3.4.3 Two-Tower Framework. Three papers [20, 35, 100] use the two-tower framework. Chen et al. [20] describe a recommender in the media and e-commerce domains. The goal of the recommender is to learn users' preferences while accounting for the popularity of items. The paper computes the number of impressions of any item. However, the paper does not specify whether the feature is computed globally, user-wise, item-wise, or pair-wise. Moreover, the paper only uses the number of impressions in the loss function of the recommender, i.e., the recommender does not receive as input a non-interacted impression. Wang et al. [100] describe a recommender in the e-commerce domain. The goal of the recommender is to estimate users' preferences toward items while accounting for popularity bias (overexposure of specific items). In the paper, an item is an article, and the user may perform two types of interactions: clicking or purchasing items. The paper defines three levels of user preferences, where the highest level of user preference is Manuscript submitted to ACM a purchased item, then a clicked item, and lastly, a non-interacted item. The recommender comprises three neural networks, where two networks are trained using all types of impressions. The input of both networks is a triplet containing the identifier of a user, an item, and a label, where the label indicates whether the user-item pair is a non-interacted or interacted impression. The other network is trained using only interacted impressions. Gong and Zhu [35] describe a session-based recommender in the news domain. The goal of the recommender is to recommend the next interacted item for a given sequence of impressions in a session. In the paper, items are news articles, and sessions are sequences of impressions within a period. Depending on the user's reading time of an article, the paper considers a user-item pair as an interacted or non-interacted impression. In particular, interacted impressions are user-item pairs exceeding a certain reading time threshold; analogously, non-interacted impressions are pairs with lower reading time than the threshold. For a given session-item pair, the recommender is t<rained to distinguish an interacted impression from a non-interacted one; it considers non-interacted impressions as negative signals while interacted ones as positives. The paper samples items (interacted or non-interacted impressions) from contextual impressions shown in a session. 3.4.4 Multi-Gate Mixture of Experts. Five papers [36, 42, 67, 108, 125] use MMoE. Zhao et al. [125] describe a re-ranker recommender in the media domain. The paper tasks the recommender to predict different types of user-item feedback, e.g., clicks, watch time, likes, and ratings. For each type of user-item feedback, the recommender outputs a score. Then, the recommender produces an aggregated score as a weighted linear combination of each feedback score. To re-rank an impression, the recommender computes the aggregated score of each item in the impression; then, it re-orders the impression by the aggregated score in descending order. The signals of non-interacted impressions depend on the type of user-item feedback (e.g., watching an item or clicking on a dislike button) and the weight associated with such feedback. As the paper does not disclose the weights, it is not possible to assess how the paper deems non-interacted impressions. Ma et al. [67] describe a recommender in the online advertisements domain. In the paper, an item is an advertisement, and the user may perform two types of interactions: clicking or dismissing items. The paper considers clicking as positive user-item feedback while dismissing it as negative. The goal of the recommender is to model user preferences to advertisements using those two types of interactions. The recommender is composed of three networks where only two use impressions. The first network predicts user preferences by predicting the ratio between the number of interactions and impressions for a given user-item pair. The second network predicts user preferences by predicting the probability of a user 'dismissing' an item. The input of both networks is a triplet containing the identifier of a user, an item, and a label, where the label indicates whether the user-item pair is a non-interacted or interacted impression. The first network learns from non-interacted and interacted (clicked items) impressions and considers them negative and positive signals, respectively. Instead, the second network learns from non-interacted and interacted (dismissed items) impressions and considers them positive and negative signals, respectively. Gong et al. [36] describe a re-ranker recommender in the media domain; more specifically, short-videos recommendations. The paper shows users one video at a time; however, the recommender generates an impression of \ud835\udc41 items. The recommender is tasked to re-rank the remaining \ud835\udc41 -\ud835\udc5a items, where \ud835\udc5a is the number of items in the impression the user has already consumed. The recommender receives as input the impression, the sequence of watched items in the impression, a target video, features computed from the impression, and user feedback on the video (e.g., watch time of videos and types of interactions). For a given item in an impression, the recommender is trained with a MMoE to output three probabilities: the user watching another item, watching a certain percentage of the item, and interacting with the item. Xi et al. [108] describe a re-ranking recommender in the mobile applications domain. The goal of the recommender is to re-rank the impressions on a page, where a page is a two-dimensional arrangement of several impressions, and each impression is a list. In the Manuscript submitted to ACM paper, the recommender solely re-ranks the items in the impressions, i.e., it generates a permutation of the contents of the impressions and does not change their arrangement on-screen. The recommender encodes a page as a matrix, where the rows are impressions, and the columns are the items in the impressions. For a given page, the recommender receives the sequence of user-item interactions and the matrix of impressions as input. Then, the recommender is trained to predict whether a user-item pair in the matrix is an interaction; hence, non-interacted impressions are deemed negative feedback. Hu et al. [42] describe a recommender in the jobs domain. The paper proposes a MMoE recommender to predict whether a user seeking a job will perform four actions: click, apply, review, and accept. Thus, the recommender is composed of four experts, one for each user action, designed to correctly predict its corresponding users' actions. The paper uses impressions to train the recommender. In particular, on the one hand, non-interacted impressions, i.e., those that did not receive any kind of user action, are treated as negative signals across the four experts. Positive signals, on the other hand, are only those user-item pairs that match a specific user action with the corresponding expert. Part of the input of the recommender is also the time of impression; however, the paper does not detail such a feature. 3.4.5 Knowledge Distillation. Lu [65] proposes a recommender using knowledge distillation in the e-commerce domain. The recommender uses DeepGBM [48], a framework for knowledge distillation where the teacher and student models are GBDT and MLP, respectively. In other words, users' preferences learned by the GBDT model are compressed and transferred to the MLP. For a given user-item pair, the recommender estimates the probability of the pair resulting in clicks, purchases, and money spent. Consequently, the paper uses interacted impressions as positive signals, while non-interacted impressions are negative. 3.4.6 Pre-trained Language Models. Wang et al. [99] propose a recommender using a PLM in online advertisements. The recommender, called BERT4CTR, is based on the NumBERT[119] language model and a novel attention mechanism called Uni-Attention. The paper optimizes the recommender to predict the CTR of a given user-item pair, i.e., the ratio between the number of interactions and the number of impressions of the pair. As such, the paper treats interacted impressions as positive and non-interacted impressions as negative signals. The paper also computes and includes several features from impressions when training the recommender. For instance, the user-wise CTR, number of impressions for a given item, and the items' position on-screen.", "3.5 Reinforcement Learning": "In this section, we present eleven papers describing recommenders using reinforcement learning (RL) to model users' preferences. Papers in this section model the recommendation task as a Markov decision process [4]. The notation and terminology of a recommender using reinforcement learning is: \u00b7 State ( \ud835\udc60 ): is a tuple containing a user and their impressions and interactions. \u00b7 Action ( \ud835\udc4e ): is an impression generated by the model for a given user and state. \u00b7 Reward ( \ud835\udc5f ): indicates the users' preference for the items in an impression. It is a function of the user, state, and action to the set of real numbers. \u00b7 Policy ( \ud835\udf0b ): is the objective function of the recommender. A recommender using reinforcement learning uses the reward to model users' preferences with higher granularity. Reinforcement learning aims to produce an unbiased estimator maximizing accumulated rewards over time. One paper uses the policy gradient REINFORCE [105] algorithm: a method computing a stochastic approximate gradient [117]. Two papers use the actor-critic (AC) framework [38]: evaluating and updating the policy driving the Manuscript submitted to ACM recommender system during its learning process. One paper uses evolution strategies (ES) [88] to model user preferences: optimization algorithms using heuristic emulating the evolution of organisms. Three papers model the recommendation task as the multi-armed bandits (MAB) [46, 95] problem: the recommender considers each item as an arm and generates impressions by selecting specific arms. Lastly, four papers use deep neural networks adapted to the reinforcement learning paradigm. 3.5.1 REINFORCE. Xie et al. [110] describe a recommender using the REINFORCE algorithm in the e-commerce domain. The recommender is a generative adversarial networks, i.e., a composition of two neural networks called generator and discriminator . The generator network creates user-item pairs representing realistic user feedback, either interacted or non-interacted impressions. The discriminator is tasked to distinguish whether any user-item pair is real or created by the generator. Both networks are trained in an adversarial setting: the generator improves by creating realistic user-item pairs deceiving the discriminator; the discriminator improves by classifying the pair's source. 3.5.2 Actor-Critic Framework. Two papers [19, 25] in the reviewed literature use the AC framework. However, one paper uses the soft actor-critic (SAC) framework, an off-policy AC devised for reinforcement learning using deep neural networks. Chen et al. [19] describe a re-ranking recommender in the online advertisements domain. The paper defines the actor as a deep neural network using the encoder-decoder architecture and aiming at re-ranking an impression. The paper defines uses DeepSet[114] as the encoder network, while it uses PointerNet[98] as the decoder network. Regarding the critic, the paper uses a MLP architecture that predicts whether a given impression will receive an interaction from the user, i.e., whether any item inside the impression will be interacted with. As such, the paper considers a positive signal when at least an item in an impression is interacted with; on the contrary, a negative signal is when all items do not receive any interaction. The paper also describes a business-oriented metric called flow control that limits the number of impressions of certain items. Deffayet et al. [25] describe a recommender evaluated using simulated user profiles. The paper uses the SAC [40] framework to train a recommendation model composed of a variational auto-encoder (VAE) [49]. In particular, the paper first trains a VAE on impressions and their received user feedback, i.e., the VAE learns to generate another impression and to predict the user feedback on such impression. After training the VAE model, the paper uses the VAE's decoder as the critic of the SAC framework. 3.5.3 Evolution Strategies. Pei et al. [76] describe a recommender using ES in the e-commerce domain. The goal of the recommender is to maximize the financial earnings associated with each type of user-item interaction, e.g., the paper considers clicks and purchases to yield different revenues. The recommender receives as input a tuple containing several features from the user (e.g., age) and an impression as a vector of features from impressed items. The paper considers non-interacted impressions as negative signals, as the reward for this type of user-item feedback is 0. The reward of other types of user-item feedback varies by the expected economic profit for the action performed by the user. 3.5.4 Multi-Armed Bandits. Three papers [39, 59, 69] describe MAB recommenders. Li et al. [59] describe a recommender in the domain of online advertisements. The goal of the recommender is to balance exploitation and exploration in their generated recommendations. In particular, the recommender creates clusters of users and items using global impressions. The paper defines the reward as a piece-wise function, where non-interacted impressions receive a reward of 0, while interacted impressions receive a reward of 1. McInerney et al. [69] describe a contextual multi-armed bandit recommender in the music domain. The goal of the recommender is to generate relevant recommendations and 'explanations', i.e., detailing the reasons behind recommendations. The recommender is tasked to predict whether a given user-item pair is an interacted or non-interacted impression. Then, the recommender generates impressions containing Manuscript submitted to ACM items with the highest probability of being interactions. Consequently, the paper deems non-interacted impressions as negative signals. Moreover, the paper assigns the label '1' to interacted impressions and the label '0' to non-interacted impressions. The recommender predicts such labels using a factorization machine [84]. Gruson et al. [39] describe a recommender and in the music domain. The goal of the recommender is to maximize the 'impression-to-stream', i.e., the number of interactions per impression on a two-dimensional carousel layout. The paper defines interacted impressions as playlists with at least one song listened for more than thirty seconds, while non-interacted impressions are playlists without listened songs or with songs reproduced for less than thirty seconds. Similar to previous papers, the reward is 1 when the playlist is an interacted impression, while 0 when it is a non-interacted one. 3.5.5 Deep Neural Networks. Four papers [18, 25, 31, 109] use deep neural networks adapted to the reinforcement learning paradigm. Chen et al. [18] describe a recommender in the video domain. The recommender consists of a recurrent neural networks (RNN) architecture with chaos-free layers [54]. The paper defines the reward function as a non-negative decreasing function of the position of items and whether such items received interactions. For instance, for an impression with five items, an interaction with the item in the first position yields a reward of 5, while an interaction with the item in the last position yields a reward of 1. If no item in the impression is interacted with, then the reward is 0. Xie et al. [109] describe a recommender in the product's domain. The goal of the recommender is to generate relevant recommendations in a resource-constrained scenario. The recommender is a composition of two DQNs [71], where each network receives the state as input, and their output is an impression. The state consists of the set of users' profiles, a vector of the user's interacted impressions, and a set of the user's contextual impressions. The paper evaluates the recommender in an offline and online setting. Ge et al. [31] describe a recommender in the media and e-commerce domains. The goal of the recommender is to generate accurate and fair recommendations. The recommender consists of a single MLP network with GRU layers. In the paper, fairness is related to the number of impressions of a given user with the same item. The paper defines the set of long-tail items (denoted as \ud835\udc3f\ud835\udc47 \ud835\udc60 ) on a given state containing items with the lowest number of impressions, precisely, \ud835\udc3f\ud835\udc47 \ud835\udc60 encloses 80 % of the items in the catalog. The reward is a combination of an accuracy-based and a fairness-based reward. For a given state and action, the accuracy-based reward (denoted as \ud835\udc5f \ud835\udc4e\ud835\udc50\ud835\udc50 \ud835\udc60,\ud835\udc4e ) is the precision [29] and the fairness-based reward (denoted as \ud835\udc5f \ud835\udc53 \ud835\udc4e\ud835\udc56\ud835\udc5f \ud835\udc60,\ud835\udc4e ) is the hinge-loss between the precision of long-tail items and the desired percentage of long-tail items in an impression:  where I returns 1 if the predicate is true, 0 otherwise; \ud835\udc3f\ud835\udc47 \ud835\udc60 is the set of long-tail items for a given user in \ud835\udc60 ; and \ud835\udefd is the target percentage of long-tail items in \ud835\udc4e .", "3.6 Not Described": "In this section, we describe three reviewed papers that do not propose a recommendation model using impressions, but analyze impressions in recommender systems from other angles or contribute to the research and development of IARS in other ways. Zhao et al. [124] describe how to extract the signals from non-interacted impressions using user studies on the media domain. The paper describes participants of the study as registered users of a movie recommender system, who, after a certain number of interactions, were given the option to participate in the study. Participants were asked about their preference for a non-interacted item in an impression after interacting with it. Regarding the results of the study, 38 . 6 % of the responses were classified as unaware , meaning the participant did not know the item was in the impression. Moreover, only 5 . 8 % of the responses were classified as not enjoy , meaning the impressed item is a negative Manuscript submitted to ACM signal. Due to the low number of responses in the last category, the paper states that treating non-interacted impressions as negative signals 'could be problematic'. Nayak et al. [73] propose three evaluation metrics for recommender systems on the news domain. Those metrics inspect all items included in the impressions generated by the recommendation model. The first metric, called lifespan, measures the period items are deemed as relevant by users. The second metric, called half-life, measures the period items take to reach half their number of impressions since their first one. The third metric, called peak-time, measures the period items take to reach their peak number of impressions since their first one; it is computed as a moving average. Sun [96] proposes several directions to improve users' preferences modeling. One direction is to exploit contextual impressions in the learning process of recommendation models. By adding this type of impression, it is expected that the recommendation model can extract more refined information about users' preferences, at least when compared to using interactions alone. With contextual impressions, it is possible to contextualize the users' decision process, as they contain all the shown items, their position on-screen, and kind of received user feedback.", "3.7 Discussion": "After reviewing the literature of IARS, composed by 43 papers, we identify several trends in the recommendation models present in those papers and how they use impressions. We observe an increase in the number of IARS papers over time, especially in recent years, as Figure 2 shows. A higher number of published papers serves as an indicator of the community's interest in this learning paradigm. In particular, almost half of the reviewed papers were published between 2023 and 2022; furthermore, two-thirds of the reviewed papers were published in the past five years, and all but one were published in the past ten years. 3.7.1 Model-centric Taxonomy. Table 3 shows the classification of each reviewed paper. In the table, each row presents the classification of one paper according to the proposed taxonomies described in Section 2.4 and properties of recommenders and impressions described in Section 2.1. 1112 As seen in the table, the two most popular categories of recommendation models are deep learning and reinforcement learning , becoming popular in the past five years. Older papers, instead, describe recommendation models classified as heuristics or statistical. Between older and recent papers, we find that papers describe recommendation models that use shallow machine learning, particularly in 2016, 2017, 2019, and 2020. 3.7.2 Data-centric Taxonomy. The two most popular choices in the literature are extracting features and learning from impressions, as seen in Table 3. In the literature, the most popular feature is the number of user-item impressions , i.e., \ud835\udc5b\ud835\udc52 \ud835\udc62,\ud835\udc56 . Particularly, this feature indicates the times a given user has seen a given item inside an impression. Other features, less observed in the literature, comprise the CTR, the on-screen position of impressed items, and the time since the last impression with the same item. In Section 2.4, we also define learning from impressions as receiving either a single impressed item or all items in an impression as part of the input of the recommendation model. In the literature, most papers pass a single impressed item to recommendation models. This means the input of a recommendation model consists of a \ud835\udc5b -tuple holding a user identifier, an impressed item identifier, the users' action on the item, and a variable number of user-wise and item-wise attributes. 11 One paper [63] appears twice in Table 3 because it describes two recommenders using impressions. 12 The order of papers in the text and the table is the same. Manuscript submitted to ACM Table 3. Categorization of IARS papers reviewed in this work, where each row is one paper. Model-Centric Taxonomy categorizes papers by their recommender design. Data-Centric Taxonomy categorizes papers by how they use impressions. Signal-Centric Taxonomy categorizes papers by how they deem non-interacted impressions to user preferences. Impression Type categorizes papers using contextual or global impressions. Impression Signals categorizes papers using non-interacted impressions as positive, negative, or neutral signals. Recommender Type categorizes papers by how the recommender generates impressions. Manuscript submitted to ACM 3.7.3 Signal-centric Taxonomy. In terms of how papers deem impressions in terms of users' preferences, especially non-interacted impressions, we observe that reviewed papers use several approaches with varying complexity. On the one hand, most papers treat non-interacted impressions as negative signals implicitly issued by users. This approach assumes that users' preferences are binary, where an interaction represents strong positive feedback, while a noninteraction represents strong negative feedback. Moreover, this approach is also the simplest to implement; however, as illustrated in previous research [124], it does not take advantage of impressions and their signals. On the other hand, a handful of papers prefer recommendation models that learn the users' preferences toward impressed items using additional information. For instance, Lee et al. [55] computes the number of past impressions for user-item pairs, while Zhan et al. [116] measure the time spent by a user watching an item. Approaches that learn users' preferences are more complex in the literature. Also, they tend to extract more information from impressions. When combined, both aspects may result in better modeling of users' preferences and, ultimately, better recommendations.", "4 Datasets with Impressions": "Researchers and practitioners need access to datasets with impressions to evaluate their proposed IARS. Before 2020, only five datasets were available for research purposes. The landscape has evolved, as nowadays, researchers can access and use thirteen datasets in their research works. This section describes datasets with impressions, where we use the definitions of impressions, interactions, and the different types of user-item feedback provided in Section 2.1. We classify datasets with impressions into three categories: public , expired , and private datasets. The definition of each category is the same as the one stated by P\u00e9rez Maurera et al. [80]: \u00b7 Public: datasets accessible via the Internet or by request to publishers. They can be used in future research activities if their license agreements are met. \u00b7 Expired: datasets available to participants of competitions. They are currently not accessible or cannot be used in research activities. \u00b7 Private: datasets not published nor publicly available. Table 4 and Table 5 summarize the statistics of the datasets with impressions that we identify in the literature. Table 4 reports the statistics of public datasets, where those statistics are computed using our definition of impressions and interactions. Table 5 reports the statistics of expired and private datasets, where those statistics are extracted from the paper using the dataset. In most cases, papers do not report such statistics or may compute them using different definitions. This section only describes public and expired datasets, as papers limit the details of private datasets due to privacy and business property constraints.", "4.1 Public Datasets": "Public datasets are accessible to researchers and practitioners and can be used in future research activities. Such datasets are available online or upon request to the publishers. However, future work must comply with each dataset's license agreements. 13 Table 4 summarizes relevant statistics of public datasets, such as the number of users, items, user-item interactions, and user-item impressions. In this section, we comprehensively describe each public dataset and its attributes, e.g., its definition of users, items, and collection period. We classify public datasets into two categories based on the type of impressions such datasets contain: 13 For instance, the ContentWise Impressions dataset cannot be used for commercial purposes. Manuscript submitted to ACM Table 4. Statistics of public datasets with impressions. Type refers to the type of impressions in the dataset. Year refers to when the dataset is published. Users and Items refer to the number of users and items, respectively. Impressions refers to the number of impressed user-item pairs. Interactions refer to the number of interacted user-item pairs. Imp x Int refers to the ratio between the number of impressed and interacted user-item pairs. Datasets are grouped by category and by year in ascending order. a The number of users cannot be computed as the dataset does not include unique numerical identifiers for users. b https://www.kaggle.com/competitions/kddcup2012-track2 \u00b7 Contextual: datasets containing interactions and impressions with their connections, i.e., for a user-item interaction, it is known which impression has the interacted item. \u00b7 Global: datasets containing interactions and impressions without their connections, i.e., for a user-item interaction, it is not known which impression has the interacted item. Global datasets have a reduced utility when compared to contextual counterparts. By their definition, global datasets do not contain the context of interactions, i.e., it is not possible to connect interacted items with the impression holding them. This implies it is not possible to know which other items were impressed when the interaction happened, the position of the interacted item on the impression, or the arrangement of the impression on-screen. Furthermore, five recommenders in reviewed papers [35, 66, 76, 109, 110] use contextual impressions. Lastly, global datasets cannot be used when sampling interacted and non-interacted items from the same impression, as used in the literature [35, 107].", "4.2 Public Datasets with Contextual Impressions": "We identify four public datasets containing contextual impressions. In those datasets, a contextual impression is a tuple containing, at least, a user identifier and an impression as a vector of item identifiers. In two datasets, the tuple also contains an item identifier representing the interacted item. When the user did not interact with any item in the impression, the item identifier placed in the dataset is empty or replaced with a unique code. In the two other datasets, the tuple contains an additional vector of labels with the same number of elements as the impression vector. In this vector, there is one label for each impressed item, where the label indicates the type of user feedback such item received. Two datasets contain the item identifier in the contextual impression. The ContentWise Impressions dataset [80] contains impressions from an online streaming media service. 14 The data was collected from January to April 2019. Users are anonymized registered accounts with the service, and items are the media content related to TV series and 14 ContentWise Impressions is accessible at https://github.com/ContentWise/contentwise-impressions Manuscript submitted to ACM movies. The dataset also contains on-screen layout information: the position of the impression on a two-dimensional layout. Lastly, most impressions in the dataset do not contain interacted items. The FINN.no Slates [27, 28] dataset contains contextual impressions from an e-commerce service. 15 The data was collected over thirty days; however, the dataset does not contain the date and time of impressions or interactions. Users are registered accounts, and items are products and goods. Similar to the ContentWise Impressions dataset, most impressions do not contain interactions. The dataset contains impressions generated by a search engine and a recommender system. Two datasets contain labels of users' feedback. The MIND dataset [107] contains impressions from an online news service. 16 The data was collected between October 12 th and November 22 nd 2019, for a total of six weeks, on users with at least five interactions between those dates. Users are anonymized registered accounts, and items are news articles. The dataset does not contain all the impressions generated by the recommender system during the collection period. Instead, it contains the impressions generated between the 5 th and 6 th weeks. Moreover, impressions in the 6 th week are not labeled. This dataset was provided to the participants of the MIND News Recommendation Competition where they were tasked to devise a re-ranker recommender (see Section 2.1). 17 The SL4RS dataset [103] contains impressions from an e-commerce service. 18 The dataset's reference does not specify the period where the data was collected, nor the definition of users or items. However, it does specify that data were collected from an online game and describes some of the users' contextual and items' content information available in the dataset. A unique trait of the dataset is that it contains data points collected before and after the deployment of a recommender system. Another unique trait is that it contains impressions generated for a single user action and a sequence of users' actions. Consequently, the dataset can be divided into four partitions based on the type of data points and the recommendation task at hand.", "4.3 Public Datasets with Global Impressions": "We identify ten public datasets containing global impressions. In those datasets, a global impression is a tuple containing a user identifier and an item identifier. Seven datasets include a label to indicate whether the user-item pair corresponds to an interacted or non-interacted impression. One dataset includes two binary labels to indicate whether the item was impressed to the user and whether the item received an interaction, respectively. One dataset includes the number of interactions and impressions for the user-item pair. One dataset includes the numbers of user-item clicks and user-item purchases for the user-item pair. Hence, a non-interacted impression is a tuple with zero user-item clicks and purchases. Seven datasets contain a label to indicate an interacted or non-interacted impression. The Yahoo! - R6A and Yahoo! - R6B datasets [22, 33, 57, 59] contain impressions from an online news service. 1920 In the first dataset, the data was collected in the first ten days of May 2009, while in the second it was collected between October 2 nd and 16 th 2011. In both datasets, users are anonymous accounts visiting an online news recommender system, and items are news articles. Those datasets contain impressions generated by a recommender selecting items at random. Hence, the dataset is useful for evaluating recommenders using reinforcement learning or counterfactual learning. The PANDOR dataset [94] contains impressions of online advertisements from a media and news service. 21 Users are anonymous accounts using the service, and items are advertisements. The dataset contains impressions generated by a top-popular or a similarity-based recommender. The In-Shop Combo and Cross-Shop Combo datasets [127] contain impressions of 15 FINN.no Slates is accessible at https://github.com/finn-no/recsys_slates_dataset 16 MIND is accessible at https://msnews.github.io. 17 Details on the MIND News Recommendation Competition are available at https://msnews.github.io/competition.html 18 SL4RS is accessible at https://github.com/fuxiAIlab/RL4RS. 19 Yahoo! - R6A is accessible upon request at https://webscope.sandbox.yahoo.com/catalog.php?datatype=r&did=49 20 Yahoo! - R6B is accessible upon request at https://webscope.sandbox.yahoo.com/catalog.php?datatype=r&did=54 21 PANDOR is accessible at https://archive.ics.uci.edu/ml/datasets/PANDOR Manuscript submitted to ACM fashion garments on an e-commerce service. In both datasets, the data was collected over forty days. Users are registered accounts on the service, and items are combinations of bottom and top garments. 22 Each garment has an attribute called store ; however, the paper does not detail the meaning of such an attribute. Nevertheless, that attribute is used to distinguish the types of items in each dataset: in the In-Shop Combo dataset, top and bottom garments share the same store, while in the Cross-Shop Combo dataset, they may have different stores. The Kwai_FAIR System and Kwai_FAIR Experiment datasets [102] contain impressions of short videos from a social network. Users are accounts registered in the social network, while items are short videos recently published by users. 23 The difference between both datasets is how items were selected: in the Kwai_FAIR Experiment dataset, the items were selected randomly, while in the Kwai_FAIR System dataset, the items were selected by a recommender system. The Alimama dataset [92] contains two binary labels in the global impression: one indicates whether the user was impressed with the item, and the other indicates whether the user interacted with the item. The dataset contains impressions of online advertisements from an e-commerce service. The data was collected over eight days. 24 Users are registered accounts, and items are advertisements. In the dataset, a non-interacted impression has the first label as true and the second as false , while an interacted impression has both labels as true . The Search Ads dataset [55] contains the number of interactions and impressions in the global impression. The dataset contains impressions of online advertisements shown by a search engine. 25 Users are individuals using the search engine, and items are advertisements. The dataset is provided with three partitions: training , validation , and testing . The dataset was available to the participants of the KDD Cup 2012 - Track 2 : where they were tasked to compute the ratio between the number of interactions and impressions for any user-item pair. 26 Lastly, the Ali-CCP dataset [68] contains the number of user-item clicks and purchases in a global impression. The dataset contains impressions of articles from an e-commerce service. 27 Users are registered accounts, and items are products and goods. The dataset contains two types of user-item feedback: clicks and purchases. In the dataset, a non-interacted impression has zero clicks and purchases. An interacted impression has at least one click or purchase.", "4.4 Expired Datasets": "Expired datasets were accessible to participants of the ACM RecSys Challenge, a yearly competition where participants are tasked to solve industrial recommendation tasks. Such challenges run in a limited period, where after such a period, the datasets are not accessible and cannot be used in future research works. Table 5 summarizes statistics of expired datasets, where the statistics values come from each dataset's papers. Four expired datasets exist in the literature, where one dataset contains contextual impressions, and three contain global ones (classification detailed in Section 4.1). The Trivago 2019 [50] dataset contains contextual impressions from an online travel service. Users are accounts registered in the service, while items are accommodations. The dataset was released as part of the ACM RecSys Challenge 2019. In the dataset, a contextual impression is a tuple of a user identifier, an item identifier, and an impression as a vector of item identifiers. Three datasets contain global impressions. The XING 2016 [1] dataset contains impressions from a job-oriented social network. Users are accounts registered in the social network, while items are job offers. The dataset was released 22 In-Shop Combo and Cross-Shop Combo are accessible at https://tianchi.aliyun.com/dataset/dataDetail?dataId=131519. 23 Kwai_FAIR System and Kwai_FAIR Experiment are accessible at https://github.com/Alice1998/MakeFairnessMoreFair 24 Alimama is accessible at https://tianchi.aliyun.com/dataset/dataDetail?dataId=56 25 Search Ads is accessible at https://www.kaggle.com/competitions/kddcup2012-track2/data 26 Details on the KDD Cup 2012 - Track 2 are available at https://www.kaggle.com/competitions/kddcup2012-track2 27 Ali-CCP is accessible at https://tianchi.aliyun.com/datalab/dataSet.html?dataId=408 Manuscript submitted to ACM Table 5. Statistics of expired and private datasets with impressions. Statistics come from datasets' papers. Each paper may define and count interactions and impressions differently than this work. Expired datasets (3) are presented first. Then, private datasets (9). Classification refers to the accessibility of the dataset. Year refers to when the dataset is published. Users and Items refer to the number of users and items, respectively. Impressions refers to the number of non-interacted user-item impressions. Interactions refers to the number of interacted user-item impressions. '-' indicates the value is not reported. a https://www.recsyschallenge.com/2023/ as part of the ACM RecSys Challenge 2016. In the dataset, a global impression is a tuple containing a user identifier and an item identifier or a tuple containing a user identifier and an impression as a vector of item identifiers. The XING 2017 [2] dataset contains impressions from the same job-oriented social network. Users are accounts registered in the social network, while items are job offers. The dataset was released as part of the ACM RecSys Challenge 2017. Unlike the 2016 dataset, a global impression in this dataset is a tuple of a user identifier, an item identifier, and a label indicating whether the pair is an interacted or non-interacted impression. Lastly, The ShareChat 2023 dataset contains impressions from an online advertisement service. 28 Users are accounts receiving advertisements, while items are advertisements of mobile applications. The dataset was released as part of the ACM RecSys Challenge 2023. The dataset contains two types of user feedback: clicks and installs. In the dataset, a global impression is a tuple of a user's features, an item's features, a binary label indicating whether the user clicked the item, and a binary label indicating whether the user installed the item. Hence, an interacted impression has at least one label with the value true , and a non-interacted impression has both labels with the value false .", "5 Evaluation": "Due to the importance of evaluation methodologies in recommender systems, we describe the current trends in evaluating impression-aware recommender systems (IARS). The section discusses three topics on evaluation. First, the types of evaluations used in the literature, where we compare offline evaluations, user studies, and online evaluations. Second, the research goals and evaluation methodologies followed when evaluating IARS. Third, the challenges faced when working with impressions. The evaluation of recommender systems is an active and extensive research area with several open questions. It is beyond the scope of this section to provide effective answers to those open directions. 28 Details of the dataset are available at: https://www.recsyschallenge.com/2023/ Manuscript submitted to ACM Table 6. Classification of reviewed papers according to the type of evaluations they use. We group those papers that describe offline and online evaluations of their recommenders into a distinct group.", "5.1 Evaluation Types": "Evaluation types refer to the methods researchers and practitioners use to measure the recommendation quality of their recommenders. Four categories of evaluation types exist in the literature of recommender systems [15, 115]: \u00b7 Simulations: consist of measuring the recommendation's quality of a recommender using crafted preferences of users. Their main advantage is their low complexity. Their drawback is their low generalization capabilities due to their reliance on artificial user feedback. \u00b7 Offline evaluations: consist of measuring the recommendation's quality of a recommender using a dataset with impressions. Their advantages are low cost, accessibility, and reproducibility. Their drawback is its low generalization capability due to their reliance on logged and not updated feedback. In Section 4, we describe the datasets with impressions used in offline evaluations in the reviewed literature. \u00b7 User studies: consist of exposing impressions to a selected and reduced group of users in a controlled environment. User studies are more challenging to reproduce and have limited generalization power; however, they are especially useful for collecting explicit user feedback regarding a given set of qualitative or quantitative metrics. \u00b7 Online evaluations: consist of exposing impressions to users of an online and deployed recommender system. This is the most challenging evaluation because it is costly, time-consuming, and increases business risks. However, they provide the most realistic picture of user preferences toward impressions. As shown in Table 6, most reviewed papers use offline evaluations to measure the quality of their recommenders. Moreover, half of the reviewed papers perform offline and online evaluations, two evaluate recommenders via user studies, three exclusively perform online evaluations, and one performs simulations.", "5.2 Research Goals and Evaluation Methodologies": "Researchers must ensure the entire methodology, either ad-hoc or based on existing literature, is in line with their research goals, i.e., the methods do not conflict, pollutes, or invalidate results. We classify the research goals of reviewed papers into two categories: \u00b7 Improving the quality of recommendations: an extension of the traditional research goal in recommender systems applied to IARS. The aim is to increase the quality of recommendations by devising novel recommenders using impressions. Consequently, the usual best practices in recommender systems research apply. When using impressions, particular care must be taken to ensure the evaluation methodology is consistent and aligned with the research goal, e.g., researchers must not use impressions at test time when evaluating end-to-end or plug-in recommenders. Manuscript submitted to ACM \u00b7 Extracting signals from impressions: aims to disentangle the user preference on impressions with emphasis on non-interacted impressions. Several papers state [78, 79, 124] impressions contain complex and mixed signals. For instance, Zhao et al. [124] user's inaction on impressions can be attributed to different factors, such as users not being interested in particular items or having already interacted with such items. Reviewed papers use traditional or ad-hoc methodologies depending on the nature of their studies. Papers extracting signals from impressions use two approaches. The first approach gathers users' explicit preference for non-interacted impressions with user studies or online evaluations. Zhao et al. [124] describe how to perform a user study to gather users' preferences on non-interacted impressions. The second approach extracts the preference for impressions using heuristic or machine learning methods in offline or online evaluations. Several reviewed papers [8, 55] describe recommenders learning the preference of users toward impressions. Aharon et al. [8] includes an additional bias term, called frequency bias, to a traditional matrix factorization recommender, while Lee et al. [55] defines a weighted factor accounting the user preferences to several features from impressions. Other papers [78, 79] describe how adding an extra hyper-parameter to recommenders aids in identifying whether impressions are positive or negatives signals. Weexemplify a case of a methodology conflicting and confounding the research goal using the ACM RecSys Challenge 2019. The goal of the competition was to devise end-to-end recommenders, i.e., a recommender generating learning user preferences and generating impressions. 29 The competition employed a well-known evaluation methodology in recommender systems: it tasked participants to submit impressions containing interacted items at test time and evaluated submissions using the mean reciprocal rank metric. However, the competition provided the impressions at test time, i.e., the impression participants had to submit. That evaluation methodology is designed to assess the quality of re-ranking recommenders instead of end-to-end ones, i.e., the methodology evaluates recommenders receiving an impression and generating a permutation of it.", "5.3 Challenges": "In this section, we identify and describe several challenges researchers and practitioners encounter when handling impressions in recommender systems, either when devising recommendation models, disseminating datasets, or evaluating recommender systems. 5.3.1 Signals in Impressions. The first challenge is connected to fully utilizing impressions and extracting their signals to learn users' preferences. In this regard, in Section 3, we describe all the techniques and approaches the literature has employed to use impressions in their recommendation models. Despite using non-interacted impressions as negative signals is the most popular approach, it may not be the most effective. That approach is problematic because it does not take into account that user inaction towards good recommendations may be due to factors unrelated to the items' relevance, as found by Zhao et al. [124]. For example, a non-interacted impressed item may be relevant; however, it is superseded by another more relevant impressed item given the users' context, mood, or awareness of all impressed items. At the same time, users' preferences are not binary or stationary; instead, they depend on many factors, such as the users' context, short and long interest, and location, among other factors [3]. Thus, a non-interacted impression may be relevant to the user; however, in different contexts or situations. The literature has not encountered, yet, a set of approaches able to disentangle the signals from impressions; specially, from non-interacted impressions. Moreover, it is also challenging the effective integration of such signals into existing or newer recommendation models. 29 The definitions of several types of recommenders are provided in Section 2.1. Manuscript submitted to ACM 5.3.2 Scalability. Another challenge concerns the scalability of recommenders due to impressions being more abundant than interactions. As illustrated in Table 4, the ratio between the numbers of impressions and interactions ranges from 1 . 82 and 143 . 45 with a median value of 18 . 58 and mean of 26 . 54 \u00b1 36 . 30 in public datasets. Notably, in four datasets (In-Shop Combo, Kwai_FAIR Experiment, Kwai_FAIR System, and MIND), the number of impressions and interactions align closely with their magnitude: millions of records. In eight datasets (ContentWise Impressions, FINN.no Slates, Yahoo! - R6A, Yahoo! - R6B, Search Ads, Ali-CCP, Alimama, Cross-Shop Combo), the number of impressions surpasses the number of interactions by one order of magnitude, and in one dataset (PANDOR) it is exceeded by two orders of magnitude. Hence, future works must be attentive to address scalability concerns when using impressions. Three of our previous papers [78, 79] already highlight this challenge, whereby certain recommenders could not be evaluated to scalability issues. 5.3.3 Public Datasets with Impressions. The dissemination of public datasets with impressions is another challenging task. The extraction of datasets from real-world recommender systems is already a difficult task, entailing careful considerations encompassing data collection methodologies, data cleansing procedures, privacy safeguards, and other aspects [32]. Furthermore, disseminating datasets with impressions introduces novel considerations and exacerbates existing risks. Specifically, datasets derived from real-world proprietary recommenders entail inherent business risks, as they expose users' interests, system behaviors, and the system's notion of user relevance. Moreover, additional concerns, such as robust anonymization techniques, must be considered and extended to impressions. 5.3.4 Incomplete Information. Another challenge arises from the missing information in current public datasets, consequently constraining the efficacy of evaluation methodologies. As detailed in Section 4, eleven public datasets with impressions are available for research purposes. Among those, eight datasets contain global impressions, where connecting interactions and impressions is not possible. Three datasets contain contextual impressions, which can connect interactions and impressions; however, two lack all impressions records, and two lack time-related attributes in some or all impressions. The absence of such information limits future studies and modeling capabilities of users' preferences. For instance, the research of position biases within datasets with global impressions is not achievable due to those datasets not having position-related attributes. 5.3.5 Biases within Impressions. The last challenge stems from the biases present in datasets with impressions, which are important to identify in order to adapt methodologies accordingly. In this context, data bias refers to the disparities between the anticipated and actual statistical distributions within data [17]. It is worth noting that traditional interaction data and impressions are generated mostly through the same process and combine the biases produced by the recommender system, the user interface and the users themselves. Despite this, impressions may present new unique bias characteristics that deserve to be studied. When training with impressions, we can identify two main scenarios. First, certain biases may manifest exclusively within impressions, such as new biases related to which non-relevant items are recommended or the position biases [17] observed in contextual impressions. Second, impressions likely exhibit biases akin to those found in interactions or other data sources, but possibly to different degrees. For instance, exposure biases [17] are present in impressions as well due to the tendency of recommender systems to include popular items in impressions. In order to overcome these challenges, it is also necessary that the community further studies biases in impressions and recommender systems, a direction that we discuss in Section 6. Manuscript submitted to ACM", "6 Open Research Questions & Future Directions": "In previous sections, we review the state-of-the-art in impression-aware recommender systems (IARS). From such a review, we identify several research questions that remain unanswered. As impressions are a novel data type in recommender systems, they allow researchers to study different directions and devise more refined evaluation methodologies than those currently used in the literature. Previous work by Jeunen [44] highlights several open research questions related to impressions. In this section, we describe such questions, identify research needs, and propose additional research directions for future works. We focus our discussion on six areas of improvement: recommendation models, datasets with impressions, debiased recommendations and evaluations, impressions signals, and user fatigue.", "6.1 Impressions Signals": "In Section 2, we propose the signal-centric taxonomy, which classifies recommenders by whether they assume or learn impressions signals. When reviewing recommenders, we observe that most papers assume non-interacted impressions are negative signals, i.e., users dislike such items. The literature, however, does not contain strong empirical evidence of non-interacted impressions being negative or positive feedback. In both Section 2 and Section 5, we emphasize only three papers [78, 79, 124] address this topic. Given such few studies and inconclusive evidence, it remains an open question how to treat impressions, especially non-interacted impressions . Furthermore, it also remains an open question how to disentangle the signals of users' preferences inside impressions . We identify two considerations when addressing such open questions. First, as happens in several research areas in machine learning, researchers must be aware impressions may be subject to concept drift [72, 81]. Concept drift represents statistical changes in data points over time, degrading the ability of machine learning models to accurately predict future data points. Hence, future research works may study detection methods for concept drift using impressions. Second, as we highlighted in previous discussions, different entities generate impressions, and the signals in impressions may be tied to those entities. Consequently, future works may need to study whether impressions alone are sufficient to disentangle their signals.", "6.2 User Fatigue": "User fatigue is the phenomenon where users dislike the impressions generated by the recommender system regardless of their relevance due to impressions being repetitive or uninteresting. For example, recommendations of movies similar to those already watched by users may result in positive user experiences. However, users exhibit fatigue with those movies when they are not rewarded with positive user feedback after many impressions. At this point, the recommender must vary the recommendations; otherwise, it risks losing users' interest and trust in the recommenders' capabilities. In the example, impressed items are relevant due to the users' past consumption patterns but not desirable as they do not show interest in them. It remains an open question how to identify and model user fatigue using impressions . The literature contains five papers [8, 13, 55, 66, 106] addressing this question; however, they use hard-coded rules, ad-hoc fatigue functions, or learn non-personalized functions. Impressions enable the study of users' fatigue because they contain the necessary information for its study: the items presented to the user and their received back. In this regard, impressions can be complemented with users' intent and context for a comprehensive study of users' fatigue. The reviewed literature studies users' fatigue by using the number of interactions and impressions for a given user-item pair. Manuscript submitted to ACM", "6.3 Recommendation Models": "Through the lens of the model-centric taxonomy, recommendation models in the literature are varied, where they mostly use deep learning or reinforcement learning to learn users' preferences. Notably, we observe that the community has not explored many other categories of recommendation models; some of which may be suitable to work with impressions. Thus, a research area that may be further studied is the design and development of recommendation models belonging to other categories . Although this research area is not unique to IARS, addressing it involves the discussion of topics unique to this recommendation paradigm. For example, redefining the similarity in a k-nearest neighbor recommender to capture the similarities between items based on their impressions. A good starting point in this area is to consider recommendation models able to encode side information , e.g., graph-based models [21, 23] or factorization machines [84], where the impressions are the side information of interactions. One of our previous works [77] shows two approaches to effectively incorporate impressions into graph-based recommenders. In particular, we redefine the graph and build it using both interacted and non-interacted impressions. Through the lens of the data-centric taxonomy, only a handful of works in the literature sample from impressions; however, item sampling is a highly relevant area in recommender systems research. In our review, we find that the literature has not studied how different sampling techniques affect the recommendation quality of IARS . A good starting point in this direction is in differentiating sampling items within the same impressions or globally. However, more complex types of item sampling can be studied as well. For instance, impressions can be treated as an additional channel of user feedback. Thus they can be sampled using the techniques proposed by Loni et al. [64] while considering their entangled signals. Recently, Jain and Jindal [43] review and collect into a single document many item sampling techniques used in past recommendation models. Lastly, through the lens of the signal-centric taxonomy, few recommendation models in the literature learn the signals of impressions. Instead, most assume non-interacted impressions represent negative signals, while interacted impressions represent positive ones. This is more noticeable in recommender systems using reinforcement learning. In those cases, the literature typically assigns a zero reward to non-interacted impressions. One research direction to pursue is devising recommendation models able to learn the signals in impressions . For reinforcement learning recommenders, this implies modifying the reward function so it does not always yield zero to non-interacted impressions. Instead, the function may consider other features or factors, e.g., users' fatigue or the number of impressions with the same item. Another research direction without much exploration is the study of non-interacted impressions as neutral or positive signals .", "6.4 Biases in Impressions, Debiased Recommendations & Evaluations": "One of the challenges (see Section 5) that the community faces when using impressions is the identification and balancing of biases in impressions. Chen et al. [17] states that a data bias is a difference between the expected statistical distribution of certain data and their real statistical distribution. In recommender systems, Chen et al. [17] also argues that biases in interactions may negatively affect the recommendation quality. In our review, we find that the literature has not deeply studied biases in impressions, has not proposed a characterization of them, and has not studied their effects on recommendations. Similarly, the literature has not studied debiasing techniques in impressions or by using impressions yet. Since impressions are generated through the same process that generated interactions: the recommender system, the user interface, and the choice made by the user, impressions present a strong connection with interactions but can also be seen as a complementary source of information. In this regard, the biases present in interactions and impressions Manuscript submitted to ACM are likely related, but not identical, and studying one may help to better understand the other. Broadly speaking, we highlight two directions for further studies. Concerning the study of existing biases, impressions may enable a more comprehensive study of biases due to the more granular classification of items: never impressed, impressed but not interacted with, and interacted with items. Additionally, the community can expand the current studies on biases in recommender systems to identify biases in impressions. One starting point comes from the very definition of impression: a selection of \ud835\udc41 items from the catalog created by a recommender system, search engine, or any other entity; thus, when the entity generating impressions is biased, then its generated impressions will be biased as well. Examples of new types of bias that can be studied are how the recommender system identifies recommended items that are not interacted with (i.e., that are non-relevant for the user) and how the contextual impressions change or bias the user assessment of what is relevant and, therefore, their interactions. Additionally, training a recommender using impressions may amplify or diminish the effects of biases during the feedback loop [17] that recommender systems go through. Lastly, the identification of biases in impressions may be challenging due to the incomplete information on the policies of the entities that generated them. Impressions may also enable the improvement or creation of new debiasing techniques for recommender systems. Inverse propensity weighting (IPW) is an example of a popular method to correct items' relevance by accounting for their probability of exposure, i.e., by computing the items' propensity score [90]. Generally, inverse propensity weighting (IPW) approaches are computed using interactions; which are an incomplete representation of the users' exposure to items in the catalog. The use of impressions can mitigate this problem since they are a more comprehensive description of users' exposure, in some cases, a complete one. It is still an open question whether using impressions for IPW (or other debiasing methods) results in effective unbiased estimators or unbiased evaluation of recommenders. In the case of creation of new debiasing techniques, two recent papers [118, 126] propose two distinct approaches to identify, model, and correct exposure biases in recommendations using impressions. Overall, only very few of the many biases described by Chen et al. [17] have been studied in the context of impressions. Consequently, using impressions for debiased evaluations still remains a wide and open research direction.", "6.5 Datasets with Impressions": "Unlike recommendation models, we do not identify open research questions after reviewing and analyzing existing datasets with impressions. However, we identify two research needs: one relates to the existing number of public datasets with contextual impressions, and the other relates to the lack of impression's origin in existing datasets. Publishing those types of datasets allows future works to propose more robust models and further analyze the impact and meaning of impressions on users' preferences. The first research need is the publication of public datasets with contextual impressions . In Section 2, we define contextual impressions as those where interacted and non-interacted impressions shown at a given time are recorded, i.e., researchers know the position of impressed items and whether users interacted with them or not. In Section 4, we classify datasets with impressions into three categories ( public , expired , and private datasets). There, we highlight the importance of public datasets due to their availability and flexible licensing, permitting researchers to use them in future research. Despite the existence of 13 public datasets, 10 of them contain global impressions, which have limited information when compared to their contextual counterparts. The second research need is the publication of datasets, including the origin of impressions . As we highlight in Section 5, one research goal is disentangling the signals within impressions. Under such a goal, existing or ad-hoc evaluation methodologies need labels indicating which system generated impressions. Those labels characterize whether a given Manuscript submitted to ACM impression comes from a recommender system, a search engine, editorial selections, or other systems. Without such labels, disentangling the signals is a more challenging task.", "6.6 Recommendation Quality of Impression-Aware Recommender Systems": "Throughout this work, we analyze three dimensions of IARS, namely recommendation models, datasets with impressions, and evaluation. Despite covering a broad selection of dimensions, it is still an open question what is the recommendation quality of the reviewed IARS both in the general case and in particular contexts. As we state at the beginning of Section 3, addressing this direction has its own challenges due to the numerous considerations to make in order to make a fair and representative assessment of the quality of reviewed recommendation models. Despite the inherent complexity of evaluating recommendation models, this is a topic of increased interest to the community, where research works explore many complementary dimensions. Zangerle and Bauer [115] in a recent survey describe an evaluation framework for general recommender systems, highlighting the different perspectives to consider. For instance, defining recommendation goals, selection of evaluation methods, selection of metrics, among others. Ca\u00f1amares et al. [15] provides a list of methodological decisions to make when evaluating recommenders when following an offline evaluation . Ferrari Dacrema et al. [29] found previous progress claims to be non-reproducible after carefully evaluating recommendation models under the same evaluation methodology. On a similar note, Shehzad and Jannach [91] found the hyper-parameter tuning of recommendation models is a necessary step to ensure a fair comparison of recommendation models. Regarding the evaluation of IARS, two of our previous works [78, 79] have partially addressed this direction. In those, we assess the recommendation quality IARS under a single recommendation task, training a subset of reviewed recommendation models (cycling [123], hard frequency capping [13], and impressions discounting framework [55]) on a selection of public datasets with impressions (ContentWise Impressions [80], MIND [107], and FINN.no Slates [27, 28]) under a single evaluation framework. Particularly, those studies study the recommendation quality of plug-in IARS when paired with an already-trained CF recommenders. 30 Despite those studies representing a start in this direction, they are far from representing an exhaustive assessment of the recommendation quality of IARS. Thus, it is still needed comprehensive studies on the recommendation quality of IARS on different scenarios and contexts.", "7 Conclusions": "Academic and industrial interest in impressions and their use in recommender systems have steadily increased over the years. Using impressions as a new data source increases the creation of a novel paradigm for personalized recommendations, termed impression-aware recommender systems (IARS). Recommender systems following this paradigm have the opportunity to model users' preferences more accurately than using interactions alone. For instance, a recommender may decide whether to recommend a particular item based on the number of impressions it has with a given user [13, 55]. Several initiatives raise the attention and sustain the use of impressions recommender systems: previous publications, public datasets, and competitions. To evaluate IARS, researchers and practitioners need access to datasets with impressions. Without public datasets, it is not possible to validate existing works nor compare the effectiveness of recommenders with impressions. In this work, we systematically review impressions in recommender systems under three perspectives (recommendation models, datasets, and evaluation methodologies). We term recommenders using impressions as impression-aware 30 See the definition of plug-in recommenders in Section 2. Manuscript submitted to ACM recommender systems (IARS) and define a theoretical framework enclosing them. Under such a framework, we highlight the similarities and differences between IARS and other recommendation paradigms. In such comparison, we find that although similar paradigms exist, IARS are part of a unique type of recommenders. This work describes a systematic literature review methodology to collect relevant papers in IARS. This methodology consists of discovering papers through academic search engines and selecting only those conference or journal papers published in high-level venues. Under this methodology, we discovered 1351 unique papers and selected 43 to review. During the work, we propose a classification system composed of three taxonomies for IARS, which we term model-centric, data-centric, and signal-centric. Such taxonomies group recommenders based on how they define their recommendation model, use impressions, and whether they assume or learn a connotation of impressions in users' preferences. From the review, we highlight several patterns. First, recommenders have been using more complex paradigms (machine learning, deep learning, and reinforcement learning) since 2016, while the last recommender using simpler paradigms (heuristics and statistics) is from 2017. Second, most recommenders either learn from impressions or compute features from impressions and then use such features; only a handful of papers in the literature sample from all impressions. Also, we note the literature does not contain recommenders using factorization machines or graph structures. Regarding datasets, we describe datasets with impressions and classify them based on their availability to be used in future research works. In this regard, only one category of datasets (termed public ) can be used for such purposes. The literature contains 13 public datasets, where 3 contain contextual impressions and the rest global impressions . The former indicates which impression contains a given interaction, while the latter does not contain such information. We highlight that global impressions are less informative than contextual ones. For example, it is not possible to adjust presentation and position biases in the data on global datasets, as this information is not present. When looking at datasets, we note that several papers evaluate their recommenders on private datasets; this is not favorable as such results are not possible to reproduce. Future research should use public datasets in their experiments. Moreover, future works may publish public datasets with contextual impressions with labels indicating whether impressions come from recommenders, editorial selections, or other systems. We present a discussion of current evaluation methodologies of IARS in reviewed papers. In such a discussion, we highlight the importance of sound evaluation methodologies to ensure real progress; we describe research goals with impressions using proper evaluation methodologies. We also discuss the challenges researchers must consider when evaluating recommenders using impressions, especially the effects of biases, scalability, data collection, and data dissemination. We identify new evaluation methodologies for future research thanks to impressions and the information they provide. In particular, we highlight that impressions permit researchers to validate modeling techniques for propensity scores, more effective debiasing techniques, and others. We close this work by noting several open questions and directions for future works. In particular, we emphasize the discussion in the three pillars of this work (recommenders, datasets, and evaluation). We detail papers in the reviewed literature that do not describe certain types of strong recommenders, such as graph-based or factorization machines. At the same time, we propose novel evaluation methodologies with impressions, accounting for the type of information provided with impressions, e.g., to debias evaluations by incorporating layout information on impressed items or measuring propensity scores using impressions. We close this work with future ideas on topics discussed in a few papers but of high relevance to recommender systems. For example, to model user fatigue due to repeated impressions or to model biases within recommender systems using impressions. Manuscript submitted to ACM", "References": "[1] Fabian Abel, Andr\u00e1s A. Bencz\u00far, Daniel Kohlsdorf, Martha A. Larson, and R\u00f3bert P\u00e1lovics. 2016. RecSys Challenge 2016: Job Recommendations. In Proceedings of the 10th ACM Conference on Recommender Systems, Boston, MA, USA, September 15-19, 2016 , Shilad Sen, Werner Geyer, Jill Freyne, and Pablo Castells (Eds.). ACM, 425-426. https://doi.org/10.1145/2959100.2959207 [2] Fabian Abel, Yashar Deldjoo, Mehdi Elahi, and Daniel Kohlsdorf. 2017. RecSys Challenge 2017: Offline and Online Evaluation. In Proceedings of the Eleventh ACM Conference on Recommender Systems, RecSys 2017, Como, Italy, August 27-31, 2017 , Paolo Cremonesi, Francesco Ricci, Shlomo Berkovsky, and Alexander Tuzhilin (Eds.). ACM, 372-373. https://doi.org/10.1145/3109859.3109954 [3] Gediminas Adomavicius, Konstantin Bauman, Alexander Tuzhilin, and Moshe Unger. 2022. Context-Aware Recommender Systems: From Foundations to Recent Developments. In Recommender Systems Handbook , Francesco Ricci, Lior Rokach, and Bracha Shapira (Eds.). Springer US, 211-250. https://doi.org/10.1007/978-1-0716-2197-4_6 [4] Mohammad Mehdi Afsar, Trafford Crump, and Behrouz H. Far. 2023. Reinforcement Learning based Recommender Systems: A Survey. ACM Comput. Surv. 55, 7 (2023), 145:1-145:38. https://doi.org/10.1145/3543846 [5] Deepak Agarwal, Bee-Chung Chen, and Pradheep Elango. 2009. Spatio-temporal models for estimating click-through rate. In Proceedings of the 18th International Conference on World Wide Web, WWW 2009, Madrid, Spain, April 20-24, 2009 . ACM, 21-30. https://doi.org/10.1145/1526709.1526713 [6] Deepak Agarwal, Bee-Chung Chen, Rupesh Gupta, Joshua Hartman, Qi He, Anand Iyer, Sumanth Kolar, Yiming Ma, Pannagadatta Shivaswamy, Ajit Singh, and Liang Zhang. 2014. Activity ranking in LinkedIn feed. In The 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '14, New York, NY, USA - August 24 - 27, 2014 , Sofus A. Macskassy, Claudia Perlich, Jure Leskovec, Wei Wang, and Rayid Ghani (Eds.). ACM, 1603-1612. https://doi.org/10.1145/2623330.2623362 [7] Michal Aharon, Natalie Aizenberg, Edward Bortnikov, Ronny Lempel, Roi Adadi, Tomer Benyamini, Liron Levin, Ran Roth, and Ohad Serfaty. 2013. OFF-set: one-pass factorization of feature sets for online recommendation in persistent cold start settings. In Seventh ACM Conference on Recommender Systems, RecSys '13, Hong Kong, China, October 12-16, 2013 , Qiang Yang, Irwin King, Qing Li, Pearl Pu, and George Karypis (Eds.). ACM, 375-378. https://doi.org/10.1145/2507157.2507221 [8] Michal Aharon, Yohay Kaplan, Rina Levy, Oren Somekh, Ayelet Blanc, Neetai Eshel, Avi Shahar, Assaf Singer, and Alex Zlotnik. 2019. Soft Frequency Capping for Improved Ad Click Prediction in Yahoo Gemini Native. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management, CIKM 2019, Beijing, China, November 3-7, 2019 , Wenwu Zhu, Dacheng Tao, Xueqi Cheng, Peng Cui, Elke A. Rundensteiner, David Carmel, Qi He, and Jeffrey Xu Yu (Eds.). ACM, 2793-2801. https://doi.org/10.1145/3357384.3357801 [9] Davide Azzalini, Fabio Azzalini, Chiara Criscuolo, Tommaso Dolci, Davide Martinenghi, and Sihem Amer-Yahia. 2022. SoCRATe: A Recommendation System with Limited-Availability Items. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management, Atlanta, GA, USA, October 17-21, 2022 , Mohammad Al Hasan and Li Xiong (Eds.). ACM, 4793-4797. https://doi.org/10.1145/3511808.3557208 Eduardo Barbaro, Eoin Martino Grua, Ivano Malavolta, Mirjana Stercevic, Esther Weusthof, and Jeroen van den Hoven. 2020. Modelling and [10] predicting User Engagement in mobile applications. Data Sci. 3, 2 (2020), 61-77. https://doi.org/10.3233/ds-190027 [11] Guillaume Bied, Solal Nathan, Elia Perennes, Morgane Hoffmann, Philippe Caillou, Bruno Cr\u00e9pon, Christophe Gaillac, and Mich\u00e8le Sebag. 2023. Toward Job Recommendation for All. In Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, IJCAI 2023, 19th-25th August 2023, Macao, SAR, China . ijcai.org, 5906-5914. https://doi.org/10.24963/IJCAI.2023/655 [12] Fedor Borisyuk, Liang Zhang, and Krishnaram Kenthapadi. 2017. LiJAR: A System for Job Application Redistribution towards Efficient Career Marketplace. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax, NS, Canada, August 13 - 17, 2017 . ACM, 1397-1406. https://doi.org/10.1145/3097983.3098028 [13] Niv Buchbinder, Moran Feldman, Arpita Ghosh, and Joseph Naor. 2014. Frequency capping in online advertising. J. Sched. 17, 4 (2014), 385-398. https://doi.org/10.1007/s10951-014-0367-z [14] Robin D. Burke. 2007. Hybrid Web Recommender Systems. In The Adaptive Web, Methods and Strategies of Web Personalization (Lecture Notes in Computer Science, Vol. 4321) , Peter Brusilovsky, Alfred Kobsa, and Wolfgang Nejdl (Eds.). Springer, 377-408. https://doi.org/10.1007/978-3-54072079-9_12 [15] Roc\u00edo Ca\u00f1amares, Pablo Castells, and Alistair Moffat. 2020. Offline evaluation options for recommender systems. Inf. Retr. J. 23, 4 (2020), 387-410. https://doi.org/10.1007/s10791-020-09371-3 [16] Jia-Wei Chang, Ming-Che Lee, and Tzone I. Wang. 2016. Integrating a semantic-based retrieval agent into case-based reasoning systems: A case study of an online bookstore. Comput. Ind. 78 (2016), 29-42. https://doi.org/10.1016/j.compind.2015.10.007 [17] Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan He. 2023. Bias and Debias in Recommender System: A Survey and Future Directions. ACM Trans. Inf. Syst. 41, 3 (2023), 67:1-67:39. https://doi.org/10.1145/3564284 [18] Minmin Chen, Alex Beutel, Paul Covington, Sagar Jain, Francois Belletti, and Ed H. Chi. 2019. Top-K Off-Policy Correction for a REINFORCE Recommender System. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, WSDM 2019, Melbourne, VIC, Australia, February 11-15, 2019 , J. Shane Culpepper, Alistair Moffat, Paul N. Bennett, and Kristina Lerman (Eds.). ACM, 456-464. https: //doi.org/10.1145/3289600.3290999 [19] Sirui Chen, Yuan Wang, Zijing Wen, Zhiyu Li, Changshuo Zhang, Xiao Zhang, Quan Lin, Cheng Zhu, and Jun Xu. 2023. Controllable Multi-Objective Re-ranking with Policy Hypernetworks. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2023, Long Beach, CA, USA, August 6-10, 2023 , Ambuj K. Singh, Yizhou Sun, Leman Akoglu, Dimitrios Gunopulos, Xifeng Yan, Ravi Kumar, Fatma Ozcan, Manuscript submitted to ACM and Jieping Ye (Eds.). ACM, 3855-3864. https://doi.org/10.1145/3580305.3599796 [20] Zhihong Chen, Jiawei Wu, Chenliang Li, Jingxu Chen, Rong Xiao, and Binqiang Zhao. 2022. Co-training Disentangled Domain Adaptation Network for Leveraging Popularity Bias in Recommenders. In SIGIR '22: The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, Madrid, Spain, July 11 - 15, 2022 , Enrique Amig\u00f3, Pablo Castells, Julio Gonzalo, Ben Carterette, J. Shane Culpepper, and Gabriella Kazai (Eds.). ACM, 60-69. https://doi.org/10.1145/3477495.3531952 [21] Fabian Christoffel, Bibek Paudel, Chris Newell, and Abraham Bernstein. 2015. Blockbusters and Wallflowers: Accurate, Diverse, and Scalable Recommendations with Random Walks. In Proceedings of the 9th ACM Conference on Recommender Systems, RecSys 2015, Vienna, Austria, September 1620, 2015 , Hannes Werthner, Markus Zanker, Jennifer Golbeck, and Giovanni Semeraro (Eds.). ACM, 163-170. https://doi.org/10.1145/2792838.2800180 [22] Wei Chu, Seung-Taek Park, Todd Beaupre, Nitin Motgi, Amit Phadke, Seinjuti Chakraborty, and Joe Zachariah. 2009. A case study of behavior-driven conjoint analysis on Yahoo!: front page today module. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Paris, France, June 28 - July 1, 2009 , John F. Elder IV, Fran\u00e7oise Fogelman-Souli\u00e9, Peter A. Flach, and Mohammed Javeed Zaki (Eds.). ACM, 1097-1104. https://doi.org/10.1145/1557019.1557138 [23] Colin Cooper, Sang-Hyuk Lee, Tomasz Radzik, and Yiannis Siantos. 2014. Random walks in recommender systems: exact computation and simulations. In 23rd International World Wide Web Conference, WWW '14, Seoul, Republic of Korea, April 7-11, 2014, Companion Volume , Chin-Wan Chung, Andrei Z. Broder, Kyuseok Shim, and Torsten Suel (Eds.). ACM, 811-816. https://doi.org/10.1145/2567948.2579244 [24] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations. In Proceedings of the 10th ACM Conference on Recommender Systems, Boston, MA, USA, September 15-19, 2016 , Shilad Sen, Werner Geyer, Jill Freyne, and Pablo Castells (Eds.). ACM, 191-198. https://doi.org/10.1145/2959100.2959190 [25] Romain Deffayet, Thibaut Thonet, Jean-Michel Renders, and Maarten de Rijke. 2023. Generative Slate Recommendation with Reinforcement Learning. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining, WSDM 2023, Singapore, 27 February 2023 - 3 March 2023 , Tat-Seng Chua, Hady W. Lauw, Luo Si, Evimaria Terzi, and Panayiotis Tsaparas (Eds.). ACM, 580-588. https://doi.org/10.1145/3539597.3570412 [26] A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum Likelihood from Incomplete Data via the EM Algorithm. Journal of the Royal Statistical Society. Series B (Methodological) 39, 1 (1977), 1-38. http://www.jstor.org/stable/2984875 [27] Simen Eide, David S. Leslie, and Arnoldo Frigessi. 2022. Dynamic slate recommendation with gated recurrent units and Thompson sampling. Data Min. Knowl. Discov. 36, 5 (2022), 1756-1786. https://doi.org/10.1007/s10618-022-00849-w [28] Simen Eide, David S. Leslie, Arnoldo Frigessi, Joakim Rishaug, Helge Jenssen, and Sofie Verrewaere. 2021. FINN.no Slates Dataset: A new Sequential Dataset Logging Interactions, all Viewed Items and Click Responses/No-Click for Recommender Systems Research. In RecSys '21: Fifteenth ACM Conference on Recommender Systems, Amsterdam, The Netherlands, 27 September 2021 - 1 October 2021 , Humberto Jes\u00fas Corona Pamp\u00edn, Martha A. Larson, Martijn C. Willemsen, Joseph A. Konstan, Julian J. McAuley, Jean Garcia-Gathright, Bouke Huurnink, and Even Oldridge (Eds.). ACM, 556-558. https://doi.org/10.1145/3460231.3474607 [29] Maurizio Ferrari Dacrema, Simone Boglio, Paolo Cremonesi, and Dietmar Jannach. 2021. A Troubling Analysis of Reproducibility and Progress in Recommender Systems Research. ACM Trans. Inf. Syst. 39, 2 (2021), 20:1-20:49. https://doi.org/10.1145/3434185 [30] Maurizio Ferrari Dacrema, Nicol\u00f2 Felicioni, and Paolo Cremonesi. 2022. Offline Evaluation of Recommender Systems in a User Interface With Multiple Carousels. Frontiers Big Data 5 (2022), 910030. https://doi.org/10.3389/fdata.2022.910030 [31] Yingqiang Ge, Xiaoting Zhao, Lucia Yu, Saurabh Paul, Diane Hu, Chu-Cheng Hsieh, and Yongfeng Zhang. 2022. Toward Pareto Efficient FairnessUtility Trade-off in Recommendation through Reinforcement Learning. In WSDM '22: The Fifteenth ACM International Conference on Web Search and Data Mining, Virtual Event / Tempe, AZ, USA, February 21 - 25, 2022 , K. Selcuk Candan, Huan Liu, Leman Akoglu, Xin Luna Dong, and Jiliang Tang (Eds.). ACM, 316-324. https://doi.org/10.1145/3488560.3498487 [32] Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna M. Wallach, Hal Daum\u00e9 III, and Kate Crawford. 2018. Datasheets for Datasets. CoRR abs/1803.09010 (2018). arXiv:1803.09010 http://arxiv.org/abs/1803.09010 [33] Claudio Gentile, Shuai Li, and Giovanni Zappella. 2014. Online Clustering of Bandits. In Proceedings of the 31th International Conference on Machine Learning, ICML 2014, Beijing, China, 21-26 June 2014 (JMLR Workshop and Conference Proceedings, Vol. 32) . JMLR.org, 757-765. http://proceedings.mlr.press/v32/gentile14.html [34] Zhabiz Gharibshah and Xingquan Zhu. 2022. User Response Prediction in Online Advertising. ACM Comput. Surv. 54, 3 (2022), 64:1-64:43. https://doi.org/10.1145/3446662 [35] Shansan Gong and Kenny Q. Zhu. 2022. Positive, Negative and Neutral: Modeling Implicit Feedback in Session-based News Recommendation. In SIGIR '22: The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, Madrid, Spain, July 11 - 15, 2022 , Enrique Amig\u00f3, Pablo Castells, Julio Gonzalo, Ben Carterette, J. Shane Culpepper, and Gabriella Kazai (Eds.). ACM, 1185-1195. https: //doi.org/10.1145/3477495.3532040 [36] Xudong Gong, Qinlin Feng, Yuan Zhang, Jiangling Qin, Weijie Ding, Biao Li, Peng Jiang, and Kun Gai. 2022. Real-time Short Video Recommendation on Mobile Devices. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management, Atlanta, GA, USA, October 17-21, 2022 , Mohammad Al Hasan and Li Xiong (Eds.). ACM, 3103-3112. https://doi.org/10.1145/3511808.3557065 [37] Thore Graepel, Joaquin Qui\u00f1onero Candela, Thomas Borchert, and Ralf Herbrich. 2010. Web-Scale Bayesian Click-Through rate Prediction for Sponsored Search Advertising in Microsoft's Bing Search Engine. In Proceedings of the 27th International Conference on Machine Learning (ICML-10), June 21-24, 2010, Haifa, Israel , Johannes F\u00fcrnkranz and Thorsten Joachims (Eds.). Omnipress, 13-20. https://icml.cc/Conferences/2010/papers/901.pdf Manuscript submitted to ACM [38] Ivo Grondman, Lucian Busoniu, Gabriel A. D. Lopes, and Robert Babuska. 2012. A Survey of Actor-Critic Reinforcement Learning: Standard and Natural Policy Gradients. IEEE Trans. Syst. Man Cybern. Part C 42, 6 (2012), 1291-1307. https://doi.org/10.1109/TSMCC.2012.2218595 [39] Alois Gruson, Praveen Chandar, Christophe Charbuillet, James McInerney, Samantha Hansen, Damien Tardieu, and Ben Carterette. 2019. Offline Evaluation to Make Decisions About Playlist Recommendation Algorithms. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, WSDM 2019, Melbourne, VIC, Australia, February 11-15, 2019 , J. Shane Culpepper, Alistair Moffat, Paul N. Bennett, and Kristina Lerman (Eds.). ACM, 420-428. https://doi.org/10.1145/3289600.3291027 [40] Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. 2018. Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor. In Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsm\u00e4ssan, Stockholm, Sweden, July 10-15, 2018 (Proceedings of Machine Learning Research, Vol. 80) , Jennifer G. Dy and Andreas Krause (Eds.). PMLR, 1856-1865. http://proceedings.mlr.press/v80/haarnoja18b.html [41] Geoffrey E. Hinton, Oriol Vinyals, and Jeffrey Dean. 2015. Distilling the Knowledge in a Neural Network. CoRR abs/1503.02531 (2015). arXiv:1503.02531 http://arxiv.org/abs/1503.02531 [42] Xiao Hu, Yuan Cheng, Zhi Zheng, Yue Wang, Xinxin Chi, and Hengshu Zhu. 2023. BOSS: A Bilateral Occupational-Suitability-Aware Recommender System for Online Recruitment. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2023, Long Beach, CA, USA, August 6-10, 2023 , Ambuj K. Singh, Yizhou Sun, Leman Akoglu, Dimitrios Gunopulos, Xifeng Yan, Ravi Kumar, Fatma Ozcan, and Jieping Ye (Eds.). ACM, 4146-4155. https://doi.org/10.1145/3580305.3599783 [43] Kirti Jain and Rajni Jindal. 2023. Sampling and noise filtering methods for recommender systems: A literature review. Eng. Appl. Artif. Intell. 122 (2023), 106129. https://doi.org/10.1016/J.ENGAPPAI.2023.106129 [44] Olivier Jeunen. 2019. Revisiting offline evaluation for implicit-feedback recommender systems. In Proceedings of the 13th ACM Conference on Recommender Systems, RecSys 2019, Copenhagen, Denmark, September 16-20, 2019 , Toine Bogers, Alan Said, Peter Brusilovsky, and Domonkos Tikk (Eds.). ACM, 596-600. https://doi.org/10.1145/3298689.3347069 [45] Kyung-Yong Jung, Dong-Hyun Park, and Jung-Hyun Lee. 2004. Hybrid Collaborative Filtering and Content-Based Filtering for Improved Recommender System. In Computational Science - ICCS 2004, 4th International Conference, Krak\u00f3w, Poland, June 6-9, 2004, Proceedings, Part I (Lecture Notes in Computer Science, Vol. 3036) , Marian Bubak, G. Dick van Albada, Peter M. A. Sloot, and Jack J. Dongarra (Eds.). Springer, 295-302. https://doi.org/10.1007/978-3-540-24685-5_37 [46] Michael N. Katehakis and Arthur F. Veinott Jr. 1987. The Multi-Armed Bandit Problem: Decomposition and Computation. Math. Oper. Res. 12, 2 (1987), 262-268. https://doi.org/10.1287/moor.12.2.262 [47] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. LightGBM: A Highly Efficient Gradient Boosting Decision Tree. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA , Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett (Eds.). 3146-3154. https://proceedings.neurips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html [48] Guolin Ke, Zhenhui Xu, Jia Zhang, Jiang Bian, and Tie-Yan Liu. 2019. DeepGBM: A Deep Learning Framework Distilled by GBDT for Online Prediction Tasks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD 2019, Anchorage, AK, USA, August 4-8, 2019 , Ankur Teredesai, Vipin Kumar, Ying Li, R\u00f3mer Rosales, Evimaria Terzi, and George Karypis (Eds.). ACM, 384-394. https://doi.org/10.1145/3292500.3330858 [49] Diederik P. Kingma and Max Welling. 2014. Auto-Encoding Variational Bayes. In 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings , Yoshua Bengio and Yann LeCun (Eds.). http://arxiv.org/abs/1312.6114 [50] Peter Knees, Yashar Deldjoo, Farshad Bakhshandegan Moghaddam, Jens Adamczak, Gerard Paul Leyson, and Philipp Monreal. 2019. RecSys challenge 2019: session-based hotel recommendations. In Proceedings of the 13th ACM Conference on Recommender Systems, RecSys 2019, Copenhagen, Denmark, September 16-20, 2019 , Toine Bogers, Alan Said, Peter Brusilovsky, and Domonkos Tikk (Eds.). ACM, 570-571. https://doi.org/10.1145/ 3298689.3346974 [51] Arnd Christian K\u00f6nig, Michael Gamon, and Qiang Wu. 2009. Click-through prediction for news queries. In Proceedings of the 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2009, Boston, MA, USA, July 19-23, 2009 , James Allan, Javed A. Aslam, Mark Sanderson, ChengXiang Zhai, and Justin Zobel (Eds.). ACM, 347-354. https://doi.org/10.1145/1571941.1572002 [52] Yehuda Koren, Steffen Rendle, and Robert M. Bell. 2022. Advances in Collaborative Filtering. In Recommender Systems Handbook , Francesco Ricci, Lior Rokach, and Bracha Shapira (Eds.). Springer US, 91-142. https://doi.org/10.1007/978-1-0716-2197-4_3 [53] S. Shunmuga Krishnan and Ramesh K. Sitaraman. 2013. Understanding the effectiveness of video ads: a measurement study. In Proceedings of the 2013 Internet Measurement Conference, IMC 2013, Barcelona, Spain, October 23-25, 2013 , Konstantina Papagiannaki, P. Krishna Gummadi, and Craig Partridge (Eds.). ACM, 149-162. https://doi.org/10.1145/2504730.2504748 [54] Thomas Laurent and James von Brecht. 2017. A recurrent neural network without chaos. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings . OpenReview.net. https://openreview.net/forum?id=S1dIzvclg [55] Pei Lee, Laks V. S. Lakshmanan, Mitul Tiwari, and Sam Shah. 2014. Modeling impression discounting in large-scale recommender systems. In The 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '14, New York, NY, USA - August 24 - 27, 2014 , Sofus A. Macskassy, Claudia Perlich, Jure Leskovec, Wei Wang, and Rayid Ghani (Eds.). ACM, 1837-1846. https://doi.org/10.1145/2623330.2623356 [56] Cheng Li, Yue Lu, Qiaozhu Mei, Dong Wang, and Sandeep Pandey. 2015. Click-through Prediction for Advertising in Twitter Timeline. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Sydney, NSW, Australia, August 10-13, 2015 , Manuscript submitted to ACM Longbing Cao, Chengqi Zhang, Thorsten Joachims, Geoffrey I. Webb, Dragos D. Margineantu, and Graham Williams (Eds.). ACM, 1959-1968. https://doi.org/10.1145/2783258.2788582 [57] Lihong Li, Wei Chu, John Langford, and Xuanhui Wang. 2011. Unbiased offline evaluation of contextual-bandit-based news article recommendation algorithms. In Proceedings of the Forth International Conference on Web Search and Web Data Mining, WSDM 2011, Hong Kong, China, February 9-12, 2011 , Irwin King, Wolfgang Nejdl, and Hang Li (Eds.). ACM, 297-306. https://doi.org/10.1145/1935826.1935878 [58] Pengyang Li, Rong Chen, Quan Liu, Jian Xu, and Bo Zheng. 2022. Transform Cold-Start Users into Warm via Fused Behaviors in Large-Scale Recommendation. In SIGIR '22: The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, Madrid, Spain, July 11 - 15, 2022 , Enrique Amig\u00f3, Pablo Castells, Julio Gonzalo, Ben Carterette, J. Shane Culpepper, and Gabriella Kazai (Eds.). ACM, 2013-2017. https://doi.org/10.1145/3477495.3531797 [59] Shuai Li, Alexandros Karatzoglou, and Claudio Gentile. 2016. Collaborative Filtering Bandits. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, SIGIR 2016, Pisa, Italy, July 17-21, 2016 , Raffaele Perego, Fabrizio Sebastiani, Javed A. Aslam, Ian Ruthven, and Justin Zobel (Eds.). ACM, 539-548. https://doi.org/10.1145/2911451.2911548 [60] Dawen Liang, Laurent Charlin, James McInerney, and David M. Blei. 2016. Modeling User Exposure in Recommendation. In Proceedings of the 25th , Jacqueline Bourdeau, Jim Hendler, Roger Nkambou, International Conference on World Wide Web, WWW 2016, Montreal, Canada, April 11 - 15, 2016 Ian Horrocks, and Ben Y. Zhao (Eds.). ACM, 951-961. https://doi.org/10.1145/2872427.2883090 [61] Xiao Lin, Xiaokai Chen, Linfeng Song, Jingwei Liu, Biao Li, and Peng Jiang. 2023. Tree based Progressive Regression Model for Watch-Time Prediction in Short-video Recommendation. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2023, Long Beach, CA, USA, August 6-10, 2023 , Ambuj K. Singh, Yizhou Sun, Leman Akoglu, Dimitrios Gunopulos, Xifeng Yan, Ravi Kumar, Fatma Ozcan, and Jieping Ye (Eds.). ACM, 4497-4506. https://doi.org/10.1145/3580305.3599919 [62] Bin Liu, Niannan Xue, Huifeng Guo, Ruiming Tang, Stefanos Zafeiriou, Xiuqiang He, and Zhenguo Li. 2020. AutoGroup: Automatic Feature Grouping for Modelling Explicit High-Order Feature Interactions in CTR Prediction. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event, China, July 25-30, 2020 , Jimmy X. Huang, Yi Chang, Xueqi Cheng, Jaap Kamps, Vanessa Murdock, Ji-Rong Wen, and Yiqun Liu (Eds.). ACM, 199-208. https://doi.org/10.1145/3397271.3401082 [63] David C. Liu, Stephanie Kaye Rogers, Raymond Shiau, Dmitry Kislyuk, Kevin C. Ma, Zhigang Zhong, Jenny Liu, and Yushi Jing. 2017. Related Pins at Pinterest: The Evolution of a Real-World Recommender System. In Proceedings of the 26th International Conference on World Wide Web Companion, Perth, Australia, April 3-7, 2017 , Rick Barrett, Rick Cummings, Eugene Agichtein, and Evgeniy Gabrilovich (Eds.). ACM, 583-592. https://doi.org/10.1145/3041021.3054202 [64] Babak Loni, Roberto Pagano, Martha A. Larson, and Alan Hanjalic. 2016. Bayesian Personalized Ranking with Multi-Channel User Feedback. In Proceedings of the 10th ACM Conference on Recommender Systems, Boston, MA, USA, September 15-19, 2016 , Shilad Sen, Werner Geyer, Jill Freyne, and Pablo Castells (Eds.). ACM, 361-364. https://doi.org/10.1145/2959100.2959163 [65] Wenjie Lu. 2023. Knowledge distillation-enhanced multitask framework for recommendation. Inf. Sci. 630 (2023), 235-251. https://doi.org/10.1016/ J.INS.2023.02.021 [66] Hao Ma, Xueqing Liu, and Zhihong Shen. 2016. User Fatigue in Online News Recommendation. In Proceedings of the 25th International Conference on World Wide Web, WWW 2016, Montreal, Canada, April 11 - 15, 2016 , Jacqueline Bourdeau, Jim Hendler, Roger Nkambou, Ian Horrocks, and Ben Y. Zhao (Eds.). ACM, 1363-1372. https://doi.org/10.1145/2872427.2874813 [67] Ning Ma, Mustafa Ispir, Yuan Li, Yongpeng Yang, Zhe Chen, Derek Zhiyuan Cheng, Lan Nie, and Kishor Barman. 2022. An Online Multi-task Learning Framework for Google Feed Ads Auction Models. In KDD '22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022 , Aidong Zhang and Huzefa Rangwala (Eds.). ACM, 3477-3485. https://doi.org/10.1145/3534678.3539055 [68] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun Gai. 2018. Entire Space Multi-Task Model: An Effective Approach for Estimating Post-Click Conversion Rate. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, SIGIR 2018, Ann Arbor, MI, USA, July 08-12, 2018 , Kevyn Collins-Thompson, Qiaozhu Mei, Brian D. Davison, Yiqun Liu, and Emine Yilmaz (Eds.). ACM, 1137-1140. https://doi.org/10.1145/3209978.3210104 [69] James McInerney, Benjamin Lacker, Samantha Hansen, Karl Higley, Hugues Bouchard, Alois Gruson, and Rishabh Mehrotra. 2018. Explore, exploit, and explain: personalizing explainable recommendations with bandits. In Proceedings of the 12th ACM Conference on Recommender Systems, RecSys 2018, Vancouver, BC, Canada, October 2-7, 2018 , Sole Pera, Michael D. Ekstrand, Xavier Amatriain, and John O'Donovan (Eds.). ACM, 31-39. https://doi.org/10.1145/3240323.3240354 [70] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre, Ilana Heintz, and Dan Roth. 2024. Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey. ACM Comput. Surv. 56, 2 (2024), 30:1-30:40. https://doi.org/10.1145/3605943 [71] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin A. Riedmiller. 2013. Playing Atari with Deep Reinforcement Learning. CoRR abs/1312.5602 (2013). arXiv:1312.5602 http://arxiv.org/abs/1312.5602 [72] Jose G. Moreno-Torres, Troy Raeder, Roc\u00edo Ala\u00edz-Rodr\u00edguez, Nitesh V. Chawla, and Francisco Herrera. 2012. A unifying view on dataset shift in classification. Pattern Recognit. 45, 1 (2012), 521-530. https://doi.org/10.1016/j.patcog.2011.06.019 [73] Ashutosh Nayak, Mayur Garg, and Rajasekhara Reddy Duvvuru Muni. 2023. News Popularity Beyond the Click-Through-Rate for Personalized Recommendations. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2023, Taipei, Taiwan, July 23-27, 2023 , Hsin-Hsi Chen, Wei-Jou (Edward) Duh, Hen-Hsen Huang, Makoto P. Kato, Josiane Mothe, and Barbara Poblete Manuscript submitted to ACM (Eds.). ACM, 1396-1405. https://doi.org/10.1145/3539618.3591741 [74] Xia Ning and George Karypis. 2012. Sparse linear methods with side information for top-n recommendations. In Sixth ACM Conference on Recommender Systems, RecSys '12, Dublin, Ireland, September 9-13, 2012 , Padraig Cunningham, Neil J. Hurley, Ido Guy, and Sarabjot Singh Anand (Eds.). ACM, 155-162. https://doi.org/10.1145/2365952.2365983 [75] Andrzej Pacuk, Piotr Sankowski, Karol Wegrzycki, Adam Witkowski, and Piotr Wygocki. 2016. RecSys Challenge 2016: job recommendations based on preselection of offers and gradient boosting. In Proceedings of the 2016 Recommender Systems Challenge, RecSys Challenge 2016, Boston, Massachusetts, USA, September 15, 2016 , Fabian Abel, Andr\u00e1s A. Bencz\u00far, Daniel Kohlsdorf, Martha A. Larson, and R\u00f3bert P\u00e1lovics (Eds.). ACM, 10:1-10:4. https://doi.org/10.1145/2987538.2987544 [76] Changhua Pei, Xinru Yang, Qing Cui, Xiao Lin, Fei Sun, Peng Jiang, Wenwu Ou, and Yongfeng Zhang. 2019. Value-aware Recommendation based on Reinforcement Profit Maximization. In The World Wide Web Conference, WWW 2019, San Francisco, CA, USA, May 13-17, 2019 , Ling Liu, Ryen W. White, Amin Mantrach, Fabrizio Silvestri, Julian J. McAuley, Ricardo Baeza-Yates, and Leila Zia (Eds.). ACM, 3123-3129. https: //doi.org/10.1145/3308558.3313404 [77] Fernando Benjam\u00edn P\u00e9rez Maurera, Maurizio Ferrari Dacrema, Pablo Castells, and Paolo Cremonesi. 2023. Incorporating Impressions to Graph-Based Recommenders. In Proceedings of the Workshop on Learning and Evaluating Recommendations with Impressions 2023, Singapore, September 19, 2023 (CEUR Workshop Proceedings, Vol. 3590) , Maurizio Ferrari Dacrema, Justin Basilico, Pablo Castells, Paolo Cremonesi, and Fernando Benjam\u00edn P\u00e9rez Maurera (Eds.). CEUR-WS.org. http://ceur-ws.org/Vol-3590/short5.pdf [78] Fernando Benjam\u00edn P\u00e9rez Maurera, Maurizio Ferrari Dacrema, and Paolo Cremonesi. 2022. Replication of Recommender Systems with Impressions. In Proceedings of the 12th Italian Information Retrieval Workshop 2022, Milan, Italy, June 29-30, 2022 (CEUR Workshop Proceedings, Vol. 3177) , Gabriella Pasi, Paolo Cremonesi, Salvatore Orlando, Markus Zanker, David Massimo, and Gloria Turati (Eds.). CEUR-WS.org. http://ceur-ws.org/Vol3177/paper20.pdf [79] Fernando Benjam\u00edn P\u00e9rez Maurera, Maurizio Ferrari Dacrema, and Paolo Cremonesi. 2022. Towards the Evaluation of Recommender Systems with Impressions. In RecSys '22: Sixteenth ACM Conference on Recommender Systems, Seattle, WA, USA, September 18 - 23, 2022 , Jennifer Golbeck, F. Maxwell Harper, Vanessa Murdock, Michael D. Ekstrand, Bracha Shapira, Justin Basilico, Keld T. Lundgaard, and Even Oldridge (Eds.). ACM, 610-615. https://doi.org/10.1145/3523227.3551483 [80] Fernando Benjam\u00edn P\u00e9rez Maurera, Maurizio Ferrari Dacrema, Lorenzo Saule, Mario Scriminaci, and Paolo Cremonesi. 2020. ContentWise Impressions: An Industrial Dataset with Impressions Included. In CIKM '20: The 29th ACM International Conference on Information and Knowledge Management, Virtual Event, Ireland, October 19-23, 2020 , Mathieu d'Aquin, Stefan Dietze, Claudia Hauff, Edward Curry, and Philippe Cudr\u00e9-Mauroux (Eds.). ACM, 3093-3100. https://doi.org/10.1145/3340531.3412774 [81] Joaquin Quionero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D. Lawrence. 2009. Dataset Shift in Machine Learning . The MIT Press. [82] Ghazala Rafiq, Muhammad Rafiq, and Gyu Sang Choi. 2023. Video description: A comprehensive survey of deep learning approaches. Artif. Intell. Rev. 56, 11 (2023), 13293-13372. https://doi.org/10.1007/S10462-023-10414-6 [83] Yi Ren, Xiao Han, Xu Zhao, Shenzheng Zhang, and Yan Zhang. 2023. Slate-Aware Ranking for Recommendation. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining, WSDM 2023, Singapore, 27 February 2023 - 3 March 2023 , Tat-Seng Chua, Hady W. Lauw, Luo Si, Evimaria Terzi, and Panayiotis Tsaparas (Eds.). ACM, 499-507. https://doi.org/10.1145/3539597.3570380 [84] Steffen Rendle. 2010. Factorization Machines. In ICDM 2010, The 10th IEEE International Conference on Data Mining, Sydney, Australia, 14-17 December 2010 , Geoffrey I. Webb, Bing Liu, Chengqi Zhang, Dimitrios Gunopulos, and Xindong Wu (Eds.). IEEE Computer Society, 995-1000. https://doi.org/10.1109/ICDM.2010.127 [85] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In UAI 2009, Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, Montreal, QC, Canada, June 18-21, 2009 , Jeff A. Bilmes and Andrew Y. Ng (Eds.). AUAI Press, 452-461. https://dslpitt.org/uai/displayArticleDetails.jsp?mmnu=1&smnu=2&article_id= 1630&proceeding_id=25 [86] Francesco Ricci, Lior Rokach, and Bracha Shapira. 2022. Recommender Systems: Techniques, Applications, and Challenges. In Recommender Systems Handbook , Francesco Ricci, Lior Rokach, and Bracha Shapira (Eds.). Springer US, 1-35. https://doi.org/10.1007/978-1-0716-2197-4_1 [87] Matthew Richardson, Ewa Dominowska, and Robert Ragno. 2007. Predicting clicks: estimating the click-through rate for new ads. In Proceedings of the 16th International Conference on World Wide Web, WWW 2007, Banff, Alberta, Canada, May 8-12, 2007 , Carey L. Williamson, Mary Ellen Zurko, Peter F. Patel-Schneider, and Prashant J. Shenoy (Eds.). ACM, 521-530. https://doi.org/10.1145/1242572.1242643 [88] Tim Salimans, Jonathan Ho, Xi Chen, and Ilya Sutskever. 2017. Evolution Strategies as a Scalable Alternative to Reinforcement Learning. CoRR abs/1703.03864 (2017). arXiv:1703.03864 http://arxiv.org/abs/1703.03864 [89] Masahiro Sato, Janmajay Singh, Sho Takemori, Takashi Sonoda, Qian Zhang, and Tomoko Ohkuma. 2019. Uplift-based evaluation and optimization of recommenders. In Proceedings of the 13th ACM Conference on Recommender Systems, RecSys 2019, Copenhagen, Denmark, September 16-20, 2019 , Toine Bogers, Alan Said, Peter Brusilovsky, and Domonkos Tikk (Eds.). ACM, 296-304. https://doi.org/10.1145/3298689.3347018 [90] Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and Thorsten Joachims. 2016. Recommendations as Treatments: Debiasing Learning and Evaluation. In Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016 (JMLR Workshop and Conference Proceedings, Vol. 48) , Maria-Florina Balcan and Kilian Q. Weinberger (Eds.). JMLR.org, 1670-1679. http://proceedings.mlr.press/v48/schnabel16.html Manuscript submitted to ACM [91] Faisal Shehzad and Dietmar Jannach. 2023. Everyone's a Winner! On Hyperparameter Tuning of Recommendation Models. In Proceedings of the 17th ACM Conference on Recommender Systems, RecSys 2023, Singapore, Singapore, September 18-22, 2023 , Jie Zhang, Li Chen, Shlomo Berkovsky, Min Zhang, Tommaso Di Noia, Justin Basilico, Luiz Pizzato, and Yang Song (Eds.). ACM, 652-657. https://doi.org/10.1145/3604915.3609488 [92] Qijie Shen, Hong Wen, Wanjie Tao, Jing Zhang, Fuyu Lv, Zulong Chen, and Zhao Li. 2022. Deep Interest Highlight Network for Click-Through Rate Prediction in Trigger-Induced Recommendation. In WWW'22: The ACM Web Conference 2022, Virtual Event, Lyon, France, April 25 - 29, 2022 , Fr\u00e9d\u00e9rique Laforest, Rapha\u00ebl Troncy, Elena Simperl, Deepak Agarwal, Aristides Gionis, Ivan Herman, and Lionel M\u00e9dini (Eds.). ACM, 422-430. https://doi.org/10.1145/3485447.3511970 [93] Ting-Yi Shih, Ting-Chang Hou, Jian-De Jiang, Yen-Chieh Lien, Chia-Rui Lin, and Pu-Jen Cheng. 2016. Dynamically Integrating Item Exposure with Rating Prediction in Collaborative Filtering. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, SIGIR 2016, Pisa, Italy, July 17-21, 2016 , Raffaele Perego, Fabrizio Sebastiani, Javed A. Aslam, Ian Ruthven, and Justin Zobel (Eds.). ACM, 813-816. https://doi.org/10.1145/2911451.2914769 [94] Sumit Sidana, Charlotte Laclau, and Massih-Reza Amini. 2018. Learning to recommend diverse items over implicit feedback on PANDOR. In Proceedings of the 12th ACM Conference on Recommender Systems, RecSys 2018, Vancouver, BC, Canada, October 2-7, 2018 , Sole Pera, Michael D. Ekstrand, Xavier Amatriain, and John O'Donovan (Eds.). ACM, 427-431. https://doi.org/10.1145/3240323.3240400 [95] N\u00edcollas Silva, Heitor Werneck, Thiago Silva, Adriano C. M. Pereira, and Leonardo Rocha. 2022. Multi-Armed Bandits in Recommendation Systems: A survey of the state-of-the-art and future directions. Expert Syst. Appl. 197 (2022), 116669. https://doi.org/10.1016/j.eswa.2022.116669 [96] Aixin Sun. 2023. Take a Fresh Look at Recommender Systems from an Evaluation Standpoint. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2023, Taipei, Taiwan, July 23-27, 2023 , Hsin-Hsi Chen, Wei-Jou (Edward) Duh, Hen-Hsen Huang, Makoto P. Kato, Josiane Mothe, and Barbara Poblete (Eds.). ACM, 2629-2638. https://doi.org/10.1145/3539618.3591931 [97] Norha M. Villegas, Cristian S\u00e1nchez, Javier D\u00edaz-Cely, and Gabriel Tamura. 2018. Characterizing context-aware recommender systems: A systematic literature review. Knowl. Based Syst. 140 (2018), 173-200. https://doi.org/10.1016/j.knosys.2017.11.003 [98] Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. 2015. Pointer Networks. In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada , Corinna Cortes, Neil D. Lawrence, Daniel D. Lee, Masashi Sugiyama, and Roman Garnett (Eds.). 2692-2700. https://proceedings.neurips.cc/paper/2015/hash/29921001f2f04bd3baee84a12e98098fAbstract.html [99] Dong Wang, Kav\u00e9 Salamatian, Yunqing Xia, Weiwei Deng, and Qi Zhang. 2023. BERT4CTR: An Efficient Framework to Combine Pre-trained Language Model with Non-textual Features for CTR Prediction. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2023, Long Beach, CA, USA, August 6-10, 2023 , Ambuj K. Singh, Yizhou Sun, Leman Akoglu, Dimitrios Gunopulos, Xifeng Yan, Ravi Kumar, Fatma Ozcan, and Jieping Ye (Eds.). ACM, 5039-5050. https://doi.org/10.1145/3580305.3599780 [100] Hao Wang, Tai-Wei Chang, Tianqiao Liu, Jianmin Huang, Zhichao Chen, Chao Yu, Ruopeng Li, and Wei Chu. 2022. ESCM2: Entire Space Counterfactual Multi-Task Model for Post-Click Conversion Rate Estimation. In SIGIR '22: The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, Madrid, Spain, July 11 - 15, 2022 , Enrique Amig\u00f3, Pablo Castells, Julio Gonzalo, Ben Carterette, J. Shane Culpepper, and Gabriella Kazai (Eds.). ACM, 363-372. https://doi.org/10.1145/3477495.3531972 [101] Haifeng Wang, Jiwei Li, Hua Wu, Eduard Hovy, and Yu Sun. 2023. Pre-Trained Language Models and Their Applications. Engineering 25 (2023), 51-65. https://doi.org/10.1016/j.eng.2022.04.024 [102] Jiayin Wang, Weizhi Ma, Jiayu Li, Hongyu Lu, Min Zhang, Biao Li, Yiqun Liu, Peng Jiang, and Shaoping Ma. 2022. Make Fairness More Fair: Fair Item Utility Estimation and Exposure Re-Distribution. In KDD '22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022 , Aidong Zhang and Huzefa Rangwala (Eds.). ACM, 1868-1877. https://doi.org/10.1145/3534678.3539354 [103] Kai Wang, Zhene Zou, Minghao Zhao, Qilin Deng, Yue Shang, Yile Liang, Runze Wu, Xudong Shen, Tangjie Lyu, and Changjie Fan. 2023. RL4RS: A Real-World Dataset for Reinforcement Learning based Recommender System. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2023, Taipei, Taiwan, July 23-27, 2023 , Hsin-Hsi Chen, Wei-Jou (Edward) Duh, Hen-Hsen Huang, Makoto P. Kato, Josiane Mothe, and Barbara Poblete (Eds.). ACM, 2935-2944. https://doi.org/10.1145/3539618.3591899 [104] Yifan Wang, Weizhi Ma, Min Zhang, Yiqun Liu, and Shaoping Ma. 2023. A Survey on the Fairness of Recommender Systems. ACM Trans. Inf. Syst. 41, 3 (2023), 52:1-52:43. https://doi.org/10.1145/3547333 [105] Ronald J. Williams. 1992. Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning. Mach. Learn. 8 (1992), 229-256. https://doi.org/10.1007/BF00992696 [106] Chao-Yuan Wu, Christopher V. Alvino, Alexander J. Smola, and Justin Basilico. 2016. Using Navigation to Improve Recommendations in Real-Time. In Proceedings of the 10th ACM Conference on Recommender Systems, Boston, MA, USA, September 15-19, 2016 , Shilad Sen, Werner Geyer, Jill Freyne, and Pablo Castells (Eds.). ACM, 341-348. https://doi.org/10.1145/2959100.2959174 [107] Fangzhao Wu, Ying Qiao, Jiun-Hung Chen, Chuhan Wu, Tao Qi, Jianxun Lian, Danyang Liu, Xing Xie, Jianfeng Gao, Winnie Wu, and Ming Zhou. 2020. MIND: A Large-scale Dataset for News Recommendation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020 , Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel R. Tetreault (Eds.). Association for Computational Linguistics, 3597-3606. https://doi.org/10.18653/v1/2020.acl-main.331 [108] Yunjia Xi, Jianghao Lin, Weiwen Liu, Xinyi Dai, Weinan Zhang, Rui Zhang, Ruiming Tang, and Yong Yu. 2023. A Bird's-eye View of Reranking: From List Level to Page Level. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining, WSDM 2023, Singapore, 27 February 2023 - 3 March 2023 , Tat-Seng Chua, Hady W. Lauw, Luo Si, Evimaria Terzi, and Panayiotis Tsaparas (Eds.). ACM, 1075-1083. Manuscript submitted to ACM", "https://doi.org/10.1145/3539597.3570399": "[109] Ruobing Xie, Shaoliang Zhang, Rui Wang, Feng Xia, and Leyu Lin. 2021. Explore, Filter and Distill: Distilled Reinforcement Learning in Recommendation. In CIKM '21: The 30th ACM International Conference on Information and Knowledge Management, Virtual Event, Queensland, Australia, November 1 - 5, 2021 , Gianluca Demartini, Guido Zuccon, J. Shane Culpepper, Zi Huang, and Hanghang Tong (Eds.). ACM, 4243-4252. https://doi.org/10.1145/3459637.3481917 [110] Ruobing Xie, Shaoliang Zhang, Rui Wang, Feng Xia, and Leyu Lin. 2022. A Peep into the Future: Adversarial Future Encoding in Recommendation. In WSDM '22: The Fifteenth ACM International Conference on Web Search and Data Mining, Virtual Event / Tempe, AZ, USA, February 21 - 25, 2022 , K. Selcuk Candan, Huan Liu, Leman Akoglu, Xin Luna Dong, and Jiliang Tang (Eds.). ACM, 1177-1185. https://doi.org/10.1145/3488560.3498476 [111] Xin Xin, Jiyuan Yang, Hanbing Wang, Jun Ma, Pengjie Ren, Hengliang Luo, Xinlei Shi, Zhumin Chen, and Zhaochun Ren. 2023. On the User Behavior Leakage from Recommender System Exposure. ACM Trans. Inf. Syst. 41, 3 (2023), 57:1-57:25. https://doi.org/10.1145/3568954 [112] Yanwu Yang and Panyu Zhai. 2022. Click-through rate prediction in online advertising: A literature review. Inf. Process. Manag. 59, 2 (2022), 102853. https://doi.org/10.1016/j.ipm.2021.102853 [113] Xinyang Yi, Ji Yang, Lichan Hong, Derek Zhiyuan Cheng, Lukasz Heldt, Aditee Kumthekar, Zhe Zhao, Li Wei, and Ed H. Chi. 2019. Samplingbias-corrected neural modeling for large corpus item recommendations. In Proceedings of the 13th ACM Conference on Recommender Systems, RecSys 2019, Copenhagen, Denmark, September 16-20, 2019 , Toine Bogers, Alan Said, Peter Brusilovsky, and Domonkos Tikk (Eds.). ACM, 269-277. https://doi.org/10.1145/3298689.3346996 [114] Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnab\u00e1s P\u00f3czos, Ruslan Salakhutdinov, and Alexander J. Smola. 2017. Deep Sets. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA , Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett (Eds.). 3391-3401. https://proceedings.neurips.cc/paper/2017/hash/f22e4747da1aa27e363d86d40ff442fe-Abstract.html [115] Eva Zangerle and Christine Bauer. 2023. Evaluating Recommender Systems: Survey and Framework. ACM Comput. Surv. 55, 8 (2023), 170:1-170:38. https://doi.org/10.1145/3556536 [116] Ruohan Zhan, Changhua Pei, Qiang Su, Jianfeng Wen, Xueliang Wang, Guanyu Mu, Dong Zheng, Peng Jiang, and Kun Gai. 2022. Deconfounding Duration Bias in Watch-time Prediction for Video Recommendation. In KDD '22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022 , Aidong Zhang and Huzefa Rangwala (Eds.). ACM, 4472-4481. https://doi.org/10.1145/ 3534678.3539092 [117] Junzi Zhang, Jongho Kim, Brendan O'Donoghue, and Stephen P. Boyd. 2021. Sample Efficient Reinforcement Learning with REINFORCE. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021 . AAAI Press, 10887-10895. https://ojs.aaai.org/index.php/AAAI/article/view/17300 [118] Qing Zhang, Xiaoying Zhang, Yang Liu, Hongning Wang, Min Gao, Jiheng Zhang, and Ruocheng Guo. 2023. Debiasing Recommendation by Learning Identifiable Latent Confounders. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2023, Long Beach, CA, USA, August 6-10, 2023 , Ambuj K. Singh, Yizhou Sun, Leman Akoglu, Dimitrios Gunopulos, Xifeng Yan, Ravi Kumar, Fatma Ozcan, and Jieping Ye (Eds.). ACM, 3353-3363. https://doi.org/10.1145/3580305.3599296 [119] Xikun Zhang, Deepak Ramachandran, Ian Tenney, Yanai Elazar, and Dan Roth. 2020. Do Language Embeddings capture Scales?. In Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, BlackboxNLP@EMNLP 2020, Online, November 2020 , Afra Alishahi, Yonatan Belinkov, Grzegorz Chrupala, Dieuwke Hupkes, Yuval Pinter, and Hassan Sajjad (Eds.). Association for Computational Linguistics, 292-299. https://doi.org/10.18653/V1/2020.BLACKBOXNLP-1.27 [120] XianXing Zhang, Yitong Zhou, Yiming Ma, Bee-Chung Chen, Liang Zhang, and Deepak Agarwal. 2016. GLMix: Generalized Linear Mixed Models For Large-Scale Response Prediction. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, August 13-17, 2016 , Balaji Krishnapuram, Mohak Shah, Alexander J. Smola, Charu C. Aggarwal, Dou Shen, and Rajeev Rastogi (Eds.). ACM, 363-372. https://doi.org/10.1145/2939672.2939684 [121] Yujing Zhang, Zhangming Chan, Shuhao Xu, Weijie Bian, Shuguang Han, Hongbo Deng, and Bo Zheng. 2022. KEEP: An Industrial Pre-Training Framework for Online Recommendation via Knowledge Extraction and Plugging. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management, Atlanta, GA, USA, October 17-21, 2022 , Mohammad Al Hasan and Li Xiong (Eds.). ACM, 3684-3693. https://doi.org/10.1145/3511808.3557106 [122] Feipeng Zhao, Min Xiao, and Yuhong Guo. 2016. Predictive Collaborative Filtering with Side Information. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016, New York, NY, USA, 9-15 July 2016 , Subbarao Kambhampati (Ed.). IJCAI/AAAI Press, 2385-2391. http://www.ijcai.org/Abstract/16/340 [123] Qian Zhao, Gediminas Adomavicius, F. Maxwell Harper, Martijn C. Willemsen, and Joseph A. Konstan. 2017. Toward Better Interactions in Recommender Systems: Cycling and Serpentining Approaches for Top-N Item Lists. In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing, CSCW 2017, Portland, OR, USA, February 25 - March 1, 2017 , Charlotte P. Lee, Steven E. Poltrock, Louise Barkhuus, Marcos Borges, and Wendy A. Kellogg (Eds.). ACM, 1444-1453. https://doi.org/10.1145/2998181.2998211 [124] Qian Zhao, Martijn C. Willemsen, Gediminas Adomavicius, F. Maxwell Harper, and Joseph A. Konstan. 2018. Interpreting user inaction in recommender systems. In Proceedings of the 12th ACM Conference on Recommender Systems, RecSys 2018, Vancouver, BC, Canada, October 2-7, 2018 , Sole Pera, Michael D. Ekstrand, Xavier Amatriain, and John O'Donovan (Eds.). ACM, 40-48. https://doi.org/10.1145/3240323.3240366 Manuscript submitted to ACM [125] Zhe Zhao, Lichan Hong, Li Wei, Jilin Chen, Aniruddh Nath, Shawn Andrews, Aditee Kumthekar, Maheswaran Sathiamoorthy, Xinyang Yi, and Ed H. Chi. 2019. Recommending what video to watch next: a multitask ranking system. In Proceedings of the 13th ACM Conference on Recommender Systems, RecSys 2019, Copenhagen, Denmark, September 16-20, 2019 , Toine Bogers, Alan Said, Peter Brusilovsky, and Domonkos Tikk (Eds.). ACM, 43-51. https://doi.org/10.1145/3298689.3346997 [126] Guanglin Zhou, Chengkai Huang, Xiaocong Chen, Xiwei Xu, Chen Wang, Liming Zhu, and Lina Yao. 2023. Contrastive Counterfactual Learning for Causality-aware Interpretable Recommender Systems. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management, CIKM 2023, Birmingham, United Kingdom, October 21-25, 2023 , Ingo Frommholz, Frank Hopfgartner, Mark Lee, Michael Oakes, Mounia Lalmas, Min Zhang, and Rodrygo L. T. Santos (Eds.). ACM, 3564-3573. https://doi.org/10.1145/3583780.3614823 [127] Chenxu Zhu, Peng Du, Weinan Zhang, Yong Yu, and Yang Cao. 2022. Combo-Fashion: Fashion Clothes Matching CTR Prediction with Item History. In KDD '22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022 , Aidong Zhang and Huzefa Rangwala (Eds.). ACM, 4621-4629. https://doi.org/10.1145/3534678.3539101 Received 05 February 2024; revised 08 August 2024; accepted 07 December 2024 Manuscript submitted to ACM"}
