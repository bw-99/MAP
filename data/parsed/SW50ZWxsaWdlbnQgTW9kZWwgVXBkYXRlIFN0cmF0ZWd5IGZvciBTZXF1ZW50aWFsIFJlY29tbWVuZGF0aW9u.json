{"Intelligent Model Update Strategy for Sequential Recommendation": "Zheqi Lv Zhejiang University Hangzhou, China zheqilv@zju.edu.cn Wenqiao Zhang Zhejiang University Hangzhou, China wenqiaozhang@zju.edu.cn Zhengyu Chen Zhejiang University Hangzhou, China chenzhengyu@zju.edu.cn Shengyu Zhang \u2217 Zhejiang University Hangzhou, China sy_zhang@zju.edu.cn", "ABSTRACT": "Modern online platforms are increasingly employing recommendation systems to address information overload and improve user engagement. There is an evolving paradigm in this research field that recommendation network learning occurs both on the cloud and on edges with knowledge transfer in between ( i.e. , edge-cloud collaboration). Recent works push this field further by enabling edge-specific context-aware adaptivity, where model parameters are updated in real-time based on incoming on-edge data. However, we argue that frequent data exchanges between the cloud and edges often lead to inefficiency and waste of communication/computation resources, as considerable parameter updates might be redundant. To investigate this problem, we introduce Intell igent E dgeC loud Parame t er Req uest Model ( IntellectReq ). IntellectReq is designed to operate on edge, evaluating the cost-benefit landscape of parameter requests with minimal computation and communication overhead. We formulate this as a novel learning task, aimed at the detection of out-of-distribution data, thereby fine-tuning adaptive communication strategies. Further, we employ statistical mapping techniques to convert real-time user behavior into a normal distribution, thereby employing multi-sample outputs to quantify the model's uncertainty and thus its generalization capabilities. Rigorous empirical validation on three widely-adopted benchmarks evaluates our approach, evidencing a marked improvement in the efficiency and generalizability of edge-cloud collaborative and dynamic recommendation systems.", "CCS CONCEPTS": "\u00b7 Information systems \u2192 Mobile information processing systems ; Personalization ; \u00b7 Human-centered computing \u2192 Mobile computing . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WWW'24, May 13-17, 2024, Singapore, Singapore \u00a9 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0171-9/24/05...$15.00 https://doi.org/10.1145/3589334.3645316", "Kun Kuang \u2217": "Zhejiang University Hangzhou, China kunkuang@zju.edu.cn", "KEYWORDS": "Edge-Cloud Collaboration, Distribution Shift, Mis-Recommendation Detection, Out-of-Domain Detection, Sequential Recommendation", "ACMReference Format:": "Zheqi Lv, Wenqiao Zhang, Zhengyu Chen, Shengyu Zhang, and Kun Kuang. 2024. Intelligent Model Update Strategy for Sequential Recommendation. In Proceedings of the ACM Web Conference 2024 (WWW '24), May 13-17, 2024, Singapore, Singapore. ACM, New York, NY, USA, 12 pages. https://doi.org/ 10.1145/3589334.3645316", "1 INTRODUCTION": "With the rapid development of e-commerce and social media platforms, recommendation systems [11, 17, 28, 56, 62] have become indispensable tools in people's daily life. They can be recognized as various forms depending on industries, like product suggestions on online e-commerce websites, ( e.g. , Amazon and Taobao) or playlist generators for video and music services ( e.g. , YouTube, Netflix, and Spotify). Among them, one of the classical recommendation systems in the industry prefers to trains a universal model with static parameters on a powerful cloud conditioned on rich data collected from different edges, and then perform edge inference for all users, such as e.g. , DIN [63], SASRec [17], and GRU4Rec [11]. In the first model presented in Figure 1, this cloud-based static model allows users to share a centralized model, enabling real-time inference across all edges. However, it does not take advantage of the personalized recommendation patterns specific to each edge due to the shift in data distribution between the cloud and edge. As we all know, the shift in the distribution of test data compared to training data will reduce the performance of the model [5, 6, 44, 54, 55, 58-61, 64, 65]. To address this issue, existing solutions can be broadly classified into two categories: (i) On-Edge Learning : It improve personalization by on-edge learning with the second method depicted in Figure 1(a), based on the on-edge static model. Techniques such as distillation [37] and fine-tuning [2] can mitigate the discrepancy between edge and cloud distributions through re-training at the edge. However, retraining at the edge involves a significant amount of computation, particularly in backpropagation. The sudden drop in real-time performance also reduces its practicality. (ii) Edge-Cloud Collaboration [51, 52]: It leverages the edge-cloud collaboration to efficiently update the parameters of the edge-model according to on-edge real-time data distribution [30, 50]. Recent advancements Recommendation System Development On-Edge Static Model On-Edge Leaning Edge-Cloud Learning IntellectReq Model Personalization Low Device Learning Cost Low Communication Cost \u2717 \u2713 \u2713 \u2713 a b t 1 t 2 t 3 Current Distribution \u2206\ud835\udc46 Previous Distribution IntellectReq Real-time Sequence Controller Distribution Shift Cloud Parameters Generation Dynamic Model Methods Characteristics \u2713 \u2717 \u2713 \u2713 \u2713 \u2717 \u2713 \u2713 Our Method c Method Comparison Global Data Edge Cloud Static Model Dynamic Model Edge Cloud Parameters Generation Real-time Sequence On-Edge Static Model On-Edge Learning Edge-Cloud Learning t 1 t 2 t 3 Dynamic Model No Distribution Shift or Previous On-Edge Dynamic Model On-Edge Static Model Communication Frequency HR@20 0 25 50 75 100 E C-CDR IntellectReq 0.850 0.855 0.860 0 25 50 75 100 E C-CDR IntellectReq 0. 64 0 0. 64 5 0. 65 0 Communication Frequency AUC Real-time Sequence t 1 t 2 t 3 Real-time Retraining Send Send Send \u21d1 \u21d1 \u21d1 have introduced a technique known as adaptive parameter generation [30, 50] (shown as the third method in Figure 1(a)), which facilitating model personalization without additional on-edge computational cost. This method specifically utilizes a pre-trained hypernetwork [10] to convert the user's real-time click sequence into adaptive parameters through forward propagation. These parameters then be updated to the edge model, allowing it to better fit real-time data distribution for swift personalization of recommendations. This method, termed the E dgeC loud C ollaborative and D ynamic R ecommendation ( EC-CDR ), offers tailored recommendation models across various on-edge distribution. found that users typically engage with only 10 to 15 domains. This repeated behavior indicates a failure of EC-CDR to recognize shifts in data distribution on the edge, resulting in frequent dynamic parameter requests and high communication overhead. EC-CDR faces deployment challenges in real-world settings due to two key issues: (i) High Request Frequency. Updating ECCDR model parameters through edge-cloud communication after a user clicks a new item causes a surge in concurrent cloud requests from multiple edges in industrial settings. This problem worsens in unstable networks, limiting EC-CDR's efficiency due to communication and network constraints. (ii) Low Communication Revenue. When the latest real-time data is the same as, or closely related to, the distribution used previously to update model parameters, communication from edge to cloud is unnecessary. That is, the moment of distribution shift does not always coincide with the timing of model updates at the edge. Unnecessary communication between cloud and edge can lead to low efficiency in communication resource utilization. 0 10 20 30 40 50 Domain Number 0.00 0.05 0.10 0.15 0.20 Proportion of Users CDs Electronic Book To address EC-CDR's communication issues, we analyzed users' click classes (viewed as domains) on the edge. As shown in Figure 2, by collecting item embedding vectors from user clicks across three datasets and classifying them into 50 domains, we Based on the insights discussed earlier, our primary optimization goal is to minimize unnecessary communications, aiming for a highly efficient EC-CDR system. To achieve this, we design IntellectReq for deployment on the edge, tasked with assessing the necessity of requests with minimal resource usage. This strategy significantly boosts efficient communication in EC-CDR. IntellectReq is operationalized through the development of the MisRecommendation Detector (MRD) and Distribution Mapper (DM). The MRD is engineered to predict the likelihood of edge recommendation models making incorrect recommendations, termed as Mis-Recommendations. It accomplishes this by learning to map current data and previous data which is used to update the last model to mis-recommendation labels. Moreover, MRD translates these predictions into the potential revenue from updating the edge model, thus maximizing revenue within any communication budget and ensuring the model's optimal performance. The DM is designed to allow the model to detect potential shifts in data distribution and assess the model's uncertainty in interpreting real-time data, which in turn, augments the capabilities of the MRD module. It comprises three components: a prior network, a posterior network, and a next-item prediction network, with the last serving as DM's backbone. During the training phase, data features are extracted through both prior and posterior networks, using label-provided prior information to enhance training efficiency. In the inference stage, the posterior network is utilized for feature extraction. By evaluating the model's uncertainty in processing real-time data-achieved by mapping this data to a normal distribution-DM significantly improves MRD's prediction accuracy. The conventional recommendation datasets prove inadequate for these tasks. Therefore, we have restructured these datasets into a new MRD dataset, eliminating the need for extra annotations. This restructuring process provides essential supervisory data for training our MRD and DM models, ensuring their effectiveness in the EC-CDR system. To summarize, our contributions are four-fold: \u00b7 We are the first to point out and introduce IntellectReq to address the issues of high communication frequency and low communication revenue in EC-CDR, a method that improves edge recommendation models to SOTA performance and achieve personalized updates without retraining. \u00b7 We designed IntellectReq and developed both a MisRecommendation Detector (MRD) and a Distribution Mapper (DM) to instantiate IntellectReq. IntellectReq can quantify changes in the data distribution on the edge, and based on the actual communication budget or cloud computing budget, it can determine which edge models need to be updated. \u00b7 We construct Mis-Recommendation datasets from existing recommendation datasets, as current datasets are not suitable for training IntellectReq, thereby enabling its training without requiring additional manual annotations. \u00b7 We evaluate our method with extensive experiments. Experiments demonstrate that IntellectReq can achieve high revenue under any edge-cloud communication budget.", "2 RELATED WORK": "Edge-cloud Collaboration. Deep learning applications are widely used [24-26, 35, 42, 45, 47, 48], but they are fundamentally resourceintensive and difficult to deploy on the edge [3, 7, 8, 12-14, 2123, 41], so edge-cloud collaboration [34, 53] is playing an increasingly important role. Cloud-based and on-edge machine learning are two distinct approaches with different benefits and drawbacks. Edge-cloud collaboration can take advantage of them and make them complement one another. Federated learning, such as FedAVG [32], is one of the most well-known forms of edge-cloud collaboration. Federated learning is also often used for various tasks such as multi-task learning [31, 33], etc. But the federated learning method for edge-cloud collaboration is too rigid for many real-world scenarios. [52] designs multiple models with the same functions but different training processes, and a Meta Controller is used to determine which model should be used. EC-CDR, such as DUET [30], draw inspiration from the HyperNetwork concept, ensuring that models on the edge can generalize well to the current data distribution at every moment without the need for any training on the edge. However, high request frequency and low communication revenue significantly reduce their practicality. This paper focuses on addressing these shortcomings of EC-CDR. Sequential Recommendation. Sequential recommendation models the user's historical behavior sequence. Previous sequential recommendation algorithm such as [36] and [18] are non-deep learning based and uses Markov decision chains to model behavioral sequences. To improve the performance of the model, recent works [4, 9, 11, 15-17, 19, 20, 27-29, 38-40, 46, 49, 56, 57, 63] propose the sequential recommendation model based on deep learning. Among them, the most well-known sequence recommendation models are as follows: GRU4Rec [11] uses GRU to model behavior sequences and achieves excellent performance. DIN [63] and SASRec [17] algorithms, respectively, introduce attention and transformer into sequential recommendation, which is fast and efficient. These methods are relatively influential in both academia and industry. In practical settings, deploying recommendation models at the edge faces constraints due to limited parameters and complexity, alongside the need for real-time operation which hampers realtime model updates using conventional methods. This impacts the model's generalization capability across different data distributions. This paper explores methods to lower communication costs for a more efficient EC-CDR paradigm.", "3 METHODOLOGY": "We describe the proposed IntellectReq in this section by presenting each module and introduce the learning strategy of IntellectReq.", "3.1 Problem Formulation": "In EC-CDR, we have access to a set of edges D = { \ud835\udc51 ( \ud835\udc56 ) } N \ud835\udc51 \ud835\udc56 = 1 , where each edge with its personal i.i.d history samples S \ud835\udc3b ( \ud835\udc56 ) = { \ud835\udc65 ( \ud835\udc57,\ud835\udc61 ) \ud835\udc3b ( \ud835\udc56 ) = { \ud835\udc62 ( \ud835\udc57 ) \ud835\udc3b ( \ud835\udc56 ) , \ud835\udc63 ( \ud835\udc57 ) \ud835\udc3b ( \ud835\udc56 ) , \ud835\udc60 ( \ud835\udc57,\ud835\udc61 ) \ud835\udc3b ( \ud835\udc56 ) } , \ud835\udc66 ( \ud835\udc57 ) \ud835\udc3b ( \ud835\udc56 ) } N \ud835\udc3b ( \ud835\udc56 ) \ud835\udc57 = 1 and real-time samples S \ud835\udc45 ( \ud835\udc56 ) = { \ud835\udc65 ( \ud835\udc57,\ud835\udc61 ) \ud835\udc45 ( \ud835\udc56 ) = { \ud835\udc62 ( \ud835\udc57 ) \ud835\udc45 ( \ud835\udc56 ) , \ud835\udc63 ( \ud835\udc57 ) \ud835\udc45 ( \ud835\udc56 ) , \ud835\udc60 ( \ud835\udc57,\ud835\udc61 ) \ud835\udc45 ( \ud835\udc56 ) }} N \ud835\udc45 ( \ud835\udc56 ) \ud835\udc57 = 1 in the current session, where N \ud835\udc51 , N \ud835\udc3b ( \ud835\udc56 ) and N \ud835\udc45 ( \ud835\udc56 ) represent the number of edges, history data, and real-time data, respectively. \ud835\udc62 , \ud835\udc63 and \ud835\udc60 represent user, item and click sequence composed of items. It should be noted that \ud835\udc60 ( \ud835\udc57,\ud835\udc61 ) represents the click sequence at moment \ud835\udc61 in the \ud835\udc57 -th sample.The goal of EC-CDR is to generalize a trained global cloud model M \ud835\udc54 (\u00b7 ; \u0398 \ud835\udc54 ) learned from {S \ud835\udc3b ( \ud835\udc56 ) } N \ud835\udc51 \ud835\udc56 = 1 to each specific local edge model M \ud835\udc51 ( \ud835\udc56 ) (\u00b7 ; \u0398 \ud835\udc51 ( \ud835\udc56 ) ) conditioned on real-time samples S \ud835\udc45 ( \ud835\udc56 ) , where \u0398 \ud835\udc54 and \u0398 \ud835\udc51 ( \ud835\udc56 ) respectively denote the learned parameters for the global cloud model and local edge model. To determine whether to request parameters from the cloud, IntellectReq uses S MRD to learn a Mis-Recommendation Detector, which decides whether to update the edge model by the EC-CDR framework. S MRD is the dataset constructed based on S \ud835\udc3b without any additional annotations for training IntellectReq. \u0398 MRD denotes the learned parameters for the local MRD model.", "3.2 IntellectReq": "Figure 3 is the overview of Recommendation model, EC-CDR, and IntellectReq framework which consists of Mis-Recommendation Detector (MRD) and Distribution Mapper (DM) to achieve high revenue under any requested budget. We first introduce the EC-CDR, and then present IntellectReq, which we propose to overcome the frequent and low-revenue drawbacks of EC-CDR requests. IntellectReq achieves high communication revenue under any edge-cloud communication budget in EC-CDR. MRD can determine whether to request parameters from the cloud model M \ud835\udc54 or to use the edge recommendation model M \ud835\udc51 based on real-time data S \ud835\udc45 ( \ud835\udc56 ) . DMhelps MRD make further judgments by discriminating the uncertainty in the recommendation model's understanding of data semantics. (b) EC-CDR (a) Recommendation Model (c) Mis-Recommendation Detector (d) Distribution Mapper \ud835\udc67 ! \ud835\udc37 ! \ud835\udc67 ! Others \ud835\udc37 ! \ud835\udf07 ! \ud835\udf0e ! Distribution Mapper Sampling Label Prediction Ground-Truth Mis-Rec \u2713 \u2717 \u2713 \u2717 \u2717 Click Prediction \u2717 \u2717 Click Prediction \u2717 Click Prediction \u2717 Click Prediction \u2717 \u2717 Mis-Rec Prediction \u2713 \u2717 Repeat \ud835\udc5b times. \u2717 Uncertainty \ud835\udc62 ! \ud835\udec0 \ud835\udc83 \ud835\udec0 \ud835\udc83 \ud835\udec0 \ud835\udc83 \ud835\udec0 \ud835\udc83 \ud835\udc52 ! \ud835\udc52 ! \ud835\udc52 ! \ud835\udc52 ! ' \ud835\udec0 \ud835\udc84 ' \ud835\udec0 \ud835\udc84 ' \ud835\udec0 \ud835\udc84 \ud835\udec0 \ud835\udc84 \ud835\udc60 ! \ud835\udc60 # Parameters Generation \u0398 $%& \ud835\udc60 ! \ud835\udc60 ! \ud835\udc60 ! Uncertainty \ud835\udc62 ! Parameters Generation Parameters Generation \ud835\udc60 # where \ud835\udc37 \ud835\udc50\ud835\udc52 (\u00b7 ; \u0398 \ud835\udc4f \ud835\udc54 ) denotes the cross-entropy between two probability distributions, \ud835\udc53 rec (\u00b7) denotes the dynamic layers of the recommendation model, \u03a9 ( \ud835\udc65 ( \ud835\udc57 ) \ud835\udc3b ( \ud835\udc56 ) ; \u0398 \ud835\udc4f \ud835\udc54 ) is the static layers extracting features from \ud835\udc65 ( \ud835\udc57 ) \ud835\udc3b ( \ud835\udc56 ) . EC-CDR is decoupled edge-model with a 'static layers' and 'dynamic layers' training scheme to achieve better personalization. The primary factor enhancing the on-edge model's generalization to real-time data through EC-CDR is its dynamic layers. Upon completion of training, the static layers' parameters remain static, denoted as \u0398 \ud835\udc4f \ud835\udc54 , as determined by Eq. 3. Conversely, the dynamic layers' parameters, represented by \u0398 \ud835\udc50 \ud835\udc54 , are dynamically generated based on real-time data by the cloud generator. In edge inference , the cloud-based parameter generator uses the real-time click sequence \ud835\udc60 ( \ud835\udc57,\ud835\udc61 ) \ud835\udc45 ( \ud835\udc56 ) \u2208 S \ud835\udc45 ( \ud835\udc56 ) to generate the parameters, where \ud835\udc38 share (\u00b7) represents the shared encoder. \ud835\udc3f ( \ud835\udc5b ) layer (\u00b7) is a linear layer used to adjust \ud835\udc86 ( \ud835\udc57,\ud835\udc61 ) \ud835\udc45 ( \ud835\udc56 ) which is the output of \ud835\udc38 share (\u00b7) to the \ud835\udc5b \ud835\udc61\u210e dynamic layer features. \ud835\udc86 ( \ud835\udc57,\ud835\udc61 ) \ud835\udc45 ( \ud835\udc56 ) means embedding vector generated by the click sequence at the moment \ud835\udc61 . The cloud generator model treats the parameters of a fullyconnected layer as a matrix \ud835\udc3e ( \ud835\udc5b ) \u2208 R \ud835\udc41 \ud835\udc56\ud835\udc5b \u00d7 \ud835\udc41 \ud835\udc5c\ud835\udc62\ud835\udc61 , where \ud835\udc41 \ud835\udc56\ud835\udc5b and \ud835\udc41 \ud835\udc5c\ud835\udc62\ud835\udc61 represent the number of input neurons and output neurons of the \ud835\udc5b \ud835\udc61\u210e fully-connected layers, respectively. Then the cloud generator model \ud835\udc54 (\u00b7) converts the real-time click sequence \ud835\udc60 ( \ud835\udc57,\ud835\udc61 ) \ud835\udc45 ( \ud835\udc56 ) into dynamic layers parameters \u02c6 \u0398 \ud835\udc50 \ud835\udc54 by \ud835\udc3e ( \ud835\udc5b ) \ud835\udc45 ( \ud835\udc56 ) = \ud835\udc54 ( \ud835\udc5b ) ( \ud835\udc86 ( \ud835\udc5b ) \ud835\udc45 ( \ud835\udc56 ) ) . Since the following content no longer needs the superscript ( \ud835\udc5b ) , we simplify \ud835\udc54 (\u00b7) to \ud835\udc54 (\u00b7) = \ud835\udc3f ( \ud835\udc5b ) layer ( \ud835\udc38 shared (\u00b7)) . Then, the edge recommendation model updates the parameters and makes inference as follows, In cloud training , all layers of the cloud generator model are optimized together with the static layers of the primary model that are conditioned on the global history data S \ud835\udc3b ( \ud835\udc56 ) = { \ud835\udc65 ( \ud835\udc57 ) \ud835\udc3b ( \ud835\udc56 ) , \ud835\udc66 ( \ud835\udc57 ) \ud835\udc3b ( \ud835\udc56 ) } N \ud835\udc3b ( \ud835\udc56 ) \ud835\udc57 = 1 , instead of optimizing the static layers of the primary model first and then optimizing the cloud generator model. The cloud generator model loss function is defined as follows: EC-CDR could improve the generalization ability of the edge recommendation model. However, EC-CDR could not be easily deployed in a real-world environment due to the high request frequency and low communication revenue. Under the EC-CDR framework, the moment \ud835\udc61 in Eq. 5 is equal to the current moment \ud835\udc47 , which means that the edge and the cloud communicate at every moment. In fact, however, a lot of communication is unnecessary because \u02c6 \u0398 \ud835\udc50 \ud835\udc54 generated by the sequence earlier may work well enough. To alleviate this issue, we propose MRD and DM to solve the problem when the edge recommendation model should update parameters. 3.2.2 Mis-Recommendation Detector. The training procedure of MRD can be divided into two stages. The goal of the first stage is to construct a MRD dataset S \ud835\udc36 based on the user's historical data without any additional annotation to train the MRD. The cloud model M \ud835\udc54 and the edge model M \ud835\udc51 are trained in the same way as the training procedure of EC-CDR. Here, we set \ud835\udc61 \u2032 \u2264 \ud835\udc61 = \ud835\udc47 . That is, when generating model parameters, we use the click sequence \ud835\udc60 ( \ud835\udc57,\ud835\udc61 \u2032 ) \ud835\udc45 ( \ud835\udc56 ) at the previous moment \ud835\udc61 \u2032 , but this model is used to predict the current data. Then we can get \ud835\udc50 ( \ud835\udc57,\ud835\udc61,\ud835\udc61 \u2032 ) that means whether the sample be correctly predicted based on the (c) Next-item Prediction Network \ud835\udc67 ! \ud835\udcab \ud835\udc9b (#,%) Others \ud835\udcab \ud835\udf07 !\"#$\" (&,() \ud835\udf0e !\"#$\" (&,() Prior Distribution (b) Prior Network (c) Posterior Network \ud835\udcac \ud835\udc9b (#,%) Others \ud835\udcac \ud835\udf07 !\"#$\" (&,() \ud835\udf0e !\"#$\" (&,() Posterior Distribution KL-divergence \ud835\udc67 ! (a) Recommendation Network \ud835\udc86 (#,%) \u0398 '()* \u0398 '+,(+ \ud835\udc86 (#,%) \ud835\udc60 (#,%) \ud835\udec0 Backbone Classifier Parameters Generation ) \ud835\udc93 #,% \ud835\udc93 (#,%) \ud835\udc66 (#,%) ) \ud835\udc66 #,% BCELoss Training Procedure Inference Procedure \ud835\udc86 (#,%) \ud835\udc67 (#,%) ) \ud835\udc93 #,% Repeat \ud835\udc5b times. \ud835\udc67 #,% \u2208 \ud835\udc67 - #,% , \ud835\udc67 . #,% , \u2026 , \ud835\udc67 / #,% Prediction \ud835\udc93 (#,%) \ud835\udc67 (#,%) \ud835\udc86 (#,%) ) \ud835\udc93 #,% Ground-Truth Uncertainty \ud835\udc62 (#,%) (d) Next-item Prediction Network \ud835\udc67 #,% Sampling \ud835\udc67 #,% Sampling \ud835\udc86 #,% \u2295\ud835\udc93 #,% prediction \u02c6 \ud835\udc66 ( \ud835\udc57,\ud835\udc61,\ud835\udc61 \u2032 ) \ud835\udc45 ( \ud835\udc56 ) and the ground-truth \ud835\udc66 ( \ud835\udc57,\ud835\udc61 ) \ud835\udc45 ( \ud835\udc56 ) . Then we construct the new mis-recommendation training dataset as follows: S ( \ud835\udc56 ) MRD = { \ud835\udc60 ( \ud835\udc57,\ud835\udc61 ) , \ud835\udc60 ( \ud835\udc57,\ud835\udc61 \u2032 ) , \ud835\udc50 ( \ud835\udc57,\ud835\udc61,\ud835\udc61 \u2032 ) } 0 \u2264 \ud835\udc61 \u2032 \u2264 \ud835\udc61 = \ud835\udc47 . Then, a dynamic layers \ud835\udc53 MRD (\u00b7) can be trained on S ( \ud835\udc56 ) MRD according to the Eq. 9, where \ud835\udc61 = \ud835\udc47 and the loss function \ud835\udc59 (\u00b7) is cross entropy. 3.2.3 Distribution Mapper. Although the MRD could determine when to update edge parameters, it is insufficient to simply map a click sequence to a certain representation in a high-dimensional space due to ubiquitous noises in click sequences. So we design the DMas Figure 4 make it possible to directly perceive the data distribution shift and determine the uncertainty in the recommendation model's understanding of the semantics of the data. Inspired by Conditional-VAE, we map click sequences to normal distributions. Different from the MRD, the DM module consider a variable \ud835\udc62 ( \ud835\udc57,\ud835\udc61 ) to denote the uncertainty in Eq. 9 as: The uncertainty variable \ud835\udc62 ( \ud835\udc57,\ud835\udc61 ) shows the recommendation model's understanding of the semantics of the data. DM focuses on how to learn such uncertainty variable \ud835\udc62 ( \ud835\udc57,\ud835\udc61 ) . Distribution Mapper consists of three components as shown in the figure in Appendix, namely the Prior Network \ud835\udc43 (\u00b7) (PRN), the Posterior Network \ud835\udc44 (\u00b7) (PON), and the Next-item Prediction Network \ud835\udc53 (\u00b7) (NPN) that includes the static layers \u03a9 (\u00b7) and dynamic layers \ud835\udc53 NPN (\u00b7) . Note that \u03a9 (\u00b7) here is the same as \u03a9 (\u00b7) in section 3.2.1 and 3.2.2, so there is almost no additional resource consumption. We will first introduce the three components separately, and then introduce the training procedure and inference procedure. Prior Network. The Prior Network with weights \u0398 prior and \u0398 \u2032 prior maps the representation of a click sequence \ud835\udc60 ( \ud835\udc57,\ud835\udc61 ) to a prior probability distribution. We set this prior probability distribution as a Posterior Network. The Posterior Network \u03a9 post with weights \u0398 post and \u0398 \u2032 post can enhance the training of the Prior Network by introducing posterior information. It maps the representation concatenated by the representation of the next-item \ud835\udc5f ( \ud835\udc57,\ud835\udc61 ) and of the click sequence \ud835\udc60 ( \ud835\udc57,\ud835\udc61 ) to a normal distribution. we define the posterior probability distribution as a normal distribution with mean \ud835\udf07 ( \ud835\udc57,\ud835\udc61 ) post = \u03a9 post ( \ud835\udc60 ( \ud835\udc57,\ud835\udc61 ) ; \u0398 post ) \u2208 R \ud835\udc41 and variance \ud835\udf0e ( \ud835\udc57,\ud835\udc61 ) post = \u03a9 \u2032 post ( \ud835\udc60 ( \ud835\udc57,\ud835\udc61 ) ; \u0398 \u2032 post ) \u2208 R \ud835\udc41 . Next-item Prediction Network. The Next-item Prediction Network with weights \u0398 \ud835\udc50 predicts the embedding of the next item \u02c6 \ud835\udc5f ( \ud835\udc57,\ud835\udc61 ) to be clicked based on the user's click sequence \ud835\udc60 ( \ud835\udc57,\ud835\udc61 ) as follows, Training Procedure. In the training procedure, two losses need to be constructed, one is recommendation prediction loss L \ud835\udc5f\ud835\udc52\ud835\udc50 and the other is distribution difference loss L \ud835\udc51\ud835\udc56\ud835\udc60\ud835\udc61 . Like the way that most recommendation models are trained, L \ud835\udc5f\ud835\udc52\ud835\udc50 uses the binary cross-entropy loss function \ud835\udc59 (\u00b7) to penalize the difference between \u02c6 \ud835\udc66 ( \ud835\udc57,\ud835\udc61 ) and \ud835\udc66 ( \ud835\udc57,\ud835\udc61 ) . The difference is that here NPN uses the feature \ud835\udc67 sampled from the prior distribution \ud835\udc44 to replace \ud835\udc52 in formula 5 In addition, L \ud835\udc51\ud835\udc56\ud835\udc60\ud835\udc61 penalizes the difference between the posterior distribution \ud835\udc44 and the prior distribution \ud835\udc43 with the help of the Kullback-Leibler divergence. L \ud835\udc51\ud835\udc56\ud835\udc60\ud835\udc61 \"pulls\" the posterior and prior distributions towards each other. The formulas for L \ud835\udc5f\ud835\udc52\ud835\udc50 and L \ud835\udc51\ud835\udc56\ud835\udc60\ud835\udc61 are as follows, Finally, we optimize DM according to, During training, the weights are randomly initialized. Inference Procedure . In the inference procedure, the posterior network will be removed from DM because there is no posterior information during the inference procedure. Uncertainty variable \ud835\udc62 ( \ud835\udc57,\ud835\udc61 ) is calculated by the multi-sampling outputs as follows: where \ud835\udc5b denotes the sampling times. Specifically, we consider the dimension of \u02c6 \ud835\udc5f ( \ud835\udc57,\ud835\udc61 ) is \ud835\udc41 \u00d7 1, \u02c6 \ud835\udc5f ( \ud835\udc57,\ud835\udc61 ) , ( \ud835\udc58 ) \ud835\udc56 as the \ud835\udc58 -th value of the \u02c6 \ud835\udc5f ( \ud835\udc57,\ud835\udc61 ) \ud835\udc56 vector, and calculate the variance as follows: 3.2.4 On-edge Model Update. M isR ecommendation S core (MRS) is a variable calculated based on the output of MRD and DM, which directly affects whether the model needs to be updated. In the equation above, 1 (\u00b7) is the indicator function. To get the threshold, we need to collect user data for a period of time, then get the MRS values corresponding to these data on the cloud and sort them, and then set the threshold according to the load of the cloud server. For example, if the load of the cloud server needs to be reduced by 90%, that is, when the load is only 10% of the previous value, only the minimum 10% position value needs to be sent to each edge as the threshold. During inference, each edge determines whether it needs to update the edge model based on equation 19 and 20, that is, whether it needs to request new parameters.", "4 EXPERIMENTS": "We conducted extensive experiments to evaluate the effectiveness and generalizability of the proposed IntellectReq. We put part of the experimental setup, results and analysis in the Appendix.", "4.1 Experimental Setup.": "Datasets. We evaluate on Amazon CDs (CDs) , Amazon Electronic (Electronic) , Douban Book (Book) , three widely used public benchmarks in the recommendation tasks. Evaluation Metrics In the experiments, we use the widely adopted AUC 1 , UAUC 1 , HitRate and NDCG as the metrics. Baselines. To verify the applicability, the following representative sequential modeling approaches are implemented and compared with the counterparts combined with the proposed method. DUET [30] and APG [50] are SOTA of EC-CDR, which generate parameters through the edge-cloud collaboration for different tasks. With the cloud generator model, the on-edge model could generalize well to the current data distribution in each session without training on the edge. GRU4Rec [11], DIN [63], and SASRec [17] are three of the most widely used sequential recommendation methods in the academia and industry, which respectively introduce GRU, Attention, and Self-Attention into the recommendation system. LOF [1] and OC-SVM [43] estimate the density of a given point via the ratio of the local reachability of its neighbors and itself. They can be used to detect changes in the distribution of click sequences. For the IntellectReq, we consider SASRec as edge-model unless otherwise stated, but note that IntellectReq broadly applies to lots of sequential recommendation model such as DIN, GRU4Rec, etc. Evaluation Metrics. We use the widely adopted AUC, HitRate, and NDCG as the metrics to evaluate model performance.", "4.2 Experimental Results.": "4.2.1 Quantitative Results. Figure 5, 6, and 7 summarize the quantitative results of our framework and other methods on CDs and Electronic datasets. The experiments are based on state-of-the-art EC-CDR frameworks such as DUET and APG. As shown in Figure 5-6, we combine the parameter generation framework with three sequential recommendation models, DIN, GRU4Rec, SASRec. We evaluate these methods with AUC and UAUC metrics on CDs and Book datasets. We have the following findings: (1) If all edgemodel updated at \ud835\udc61 -1 moment, the DUET framework (DUET) and the APG framework (APG) can be viewed as the upper bound of performance for all methods since DUET and APG are evaluated with fixed 100% request frequency and other methods are evaluated with increasing frequency. If all edge-model are the same as the cloud pretrained model, IntellectReq can even beat DUET, which indicates that in EC-CDR, not all edges need to be updated at every moment. In fact, model parameters generated by user data at some moments can be detrimental to performance. Note that directly comparing the other methods with DUET and APG is not fair as DUET and APG use the fixed 100% request frequency, which could not be deployed in lower request frequency. (2) The random request method (DUET (Random), APG (Random)) works well with any request budget. However, it does not give the optimal request scheme for any request budget in most cases (such as Row.1). The correlation between its performance and Request Frequency tends to be linear. The performances of random request methods are unstable and unpredictable, where these methods outperform other methods in a few cases. (3) LOF (DUET (LOF), APG (LOF)) and OC-SVM (DUET (OC-SVM), APG (OC-SVM)) are two methods that could be used as simple baselines to make the optimal request scheme under a special and specific request budget. However, they have two weaknesses. One is that they consume a lot of resources and thus significantly reduce the calculation speed. The other is they can only work under a specific request budget instead of an arbitrary request budget. For example, in the first line, the Request Frequency of OC-SVM can only be (4) In most cases, our IntellectReq can make the optimal request scheme under any request budget. 4.2.2 Mis-recommendation score and profit. To further study the effectiveness of MDR, we visualize the request timing and revenue in Figure 8. As shown in Figure 8, we analyze the relationship between request and revenue. Every 100 users were assigned to one of 15 groups, which were selected at random. The Figure is divided into three parts, with the first part used to assess the request and the second and third parts used to assess the benefit. The metric used here is Mis-Recommendation Score (MRS) to evaluate the request revenue. MRS is a metric to measure whether a recommendation will be made in error. In other words, it can be viewed as an evaluation of the model's generalization ability. The probabilities of a IntellectReq Baseline (LOF) Baseline (OC-SVM) Baseline (Random) DUET DIN GRU4Rec SASRec APG DIN GRU4Rec SASRec Request frequency compared to DUET Request frequency compared to DUET Request frequency compared to DUET % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % Request frequency compared to DUET Request frequency compared to DUET Request frequency compared to DUET Request frequency compared to APG Request frequency compared to APG Request frequency compared to APG Request frequency compared to APG Request frequency compared to APG Request frequency compared to APG IntellectReq Baseline (LOF) Baseline (OC-SVM) Baseline (Random) Baseline=DUET DIN GRU4Rec SASRec Baseline = APG DIN GRU4Rec SASRec Request frequency compared to DUET Request frequency compared to DUET Request frequency compared to DUET % % % % % % % % % % % % % % % % % % Request frequency compared to APG Request frequency compared to APG Request frequency compared to APG % % % % % % % % % % % % % % % % % % mis-recommendation and requesting model parameters are higher and the score is lower. \u00b7 IntellectReq predicts the MRS based on the uncertainty and the click sequences at the moment \ud835\udc61 and \ud835\udc61 -1. \u00b7 DUET (Random) randomly selects edges to request the cloud model to update the parameters of the edges. At this point, MRS can be considered as an arbitrary constant. We take the average value of IntellectReq's MRS as the MRS value. \u00b7 DUET (w. Request) represents all edge-model be updated at the moment \ud835\udc61 . GRU4Rec SASRec Dataset =Electronic 0 20 40 60 80 100 Request Frequency HR@20 DUET (OC-SVM) DUET (LOF) IntellectReq DUET 0.66 0 0.65 0 0.66 5 0.6 55 0.6 45 0 20 40 60 80 100 Request Frequency HR@20 DUET (OC-SVM) DUET (LOF) IntellectReq DUET 0.68 0.69 0.67 0. 70 0. 71 0. 72 0. 73 0. 74 0. 75 0 20 40 60 80 100 Request Frequency HR@20 DUET (OC-SVM) DUET (LOF) IntellectReq DUET 0.70 0.71 0.72 0.73 0 20 40 60 80 100 Request Frequency HR@20 DUET (OC-SVM) DUET (LOF) IntellectReq DUET 0.65 0.64 0.63 0.66 0.6 2 GRU4Rec SASRec Dataset =CDs (a) CDs (b) Electronic MRS AUC AUC MRS AUC AUC IntellectReq Request Revenue DUET (w. Request) DUET (w/o Request) DUET (Random) 10 11 12 13 14 15 Group Number Group Number \u00b7 DUET (w/o. Request) represents no edge-model be updated at moment \ud835\udc61 -1 in Figure 5 and 6, represents no edge-model be updated at moment 0 in Figure 7. \u00b7 Request Revenue represents the revenue, that is, DUET (w. Request) curve minus DUET (w/o Request). From Figure 8, we have the following observations: (1) The trends of MRS and DUET Revenue are typically in the opposite direction, which means that when the MRS value is low, IntellectReq tends to believe that the edge's model cannot generalize well to the current data distribution. Then, the IntellectReq uses the most recent realtime data to request model parameters. As a result, the revenue at this time is frequently positive and relatively high. When the MRS value is high, IntellectReq tends to continue using the model that was updated at the previous moment \ud835\udc61 -1 instead of \ud835\udc61 because it believes that the model on the edge can generalize well to the current data distribution. The revenue is frequently low and negative if the model parameters are requested at this point. (2) Since the MRS of DUET (Random) is constant, it cannot predict the revenue of each request. The performance curve changes randomly because of the irregular arrangement order of groups. IntellectReq IntellectReq (w/o DM) IntellectReq (w/o MRD) DUET CDs Electronic % % % % % % % % % % % % % % % % % % % % % % % % Update ratio compared to DUET Update ratio compared to DUET Update ratio compared to DUET Update ratio compared to DUET 4.2.3 Ablation Study. We conducted an ablation study to show the effectiveness of different components in IntellectReq. The results are shown in Figure 9. We use w/o. and w. to denote without and with, respectively. From the table, we have the following findings: \u00b7 IntellectReq means both DM and MRD are used. \u00b7 (w/o. DM) means MRD is used but DM is not used. \u00b7 (w/o. MRD) means DM is used but MRD is not used. From the figure and table, we have the following observations: (1) Generally, IntellectReq achieves the best performance with different evaluation metrics in most cases, demonstrating the effectiveness of IntellectReq. (2) When the request frequency is small, the difference between IntellectReq and IntellectReq ( w/o. DM)is not immediately apparent, as shown in Fig. 9(d). The difference becomes more noticeable when the Request Frequency increases within a certain range. In brief, the difference exhibits the traits of first getting smaller, then larger, and finally smaller. 4.2.4 Time and Space Cost. Most edges have limited storage space, so the on-edge model must be small and sufficient. The edge's computing power is rather limited, and the completion of the recommendation task on the edge requires lots of real-time processing, so the model deployed on the edge must be both simple and fast. Therefore, we analyze whether these methods are controllable and highly profitable based on the DUET framework, and additional time and space resource consumption under this framework is shown in Table 1. In the time consumption column, signal '/' separates the time consumption of cloud preprocessing and edge inference. Cloud preprocessing means that the cloud server first calculates the MRS value based on recent user data and then determines the threshold based on the communication budget of the cloud server and sends it to the edge. Edge inference refers to the MRS calculated when the click sequence on the edge is updated. The experimental results show that: 1) In terms of time consumption, both cloud preprocessing and edge inference are the fastest for random requests, followed by our IntellectReq. LOF and OC-SVM are the slowest. 2) In terms of space consumption, random, LOF, and OC-SVM can all be regarded as requiring no additional space consumption. In contrast, our method requires the additional deployment of 5.06k parameters on the edge. 3) Random and our IntellectReq can be realized in terms of controllability. It means that edge-cloud communication can be realized under the condition of an arbitrary communication budget, while LOF and OC-SVM cannot. 4) In terms of high yield, LOF, OC-SVM, and our IntellectReq can all be achieved, but random requests cannot. In general, our IntellectReq only requires minimal time consumption (does not affect real-time performance) and space consumption (easy to deploy for smart edges) and can take into account controllability and high profitability.", "5 CONCLUSION": "In our paper, we argue that under the EC-CDR framework, most communications requesting new parameters for the cloud-based recommendation system are unnecessary due to stable on-edge data distributions. We introduced IntellectReq, a low-resource solution for calculating request value and ensuring adaptive, high-revenue edge-cloud communication. IntellectReq employs a novel edge intelligence task to identify out-of-domain data and uses real-time user behavior mapping to a normal distribution, alongside multisampling outputs, to assess the edge model's adaptability to user actions. Our extensive tests across three public benchmarks confirm IntellectReq's efficiency and broad applicability, promoting a more effective edge-cloud collaborative recommendation approach.", "ACKNOWLEDGMENT": "This work was supported by National Key R&D Program of China (No. 2022ZD0119100), Scientific Research Fund of Zhejiang Provincial Education Department (Y202353679), National Natural Science Foundation of China (No. 62376243, 62037001, U20A20387), the StarryNight Science Fund of Zhejiang University Shanghai Institute for Advanced Study (SN-ZJU-SIAS-0010), Project by Shanghai AI Laboratory (P22KS00111) and Program of Zhejiang Province Science and Technology (2022C01044)", "REFERENCES": "[1] Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and J\u00f6rg Sander. 2000. LOF: identifying density-based local outliers. In Proceedings of the 2000 ACM SIGMOD international conference on Management of data. 93-104. [2] Han Cai, Chuang Gan, Ligeng Zhu, and Song Han. 2020. Tinytl: Reduce activations, not trainable parameters for efficient on-device learning. (2020). [3] Defu Cao, Yixiang Zheng, Parisa Hassanzadeh, Simran Lamba, Xiaomo Liu, and Yan Liu. 2023. Large Scale Financial Time Series Forecasting with Multifaceted Model. In Proceedings of the Fourth ACM International Conference on AI in Finance (<conf-loc>, <city>Brooklyn</city>, <state>NY</state>, <country>USA</country>, </conf-loc>) (ICAIF '23). Association for Computing Machinery, New York, NY, USA, 472-480. https://doi.org/10.1145/3604237.3626868 [4] Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song, Depeng Jin, and Yong Li. 2021. Sequential recommendation with graph neural networks. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 378-387. [5] Zhengyu Chen and Donglin Wang. 2021. Multi-Initialization Meta-Learning with Domain Adaptation. In ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 1390-1394. [6] Zhengyu Chen, Teng Xiao, and Kun Kuang. 2022. BA-GNN: On Learning BiasAware Graph Neural Network. In 2022 IEEE 38th International Conference on Data Engineering (ICDE). IEEE, 3012-3024. [7] Zhengyu Chen, Teng Xiao, Kun Kuang, Zheqi Lv, Min Zhang, Jinluan Yang, Chengqiang Lu, Hongxia Yang, and Fei Wu. 2023. Learning to Reweight for Graph Neural Network. arXiv preprint arXiv:2312.12475 (2023). [8] Zhengyu Chen, Teng Xiao, Kun Kuang, Zheqi Lv, Min Zhang, Jinluan Yang, Chengqiang Lu, Hongxia Yang, and Fei Wu. 2024. Learning to Reweight for Generalizable Graph Neural Network. Proceedings of the AAAI conference on artificial intelligence (2024). [9] Zhengyu Chen, Ziqing Xu, and Donglin Wang. 2021. Deep transfer tensor decomposition with orthogonal constraint for recommender systems. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 4010-4018. [10] David Ha, Andrew Dai, and Quoc V Le. 2017. Hypernetworks. (2017). [11] Bal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based recommendations with recurrent neural networks. International Conference on Learning Representations 2016 (2016). [12] Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang Yin, and Zhou Zhao. 2023. Make-an-audio: Textto-audio generation with prompt-enhanced diffusion models. arXiv preprint arXiv:2301.12661 (2023). [13] Rongjie Huang, Max W. Y. Lam, Jun Wang, Dan Su, Dong Yu, Yi Ren, and Zhou Zhao. 2022. FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis. In IJCAI. ijcai.org, 4157-4163. [14] Rongjie Huang, Yi Ren, Jinglin Liu, Chenye Cui, and Zhou Zhao. 2022. Generspeech: Towards style transfer for generalizable out-of-domain text-to-speech. Advances in Neural Information Processing Systems 35 (2022), 10970-10983. [15] Wei Ji, Renjie Liang, Lizi Liao, Hao Fei, and Fuli Feng. 2023. Partial Annotationbased Video Moment Retrieval via Iterative Learning. In Proceedings of the 31th ACM international conference on Multimedia. [16] Wei Ji, Xiangyan Liu, An Zhang, Yinwei Wei, and Xiang Wang. 2023. Online Distillation-enhanced Multi-modal Transformer for Sequential Recommendation. In Proceedings of the 31th ACM international conference on Multimedia. [17] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 197-206. [18] Sara Latifi, Noemi Mauro, and Dietmar Jannach. 2021. Session-aware recommendation: A surprising quest for the state-of-the-art. Information Sciences 573 (2021), 291-315. [19] Haoxuan Li, Yanghao Xiao, Chunyuan Zheng, Peng Wu, and Peng Cui. 2023. Propensity matters: Measuring and enhancing balancing for recommendation. In International Conference on Machine Learning. PMLR, 20182-20194. [20] Haoxuan Li, Yanghao Xiao, Chunyuan Zheng, Peng Wu, Zhi Geng, Xu Chen, and Peng Cui. 2024. Debiased Collaborative Filtering with Kernel-based Causal Balancing. In International Conference on Learning Representations. [21] Juncheng Li, Xin He, Longhui Wei, Long Qian, Linchao Zhu, Lingxi Xie, Yueting Zhuang, Qi Tian, and Siliang Tang. 2022. Fine-grained semantically aligned visionlanguage pre-training. Advances in neural information processing systems 35 (2022), 7290-7303. [22] Juncheng Li, Kaihang Pan, Zhiqi Ge, Minghe Gao, Hanwang Zhang, Wei Ji, Wenqiao Zhang, Tat-Seng Chua, Siliang Tang, and Yueting Zhuang. 2023. Finetuning Multimodal LLMs to Follow Zero-shot Demonstrative Instructions. arXiv preprint arXiv:2308.04152 (2023). [23] Li Li, Chenwei Wang, You Qin, Wei Ji, and Renjie Liang. 2023. BiasedPredicate Annotation Identification via Unbiased Visual Predicate Representation. In Proceedings of the 31st ACM International Conference on Multimedia (<conf-loc>, <city>Ottawa ON</city>, <country>Canada</country>, </confloc>) (MM '23). Association for Computing Machinery, New York, NY, USA, [44] Yunze Tong, Junkun Yuan, Min Zhang, Didi Zhu, Keli Zhang, Fei Wu, and Kun Kuang. 2023. Quantitatively Measuring and Contrastively Exploring Heterogeneity for Domain Generalization. In KDD. ACM, 2189-2200. [45] Xiao Wang, Peng Cui, Jing Wang, Jian Pei, Wenwu Zhu, and Shiqiang Yang. 2017. Community preserving network embedding. In Proceedings of the AAAI conference on artificial intelligence, Vol. 31. [46] Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-based recommendation with graph neural networks. In Proceedings of the AAAI conference on artificial intelligence, Vol. 33. 346-353. [47] Yiquan Wu, Weiming Lu, Yating Zhang, Adam Jatowt, Jun Feng, Changlong Sun, Fei Wu, and Kun Kuang. 2023. Focus-aware response generation in inquiry conversation. In Findings of the Association for Computational Linguistics: ACL 2023. 12585-12599. [48] Yiquan Wu, Siying Zhou, Yifei Liu, Weiming Lu, Xiaozhong Liu, Yating Zhang, Changlong Sun, Fei Wu, and Kun Kuang. 2023. Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model Collaboration. arXiv preprint arXiv:2310.09241 (2023). [49] Jujia Zhao Yongqi Li Fuli Feng Xinyu Lin, Wenjie Wang and Tat-Seng Chua. 2024. Temporally and Distributionally Robust Optimization for Cold-start Recommendation. In AAAI. [50] Bencheng Yan, Pengjie Wang, Kai Zhang, Feng Li, Jian Xu, and Bo Zheng. 2022. APG: Adaptive Parameter Generation Network for Click-Through Rate Prediction. In Advances in Neural Information Processing Systems. [51] Yikai Yan, Chaoyue Niu, Renjie Gu, Fan Wu, Shaojie Tang, Lifeng Hua, Chengfei Lyu, and Guihai Chen. 2022. On-Device Learning for Model Personalization with Large-Scale Cloud-Coordinated Domain Adaption. In KDD '22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022. 2180-2190. [52] Jiangchao Yao, Feng Wang, Xichen Ding, Shaohu Chen, Bo Han, Jingren Zhou, and Hongxia Yang. 2022. Device-cloud Collaborative Recommendation via Meta Controller. In KDD '22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022. 4353-4362. [53] Jiangchao Yao, Shengyu Zhang, Yang Yao, Feng Wang, Jianxin Ma, Jianwei Zhang, Yunfei Chu, Luo Ji, Kunyang Jia, Tao Shen, et al. 2022. Edge-Cloud Polarization and Collaboration: A Comprehensive Survey for AI. IEEE Transactions on Knowledge and Data Engineering (2022). [54] Fengda Zhang, Kun Kuang, Long Chen, Yuxuan Liu, Chao Wu, and Jun Xiao. 2022. Fairness-aware contrastive learning with partially annotated sensitive attributes. In The Eleventh International Conference on Learning Representations. [55] Fengda Zhang, Kun Kuang, Long Chen, Zhaoyang You, Tao Shen, Jun Xiao, Yin Zhang, Chao Wu, Fei Wu, Yueting Zhuang, et al. 2023. Federated unsupervised representation learning. Frontiers of Information Technology & Electronic Engineering 24, 8 (2023), 1181-1193. [58] Wenqiao Zhang, Changshuo Liu, Lingze Zeng, Bengchin Ooi, Siliang Tang, and Yueting Zhuang. 2023. Learning in Imperfect Environment: Multi-Label Classification with Long-Tailed Distribution and Partial Labels. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 1423-1432. [59] Wenqiao Zhang and Zheqi Lv. 2024. Revisiting the Domain Shift and Sample Uncertainty in Multi-source Active Domain Transfer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. [60] Wenqiao Zhang, Haochen Shi, Jiannan Guo, Shengyu Zhang, Qingpeng Cai, Juncheng Li, Sihui Luo, and Yueting Zhuang. 2021. MAGIC: Multimodal relAtional Graph adversarIal inferenCe for Diverse and Unpaired Text-based Image Captioning. arXiv preprint arXiv:2112.06558 (2021).", "A APPENDIX": "This is the Appendix for 'Intelligent Model Update Strategy for Sequential Recommendation'.", "A.1 Supplementary Method": "A.1.1 Notations and Definitions. We summarize notations and definitions in the Table 2. A.1.2 Optimization Target. To describe it in the simplest way, we assume that the set of the edges is D = { \ud835\udc51 ( \ud835\udc56 ) } N \ud835\udc51 \ud835\udc56 = 1 , the set updated using the baseline method is D \u2032 \ud835\udc62 = { \ud835\udc51 ( \ud835\udc56 ) } N \u2032 \ud835\udc62 \ud835\udc56 = 1 , the set updated using our method is D \ud835\udc62 = { \ud835\udc51 ( \ud835\udc56 ) } N \ud835\udc62 \ud835\udc56 = 1 . N \ud835\udc51 , N \u2032 \ud835\udc62 , and N \ud835\udc62 are the amount of the D , D \u2032 \ud835\udc62 and D \ud835\udc62 , respectively. The communication upper bound is set to \ud835\udc41 thres . Suppose the ground-truth value \ud835\udc66 , and the prediction of the baseline models \u02c6 \ud835\udc66 \u2032 , and the prediction of our model \u02c6 \ud835\udc66 are row vectors. Therefore, our optimization target is to obtain the highest performance of the model while limiting the upper bound of the communication frequency. In this case, the improvement of our method is \u0394 = \u02c6 \ud835\udc66\ud835\udc66 \ud835\udc47 -\u02c6 \ud835\udc66 \u2032 \ud835\udc66 \ud835\udc47 . Or it can also be regarded as reducing the communication frequency without degrading performance. In this case, the improvement of our method is \u0394 = N - N \ud835\udc62 .", "A.2 Supplementary Experimental Results": "A.2.1 Datasets. We evaluate IntellectReq and baselines on Amazon CDs (CDs) 2 , Amazon Electronic (Electronic) 2 , Douban Book (Book) 3 , three widely used public benchmarks in the recommendation tasks, Table 3 shows the statistics. Following conventional practice, all user-item pairs in the dataset are treated as positive samples. To conduct sequential recommendation experiments, we arrange the items clicked by the user into a sequence in the order of timestamps. We also refer to [11, 17, 63], which is negatively sampled at 1 : 4 and 1 : 99 in the training set and testing set, respectively. Negative sampling considers all user-item pairs that do not exist in the dataset as negative samples. A.2.2 Evaluation Metrics. In the experiments, we use the widely adopted AUC, Logloss, HitRate and NDCG as the metrics to evaluate model performance. They are defined by the following equations. In the equation above, 1 (\u00b7) is the indicator function. \ud835\udc53 is the model to be evaluated. \ud835\udc45 \ud835\udc62,\ud835\udc54 \ud835\udc62 is the rank predicted by the model for the ground truth item \ud835\udc54 \ud835\udc62 and user \ud835\udc62 . D \ud835\udc47 , D \ud835\udc39 is the positive and negative testing sample set, respectively, and D \ud835\udc62 \ud835\udc47 , D \ud835\udc62 \ud835\udc39 is the positive and negative testing sample set for user \ud835\udc62 respectively. A.2.3 Request Frequency and Threshold. Figure 10 shows that the relationship between request frequency and different threshold. Baseline=DUET DIN GRU4Rec SASRec (%) Baseline = APG DIN GRU4Rec SASRec (%) (%) (%) (%) (%)", "A.3 Training Procedure and Inference Procedure": "In this section, we describe the overall pipeline in detail in conjunction with Figure 11.", "1. Training Procedure": "1 \u25cb We first pre-trained a EC-CDR framework, and EC-CDR can use data to generate model parameters. 2 \u25cb MRDtraining procedure . 1) Construct the MRD dataset . We assume that the time at this time is \ud835\udc47 , and then we use the model parameters generated by the data at moment \ud835\udc61 = 0 under the EC-CDR framework, and the model is applied to the data at the current moment \ud835\udc61 = \ud835\udc47 . At this point, we can get a prediction result \u02c6 \ud835\udc66 , compare \u02c6 \ud835\udc66 with \ud835\udc66 to get whether the model do mis-recommendation. We then repeat the data used for parameter generation from \ud835\udc61 = 0 to \ud835\udc61 = \ud835\udc47 -1, which constructs an MRD dataset. It contains three columns, namely: the data used for parameter generation ( \ud835\udc65 1), the current data ( \ud835\udc65 2), and whether it do mis-recommendation ( \ud835\udc66 MRD). 2) Train MRD . MRD is a fully connected neural network that takes \ud835\udc65 1 and \ud835\udc65 2 as input and fits the mis-recommendation label \ud835\udc66 MRD. And then we get the MRD. MRD can be used to determine whether the model parameters generated using the data at a certain moment before are still valid for the current data. The prediction result output by MRD can be simply considered as Mis-Recommendation Score (MRS). 3 \u25cb DMtraining procedure . We map the data into a Gaussian distribution through the Conditional-VAE method, and then sample the feature vector from the distribution to complete the next-item prediction task, that is, to predict the item that the user will click next. Then we can get DM. DM can calculate multiple next-items by sampling from the distribution multiple times, which can be used to calculate Uncertainty. 4 \u25cb Joint training procedure of MRD and DM . We use a fully connected neural network, denoted as \ud835\udc53 (\u00b7) , and use MRS and Uncertainty as input to fit \ud835\udc66 MRD in the MRD dataset, which is the Mis-Recommendation Label.", "2. Inference Procedure": "The MRS is calculated using all recent user data on the cloud, and the threshold of the MRS is determined according to the load. Then send this threshold to each edge. The edge has updated the model at a certain moment \ud835\udc61 = \ud835\udc5b, \ud835\udc5b < \ud835\udc47 before, and now whether it is necessary to continue to update the model at moment \ud835\udc61 = \ud835\udc47 , that is, whether the model is invalid for the current data distribution? Real-time Data Transformer Layers GRU Layers Attention Layers t 1 t 2 t 3 t 4 t 5 t 6 t 7 t 8 Embedding Layer Static Layers with Static Parameters Dynamic Layers with Dynamic Parameters User Click Sequence Parameter Generator Linear Layer Mis-Recommendation Detector Large Distribution Shift Distribution Mapper No/Small Distribution Shift IntellectReq  Framework EC-CDR Framework Update Model Sequence Embedding Item Set Keep Model We only need to input the MRD and Uncertainty calculated by the data at the moment \ud835\udc61 = \ud835\udc5b data and the data at the moment \ud835\udc61 = \ud835\udc47 into \ud835\udc53 (\u00b7) for determine. In fact, what we output is a invalid degree, which is a continuous value between 0 and 1. Whether to update the edge model depends on the threshold calculated on the cloud based on the load.", "A.4 Hyperparameters and Training Schedules": "We summarize the hyperparameters and training schedules of IntellectReq on the three datasets in Table 4. A.4.1 Impact on the Real World. A case based on a dynamic model from the previous moment is as follows. If it were based on a on-edge static model, the improvement would be much more significant. We found some more intuitive data and examples to show the challenge and IntellectReq's impact on the real world: (1) We calcu- late the number of bytes and FLOPs required to update a parameter. Bytes: 48.5kB, FLOPs: 1.53M. That is, updating a model on the edge requires the transmission of 48.5kB data through edge-cloud communication, and consumes 1.53M computing power of the cloud model. (2) According to the report, Google processes 99,000 clicks per second, so it needs to transmit 48.5kB \u2217 99k=4.69GB per second, and consume 1.53M \u2217 99k=152.46G of computing power in the cloud server. Alibaba processes 1,150,000 clicks per second, so it needs to transmit 48.5kB \u2217 1150k=53.19GB per second, and consume 1.53M \u2217 1150k=1.68T of computing power in the cloud server. These are not the peak value yet. Obviously, such a huge loan and computing power consumption make it hard to update the model for edges every moment especially at peak times. (3) Sometimes, the distributed nature of clouds today may can afford the computational volume, since it can call enough servers to support edge-cloud collaboration. However, the huge resource consumption is impractical in real-scenario. Besides, according to our empirical study, our IntellectReq can bring 21.4% resource saving when the performance is the same using the APG framework. Under the DUET framework, IntellectReq can bring 16.6% resource saving when the performance is the same. Summing up, IntellectReq can save 19% resources on average, which is very helpful for cost control and can facilitate the EC-CDR development in practice. The following Table 5 is the comparison between our method IntellectReq and EC-CDR in the amount of transmitted data and the computing power consumed on the cloud. (4) During the peak period, resources will be tight and cause freezes or even crashes. This is still in the case that EC-CDR has not been deployed yet, that is, the edge-cloud communication only performs the most basic user data transmission. Then, IntellectReq can achieve better performance than EC-CDR under any resource limit \ud835\udf16 , or to achieve the performance that EC-CDR requires \ud835\udf16 + 19% of resources to achieve."}
