{"Click-Conversion Multi-Task Model with Position Bias Mitigation for Sponsored Search in eCommerce": "Yibo Wang ywang633@uic.edu University of Illinois Chicago Chicago, IL, USA Yanbing Xue yanbing.xue@walmart.com Walmart eCommerce Sunnyvale, CA, USA Bo Liu bo.liu1@walmart.com Walmart eCommerce Sunnyvale, CA, USA Musen Wen musen.wen@walmart.com Walmart eCommerce Sunnyvale, CA, USA Wenting Zhao wzhao41@uic.edu University of Illinois Chicago Chicago, IL, USA Stephen Guo sguo@indeed.com Indeed Sunnyvale, CA, USA", "ABSTRACT": "Philip S. Yu psyu@uic.edu University of Illinois Chicago Chicago, IL, USA", "1 INTRODUCTION": "Position bias, the phenomenon whereby users tend to focus on higher-ranked items of the search result list regardless of the actual relevance to queries, is prevailing in many ranking systems. Position bias in training data biases the ranking model, leading to increasingly unfair item rankings, click-through-rate (CTR), and conversion rate (CVR) predictions. To jointly mitigate position bias in both item CTR and CVR prediction, we propose two positionbias-free CTR and CVR prediction models: Position-Aware ClickConversion (PACC) and PACC via Position Embedding (PACC-PE). PACC is built upon probability decomposition and models position information as a probability. PACC-PE utilizes neural networks to model product-specific position information as embedding. Experiments on the E-commerce sponsored product search dataset show that our proposed models have better ranking effectiveness and can greatly alleviate position bias in both CTR and CVR prediction.", "CCS CONCEPTS": "\u00b7 Applied computing \u2192 Electronic commerce ; \u00b7 Computing methodologies \u2192 Machine learning .", "KEYWORDS": "Multi-task Learning; Sponsored Product Search; Position Bias", "ACMReference Format:": "Yibo Wang, Yanbing Xue, Bo Liu, Musen Wen, Wenting Zhao, Stephen Guo, and Philip S. Yu. 2023. Click-Conversion Multi-Task Model with Position Bias Mitigation for Sponsored Search in eCommerce. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '23), July 23-27, 2023, Taipei, Taiwan. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3539618.3591963 Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '23, July 23-27, 2023, Taipei, Taiwan \u00a9 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-9408-6/23/07...$15.00 https://doi.org/10.1145/3539618.3591963 The phenomenon of position bias is commonly observed in many ranking and information retrieval systems, including digital advertising and recommender systems. Position bias is the tendency of users to pay greater attention to higher-ranked items, regardless of their actual relevance to the query. For example, the eye-tracking study [13] and [14] show that in web search, the highest-ranked items receive the most attention; the study of digital library recommendation system [5] discovers that items shown at the top positions are more often clicked regardless of their actual relevance. Acommonpractice from machine-learned ranking (MLR) models is to use implicit user feedback, such as click/no-click as training data labels. However, due to inherited position bias, these models tend to exhibit lower predicted click-through rates (CTR) for lowerranked items. This bias in prediction can then affect subsequent training data collection, leading to a persistent and cyclical effect. The accumulative position bias of the training data will skew the MLR model, leading to increasingly unfair item rank prediction [6]. To address this position bias problem, various approaches have been proposed, including factorization models [4], inverse propensity scores [9, 15, 19], deep neural network-based CTR prediction models [8, 17, 21], and more. Pioneering approaches such as [4] proposed a factorization model that decouples CTR into positionnormalized CTR and position bias, which are then estimated by an Expectation-Maximization (EM) algorithm framework. To remove the position bias for learning to rank models, a propensity-weighted empirical risk minimization framework is proposed in [15]. In [10], an unbiased LambdaMART model is proposed, which jointly estimates the biases at click positions and unclick positions and learns an unbiased ranker. Several literatures dedicate to the propensity estimation, such as [1, 2, 18]. Recently, increasing research studies correcting position bias in the deep-ranking models. In [12], the authors propose to combine recurrent neural network and survival analysis techniques to model unbiased user behaviors. [3] designs a neural-based Context-Aware Click Model with an examination predictor able to automatically learn the position bias during training. The existing methods primarily consider single-task objectives like CTR prediction. However, in E-commerce, typical ranking models can have multiple objectives, such as maximizing both CTR and CVR. Deep Multifaceted Transformers (DMT) [7] learns both CTR and CVR predictors by modeling multiple user behaviors simultaneously with bias mitigation and treats CTR and CVR prediction SIGIR '23, July 23-27, 2023, Taipei, Taiwan Yibo Wang et al. as two parallel tasks. However, item impression, click, and conversion processes have sequential dependencies and are all affected by position bias. Such dependencies are not leveraged in DMT. In this paper, two models, Position Aware Click-Conversion (PACC) and PACC with Position Embedding (PACC-PE) are proposed to model the sequential relationship and jointly mitigate position bias in both CTR prediction and CVR prediction. PACC is based on the following two assumptions: (1). whether an item will be seen is only related to its position; (2). after an item is seen, whether it will be clicked/purchased is independent of its position. PACC is built upon the probability decomposition presented in \u00a72.2. PACC-PE is a variant of PACC, which adopts a neural network to model the product-specific position information as embedding. Compared to PACC, learning the product-specific position embedding with a neural network enables PACC-PE to achieve richer information and superior performance than PACC. Specifically, our work has the following contributions: \u00b7 We propose to jointly learn position-bias-free CTR and CVR prediction models in a multi-task learning framework. By mitigating position bias, the proposed models achieve comparable performance as state-of-the-art models on CTR prediction and significant performance improvement on CVR prediction regarding weighted Mean-Reciprocal-Rank (MRR) [19], MRR, position-wise AUC (PAUC) [11], and AUC. \u00b7 We conduct experiments on real-world E-commerce sponsored product searches. Our proposed models achieve better ranking effectiveness and greatly mitigate position bias.", "2 METHODOLOGY": "In this section, we first introduce our problem formulation and then present assumptions and theoretical basis. Finally, detailed explanations of our proposed PACC and PACC-PE models are provided.", "2.1 Notation and Problem Formulation": "We assume the training set to be \ud835\udc47 = {( \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) \u2192 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 , \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 )}| \ud835\udc41 \ud835\udc56 = 1 , where \ud835\udc53 \ud835\udc56 is features other than position of sample \ud835\udc56 , \ud835\udc5d \ud835\udc56 is the position of sample \ud835\udc56 , \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 \u2208 { 0 , 1 } is the click label of sample \ud835\udc56 , \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 \u2208 { 0 , 1 } is the conversion label of sample \ud835\udc56 , and \ud835\udc41 is the number of samples in \ud835\udc47 . Therefore, our models estimate the two probabilities: \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) , the probability of an item to be clicked according to features and position, and \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) , the probability of an item to be purchased according to features and position. Besides, we use \ud835\udc60 \ud835\udc56 \u2208 { 0 , 1 } to represent whether an item is seen by the user or not.", "2.2 Assumptions and Theoretical Basis": "PACC is based on two assumptions: 1) whether an item will be seen by the user is only related to item position, which is \ud835\udc43 ( \ud835\udc60 \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) = \ud835\udc43 ( \ud835\udc60 \ud835\udc56 | \ud835\udc5d \ud835\udc56 ) ; 2) if an item is already seen, whether it will be clicked/purchased is independent of item position, which is \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 , \ud835\udc60 \ud835\udc56 = 1 ) = \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc60 \ud835\udc56 = 1 ) and \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 , \ud835\udc60 \ud835\udc56 = 1 ) = \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc60 \ud835\udc56 = 1 ) . In addition to these two assumptions, two facts underlie PACC: 1) an item has to be seen before it can be clicked, which is \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) = \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 = 1 \u2229 \ud835\udc60 \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) ; 2) an item has to be clicked and seen before it can be purchased, which is \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) = \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 = 1 \u2229 \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) and \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 , \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 ) = \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 = 1 \u2229 \ud835\udc60 \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 , \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 ) . The probability of an item being clicked is represented as:", "2.3 Proposed Framework": "2.3.1 Overview. Figure 1 illustrates the architecture of our proposed models. In both models, CTR prediction and CVR prediction share the same feature embedding but have different model architectures and parameters. A neural network is utilized to adaptively learn what and how much information to transfer from CTR prediction to CVR prediction. Position information is modeled separately and combined in innovative ways with the click-conversion multitask model. With this novel framework, our proposed models can jointly alleviate the position bias of both CTR and CVR prediction. 2.3.2 Position Aware Click-Conversion Model. The model architecture of PACC is shown in Fig. 1a. Given the input feature \ud835\udc53 \ud835\udc56 embedded as \ud835\udc63 \ud835\udc56 , for task \ud835\udc58 \u2208 { \ud835\udc50\ud835\udc61\ud835\udc5f, \ud835\udc50\ud835\udc63\ud835\udc5f } , the output of \ud835\udc58 Tower is defined as \ud835\udc47 \ud835\udc58 = \ud835\udc54 \ud835\udc58 \ud835\udc61 ( \ud835\udc63 \ud835\udc56 ) , where \ud835\udc54 \ud835\udc58 \ud835\udc61 (\u00b7) is three linear layers each followed by a ReLU activation function and a drop-out layer. Then \ud835\udc47 \ud835\udc50\ud835\udc61\ud835\udc5f is fed into a linear layer with a sigmoid function to calculate \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc60 \ud835\udc56 = 1 ) , which is the probability of an item to be clicked after it is seen. \ud835\udc47 \ud835\udc50\ud835\udc61\ud835\udc5f is also fed into a linear layer followed by a ReLU activation function and a drop-out layer, whose output is \ud835\udc3c \ud835\udc41 \ud835\udc39\ud835\udc42 \ud835\udc50\ud835\udc61\ud835\udc5f . Then \ud835\udc47 \ud835\udc50\ud835\udc63\ud835\udc5f and \ud835\udc3c \ud835\udc41 \ud835\udc39\ud835\udc42 \ud835\udc50\ud835\udc61\ud835\udc5f are concatenated and fed into an attention layer as \ud835\udc34 \ud835\udc50\ud835\udc63\ud835\udc5f = \ud835\udc54 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc4e ([ \ud835\udc47 \ud835\udc50\ud835\udc63\ud835\udc5f ; \ud835\udc3c \ud835\udc41 \ud835\udc39\ud835\udc42 \ud835\udc50\ud835\udc61\ud835\udc5f ]) , where \ud835\udc54 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc4e is the function of the attention layer and \ud835\udc34 \ud835\udc50\ud835\udc63\ud835\udc5f is the output. Then \ud835\udc34 \ud835\udc50\ud835\udc63\ud835\udc5f is fed into a linear layer with a sigmoid function to calculate \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 = 1 , \ud835\udc60 \ud835\udc56 = 1 ) , which is the probability of an item to be purchased if it is already seen and clicked. \ud835\udc43 ( \ud835\udc60 \ud835\udc56 | \ud835\udc5d \ud835\udc56 ) , the probability of an item to be seen given the position, is modeled using a linear layer and a sigmoid function. Then \ud835\udc43 ( \ud835\udc60 \ud835\udc56 | \ud835\udc5d \ud835\udc56 ) is multiplied by \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc60 \ud835\udc56 = 1 ) for \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) and \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) is multiplied by \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 = 1 , \ud835\udc60 \ud835\udc56 = 1 ) for \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) according to Eq.(1) and Eq.(2). 2.3.3 Position Aware Click-Conversion Model with Position Embedding. The architecture of PACC-PE is shown in Fig. 1b. Given \ud835\udc63 \ud835\udc56 as the shared feature embedding of sample \ud835\udc56 , for task \ud835\udc58 \u2208 { \ud835\udc5d\ud835\udc5c\ud835\udc60,\ud835\udc50\ud835\udc61\ud835\udc5f,\ud835\udc50\ud835\udc63\ud835\udc5f } , the output of \ud835\udc58 Tower is defined as \ud835\udc47 \ud835\udc58 = \ud835\udc54 \ud835\udc58 \ud835\udc61 ( \ud835\udc63 \ud835\udc56 ) , where \ud835\udc54 \ud835\udc58 \ud835\udc61 (\u00b7) encodes \ud835\udc63 \ud835\udc56 through three linear layers each followed by a ReLU activation function and a drop-out layer. \ud835\udc47 \ud835\udc5d\ud835\udc5c\ud835\udc60 is then fed into a linear layer followed by a ReLU activation function and a drop-out layer, whose output is \ud835\udc3c \ud835\udc41 \ud835\udc39\ud835\udc42 \ud835\udc5d\ud835\udc5c\ud835\udc60 . Then \ud835\udc47 \ud835\udc50\ud835\udc61\ud835\udc5f and \ud835\udc3c \ud835\udc41 \ud835\udc39\ud835\udc42 \ud835\udc5d\ud835\udc5c\ud835\udc60 are concatenated and fed into an attention layer as \ud835\udc34 \ud835\udc50\ud835\udc61\ud835\udc5f = \ud835\udc54 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc4e ([ \ud835\udc47 \ud835\udc50\ud835\udc61\ud835\udc5f ; \ud835\udc3c \ud835\udc41 \ud835\udc39\ud835\udc42 \ud835\udc5d\ud835\udc5c\ud835\udc60 ]) , where \ud835\udc54 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc4e is the function of the attention layer and \ud835\udc34 \ud835\udc50\ud835\udc61\ud835\udc5f is the output. Then \ud835\udc34 \ud835\udc50\ud835\udc61\ud835\udc5f is fed into a linear layer with a sigmoid function to calculate \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) , which is the probability of an item to be clicked. \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) is obtained similar as \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) . The difference between PACC and PACC-PE is that PACC models position information into a scalar while PACC-PE models productspecific position information into an embedding. Thus, PACC-PE focuses on representing product-related position information, which Click-Conversion Multi-Task Model with Position Bias Mitigation for Sponsored Search in eCommerce SIGIR '23, July 23-27, 2023, Taipei, Taiwan (a) Position Aware Click-Conversion Model Lincar Laycr Sigmoid Attention Concat Lincar Laycr Lincar Sigmoid RcLU Out IClick Towcr (Convcrsion Iower Lnear Layer ReLU Lincar RelU Drop Out Drop Out Sigmoid Position Embedding Dror Layer Lincar Laycr Lincar Concat concat Linear Laver Linear Layei Relu Drop Out Relu [Click Iowcr Conversion Tower RelU Lincar Layer RcLU Out Fealure Embedding Oror pror (b) Position Aware Click-Conversion Model with Position Embedding Figure 1: An overview of PACC and PACC-PE. The left figure shows the overall structure of the PACC model which utilizes the assumptions and probability decomposition in \u00a72.2 to estimate the probability of an item being clicked and the probability of an item being purchased based on position and feature embedding. The right figure illustrates the PACC-PE model that integrates neural networks to model product-specific position information as embedding. is richer and more useful. Besides, PACC-PE has high fault tolerance compared with PACC, where subsequent tasks will be greatly affected if the probability of a former task is predicted wrongly. Table 1: Ranking Performance Comparison Results with Based Models 2.3.4 Loss Function. The loss function of our proposed models is  where L \ud835\udc36\ud835\udc47\ud835\udc45 ( \ud835\udf03 ) is the binary cross entropy loss of the CTR prediction task, L \ud835\udc36\ud835\udc49\ud835\udc45 ( \ud835\udf03 ) is the binary cross entropy loss of the CVR prediction task and L \ud835\udc5f\ud835\udc52\ud835\udc60 ( \ud835\udf03 ) is a restriction loss. The restriction loss is based on the fact that an item has to be clicked before it can be purchased, which is defined as", "3 EXPERIMENTS": "", "3.1 Dataset and Data Preprocessing": "The training and testing query-item pair data are collected using Walmart 1 sponsored ads logs. The dataset is a real-world dataset with position bias, containing 4.2M training samples, 1.1M validation samples, and 7.5M testing samples. The extracted features are categorized into three types: categorical features, numeric features, and text features. The categorical features are transformed into one-hot vectors; the numeric features are normalized; and the text features are embedded using BERT [16] to calculate cosine similarity scores and element-wise product between query and ad item. The element-wise product obtained using \ud835\udc35\ud835\udc38\ud835\udc45\ud835\udc47 \ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52 has a dimension of 768, whereas the dimensions of other features are much smaller. To prevent the element-wise product from overwhelming other features, we use PCA to reduce its dimensionality to 5. In addition, the position feature is transformed into a one-hot format.", "3.2 Evaluation Metrics": "Since the standard Mean Reciprocal Rank (MRR) assumes that the clicked/purchased items are relevant while ignoring the position 1 https://www.walmart.com bias, we use weighted MRR [19] to evaluate ranking effectiveness, which is formulated as \ud835\udc40\ud835\udc45\ud835\udc45 \ud835\udc5a = 1 \u02dd \ud835\udc41 \ud835\udc56 = 1 , \u02dc \ud835\udc66 \ud835\udc5a \ud835\udc56 = 1 \ud835\udc64 \ud835\udc56 \ud835\udc5a \u02dd \ud835\udc41 \ud835\udc56 = 1 , \u02dc \ud835\udc66 \ud835\udc56 \ud835\udc5a = 1 \ud835\udc64 \ud835\udc5a \ud835\udc56 1 \ud835\udc5d \ud835\udc56 , where \ud835\udc5a \u2208 { \ud835\udc50\ud835\udc61\ud835\udc5f, \ud835\udc50\ud835\udc63\ud835\udc5f } , \ud835\udc41 is the number of samples, \ud835\udc64 \ud835\udc5a \ud835\udc56 = 1 \ud835\udc43 ( \ud835\udc60 \ud835\udc56 | \ud835\udc53 \ud835\udc56 ,\ud835\udc5d \ud835\udc56 ) is a weight of \ud835\udc56 -th sample, \ud835\udc5d \ud835\udc56 is the position of the \ud835\udc56 -th sample and \u02dc \ud835\udc66 \ud835\udc5a \ud835\udc56 is the predicted label. \ud835\udc64 \ud835\udc5a \ud835\udc56 is defined through the reciprocal of \ud835\udc43 ( \ud835\udc60 \ud835\udc56 | \ud835\udc5d \ud835\udc56 ) which reflects the impact of position. For PACC, \ud835\udc64 \ud835\udc5a \ud835\udc56 can be calculated in a straightforward way since \ud835\udc43 ( \ud835\udc60 \ud835\udc56 | \ud835\udc5d \ud835\udc56 ) = \ud835\udc43 ( \ud835\udc60 \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) is obtained after training. To compute \ud835\udc43 ( \ud835\udc60 \ud835\udc56 | \ud835\udc53 \ud835\udc56 , \ud835\udc5d \ud835\udc56 ) for PACC-PE as mentioned in [15], we first swap \ud835\udc5d \ud835\udc56 with \ud835\udc5d \ud835\udc56 = \ud835\udc5f for item \ud835\udc56 . The probability of this item being clicked at position \ud835\udc5d \ud835\udc56 = \ud835\udc5f is  The probability of this item being clicked at position \ud835\udc5d \ud835\udc56 is  With Eq. (5) and Eq. (6), the ratio \ud835\udc43 ( \ud835\udc60 \ud835\udc56 | \ud835\udc53 \ud835\udc56 ,\ud835\udc5d \ud835\udc56 ) \ud835\udc43 ( \ud835\udc60 \ud835\udc56 | \ud835\udc53 \ud835\udc56 ,\ud835\udc5d \ud835\udc56 = \ud835\udc5f ) = \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 ,\ud835\udc5d \ud835\udc56 ) \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 ,\ud835\udc5d \ud835\udc56 = \ud835\udc5f ) is obtained. Thus, the weight \ud835\udc64 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 for PACC-PE is  which is proportional to \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 ,\ud835\udc5d \ud835\udc56 = \ud835\udc5f ) \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 ,\ud835\udc5d \ud835\udc56 ) since \ud835\udc43 ( \ud835\udc60 \ud835\udc56 | \ud835\udc5d \ud835\udc56 = \ud835\udc5f ) is a constant for a fixed position \ud835\udc5f . \ud835\udc64 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 can be calculated similarly. In addition to the weighted MRR, we also apply the widely-used evaluation metrics: standard MRR, AUC, and position-wise AUC (PAUC) [11] to evaluate model performance. SIGIR '23, July 23-27, 2023, Taipei, Taiwan Yibo Wang et al.", "3.3 Experimental Results and Analysis": "3.3.1 Ranking Effectiveness. We compare the weighted MRR, MRR, PAUC, and AUC of our proposed models and the baselines PAL [8], AITM [20], and DMT [7] models. PAL is a single-task position bias mitigation model; AITM is a multi-task model; DMT is a multi-task position bias mitigation model. The evaluation results are reported in Table 1. For CTR prediction, all models perform similarly in terms of weighted MRR and MRR. PACC-PE outperforms the best baseline by 3.27%/2.64% in terms of PAUC/AUC with p-value = 0.0072 and confidence level > 99%. For CVR prediction, PACC-PE significantly outperforms all other baseline models regarding weighted MRR and MRR, increasing weighted MRR/MRR by 4.92%/4.07% with p-value = 0.0088 and confidence level > 99%. PACC also outperforms other baseline models. The substantial improvement in CVR prediction of our proposed models indicates that jointly mitigating position bias for both CTR and CVR and considering the sequential dependencies in order between click and purchase is effective for performance improvement. 3.3.2 Position Bias. To generally evaluate the ability of our proposed model in mitigating position bias, we randomly select 500 query-item pairs and visualize their probability of being clicked and purchased before and after swapping positions. To better interpret the predicted probabilities, the log odds function is used to project probabilities in log odds space. From Fig 2 and Fig 3, the sample points of PACC and PACC-PE fit better on \ud835\udc66 = \ud835\udc65 compared to AITM, indicating that swapping item positions with position 1 has less influence on the predicted probabilities of being clicked and purchased by PACC and PACC-PE. 3.3.3 Position Bias on Different Positions. To evaluate the ability of our proposed models in mitigating position bias on different positions, we investigate the differences in model prediction changes for items at different positions due to swapping positions with position -25 -20 -15 -10 -5 log(P*(1-P)) of Click in Position 1 -25 -20 -15 -10 -5 log(P*(1-P)) of Click in Original Position MSE with y=x: 0.1836 (a) AITM -14 -12 -10 -8 -6 -4 -2 log(P*(1-P)) of Click in Position 1 -14 -12 -10 -8 -6 -4 -2 log(P*(1-P)) of Click in Original Position MSE with y=x: 0.0041 (b) PACC -25 -20 -15 -10 -5 log(P*(1-P)) of Click in Position 1 -25 -20 -15 -10 -5 log(P*(1-P)) of Click in Original Position MSE with y=x: 0.0 (c) PACC-PE Figure 2: The log odds of probabilities of being clicked of 500 randomly selected query-item pairs. The y-axis is the probability of being clicked at the original position; the xaxis is the probability of being clicked at position 1. Figure 3: The log odds of probabilities of being purchased of 500 randomly selected query-item pairs. The y-axis is the probability of being purchased at the original position; the x-axis is the probability of being purchased at position 1. -50 -40 -30 -20 -10 log(P*(1-P)) of Conversion in Position 5 -60 -50 -40 -30 -20 -10 log(P*(1-P)) of Conversion in Original Position MSE with y=x: 0.9387 (a) AITM -45 -40 -35 -30 -25 -20 -15 -10 log(P*(1-P)) of Conversion in Position 5 -45 -40 -35 -30 -25 -20 -15 -10 log(P*(1-P)) of Conversion in Original Position MSE with y=x: 0.0042 (b) PACC -45.0 -42.5 -40.0 -37.5 -35.0 -32.5 -30.0 log(P*(1-P)) of Conversion in Position 5 -46 -44 -42 -40 -38 -36 -34 -32 -30 log(P*(1-P)) of Conversion in Original Position MSE with y=x: 0.0 (c) PACC-PE Figure 4: Visualization of the impact of position swapping demonstrated by 300 randomly selected examples. Red \u25e6 are clicked query-item pairs. Blue \u00d7 are purchased query-item pairs. Green \u25e6 are the impact of swapping positions at each position in PACC. 5 10 15 20 Position 0.0 0.2 0.4 0.6 0.8 1.0 1.2 Weights in Weighted MRR click conversion (a) AITM 5 10 15 20 Position 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 Weights in Weighted MRR (b) PACC 5 10 15 20 Position 0.96 0.98 1.00 1.02 1.04 Weights in Weighted MRR click conversion (c) PACC-PE 1. The smaller the position bias, the smaller the prediction changes due to swapping positions. The impact of swapping item positions is visualized in Fig 4. In Fig 4a and Fig 4c, \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 ,\ud835\udc5d \ud835\udc56 = 1 ) \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc61\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 ,\ud835\udc5d \ud835\udc56 ) and \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 ,\ud835\udc5d \ud835\udc56 = 1 ) \ud835\udc43 ( \ud835\udc66 \ud835\udc50\ud835\udc63\ud835\udc5f \ud835\udc56 = 1 | \ud835\udc53 \ud835\udc56 ,\ud835\udc5d \ud835\udc56 ) are used to measure the impact of swapping item positions on CTR prediction and CVR prediction, respectively. As in Fig 4c, swapping item positions almost has no effect on both CTR and CVR prediction for PACC-PE on all positions, indicating that PACC-PE has the ability to mitigate position bias on all positions. In Fig 4a swapping item positions has a large impact on the top few items and the last item in the ranking list for AITM. For items on the top, swapping them to position 1 improves the probability of being clicked and purchased, while for the last items swapping them to position 1 decreases the probability of being clicked and purchased. This phenomenon is counter-intuitive because intuitively swapping items to position 1 should increase the probability of being clicked and purchased. One possible explanation is that some items are safe choices, but not preferred. For these items, if they are ranked high, users will not click on them. But if they are ranked low, users may click them given no better items at the end of their browsing. In Fig 4b, \ud835\udc43 ( \ud835\udc60 \ud835\udc56 | \ud835\udc5d \ud835\udc56 = 1 ) \ud835\udc43 ( \ud835\udc60 \ud835\udc56 | \ud835\udc5d \ud835\udc56 ) is used to measure the impact of swapping item positions. The impact of swapping item positions for PACC is low compared to AITM, demonstrating the ability of PACC to alleviate position bias. For items at most positions, swapping positions to position 1 increases the probability of being clicked and purchased a little bit. One difference between PACC-PE and PACC from Fig 4c and Fig 4b is that for PACC, position bias of different items at the same position is the same, while for PACC-PE position bias of different items at the same position is different. This difference makes PACCPE more flexible to different items and conveys richer information.", "4 CONCLUSION": "To jointly mitigate position bias that exists in both item CTR and CVR prediction, we propose two position-bias-free CTR and CVR prediction models: Position Aware Click-Conversion and PACC with Position Embedding. In PACC, the position is modeled as a probability while in PACC-PE position is modeled into embedding. Our experiments and analyses illustrate that our proposed models achieve better ranking effectiveness than the state-of-the-art models and effectively mitigate position bias in all positions. Besides, PACCPE outperforms PACC in ranking effectiveness and position debias due to the rich information by modeling product-specific position information as embedding. Click-Conversion Multi-Task Model with Position Bias Mitigation for Sponsored Search in eCommerce SIGIR '23, July 23-27, 2023, Taipei, Taiwan", "REFERENCES": "[1] Aman Agarwal, Ivan Zaitsev, Xuanhui Wang, Cheng Li, Marc Najork, and Thorsten Joachims. 2019. Estimating position bias without intrusive interventions. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining . 474-482. [2] Qingyao Ai, Keping Bi, Cheng Luo, Jiafeng Guo, and W Bruce Croft. 2018. Unbiased learning to rank with unbiased propensity estimation. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval . 385-394. [3] Jia Chen, Jiaxin Mao, Yiqun Liu, Min Zhang, and Shaoping Ma. 2020. A contextaware click model for web search. In Proceedings of the 13th International Conference on Web Search and Data Mining . 88-96. [4] Ye Chen and Tak W Yan. 2012. Position-normalized click prediction in search advertising. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining . 795-803. [5] Andrew Collins, Dominika Tkaczyk, Akiko Aizawa, and Joeran Beel. 2018. A study of position bias in digital library recommender systems. arXiv preprint arXiv:1802.06565 (2018). [6] Nick Craswell, Onno Zoeter, Michael Taylor, and Bill Ramsey. 2008. An experimental comparison of click position-bias models. In Proceedings of the 2008 international conference on web search and data mining . 87-94. [7] Yulong Gu, Zhuoye Ding, Shuaiqiang Wang, Lixin Zou, Yiding Liu, and Dawei Yin. 2020. Deep Multifaceted Transformers for Multi-Objective Ranking in Large-Scale E-Commerce Recommender Systems. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management (Virtual Event, Ireland) (CIKM '20) . Association for Computing Machinery, New York, NY, USA, 2493-2500. https://doi.org/10.1145/3340531.3412697 [8] Huifeng Guo, Jinkai Yu, Qing Liu, Ruiming Tang, and Yuzhou Zhang. 2019. PAL: a position-bias aware learning framework for CTR prediction in live recommender systems. In Proceedings of the 13th ACM Conference on Recommender Systems . 452-456. [9] Ruocheng Guo, Xiaoting Zhao, Adam Henderson, Liangjie Hong, and Huan Liu. 2020. Debiasing grid-based product search in e-commerce. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 2852-2860. [10] Ziniu Hu, Yang Wang, Qu Peng, and Hang Li. 2019. Unbiased lambdamart: an unbiased pairwise learning-to-rank algorithm. In The World Wide Web Conference . 2830-2836. [11] Jianqiang Huang, Ke Hu, Qingtao Tang, Mingjian Chen, Yi Qi, Jia Cheng, and Jun Lei. 2021. Deep position-wise interaction network for CTR prediction. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1885-1889. [12] Jiarui Jin, Yuchen Fang, Weinan Zhang, Kan Ren, Guorui Zhou, Jian Xu, Yong Yu, Jun Wang, Xiaoqiang Zhu, and Kun Gai. 2020. A deep recurrent survival model for unbiased ranking. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval . 29-38. [13] Thorsten Joachims, Laura Granka, Bing Pan, Helene Hembrooke, and Geri Gay. 2005. Accurately Interpreting Clickthrough Data as Implicit Feedback. In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (Salvador, Brazil) (SIGIR '05) . Association for Computing Machinery, New York, NY, USA, 154-161. https: //doi.org/10.1145/1076034.1076063 [14] Thorsten Joachims, Laura Granka, Bing Pan, Helene Hembrooke, Filip Radlinski, and Geri Gay. 2007. Evaluating the Accuracy of Implicit Feedback from Clicks and Query Reformulations in Web Search. ACM Trans. Inf. Syst. 25, 2 (apr 2007), 7-es. https://doi.org/10.1145/1229179.1229181 [15] Thorsten Joachims, Adith Swaminathan, and Tobias Schnabel. 2017. Unbiased Learning-to-Rank with Biased Feedback. In Proceedings of the Tenth ACM International Conference on Web Search and Data Mining (Cambridge, United Kingdom) (WSDM'17) . Association for Computing Machinery, New York, NY, USA, 781-789. https://doi.org/10.1145/3018661.3018699 [16] Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of NAACL-HLT . 4171-4186. [17] Xiaoliang Ling, Weiwei Deng, Chen Gu, Hucheng Zhou, Cui Li, and Feng Sun. 2017. Model ensemble for click prediction in bing search ads. In Proceedings of the 26th international conference on world wide web companion . 689-698. [18] Ali Vardasbi, Maarten de Rijke, and Ilya Markov. 2020. Cascade model-based propensity estimation for counterfactual learning to rank. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval . 2089-2092. [19] Xuanhui Wang, Nadav Golbandi, Michael Bendersky, Donald Metzler, and Marc Najork. 2018. Position Bias Estimation for Unbiased Learning to Rank in Personal Search. In Proceedings of the 11th ACM International Conference on Web Search and Data Mining (WSDM) . 610-618. [20] Dongbo Xi, Zhen Zi Chen, Peng Yan, Yinger Zhang, Yongchun Zhu, Fuzhen Zhuang, and Yu Chen. 2021. Modeling the Sequential Dependence among Audience Multi-step Conversions with Multi-task Learning in Targeted Display Advertising. Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (2021). [21] Honglei Zhuang, Zhen Qin, Xuanhui Wang, Michael Bendersky, Xinyu Qian, Po Hu, and Dan Chary Chen. 2021. Cross-positional attention for debiasing clicks. In Proceedings of the Web Conference 2021 . 788-797."}
