{"Fragment and Integrate Network (FIN): A Novel Spatial-Temporal Modeling Based on Long Sequential Behavior for Online Food Ordering Click-Through Rate Prediction": "Jun Li, Jingjian Wang, Hongwei Wang, Xing Deng Jielong Chen, Bing Cao, Zekun Wang, Guanjie Xu, Ge Zhang, Feng Shi, Hualei Liu \u2217 Alibaba Group Beijing, China {lj251092,whw383259,jielong.cjl,bingcao.cb,hengkun.wzk,guanjie.xgj,luoge.zg,sam.sf}@alibabainc.com,jingjianwang.wjj@koubei.com,dengxing.dx@autonavi.com,jianglang@taobao.com", "ABSTRACT": "", "KEYWORDS": "Spatial-temporal information has been proven to be of great significance for click-through rate prediction tasks in online LocationBased Services (LBS), especially in mainstream food ordering platforms such as DoorDash, Uber Eats, Meituan, and Ele.me. Modeling user spatial-temporal preferences with sequential behavior data has become a hot topic in recommendation systems and online advertising. However, most of existing methods either lack the representation of rich spatial-temporal information or only handle user behaviors with limited length, e.g. 100. In this paper, we tackle these problems by designing a new spatial-temporal modeling paradigm named F ragment and I ntegrate N etwork (FIN). FIN consists of two networks: (i) Fragment Network (FN) extracts M ultiple S ubS equences (MSS) from lifelong sequential behavior data, and captures the specific spatial-temporal representation by modeling each MSS respectively. Here both a simplified attention and a complicated attention are adopted to balance the performance gain and resource consumption. (ii) Integrate Network (IN) builds a new integrated sequence by utilizing spatial-temporal interaction on MSS and captures the comprehensive spatial-temporal representation by modeling the integrated sequence with a complicated attention. Both public datasets and production datasets have demonstrated the accuracy and scalability of FIN. Since 2022, FIN has been fully deployed in the recommendation advertising system of Ele.me, one of the most popular online food ordering platforms in China, obtaining 5.7% improvement on Click-Through Rate (CTR) and 7.3% increase on Revenue Per Mille (RPM).", "CCS CONCEPTS": "", "\u00b7 Information systems \u2192 Spatial-temporal systems ; Online advertising ; Recommender systems .": "\u2217 J. Li and G. Zhang are the corresponding authors. {lj251092,luoge.zg}@alibaba-inc.com. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference acronym 'XX, June 03-05, 2018, Woodstock, NY \u00a9 2018 Association for Computing Machinery. ACM ISBN 978-1-4503-XXXX-X/18/06...$15.00 https://doi.org/XXXXXXX.XXXXXXX Click-Through Rate Prediction; Long Sequential Behavior; Spatialtemporal Modeling; Online Food Ordering", "ACMReference Format:": "Jun Li, Jingjian Wang, Hongwei Wang, Xing Deng and Jielong Chen, Bing Cao, Zekun Wang, Guanjie Xu, Ge Zhang, Feng Shi, Hualei Liu. 2018. Fragment and Integrate Network (FIN): A Novel Spatial-Temporal Modeling Based on Long Sequential Behavior for Online Food Ordering Click-Through Rate Prediction. In Proceedings of Make sure to enter the correct conference title from your rights confirmation emai (Conference acronym 'XX). ACM, New York, NY, USA, 7 pages. https://doi.org/XXXXXXX.XXXXXXX", "1 INTRODUCTION": "Online Food Ordering Service (OFOS) is a popular location-based service that helps people order the food they want. Unlike traditional e-commerce scenarios, the spatial and temporal information has a great impact on users' behavioral preferences in OFOS platforms such as DoorDash, Uber Eats, Meituan, and Ele.me 1 . For example, the probability of a user ordering at a restaurant decreases as the spatial distance between the restaurant and the user increases. Additionally, the categories of food ordered by users vary significantly across different periods of the day. Specifically, people tend to order fast food during lunchtime at their workplace, while they may prefer kebab in the evening at his residence. A user's dietary preferences are reflected in their historical behavior data [19]. Over 22% of users in Ele.me, have more than 1000 click behaviors in the last 12 months. User behavior sequence data has a lot of spatial-temporal information, which makes it ideal for learning user preference in different spatial-temporal contexts. Recently, modeling spatial-temporal information with sequential behavior has become a hot research topic [19, 22, 26]. StEN [19] activates relevant preferences from user behavior sequences using Feed Forward Network (FFN) and average-pooling with time periods and location information. BASM [7] filters behavior sequences with time periods and locations, and then generates dynamic network parameters through a meta-network. However, these approaches can only handle user behaviors with limited length and lack the representation of comprehensive spatial-temporal information. SIM [22], UBR4CTR [24], and ETA [5] adopt two cascading units, one of which extracts the top-K relevant behaviors as a sub-sequence from long behavior sequence, while the other adopts the complicated attention to model the precise relationship between query items and the sub-sequence. However, these approaches can not involve rich spatial-temporal information of long sequential behavior data, which is of great value for ranking in online food ordering scenarios. In this paper, we address the above problems by designing a new spatial-temporal modeling paradigm named as F ragment and I ntegrate N etwork (FIN). Inspired by the ideas of SIM [22] and StEN [19], FIN can capture complex spatial-temporal intent representation of lifelong behavior sequences. FIN consists of a Fragment Network (FN) and an Integrate Network (IN). FN captures the specific spatial-temporal representation by modeling each MSS respectively. IN captures the comprehensive spatial-temporal representation by modeling a integrated sequence. The main contributions of this paper are summarized as follows: \u00b7 We propose a new modeling paradigm FIN for modeling spatial-temporal intent representation based on long behavior sequences, of which FN can model the specific spatialtemporal representation in MSS, while IN can model the comprehensive spatial-temporal representation among MSS. \u00b7 In FN, a simplified attention is proposed to balance the performance gain and resource consumption for modeling long sub-sequence. In IN, a new spatial-temporal interaction is proposed to capture the comprehensive spatial-temporal representation among MSS. \u00b7 Since 2022, FIN has been fully deployed in the recommendation advertising system in Ele.me, one of the most popular online food ordering platforms in China, bringing 5.7% CTR and 7.3% RPM lift. \u00b7 The design of Fragment and Integrate mechanism enables FIN with a better ability to deploy in both scalability and accuracy, providing a new approach for modeling lifelong sequential behavior data in recommendation systems and online advertising.", "2 RELATED WORK": "Long-term User Interest. Deep learning based methods have achieved great success in CTR prediction task [6, 9, 18, 27]. Recently, a series of works [2, 8, 28] on modeling user behavior sequence have emerged. DIN [32], DIEN [31], MIND [15] and Transformer [25] usually model short-term user behaviors due to the limitation of latency. MIMN [21] has proven that long sequence behaviors can significantly improve the performance of CTR models, adopting a memory network to compress long user behavior into a fixed-sized interest memory. SIM [22] selects top-K behaviors as a sub-sequence from lifelong sequence, and models the sub-sequence using multihead attention. In a similar way, ETA [5], SDIM [3], and TWIN [4] propose an end-to-end method to address the inconsistency between GSU and ESU of SIM [22]. In the field of NLP and CV, FLASH [11] and GSA-CCA [12] utilize both local attention and global attention to model long sequences. However, these works mentioned above rarely involve modeling the spatial-temporal information in long behavior sequence. Spatial-temporal Modeling. The CTR prediction task can be represented as the likelihood of a user clicking on an item in a certain context, of which the spatial-temporal information has been proven to be of great value [1, 17, 20]. Recently, a series of works has emerged combining spatial-temporal information with behavior sequences [19, 22, 29]. SLi-Rec [30] models user long-term and shortterm interests by introducing time-aware and content-aware controllers. TRISAN [23] leverages a triangular relationship between user geographic location, item geographic location, and user click time to enhance the representation of spatial-temporal information. BASM [7] proposes a bottom-up network to model multiple spatialtemporal data distributions. StEN [19] proposes a spatial-temporal enhancement network to model the spatial-temporal representation of user behavior data. However, these models can only handle user behaviors with limited length and lack the representation of comprehensive spatial-temporal relationships in long sequential behavior data.", "3 FRAGMENT AND INTEGRATE NETWORK": "Both the spatial-temporal information and sequential behavior data have been proved to be effective for CTR prediction tasks. BASM [7] and StEN [19] adopt an adaptive spatial-temporal network to model user behavior sequences with limited length. SIM [22] and ETA [5] model long sequential behavior data with limited temporal information (time intervals). How to efficiently model the rich spatial-temporal information based on long behavior sequences has become a major challenge, particularly for online LBS. To tackle this challenge, we propose a new modeling named F ragment and I ntegrate N etwork (FIN), which can both efficiently model long behavior sequences and effectively learn the rich spatialtemporal information. In this section, we will first introduce overall architecture of FIN, and then introduce the two proposed networks in detail.", "3.1 Overview Architecture": "The overall architecture of FIN is shown in Figure 1, consisting of a Fragment Network (FN) and an Integrate Network (IN). In FN , four sub-sequences are extracted, following a strategy of spatial-temporal search. A simplified attention is proposed to model the long sub-sequences, followed by a complicated multihead attention to model the truncated dozens of behaviors in these sub-sequences respectively. In IN , we build a new integrated sequence from the four subsequences by utilizing spatial-temporal interactions so that the comprehensive spatial-temporal representation can be learned with a complicated multi-head attention. It is worth mentioning that the spatial-temporal interaction has a practical physical meaning and is compatible among multiple sub-sequences with various lengths and dimensions.", "3.2 Fragment Network": "It is impractical to directly model all user behavior sequences in large-scale recommendation systems and online advertising, due to limited resource and response time. Inspired by category-based search proposed in SIM [22], we propose a hard search method based on spatial-temporal information: \u00b7 Geohash-block : Divide the latitude and longitude data into a finite geohash 2 code block. Use the geohash block as a (b 1 ,...,b M ) (b 1 ,...,b K ) (b 1 ,...,b N ) (b 1 ,...,b T ) (e 1 ,...,e T ) (e 1 ,...,e K ) (e 1 ,...,e M ) (e 1 ,...,e N ) Other feature Query (short-term) Concat & Flatten LReLU(200) LReLU(80) Softmax(2) output Spatial-Temporal Behavior Data Equal Count of click Multiply Normal Average-pooling Multiply (e 1 ,...,e N ) Length cut & Linear projection Multi-head Attention Spatial-temporal interaction Concat Simplified&Multi- head Attention Multi-head Attention Simplified&Multi- head Attention Simplified&Multi- head Attention Geohash-block sub-sequence Short-term sub-sequence Query (long-term) Query (meal-time) Query (geohash-block) Query (geohash-block) Geohash-block sub-sequence Geohash-block sub-sequence Simplified Attention : The integrated query representation : Element-wise multiplication : Element-wise subtraction : Element-wise addition : Embedding : Integrate Network Long-term sub-sequence Meal-time sub-sequence query to search the user's lifelong behavior sequence and extract a Geohash-block sub-sequence. \u00b7 Meal-time : Divide 24 hours of a day into several meal-time periods by bucketing minutes in our sample and extract a Meal-time sub-sequence using the periods. [ \ud835\udc60\ud835\udc4f \ud835\udc56 1 ; \ud835\udc60\ud835\udc4f \ud835\udc56 2 ; ... ; \ud835\udc60\ud835\udc4f \ud835\udc56 \ud835\udc57 ; ... ; \ud835\udc60\ud835\udc4f \ud835\udc56 \ud835\udc47 ] be \ud835\udc56 -th S ide information in \ud835\udc35 \u2217 , where \ud835\udc60\ud835\udc4f \ud835\udc56 \ud835\udc57 is the \ud835\udc57 -th user behavior with \ud835\udc56 -th side information, and \ud835\udc47 is the length of \ud835\udc35 \u2217 . The \ud835\udc46\ud835\udc35 \ud835\udc56 is encoded as embedding \ud835\udc38 \ud835\udc56 = [ \ud835\udc52 \ud835\udc56 1 ; \ud835\udc52 \ud835\udc56 2 ; ... ; \ud835\udc52 \ud835\udc56 \ud835\udc57 ; ... ; \ud835\udc52 \ud835\udc56 \ud835\udc47 ] . We equal \ud835\udc60\ud835\udc4f \ud835\udc56 \ud835\udc57 with \ud835\udc60\ud835\udc5e \ud835\udc56 and generate relevant score \ud835\udc5f \ud835\udc56 \ud835\udc57 : \u00b7 Short-term : Select a period as Short-term, e.g. the recent 30 days. Use it to extract a short-term sub-sequence. \u00b7 Long-term : Select another period as Long-term, e.g. the recent 365 days and build the long-term sub-sequence in a similar way to Geohash-block. Here we introduce methods for modeling these sub-sequences respectively: Geohash-block Modeling : We convert each latitude-longitude pair ( \ud835\udc59 1 , \ud835\udc59 2 ) into a 6-digit alphanumeric string geohash6 . Given the list of long user behaviors \ud835\udc35 = [ \ud835\udc4f 1; \ud835\udc4f 2; ... ; \ud835\udc4f \ud835\udc56 ; ... ; \ud835\udc4f \ud835\udc41 ] , where \ud835\udc4f \ud835\udc56 is the \ud835\udc56 -th user behavior and N is the length of user behavior list. Then we utilize geohash6 as a query to retrieve a sub-sequence \ud835\udc35 \u2217 under the same geohash6 from \ud835\udc35 . Because the length of \ud835\udc35 \u2217 is still long, up to several hundreds, we firstly adopt a simplified attention to model it. Given the S ide information of Q uery item 3 \ud835\udc46\ud835\udc44 = [ \ud835\udc60\ud835\udc5e 1; \ud835\udc60\ud835\udc5e 2; ... ; \ud835\udc60\ud835\udc5e \ud835\udc56 ; ... ; \ud835\udc60\ud835\udc5e \ud835\udc3e ] , where \ud835\udc60\ud835\udc5e \ud835\udc56 is \ud835\udc56 -th side information (such as category-id, item-id, geohash, meal-time, etc), and \ud835\udc3e is the number of side information. Let \ud835\udc46\ud835\udc35 \ud835\udc56 = Let \ud835\udc36 = [ \ud835\udc50 1; \ud835\udc50 2; ... ; \ud835\udc50 \ud835\udc57 ; ... ; \ud835\udc50 \ud835\udc47 ] be the count of clicks in \ud835\udc35 \u2217 , where \ud835\udc50 \ud835\udc57 is the cumulative clicks for \ud835\udc57 -th item in \ud835\udc35 \u2217 . Note that \ud835\udc50 \ud835\udc57 maybegreater than 1, since we de-duplicate the items in \ud835\udc35 \u2217 . The normalization score \ud835\udc67 \ud835\udc56 \ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 of \ud835\udc56 -th side information is obtained by multiplying the \ud835\udc5f \ud835\udc56 \ud835\udc57 and \ud835\udc50 \ud835\udc57 , and divided by total clicks \ud835\udc50 \ud835\udc57 : The simplified attention representation \ud835\udc48 \u2217 is obtained by multiplying \ud835\udc67 \ud835\udc56 \ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 and \ud835\udc52 \ud835\udc56 \ud835\udc57 with pooling and concatenate the \ud835\udc3e representations \ud835\udc48 \ud835\udc3e : To model \ud835\udc35 \u2217 precisely, we select \ud835\udc35 \u2217 \ud835\udc50 by truncating the length of \ud835\udc35 \u2217 to the latest dozens and take advantage of the complicated multi-head attention to model \ud835\udc35 \u2217 \ud835\udc50 with different query items: Conference acronym 'XX, June 03-05, 2018, Woodstock, NY where \ud835\udc52 \ud835\udc58 and \ud835\udc52 \ud835\udc5e denote the embedding of \ud835\udc35 \u2217 \ud835\udc50 and query item respectively. \ud835\udc4a \ud835\udc58\ud835\udc5a , \ud835\udc4a \ud835\udc5e\ud835\udc5a , \ud835\udc4a \ud835\udc63\ud835\udc5a are the \ud835\udc5a -th matrix parameter of \u210e\ud835\udc52\ud835\udc4e\ud835\udc51 \ud835\udc5a . \ud835\udc4e\ud835\udc61\ud835\udc61 \ud835\udc5a is the \ud835\udc5a -th attention score, and \u210e\ud835\udc52\ud835\udc4e\ud835\udc51 \ud835\udc5a is \ud835\udc5a -th head in multihead attention. The \ud835\udc41 heads are concatenated as the representation \ud835\udc48 \u2217 \ud835\udc50 . Finally, we concatenate \ud835\udc48 \u2217 with \ud835\udc48 \u2217 \ud835\udc50 as the output of Geohashblock sub-sequence modeling. Meal-time Modeling : According to dietary habits 4 , meal-time can be roughly divided into five periods: breakfast, lunch, afternoon tea, dinner, and late-night snack. Here, based on the distribution of our industrial samples, we divide the meal-time into some finegrained time periods \ud835\udc43 = [ \ud835\udc5d 1; ... ; \ud835\udc5d \ud835\udc40 ] by bucketing the minute-level data \ud835\udc47 using equal-frequency binning [14], here \ud835\udc40 as 95. Given the current time \ud835\udc3b\ud835\udc3b : \ud835\udc40\ud835\udc40 : \ud835\udc46\ud835\udc46 , \ud835\udc47 and \ud835\udc43 can be formulated as: We use the query \ud835\udc43 to retrieve a sub-sequence \ud835\udc35 \u2217 under the same \ud835\udc43 from \ud835\udc35 . Then the simplified attention and multi-head attention are adopted respectively, in a similar way to the formulations shown in Eq. (1-7). Additionally, practical experience indicates that user behaviors in \ud835\udc35 , include not only static features, such as item-id, category-id, brand-id, geohash, etc., but also contextual features such as time intervals, stay time, weekdays, weekends, delivery distance, furthermore, they also include statistical features such as impressions and clicks in recent days. These pieces of information are particularly important for online food ordering CTR prediction. Short-term Modeling : Recent user behaviors, including realtime actions, are crucial for the user's next decision. To capture short-term patterns, the latest dozens of behaviors are extracted from the user's recent 30-day sequence to form a sub-sequence \ud835\udc35 \u2217 . Then we model \ud835\udc35 \u2217 using multi-head attention. Long-term de-duplicate Modeling : Some user behaviors \ud835\udc35 # are not considered by Geohash-block, Meal-time, and Short-term. The \ud835\udc35 # is mainly composed of long-term user behavior in noncurrent Geohash-block or non-current Meal-time. In Ele.me, in the last 6 months, over 38% of users have geohash6 with a number of more than 3, while over 57% of users have meal-time with a number of more than 3. Capturing \ud835\udc35 # is important for the comprehensive understanding of user preferences. To this end, we initially borrow ETA [5] and model the whole user behaviors with a length of 1024 in last 12 months, but the AUC score does not show a significant improvement. In online food ordering scenarios, people tends to order meals in the same restaurant repeatedly, since the region in which users can order meals is limited with geographic constraints [19]. Therefore, we de-duplicate the restaurants in the behavior sequence, and add behavior frequency and time interval to the side information of the behavior sequence. The de-duplicate sequence length is reduced by 3.5 times. Our experiments found that the performance of modeling the de-duplicate sequence truncated to latest 100 using multi-head attention, is superior to ETA which selects top-64 from a long sequence of length 500. Given constraints of storage and computing cost, we adopt multi-head attention to model the truncated long-term sub-sequence. It is worth noting that the modeling of these sub-sequences mentioned above is parallel and independent of each other, which ensures deploying flexibility and serving efficiency. The output of each sub-sequence modeling represents a specific user intent representation in a specific spatial-temporal context, respectively.", "3.3 Integrate Network": "We can learn the comprehensive representation of spatial-temporal interest by building a new integrated sequence using spatial-temporal interactions on these sub-sequences of Meal-time, Geohash-block, Long-term, and Short-term. The spatial-temporal interaction has a practical physical meaning, as shown in Figure 2. Meal-time sub-sequence Geohash-block sub-sequence Long-term sub-sequence Short-term sub-sequence Representation of current location and current time Representation of multiple past locations Representation of periodic pattern When implementing the integrate network, we encounter a practical issue: both the lengths and dimensions of each sub-sequence are different. A naive solution is to average the lengths of subsequences to 1 and align the dimensions of sub-sequences through linear projection. Although this method can improve AUC to some extent, averaging the lengths to 1 may result in the loss of behavior information, we ultimately adopt a spatial-temporal interaction based on the granularity of sequence elements instead. Let \ud835\udc35 \ud835\udc3a , \ud835\udc35 \ud835\udc40 , \ud835\udc35 \ud835\udc46 and \ud835\udc35 \ud835\udc3f be the sub-sequences of Geohash-block, Meal-time, Short-term and Long-term, respectively. \ud835\udc35 \u2217 \ud835\udc3a , \ud835\udc35 \u2217 \ud835\udc40 , \ud835\udc35 \u2217 \ud835\udc46 and \ud835\udc35 \u2217 \ud835\udc3f are obtained by truncating the lengths of the sub-sequences to dozens, and aligning the dimensions through linear projection [25]. The spatial-temporal interaction can be formulated as: where \ud835\udc50\ud835\udc5f\ud835\udc5c\ud835\udc60\ud835\udc60 is the set of operations including element-wise multiplication, subtraction, and addition. The \ud835\udc48 \u2217 \ud835\udc3c is the integrated user representation by concatenating \ud835\udc35 \u2217 \ud835\udc56 . Let \ud835\udc44 \ud835\udc3a , \ud835\udc44 \ud835\udc40 , \ud835\udc44 \ud835\udc46 and \ud835\udc44 \ud835\udc3f be the query with respect to these sub-sequences, we can also obtain the integrated query representation \ud835\udc44 \u2217 \ud835\udc3c , in a similar way to \ud835\udc48 \u2217 \ud835\udc3c . Then we take advantage of multi-head attention to capture the comprehensive spatial-temporal interest representation between \ud835\udc48 \u2217 \ud835\udc3c and \ud835\udc44 \u2217 \ud835\udc3c by using the formulations shown in Eq. (5-7). Both the output of Fragment Network and Integrate Network are concatenated as the final representation of user spatial-temporal interest for CTR prediction.", "4 EXPERIMENTS": "In this section, we present our experiments in detail, including the datasets, compared models, implementation details, and some corresponding analyses. The proposed FIN is compared with several state-of-the-art works on two public datasets and one industrial dataset as shown in Table 1. To demonstrate the practicality and scalability of the proposed method, we utilize category, price buckets, and geohash information to represent the spatial-temporal information on public datasets. We also conduct careful online A/B testing, with a comparison of several SOTA industry models.", "4.1 Experimental Settings": "Datasets. The statistical metrics of all datasets is shown in Table 1. Amazon dataset 5 consists of product reviews and metadata from Amazon [10]. We use the Books subset, and choose price data equifrequency binned with a total of 48 bins and category data to represent the spatial-temporal information. We create corresponding user behavior sequences, and randomly select 80% of the samples as the training set and 20% of the samples as the test set, following previous works [21, 22]. Google Local dataset 6 consists of review information and business metadata from Google Maps [16]. We use the New York subset, and encode the latitude and longitude data into 5-digit alphanumeric string (geohash5) with a total of 4223 geohash5. Then Geohash5 and category data are chosen as the spatial-temporal information. The following dataset preprocessing steps are the same as the Amazon dataset. Industrial dataset is collected from the Ele.me online recommendation advertising system. Samples are constructed from impression logs, with 'click' or 'not' as the label. Two weeks' samples are used for training, while the samples on the following day for testing. Comparing with the e-commerce scenario, we have fewer categories but richer spatial-temporal information. We convert each latitude and longitude data into a 6-digit alphanumeric string (geohash6) with a total of 1.3 million geohash6, and bucket the minute-level data into meal-time periods with a total of 95 time periods. More than 55% of the samples contain user behaviors with lengths exceeding 500. Compared models. We compare our proposed FIN network with mainstream CTR prediction models, including: \u00b7 DIN [32] is a method that models short-term user behavior using attention. \u00b7 Avg-Pooling Long DIN applies average-pooling on longterm behavior and concatenates with DIN output. \u00b7 SIM [22] We choose SIM (hard) instead of SIM (soft) considering their practicality. The embedding of time intervals is added in all models compared on our industrial dataset. \u00b7 ETA [5] is an end-to-end long sequence modeling method based on the LSH method. \u00b7 StEN [19] is a spatial-temporal model based on user behavior with time periods and location information. \u00b7 FIN models the specific spatial-temporal representation in FN and the comprehensive spatial-temporal representation in IN. Implementation details. All models are trained with Adam [13], the learning rate is set to 0.001. We model the behavior sequence using multi-head attention, the number of heads is set to 4. Layers of fully connected network (FCN) are set by 200 \u00d7 80 \u00d7 2, same as previous works [21, 22]. The number of embedding dimension is set to 4. We choose widely-used AUC as model performance measurement metrics.", "4.2 Results on Public Datasets": "Table 2 shows the results of all the compared models. Compared with DIN, Avg-Pooling Long DIN performs better, demonstrating that long-term user behavior is helpful. SIM and ETA outperform Avg-Pooling Long DIN, proving that using multi-head attention is more effective to model user behavior sequences. Compared with SIM and ETA, StEN performs better, indicating that the performance of the two sub-sequences extracted by spatial-temporal information is superior to single sub-sequence modeled exactly. Compared with StEN, FIN achieves significant performance improvement, because StEN drops part of sequence information and tends to ignore the spatial-temporal interaction between multiple sub-sequences. The experimental results have demonstrated that FIN outperforms all other models. Ablation study. We evaluate the effectiveness of the proposed FIN network by applying different operators to long sequential behavior. As shown in Table 3, both StEN and our proposed Simplified attention outperform SIM. The performance of FN is better than StEN, demonstrating the effectiveness of long-term de-duplicate sub-sequence in FN. Finally, the proposed FIN achieves further performance improvement than FN, demonstrating that the spatialtemporal interaction between multiple sub-sequences can bring rich information gain.", "4.3 Results on Industrial Dataset": "We further conduct experiments on the dataset collected from the online recommendation advertising system of Ele.me. All models first take Short-term sub-sequence as one of inputs. SIM is the model based on Geohash-block sub-sequence. The K value is set to 64 in ETA. StEN models the Geohash-block sub-sequence and Mealtime sub-sequence. Table 4 shows the results, StEN outperforms SIM and ETA, demonstrating the importance of spatial-temporal information in our online food ordering scenario. FIN performs better than StEN, proving that our spatial-temporal modeling with the fragment and integrate network is significantly more effective to capture users' interest on various restaurants. Compared with SIM, FIN achieves an AUC increase of 0.0066, which is significant for our business. Online A/B Testing. Since 2022, we have deployed our proposed FIN in the recommendation advertising system of Ele.me. From June 17, 2022 to August 1, 2022, we conduct a rigorous online A/B testing experiment to validate the proposed model. Compared to SIM (our last product base model), FIN achieves significantly higher gain in terms of CTR and RPM in the recommendation advertising scene, which shows in Table 5. Since August 2022, FIN serves the main scene traffic every day, which contributes significant business revenue growth. Case Study. The proposed FIN performs well in both offline and online evaluations. Will FIN be able to rank items according to the user's current spatial-temporal interest? After the online A/B testing, we analyze the collected click samples from FIN and SIM. FIN introduces temporal interaction information on the basis of spatial information. We analyze the improvement of several typical categories in different time periods, as shown in Figure 3 (the vertical axis values are not clearly indicated, considering commercial data privacy). For the category of milk tea and fruit juice, both the matching efficiency (RPM) and Exposure are improved during the periods of afternoon tea and dinner. For the category of marinated cooked food, the Exposure during the periods of lunch and afternoon tea is greatly improved while ensuring RPM, bringing merchants more orders. For the category of convenience store, the RPM and Exposure during the late night snack period are greatly improved, while the Exposure during the periods of lunch is suppressed. This analysis testifies that FIN does recommend the user relevant items under his current spatial-temporal circumstances. afternoon tea dinner lunch afternoon tea lunch night snack milk tea&fruit juice milk tea&fruit juice marinated cooked marinated cooked convenience store convenience store Impr of Exposure Impr of RPM Practical Experience For Deployment. Here we introduce our practical experience of implementing FIN in our online service system. In Ele.me, the QPS during the lunch peak period can reach up to ten thousand. Real-Time Prediction (RTP) system predicts CTR for hundreds of items in dozens of milliseconds. We decouple realtime behavior data and offline behavior data, so that the real-time behavior data can be updated in seconds, keeping offline behavior data updated daily. The complete behavior sequence is built by combining the real-time behavior data and offline behavior data together in the online service system. The Short-term sub-sequence is consisted of recent dozens of behaviors from the last few days, Geohash-block sub-sequence, Meal-time sub-sequence and Longterm de-duplicate sub-sequence include hundreds of behaviors from the last 12 months, respectively. Furthermore, we optimize the calculation efficiency of multi-head attention in FIN by deep kernel fusion and address the kernel launch overhead issue with CUDA Graph optimization.", "5 CONCLUSIONS": "In this paper, we propose a novel spatial-temporal model based on long sequential behavior data to capture the diverse intent representation of user interest in complex spatial-temporal contexts. We have implemented the proposed FIN in the recommendation advertising system of Ele.me and have brought significant business improvements. We believe that this work will bring new inspiration to spatial-temporal modeling and long behavior sequence modeling. In the future, we will continue to develop spatial-temporal models for various types of user behaviors, such as search behaviors and exposure-unclicked behaviors in the diverse spatial-temporal contexts.", "ACKNOWLEDGMENTS": "The authors would like to thank Jingjing Duan, Xufeng He, Dawei Wang, Lingbao Ye, Juanjuan Li, Weijie Zhuang, Jiajia Shi, Jianghua Ye who did effective optimization work for online deployment.", "REFERENCES": "[1] Deepak Agarwal, Bee-Chung Chen, and Pradheep Elango. 2009. Spatio-temporal models for estimating click-through rate. WWW'09 - Proceedings of the 18th International World Wide Web Conference , 21-30. https://doi.org/10.1145/1526709. 1526713 [2] Weijie Bian, Kailun Wu, Lejian Ren, Qi Pi, Yujing Zhang, Can Xiao, Xiang-Rong Sheng, Yong-Nan Zhu, Zhangming Chan, Na Mou, Xinchen Luo, Shiming Xiang, Guorui Zhou, Xiaoqiang Zhu, and Hongbo Deng. 2021. CAN: Feature Co-Action for Click-Through Rate Prediction. arXiv:2011.05625 [cs.IR] [3] Yue Cao, XiaoJiang Zhou, Jiaqi Feng, Peihao Huang, Yao Xiao, Dayao Chen, and Sheng Chen. 2022. Sampling Is All You Need on Modeling Long-Term User Behaviors for CTR Prediction. arXiv:2205.10249 [cs.IR] [4] Jianxin Chang, Chenbin Zhang, Zhiyi Fu, Xiaoxue Zang, Lin Guan, Jing Lu, Yiqun Hui, Dewei Leng, Yanan Niu, Yang Song, and Kun Gai. 2023. TWIN: TWo-stage Interest Network for Lifelong User Behavior Modeling in CTR Prediction at Kuaishou. arXiv:2302.02352 [cs.IR] [5] Qiwei Chen, Changhua Pei, Shanshan Lv, Chao Li, Junfeng Ge, and Wenwu Ou. 2021. End-to-End User Behavior Retrieval in Click-Through RatePrediction Model. CoRR abs/2108.04468 (2021). arXiv:2108.04468 https://arxiv.org/abs/2108.04468 [6] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, Rohan Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah. 2016. Wide & Deep Learning for Recommender Systems. CoRR abs/1606.07792 (2016). arXiv:1606.07792 http://arxiv.org/abs/1606.07792 [7] Boya Du, Shaochuan Lin, Jiong Gao, Xiyu Ji, Mengya Wang, Taotao Zhou, Hengxu He, Jia Jia, and Ning Hu. 2022. BASM: A Bottom-up Adaptive Spatiotemporal Model for Online Food Ordering Service. arXiv:2211.12033 [cs.LG] [8] Yufei Feng, Fuyu Lv, Weichen Shen, Menghan Wang, Fei Sun, Yu Zhu, and Keping Yang. 2019. Deep Session Interest Network for Click-Through Rate Prediction. arXiv:1905.06482 [cs.IR] [9] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction. arXiv:1703.04247 [cs.IR] [10] Ruining He and Julian McAuley. 2016. Ups and Downs. In Proceedings of the 25th International Conference on World Wide Web . International World Wide Web Conferences Steering Committee. https://doi.org/10.1145/2872427.2883037 [11] Weizhe Hua, Zihang Dai, Hanxiao Liu, and Quoc V. Le. 2022. Transformer Quality in Linear Time. arXiv:2202.10447 [cs.LG] [12] Bumjun Jung, Yusuke Mukuta, and Tatsuya Harada. 2022. Grouped self-attention mechanism for a memory-efficient Transformer. arXiv:2210.00440 [cs.LG] [13] Diederik P. Kingma and Jimmy Ba. 2017. Adam: A Method for Stochastic Optimization. arXiv:1412.6980 [cs.LG] [14] Sotiris B. Kotsiantis and Dimitris N. Kanellopoulos. 2006. Discretization Techniques: A recent survey. [15] Chao Li, Zhiyuan Liu, Mengmeng Wu, Yuchi Xu, Pipei Huang, Huan Zhao, Guoliang Kang, Qiwei Chen, Wei Li, and Dik Lun Lee. 2019. Multi-Interest Network with Dynamic Routing for Recommendation at Tmall. arXiv:1904.08030 [cs.IR] [16] Jiacheng Li, Jingbo Shang, and Julian McAuley. 2022. UCTopic: Unsupervised Contrastive Learning for Phrase Representations and Topic Mining. arXiv:2202.13469 [cs.CL] [17] Yinfeng Li, Chen Gao, Xiaoyi Du, Huazhou Wei, Hengliang Luo, Depeng Jin, and Yong Li. 2022. Spatiotemporal-Aware Session-Based Recommendation with Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Graph Neural Networks (CIKM '22) . Association for Computing Machinery, New York, NY, USA, 1209-1218. https://doi.org/10.1145/3511808.3557458 [18] Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018. xDeepFM. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining . ACM. https: //doi.org/10.1145/3219819.3220023 [19] Shaochuan Lin, Yicong Yu, Xiyu Ji, Taotao Zhou, Hengxu He, Zisen Sang, Jia Jia, Guodong Cao, and Ning Hu. 2022. Spatiotemporal-Enhanced Network for ClickThrough Rate Prediction in Location-based Services. arXiv:2209.09427 [cs.IR] [20] Wentao Ouyang, Xiuwu Zhang, Li Li, Heng Zou, Xin Xing, Zhaojie Liu, and Yanlong Du. 2019. Deep Spatio-Temporal Neural Networks for Click-Through Rate Prediction. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining . ACM. https://doi.org/10.1145/ 3292500.3330655 [21] Qi Pi, Weijie Bian, Guorui Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Practice on Long Sequential User Behavior Modeling for Click-Through Rate Prediction. CoRR abs/1905.09248 (2019). arXiv:1905.09248 http://arxiv.org/abs/1905.09248 [22] Qi Pi, Xiaoqiang Zhu, Guorui Zhou, Yujing Zhang, Zhe Wang, Lejian Ren, Ying Fan, and Kun Gai. 2020. Search-based User Interest Modeling with Lifelong Sequential Behavior Data for Click-Through Rate Prediction. CoRR abs/2006.05639 (2020). arXiv:2006.05639 https://arxiv.org/abs/2006.05639 [23] Yi Qi, Ke Hu, Bo Zhang, Jia Cheng, and Jun Lei. 2021. Trilateral Spatiotemporal Attention Network for User Behavior Modeling in Location-Based Search. In Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management (Virtual Event, Queensland, Australia) (CIKM '21) . Association for Computing Machinery, New York, NY, USA, 3373-3377. https: //doi.org/10.1145/3459637.3482206 [24] Jiarui Qin, Weinan Zhang, Xin Wu, Jiarui Jin, Yuchen Fang, and Yong Yu. 2020. User Behavior Retrieval for Click-Through Rate Prediction. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval . ACM. https://doi.org/10.1145/3397271.3401440 [25] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention Is All You Need. CoRR abs/1706.03762 (2017). arXiv:1706.03762 http://arxiv.org/abs/ 1706.03762 [26] Daheng Wang, Meng Jiang, Munira Syed, Oliver Conway, Vishal Juneja, Sriram Subramanian, and Nitesh V. Chawla. 2020. Calendar Graph Neural Networks for Modeling Time Structures in Spatiotemporal User Behaviors. arXiv:2006.06820 [cs.LG] [27] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep & Cross Network for Ad Click Predictions. arXiv:1708.05123 [cs.LG] [28] Shoujin Wang, Liang Hu, Yan Wang, Longbing Cao, Quan Z. Sheng, and Mehmet Orgun. 2019. Sequential Recommender Systems: Challenges, Progress and Prospects. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence . International Joint Conferences on Artificial Intelligence Organization. https://doi.org/10.24963/ijcai.2019/883 [29] Haifeng Yang, Linjing Yao, Jianghui Cai, Yupeng Wang, and Xujun Zhao. 2023. A new interest extraction method based on multi-head attention mechanism for CTR prediction. Knowledge and Information Systems (04 2023), 1-16. https: //doi.org/10.1007/s10115-023-01867-w [30] Zeping Yu, Jianxun Lian, Ahmad Mahmoody, Gongshen Liu, and Xing Xie. 2019. Adaptive User Modeling with Long and Short-Term Preferences for Personalized Recommendation. In Proceedings of the 28th International Joint Conference on Artificial Intelligence (Macao, China) (IJCAI'19) . AAAI Press, 4213-4219. [31] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. 2018. Deep Interest Evolution Network for Click-Through Rate Prediction. arXiv:1809.03672 [stat.ML] [32] Guorui Zhou, Chengru Song, Xiaoqiang Zhu, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep Interest Network for Click-Through Rate Prediction. arXiv:1706.06978 [stat.ML]"}
