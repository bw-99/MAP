{
  "Enhancing Cross-Domain Click-Through Rate Prediction via Explicit Feature Augmentation": "Xu Chen, Zida Cheng, Jiangchao Yao, Chen Ju, Weilin Huang, Jinsong Lan, Xiaoyi Zeng, Shuai Xiao âˆ— {huaisong.cx,chengzida.czd,weilin.hwl,jinsonglan.ljs,yuanhan,shuai.xsh}@taobao.com,{sunarker,ju_chen}@sjtu.edu.cn Alibaba Group and Shanghai Jiao Tong University China",
  "ABSTRACT": "",
  "KEYWORDS": "Cross-domain CTR (CDCTR) prediction is an important research topic that studies how to leverage meaningful data from a related domain to help CTR prediction in target domain. Most existing CDCTR works design implicit ways to transfer knowledge across domains such as parameter-sharing that regularizes the model training in target domain. More effectively, recent researchers propose explicit techniques to extract user interest knowledge and transfer this knowledge to target domain. However, the proposed method mainly faces two issues: 1) it usually requires a super domain, i.e. an extremely large source domain, to cover most users or items of target domain, and 2) the extracted user interest knowledge is static no matter what the context is in target domain. These limitations motivate us to develop a more flexible and efficient technique to explicitly transfer knowledge. In this work, we propose a cross-domain augmentation network (CDAnet) being able to perform explicit knowledge transfer between two domains. Specifically, CDAnet contains a designed translation network and an augmentation network which are trained sequentially. The translation network computes latent features from two domains and learns meaningful cross-domain knowledge of each input in target domain by using a designed cross-supervised feature translator. Later the augmentation network employs the explicit cross-domain knowledge as augmented information to boost the target domain CTR prediction. Through extensive experiments on two public benchmarks and one industrial production dataset, we show CDAnet can learn meaningful translated features and largely improve the performance of CTR prediction. CDAnet has been conducted online A/B test in image2product retrieval at Taobao app, bringing an absolute 0.11 point CTR improvement, a relative 0.64% deal growth and a relative 1.26% GMV increase.",
  "CCS CONCEPTS": "Â· Information systems â†’ Retrieval models and ranking . âˆ— corresponding author Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference WWW 2024, May 13-17, 2024, Singapore Â© 2024 Association for Computing Machinery. ACM ISBN xxx-x-xxxx-XXXX-X/xx/xx...$15.00 https://doi.org/XXXXXXX.XXXXXXX feature translation, cross-domain CTR prediction,explicit feature augmentation",
  "ACMReference Format:": "Xu Chen, Zida Cheng, Jiangchao Yao, Chen Ju, Weilin Huang, Jinsong Lan, Xiaoyi Zeng, Shuai Xiao. 2024. Enhancing Cross-Domain Click-Through Rate Prediction via Explicit Feature Augmentation. In Proceedings of The Web Conference (Conference WWW 2024). ACM, New York, NY, USA, 10 pages. https://doi.org/XXXXXXX.XXXXXXX",
  "1 INTRODUCTION": "Click-through rate (CTR) prediction which estimates the probability of a user clicking on a candidate item, has a vital role in online services like recommendation, retrieval, and advertising [3, 16, 37]. It has been pointed out that data sparsity is a key issue that significantly limits the improvement of single-domain CTR models [10], and recent effort has been devoted to improving the target domain CTR models by leveraging data from other related domains [10, 12, 17, 22, 35]. Various cross-domain CTR prediction (CDCTR) methods have recently been developed, which can be roughly categorized into two groups: joint training and pre-training & fine-tuning . The joint training approach is developed by combining multiple CTR objectives from different domains into a single optimization process. It usually has shared parameters to build connections, and transfer the learned knowledge across different domains like MiNet [17], DDTCDR [11] and STAR [22]. However, since two domains usually have different objectives in optimization, these methods usually suffer from an optimization conflict problem, which might lead to a negative transfer result [21, 24]. To deal with this issue, a number of recent approaches study more advanced mixture-of-expert [15, 33] parameter-sharing technique for jointly optimizing CDCTR objectives [14, 23, 23]. Further, researchers believe that the knowledge are encoded in the network parameters and they propose many pre-training & fine-tuning models for CDCTR. The pre-training & fine-tuning method [12, 35] often has two stages, by training a CTR model sequentially in a source domain and then in a target domain, where the performance in the target domain can be generally improved by leveraging model parameters pre-trained from the source domain. This two-stage learning style enables the model to have only one objective at each training stage, which significantly reduces the impact of negative transfer. It is also parameter-efficient and has been widely applied at Taobao platform. Especially for KEEP [35], it first extracts user interest knowledge from super domain which is an extremely large domain that covers most users or items in target domain. Then, with the knowledge extraction module frozen, it feeds the knowledge to target click prediction Conference WWW 2024, May 13-17, 2024, Singapore Xu Chen et al. model by a plug-in network. KEEP provides a good way to utilize the huge knowledge in super-domain and has achieved remarkable performance in industrial applications. Importantly, most of the above methods actually design different implicit ways to transfer knowledge. The employed parametersharing technique in both joint training and pre-training & finetuning can regularize the target model's parameter learning, and enable the target model to have less probability of over-fitting suspicious features. Recent researchers designed explicit ways to more efficiently transfer knowledge. For example, KEEP [35] explicitly extracts user interests and feeds these interests into the downstream target model for CTR prediction. However, it still has two limitations. 1) Super-domain data requirement : The model requires a super-domain that covers most users or items over the target domain so that the extracted user interests could be statistically useful in the target model learning, which is not always easily met in many business cases. 2) Static user interest : The extracted user interest keeps unchanged for the target domain model even when the user is in different contexts ( e.g. item features, page statistic features). While static user interests under different contexts could result in inferior performance and context-aware user interest enables the model to better capture different importance of input features [5, 25]. These motivates us to design a more flexible and efficient method to make explicit knowledge transfer for CDCTR. In this work, we propose novel cross-domain augmentation networks (CDAnet), which explicitly transfers knowledge from source domain to target domain. CDAnet is performed sequentially by first explicitly learning cross-domain knowledge and then encoding the learned knowledge into the target model via cross-domain augmentation. Specifically, a translation network is designed to encode the inputs (including user features, item features, etc.) from different domains, and learn feature translation in latent space via a designed cross-supervised feature translator. Then cross-domain augmentation is performed in the augmentation network by augmenting target domain samples in latent space with their additional translated latent features. This explicitly encodes the knowledge learned from the source domain, providing diverse yet meaningful additional view information of each input in target domain and improving the fine-tuning on target model. When performing translation learning, CDAnet has no overlap requirement on users or items between domains, and thus has no super-domain data requirement , providing more flexible usage. Moreover, the inputs including various features of target domain are together translated in translation network, and thus user interest is context-aware in target model fine-tuning, exerting more efficient knowledge transfer. Through experiments, we demonstrate that CDAnet can largely improve the performance of CTR prediction, and it has been conducted online A/B test in image2product retrieval at Taobao app, bringing an absolute 0.11 point CTR improvement, with a relative 0.64% deal growth and a relative 1.26% GMV increase. It has been successfully deployed online, serving hundreds of millions of consumers. In a nutshell, the contributions of this work are summarized as follows: Â· We advocate to enhance CDCTR with explicit feature augmentation and propose CDAnet consisting of a designed translation network and an augmentation network. CDAnet explicitly translates the input of target domain into source domain as additional view information, and employ this information as augmented features to boost the target domain model training. Â· Extensive experiments on various datasets demonstrate the effectiveness of the proposed method. Our CDAnet has been deployed in image2product retrieval at Taobao app, and achieved obvious improvements on CTR, deal and GMV. Through empirical studies, we show that CDAnet is able to learn meaningful translated features for boosted CTR improvement.",
  "2 RELATED WORK": "Single-domain CTR : Click-through rate (CTR) prediction plays a vital role in various online services, such as modern search engines, recommendation systems and online advertising. Previous works usually combine logistic regression [20] and feature engineering for CTR prediction. These methods often lack the ability to model sophisticated feature interactions, and heavily rely on human labor of designing features. With the excellent feature learning ability of deep neural networks (DNN), deep learning approaches have been extensively studied on CTR prediction, and recent works focus on applying DNN for learning feature interactions [3, 4, 26]. For example, Cheng et al. [3] combined shallow linear models and deep non-linear networks to capture both low and high-order features, while the power of factorization machine [19] and deep networks are combined for CTR prediction in [4]. Wang et al. [26] designed a deep & cross network to learn bounded-degree feature interactions. Further, some works study how to model richer information for CTR tasks. For instance, DIN [37] and DIEN [36] were proposed to capture user interests based on historical click behaviors, and DSTN [16] takes contextual ads when modeling user behaviors. Cross-domain CTR : Single-domain CTR prediction suffers from a data sparsity issue because user behaviors in a real-world system are usually extremely sparse and have single-domain data bias. Accordingly, cross-domain CTR prediction is developed to leverage user behaviors in a relevant but data-rich domain, i.e. source domain, to facilitate learning in the target domain. A joint learning method was recently developed and has become a representative approach for cross-domain CTR. For example, STAR [22] is a star topology model that contains a centered network shared by different domains, with multiple domain-specific networks tailored for each domain. In MiNet [17], Ouyang et al. attempted to explore auxiliary data ( e.g. historical user behaviors and ad title) from a source domain to improve the performance of a target domain. Meanwhile, a number of cross-domain recommendation (CDR) methods have been developed [2, 6, 11, 32], which can be naturally introduced to cross-domain CTR problems. For instance, in DDTCDR [11], Li et al. proposed a deep dual transfer network that can bi-directionally transfer information across domains in an iterative style. However, when such models benefit from sharing parameters to transfer knowledge, they meanwhile face the problem of gradient interference issue [21, 28, 31] because they have two different CTR objectives during joint learning. To handle the issue, MMOE [14] employs a more advanced shared mixture-of-expert model, which allows for automatically allocating Enhancing Cross-Domain Click-Through Rate Prediction via Explicit Feature Augmentation Conference WWW 2024, May 13-17, 2024, Singapore model parameters and alleviating task conflicts in optimization. To decouple learning task-specific and task-shared information more explicitly, PLE [23] separates the network of task-shared components and task-specific components, and then adopts a progressive routing mechanism being able to extract and separate deeper semantic knowledge gradually. Further, Zhang et al. [34] highlighted that different source domains should contribute differently to the target domain when transferring knowledge. Then, they proposed CCTLthat could evaluate the information gain of the source domain on the target domain and adjust the information transfer weight of each source domain. Different from joint training , pre-training & fine-tuning is a twostage learning paradigm. In pre-training stage, a model is first trained in a source domain. Then in fine-tuning stage, a target model would load the pre-trained model parameters, and then finetune itself for target domain CTR prediction. In each stage, only one objective is used for optimization, and thus the gradient interference issue can be alleviated to some extent. This method has been widely-applied in industrial systems [1, 12, 29, 35]. In CTNet [12], Liu et al. focus on the CDCTR problem in a time-evolving scenario. The heterogeneous multi-scenario knowledge transfer problem is studied in [7]. Zhang et al. proposed KEEP [35] which is a two-stage framework that consists of a supervised pre-training knowledge extraction module performing on web-scale and long-time source domain data ( i.e. super domain), and a plug-in network that incorporates the extracted knowledge into the downstream target fine-tuning model. Different from KEEP, the proposed CDAnet, explicitly learns knowledge transfer across domains without requiring super-domain data and with context-aware user interest transferring.",
  "3 METHOD": "",
  "3.1 Preliminary": "In CDCTR prediction, given source domain S , we have its training samples ( ğ’™ ğ’” , ğ‘¦ ğ‘  ) where ğ’™ ğ’” âˆˆ R ğ¹ ğ‘  Ã— 1 denotes the input features and ğ‘¦ ğ‘  âˆˆ { 0 , 1 } is the click label ( i.e. 1 means click while 0 means nonclick). Similarly, we have the target domain T and its training samples ( ğ’™ ğ’• , ğ‘¦ ğ‘¡ ) in which ğ‘¦ ğ‘¡ âˆˆ { 0 , 1 } is the click label in target domain and ğ’™ ğ’• âˆˆ R ğ¹ ğ‘¡ Ã— 1 is the input features. ğ¹ ğ‘  and ğ¹ ğ‘¡ denote the input feature dimension of source and target domain, respectively. The goal is to transfer knowledge from source domain to target domain and improve the target domain CTR prediction. In the proposed CDAnet, there are two sequentially learned networks: translation network and augmentation network. First, the translation network encodes the inputs as latent features and learns how the latent features are translated by a designed crosssupervised feature translator. Then, the pre-trained parameters of translation network are transferred to the augmentation network. Next, the augmentation network will combine the translated latent features and the original latent features of target domain samples together to augment the target domain model training. The model architecture is shown in Figure 1. Details about each module are demonstrated in the following parts.",
  "3.2 Translation Network": "The translation network aims to learn latent feature translation between source domain and target domain. It has four parts including embedding layer, feature extractor, cross-supervised feature translator and prediction tower. Embedding Layer : The embedding layer aims to encode the various input features from different domains as embeddings. In the embedding layer, overlapped feature fields have shared sub-embedding parts while non-overlapped feature fields use non-shared sub-embedding parts. We briefly denote the the whole embedding layer as ğ¸ for simplicity. Given the inputs ğ’™ ğ’” of source domain and ğ’™ ğ’• of the target domain, we have:  where ğ’† ğ’” âˆˆ R ğ‘‘ Ã— 1 and ğ’† ğ’• âˆˆ R ğ‘‘ Ã— 1 are the embedding features of ğ’™ ğ’” and ğ’™ ğ’• , respectively. ğ‘‘ is the embedding dimension. Feature Extractor : After embedding layer, CTR prediction usually has feature extraction module to capture high-order feature interactions for user behavior modeling. In CDCTR, we similarly have this feature extraction module and it can be fused with some transfer learning techniques such as vanilla shared MLP in [22, 35] and mixture-of-expert in [14, 23] that implicitly transfer knowledge across domains. The vanilla shared MLP has the advantage of simplicity and low computation complexity but may have the risk of gradient interference issue when optimizing different objectives. The mixture-of-expert technique can alleviate this gradient interference issue but has higher computation complexity. Our CDAnet is flexible on the choice of feature extractor such as shared MLP or mixture-of-expert, which means it could be combined with existing implicit knowledge transfer techniques. To make an easy demonstration, we denote the feature extractor of source domain and target domain as ğ¹ ğ‘  and ğ¹ ğ‘¡ , respectively. Then, we have:  where ğ’› ğ’” âˆˆ R ğ‘‘ and ğ’› ğ’• âˆˆ R ğ‘‘ are extracted latent features of source domain and target domain, respectively. Note ğ¹ ğ‘  and ğ¹ ğ‘¡ could be independent, i.e. no transfer technique between ğ¹ ğ‘  and ğ¹ ğ‘¡ , or they could be related by some transfer techniques such as MMOE [14]. Cross-supervised Feature Translator : After obtaining the latent features of each domain, we propose a cross-supervised translator to learn the latent feature translation, which is inspired by image2image translation [8, 9, 13, 18, 30, 38]. In image2image translation, images from target domain are translated as the images in the source domain, supervised by the true images in source domain. Whereas in CDCTR, the sample ( i.e. combined user feature and item feature) in the target domain should not share the user behavior label with a sample in the source domain, because these two samples do not have paired relationship. Remark. Instead, a widely held belief in CDCTR is that if a user favors an item in the target domain, the favor behavior is preserved if the user and item are mapped into the source domain as corresponding features. For example, if a user likes science movies, he or she will also tend to love science novels. This indicates that a target domain sample should preserve its target domain label when this sample is translated as corresponding features in source domain. Conference WWW 2024, May 13-17, 2024, Singapore Xu Chen et al. Figure 1: The architecture of our cross-domain augmentation networks (CDAnet). At the translation stage, the translation network encodes the inputs from two domains as latent features by two feature extractors, and then learns the feature translator. The two extractors could be independent which means no additional feature transfer technique between them. Or we can use some parameter-sharing techniques [14, 17, 22, 23] to additionally introduce implicit feature transfer ways. The feature translator learns to translate latent feature between two spaces. At the augmentation stage, translation network parameters except the tower layer are reused. The augmentation network takes the target domain samples and their translated latent features together to boost the target model training. âŠ• denotes the concatenation operation. Note that the embedding layer is a simplified plot. When two domains have non-overlapped feature fields, we use different sub-embedding layer. sale volume price item image gender age query image sale volume seller item title gender age query text feature learning prediction tower translator ğ‘§ ! ğ‘§ \" latent features ğ‘¦ ! ğ‘¦ \" Translation Network ğ‘§ ! â€² ğ‘§ \" â€² embedding layer cross-supervised feature translator translator Source CTR feature extractor Target CTR feature extractor with or without feature transfer parameter transfer ğ‘§ \" ğ‘§ \" â€² ğ‘§ ! ğ‘§ ! â€² source domain target domain ğ‘§ \" latent features ğ‘¦ ! Augmentation Network ğ‘§ \" â€² + embedding layer new prediction tower cross-supervised translator sale volume price item image gender age query image Target CTR feature extractor feature learning translator In other words, given the latent feature ğ’› ğ’• of target domain, we aim to translate it into source domain as ğ’› â€² ğ’• while preserving the content of ğ’› ğ’• . Then, ğ’› â€² ğ’• can be taken into the prediction tower of source domain while supervised by the target domain label ğ‘¦ ğ‘¡ . Let ğ‘¾ ğ’•ğ’“ğ’‚ğ’ ğ’• âˆˆ R ğ‘‘ Ã— ğ‘‘ be the translator of target domain and ğµğ¶ğ¸ be the binary cross entropy loss, then the translator of target domain is optimized by:  where ğœ is the sigmoid function and ğ‘… ğ‘  is the prediction tower of source domain that maps latent feature into prediction logit. To stabilize the training, we have the symmetric formulation for source domain like Eq. 3 as:  where ğ‘… ğ‘¡ is the prediction tower of target domain and ğ‘¾ ğ’•ğ’“ğ’‚ğ’ ğ’” âˆˆ R ğ‘‘ Ã— ğ‘‘ is the translator of source domain. The network architecture of ğ‘… ğ‘  and ğ‘… ğ‘¡ is the commonly used MLP layers. In order to better conduct the latent feature translation, apart from the above cross supervision, we add an orthogonal mapping constraint on the translators ğ‘¾ ğ’•ğ’“ğ’‚ğ’ ğ’” and ğ‘¾ ğ’•ğ’“ğ’‚ğ’ ğ’• as:  where T is the transpose operation. The orthogonal transformation in mathematics has a characteristic that can preserve lengths and angles between vectors. Therefore, the orthogonal mapping constraint in Eq. 5 can help the latent features ğ’› ğ’• of different samples preserve the similarity and avoid a case where multiple ğ’› ğ’• collapse to a single point after translation. 3.2.1 Objective Function in Translation. Apart from the above objective of learning translator, we still need the vanilla objective for optimizing the CTR task in each domain. Namely, the vanilla CTR objectives of source and target domain are formulated as:  Remark . These two objectives help the model learn the network parameters ( e.g. the tower network) targeted for CTR prediction. Meanwhile, when the tower networks are optimized for each domain's CTR prediction, the translators can adapt to the tower networks and learn feature translation in a meaningful and right direction. To sum up, the objective of translation network is:  where ğ›¼ and ğ›½ are hyper-parameters on loss weights.",
  "3.3 Augmentation Network": "The augmentation network exploits the previously learned feature translator to augment the target model's fine-tuning for boosted CTR performance. In particular, we would first transfer the network parameters including the embedding layer, the feature extractor module and the translator to the augmentation network. As shown in Figure 1, in order to enable learning flexibility for augmentation network and adapt to the feature shift between two stages, the prediction tower is newly initialized rather than coming from the translation network. Then, given a target domain training sample, Enhancing Cross-Domain Click-Through Rate Prediction via Explicit Feature Augmentation Conference WWW 2024, May 13-17, 2024, Singapore Table 1: The statistics of datasets. we can combine its original latent feature ğ’› ğ’• and the additional translated latent feature ğ’› â€² ğ’• to conduct cross-domain augmentation for the target model's fine-tuning. Cross-domain Augmentation : In cross-domain augmentation, the augmented latent feature of target domain is formulated as:  where âŠ• denotes the concatenation operation. Also, when caring about the augmentation in source domain, the augmented feature can be obtained in a similar formula. Objective Function in Augmentation With the augmented latent feature ğ’› ğ’‚ğ’–ğ’ˆ ğ’• , we would feed it into the new prediction tower ğ‘… ğ‘ğ‘¢ğ‘” ğ‘¡ and use the vanilla CTR objective for fine-tuning. The objective is defined as:  In this augmentation stage, the model has only one CTR objective and can avoid the optimization conflict problem in multi-objective models. When focusing on the performance of source domain, its augmentation network can be optimized in a similar way. The constraint in Eq. 5 also works here with the same ğ›½ as in Eq. 7. Discussion. Considering the technique in knowledge transfer, the joint training works [6, 14, 22, 23] and fine-tuning methods [12, 17, 35] mainly employ different parameter-sharing techniques to regularize the target model training [6, 11, 14, 32, 35] and implicitly learn the knowledge from source domain. To achieve more efficient knowledge transfer, KEEP [35] introduces a way to explicitly extract the knowledge from source domain, but it is limited in requiring super-domain data and learning static user interests. By contrast, the proposed CDAnet explicitly learns knowledge transfer by a novel translation then augmentation idea. It has no super-domain data requirement and enables context-aware user interest transfer, which shows its flexibility and efficiency . Moreover, CDAnet is compatible with the parameter-sharing technique to achieve more flexible usage and better performance in different scenarios.",
  "4 EXPERIMENTS AND ANALYSIS": "",
  "4.1 Experiment Setup": "4.1.1 Datasets. We first conduct our experiments on two public benchmarks: Amazon 1 and Taobao 23 . For Amazon, we choose two largest domains-movie and book to conduct experiments. In movie domain, we have user ID, movie ID, movie genre, movie director and movie name information. While in book domain, we have user ID, book ID, book category, book writer and book name information. 1 https://jmcauley.ucsd.edu/data/amazon/ 2 https://tianchi.aliyun.com/dataset/56 3 https://tianchi.aliyun.com/dataset/649 The original user behaviors are 0-5 ratings and we process ratings larger than 3 as positive feedback and others as negative feedback for CTR prediction. Both movie and book name are processed as vectors by a word2vec Glove-6B model 4 . Taobao dataset contains user-item interactions of advertisement (ad) and recommendation (rec) domain. We consider buy behavior type as positive feedback and no-buy as negative feedback. In ad domain, we get user ID, age, gender, occupation, some other user profile information, ad ID, ad category and ad brand information. In rec domain, we get user ID, item ID and item category information. For both datasets, user and item ID are both embedded as 64-dim features. Other discrete features are processed as one-hot or multi-hot features. The dataset statistics are summarized in Table 1. Furthermore, we also evaluate our model on Alibaba production data and online experiments on Taobao mobile app. In particular, we collect six-month user behaviors in text2product retrieval as source domain data and one-year user behaviors in image2product retrieval as target domain data. The number of train data in text2product is nearly four times larger than that of image2product domain. Both domains contain hundreds of billions of samples and hundreds of input feature fields that are used in our online production system. 4.1.2 Baselines. We adopt different strong algorithms for comparison, including the single domain, joint training and pre-training & fine-tuning methods. The single domain models are: 1) MLP . A deep multi-layer perception (MLP) model is a common and efficient single-domain ranking model in online search and recommendation systems. 2) ShareBottom . It is a multi-task model that shares parameters of the bottom layers. In our implementation, since two domains may have non-overlapped feature fields, we thus only share the embedding parameters of overlapped feature fields and two middle-layer feature mapping parameters. The joint training models are: 3) STAR [22]. STAR is a star topology model that trains a single model to serve all domains by leveraging the data from all domains simultaneously. 4) DDTCDR [11]. It is a deep dual transfer learning model that transfers knowledge between related domains in an iterative manner. 5) MMOE [14]. MMOE implicitly models task relationships for multi-task learning by a shared mixture-of-experts module and task-specific gates. 6) PLE [23]. PLE is a multi-task learning model that separates shared components and task-specific components and adopts a progressive routing mechanism to extract and transfer knowledge. The pre-training & fine-tuning method: 7) KEEP [35]. KEEP is an industrial knowledge extraction and plugging framework for online recommendation 5 . 4.1.3 Parameter Settings. In our experiments on public benchmarks, we split the data into train, validation, and test sets with the common 8:1:1 setting according to chronological order. The experiments are conducted multiple times and the mean value is taken as the model performance. We set the latent feature size as 128 for all models. We use the validation performance as early stop condition and the max number of training epoch is 200. To make a fair comparison, we conduct a grid search of hyper-parameters and the number of layers for all models. On Amazon dataset, ğ›¼ is 4 https://nlp.stanford.edu/projects/glove/ 5 We only use it on the production dataset because the public benchmarks do not have a super domain that covers most users or items of the target domain Conference WWW 2024, May 13-17, 2024, Singapore Xu Chen et al. Table 2: AUC comparison results of different models on Amazon and Taobao. 'CDAnet+IndepMLP' indicates the feature extractor of both domains are independent MLP. 'CDAnet+SharedMLP/PLE/MMOE' means we take shared MLP/PLE/MMOE as the feature extraction module. Table 3: Overall comparison results of different models on ourimage2productdomain.Hereweconsidertext2productas the source domain and image2product domain as the target domain. AUC indicates the offline evaluation metric. CTR, deal number and GMV are online A/B test metrics. Due to the company's regulations, some online metric values of Base model are blinded and denoted as â˜… . We provide the improvement gap of CDAnet. Table 4: Online CTR improvement gap of CDAnet on different views. 'User Group' indicates users are split into different groups according to their consumption power. 'Query Category' indicates the query image category in our business. The improvement gap is measure by 'point' as it in Table 3. 0.01, ğ›½ equals 0.1, the number of experts is 2 and each expert has 2 layers when using mixture-of-experts, the prediction tower has 2 layers including the logit mapping layer. On Taobao dataset, ğ›¼ is 0.03, ğ›½ equals 0.1, the number of experts is 2 and each expert has 2 layers when using mixture-of-experts, and the prediction tower has 3 layers including the logit mapping layer.",
  "4.2 Overall Comparison": "In this part, we make model comparisons with various baselines on different public benchmarks. Meanwhile we study the model performance when the feature extractor is combined with no-parametersharing ( i.e. CDAnet+IndepMLP) and existing implicit knowledge transfer techniques ( i.e. CDAnet+SharedMLP/PLE/MMOE). From Table 2, we observe that CDAnet with different feature extractors generally achieve better performance than other models. First, the joint training models ( i.e. ShareBottom, DDTCDR, MMOE, Table 5: CDAnet's relative improvement gap regarding the exposed product quality (EPQ) score and the deal number at different item price levels. (a) shows CDAnet's relative improvement gap on the EPQ score and (b) indicates the relative improvement gap on deal number. PLE) mainly rely on shared embedding layers for implicit knowledge transfer. Whereas in most real-world cases, there are not many overlapped feature fields across domains and the used benchmarks are in this case. Then, most embedding parameters of these models cannot be shared and the knowledge transfer is largely affected. By contrast, CDAnet relies on the explicitly translated knowledge to augment the target model for transferring, and thus can keep good performance. Second, STAR mainly relies on a centered and domain-shared network to transfer knowledge, which is much less efficient than CDAnet's translation and augmentation idea for explicit knowledge transfer. Third, we see that 'CDAnet+IndepMLP' achieves better performance than 'CDAnet+SharedMLP/MMOE/PLE' on Tabao dataset while not on Amazon dataset. Combining the implicit knowledge transfer techniques with CDAnet on one hand could regularize the model training, but on the other hand may limit the ability of fitting more useful features. The key is which part takes the main position in model learning, and this is usually determined by model architectures and data scenarios. With CDAnet, we can flexibly choose feature extractors to adapt to the data scenarios and achieve well performance.",
  "4.3 Production Deployment": "We further evaluate CDAnet through production deployment in image2product retrieval of Alibaba Taobao system. In the deployment, the training dataset is previously illustrated in Section 4.1.1. Since the text2product retrieval and our image2product retrieval have many non-overlapped feature fields, we only partly share embedding layer parameters of two domains. Then, after embedding layer, we empirically use DCN-v2 [27] to extract latent features of text2product domain 6 , while feature extractor of our image2product domain is our online serving model. The prediction tower of both domains is two-layer MLP including the logit mapping layer. Based on the experience on public benchmarks, we set ğ›¼ and ğ›½ as 0.01. 4.3.1 Offline Performance on Production Dataset. In this part, we implement KEEP [35], which is one state-of-the-art cross-domain knowledge transfer algorithm for large-scale industrial system, as the comparison model. It takes the text2product domain as superdomain and image2product domain as target domain. The comparison results are summarized in Table 3. KEEP explicitly extracts user interests from text2product domain and provides this information for our image2product domain. However, it only provides user interests while ignoring other various features, and the extracted user interests are static no matter what the context features of the target domain inputs are. Instead, CDAnet does not have the above 6 We have no access to the online production model of text2product domain. Enhancing Cross-Domain Click-Through Rate Prediction via Explicit Feature Augmentation Conference WWW 2024, May 13-17, 2024, Singapore Figure 2: Ranking examples of online Base model and our CDAnet. Given an image query, we list the top5 ranking items of different models. (a) is an example of Wangzai milk and (b) is an example of a dress. Bad cases of Base model are circled with red box. In (a), the user expected to find a bottle of Wangzai milk, but Base model returned a bad case which is a bottle of Wangzai candy. In (b), the user uploaded a query of black and red plaid dress, but Base model returned a bad case which is a skirt. upload a query Base model CDAnet Base model CDAnet upload a query A bottle of Wangzai milk A black and red plaid dress (a) example of Wangzai milk upload a query Base model CDAnet Base model C upload a query A bottle of Wangzai milk A black and red plaid dress (b) example of a dress U 074452478101 0000 000 drawbacks and performs better. It brings an absolute 0.21% AUC increase, which is significant for Taobao's image2product retrieval. 4.3.2 Online A/B Test. Weconducted online experiments in an A/B test framework of image2product retrieval at Taobao app during the period from 2022/12/26 to 2023/01/16 and from 2023/02/06 to 2023/03/31. In this experiment, the baseline model is our online serving model trained only on image2product domain data. The online evaluation metrics are real CTR, deal number and GMV. The result in Table 3 shows that CDAnet leads to an absolute 0.11 point CTR increase, a relative 0.64% deal growth and a relative 1.26% GMVincrease. In Table 4, we also listed CDAnet's CTR improvements gap over online base model regarding different user groups and query categories to more comprehensively evaluate model performance. From this table, we see that CDAnet has obvious improvement under different evaluation views, demonstrating its effectiveness in our production system. It has been fully deployed online since April 2023, serving hundreds and millions of consumers. text2product retrieval could be transferred to our image2product retrieval. As a result, at high price levels of our image2product retrieval, the EPQ score is largely improved, and we could provide better ranking items to encourage deals. It is also interesting to find that the GMV increase is much larger than the deal growth. This indicates that the average deal price becomes larger and we want to investigate the reason behind it. Specifically, the items are divided into 5 different price levels from low to high according to their price. Then, we investigate how CDAnet performs on these items with different price levels. In Table 5, compared to our online base model, we show the improvement gap of CDAnet in terms of the exposed product quality(EPQ) score 7 and the deal number at different price levels. From Table 5, we see that CDAnet tends to improve the EPQ score much more at high price levels and the deal increase is also larger at high price levels. This result is quite meaningful. In our image2product retrieval, we face a severe data imbalance problem where the high price products (e.g. Beats earphone, iPhone) are less likely searched than the low price ones (e.g. a cup, a shirt), so the user behaviors are too sparse to learn a reliable model on the high price ones. With CDAnet, the rich and huge data knowledge accumulated for many years in 7 This is a designed score in our business to reflect the quality of the exposed products regarding seller ratings and product sales volume. The larger score is, the higher quality is. 4.3.3 Online Ranking Example. In addition, we compare some online ranking examples between the baseline model and CDAnet to empirically show the improved ranking ability. The result is shown in Figure 2. In (a), the user uploaded a picture of Wangzai milk, we see the online Base model ranks a bottle of Wangzai candy (circled with red box) that is quite visually similar but not the expected product in position 2. Instead, CDAnet can exclude this case and the top5 items are all about Wangzai milk. A possible reason may be that the Wangzai milk and candy in text domain are quite different, while they are not easily to be distinguished in image domain. CDAnet can transfer the knowledge of text2product domain into the image2product domain and improve the ranking results. In (b), we show a ranking example of a dress. Although our database does not have the the same item as the query, CDAnet has better ability of understanding which items are similar to the dress, while the online Base model ranked a skirt (circled with red box) in position 5. These cases help us to better understand the superiority of CDAnet.",
  "4.4 Content of Translated Features": "CDAnetlearns how to translate the latent features between domains and exploits these translated features as augmentation information to boost the target domain CTR prediction, so it is curious to see whether the translated features are meaningful for CTR prediction. In this part, we design an experiment to see whether the latent features have related content before and after translation. To be specific on Amazon dataset, given a user ğ‘¢ that has training instances sharing positive labels in both domains 8 , we can obtain the latent feature matrix ğ’ ğ’– ğ’ƒ âˆˆ R ğ‘ ğ‘¢ ğ‘ Ã— ğ‘‘ of book domain and ğ’ ğ’– ğ’ âˆˆ 8 CDAnet does not require a user to have training instances in both domains. We control the user variable here to better analyze the translated features. We let the instances in two domains share the positive label here for better analysis, because the 'negative' instances in CTR are usually sampled and have less confidence than positives. Conference WWW 2024, May 13-17, 2024, Singapore Xu Chen et al. Table 6: Results to show that the translated features in book space have related item content as its original item content in movie space. The last column indicates whether the book title has close content as the movie. Table 7: Ablation study on different model parts of CDAnet. We take CDAnet+MMOE here as an example. 'w/o' means without the corresponding module. 'w/o translation network' means we directly train the augmentation network which is random initialized. 'w/o augmentation network' means we directly use the translation network for evaluation. R ğ‘ ğ‘¢ ğ‘š Ã— ğ‘‘ of movie domain, where ğ‘ ğ‘¢ ğ‘ and ğ‘ ğ‘¢ ğ‘š denote the number of positive training instances for user ğ‘¢ in book domain and movie domain respectively. Then, we can get the translated features of ğ’ ğ’– ğ’ by the learned translator and it is denoted as ğ’ ğ’– â€² ğ’ âˆˆ R ğ‘ ğ‘¢ ğ‘š Ã— ğ‘‘ . Next, for a row (i.e. a sample contains user and item features) in the the translated feature ğ’ ğ’– â€² ğ’ , we find its ğ‘˜ -nearest neighbours in ğ’ ğ’– ğ’ƒ . In this case, we denote the book names from these neighbors as the content information of the translated feature. Finally, for a row in ğ’ ğ’– â€² ğ’ , we can check whether the content information of translated features in book space is related to the original movie name in movie space. The results are summarized in Table 6. From this Table, we find that the 5-nearest neighbour books have close content to the corresponding movie. For example, given UserID '21778', the interacted the movie is 'The Addams Family' which tells an emotional and love story. Meanwhile, for the corresponding translated features, the 5-nearest neighbor books are also about emotion and love. It shows that the translated features can capture related content from movie domain to book domain. Note CDAnet does not use any alignment information of items across domains, but it can automatically capture this and provide additional information to boost the CTR prediction in target domain.",
  "4.5 Impacts of Different Model Parts": "To assess the consequences of varying model components, we undertook an experiment to analyze the effects on performance when removing the associated module. The results are shown in Table 7. Considering the result of w/o L ğ‘œğ‘Ÿğ‘¡â„ and w/o L ğ‘ğ‘Ÿğ‘œğ‘ ğ‘  , we see either removing the orthogonal constraint loss or removing the cross-supervision loss would cause deteriorated performance. The orthogonal constraint loss L ğ‘œğ‘Ÿğ‘¡â„ can help CDAnet keep the similarity among latent features after translation and avoid mode collapse problem. The cross-supervision loss L ğ‘ğ‘Ÿğ‘œğ‘ ğ‘  plays a vital role in learning two translators. Further, either removing translation network or augmentation network would cause rather poor performance. The translation network learns how to transfer knowledge between domains. When removing it, we cannot have useful knowledge for later augmentation network. The augmentation network reuses the pre-trained parameters of translation network and employs the additional translated latent features for final CTR prediction. When removing it, we only have the translation network whose goal is translation and cannot guarantee good CTR prediction performance.",
  "5 CONCLUSION AND FUTURE WORK": "Cross-domain click-through rate (CDCTR) prediction is an important research topic in real-world systems. Compared to most existing methods that rely on different implicit ways to transfer knowledge, we propose a novel model named CDAnet for explicit, flexible and efficient knowledge transfer. CDAnet contains a translation stage that translates the latent feature of target domain into source domain view and augmentation stage that uses this translated feature to augment the target domain model learning. Through extensive experiments, we show CDAnet is able to learn meaningful translated features and boost the target domain CTR prediction performance. Results on the large-scale production dataset and online system at Taobao app show its superiority in real-world applications. Despite of this, CDAnet still has inadequacies in transferring knowledge. Some ingredients of the latent features may not be transferrable and have negative effects in translation. In the future, we will study a more effective technique for feature translation. Enhancing Cross-Domain Click-Through Rate Prediction via Explicit Feature Augmentation Conference WWW 2024, May 13-17, 2024, Singapore",
  "REFERENCES": "[1] Lei Chen, Fajie Yuan, Jiaxi Yang, Xiangnan He, Chengming Li, and Min Yang. 2021. User-specific Adaptive Fine-tuning for Cross-domain Recommendations. IEEE Transactions on Knowledge and Data Engineering (2021). [2] XuChen, Ya Zhang, Ivor W Tsang, Yuangang Pan, and Jingchao Su. 2020. Towards equivalent transformation of user preferences in cross domain recommendation. ACM Transactions on Information Systems (TOIS) (2020). [3] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al. 2016. Wide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems . 7-10. [4] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A Factorization-Machine Based Neural Network for CTR Prediction. In Proceedings of the 26th International Joint Conference on Artificial Intelligence (Melbourne, Australia) (IJCAI'17) . AAAI Press, 1725-1731. [5] Xuyang Hou, Zhe Wang, Qi Liu, Tan Qu, Jia Cheng, and Jun Lei. 2023. Deep Context Interest Network for Click-Through Rate Prediction. Conference on Information and Knowledge Management (2023). [6] Guangneng Hu, Yu Zhang, and Qiang Yang. 2018. Conet: Collaborative cross networks for cross-domain recommendation. In International conference on information and knowledge management . ACM, 667-676. [7] Zhaoxin Huan, Ang Li, Xiaolu Zhang, Xu Min, Jieyu Yang, Yong He, and Jun Zhou. 2023. SAMD: An Industrial Framework for Heterogeneous MultiScenario Recommendation. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Long Beach, CA, USA) (KDD '23) . Association for Computing Machinery, New York, NY, USA, 4175-4184. https://doi.org/10.1145/3580305.3599955 [8] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. 2017. Image-toimage translation with conditional adversarial networks. In Proceedings of the IEEE conference on computer vision and pattern recognition . 1125-1134. [9] Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jung Kwon Lee, and Jiwon Kim. 2017. Learning to discover cross-domain relations with generative adversarial networks. In International conference on machine learning . PMLR, 1857-1865. [10] Cheng Li, Yue Lu, Qiaozhu Mei, Dong Wang, and Sandeep Pandey. 2015. Clickthrough prediction for advertising in twitter timeline. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining . 1959-1968. [11] Pan Li and Alexander Tuzhilin. 2020. DDTCDR: Deep Dual Transfer Cross Domain Recommendation. International conference on web search and data mining (2020). [12] Lixin Liu, Yanling Wang, Tianming Wang, Dong Guan, Jiawei Wu, Jingxu Chen, Rong Xiao, Wenxiang Zhu, and Fei Fang. 2022. Continual Transfer Learning for Cross-Domain Click-Through Rate Prediction at Taobao. arXiv preprint arXiv:2208.05728 (2022). [13] Ming-Yu Liu, Thomas Breuel, and Jan Kautz. 2017. Unsupervised image-to-image translation networks. Advances in neural information processing systems 30 (2017). [14] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed H Chi. 2018. Modeling task relationships in multi-task learning with multi-gate mixture-ofexperts. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1930-1939. [15] Saeed Masoudnia and Reza Ebrahimpour. 2014. Mixture of experts: a literature survey. Artificial Intelligence Review 42 (2014), 275-293. [16] Wentao Ouyang, Xiuwu Zhang, Li Li, Heng Zou, Xin Xing, Zhaojie Liu, and Yanlong Du. 2019. Deep spatio-temporal neural networks for click-through rate prediction. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 2078-2086. [17] Wentao Ouyang, Xiuwu Zhang, Lei Zhao, Jinmei Luo, Yu Zhang, Heng Zou, Zhaojie Liu, and Yanlong Du. 2020. Minet: Mixed interest network for crossdomain click-through rate prediction. In Proceedings of the 29th ACM international conference on information & knowledge management . 2669-2676. [18] Yingxue Pang, Jianxin Lin, Tao Qin, and Zhibo Chen. 2021. Image-to-image translation: Methods and applications. IEEE Transactions on Multimedia (2021). [19] Steffen Rendle. 2010. Factorization machines. In 2010 IEEE International conference on data mining . IEEE, 995-1000. [20] Matthew Richardson, Ewa Dominowska, and Robert Ragno. 2007. Predicting clicks: estimating the click-through rate for new ads. In Proceedings of the 16th international conference on World Wide Web . 521-530. [21] Ozan Sener and Vladlen Koltun. 2018. Multi-task learning as multi-objective optimization. Advances in neural information processing systems 31 (2018). [22] Xiang-Rong Sheng, Liqin Zhao, Guorui Zhou, Xinyao Ding, Binding Dai, Qiang Luo, Siran Yang, Jingshan Lv, Chi Zhang, Hongbo Deng, et al. 2021. One model to serve all: Star topology adaptive recommender for multi-domain ctr prediction. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management . 4104-4113. [23] Hongyan Tang, Junning Liu, Ming Zhao, and Xudong Gong. 2020. Progressive layered extraction (ple): A novel multi-task learning (mtl) model for personalized recommendations. In Fourteenth ACM Conference on Recommender Systems . 269278. [24] Simon Vandenhende, Stamatios Georgoulis, Wouter Van Gansbeke, Marc Proesmans, Dengxin Dai, and Luc Van Gool. 2021. Multi-task learning for dense prediction tasks: A survey. IEEE transactions on pattern analysis and machine intelligence (2021). [25] Fangye Wang, Yingxu Wang, Dongsheng Li, Hansu Gu, Tun Lu, Peng Zhang, and Ning Gu. 2022. Enhancing CTR prediction with context-aware feature representation learning. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval . 343-352. [26] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep & cross network for ad click predictions. In Proceedings of the ADKDD'17 . 1-7. [27] Ruoxi Wang, Rakesh Shivanna, Derek Cheng, Sagar Jain, Dong Lin, Lichan Hong, and Ed Chi. 2021. Dcn v2: Improved deep & cross network and practical lessons for web-scale learning to rank systems. In Proceedings of the Web Conference 2021 . 1785-1797. [28] Zirui Wang, Yulia Tsvetkov, Orhan Firat, and Yuan Cao. 2020. Gradient vaccine: Investigating and improving multi-task optimization in massively multilingual models. arXiv preprint arXiv:2010.05874 (2020). [29] Xiangli Yang, Qing Liu, Rong Su, Ruiming Tang, Zhirong Liu, Xiuqiang He, and Jianxi Yang. 2022. Click-through rate prediction using transfer learning with fine-tuned parameters. Information Sciences 612 (2022), 188-200. [30] Zili Yi, Hao Zhang, Ping Tan, and Minglun Gong. 2017. Dualgan: Unsupervised dual learning for image-to-image translation. In Proceedings of the IEEE international conference on computer vision . 2849-2857. [31] Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, and Chelsea Finn. 2020. Gradient surgery for multi-task learning. Advances in Neural Information Processing Systems 33 (2020), 5824-5836. [32] Feng Yuan, Lina Yao, and Boualem Benatallah. 2019. DARec: Deep Domain Adaptation for Cross-Domain Recommendation via Transferring Rating Patterns. International joint conference on artificial intelligence (2019). [33] Seniha Esen Yuksel, Joseph N Wilson, and Paul D Gader. 2012. Twenty years of mixture of experts. IEEE transactions on neural networks and learning systems 23, 8 (2012), 1177-1193. [34] Wei Zhang, Pengye Zhang, Bo Zhang, Xingxing Wang, and Dong Wang. 2023. A Collaborative Transfer Learning Framework for Cross-Domain Recommendation. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Long Beach, CA, USA) (KDD '23) . Association for Computing Machinery, New York, NY, USA, 5576-5585. https://doi.org/10.1145/3580305. 3599758 [35] Yujing Zhang, Zhangming Chan, Shuhao Xu, Weijie Bian, Shuguang Han, Hongbo Deng, and Bo Zheng. 2022. KEEP: An Industrial Pre-Training Framework for Online Recommendation via Knowledge Extraction and Plugging. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management . 3684-3693. [36] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Deep interest evolution network for click-through rate prediction. In Proceedings of the AAAI conference on artificial intelligence , Vol. 33. 5941-5948. [37] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1059-1068. [38] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. 2017. Unpaired image-to-image translation using cycle-consistent adversarial networks. In Proceedings of the IEEE international conference on computer vision . 2223-2232.",
  "A ABLATION STUDY": "",
  "A.1 Different Sparse Data": "In order to investigate how CDAnet performs under more sparse conditions, we conduct an experiment to see the model performance at different sparsity levels of the training data. In particular, fixing the validation and test set, we vary the ratio of the original train data to the new train set. The results are shown in Figure 3, where we can see that CDAnet can achieve better results at almost all sparsity levels compared to other cross-domain CTR methods. CDAnet has a better way to transfer knowledge, so that it can show more generalized performance. Conference WWW 2024, May 13-17, 2024, Singapore Xu Chen et al. Figure 3: The effects of different sparsity levels on Amazon and Taobao. Train ratio means the ratio of the original train data. We take CDAnet+MMOE here as an example. (a) Amazon-movie (b) Amazon-book (c) Taobao-ad (d) Taobao-rec 0.66 Train Ratio Train Ratio STAR DDICDR 2 0.56 DOTCDR MHOE Train Ratio Train Ratio Figure 4: The effects of hyper-parameters on different datasets. ğ›¼ and ğ›½ are loss weights on different loss parts. We take CDAnet+MMOE here as an example. (a) ğ›¼ on Amazon-movie (b) ğ›¼ on Taobao-ad (c) ğ›½ on Amazon-movie (d) ğ›½ on Taobao-ad 0/220 07160 06192 76500 0.5800 2 06000 0.5500",
  "A.2 Parameter Sensitivity": "In CDAnet, ğ›¼ and ğ›½ control the loss weight on cross-supervision loss and orthogonal constraint loss, respectively. Here, we study the parameter sensitivity of these hyper-parameters to investigate their effects on model performance. The results are shown in Figure 4. In this figure, ğ›¼ controls the strength of cross-supervision on learning the translators. Too large ğ›¼ may dominate the learning of L ğ‘£ğ‘ğ‘›ğ‘– and cause bad effects on learning cross-supervised translators. ğ›½ controls the weight of L ğ‘œğ‘Ÿğ‘¡â„ and too large ğ›½ may limit the learning flexibility of the translators. These two hyper-parameters could be selected according to the validation set performance on different datasets. accepted 1 February 2024",
  "keywords_parsed": [
    "feature translation",
    "cross-domain CTR prediction",
    "explicit feature augmentation"
  ],
  "references_parsed": [
    {
      "ref_id": "b1",
      "title": "User-specific Adaptive Fine-tuning for Cross-domain Recommendations"
    },
    {
      "ref_id": "b2",
      "title": "Towards equivalent transformation of user preferences in cross domain recommendation"
    },
    {
      "ref_id": "b3",
      "title": "Wide & deep learning for recommender systems"
    },
    {
      "ref_id": "b4",
      "title": "DeepFM: A Factorization-Machine Based Neural Network for CTR Prediction"
    },
    {
      "ref_id": "b5",
      "title": "Deep Context Interest Network for Click-Through Rate Prediction"
    },
    {
      "ref_id": "b6",
      "title": "Conet: Collaborative cross networks for cross-domain recommendation"
    },
    {
      "ref_id": "b7",
      "title": "SAMD: An Industrial Framework for Heterogeneous MultiScenario Recommendation"
    },
    {
      "ref_id": "b8",
      "title": "Image-to-image translation with conditional adversarial networks"
    },
    {
      "ref_id": "b9",
      "title": "Learning to discover cross-domain relations with generative adversarial networks"
    },
    {
      "ref_id": "b10",
      "title": "Clickthrough prediction for advertising in twitter timeline"
    },
    {
      "ref_id": "b11",
      "title": "DDTCDR: Deep Dual Transfer Cross Domain Recommendation"
    },
    {
      "ref_id": "b12",
      "title": "Continual Transfer Learning for Cross-Domain Click-Through Rate Prediction at Taobao"
    },
    {
      "ref_id": "b13",
      "title": "Unsupervised image-to-image translation networks"
    },
    {
      "ref_id": "b14",
      "title": "Modeling task relationships in multi-task learning with multi-gate mixture-of-experts"
    },
    {
      "ref_id": "b15",
      "title": "Mixture of experts: a literature survey"
    },
    {
      "ref_id": "b16",
      "title": "Deep spatio-temporal neural networks for click-through rate prediction"
    },
    {
      "ref_id": "b17",
      "title": "Minet: Mixed interest network for cross-domain click-through rate prediction"
    },
    {
      "ref_id": "b18",
      "title": "Image-to-image translation: Methods and applications"
    },
    {
      "ref_id": "b19",
      "title": "Factorization machines"
    },
    {
      "ref_id": "b20",
      "title": "Predicting clicks: estimating the click-through rate for new ads"
    },
    {
      "ref_id": "b21",
      "title": "Multi-task learning as multi-objective optimization"
    },
    {
      "ref_id": "b22",
      "title": "One model to serve all: Star topology adaptive recommender for multi-domain ctr prediction"
    },
    {
      "ref_id": "b23",
      "title": "Progressive layered extraction (ple): A novel multi-task learning (mtl) model for personalized recommendations"
    },
    {
      "ref_id": "b24",
      "title": "Multi-task learning for dense prediction tasks: A survey"
    },
    {
      "ref_id": "b25",
      "title": "Enhancing CTR prediction with context-aware feature representation learning"
    },
    {
      "ref_id": "b26",
      "title": "Deep & cross network for ad click predictions"
    },
    {
      "ref_id": "b27",
      "title": "DCN v2: Improved deep & cross network and practical lessons for web-scale learning to rank systems"
    },
    {
      "ref_id": "b28",
      "title": "Gradient vaccine: Investigating and improving multi-task optimization in massively multilingual models"
    },
    {
      "ref_id": "b29",
      "title": "Click-through rate prediction using transfer learning with fine-tuned parameters"
    },
    {
      "ref_id": "b30",
      "title": "Dualgan: Unsupervised dual learning for image-to-image translation"
    },
    {
      "ref_id": "b31",
      "title": "Gradient surgery for multi-task learning"
    },
    {
      "ref_id": "b32",
      "title": "DARec: Deep Domain Adaptation for Cross-Domain Recommendation via Transferring Rating Patterns"
    },
    {
      "ref_id": "b33",
      "title": "Twenty years of mixture of experts"
    },
    {
      "ref_id": "b34",
      "title": "A Collaborative Transfer Learning Framework for Cross-Domain Recommendation"
    },
    {
      "ref_id": "b35",
      "title": "KEEP: An Industrial Pre-Training Framework for Online Recommendation via Knowledge Extraction and Plugging"
    },
    {
      "ref_id": "b36",
      "title": "Deep interest evolution network for click-through rate prediction"
    },
    {
      "ref_id": "b37",
      "title": "Deep interest network for click-through rate prediction"
    },
    {
      "ref_id": "b38",
      "title": "Unpaired image-to-image translation using cycle-consistent adversarial networks"
    }
  ]
}