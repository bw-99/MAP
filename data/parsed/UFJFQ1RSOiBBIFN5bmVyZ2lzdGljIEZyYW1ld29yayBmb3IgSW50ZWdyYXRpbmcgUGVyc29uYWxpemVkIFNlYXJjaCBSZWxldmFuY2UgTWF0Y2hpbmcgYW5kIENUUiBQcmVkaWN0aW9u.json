{"PRECTR: A Synergistic Framework for Integrating Personalized Search Relevance Matching and CTR Prediction": "Rong Chen \u2217 Alibaba Group Hangzhou, China xingshu.cr@taobao.com Shuzhi Cao \u2217\u2020 Xi'an Jiaotong University Xi'an, China cao309615@gmail.com Ailong He Alibaba Group Hangzhou, China along.hal@taobao.com Shuguang Han \u2021 Alibaba Group Hangzhou, China shuguang.sh@taobao.com Jufeng Chen Alibaba Group Hangzhou, China jufeng.cjf@taobao.com", "Abstract": "The two primary tasks in the search recommendation system are search relevance matching and click-through rate (CTR) prediction - the former focuses on seeking relevant items for user queries whereas the latter forecasts which item may better match user interest. Prior research typically develops two models to predict the CTR and search relevance separately, then ranking candidate items based on the fusion of the two outputs. However, such a divide-and-conquer paradigm creates the inconsistency between different models. Meanwhile, the search relevance model mainly concentrates on the degree of objective text matching while neglecting personalized differences among different users, leading to restricted model performance. To tackle these issues, we propose a unified P ersonalized Search RE levance Matching and CTR Prediction Fusion Model (PRECTR) . Specifically, based on the conditional probability fusion mechanism, PRECTR integrates the CTR prediction and search relevance matching into one framework to enhance the interaction and consistency of the two modules. However, directly optimizing CTR binary classification loss may bring challenges to the fusion model's convergence and indefinitely promote the exposure of items with high CTR, regardless of their search relevance. Hence, we further introduce two-stage training and semantic consistency regularization to accelerate the model's convergence and restrain the recommendation of irrelevant items. Finally, acknowledging that different users may have varied relevance preferences, we assessed current users' relevance preferences by analyzing past users' preferences for similar queries and tailored incentives for different candidate items accordingly. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. https://doi.org/10.1145/3701716.3715256 Extensive experimental results on our production dataset and online A/B testing demonstrate the effectiveness and superiority of our proposed PRECTR method.", "CCS Concepts": "\u00b7 Information systems \u2192 Data mining .", "Keywords": "Search Recommendation System, CTR Prediction, Personalized Search Relevance Matching, Fusion Model", "ACMReference Format:": "Rong Chen, Shuzhi Cao, Ailong He, Shuguang Han, and Jufeng Chen. 2025. PRECTR: A Synergistic Framework for Integrating Personalized Search Relevance Matching and CTR Prediction. In Companion Proceedings of the ACM Web Conference 2025 (WWW Companion '25), April 28-May 2, 2025, Sydney, NSW, Australia. ACM, New York, NY, USA, 10 pages. https://doi. org/10.1145/3701716.3715256", "1 Introduction": "Search relevance matching and click-through rate (CTR) prediction are the two core concepts in the search recommendation system. An ideal search recommendation system aims to present highly relevant items with elevated click-through rates to different users, contingent upon their current queries and individual preferences. Consequently, precisely modeling the relevance between queries and items and evaluating the CTR has emerged as the key challenge in the online search industry. In the typical search recommendation system, two separate models are utilized to represent search relevance and CTR, respectively. The search system will then make a comprehensive ranking of candidate items based on their outputs. For example, Xianyu, the largest Chinese online second-hand trading platform, initially categorizes items into distinct relevance score levels based on their original relevance matching score and then ranks the candidate items according to their click-through rates within each level. However, such distinct relevance score level separation results in somewhat less related commodities with high CTR losing exposure when they fall into the lower relevance score level. Hence, the decoupling training of the two models resulted in the inconsistency between them, leading to restricted performance. Meanwhile, current approaches merely depict relevance with the objective text matching degree and ignore the users' personal relevance preferences towards various items. All these factors constrain the performance of the current online search engine. Therefore, it remains challenging to effectively integrate search relevance matching and CTR prediction into one overall framework to boost user interaction and personalize item sorting based on users' individual relevance preferences. Recently, some pioneering works have attempted to capture the semantic relevance between the queries and items and take it as a supplementary feature for the CTR prediction model to generate a more comprehensive prediction. For instance, [34] employ a pretrained language model [7, 21, 47] to extract the relevance feature from queries and items' raw texts and take it as an additional feature; [43] transforms the basic numerical features into fine-grained tokens and feeds them with queries and items' textual features into the language model to boost their interaction. On this basis, [33] further proposes Uti-Attention to avoid unnecessary interaction and reduce the computational complexity to meet the deployment requirements in real-world industrial scenarios. Although all these methods successfully introduce the search relevance matching features into the CTR model to boost its performance, they only take it as a supplement for basic features and do not explicitly model the relevance between the queries and items, which restricts the capability of these models. To resolve these issues, we introduce a novel synergistic and unified Personalized Search Relevance Matching and CTR Prediction Fusion Model (PRECTR). Specifically, based on the conditional probability fusion mechanism, PRECTR integrates the CTR prediction and search relevance matching into one unified framework to enhance the feature interaction and module consistency. However, directly optimizing the CTR binary classification loss poses challenges for the convergence of the fusion model and may lead to the overexposure of items with high CTR, irrespective of their search relevance. Hence, we further introduce two-stage training and semantic consistency regularization to accelerate the model's convergence and restrain the recommendation of irrelevant items. Finally, recognizing that different users may have various levels of sensitivity to search relevance due to their personalized relevance preferences, we designed a personalized relevance incentive module to assess the current user's relevance preference by analyzing her/his historical preference for similar queries and tailored incentives for different candidate items accordingly. The main contributions of this paper are summarized as follows: \u00b7 To address the module inconsistency and insufficient interaction caused by decoupling training two separate models, we propose a novel synergistic Personalized Search Relevance Matching and CTR Prediction Fusion Model (PRECTR) to integrate CTR prediction and search relevance matching into one unified framework. \u00b7 The search relevance matching and CTR prediction are synergistically integrated under the conditional probability fusion mechanism. In addition, to tackle the problem of nonconvergence for the fusion model and the overexposure of items with high CTR and extremely low search relevance, we introduce a two-stage training process and a semantic consistency regularization technique. Finally, realizing that users may have different tastes in semantic relevance, we analyze their historical preferences and offer tailored incentives accordingly. This integrated model alleviates the discrepancy between the two separate models and naturally improves the ranking performance. \u00b7 An extensive amount of experimental analysis on both industrial datasets and online A/B testing demonstrates the effectiveness and superiority of the proposed PRECTR method over the existing methods. The remainder of this paper is organized as follows: Section 2 reviews related work. Section 3 describes preliminary concepts and notations. Section 4 details the proposed method. Section 5 presents experimental results. Finally, Section 6 concludes this paper.", "2 Related Work": "This section provides a concise overview of CTR prediction, search relevance matching, and their fusion techniques for final ranking.", "2.1 CTR Prediction": "CTR prediction plays a vital role in industrial search systems since it improves user experience and increases revenue for e-commerce platforms. Early statistics-based methods like collaborative filtering (CF) [14, 15, 30] made recommendations by mining similarities between users or items. Subsequently, shallow machine-learningbased methods like logistic regression (LR) [19], gradient boosting decision tree (GBDT) [9], factorization machines (FM) [27], fieldaware factorization machines (FFM) [18] are proposed to predict CTR. The primary goal of these methods is to exploit feature interaction and examine how such interaction helps predict user clicks. In recent years, the success of deep learning has brought the CTR prediction from shallow models to deep models, achieving remarkable performance. Specifically, [3] first utilizes deep neural networks to predict CTR. Wide&Deep [6] jointly trains wide linear models and deep neural networks to combine the benefits of memorization and generalization. On this basis, DCN [36] designs an additional cross-network to boost the feature interaction explicitly; DeepFM [11] combines the DNN and a factorization machine component to facilitate both high- and low-order feature interactions. Futhermore, AFM [39] introduces the attention mechanism [31] to capture the importance of each feature interaction, leading to advanced CTR prediction performance. Moreover, CTR models have become increasingly personalized. To accommodate this trend of development, more and more powerful models [2, 4, 5, 8, 10, 20, 23, 29, 37, 44, 46, 49, 50] are proposed to capture the user's personal preferences by analyzing their historical behaviors. For example, DIN [50] uses Target-Attention to assess the relevance of the candidate item to previously clicked items for discovering the items that users are interested in. On this basis, DIEN [49] further considers that user interest evolves dynamically and therefore designs an interest extractor layer to capture users' temporal interests. Moreover, BST [5] deploys the advanced Transformer [31] architecture into the CTR model to boost its prediction. Later, the industry attempts to explore users' interests in long-sequence scenarios, and some representative work like SIM [23] and TWIN [2] even extend the users' behavior sequence into lifelong scope, significantly improving the CTR prediction.", "2.2 Search Relevance Matching": "In e-commerce search systems, the relevance between the query and the item is usually measured by their text-matching score. Therefore, search relevance matching is considered a text-matching task in most cases. Early work such as TF-IDF similarity [1, 26] and Bag-of-Words (BoW) models [24, 45] perform keyword-based matching with statistical word frequencies. Obviously, these methods fail to capture the contextual relationship among input texts thereby restricting the matching performance. In recent years, more powerful methods built on top of deep learning techniques have been proposed for search relevance matching. They can be roughly divided into the interaction-based model [13, 17, 25, 32, 35] and the representation-based model. The former puts all candidate texts together as inputs, then utilizes a pre-trained language model to extract their embeddings, and ultimately evaluates their relevance based on these representations. Although these techniques show impressive performance, their high computational overhead makes them difficult for online deployment. To tackle this issue, the representation-based model [12, 22, 28, 40-42] is proposed to trade-off between performance and computation cost. They encode the query and the item texts separately. This enables offline pre-computing with the sacrifice of text interaction.", "2.3 The Fusion of CTR and Textual Relevance": "Ranking the candidate items by fusing both the estimated CTR and the textual relevance to the input query is a critical task for the search system. The current approach to integrating CTR and relevance can be divided into two groups. The first group separately constructs two distinct models, one for CTR prediction and the other for computing relevance score. Then, the two scores are fused with human-defined strategies like hierarchical sorting or linear combination. However, such a decoupled training process causes insufficient feature interaction, and inconsistency between the two models as well. To resolve this issue, later approaches [33, 34, 43] attempt to capture the relevance between queries and items and take it as a supplementary feature for CTR prediction. In this way, the model takes into account the two vital factors at the same time. Nonetheless, a simple introduction of the relevance score as an input feature fails to explicitly model the relevance score, which may lessen the importance of such a feature. Meanwhile, all these solutions overlook the fact that the impact of search relevance on a user's click probability is personalized. Therefore, the fusion of CTR prediction and search relevance matching, and making further personalized recommendations based on user relevance preference remains a challenging problem.", "3 Preliminaries": "In this section, we first briefly formulate the problems of CTR prediction and search relevance matching and then introduce the existing CTR prediction model deployed in Xianyu.", "3.1 Problem Formulation": "Given the training dataset D = { \ud835\udc99 , \ud835\udc66 } \ud835\udc5b collecting from our online e-commerce platform Xianyu, where \ud835\udc99 represents the high dimensional feature vector consisting of multi-fields features, the binary click label \ud835\udc66 \u2208 { 0 , 1 } indicates whether a sample is clicked, and \ud835\udc5b denotes the number of training samples. The feature \ud835\udc99 usually consists of multi-fields information and can be denoted as \ud835\udc99 = [ \ud835\udc61 \u22a4 1 , \ud835\udc61 \u22a4 2 , ..., \ud835\udc61 \u22a4 \ud835\udc40 ] \u22a4 where \ud835\udc61 \ud835\udc56 \u2208 R \ud835\udc3e \ud835\udc56 stands for the high-dimensional sparse binary features for \ud835\udc56 -th field, \ud835\udc3e \ud835\udc56 represents the dimensionality of vector \ud835\udc61 \ud835\udc56 , and \ud835\udc40 stands for the number of fields. \ud835\udc61 \ud835\udc56 can be either a one-hot vector or a multi-hot vector depending on the number of values of the \ud835\udc56 -th field. CTR prediction task aims to estimate the probability of a sample \ud835\udc65 being clicked,i.e., \ud835\udc5d \ud835\udc50\ud835\udc61\ud835\udc5f ( \ud835\udc65 ) = \ud835\udc5d ( \ud835\udc66 = 1 | \ud835\udc65 ) . Similarly, the search relevance matching task can be formulated as below: given the original query text \ud835\udc44 \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 and item description text \ud835\udc3c \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 , our goal is to determine whether the two texts are relevant to each other. In Xianyu, for each user query, all of the candidate items are divided into four different relevance score levels based on their relevance, i.e., the degree of textual matchness between the query and the item.", "3.2 CTR Prediction in Xianyu": "The Wide & Deep model [6, 38, 48] is currently employed by Xianyu as the base CTR prediction model. It jointly trains a wide linear model and a deep neural network which brings the benefits of memorization and generalization at the same time. Here, we briefly introduce the underlying model architecture as follows: The Wide Component is a generalized linear prediction model that can be expressed as \ud835\udc66 = \ud835\udc64 \u22a4 \ud835\udc99 + \ud835\udc4f . Here, \ud835\udc99 represents the input feature consisting of both raw features and the transformed crossproduct features. \ud835\udc64 and \ud835\udc4f are model weights and biases respectively. The wide component takes advantage of the linear model and is thus incapable of memorizing the sparse feature interactions. The Deep Component follows the Embedding and MLP paradigm, which first converts the sparse high-dimensional raw features into low-dimensional, dense real-valued vectors through the embedding layer and then utilizes MLP layers to extract their high-order representations. Such deep neural networks are easily generalizable to previously unseen feature interactions through low-dimensional embeddings, thus boosting the model's generalization ability. In this paper, we select the Wide&Deep model as the base CTR prediction model for better aligning with our production setting.", "4 Methodology": "This section outlines the overall design of our proposed method, including the architecture overview and the detailed structure.", "4.1 The Fusion Mechanism": "Intuitively, in a search system, a user clicking on an item is determined by its intrinsic quality and the relevance to the user query. Thus, as shown in the below Equation, we decompose the probability of clicking \ud835\udc43 ( \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58 = 1 | \ud835\udc99 ) on an item \ud835\udc99 into two parts: the relevance to the user query and the intrinsic item characteristic. Here, the variable \ud835\udc5f\ud835\udc60\ud835\udc59 stands for the relevance score level, which can be any of the \ud835\udc58 discrete values. In specific, given a user query, all of the matching items in Xianyu are divided into four different relevance levels, i.e., \ud835\udc58 \u2208 { 1 , 2 , 3 , 4 } , representing irrelevant, weaklyrelevant, relevant, and strongly-relevant, respectively. \ud835\udc43 ( \ud835\udc5f\ud835\udc60\ud835\udc59 = \ud835\udc56 | \ud835\udc99 ) denotes the probability of the item \ud835\udc99 in the relevance score level \ud835\udc56 and \ud835\udc43 ( \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58 = 1 | \ud835\udc5f\ud835\udc60\ud835\udc59 = \ud835\udc56, \ud835\udc99 ) stands for the conditional probability of the item \ud835\udc99 being clicked in the \ud835\udc56 -th relevance score level. To estimate the click probability in Eq.(1), we design an additional Relevance Score Level Module (RSL Module for short) for predicting \ud835\udc43 ( \ud835\udc5f\ud835\udc60\ud835\udc59 = \ud835\udc56 | \ud835\udc99 ) and further combine it with the Base Module for predicting \ud835\udc43 ( \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58 = 1 | \ud835\udc5f\ud835\udc60\ud835\udc59 = \ud835\udc56, \ud835\udc99 ) . Both of them output 4-dimensional vectors. Subsequently, we take a dot product of their outputs according to Eq.(1) to calculate the ultimate click probability \ud835\udc43 ( \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58 = 1 | \ud835\udc99 ) of the given item \ud835\udc99 .", "4.2 The Model Input": "The Base Module Input: The Base Module takes all the features including the user, item, context, and relevance features as the input to predict \ud835\udc43 ( \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58 = 1 | \ud835\udc5f\ud835\udc60\ud835\udc59, \ud835\udc99 ) . TheRSLModuleInput: As for the RSL module, we first extract the relevance features \ud835\udc65 \ud835\udc5f\ud835\udc60\ud835\udc59 that characterize the relevance relationship between the query words and candidate items as the input. Specifically, \ud835\udc65 \ud835\udc5f\ud835\udc60\ud835\udc59 is constructed as follows: we use the original raw text of query words and item descriptions as the main input and construct derived features like \"whether the category matches\", \"whether the description contains search terms\" and so on to generate \ud835\udc65 \ud835\udc5f\ud835\udc60\ud835\udc59 . Subsequently, we feed \ud835\udc65 \ud835\udc5f\ud835\udc60\ud835\udc59 into the RSL module to estimate \ud835\udc43 ( \ud835\udc5f\ud835\udc60\ud835\udc59 | \ud835\udc99 ) . To handle the raw text feature, we utilize the pre-trained BERT to encode the text embedding. Considering the latent high computational complexity resulting from high dimensional word representation, we also include a 3-layer MLP network for dimensionality reduction. The pre-trained BERT and dimensionality reduction layers are trained offline in advance, including the following two stages: (1) Pre-trained Stage: In this stage, we construct the training dataset via extensive available implicit feedback data collected from the Xianyu platform. To be specific, we consider the clicked and unclicked query-item pairs as relevant and irrelevant text pairs, respectively, and pre-train the network through the binary classification task of identifying whether the text pair is related. (2) Fine-Tuning Stage: In this stage, we manually annotate the relevance of the query-item pairs collected from the Xianyu platform and use it as supervised data to fine-tune the network. However, directly integrating BERT into the CTR model may exacerbate the time-consuming challenge of online inference. To solve this issue, we pre-compute the textual embeddings and store them in a static index table for online searching, maintaining low online inference latency.", "4.3 Two-Stage Training": "Following the fusion mechanism in Section 4.1, we have successfully merged CTR prediction and search relevance matching within one unified training framework. However, directly optimizing the CTR prediction binary classification loss through end-to-end training manner may bring challenges to the model's convergence. This is because the click label is a too-weak supervised signal for all the parts of the model to converge to their true physical meaning, and the end-to-end loss function is usually more complicated, making the optimization process difficult. Therefore, to realize the physical meaning of each module and accelerate the model's convergence, we propose a two-stage training strategy. Specifically, using the relevance score level \ud835\udc5f\ud835\udc60\ud835\udc59 as the supervised label, we first pre-train the RSL Module to initialize its parameters. Suppose \ud835\udc47 ( \ud835\udc99 ; \ud835\udf03 ) represents the RSL Module parameterized by \ud835\udf03 , which models the probability distribution of different relevance score levels and can be expressed as \ud835\udc47 ( \ud835\udc99 ; \ud835\udf03 ) = [ \ud835\udc43 ( \ud835\udc5f\ud835\udc60\ud835\udc59 = 1 | \ud835\udc99 ) , ..., \ud835\udc43 ( \ud835\udc5f\ud835\udc60\ud835\udc59 = 4 | \ud835\udc99 )] \u22a4 . Taking the relevance score level \ud835\udc5f\ud835\udc60\ud835\udc59 as the supervised label, we warm up the parameters \ud835\udf03 of the RSL Module by treating it as a multi-class classification task. The corresponding pre-train risk is in cross-entropy form and is formulated as follows: After the pre-training process, we then jointly train both the Base Module and the RSL Module by optimizing the CTR prediction objective. It is worth noting that we apply a smaller learning rate for fine-tuning the RSL Module since the main goal is to update the parameters of the Base Module. Let \ud835\udc54 ( \ud835\udc99 ; \ud835\udf02 ) denote the output of the Base Module, i.e, \ud835\udc54 ( \ud835\udc99 ; \ud835\udf02 ) = [ \ud835\udc43 ( \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58 = 1 | \ud835\udc5f\ud835\udc60\ud835\udc59 = 1 , \ud835\udc99 ) , ..., \ud835\udc43 ( \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58 = 1 | \ud835\udc5f\ud835\udc60\ud835\udc59 = 4 , \ud835\udc99 )] \u22a4 . The final click probability of the item \ud835\udc99 can be expressed as \ud835\udc43 ( \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58 = 1 | \ud835\udc99 ) = \ud835\udc54 ( \ud835\udc99 ; \ud835\udf02 ) \u00b7 \ud835\udc47 ( \ud835\udc99 ; \ud835\udf03 ) = \ud835\udc53 ( \ud835\udc65 ) . The cotraining risk is defined as the pointwise CTR prediction risk in negative log-likelihood function, which is shown below:", "4.4 Semantic Consistency Regularization": "As mentioned in Section 4.3, the fusion model first pre-trains the RSL Module and then takes the CTR prediction task as the final optimization objective for co-training. However, using the unitary click label for model training may inevitably lead to the recommendation of irrelevant cases. The CTR prediction task tends to incentivize high click-through items to get exposure without considering their relevance to the user's query. For example, when a user searches for \"mobile phone\", the search system may recommend unrelated \"mobile phone cover\" items as they have high click-through rates. To restrain this phenomenon, we propose a novel listwise loss as the semantic consistency regularization to enhance the relevance standard of the recommended items. Specifically, we design the listwise loss to keep the ranking order consistent with the ideal ranking order, where the ideal ranking of items is determined by both the item's click label and relevance score level. The two main principles of ranking are shown as follows: (1) all the clicked items should be ranked preceding the unclicked items, and (2) the relevance priority should remain the same for the unclicked items, and thereby, the unclicked items with larger relevance score levels should be prioritized. To achieve this goal, we re-defined the priority of items \ud835\udc99 by combining both their click label \ud835\udc66 and their relevance score level \ud835\udc5f\ud835\udc60\ud835\udc59 . To be specific, we synthesize a new listwise label \ud835\udc66 \ud835\udc3f\ud835\udc56\ud835\udc60\ud835\udc61 to indicate item priority in a training batch, which is formulated as below: Here \ud835\udefc and \ud835\udefd are pre-defined hyper-parameters. According to Eq.(4), the larger the value of \ud835\udc66 \ud835\udc3f\ud835\udc56\ud835\udc60\ud835\udc61 , the higher the priority of the corresponding item \ud835\udc99 . We expect the distribution of the model scores for candidate items to be consistent with its distribution of priority. Let \ud835\udc53 ( \ud835\udc65 ) = \ud835\udc43 ( \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58 = 1 | \ud835\udc99 ) = \ud835\udc54 ( \ud835\udc99 ; \ud835\udf02 ) \u00b7 \ud835\udc47 ( \ud835\udc99 ; \ud835\udf03 ) denote the final score for PRECTR: A Synergistic Framework for Integrating Personalized Search Relevance Matching and CTR Prediction \ud835\udc66 = 1 \ud835\udc66 = 1 \u2026\u2026 \ud835\udc66 = 0 \ud835\udc66 = 0 \ud835\udefc \u2217 \ud835\udc5f\ud835\udc60\ud835\udc59 = 3 \ud835\udc5f\ud835\udc60\ud835\udc59 = 2 \ud835\udc5f\ud835\udc60\ud835\udc59 = 1 \ud835\udc5f\ud835\udc60\ud835\udc59 = 0 Click Label Relevance Score Level +\ud835\udefd \u2217 1 - \ud835\udc66 \u2217 \u2026\u2026 Listwise Label \ud835\udc661 \ud835\udc3f\ud835\udc56\ud835\udc60\ud835\udc61 \ud835\udc662 \ud835\udc3f\ud835\udc56\ud835\udc60\ud835\udc61 \ud835\udc663 \ud835\udc3f\ud835\udc56\ud835\udc60\ud835\udc61 \ud835\udc66\ud835\udc5b \ud835\udc3f\ud835\udc56\ud835\udc60\ud835\udc61 = \ud835\udc53(\ud835\udc651) \ud835\udc53(\ud835\udc652) \ud835\udc53(\ud835\udc653) \ud835\udc53(\ud835\udc65\ud835\udc5b) Consistency Score \u211b\ud835\udc5f\ud835\udc52\ud835\udc54\ud835\udc62\ud835\udc59\ud835\udc4e\ud835\udc5f the item \ud835\udc99 given by the fusion model, \ud835\udc37 \ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 = [ \ud835\udc53 ( \ud835\udc65 1 ) , ..., \ud835\udc53 ( \ud835\udc65 \ud835\udc5b )] and \ud835\udc37 \ud835\udc5d\ud835\udc5f\ud835\udc56\ud835\udc5c\ud835\udc5f\ud835\udc56\ud835\udc61\ud835\udc66 = [ \ud835\udc66 \ud835\udc3f\ud835\udc56\ud835\udc60\ud835\udc61 1 , ..., \ud835\udc66 \ud835\udc3f\ud835\udc56\ud835\udc60\ud835\udc61 \ud835\udc5b ] represent the score and priority distribution within a batch respectively. We first use the softmax function to smooth these two distributions to ensure their comparability and subsequently minimize the KL divergence between them as an extra regularization to reinforce the semantic consistency, reducing the recommendation of irrelevant items. The final semantic consistency regularization is formulated as follows: By adding the semantic consistency regularization in Eq. (5), we introduce the relevance score level as an additional constraint to model training. This greatly reduces the recommendation of irrelevant items. The overview of semantic consistency regularization can be shown in Figure 1.", "4.5 Personalized Relevance Incentive": "In addition to the framework mentioned above that integrates CTR and textual relevance, we still omit that textual relevance can be personalized - different users have different sensitivities to search relevance. For example, users who are sensitive to textual relevance are less likely to click on irrelevant items, whereas the effect of query-item relevance may not affect that much on insensitive users. Meanwhile, even for the same user, it may have different relevance tastes on different types of queries. As a result, it is vital to model personal relevance preferences and provide individualized item recommendation experiences. To achieve this goal, we include an extra P ersonalized R elevance I ncentive M odule (PRIM) in the training framework, which consists of three parts: Historical Relevance Preference Extraction Module: We first extract the users' personal relevance preferences from their historical interaction records. Specifically, given a user's historical clicked item sequence and its corresponding query sequence S = {( \ud835\udc44 1 , \ud835\udc3c 1 ) , ..., ( \ud835\udc44 \ud835\udc5a , \ud835\udc3c \ud835\udc5a )} , where \ud835\udc5a denotes the length of historical click sequence, \ud835\udc44 \ud835\udc56 and \ud835\udc3c \ud835\udc56 represent the raw text of the query and clicked item respectively. Then, we concatenate the original query and item text and add a special character [SEP] to mark their separation. After that, we feed them as a whole sentence into the pre-trained language model and apply the MeanPooling operation in the output layer to aggregate the representation of the entire text as the relevance embedding \ud835\udc5f \ud835\udc52\ud835\udc5a\ud835\udc4f . Here \ud835\udc5f \ud835\udc52\ud835\udc5a\ud835\udc4f is regarded as the representation that contains information from both query and item text and is thus able to measure the degree of relevance. This process is formulated as follows: Current Relevance Preference Estimation Module: In this module, we estimate the user's current relevance preference based on its immediate query words and relevance preference extracted from the historical click sequence. As previously stated, different users may have varying relevance preferences towards various queries. Therefore, to determine the user's relevance preference under the current query, we first assess the similarity between it and historical queries through the Target-Attention operation. Let \ud835\udc44 \ud835\udc50\ud835\udc62\ud835\udc5f denote the raw text of the user's current query and \ud835\udc44 \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc50\ud835\udc62\ud835\udc5f represent its embedding after the language model encoding. Define \ud835\udc44 \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc60\ud835\udc52\ud835\udc5e = [ \ud835\udc44 \ud835\udc52\ud835\udc5a\ud835\udc4f 1 , ..., \ud835\udc44 \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc5a ] and \ud835\udc5f \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc60\ud835\udc52\ud835\udc5e = [ \ud835\udc5f \ud835\udc52\ud835\udc5a\ud835\udc4f 1 , ..., \ud835\udc5f \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc5a ] the set of embedding vectors of queries and relevance preferences in the user's historical behaviors respectively, where \ud835\udc44 \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc56 denotes the embedding of raw query text \ud835\udc44 \ud835\udc56 . Taking current query \ud835\udc44 \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc50\ud835\udc62\ud835\udc5f as query ( \ud835\udc44 ), historical queries' embedding \ud835\udc44 \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc60\ud835\udc52\ud835\udc5e as keys ( \ud835\udc3e ), and \ud835\udc5f \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc60\ud835\udc52\ud835\udc5e as values ( \ud835\udc49 ). Calculating Multi-Head Target-Attention (MHTA) operation based on given \ud835\udc44 , \ud835\udc3e , \ud835\udc49 , the user's current relevance preference expectation \ud835\udc5f \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc50\ud835\udc61 can be estimated as follows: where \ud835\udc44 = \ud835\udc64 \ud835\udc44 \ud835\udc44 \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc50\ud835\udc62\ud835\udc5f , \ud835\udc3e = \ud835\udc64 \ud835\udc3e \ud835\udc44 \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc60\ud835\udc52\ud835\udc5e , \ud835\udc49 = \ud835\udc64 \ud835\udc49 \ud835\udc5f \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc60\ud835\udc52\ud835\udc5e , the matrices \ud835\udc64 \ud835\udc44 \u2208 R \ud835\udc51 \u00d7 \ud835\udc51 , \ud835\udc64 \ud835\udc3e \u2208 R \ud835\udc51 \u00d7 \ud835\udc51 , and \ud835\udc64 \ud835\udc49 \u2208 R \ud835\udc51 \u00d7 \ud835\udc51 are linear projection matrices, \ud835\udc51 represents the dimension of feature embeddings. The temperature \u221a \ud835\udc51 is introduced to produce a softer attention distribution for avoiding extremely small gradients. Personalized Relevance Incentive Module: After obtaining the user's current relevance preference estimation, we compute the relevance preference representation \ud835\udc5f \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc50\ud835\udc62\ud835\udc5f between the current query \ud835\udc44 \ud835\udc50\ud835\udc62\ud835\udc5f and the candidate item \ud835\udc3c \ud835\udc50\ud835\udc62\ud835\udc5f with pre-trained language model. Subsequently, we concatenate \ud835\udc5f \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc50\ud835\udc62\ud835\udc5f and \ud835\udc5f \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc50\ud835\udc61 together and feed it into a Multilayer Perceptron (MLP) network \ud835\udc40 ( ; \ud835\udf14 ) parameterized by \ud835\udf14 to learn the incentive score. Specifically, the MLP network outputs a scalar number \ud835\udf0f that represents the intensity of the relevance preference, which is defined as follows: Intuitively, \ud835\udc5f \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc50\ud835\udc62\ud835\udc5f stands for the relevance matching degree between the current query and the candidate item, and \ud835\udc5f \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc50\ud835\udc61 denotes the relevance expectation given the current query. As a result, the more similar the two representations are, the more the query-item candidate pairs align with the user's relevance preferences, and the greater the incentive score \ud835\udf0f we should give. On the contrary, the dissimilarity between the two representations indicates the inconsistency between the user's relevance preference and the current relevance standard. In this case, the user may not click the candidate item due to its relevance preference and thus we should give a smaller incentive score \ud835\udf0f to inhibit the recommendation of this item. Finally, we use the incentive score \ud835\udf0f to adjust the basic fusion score \ud835\udc54 ( \ud835\udc99 ; \ud835\udf02 ) \u00b7 \ud835\udc47 ( \ud835\udc99 ; \ud835\udf03 ) and outputs the ultimate personalized score \ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 = \ud835\udf0f \u00b7 \ud835\udc54 ( \ud835\udc99 ; \ud835\udf02 ) \u00b7 \ud835\udc47 ( \ud835\udc99 ; \ud835\udf03 ) . Therefore, the final CTR optimization objective risk consists of two parts: (1) a cross-entropy loss between the ultimate personalized score \ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 = \ud835\udf0f \u00b7 \ud835\udc54 ( \ud835\udc99 ; \ud835\udf02 ) \u00b7 \ud835\udc47 ( \ud835\udc99 ; \ud835\udf03 ) and click label \ud835\udc66 and (2) a semantic consistency regularization in subsection WWWCompanion '25, April 28-May 2, 2025, Sydney, NSW, Australia 4.4, which is concluded as follows: where R \ud835\udc36\ud835\udc38 denotes the cross-entropy risk and \ud835\udefe is a pre-defined hyperparameter to trade-off between the cross entropy risk R \ud835\udc36\ud835\udc38 and regularization term R \ud835\udc5f\ud835\udc52\ud835\udc54\ud835\udc62\ud835\udc59\ud835\udc4e\ud835\udc5f . For ease of understanding, we provide a visual representation of the proposed method's overview, shown in Figure 2.", "5 Experiments": "In this section, we conduct comprehensive experiments on both the offline dataset and online A/B testing to evaluate the effectiveness and superiority of the proposed method.", "5.1 Experiments Setup": "Dataset: We collect click traffic logs from Alibaba's second-hand online trading platform Xianyu to construct the training dataset. Specifically, we treat clicked items as positive samples and unclicked items as negative samples. The daily training data volume is about 1.6 billion and each record contains 651 features (e.g., user, query, and item features). We take 9 days of data for the experiment evaluation, in which data from the first 7 days is used for model training, and the remaining data of 2 days are used for model testing. Compared Methods: To demonstrate the superiority of the proposed method, we adopt the following baseline approaches: \u00b7 LR [16]: Logistic Regression (short for LR) is a widely used shallow model before the deep model that estimates the CTR by combining features in a linear combination form. \u00b7 DNN: DNN is proposed by YouTube and has been widely used in industry scenarios. It follows classic Embedding & MLP architecture and utilizes the SumPooling operation to integrate historical behavior embeddings. \u00b7 Wide&Deep [6]: consists of both wide linear models and deep neural networks to benefit from memorization and generalization mutually. It is selected as our base model. \u00b7 DeepFM [11]: It combines factorization machine (FM) and deep neural network to improve Wide&Deep, effectively capturing both low and high-order feature interactions. \u00b7 XDeepFM [20]: which proposes a novel Compressed Interaction Network (CIN) to generate feature interactions explicitly and combine it with DNN to predict CTR. \u00b7 DIN [50]: which proposes a novel deep interest network and first utilizes the target attention operation to assess the relevance of the candidate item to previously clicked items for discovering the items that users are interested in. \u00b7 SuKD [34]: which utilizes the pre-trained BERT model to encode the raw text of query and item and take it as a supplementary feature to boost CTR prediction. Evaluation Metric: The definition of the main evaluation metric used in the experiments is presented as follows: \u00b7 AUC: Asthe most commonly used evaluation metric in the search recommendation system, Area Under the Curve (AUC) reflects the sorting ability of the CTR model. Specifically, given a positive and a negative item chosen randomly, AUC shows the likelihood that the model would rate the positive item higher than the negative one. Therefore, the AUC can be formulated as follows: \u2736 \u00b7 GAUC: Different from the AUC that measures the global ranking ability of the model, the Group Area Under the Curve (GAUC) is designed to measure the goodness of order by ranking towards various groups or users. In specific, we first calculate AUC for different users and subsequently average them to get the final GAUC. The definition of GAUC is formulated as follows, where AUC \ud835\udc56 stands for the AUC for the \ud835\udc56 -th user, #impression \ud835\udc56 is its corresponding weight, and \ud835\udc5b denotes the total number of users. where \ud835\udc43 and \ud835\udc41 represent the positive and negative item set respectively, \u0398 is the ranking function given by the CTR model, and is the indicator function. \u00b7 RelaImpr: RelaImpr is adopted to measure the relative improvement over other models. RelaImpr > 0 means the current model is superior over the base model, and vice versa. It can be formulated as follows: \u00b7 Relevance Score: To assess the relevance between the recommended items and the input query, for each query, we examine the relevance by intercepting the Top-10 items corresponding to the recommendations. To be specific, we utilize the pre-trained language model mentioned in subsection 4.1 to extract query and item's embedding \ud835\udc44 \ud835\udc52\ud835\udc5a\ud835\udc4f and \ud835\udc3c \ud835\udc52\ud835\udc5a\ud835\udc4f respectively. Afterward, we calculate the cosine similarity between them to reflect their similarity. By averaging the similarities of all query-item pairs, we get the model's relevance score below, where \ud835\udc3f denotes the number of queries in total. Implementation Details: In all of the experiments, the batch size is set to 4096, and the SGD optimizer is employed for model update. In the pre-train stage, we first warm up the RSL Module under the supervision of relevance score level with an initial learning rate 1e-4. As for the co-training stage, we fine-tune the RSL Module by adjusting the learning rate to 1e-5 while the other modules remain the same. The history click sequence is collected with the last 30 days and the maximum length is 50.", "5.2 Experimental Results": "In this subsection, we discuss the experimental results from the following three aspects: (1) Offline Experimental Results: To demonstrate the effectiveness and superiority of the proposed method, we conduct offline experiments on the Xianyu dataset and compare it with state-of-theart (SOTA) approaches. For a fair comparison, we cold start all of the models and train them from scratch. The results are presented in Table 1. Compared with the previous approaches, our method achieved the best performance on all of the metrics. Specifically, Pre-trained Language Model Historical Click Sequence Candidate Pair (\ud835\udc44\ud835\udc50\ud835\udc62\ud835\udc5f, \ud835\udc3c \ud835\udc50\ud835\udc62\ud835\udc5f ) MLP Concat Incentive Score \ud835\udf0f \ud835\udc5f \ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc50\ud835\udc61 \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc5f \ud835\udc50\ud835\udc62\ud835\udc5f \ud835\udc52\ud835\udc5a\ud835\udc4f \ud835\udc441 \ud835\udc3c 1 \ud835\udc44\ud835\udc5b \ud835\udc3c\ud835\udc5b \ud835\udc44\ud835\udc50\ud835\udc62\ud835\udc5f \ud835\udc44\ud835\udc50\ud835\udc62\ud835\udc5f Basic Feature Wide&Deep Rsl Feature \ud835\udc43(\ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58 = 1|\ud835\udc65, \ud835\udc5f\ud835\udc60\ud835\udc59) Language Model + MLP Dot product Original Score Base Module Softmax Softmax Personalized Relevance Incentive Module Rsl Module \ud835\udc43(\ud835\udc5f\ud835\udc60\ud835\udc59|\ud835\udc65) Predicted CTR min \u211b\ud835\udc36\ud835\udc38 \ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52, \ud835\udc66 +\ud835\udefe \u2217 \u211b\ud835\udc5f\ud835\udc52\ud835\udc54\ud835\udc62\ud835\udc59\ud835\udc4e\ud835\udc5f Attention Attention Qnmb compared to the base model Wide&Deep, our approach achieved a 0 . 82% improvement in AUC and a 1 . 99% increase in GAUC. Moreover, our model is also capable of perceiving the search-matching relevance and achieves the best 0 . 7561 relevance score that greatly exceeds the compared methods. (2) Ablation Experiments: Weconduct ablation experiments to verify the effectiveness of all the modules and strategies proposed in our method. Take the Wide&Deep model as the base model which directly estimates the CTR without considering the search matching relevance. To verify each module's contribution, we compare the complete PRECTR method with the model without two-stage training, the model without semantic consistency regularization, and the model without personalized relevance incentive module, respectively. Unlike offline experiments, we use the online model to warm up our model and inherit the knowledge learned in history to simulate the online environment. The corresponding results are summarized in Table 2. Specifically, compared with the base model, the complete PRECTR model achieves both the best AUC of 0 . 7642 and the best relevance score of 0 . 7561, while the base model shows the worst performance. Meanwhile, various ablation versions of models gain in AUC and relevance scores compared with the base model, exhibiting the effectiveness of each module and strategy proposed in our method. Nonetheless, we also observe that the semantic consistency regularization does not greatly enhance the overall model's performance, this might be because the majority of training data are strongly relevant items, weakening the influence of the semantic consistency regularization. (3) Online A/B Testing: We deploy the proposed model online in Xianyu's search recommendation system to test its online performance. Through an online A/B test, users are randomly assigned to control and experimental groups. Device IDs are uniformly distributed via MD5 hashing for impartial partitioning. We observed the online results in the experimental group for 7 days, which had over 5% of the total traffic. Specifically, the proposed PRECTR model improved across key metrics compared to the base model, with a 0 . 4% increase in CTR and a 1 . 1% increase in Gross Merchandise Volume (GMV). Meanwhile, the consistency between the CTR and CVR is further improved, the CTCVR metric achieves a 1 . 04% improvement compared to the current online serving model.", "5.3 Hyperparameter Tuning": "In this subsection, we conduct experiments to select the optimal hyperparameters for the proposed method. (1) The selection of \ud835\udefc and \ud835\udefd in semantic consistency regularization: \ud835\udefc and \ud835\udefd represent the weight of click label \ud835\udc66 and relevance score level \ud835\udc5f\ud835\udc60\ud835\udc59 respectively. To effectively search for their optimal value, we set \ud835\udefd = 1 as a constant and change different values for \ud835\udefc to observe its effect on the ultimate AUC and GAUC. According to Figure 3, with the rise of \ud835\udefc , the AUC and GAUC roughly rise at first and then drop. When \ud835\udefc = 4, our method achieves the best AUC and GAUC performance at the same time. Therefore, we select \ud835\udefc = 4 as the optimal hyperparameter value in all the experiments. (2) The selection of \ud835\udefe in the final optimization objective: According to Eq.(9), the hyperparameter \ud835\udefe trades off between the CTR binary classification risk and semantic consistency regularization risk. To determine its optimal value, we iterate various values 0.7615 0.7620 0.7625 0.7630 0.7635 AUC 1 2 3 4 5 6 7 0.6675 0.6680 0.6685 0.6690 0.6695 GAUC 0.750 0.755 0.760 0.765 AUC Relevance Score 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.6950 0.6975 0.7000 0.7025 0.7050 GAUC from small to large to test the model's performance. As shown in Figure 4. , when \ud835\udefe is set to 0 . 3, the overall model achieves the highest AUC, GAUC, and Relevance Score at the same time. Therefore, we set \ud835\udefe = 0 . 3 in all the experiments.", "6 Conclusion": "In this paper, we propose a synergistic framework called PRECTR to address inconsistencies from decoupling the training of separate models for search relevance and CTR prediction. Based on the conditional probability fusion mechanism, PRECTR integrates the CTR prediction and relevance modeling into one unified framework. Furthermore, we introduce the two-stage training and semantic consistency regularization to boost their integration. Finally, by analyzing the users' historical click sequences, we design an additional personalized relevance incentive module to offer tailored incentives for different users. We conduct comprehensive experiments on the Xianyu datasets and online A/B testing to demonstrate the effectiveness and superiority of our proposed method. PRECTR: A Synergistic Framework for Integrating Personalized Search Relevance Matching and CTR Prediction", "References": "[1] Akiko Aizawa. 2003. An information-theoretic perspective of tf-idf measures. Information Processing & Management 39, 1 (2003), 45-65. [2] Jianxin Chang, Chenbin Zhang, Zhiyi Fu, Xiaoxue Zang, Lin Guan, Jing Lu, Yiqun Hui, Dewei Leng, Yanan Niu, Yang Song, et al. 2023. TWIN: TWo-stage interest network for lifelong user behavior modeling in CTR prediction at kuaishou. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 3785-3794. [3] Junxuan Chen, Baigui Sun, Hao Li, Hongtao Lu, and Xian-Sheng Hua. 2016. Deep ctr prediction in display advertising. In Proceedings of the 24th ACM international conference on Multimedia . 811-820. [4] Ming Chen, Weike Pan, and Zhong Ming. 2024. Explicit and Implicit Modeling via Dual-Path Transformer for Behavior Set-informed Sequential Recommendation. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 329-340. [5] Qiwei Chen, Huan Zhao, Wei Li, Pipei Huang, and Wenwu Ou. 2019. Behavior sequence transformer for e-commerce recommendation in alibaba. In Proceedings of the 1st international workshop on deep learning practice for high-dimensional sparse data . 1-4. [6] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al. 2016. Wide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems . 7-10. [7] Jacob Devlin. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018). [8] Yingpeng Du, Ziyan Wang, Zhu Sun, Yining Ma, Hongzhi Liu, and Jie Zhang. 2024. Disentangled Multi-interest Representation Learning for Sequential Recommendation. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 677-688. [9] Jerome H Friedman. 2001. Greedy function approximation: a gradient boosting machine. Annals of statistics (2001), 1189-1232. [10] Xiaoqiang Gui, Yueyao Cheng, Xiang-Rong Sheng, Yunfeng Zhao, Guoxian Yu, Shuguang Han, Yuning Jiang, Jian Xu, and Bo Zheng. 2023. Calibrationcompatible Listwise Distillation of Privileged Features for CTR Prediction. Proceedings of the 17th ACM International Conference on Web Search and Data Mining (2023). [11] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247 (2017). [12] Jiafeng Guo, Yixing Fan, Qingyao Ai, and W Bruce Croft. 2016. A deep relevance matching model for ad-hoc retrieval. In Proceedings of the 25th ACM international on conference on information and knowledge management . 55-64. [13] Shuguang Han, Xuanhui Wang, Michael Bendersky, and Marc Najork. 2020. Learning-to-Rank with BERT in TF-Ranking. ArXiv abs/2004.08476 (2020). [14] Jonathan L Herlocker, Joseph A Konstan, and John Riedl. 2000. Explaining collaborative filtering recommendations. In Proceedings of the 2000 ACM conference on Computer supported cooperative work . 241-250. [15] Jonathan L Herlocker, Joseph A Konstan, Loren G Terveen, and John T Riedl. 2004. Evaluating collaborative filtering recommender systems. ACMTransactions on Information Systems (TOIS) 22, 1 (2004), 5-53. [16] David W Hosmer Jr, Stanley Lemeshow, and Rodney X Sturdivant. 2013. Applied logistic regression . John Wiley & Sons. [17] Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai Chen. 2014. Convolutional neural network architectures for matching natural language sentences. Advances in neural information processing systems 27 (2014). [18] Yuchin Juan, Yong Zhuang, Wei-Sheng Chin, and Chih-Jen Lin. 2016. Fieldaware factorization machines for CTR prediction. In Proceedings of the 10th ACM conference on recommender systems . 43-50. [19] Michael P LaValley. 2008. Logistic regression. Circulation 117, 18 (2008), 23952399. [20] Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018. xdeepfm: Combining explicit and implicit feature interactions for recommender systems. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1754-1763. [21] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2023. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. Comput. Surveys 55, 9 (2023), 1-35. [22] Priyanka Nigam, Yiwei Song, Vijai Mohan, Vihan Lakshman, Weitian Ding, Ankit Shingavi, Choon Hui Teo, Hao Gu, and Bing Yin. 2019. Semantic product search. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 2876-2885. [23] Qi Pi, Guorui Zhou, Yujing Zhang, Zhe Wang, Lejian Ren, Ying Fan, Xiaoqiang Zhu, and Kun Gai. 2020. Search-based user interest modeling with lifelong sequential behavior data for click-through rate prediction. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management . 2685-2692. WWWCompanion '25, April 28-May 2, 2025, Sydney, NSW, Australia [24] Wisam A Qader, Musa M Ameen, and Bilal I Ahmed. 2019. An overview of bag of words; importance, implementation, applications, and challenges. In 2019 international engineering conference (IEC) . IEEE, 200-204. [25] Yifan Qiao, Chenyan Xiong, Zhenghao Liu, and Zhiyuan Liu. 2019. Understanding the Behaviors of BERT in Ranking. arXiv preprint arXiv:1904.07531 (2019). [26] Juan Ramos et al. 2003. Using tf-idf to determine word relevance in document queries. In Proceedings of the first instructional conference on machine learning , Vol. 242. Citeseer, 29-48. [27] Steffen Rendle. 2010. Factorization machines. In 2010 IEEE International conference on data mining . IEEE, 995-1000. [28] Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng, and Gr\u00e9goire Mesnil. 2014. A latent semantic model with convolutional-pooling structure for information retrieval. In Proceedings of the 23rd ACM international conference on conference on information and knowledge management . 101-110. [29] Xiang-Rong Sheng, Jingyue Gao, Yueyao Cheng, Siran Yang, Shuguang Han, Hongbo Deng, Yuning Jiang, Jian Xu, and Bo Zheng. 2023. Joint optimization of ranking and calibration with contextualized hybrid model. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 4813-4822. [30] Xiaoyuan Su and Taghi M Khoshgoftaar. 2009. A survey of collaborative filtering techniques. Advances in artificial intelligence 2009, 1 (2009), 421425. [31] A Vaswani. 2017. Attention is all you need. Advances in Neural Information Processing Systems (2017). [32] Shengxian Wan, Yanyan Lan, Jun Xu, Jiafeng Guo, Liang Pang, and Xueqi Cheng. 2016. Match-srnn: Modeling the recursive matching structure with spatial rnn. arXiv preprint arXiv:1604.04378 (2016). [33] Dong Wang, Kav\u00e9 Salamatian, Yunqing Xia, Weiwei Deng, and Qi Zhang. 2023. BERT4CTR: An Efficient Framework to Combine Pre-trained Language Model with Non-textual Features for CTR Prediction. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 5039-5050. [34] Dong Wang, Shaoguang Yan, Yunqing Xia, Kav\u00e9 Salamatian, Weiwei Deng, and Qi Zhang. 2022. Learning Supplementary NLP Features for CTR Prediction in Sponsored Search. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 4010-4020. [35] Dong Wang, Shaoguang Yan, Yunqing Xia, Kav\u00e9 Salamatian, Weiwei Deng, and Qi Zhang. 2022. Learning Supplementary NLP Features for CTR Prediction in Sponsored Search. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 4010-4020. [36] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep & cross network for ad click predictions. In Proceedings of the ADKDD'17 . 1-7. [37] Ruoxi Wang, Rakesh Shivanna, Derek Cheng, Sagar Jain, Dong Lin, Lichan Hong, and Ed Chi. 2021. Dcn v2: Improved deep & cross network and practical lessons for web-scale learning to rank systems. In Proceedings of the web conference 2021 . 1785-1797. [38] Wenhao Wu, Jialiang Zhou, Ailong He, Shuguang Han, Jufeng Chen, and Bo Zheng. 2024. MetaSplit: Meta-Split Network for Limited-Stock Product Recommendation. Companion Proceedings of the ACM on Web Conference 2024 (2024). [39] Jun Xiao, Hao Ye, Xiangnan He, Hanwang Zhang, Fei Wu, and Tat-Seng Chua. 2017. Attentional factorization machines: Learning the weight of feature interactions via attention networks. arXiv preprint arXiv:1708.04617 (2017). [40] Shaowei Yao, Jiwei Tan, Xi Chen, Keping Yang, Rong Xiao, Hongbo Deng, and Xiaojun Wan. 2021. Learning a product relevance model from click-through data in e-commerce. In Proceedings of the Web Conference 2021 . 2890-2899. [41] Shaowei Yao, Jiwei Tan, Xi Chen, Juhao Zhang, Xiaoyi Zeng, and Keping Yang. 2022. ReprBERT: distilling BERT to an efficient representation-based relevance model for e-commerce. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 4363-4371. [42] Hongchun Zhang, Tianyi Wang, Xiaonan Meng, Yi Hu, and Hao Wang. 2019. Improving Semantic Matching via Multi-Task Learning in E-Commerce. eCOM@ SIGIR 10 (2019). [43] Xikun Zhang, Deepak Ramachandran, Ian Tenney, Yanai Elazar, and Dan Roth. 2020. Do language embeddings capture scales? arXiv preprint arXiv:2010.05345 (2020). [44] Yujing Zhang, Zhangming Chan, Shuhao Xu, Weijie Bian, Shuguang Han, Hongbo Deng, and Bo Zheng. 2022. KEEP: An industrial pre-training framework for online recommendation via knowledge extraction and plugging. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management . 3684-3693. [45] Yin Zhang, Rong Jin, and Zhi-Hua Zhou. 2010. Understanding bag-of-words model: a statistical framework. International journal of machine learning and cybernetics 1 (2010), 43-52. [46] Zhaorui Zhang, Xiang-Rong Sheng, Yujing Zhang, Biye Jiang, Shuguang Han, Hongbo Deng, and Bo Zheng. 2022. Towards Understanding the Overfitting Phenomenon of Deep Click-Through Rate Models. Proceedings of the 31st ACM International Conference on Information & Knowledge Management (2022). [47] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023. A survey of large language models. arXiv preprint arXiv:2303.18223 (2023). WWWCompanion '25, April 28-May 2, 2025, Sydney, NSW, Australia [48] Yunfeng Zhao, Xu Yan, Xiaoqiang Gui, Shuguang Han, Xiang-Rong Sheng, Guoxian Yu, Jufeng Chen, Zhao Xu, and Bo Zheng. 2023. Entire Space Cascade Delayed Feedback Modeling for Effective Conversion Rate Prediction. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management . 4981-4987. [49] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Deep interest evolution network for click-through rate prediction. In Proceedings of the AAAI conference on artificial intelligence , Vol. 33. 5941-5948. [50] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1059-1068."}
