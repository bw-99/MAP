{"title": "Cafe: Coarse-to-Fine Neural Symbolic Reasoning for Explainable Recommendation", "authors": "Yikun Xian; Zuohui Fu; Handong Zhao; Yingqiang Ge; Xu Chen; Qiaoying Huang; Shijie Geng; Zhou Qin; Gerard De Melo; S Muthukrishnan; Yongfeng 2020 Zhang; Qiaoy- Ing Huang", "pub_date": "2020-10-29", "abstract": "Recent research explores incorporating knowledge graphs (KG) into e-commerce recommender systems, not only to achieve better recommendation performance, but more importantly to generate explanations of why particular decisions are made. This can be achieved by explicit KG reasoning, where a model starts from a user node, sequentially determines the next step, and walks towards an item node of potential interest to the user. However, this is challenging due to the huge search space, unknown destination, and sparse signals over the KG, so informative and effective guidance is needed to achieve a satisfactory recommendation quality. To this end, we propose a CoArse-to-FinE neural symbolic reasoning approach (Cafe). It first generates user profiles as coarse sketches of user behaviors, which subsequently guide a path-finding process to derive reasoning paths for recommendations as fine-grained predictions. User profiles can capture prominent user behaviors from the history, and provide valuable signals about which kinds of path patterns are more likely to lead to potential items of interest for the user. To better exploit the user profiles, an improved pathfinding algorithm called Profile-guided Path Reasoning (PPR) is also developed, which leverages an inventory of neural symbolic reasoning modules to effectively and efficiently find a batch of paths over a large-scale KG. We extensively experiment on four real-world benchmarks and observe substantial gains in the recommendation performance compared with state-of-the-art methods.", "sections": [{"heading": "", "text": "Figure 1: A motivating example of KG reasoning for ecommerce recommendation. Given the start user, the target destinations (i.e., items to recommend) are unknown beforehand. The goal is -guided by user behavior patterns (bold edges) -to sequentially determine the next step traversing the KG towards potential items of interest as recommendations (e.g., Screen protector and Surface Dock). Two possible reasoning paths are marked with red arrows, which are taken as explanations to the recommendations.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "INTRODUCTION", "text": "Recommender systems on modern e-commerce platforms serve to support the personalization of the customer shopping experience by presenting potential products of interest to users [15,37]. They draw on diverse forms of historical user behavior, including but not limited to past browsing and previously purchased products, written reviews, as well as added favorites [11]. The models are expected to capture customized patterns of user preference across products, and hence can be leveraged to provide more accurate recommendations [27]. In addition to accuracy-driven recommendation, it has become increasingly important in modern e-commerce systems to present auxiliary explanations of the recommendations [49], i.e., the system aims to supply customers with product recommendations accompanied by informative explanations about why those products are being recommended.\nIn this regard, knowledge graphs (KG) [19] have recently come to prominence to address both requirements. A KG can not only provide abundant information about users and items, but can also enable explainable recommendations via explicit KG reasoning [1,43,46]: Starting from a user node, the system sequentially determines the next-hop nodes, and moves towards potential items of interest for the user. The derived path explicitly traces the decisionmaking process and can naturally be regarded as an explanation for the recommended item. For instance, as shown in Fig. 1, one possible reasoning path is User Comment --------\u2192 \"Scratch-proof\" Described_by -1 -------------\u2192 \"Screen protector\", where the product \"Screen protector\" is directly used as a recommendation.\nAlthough KG reasoning for explainable recommendation is promising, several issues still remain to be addressed. First, in order to make use of the reasoning paths to explain the decision-making process, the recommendations are supposed to be derived along with the KG reasoning. However, many existing approaches [1,44] first predict the items to be recommended, and subsequently conduct a separate search for paths matching the user-item pair. Addressing these tasks in isolation means that the explanation may not reflect the actual decision making process for the recommendation. Moreover, this fails to allow the recommendation decision making to benefit from the KG reasoning process. We discuss this further in Section 2. 3.\nSecond, previous work on KG reasoning has largely neglected the diversity of user behavior in the historical activity data. Most approaches consider only item-side knowledge integrated from external sources, such as Freebase [43,52] or product graphs [1,12], restricting user-side information to simple user interactions (e.g., purchasing a product or rating a movie). However, in e-commerce recommendation, user purchases may be triggered by different aspects of past behavior. As an example, in Fig. 1, the user having purchased product \"Pixel 4\" may contribute to the keyword \"Camera\" that the user mentioned in the comment, or to the brand (\"Google\") of some product (\"Home Mini\") owned by the user. User behavior patterns of this sort can be extracted to guide future recommendations (\"Screen protectors\" or \"Surface Dock\").\nLast but not least, a lack of effective guidance on path reasoning makes it less efficient in finding potential paths in the large search space of the KG. Due to the large scale of the KG and the unknown destination before path-finding, in practice, it is infeasible to follow previous methods that enumerate paths among all user-item pairs to choose the best one. Other works [29,46] adopt reward shaping from reinforcement learning [40] to alleviate the issue. However, the reward signal is sparse and cannot effectively and efficiently guide the model to arrive at correct items for recommendation.\nIn this paper, we seek to answer the following three questions regarding the task of KG reasoning for explainable recommendation: 1) Instead of isolating recommendation and path-finding, how to directly perform path reasoning to arrive at items of interest so that the derived paths can explain the recommendation process? 2) Besides rich item-side information, how to explicitly model diverse user behaviors from historical activities so that they can be exploited to provide good guidance in finding potential paths? 3) Upon modeling behavior, how to exploit the user model to conduct the path reasoning in a both effective and efficient manner?\nTo this end, we propose a CoArse-to-FinE neural symbolic reasoning method (Cafe), which first generates a coarse sketch of past user behavior, and then conducts path reasoning to derive recommendations based on the user model for fine-grained modeling. We draw inspiration from the literature in linguistics [2,35], where the human writing process consists of multiple stages focusing on different levels of granularity. This has also been invoked in NLP tasks such as long review generation, where coarse-level aspects are first sketched to guide the subsequent long text generation [10,14,25]. In this work, we first compose a personalized user profile consisting of diverse user-centric patterns, each of which captures prominent coarse-grained behavior from historical user activities. Each profile can provide effective guidance on what patterns of reasoning paths may more likely lead to potential items of interest for a given user. To fully exploit the profile, we maintain an inventory of neural symbolic reasoning modules and accordingly design a path-finding algorithm to efficiently conduct batch path reasoning under the guidance of such profiles. Recommendations are consequently acquired from the batch of reasoning paths produced by the algorithm.\nThis paper makes four key contributions.\n\u2022 First, we highlight important shortcomings of past KG reasoning approaches for explainable recommendation, where pathreasoning and recommendation are addressed in isolation. \u2022 Second, we introduce a coarse-to-fine paradigm to approach the problem by explicitly injecting diverse user behavior modeling into the KG reasoning process. \u2022 Third, we propose a novel profile-guided path reasoning algorithm with neural symbolic reasoning modules to effectively and efficiently find potential paths for recommendations. \u2022 Fourth, we experiment on four real-world e-commerce datasets showing that our model yields high-quality recommendation results and the designed components are effective.", "publication_ref": ["b14", "b36", "b10", "b26", "b48", "b18", "b0", "b42", "b45", "b0", "b43", "b2", "b42", "b51", "b0", "b11", "b28", "b45", "b39", "b1", "b34", "b9", "b13", "b24"], "figure_ref": [], "table_ref": []}, {"heading": "PRELIMINARIES 2.1 Concepts and Notations", "text": "In e-commerce recommendation, a knowledge graph (or product graph) denoted by G p is constructed to capture rich meta-information of products on the platform. It is defined to be a set of triples,\nG p = {(\ud835\udc52, \ud835\udc5f, \ud835\udc52 \u2032 ) | \ud835\udc52, \ud835\udc52 \u2032 \u2208 E p , \ud835\udc5f \u2208 R p }\n, where E p and R p respectively denote the sets of entities and relations. A special subset of entities are called products (items), denoted by I \u2286 E p . Each triple (\ud835\udc52, \ud835\udc5f, \ud835\udc52 \u2032 ) \u2208 G p represents a fact indicating that head entity \ud835\udc52 interacts with tail entity \ud835\udc52 \u2032 through relation \ud835\udc5f .\nAt the same time, diverse user activities can also be modeled as a heterogeneous graph denoted by\nG u = {(\ud835\udc52, \ud835\udc5f, \ud835\udc52 \u2032 ) | \ud835\udc52, \ud835\udc52 \u2032 \u2208 E u , \ud835\udc5f \u2208 R u }\n, where E u and R u are entity and relation sets satisfying that user set U \u2286 E u , item set I \u2286 E u , and user-item interaction\n\ud835\udc5f \ud835\udc62\ud835\udc56 \u2208 R u . When |R u | = 1 and E u = U \u222a I, G u is a bipartite user- item graph.\nHere, we assume G u is the general user interaction graph consisting of diverse interactions and objects, e.g., a user can make comments as in Fig. 1.\nFor convenience, we unify both product graph and user interaction graph into the same framework, which we call User-centric KG, denoted as G = G p \u222a G u with combined entity set E = E p \u222a E u and relation set R = R p \u222a R u . In the remainder of this paper, the term KG generally refers to this User-centric KG.\nA path in the KG is defined as a sequence of entities and relations, denoted by \ud835\udc3f = {\ud835\udc52 0 , \ud835\udc5f To guarantee the existence of paths, inverse edges are added into the KG, i.e., if (\ud835\udc52, \ud835\udc5f, \ud835\udc52 \u2032 ) \u2208 G, then (\ud835\udc52 \u2032 , \ud835\udc5f -1 , \ud835\udc52) \u2208 G, where \ud835\udc5f -1 denotes the inverse relation with respect to \ud835\udc5f \u2208 R. One kind of path of particular interest is called a user-centric path. Such a path originates at a user entity (\ud835\udc52 0 \u2208 U) and ends with an item entity (\ud835\udc52 |\ud835\udc3f | \u2208 I). We also define a user-centric pattern \ud835\udf0b to be a relational path between a user and an item, \ud835\udf0b = {\ud835\udc5f 1 , . . . , \ud835\udc5f |\ud835\udf0b | }. Hence, the relation sequence of any user-centric path forms a usercentric pattern. Such a pattern can be viewed as a semantic rule that describes a specific user behavior towards a product via some actions (relations) on the e-commerce platform. Additionally, we define the user profile T \ud835\udc62 of user \ud835\udc62 to be an aggregation of usercentric patterns with weights,\nT \ud835\udc62 = {(\ud835\udf0b 1 , \ud835\udc64 1 ), . . . , (\ud835\udf0b | T \ud835\udc62 | , \ud835\udc64 | T \ud835\udc62 | )},\nwhere \ud835\udc64 1 , . . . , \ud835\udc64 | T \ud835\udc62 | \u2208 N are the weights of patterns. Each user profile distinctively characterizes prominent user behavior from the purchase history as well as diverse other activities, and can be leveraged to guide KG reasoning for recommendation (Section 3.2).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Problem Formulation", "text": "In this work, we study the problem of KG reasoning for explainable recommendation in an e-commerce scenario [46]. By leveraging rich information in the KG, we aim to predict a set of items as recommendations for each user along with the corresponding usercentric paths as the explanation. The problem is formulated as follows.\nDefinition 1. (Problem Definition) Given an incomplete usercentric KG G and an integer \ud835\udc3e, for each user \ud835\udc62 \u2208 U, the goal is to generate 1) a set of \ud835\udc3e items \ud835\udc56 (\ud835\udc58) \ud835\udc56 (\ud835\udc58) \u2208 I, (\ud835\udc62, \ud835\udc5f \ud835\udc62\ud835\udc56 , \ud835\udc56 (\ud835\udc58) \n) \u2209 G, \ud835\udc58 \u2208 [\ud835\udc3e] ,\nand 2) \ud835\udc3e corresponding user-centric paths \ud835\udc3f \ud835\udc62 \ud835\udc56 (\ud835\udc58 ) \ud835\udc58 \u2208 [\ud835\udc3e ] .", "publication_ref": ["b45"], "figure_ref": [], "table_ref": []}, {"heading": "A Coarse-to-Fine Paradigm", "text": "The general framework to approach the problem in Def. 1 consists of two parts: a recommendation component \ud835\udc53 rec and a path inference component \ud835\udc53 path . In most existing approaches [1,32,41,44,46], \ud835\udc53 rec : \ud835\udc62, \ud835\udc56 \u21a6 \u2192 R estimates a similarity score between user \ud835\udc62 and an item \ud835\udc56 using enriched information from the KG. \ud835\udc53 path : \ud835\udc62, \ud835\udc56 \u21a6 \u2192 \ud835\udc3f outputs a user-centric path \ud835\udc3f given user \ud835\udc62 and item \ud835\udc56 (sometimes \ud835\udc56 is not necessary as input [46]). The major differences between existing works lie in 1) the technical implementation and 2) the composition and execution order of these components. Below we revisit the existing KG reasoning paradigms and highlight the benefits of the proposed coarse-to-fine paradigm.\nRec-First Paradigm. One group of approaches [1,41,44] first makes recommendations via \ud835\udc53 rec , followed by a separate process \ud835\udc53 path to search paths that best match the predicted user-item pair:\n\u00ee = argmax \ud835\udc56 \u2208I \ud835\udc53 rec (\ud835\udc62, \ud835\udc56; G), L\ud835\udc62 \u00ee = \ud835\udc53 path (\ud835\udc62, \u00ee; G),\nwhere \u00ee, L\ud835\udc62 \u00ee are the predicted item and path, respectively. Common choices of \ud835\udc53 rec include KG embeddings [3,41] and relational graph neural networks [38,44]. \ud835\udc53 path usually refers to a path ranking model [13,46] or graph search algorithm [1,9]. However, it is worth noting that one critical limitation of this paradigm is the isolation of recommendation \ud835\udc53 rec and path selection \ud835\udc53 path . This may degrade recommendation performance, as it is solely determined by \ud835\udc53 rec , but fails to benefit from the post-hoc path-finding of \ud835\udc53 path . More importantly, the reported path is not a genuine explanation of the actual recommendation process.\nPath-Guided Paradigm. Another line of work [46] first uses \ud835\udc53 path to perform path-finding with unknown destination and the reached item is naturally adopted as the recommendation:\nL\ud835\udc62 \ud835\udc52 \ud835\udc47 = \ud835\udc53 path (\ud835\udc62, -; G u ), \u00ee = \ud835\udc52 \ud835\udc47 ,\nwhere \"-\" means no item is required as input and \ud835\udc52 \ud835\udc47 is the last entity of path L\ud835\udc62 \ud835\udc52 \ud835\udc47 . Here, \ud835\udc53 path usually adopts a multi-step reasoning model such as a policy network [29,40,46] to sequentially pick the next step in the KG. Since the recommendation is derived along with the path inference results, \ud835\udc53 path implicitly contains the recommendation process, and the resulting path can be used to track and explain the decision-making process. However, due to the challenges of unknown destinations and the huge search space of KG, the signals (e.g., rewards) are very sparse and cannot effectively guide the path inference to achieve satisfactory recommendation, in comparison with Rec-First approaches.\nCoarse-to-Fine Paradigm. To achieve direct path reasoning while simultaneously obtaining competitive recommendation performance, we propose a novel coarse-to-fine paradigm. In the coarse stage, we introduce a new component \ud835\udc53 profile : \ud835\udc62 \u21a6 \u2192 T \ud835\udc62 that composes a user profile T \ud835\udc62 to capture prominent user behavior from historic data (details in Section 3.1). Then, for fine-grained modeling, an improved variant of path inference component \ud835\udc53 \u2032 path : \ud835\udc62, T \ud835\udc62 \u21a6 \u2192 \ud835\udc3f is developed to perform multi-step path reasoning guided by the composed user profile (details in Section 3.2):\nT \ud835\udc62 = \ud835\udc53 profile (\ud835\udc62; G u ), L\ud835\udc62 \ud835\udc52 \ud835\udc47 = \ud835\udc53 \u2032 path (\ud835\udc62, T \ud835\udc62 ; G u ), \u00ee = \ud835\udc52 \ud835\udc47 . (1)\nThe path reasoning relies on a one-step reasoner \ud835\udf19 with learnable parameter \u0398 (see Section 3.1.2). It determines the \ud835\udc61 th step action by estimating the probability \ud835\udc43 \u0398 (\ud835\udc5f \ud835\udc61 , \ud835\udc52 \ud835\udc61 |\ud835\udc62, \u210e \ud835\udc61 ) of choosing an outgoing edge (\ud835\udc5f \ud835\udc61 , \ud835\udc52 \ud835\udc61 ) given user \ud835\udc62 and history trajectory \u210e \ud835\udc61 = {\ud835\udc5f 1 , \ud835\udc52 1 , . . . , \ud835\udc5f \ud835\udc61 -1 , \ud835\udc52 \ud835\udc61 -1 }. Therefore, we can estimate the probability of a multi-step path \ud835\udc3f = {\ud835\udc62, \ud835\udc5f 1 , \ud835\udc52 1 , . . . , \ud835\udc5f \ud835\udc47 , \ud835\udc52 \ud835\udc47 } being generated by \ud835\udf19:\nlog \ud835\udc43 \u0398 (\ud835\udc3f|\ud835\udc62) = \ud835\udc47 \u2211\ufe01 \ud835\udc61 =1 log \ud835\udc43 \u0398 (\ud835\udc5f \ud835\udc61 , \ud835\udc52 \ud835\udc61 |\ud835\udc62, \u210e \ud835\udc61 )(2)\nThis paradigm has three notable benefits.\n\u2022 Explicit user modeling from \ud835\udc53 profile can detect prominent usercentric patterns, which assist the path reasoning process in arriving at potential items of interest to the user.", "publication_ref": ["b0", "b31", "b40", "b43", "b45", "b45", "b0", "b40", "b43", "b2", "b40", "b37", "b43", "b12", "b45", "b0", "b8", "b45", "b28", "b39", "b45"], "figure_ref": [], "table_ref": []}, {"heading": "\u2022 Path inference via \ud835\udc53 \u2032", "text": "path is conducted under the guidance of the user profile so as to improve both the effectiveness and efficiency of the path-finding process.\n\u2022 The reasoner \ud835\udf19 is decomposed into an inventory of neural reasoning modules, which can be composed on the fly based on the user profile to execute \ud835\udc53 \u2032 path .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "METHODOLOGY", "text": "Under the coarse-to-fine paradigm, we present a corresponding method called Cafe to approach the problem of KG reasoning for recommendation. As illustrated in Fig. 2, given a KG (a), a user profile is first composed to capture prominent user-centric patterns \n\ud835\udf53 \ud835\udc93\ud835\udfcf \ud835\udf53 \ud835\udc93\ud835\udfd0 \ud835\udf53 \ud835\udc93\ud835\udfd1 \ud835\udf53 \ud835\udc93\ud835\udfd3 \ud835\udf19 \"% \ud835\udf19 \" & '( \ud835\udf19 \"( \ud835\udf19 \" ( '( \ud835\udf19 \"( \ud835\udf19 \") \ud835\udf19 \" ) '( \ud835\udc52 \" \ud835\udc56 ! \ud835\udc62 \" \ud835\udc56 # \ud835\udc56 $ \ud835\udc62 # \ud835\udc52 ! \ud835\udc56 % \ud835\udc56 % \ud835\udc52 $ \ud835\udf53 \ud835\udc93\ud835\udfd2 \ud835\udc56 & \ud835\udc64=1 \ud835\udc5b=1 \ud835\udc5b=2 \ud835\udc5b=1 \ud835\udc5b=1 \ud835\udc5b=1 \ud835\udc5b=1 \ud835\udc5f $ \ud835\udc5f % \ud835\udc5f & \ud835\udc5f \" \ud835\udc5f # Relations \ud835\udc5b=1", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Input user", "text": "Recommend? Why?\n\ud835\udc96 \" \ud835\udc96 \" \ud835\udc96 \" \ud835\udc96 \" \ud835\udc96 \" \ud835\udc96 \" \ud835\udc96 \" \ud835\udc96 \" Profile-guided Path Reasoning (PPR) \ud835\udc93 \ud835\udfd0 \ud835\udc93 \ud835\udfd1 )\ud835\udfcf \ud835\udc93 \ud835\udfcf \ud835\udc93 \ud835\udfcf )\ud835\udfcf \ud835\udc93 \ud835\udfcf \ud835\udc93 \ud835\udfd2 \ud835\udc93 \ud835\udfcf \ud835\udc93 \ud835\udfd2 )\ud835\udfcf \ud835\udf0b \" (\ud835\udc64 \" =1) \ud835\udc5f #$%%& (b) User Profile of \ud835\udc62 \" \ud835\udf0b # (\ud835\udc64 # =2) \ud835\udf0b $ (\ud835\udc64 $ =2) (c) Neural Symbolic Reasoning Modules Selected in user profile of \ud835\udc62 ' \ud835\udc62 \" \ud835\udc56 # \ud835\udc52 # \ud835\udc56 ! \ud835\udc56 $ \ud835\udc56 % \ud835\udc62 # \ud835\udc52 ! \ud835\udc52 $ \ud835\udc56 & \ud835\udc52 \" \ud835\udc56 \" \ud835\udc62 $ \ud835\udc52 %", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Task: KG Reasoning for Recommendation (d) Layout Tree (e) Output Paths", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Input user", "text": "Unselected in the coarse stage (b). To conduct multi-hop path reasoning guided by the user profile, we decompose the reasoner \ud835\udf19 into an inventory of neural reasoning modules (c). In the fine stage, the selective neural symbolic reasoning modules are composed based on the user profile (d), which are exploited by a Profile-guided Path Reasoning (PPR) algorithm to efficiently perform batch path reasoning for recommendation (e).\n\ud835\udf53 \ud835\udc93\ud835\udfd4", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Coarse-Stage: User Profile Composition", "text": "Given a user \ud835\udc62, the goal of \ud835\udc53 profile is to find a set of user-centric patterns that can distinctively characterize user behaviors, so that the potential paths with these patterns are more likely to arrive at items of interest to the given user. Since e-commerce KGs usually contain a large number of relations, we first adopt an off-the-shelf random walk based algorithm [24] to produce a candidate set of \ud835\udc40 user-centric patterns, \u03a0 = {\ud835\udf0b 1 , \ud835\udf0b 2 , . . . , \ud835\udf0b \ud835\udc40 }, with maximum length \ud835\udc3b , from interacted user-item pairs in G. To compose the user profile, one naive way is to assign the weights in proportion to the frequency of these retrieved patterns. However, this only provides overall information of user behavior towards items and is empirically shown not to achieve satisfying performance compared to personalized user profile (details in Section 4.3).", "publication_ref": ["b23"], "figure_ref": [], "table_ref": []}, {"heading": "Personalized Pattern Selection.", "text": "The task of user profile composition now turns to selecting a subset from \u03a0 and assigning weights that reflect the prominent behaviors for each user. Formally, let \ud835\udc49 \u0398 (\ud835\udc62, \ud835\udf0b) be the prominence of a user-centric pattern \ud835\udf0b for user \ud835\udc62. Intuitively, if \ud835\udf0b is prominent with a larger value of \ud835\udc49 \u0398 (\ud835\udc62, \ud835\udf0b), it is more likely that the reasoning model \ud835\udf19 can derive a path with pattern \ud835\udf0b from \ud835\udc62 to potential items of interest. Hence, we define \ud835\udc49 \u0398 (\ud835\udc62, \ud835\udf0b) to be the likelihood of \"correct\" paths being generated by \ud835\udf19:\n\ud835\udc49 \u0398 (\ud835\udc62, \ud835\udf0b) = E \ud835\udc3f\u223c\ud835\udc37 \ud835\udf0b [log \ud835\udc43 \u0398 (\ud835\udc3f | \ud835\udc62)],(3)\nwhere \ud835\udc37 \ud835\udf0b denotes the set of paths with pattern \ud835\udf0b between the user \ud835\udc62 and interacted items in G u , and log \ud835\udc43 \u0398 (\ud835\udc3f|\ud835\udc62) is defined in Eq. 2.\nHere, we assume the reasoner \ud835\udf19 has been trained and the parameter \u0398 is fixed. The representation and model learning details will be discussed in Section 3.1.2. With the help of \ud835\udc49 \u0398 (\ud835\udc62, \ud835\udf0b), we propose a heuristic method to select prominent patterns to compose the profile for each user. Specifically, the goal is to determine the weights {\ud835\udc64 1 , . . . , \ud835\udc64 \ud835\udc40 } of candidate patterns in \u03a0 and only the patterns with positive weights are kept. This can be formalized as an optimization problem:\nmax \ud835\udc64 1 ,...,\ud835\udc64 \ud835\udc40 \u2211\ufe01 \ud835\udc57 \ud835\udc64 \ud835\udc57 \ud835\udc49 \u0398 (\ud835\udc62, \ud835\udf0b \ud835\udc57 ) s.t. \u2211\ufe01 \ud835\udc57 \ud835\udc64 \ud835\udc57 = \ud835\udc3e, 0 \u2264 \ud835\udc64 \ud835\udc57 \u2264 \ud835\udc3e \ud835\udc57 , \ud835\udc57 \u2208 [\ud835\udc40],(4)\nwhere \ud835\udc3e \ud835\udc57 is the upper bound of the quantity of pattern \ud835\udf0b \ud835\udc57 to be adopted. The optimization problem corresponds to the well-studied bounded knapsack problem with equal weights 1 and can be easily solved [9]. Consequently, the user profile can be derived from Eq. 4 by  [46], we can treat \ud835\udf19 as a stochastic policy network [40]. However, instead of solving a reinforcement learning problem that requires a careful handcrafted design of good reward functions, we train the model \ud835\udf19 via behavior cloning [40] by reusing the sampled paths that are previously retrieved to produce candidate patterns \u03a0.\nT \ud835\udc62 = {(\ud835\udf0b \ud835\udc57 , \ud835\udc64 \ud835\udc57 ) | \ud835\udf0b \ud835\udc57 \u2208 \u03a0, \ud835\udc64 \ud835\udc57 > 0, \ud835\udc57 \u2208 [\ud835\udc40]} (see example in Fig. 2(b)\nNevertheless, learning \ud835\udf19 is still challenging due to the huge search space in the KG, where the out-degrees of nodes can be very large and the number of connecting edges varies from node to node. To address this, instead of representing \ud835\udf19 as a deep and complex neural network to increase the reasoning capability, we propose to maintain an inventory of shallow neural symbolic reasoning modules \ud835\udf19 \ud835\udc5f with parameter \u0398 \ud835\udc5f for each relation \ud835\udc5f in \u03a0, as shown in Fig. 2(c). Each \ud835\udf19 \ud835\udc5f (u, h; \u0398 \ud835\udc5f ) : R \ud835\udc51 \u00d7 R \ud835\udc51 \u21a6 \u2192 R \ud835\udc51 takes as input a user embedding u and a history embedding h and outputs the estimated vector of the next-hop entity. The network structure of each \ud835\udf19 \ud835\udc5f is defined as:\n\ud835\udf19 \ud835\udc5f (\ud835\udc62, \u210e; \u0398 \ud835\udc5f ) = \ud835\udf0e (\ud835\udf0e ([u; h]\ud835\udc4a \ud835\udc5f,1 )\ud835\udc4a \ud835\udc5f,2 )\ud835\udc4a \ud835\udc5f,3 ,(5)\nwhere [; ] denotes concatenation, \ud835\udf0e (\u2022) is a nonlinear activation function (e.g., ReLU [34]), and \u0398 \ud835\udc5f = {\ud835\udc4a \ud835\udc5f,1 ,\ud835\udc4a \ud835\udc5f,2 ,\ud835\udc4a \ud835\udc5f,3 } are the learnable parameters for the module \ud835\udf19 \ud835\udc5f .\nWith the module \ud835\udf19 \ud835\udc5f \ud835\udc61 , we can compute the probability\n\ud835\udc43 \u0398 (\ud835\udc5f \ud835\udc61 , \ud835\udc52 \ud835\udc61 | \ud835\udc62, \u210e \ud835\udc61 ) \u2248 1 \ud835\udc4d exp(\u27e8\ud835\udf19 \ud835\udc5f \ud835\udc61 (u, h \ud835\udc61 ; \u0398 \ud835\udc5f \ud835\udc61 ), e \ud835\udc61 \u27e9),(6)\nwhere\n\ud835\udc4d = \ud835\udc52 \u2032 \ud835\udc61 exp(\u27e8\ud835\udf19 \ud835\udc5f \ud835\udc61 (u, h \ud835\udc61 ; \u0398 \ud835\udc5f \ud835\udc61 ), e \u2032 \ud835\udc61 \u27e9\n) is the normalization term over all possible next-hop entities, and \u27e8\u2022, \u2022\u27e9 is the dot product.\nThe benefits of this design are threefold. First, the total number of parameters of maintaining such small modules is smaller than that of a deep and complex neural network. Second, the space of next-hop actions is reduced from (\ud835\udc5f \ud835\udc61 , \ud835\udc52 \ud835\udc61 ) (all outgoing edges) to \ud835\udc52 \ud835\udc61 (only the edges of given relation), since the relation can be determined by the user profile. Third, outputting a continuous vector can effectively solve the issue of varying numbers of outgoing edges.\nObjectives. We consider the set of all parameters \u0398 = {e|\u2200\ud835\udc52 \u2208 E} \u222a {\u0398 \ud835\udc5f |\u2200\ud835\udc5f \u2208 \u03a0}, where e denotes the entity embedding and is initialized with a pretrained KG embedding [3]. Given a positive path \ud835\udc3f = {\ud835\udc62, \ud835\udc5f 1 , \ud835\udc52 1 , . . . , \ud835\udc52 \ud835\udc47 -1 , \ud835\udc5f \ud835\udc47 , \ud835\udc56 + } with (\ud835\udc62, \ud835\udc5f \ud835\udc62\ud835\udc56 , \ud835\udc56 + ) \u2208 G, the behavior cloning aims to minimize the following loss over \u0398:\n\u2113 path (\u0398; \ud835\udc3f) = -log \ud835\udc43 \u0398 (\ud835\udc3f|\ud835\udc62) = - \ud835\udc47 \u2211\ufe01 \ud835\udc61 =1 log \ud835\udc43 \u0398 (\ud835\udc5f \ud835\udc61 , \ud835\udc52 \ud835\udc61 |\ud835\udc62, \u210e \ud835\udc61 ). (7)\nHowever, the objective in Eq. 7 only forces the reasoning modules to fit the given path, but cannot identify which path may finally lead to potential items of interest. Therefore, we impose an additional pairwise ranking loss \u2113 rank (\u0398; \ud835\udc3f) to jointly train the parameters \u0398:\n\u2113 rank (\u0398; \ud835\udc3f) = -E \ud835\udc56 -\u223c\ud835\udc37 - \ud835\udc62 \ud835\udf0e i + , \u00ea\ud835\udc47 -\u27e8i -, \u00ea\ud835\udc47 \u27e9 ,(8)\nwhere \ud835\udc37 - \ud835\udc62 denotes the set of negative items of user \ud835\udc62, i.e., \ud835\udc37 - \ud835\udc62 = {\ud835\udc56 |\ud835\udc56 \u2208 I, (\ud835\udc62, \ud835\udc5f \ud835\udc62\ud835\udc56 , \ud835\udc56) \u2209 G}, \u00ea\ud835\udc47 = \ud835\udf19 \ud835\udc5f \ud835\udc47 (u, h \ud835\udc47 ; \u0398 \ud835\udc5f \ud835\udc47 ), and \ud835\udf0e (\u2022) is the sigmoid function.\nBy aggregating Eqs. 7 and 8 over all users in KG G u , the overall goal is to minimize the following objective:\n\u2113 all (\u0398) = \u2211\ufe01 \ud835\udc62 \u2211\ufe01 \ud835\udc3f\u223cL \ud835\udc62 \u2113 path (\u0398; \ud835\udc3f) + \ud835\udf06\u2113 rank (\u0398; \ud835\udc3f),(9)\nwhere L \ud835\udc62 = {\ud835\udc3f \ud835\udc62 \ud835\udc56+ | (\ud835\udc62, \ud835\udc5f \ud835\udc62\ud835\udc56 , \ud835\udc56 + ) \u2208 G u , pattern(\ud835\udc3f \ud835\udc62 \ud835\udc56+ ) \u2208 \u03a0}, and \ud835\udf06 is the weighting factor to balance between the two losses.", "publication_ref": ["b8", "b45", "b39", "b39", "b33", "b2"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Fine-Stage: Path Reasoning for Recommendation", "text": "Given the composed user profile T \ud835\udc62 = {(\ud835\udf0b 1 , \ud835\udc64 1 ), . . . , (\ud835\udf0b \ud835\udc40 , \ud835\udc64 \ud835\udc40 )} of user \ud835\udc62, the goal of \ud835\udc53 path is to output \ud835\udc3e reasoning paths along with Construct layout tree \ud835\udc47 \ud835\udc62 based on user profile T \ud835\udc62 .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "5:", "text": "\ud835\udc65 \u2190 RO O T (\ud835\udc47 \ud835\udc62 ), x \u2190 u, L \ud835\udc65 \u2190 {{\ud835\udc62}}.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "6:", "text": "Initialize queue \ud835\udc44 \u2190 CH I L D R E N (\ud835\udc65).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "7:", "text": "while \ud835\udc44 \u2260 \u2205 do 8:\n\ud835\udc65 \u2190 \ud835\udc44.\ud835\udc5d\ud835\udc5c\ud835\udc5d (), \ud835\udc5d \u2190 PA R E N T (\ud835\udc65).\n9:\nx \u2190 \ud835\udf19 \ud835\udc5f \ud835\udc65 (u, p; \u0398 \ud835\udc5f \ud835\udc65 ).\n10:\nInitialize L \ud835\udc65 \u2190 {}.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "11:", "text": "for \ud835\udc3f \u2208 L \ud835\udc5d do 12:\n\ud835\udc38 \ud835\udc65 \u2190 {\ud835\udc52 \u2032 | \u2200(\ud835\udc52 |\ud835\udc3f | , \ud835\udc5f \ud835\udc65 , \ud835\udc52 \u2032 ) \u2208 G, \ud835\udf0f (\ud835\udc52 \u2032 ) = \ud835\udf0f \ud835\udc61 (\ud835\udc5f \ud835\udc65 ), rank(\u27e8x, e \u2032 \u27e9) \u2264 \ud835\udc5b \ud835\udc65 }. 13: L \ud835\udc65 \u2190 L \ud835\udc65 \u222a (\ud835\udc3f \u222a {\ud835\udc52 \u2032 }), for \ud835\udc52 \u2032 \u2208 \ud835\udc38 \ud835\udc65 . 14: Update \ud835\udc44 \u2190 \ud835\udc44 \u222a CH I L D R E N (\ud835\udc65).\n15:\nreturn \ud835\udc65 \u2208LE A V E S (\ud835\udc47 \ud835\udc62 ) L \ud835\udc65 .\nitems such that the number of paths with pattern \ud835\udf0b \ud835\udc57 is proportional to \ud835\udc64 \ud835\udc57 . Considering that finding each path individually is inefficient due to repeated node visitation and calculation [46], we propose a Profile-guided Path-Reasoning algorithm (PPR) that is capable of finding a batch of paths simultaneously via selective neural symbolic reasoning modules according to the composed user profile. As illustrated in Fig. 2(d), it first constructs a layout tree \ud835\udc47 \ud835\udc62 from the user profile T \ud835\udc62 to specify the execution order of neural symbolic reasoning modules. Then, the reasoning modules are executed level by level to produce the next-hop embeddings that are employed to find the closest entities in the KG (Fig. 2(e)).\nThe details of the algorithm are given in Alg. 1. Specifically, the layout tree \ud835\udc47 \ud835\udc62 (line 4) is first constructed by merging patterns in T \ud835\udc62 , so that each node \ud835\udc65 \u2208 \ud835\udc47 \ud835\udc62 is associated with a relation \ud835\udc5f \ud835\udc65 (a dummy relation is used for the root node), and each root-to-leaf tree path corresponds to a pattern in T \ud835\udc62 . Next, an integer \ud835\udc5b \ud835\udc65 is assigned to each node \ud835\udc65, which specifies the number of entities to be generated at the current position. If node \ud835\udc65 is the root, one sets \ud835\udc5b \ud835\udc65 = 1. If \ud835\udc65 is a leaf, \ud835\udc5b \ud835\udc65 is initialized with \ud835\udc64 \ud835\udc57 , i.e., the weight of pattern \ud835\udf0b \ud835\udc57 that ends with relation \ud835\udc5f \ud835\udc65 . Otherwise, \ud835\udc5b \ud835\udc65 is updated by \ud835\udc5b \ud835\udc65 = min \ud835\udc50 \u2208children(\ud835\udc65) (\ud835\udc5b \ud835\udc50 ), and subsequently, the value at each child \ud835\udc50 of node \ud835\udc65 will be refreshed as \ud835\udc5b \u2032 \ud835\udc50 = \u230a\ud835\udc5b \ud835\udc50 /\ud835\udc5b \ud835\udc65 \u230b. In fact, \ud835\udc47 \ud835\udc62 specifies the layout of a tree-structured neural network composed of reasoning modules \ud835\udf19 \ud835\udc5f \ud835\udc65 at each node \ud835\udc65 with relation \ud835\udc5f \ud835\udc65 . The execution process of the network is described in Alg. 1 (lines 5-15) to derive \ud835\udc3e reasoning paths simultaneously. It starts at the root node of \ud835\udc47 \ud835\udc62 and follows level-order traversal to generate paths. At each node \ud835\udc65 \u2208 \ud835\udc47 \ud835\udc62 , \ud835\udf19 \ud835\udc5f \ud835\udc65 takes as input the user embedding u and the embedding from its parent node and outputs an embedding vector denoted by x. Meanwhile, a set of new paths L \ud835\udc65 up to node \ud835\udc65 is generated based on x as well as the paths from its parent node L \ud835\udc5d . Specifically, for each path \ud835\udc3f \u2208 L \ud835\udc5d , we find at most \ud835\udc5b \ud835\udc65 new entities such that each of them is connected to the last entity in \ud835\udc3f in the KG, and its embedding is most similar to x. Eventually, we obtain the final results by aggregating all the paths at the leaf nodes and rank them based on the dot-product score in Eq. 6. ", "publication_ref": ["b45"], "figure_ref": ["fig_1", "fig_1"], "table_ref": []}, {"heading": "CDs & Vinyl", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Model Analysis", "text": "For each user, the time complexity of PPR in Alg. 1 is \ud835\udc42 (\ud835\udc40\ud835\udc3b (\ud835\udc44 + \ud835\udc3e\ud835\udc51\ud835\udc37)), where \ud835\udc44 is the running time for executing each neural symbolic reasoning module, \ud835\udc51 is the dimensionality of entity embeddings, \ud835\udc37 is the maximum node degree in the KG. Intuitively, there are at most \ud835\udc42 (\ud835\udc40\ud835\udc3b ) nodes in \ud835\udc47 \ud835\udc62 , and for each node, it costs \ud835\udc42 (\ud835\udc40\ud835\udc3b\ud835\udc44) time for the inference (forward pass) of the neural reasoning module, and \ud835\udc42 (\ud835\udc3e\ud835\udc51\ud835\udc37) time to find nearest entities in Alg. 1. Unlike existing methods [1,46] that find each individual path separately, our PPR algorithm can derive all \ud835\udc3e paths simultaneously in the tree level order. If some resulting paths share the same entities, their corresponding embeddings will be computed only once and hence redundant computations are avoided. The efficiency of the algorithm is also empirically evaluated in Section 4.4.", "publication_ref": ["b0", "b45"], "figure_ref": [], "table_ref": []}, {"heading": "EXPERIMENTS", "text": "In this section, we extensively evaluate our proposed approach, providing a series of quantitative as well as qualitative analyses on several real-world datasets.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Setup", "text": "4.1.1 Dataset. We experiment on four domain-specific e-commerce datasets from Amazon [18], namely CDs and Vinyl, Clothing, Cell Phones, and Beauty. They provide both rich meta-information of products and diverse user behavior records such as purchase history, ratings, product reviews, and preferred styles. Each dataset is considered as an individual benchmark that constitutes a user-centric KG with various types of relations (including inverse relations), which implies that results are not necessarily comparable across different domains. Table 1 summarizes the statistical information of the four datasets. We adopt the same training (70%) and test splits (30%) as previous work [1,46], which are publicly availablefoot_0 .", "publication_ref": ["b17", "b0", "b45"], "figure_ref": [], "table_ref": ["tab_3"]}, {"heading": "Baselines and Metrics.", "text": "We consider three categories of recommendation approaches as baselines in the following experiments.\n\u2022 MF-based models: BPR [36] is a Bayesian personalized method that optimizes a pairwise ranking between different user-item pairs for top-\ud835\udc41 recommendation. BPR-HFT [33] is a reviewbased recommendation method based on Hidden Factors and Topics (HFT) to learn latent representations of users and items with the topic distributions incorporated. DeepCoNN [54] makes recommendations through a Deep Cooperative Neural Network based on reviews, which is capable of encoding both users and products for rating prediction.\n\u2022 KG embedding models: CKE [48], or Collaborative Knowledge base Embedding, is a neural recommendation method based on jointly integrating matrix factorization and heterogeneous graph data to infer recommendations. RippleNet [41] incorporates a KG into recommendation by propagating user preferences on entities. KGAT [44] is the the state-of-the-art KG-based model using graph-based attention techniques. \u2022 Path reasoning models: HeteroEmbed [1] is the state-of-the-art Rec-First approach based on TransE [3] embeddings for recommendations, followed by a post-hoc graph search to find paths. PGPR [46] is the state-of-the-art path-guided model, which conducts path reasoning using reinforcement learning. For all models, we adopted the same metrics as previous work [46] to evaluate the top-10 recommendations of each user in the test set, including Normalized Discounted Cumulative Gain (NDCG), Recall, Hit Rate (HR), and Precision (Prec.).", "publication_ref": ["b35", "b32", "b53", "b47", "b40", "b43", "b0", "b2", "b45", "b45"], "figure_ref": [], "table_ref": []}, {"heading": "Implementation Details.", "text": "In our model, the entity embedding dimensionality is 100. In each neural relation module \ud835\udf19 \ud835\udc5f with respect to some relation \ud835\udc5f , the parameters are \ud835\udc4a \ud835\udc5f,1 \u2208 R 200\u00d7256 , \ud835\udc4a \ud835\udc5f,2 \u2208 R 256\u00d7256 , and \ud835\udc4a \ud835\udc5f,3 \u2208 R 256\u00d7100 . We use Xavier initialization for the parameters and train them with Adam optimization [22] with a learning rate of 10 -4 , batch size of 128, and a number of training epochs of 20. The history \u210e \ud835\udc61 is set to \ud835\udc52 \ud835\udc61 -1 . The weighting factor \ud835\udf06 for the ranking loss is set to 10. The number of output paths \ud835\udc3e is 15. For fair comparison with previous work [1,46], we also restrict the maximum path length \ud835\udc3b to 3, which leads to 15 candidate user-centric patterns in \u03a0. The influence of these hyperparameters will be studied in Section 4.6.", "publication_ref": ["b21", "b0", "b45"], "figure_ref": [], "table_ref": []}, {"heading": "Overall Performance", "text": "We first show the top-10 recommendation performance of our proposed method Cafe compared to all baselines. We evaluate each setting 5 times and report the average scores in Table 2.\nOverall, we observe that our method outperforms three kinds of state-of-the-art methods (KGAT, HeteroEmbed, PGPR) by a large margin across all settings. For example, on the Clothing dataset, our model achieves 6.340% in Recall, which is higher than 5.172% by KGAT, 5.466% by HeteroEmbed, and 4.834% of PGPR. Similar trends can also be observed on other benchmarks. Additionally, our model shows better ranking performance than the baselines in terms of NDCG. This is mainly attributed to the ranking loss in Eq. 8, which encourages the model to identify the path based on whether it can lead to good items. The influence of the ranking loss will be studied in Section 4.6.1.\nNote that KG embedding based approaches such as RippleNet and KGAT are less competitive on these datasets. One possible reason is that unlike KGs such as Freebase, where the reasoning rules are objective and explicit (e.g., HasNationality = BornIn \u2227 CityIn), the patterns of user behavior towards items are more diverse and uncertain in e-commence settings (e.g., many factors can contribute to a user purchase behavior), making it harder to mine useful information. Our coarse-to-fine method can first learn a sketch of user behavior (i.e., user profile), which filters out noisy information that may be irrelevant to conduct path reasoning. That is why our model is able to achieve better recommendation performance. The effectiveness of user profiles is studied in the next section. Table 3: Results of recommendation performance using different user profile variants.\nIn this experiment, we evaluate the effectiveness of the approach to compose user profiles as described in Section 3.1. Specifically, we consider the following ways to compose different T \ud835\udc62 for user \ud835\udc62 while keeping the same path reasoning algorithm in Section 3.2.\n\u2022 Rand stands for randomly sampling a subset of patterns from \u03a0 to compose T \ud835\udc62 . This straightforward method can represent the path reasoning methods without considering user profiles. \u2022 Prior samples the patterns from \u03a0 proportional to their frequencies and discards low frequency patterns. This is equivalent to assigning each user the same profile based on global information. \u2022 Cafe is the approach we propose, which estimates the weights by solving the optimization problem in Eq. 4.\nAdditionally, we also compare to the SOTA path reasoning approach PGPR that also fails to model user profiles.\nThe results on all datasets are reported in Table 3. We observe that our model Cafe with composed user profile exhibits better recommendation performance than other baselines. This shows that the path reasoning guided by the user profile can find usercentric paths of higher quality, which are more likely to arrive at an item node of interest to the user. In addition, we also note that the profile-driven methods Cafe and Prior outperform the ones without profiles (PGPR, Rand). This suggests that user profiles can benefit the path reasoning process. ", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_4"]}, {"heading": "Efficiency of Path Reasoning (Fine-Stage)", "text": "We further study the efficiency of our path reasoning algorithm in Section 3.2 compared to other path-finding baselines. Specifically, we consider the SOTA Path-Guided method PGPR and the SOTA Rec-First method HeteroEmbed. We also include a variant of our algorithm in Alg. 1 named Indiv., which simply finds each individual path one by one. These algorithms are evaluated on the empirical running time of 1) making recommendations (including both items and paths) for 1k users and 2) the path-finding process (only paths) for generating 10k paths. All experiments are conducted on the same hardware with Intel i7-6850K CPU, 32G memory and one Nvidia 1080Ti GPU. The results are reported in Table 4. We observe that our method costs the least time for both tasks among all tested algorithms. In particular, our method is about 10\u00d7 faster than PGPR in making recommendations on all benchmarks, both of which aim to find paths with unknown destination. One reason is that PGPR is required to find a lot of candidate paths, which are then ranked to obtain top 10 paths for recommendation. On the contrary, our method seeks out useful paths based on the user profile, and hence it saves much more time in path-reasoning based recommendation. In addition, for both tasks, our method costs less time than Indiv., which means that the batch path finding algorithm in Alg. 1 is more efficient than finding paths individually. Our algorithm thus avoids redundant computation of embeddings and nearest nodes searches.  ", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_5"]}, {"heading": "Robustness to Unseen Patterns", "text": "Recall that the candidate set \u03a0 cannot exhaustively cover all possible user-centric patterns in a very large KG, since only high frequency patterns will be collected by the algorithm [24]. Therefore, in this experiment, we investigate if unseen patterns that do not exist in \u03a0 will influence the performance. To conduct the experiment, in the coarse stage of user profile composition, we randomly preserve 70% of the candidate patterns in \u03a0 for each user to compose the user profile. The remaining 30% of patterns are unseen to the model for each user. All other settings remain the default ones.\nThe results on the four datasets are reported in Table 5. It is interesting to see that the decrease in performance is at around 1.5-3%, which is marginal compared to the regular setting. This shows that our model is robust to unseen patterns for user profile composition and can still provide high-quality recommendations.", "publication_ref": ["b23"], "figure_ref": [], "table_ref": ["tab_7"]}, {"heading": "Ablation Study", "text": "We study how different settings of hyperparameters influence the recommendation quality of our model. We consider the ranking weight and the number of sampling paths on the Cell Phones dataset only due to space constraints. 4.6.1 Influence of ranking loss. We first show the influence of the ranking loss in Eq. 9 under different values of the weighting factor \ud835\udf06 \u2208 {0, 5, 10, 15, 20}, where \ud835\udf06 = 0 means no ranking loss is imposed for training. The results are plotted in Fig. 3, including our model (red curves) and the best baseline HeteroEmbed (blue curves).\nWe observe two interesting trends. First, our model consistently outperforms HeteroEmbed under all settings of \ud835\udf06 in terms of NDCG, Recall, and Precision. Even without the ranking loss, our model can still guarantee a high quality of recommendation. On the other hand, a proper choice of \ud835\udf06 (e.g., \ud835\udf06 = 10) not only benefits the direct ranking effect (NDCG), but also boosts the model's ability to find more relevant items (recall, hit rate, and precision). Second, a larger weight of the ranking loss may not always entail a better performance, since there is a trade-off between the ranking (Eq. 8) and path regularization (Eq. 7). This is reasonable because if the ranking loss plays a dominant role, which implies that the model pays less attention to fitting paths, as a consequence, it may fail to find the correct paths that reach promising items.    In Fig. 4, we illustrate with box plots the recommendation performance of all users in terms of various metrics. We observe similar trends across all metrics in that there exists an optimal choice of \ud835\udc3e under each setting, e.g., \ud835\udc3e = 20 for NDCG on the Cell Phones dataset. The variances are within acceptable ranges, which means that the path reasoning procedure of our model leads to satisfying results for most of the users. One possible reason is that some items suitable for recommendation are in fact ranked relatively low. Smaller sampling sizes lead to smaller search spaces that preclude the discovery of such low-ranked items.", "publication_ref": [], "figure_ref": ["fig_4", "fig_5"], "table_ref": []}, {"heading": "Case Study", "text": "We showcase two recommendation examples with path-based explanations produced by our model Cafe. As shown in Fig. 5, each case consists of a layout tree merged from the user profile along with a subset of generated reasoning paths. In Case 1, the pattern containing the \"mention\" relation takes the dominant role (\ud835\udc64 = 10). For example, the user mentions the keywords \"absorb\", \"vitamin\". The recommended items \"lotion\" and \"facial cream\" match \"absorb\", and \"vitamin serum\" is also consistent with \"vitamin\". Case 2 shows a user profile with more diverse patterns. For example, the user purchased a \"necklace\" by \"Hello Kitty\". It is reasonable for our method to recommend \"watch\" from the same \"Hello Kitty\" brand. Similar inferences can also be drawn for \"business bag\". Moreover, the interaction with another user and the \"rain\" feature leads to \"umbrella\" being recommended. In these cases, our method is capable of producing relevant recommendations along with the explainable paths via explicit KG reasoning.", "publication_ref": [], "figure_ref": ["fig_7"], "table_ref": []}, {"heading": "RELATED WORK", "text": "There are two main research lines related to our work: KG-based explainable recommendation and multi-behavior recommendation.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "KG-based Explainable Recommendation", "text": "Explainable recommendation [6-8, 26, 45, 49, 50] refers to a decision-making system that not only provides accurate recommendation results, but also generates explanations to clarify why the items are recommended.  One line of research focuses on the KG embedding approach. Several works integrate KG representation learning into the recommendation model [17,20,21,42,47]. Typically, they assume that the recommended items and their attributes can be mapped into a latent vector space along with transnational relations between the them. For example, Zhang et al. [47] propose the CKE model, which incorporates diverse item types information into Collaborative Filtering. Huang et al. [21] integrate a KG in multimodal formats capturing dynamic user preferences by modeling the sequential interactions over the KG. Wang et al. [42] consider both semantics and knowledge representations of news contents for improved news recommendation. Huang et al. [20] leverage KG to enhance item representations and He et al. [17] jointly conduct KG completion and item recommendations. These methods demonstrate the effectiveness of incorporating KG embedding into recommendation. However, they fail to directly leverage the KG structure to generate reasoning paths as explanations for the recommendation [49].\nAnother line of work explores incorporating KG reasoning into the process of recommendation. The graph structure empowers the system to exploit informative features and also to deliver intuitive path-based explanations. Early works [5] propose to model logic rules to conduct explicit reasoning over a KG for explainability. However, the rules are handcrafted and can hardly generalize to unexplored entity correlations. In contrast, recent approaches adopt deep neural networks to learn a direct mapping among users, items, and other relations in a KG to enable reasoning for explainable recommendation. Some approaches [32,41,44] only use item-side knowledge but neglect the diverse historical activities of users, while others [1,4] isolate path generation and recommendations, so the resulting path may be irrelevant to the actual decision making process. We argue that both of these two types of methods fail to model user behaviors to conduct an explicit path reasoning process, which makes the recommendation process less intuitive. Recently, Xian et al. [46] and Zhao et al. [51] perform explicit KG reasoning for explainable recommendation via reinforcement learning. Although their paths are generated together with the recommended items, the recommendation performance is limited by the large search space of the KG and the weak guidance of sparse rewards. In this work, we follow the setting of KG reasoning for explainable recommendation [46], but aim to provide better guidance from user history behavior, as confirmed in our experiments.", "publication_ref": ["b16", "b19", "b20", "b41", "b46", "b46", "b20", "b41", "b19", "b16", "b48", "b4", "b31", "b40", "b43", "b0", "b3", "b45", "b50", "b45"], "figure_ref": [], "table_ref": []}, {"heading": "Multi-Behavior Recommendation", "text": "On modern e-commerce platforms, users can interact with the system in multiple forms [23,28,30,39]. Lo et al. [30] provide several case studies covering the influence of clicking and saving behavior analysis on the final purchase decision. Existing methods for multi-behavior recommendations may be divided into two categories: collective matrix factorization based approaches and approaches based on learning from implicit interactions. Singh and Gordon [39] propose factorizing multiple user-item interaction matrices as a collective matrix factorization model with shared item-side embeddings across matrices. Zhao et al. [53] learn different embedding vectors for different behavior types in an online social network. Krohn-Grimberghe et al. [23] share the user embeddings in recommendation based social network data based on the CMF method. In contrast, Loni et al. [31] proposed an extension of Bayesian Personalized Ranking [36] as multi-channel BPR, to adapt the sampling rule from different types of behavior in the training of standard BPR. Guo et al. [16] proposed sampling unobserved items as positive items based on item-item similarity, which is calculated using multiple types of feedback. However, none of these methods consider the reasoning framework to provide explainable recommendations, let alone explicitly model diverse user behaviors over KGs on e-commerce platforms.", "publication_ref": ["b22", "b27", "b29", "b38", "b29", "b38", "b52", "b22", "b30", "b35", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "CONCLUSION", "text": "In this paper, we propose a new coarse-to-fine KG reasoning approach called Cafe for explainable recommendation. Unlike traditional KG based recommendations, our method is characterized by first composing a user profile to capture prominent user behaviors in the coarse stage, and then in the fine stage, conducting path reasoning under the guidance of the user profile. Since the recommendation and path reasoning processes are closely coupled with each other, the output paths can be regarded as the explanation to the recommendations. We extensively evaluate our model on several real-world datasets and show that the proposed approach delivers superior results in recommendation performance. Our code is available from https://github.com/orcax/CAFE.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Learning Heterogeneous Knowledge Base Embeddings for Explainable Recommendation", "journal": "", "year": "2018", "authors": "Qingyao Ai; Vahid Azizi; Xu Chen; Yongfeng Zhang"}, {"ref_id": "b1", "title": "Natural language generation", "journal": "", "year": "2003", "authors": "John Bateman; Michael Zock"}, {"ref_id": "b2", "title": "Translating embeddings for modeling multi-relational data", "journal": "", "year": "2013", "authors": "Antoine Bordes; Nicolas Usunier; Alberto Garcia-Duran; Jason Weston; Oksana Yakhnenko"}, {"ref_id": "b3", "title": "Unifying Knowledge Graph Learning and Recommendation: Towards a Better Understanding of User Preferences", "journal": "ACM", "year": "2019", "authors": "Yixin Cao; Xiang Wang; Xiangnan He; Zikun Hu; Tat-Seng Chua"}, {"ref_id": "b4", "title": "Explainable entity-based recommendations with knowledge graphs", "journal": "", "year": "2017", "authors": "Rose Catherine; Kathryn Mazaitis; Maxine Eskenazi; William Cohen"}, {"ref_id": "b5", "title": "Generate natural language explanations for recommendation", "journal": "ACM", "year": "2019", "authors": "Hanxiong Chen; Xu Chen; Shaoyun Shi; Yongfeng Zhang"}, {"ref_id": "b6", "title": "Personalized fashion recommendation with visual explanations based on multimodal attention network: Towards visually explainable recommendation", "journal": "", "year": "2019", "authors": "Hanxiong Xu Chen; Hongteng Chen; Yongfeng Xu; Yixin Zhang; Zheng Cao; Hongyuan Qin;  Zha"}, {"ref_id": "b7", "title": "Dynamic explainable recommendation based on neural attentive models", "journal": "AAAI", "year": "2019", "authors": "Yongfeng Xu Chen; Zheng Zhang;  Qin"}, {"ref_id": "b8", "title": "Introduction to algorithms", "journal": "MIT press", "year": "2009", "authors": "Charles E Thomas H Cormen; Ronald L Leiserson; Clifford Rivest;  Stein"}, {"ref_id": "b9", "title": "Coarse-to-fine decoding for neural semantic parsing", "journal": "ACL", "year": "2018", "authors": "Li Dong; Mirella Lapata"}, {"ref_id": "b10", "title": "Assymetrical Hierarchical Networks with Attentive Interactions for Interpretable Review-based Recommendation", "journal": "AAAI Press", "year": "2020", "authors": "Xin Dong; Jingchao Ni; Wei Cheng; Zhengzhang Chen; Bo Zong; Dongjin Song; Yanchi Liu; Haifeng Chen; Gerard De; Melo "}, {"ref_id": "b11", "title": "Challenges and innovations in building a product knowledge graph", "journal": "", "year": "2018", "authors": "Xin Luna; Dong "}, {"ref_id": "b12", "title": "Fairness-Aware Explainable Recommendation over Knowledge Graphs", "journal": "", "year": "2020", "authors": "Zuohui Fu; Yikun Xian; Ruoyuan Gao; Jieyu Zhao; Qiaoying Huang; Yingqiang Ge; Shuyuan Xu; Shijie Geng; Chirag Shah; Yongfeng Zhang; Gerard De; Melo "}, {"ref_id": "b13", "title": "ABSent: Cross-Lingual Sentence Representation Mapping with Bidirectional GANs", "journal": "", "year": "2020", "authors": "Zuohui Fu; Yikun Xian; Shijie Geng; Yingqiang Ge; Yuting Wang; Xin Dong; Guang Wang; Gerard De; Melo "}, {"ref_id": "b14", "title": "Understanding Echo Chambers in E-commerce Recommender Systems", "journal": "SIGIR", "year": "2020", "authors": "Yingqiang Ge; Shuya Zhao; Honglu Zhou; Changhua Pei; Fei Sun; Wenwu Ou; Yongfeng Zhang"}, {"ref_id": "b15", "title": "Resolving data sparsity by multi-type auxiliary implicit feedback for recommender systems", "journal": "Knowl. Based Syst", "year": "2017", "authors": "Guibing Guo; Huihuai Qiu; Zhenhua Tan; Yuan Liu; Jing Ma; Xingwei Wang"}, {"ref_id": "b16", "title": "Mining Implicit Entity Preference from User-Item Interaction Data for Knowledge Graph Completion via Adversarial Learning", "journal": "", "year": "2020", "authors": "Gaole He; Junyi Li; Wayne Xin Zhao; Peiju Liu; Ji-Rong Wen"}, {"ref_id": "b17", "title": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering", "journal": "", "year": "2016", "authors": "Ruining He; Julian Mcauley"}, {"ref_id": "b18", "title": "Knowledge Graphs", "journal": "", "year": "2020", "authors": "Aidan Hogan; Eva Blomqvist; Michael Cochez; Claudia Amato; Gerard De Melo; Claudio Gutierrez; Jos\u00e9 Emilio Labra; Sabrina Gayo; Sebastian Kirrane; Axel Neumaier; Roberto Polleres; Axel-Cyrille Ngonga Navigli;  Ngomo; M Sabbir; Anisa Rashid; Lukas Rula; Juan Schmelzeisen; Steffen Sequeda; Antoine Staab;  Zimmermann"}, {"ref_id": "b19", "title": "Improving sequential recommendation with knowledge-enhanced memory networks", "journal": "", "year": "2018", "authors": "Jin Huang; Wayne Xin Zhao; Hongjian Dou; Ji-Rong Wen; Edward Y Chang"}, {"ref_id": "b20", "title": "Explainable Interaction-driven User Modeling over Knowledge Graph for Sequential Recommendation", "journal": "ACM MM", "year": "2019", "authors": "Xiaowen Huang; Quan Fang; Shengsheng Qian; Jitao Sang; Yiyang Li; Changsheng Xu"}, {"ref_id": "b21", "title": "Adam: A method for stochastic optimization", "journal": "ICLR", "year": "2015", "authors": "P Diederik; Jimmy Kingma;  Ba"}, {"ref_id": "b22", "title": "Multi-relational matrix factorization using bayesian personalized ranking for social network data", "journal": "", "year": "2012", "authors": "Artus Krohn-Grimberghe; Lucas Drumond; Christoph Freudenthaler; Lars Schmidt-Thieme"}, {"ref_id": "b23", "title": "Random walk inference and learning in a large scale knowledge base", "journal": "", "year": "2011", "authors": "Ni Lao; Tom Mitchell; William W Cohen"}, {"ref_id": "b24", "title": "Generating Long and Informative Reviews with Aspect-Aware Coarse-to-Fine Decoding", "journal": "", "year": "2019", "authors": "Junyi Li; Wayne Xin Zhao; Ji-Rong Wen; Yang Song"}, {"ref_id": "b25", "title": "Generate Neural Template Explanations for Recommendation", "journal": "", "year": "2020", "authors": "Lei Li; Yongfeng Zhang; Li Chen"}, {"ref_id": "b26", "title": "A Survey on Representation Learning for User Modeling", "journal": "", "year": "2020", "authors": "Sheng Li; Handong Zhao"}, {"ref_id": "b27", "title": "TSCSet: A crowdsourced time-sync comment dataset for exploration of user experience improvement", "journal": "", "year": "2018", "authors": "Zhenyu Liao; Yikun Xian; Xiao Yang; Qinpei Zhao; Chenxi Zhang; Jiangfeng Li"}, {"ref_id": "b28", "title": "Multi-Hop Knowledge Graph Reasoning with Reward Shaping", "journal": "", "year": "2018", "authors": "Victoria Xi; Richard Lin; Caiming Socher;  Xiong"}, {"ref_id": "b29", "title": "Understanding Behaviors that Lead to Purchasing: A Case Study of Pinterest", "journal": "", "year": "2016", "authors": "Caroline Lo; Dan Frankowski; Jure Leskovec"}, {"ref_id": "b30", "title": "Bayesian Personalized Ranking with Multi-Channel User Feedback", "journal": "", "year": "2016", "authors": "Babak Loni; Roberto Pagano; Martha Larson; Alan Hanjalic"}, {"ref_id": "b31", "title": "Jointly Learning Explainable Rules for Recommendation with Knowledge Graph", "journal": "", "year": "2019", "authors": "Weizhi Ma; Min Zhang; Yue Cao; Woojeong Jin; Chenyang Wang; Yiqun Liu; Shaoping Ma; Xiang Ren"}, {"ref_id": "b32", "title": "Hidden factors and hidden topics: understanding rating dimensions with review text", "journal": "", "year": "2013", "authors": "Julian Mcauley; Jure Leskovec"}, {"ref_id": "b33", "title": "Rectified Linear Units Improve Restricted Boltzmann Machines", "journal": "", "year": "2010", "authors": "Vinod Nair; Geoffrey E Hinton"}, {"ref_id": "b34", "title": "The land of the free and The elements of style", "journal": "English Today", "year": "2010", "authors": "Geoffrey K Pullum"}, {"ref_id": "b35", "title": "BPR: Bayesian personalized ranking from implicit feedback", "journal": "", "year": "2009", "authors": "Steffen Rendle; Christoph Freudenthaler; Zeno Gantner; Lars Schmidt-Thieme"}, {"ref_id": "b36", "title": "E-commerce recommendation applications", "journal": "Data mining and knowledge discovery", "year": "2001", "authors": "Ben Schafer; Joseph A Konstan; John Riedl"}, {"ref_id": "b37", "title": "Modeling relational data with graph convolutional networks", "journal": "Springer", "year": "2018", "authors": "Michael Schlichtkrull; Thomas N Kipf; Peter Bloem; Rianne Van Den; Ivan Berg; Max Titov;  Welling"}, {"ref_id": "b38", "title": "Relational learning via collective matrix factorization", "journal": "", "year": "2008", "authors": "Paul Ajit; Geoffrey J Singh;  Gordon"}, {"ref_id": "b39", "title": "Reinforcement learning: An introduction", "journal": "MIT Press", "year": "2018", "authors": "S Richard; Andrew G Sutton;  Barto"}, {"ref_id": "b40", "title": "Ripplenet: Propagating user preferences on the knowledge graph for recommender systems", "journal": "", "year": "2018", "authors": "Hongwei Wang; Fuzheng Zhang; Jialin Wang; Miao Zhao; Wenjie Li; Xing Xie; Minyi Guo"}, {"ref_id": "b41", "title": "DKN: Deep Knowledge-Aware Network for News Recommendation", "journal": "WWW", "year": "2018", "authors": "Hongwei Wang; Fuzheng Zhang; Xing Xie; Minyi Guo"}, {"ref_id": "b42", "title": "Knowledge-aware graph neural networks with label smoothness regularization for recommender systems", "journal": "", "year": "2019", "authors": "Hongwei Wang; Fuzheng Zhang; Mengdi Zhang; Jure Leskovec; Miao Zhao; Wenjie Li; Zhongyuan Wang"}, {"ref_id": "b43", "title": "KGAT: Knowledge Graph Attention Network for Recommendation", "journal": "KDD", "year": "2019", "authors": "Xiang Wang; Xiangnan He; Yixin Cao; Meng Liu; Tat-Seng Chua"}, {"ref_id": "b44", "title": "Neural-Symbolic Reasoning over Knowledge Graph for Multi-Stage Explainable Recommendation", "journal": "", "year": "2020", "authors": "Yikun Xian; Zuohui Fu; Qiaoying Huang; Shan Muthukrishnan; Yongfeng Zhang"}, {"ref_id": "b45", "title": "Reinforcement Knowledge Graph Reasoning for Explainable Recommendation", "journal": "", "year": "2019", "authors": "Yikun Xian; Zuohui Fu; S Muthukrishnan; Gerard De Melo; Yongfeng Zhang"}, {"ref_id": "b46", "title": "Collaborative Knowledge Base Embedding for Recommender Systems", "journal": "", "year": "2016", "authors": "Fuzheng Zhang; Nicholas Jing Yuan; Defu Lian; Xing Xie; Wei-Ying Ma"}, {"ref_id": "b47", "title": "Collaborative Multi-Level Embedding Learning from Reviews for Rating Prediction", "journal": "", "year": "2016", "authors": "Wei Zhang; Quan Yuan; Jiawei Han; Jianyong Wang"}, {"ref_id": "b48", "title": "Explainable Recommendation: A Survey and New Perspectives", "journal": "", "year": "2020", "authors": "Yongfeng Zhang; Xu Chen"}, {"ref_id": "b49", "title": "Explicit factor models for explainable recommendation based on phrase-level sentiment analysis", "journal": "", "year": "2014", "authors": "Yongfeng Zhang; Guokun Lai; Min Zhang; Yi Zhang; Yiqun Liu; Shaoping Ma"}, {"ref_id": "b50", "title": "Leveraging Demonstrations for Reinforcement Recommendation Reasoning over Knowledge Graphs", "journal": "", "year": "2020", "authors": "Kangzhi Zhao; Xiting Wang; Yuren Zhang; Li Zhao; Zheng Liu; Chunxiao Xing; Xing Xie"}, {"ref_id": "b51", "title": "KB4Rec: A Data Set for Linking Knowledge Bases with Recommender Systems", "journal": "Data Intelligence", "year": "2019", "authors": "Gaole Wayne Xin Zhao; Kunlin He; Hongjian Yang; Jin Dou; Siqi Huang; Ji-Rong Ouyang;  Wen"}, {"ref_id": "b52", "title": "Improving User Topic Interest Profiles by Behavior Factorization", "journal": "", "year": "2015", "authors": "Zhe Zhao; Zhiyuan Cheng; Lichan Hong; Ed Huai Hsin; Chi "}, {"ref_id": "b53", "title": "Joint deep modeling of users and items using reviews for recommendation", "journal": "", "year": "2017", "authors": "Lei Zheng; Vahid Noroozi; Philip S Yu"}], "figures": [{"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure2: Illustration of Cafe, a coarse-to-fine KG reasoning approach. (a) Given a KG and a start user, the goal is to conduct multi-step path reasoning to derive recommendations. (b) In the coarse stage, a personalized user profile is constructed based on historic user behavior in the KG. (c) To make use of the user profile in path reasoning, an inventory of neural symbolic reasoning modules is maintained. (d) In the fine stage, a layout tree is composed with the modules based on the user profile, which is exploited by the proposed PPR algorithm (Alg. 1) to produce (e) a batch of paths along with recommendations.", "figure_data": ""}, {"figure_label": "62", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "4. 6 . 262Influence of sampling sizes of output paths. Furthermore, we study how the performance varies with different sampling sizes of output reasoning paths \ud835\udc3e \u2208 {15, 20, 25, 30} (see Section 3.2).", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 3 :3Figure 3: Results of varying ranking weights on Clothing (blue) and Cell Phones (red) datasets. (HE: [1])", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 4 :4Figure 4: Results of different number of output reasoning paths on Clothing (blue) and Cell Phones (red) datasets.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Figure 5 :5Figure 5: Two real cases discovered by our model, each containing a layout tree merged from user profile and a subset of reasoning paths. The end nodes in the resulting paths are the predicted items for recommendation.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "1 , \ud835\udc52 2 , . . . , \ud835\udc5f |\ud835\udc3f | , \ud835\udc52 |\ud835\udc3f | } (or simply \ud835\udc3f \ud835\udc52 0 \ud835\udc52 |\ud835\udc3f| ), where \ud835\udc52 0 , . . . , \ud835\udc52 |\ud835\udc3f | \u2208 E, \ud835\udc5f 1 , . . . , \ud835\udc5f |\ud835\udc3f | \u2208 R and (\ud835\udc52 \ud835\udc61 -1 , \ud835\udc5f \ud835\udc61 , \ud835\udc52 \ud835\udc61 ) \u2208 G for \ud835\udc61 = 1, . . . , |\ud835\udc3f|.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "). Each positive \ud835\udc64 \ud835\udc57 specifies the number of paths with pattern \ud835\udf0b \ud835\udc57 to be generated by \ud835\udc53 path (Section 3.2).3.1.2 Modularized Reasoning Model.As introduced in Section 2.3, the reasoner \ud835\udf19 parametrized by \u0398 determines the next-step decision in path-finding. It maps the given user \ud835\udc62 and historic trajectory \u210e \ud835\udc61 to the conditional probability of choosing outgoing edge (\ud835\udc5f \ud835\udc61 , \ud835\udc52 \ud835\udc61 ), i.e., \ud835\udf19 : \ud835\udc62, \u210e \ud835\udc61 \u21a6 \u2192 \ud835\udc43 \u0398 (\ud835\udc5f \ud835\udc61 , \ud835\udc52 \ud835\udc61 |\ud835\udc62, \u210e \ud835\udc61 ). Inspired by previous work", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Algorithm 1 Profile-guided Path Reasoning (PPR) Algorithm", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Clothing Cell Phones Beauty Statistics of four real-world Amazon KG datasets: CDs & Vinyl, Clothing, Cell Phones, and Beauty.", "figure_data": "#Users75,25839,38727,87922,363#Items64,44323,03310,42912,101#Interactions 1.10M278.86K194.32K198.58K#Entities581,105425,534163,255224,080#Relations16161616#Triples387.43M36.37M37.01M37.73M"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Overall recommendation performance of our method compared to other approaches on four benchmarks. The results are computed based on top-10 recommendations in the test set and are given as percentages (%). The best results are highlighted in bold font and the best baseline results are underlined.", "figure_data": "CDs & VinylClothingCell PhonesBeautyMeasures (%)NDCG RecallHRPrec.NDCG RecallHRPrec.NDCG RecallHRPrec.NDCG RecallHRPrec.BPR2.0092.6798.5541.0850.6011.0461.7670.1851.9983.2585.2730.5952.7534.2418.2411.143BPR-HFT2.6613.5709.9261.2681.0671.8192.8720.2973.1515.3078.1250.8602.9344.4598.2681.132DeepCoNN4.2186.00113.8571.6811.3102.3323.2860.2293.6366.3539.9130.9993.3595.4299.8071.200CKE4.6206.48314.5411.7791.5022.5094.2750.3883.9957.00510.8091.0703.7175.93811.0431.371RippleNet4.8717.14515.7271.8522.1953.8926.0320.6034.8377.71611.4541.1015.1628.12714.6811.699KGAT5.4117.76417.1732.1203.0215.1727.3940.7475.1118.97812.5891.2966.10810.022 16.7401.893HeteroEmbed5.5637.94917.5562.1923.0915.4667.9720.7635.3709.49813.4551.3256.39910.411 17.4981.986PGPR5.5907.56916.8862.1572.8584.8347.0200.7285.0428.41611.9041.2745.4498.32414.4011.707Cafe (Ours)6.868 9.376 19.692 2.5623.689 6.340 9.275 0.9756.313 11.086 15.531 1.6927.061 10.948 18.099 2.270Improvement (%)+22.86 +17.95 +12.17 +16.88+19.34 +15.99 +16.34 +24.52+17.56 +16.72 +15.43 +24.60+10.34 +5.16+3.43 +14.074.3 Effectiveness of User Profile (Coarse-Stage)CDs & VinylClothingNDCG RecallHRPrec.NDCG RecallHRPrec.PGPR5.5907.56916.886 2.1572.8584.8347.0200.728Rand5.3087.21716.158 2.0032.6544.7276.8750.680Prior5.9248.25917.825 2.3273.1575.0317.3760.773Ours6.8689.376 19.692 2.5623.6896.3409.275 0.975Cell PhonesBeautyNDCG RecallHRPrec.NDCG RecallHRPrec.PGPR5.0428.41611.904 1.2745.4498.32414.401 1.707Rand4.5457.22910.192 1.0875.2938.25614.564 1.718Prior5.2559.84213.097 1.3596.1809.39316.258 2.024Ours6.313 11.086 15.531 1.6927.061 10.948 18.099 2.270"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Time costs of recommendations per 1k users and path finding per 10k paths.", "figure_data": "CDs & VinylClothingTime (s)Rec. (1k users) Find (10k paths)Rec. (1k users) Find (10k paths)PGPR287.158 \u00b1 5.21326.725 \u00b1 0.572236.118 \u00b1 4.84021.889 \u00b1 0.437Hetero.53.984 \u00b1 1.20121.674 \u00b1 0.49855.482 \u00b1 1.70318.492 \u00b1 0.399Indiv.71.769 \u00b1 1.36625.229 \u00b1 0.48261.519 \u00b1 1.96620.128 \u00b1 0.377Ours27.184 \u00b1 1.02617.851 \u00b1 0.36422.850 \u00b1 1.37815.233 \u00b1 0.309Cell PhonesBeautyTime (s)Rec. (1k users) Find (10k paths)Rec. (1k users) Find (10k paths)PGPR279.780 \u00b1 5.13525.382 \u00b1 0.563292.447 \u00b1 6.13926.396 \u00b1 0.591Hetero.48.125 \u00b1 1.14820.037 \u00b1 0.49651.392 \u00b1 1.36921.492 \u00b1 0.467Indiv.62.259 \u00b1 1.17123.735 \u00b1 0.50268.158 \u00b1 1.20924.938 \u00b1 0.473Ours23.387 \u00b1 1.12415.591 \u00b1 0.40625.220 \u00b1 1.14116.813 \u00b1 0.458"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "Experimental results for unseen patterns", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "G p = {(\ud835\udc52, \ud835\udc5f, \ud835\udc52 \u2032 ) | \ud835\udc52, \ud835\udc52 \u2032 \u2208 E p , \ud835\udc5f \u2208 R p }", "formula_coordinates": [2.0, 318.18, 479.66, 138.92, 11.44]}, {"formula_id": "formula_1", "formula_text": "G u = {(\ud835\udc52, \ud835\udc5f, \ud835\udc52 \u2032 ) | \ud835\udc52, \ud835\udc52 \u2032 \u2208 E u , \ud835\udc5f \u2208 R u }", "formula_coordinates": [2.0, 318.05, 545.41, 239.98, 22.39]}, {"formula_id": "formula_2", "formula_text": "\ud835\udc5f \ud835\udc62\ud835\udc56 \u2208 R u . When |R u | = 1 and E u = U \u222a I, G u is a bipartite user- item graph.", "formula_coordinates": [2.0, 317.6, 580.35, 241.59, 19.39]}, {"formula_id": "formula_3", "formula_text": "T \ud835\udc62 = {(\ud835\udf0b 1 , \ud835\udc64 1 ), . . . , (\ud835\udf0b | T \ud835\udc62 | , \ud835\udc64 | T \ud835\udc62 | )},", "formula_coordinates": [3.0, 168.68, 218.82, 126.35, 9.47]}, {"formula_id": "formula_4", "formula_text": ") \u2209 G, \ud835\udc58 \u2208 [\ud835\udc3e] ,", "formula_coordinates": [3.0, 236.74, 394.43, 58.28, 7.93]}, {"formula_id": "formula_5", "formula_text": "\u00ee = argmax \ud835\udc56 \u2208I \ud835\udc53 rec (\ud835\udc62, \ud835\udc56; G), L\ud835\udc62 \u00ee = \ud835\udc53 path (\ud835\udc62, \u00ee; G),", "formula_coordinates": [3.0, 87.93, 609.76, 172.22, 17.78]}, {"formula_id": "formula_6", "formula_text": "L\ud835\udc62 \ud835\udc52 \ud835\udc47 = \ud835\udc53 path (\ud835\udc62, -; G u ), \u00ee = \ud835\udc52 \ud835\udc47 ,", "formula_coordinates": [3.0, 377.81, 161.82, 121.71, 11.53]}, {"formula_id": "formula_7", "formula_text": "T \ud835\udc62 = \ud835\udc53 profile (\ud835\udc62; G u ), L\ud835\udc62 \ud835\udc52 \ud835\udc47 = \ud835\udc53 \u2032 path (\ud835\udc62, T \ud835\udc62 ; G u ), \u00ee = \ud835\udc52 \ud835\udc47 . (1)", "formula_coordinates": [3.0, 329.73, 408.16, 228.47, 13.94]}, {"formula_id": "formula_8", "formula_text": "log \ud835\udc43 \u0398 (\ud835\udc3f|\ud835\udc62) = \ud835\udc47 \u2211\ufe01 \ud835\udc61 =1 log \ud835\udc43 \u0398 (\ud835\udc5f \ud835\udc61 , \ud835\udc52 \ud835\udc61 |\ud835\udc62, \u210e \ud835\udc61 )(2)", "formula_coordinates": [3.0, 372.01, 498.93, 186.19, 25.96]}, {"formula_id": "formula_9", "formula_text": "\ud835\udf53 \ud835\udc93\ud835\udfcf \ud835\udf53 \ud835\udc93\ud835\udfd0 \ud835\udf53 \ud835\udc93\ud835\udfd1 \ud835\udf53 \ud835\udc93\ud835\udfd3 \ud835\udf19 \"% \ud835\udf19 \" & '( \ud835\udf19 \"( \ud835\udf19 \" ( '( \ud835\udf19 \"( \ud835\udf19 \") \ud835\udf19 \" ) '( \ud835\udc52 \" \ud835\udc56 ! \ud835\udc62 \" \ud835\udc56 # \ud835\udc56 $ \ud835\udc62 # \ud835\udc52 ! \ud835\udc56 % \ud835\udc56 % \ud835\udc52 $ \ud835\udf53 \ud835\udc93\ud835\udfd2 \ud835\udc56 & \ud835\udc64=1 \ud835\udc5b=1 \ud835\udc5b=2 \ud835\udc5b=1 \ud835\udc5b=1 \ud835\udc5b=1 \ud835\udc5b=1 \ud835\udc5f $ \ud835\udc5f % \ud835\udc5f & \ud835\udc5f \" \ud835\udc5f # Relations \ud835\udc5b=1", "formula_coordinates": [4.0, 70.66, 107.91, 476.44, 153.72]}, {"formula_id": "formula_10", "formula_text": "\ud835\udc96 \" \ud835\udc96 \" \ud835\udc96 \" \ud835\udc96 \" \ud835\udc96 \" \ud835\udc96 \" \ud835\udc96 \" \ud835\udc96 \" Profile-guided Path Reasoning (PPR) \ud835\udc93 \ud835\udfd0 \ud835\udc93 \ud835\udfd1 )\ud835\udfcf \ud835\udc93 \ud835\udfcf \ud835\udc93 \ud835\udfcf )\ud835\udfcf \ud835\udc93 \ud835\udfcf \ud835\udc93 \ud835\udfd2 \ud835\udc93 \ud835\udfcf \ud835\udc93 \ud835\udfd2 )\ud835\udfcf \ud835\udf0b \" (\ud835\udc64 \" =1) \ud835\udc5f #$%%& (b) User Profile of \ud835\udc62 \" \ud835\udf0b # (\ud835\udc64 # =2) \ud835\udf0b $ (\ud835\udc64 $ =2) (c) Neural Symbolic Reasoning Modules Selected in user profile of \ud835\udc62 ' \ud835\udc62 \" \ud835\udc56 # \ud835\udc52 # \ud835\udc56 ! \ud835\udc56 $ \ud835\udc56 % \ud835\udc62 # \ud835\udc52 ! \ud835\udc52 $ \ud835\udc56 & \ud835\udc52 \" \ud835\udc56 \" \ud835\udc62 $ \ud835\udc52 %", "formula_coordinates": [4.0, 66.64, 98.68, 410.65, 168.41]}, {"formula_id": "formula_11", "formula_text": "\ud835\udf53 \ud835\udc93\ud835\udfd4", "formula_coordinates": [4.0, 317.72, 223.3, 9.32, 6.4]}, {"formula_id": "formula_12", "formula_text": "\ud835\udc49 \u0398 (\ud835\udc62, \ud835\udf0b) = E \ud835\udc3f\u223c\ud835\udc37 \ud835\udf0b [log \ud835\udc43 \u0398 (\ud835\udc3f | \ud835\udc62)],(3)", "formula_coordinates": [4.0, 112.18, 701.01, 181.87, 9.74]}, {"formula_id": "formula_13", "formula_text": "max \ud835\udc64 1 ,...,\ud835\udc64 \ud835\udc40 \u2211\ufe01 \ud835\udc57 \ud835\udc64 \ud835\udc57 \ud835\udc49 \u0398 (\ud835\udc62, \ud835\udf0b \ud835\udc57 ) s.t. \u2211\ufe01 \ud835\udc57 \ud835\udc64 \ud835\udc57 = \ud835\udc3e, 0 \u2264 \ud835\udc64 \ud835\udc57 \u2264 \ud835\udc3e \ud835\udc57 , \ud835\udc57 \u2208 [\ud835\udc40],(4)", "formula_coordinates": [4.0, 355.44, 461.54, 202.76, 46.04]}, {"formula_id": "formula_14", "formula_text": "T \ud835\udc62 = {(\ud835\udf0b \ud835\udc57 , \ud835\udc64 \ud835\udc57 ) | \ud835\udf0b \ud835\udc57 \u2208 \u03a0, \ud835\udc64 \ud835\udc57 > 0, \ud835\udc57 \u2208 [\ud835\udc40]} (see example in Fig. 2(b)", "formula_coordinates": [4.0, 317.96, 561.69, 240.25, 19.77]}, {"formula_id": "formula_15", "formula_text": "\ud835\udf19 \ud835\udc5f (\ud835\udc62, \u210e; \u0398 \ud835\udc5f ) = \ud835\udf0e (\ud835\udf0e ([u; h]\ud835\udc4a \ud835\udc5f,1 )\ud835\udc4a \ud835\udc5f,2 )\ud835\udc4a \ud835\udc5f,3 ,(5)", "formula_coordinates": [5.0, 100.11, 201.26, 193.94, 8.97]}, {"formula_id": "formula_16", "formula_text": "\ud835\udc43 \u0398 (\ud835\udc5f \ud835\udc61 , \ud835\udc52 \ud835\udc61 | \ud835\udc62, \u210e \ud835\udc61 ) \u2248 1 \ud835\udc4d exp(\u27e8\ud835\udf19 \ud835\udc5f \ud835\udc61 (u, h \ud835\udc61 ; \u0398 \ud835\udc5f \ud835\udc61 ), e \ud835\udc61 \u27e9),(6)", "formula_coordinates": [5.0, 88.39, 263.37, 205.65, 18.17]}, {"formula_id": "formula_17", "formula_text": "\ud835\udc4d = \ud835\udc52 \u2032 \ud835\udc61 exp(\u27e8\ud835\udf19 \ud835\udc5f \ud835\udc61 (u, h \ud835\udc61 ; \u0398 \ud835\udc5f \ud835\udc61 ), e \u2032 \ud835\udc61 \u27e9", "formula_coordinates": [5.0, 77.92, 284.87, 118.51, 12.62]}, {"formula_id": "formula_18", "formula_text": "\u2113 path (\u0398; \ud835\udc3f) = -log \ud835\udc43 \u0398 (\ud835\udc3f|\ud835\udc62) = - \ud835\udc47 \u2211\ufe01 \ud835\udc61 =1 log \ud835\udc43 \u0398 (\ud835\udc5f \ud835\udc61 , \ud835\udc52 \ud835\udc61 |\ud835\udc62, \u210e \ud835\udc61 ). (7)", "formula_coordinates": [5.0, 75.03, 451.82, 219.01, 25.96]}, {"formula_id": "formula_19", "formula_text": "\u2113 rank (\u0398; \ud835\udc3f) = -E \ud835\udc56 -\u223c\ud835\udc37 - \ud835\udc62 \ud835\udf0e i + , \u00ea\ud835\udc47 -\u27e8i -, \u00ea\ud835\udc47 \u27e9 ,(8)", "formula_coordinates": [5.0, 87.15, 528.0, 206.9, 12.47]}, {"formula_id": "formula_20", "formula_text": "\u2113 all (\u0398) = \u2211\ufe01 \ud835\udc62 \u2211\ufe01 \ud835\udc3f\u223cL \ud835\udc62 \u2113 path (\u0398; \ud835\udc3f) + \ud835\udf06\u2113 rank (\u0398; \ud835\udc3f),(9)", "formula_coordinates": [5.0, 92.48, 602.67, 201.56, 21.8]}, {"formula_id": "formula_21", "formula_text": "\ud835\udc38 \ud835\udc65 \u2190 {\ud835\udc52 \u2032 | \u2200(\ud835\udc52 |\ud835\udc3f | , \ud835\udc5f \ud835\udc65 , \ud835\udc52 \u2032 ) \u2208 G, \ud835\udf0f (\ud835\udc52 \u2032 ) = \ud835\udf0f \ud835\udc61 (\ud835\udc5f \ud835\udc65 ), rank(\u27e8x, e \u2032 \u27e9) \u2264 \ud835\udc5b \ud835\udc65 }. 13: L \ud835\udc65 \u2190 L \ud835\udc65 \u222a (\ud835\udc3f \u222a {\ud835\udc52 \u2032 }), for \ud835\udc52 \u2032 \u2208 \ud835\udc38 \ud835\udc65 . 14: Update \ud835\udc44 \u2190 \ud835\udc44 \u222a CH I L D R E N (\ud835\udc65).", "formula_coordinates": [5.0, 320.58, 219.5, 237.62, 45.14]}, {"formula_id": "formula_22", "formula_text": "return \ud835\udc65 \u2208LE A V E S (\ud835\udc47 \ud835\udc62 ) L \ud835\udc65 .", "formula_coordinates": [5.0, 346.65, 269.28, 100.67, 9.52]}], "doi": "10.1145/3340531.3412038"}
