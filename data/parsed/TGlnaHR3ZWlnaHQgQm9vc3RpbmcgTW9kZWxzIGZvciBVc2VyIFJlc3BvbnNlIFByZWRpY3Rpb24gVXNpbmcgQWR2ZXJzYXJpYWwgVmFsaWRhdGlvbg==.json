{"Lightweight Boosting Models for User Response Prediction Using Adversarial Validation": "HYEONWOO KIM \u2217 , Upstage AI Research, Republic of Korea WONSUNG LEE \u2217 , Upstage AI Research, Republic of Korea The ACM RecSys Challenge 2023, organized by ShareChat, aims to predict the probability of the app being installed. This paper describes the lightweight solution to this challenge. We formulate the task as a user response prediction task. For rapid prototyping for the task, we propose a lightweight solution including the following steps: 1) using adversarial validation, we effectively eliminate uninformative features from a dataset; 2) to address noisy continuous features and categorical features with a large number of unique values, we employ feature engineering techniques.; 3) we leverage Gradient Boosted Decision Trees (GBDT) for their exceptional performance and scalability. The experiments show that a single LightGBM model, without additional ensembling, performs quite well. Our team achieved ninth place in the challenge with the final leaderboard score of 6.059065. Code for our approach can be found here: https://github.com/choco9966/recsys-challenge-2023.", "CCS Concepts: \u2022 Information systems \u2192 Recommender systems .": "Additional Key Words and Phrases: ACM RecSys Challenge 2023, User Response Prediction, Adversarial Validation, Gradient Boosting Decision Trees, CTR Prediction", "ACMReference Format:": "Hyeonwoo Kim and Wonsung Lee. 2018. Lightweight Boosting Models for User Response Prediction Using Adversarial Validation. In RecSys '23: ACM Symposium on Neural Gaze Detection, June 03-05, 2018, Woodstock, NY. ACM, New York, NY, USA, 7 pages. https://doi.org/XXXXXXX.XXXXXXX", "1 INTRODUCTION": "User response prediction is challenging due to the inherent nature of the task, such as data sparsity, noisy and incomplete data, concept drift, and temporal dynamics. Researchers have explored diverse approaches to address this issue and improve prediction accuracy, including logistic regression (LR) [14], decision trees [9], factorization machines (FM) [11], and deep learning-based methods [8, 17, 18]. Deep learning models for user response prediction have recently gained popularity due to their ability to provide an inductive bias suitable for the input data type and capture intricate non-linear relationships in complex high-dimensional data spaces. However, despite the success of deep learning in predicting user responses, it is also widely known that tree-based methods often outperform neural networks in tabular data prediction tasks, especially in competitions. The goal of ACM RecSys Challenge 2023 is to estimate the probability of the app being installed. This task can be formulated naturally as a click-through rate (CTR) or conversion rate (CVR) prediction problem, which is a type of user response prediction. For rapid prototyping for the task, we propose a lightweight solution including the following steps: 1) given a dataset consisting of user and ad features, we employ adversarial validation to exclude non-informative \u2217 Both authors contributed equally to this research. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \u00a9 2018 Association for Computing Machinery. Manuscript submitted to ACM 1 RecSys '23, June 03-05, 2018, Woodstock, NY Hyeonwoo Kim and Wonsung Lee features effectively; 2) we perform feature engineering to deal with noisy continuous features and categorical features with high cardinality; 3) we utilize GBDT due to their superior performance and scalability. Our contributions are as follows. First, we provide a lightweight solution that combines adversarial validation and a set of feature engineering techniques. Second, we show that even a single LightGBM model without an additional ensembling performs quite well in user response prediction, ranking ninth in the leaderboard.", "2 RELATED WORK": "", "2.1 User Response Prediction": "Early studies that tackled user response prediction tasks include the following significant studies (mainly CTR prediction): [9, 11, 14]. Google [14] presented a regularized LR model based on an FTRL-Proximal algorithm for massive-scale sponsored search advertising. They explored several memory-saving guidances essential for building an industrialscale CTR prediction system, such as bloom filter, fewer bit encoding, and train data sub-sampling. Another work [9] published by Facebook employed a combination of decision trees and LR. The boosted decision tree performs non-linear supervised feature encoding and feeds the encoded features as an input to LR. They also stressed the importance of train data sub-sampling, negative down-sampling, and model calibration to handle large-scale real-world data. Field-aware FM [11], which is a variant of FM [15], also showed an impressive performance, showing the critical importance of capturing predictive feature interactions. Recent years have seen a growth of interest in the adoption of deep learning-based models for CTR prediction. Due to the superior ability of representation learning with multiple levels of abstraction, the use of deep neural networks (DNN) in industrial-scale CTR prediction is gradually becoming the industry standard [8, 17, 18]. The Deep & Cross Network (DCN) [17] adopts a memory-efficient cross network that explicitly learns predictive cross features without manual feature engineering. This simple yet effective architecture with significantly fewer parameters outperforms other baselines, including DNN, FM, and LR. Alibaba proposed a Deep Interest Network (DIN) [18], which utilizes a local activation unit, similar to an attention mechanism, to dynamically learn the representation of user interests based on their past behaviors related to a specific advertisement. Deep Multifaceted Transformers (DMT) [8], which models multiple types of behaviors (e.g., click, cart, and order) with multiple Transformers [16], has been successfully deployed to JD.com, one of the largest E-commerce sites in the world. DMT also shows that properly adopting multi-task learning that recognizes the user's different objectives can significantly improve real-world online performance metrics such as CTR, Conversion Rate (CVR), and Gross Merchandise Volume (GMV).", "2.2 Competitive Data Science": "Data science competitions have evolved from a niche community of passionate participants to a widely popular platform attracting millions of data scientists worldwide [2]. In 1997, the KDD Cup, one of the earliest data science competitions, was held. In 2006, the Netflix Prize [3] was held, significantly impacting the development of personalized recommender systems and collaborative filtering. Since then, various data science competitions focusing on personalized recommendations and user response prediction have been held at academic conferences and competitive data science platforms. We observed a wide variety of methodologies being used for personalized predictions in competitions, from TF-IDF to advanced deep learning architectures. Surprisingly, several top-ranking solutions utilized tree-based models. For 2 Lightweight Boosting Models for User Response Prediction Using Adversarial Validation RecSys '23, June 03-05, 2018, Woodstock, NY example, in 2017, 2018, 2019, 2020, and 2022 ACM RecSys challenges 1 , the winning solutions utilized GBDT such as LightGBM [12], CatBoost [5], and XGBoost [4] with substantial feature engineering. Also, the winning solution 2 of the H&M Personalized Fashion Recommendations competition, recently held at Kaggle, took advantage of different kinds of decision tree models (LightGBM and CatBoost) as a ranker module. Although deep learning has achieved tremendous success in the computer vision and natural language processing domains, it is known that tree-based methods often outperform neural networks in tabular data prediction tasks, especially when dealing with skewed distributions, heavy-tailed feature distributions, and dataset irregularities [6, 7, 13].", "3 PROBLEM FORMULATION": "", "3.1 Dataset Description": "The data available for the challenge was provided by ShareChat 3 , India's largest homegrown social media company with over 400M MAUs across all its platforms. The dataset consists of 10M users who visited the ShareChat and Moj apps over three months. The organizers preprocessed the dataset to have ten impressions for each user. The objective of the challenge is to predict the probability of the app being installed. Each row of the dataset consists of user and ad features. The train data consists of subsampled history from the past 22 days, and the target variable is the probability of the app being installed on the 23rd day.", "3.2 Evaluation": "The objective of the challenge is to predict whether the user will install or not for a given ad impression. The more accurately the probability is estimated, the higher the expected revenue of the platform. The metric used in the challenge was Normalized Cross Entropy (NCE):  where \ud835\udc41 , \ud835\udc5d \ud835\udc56 , \ud835\udc5d , and \ud835\udc66 \ud835\udc56 \u2208 {-1 , 1 } are the number of the dataset, the estimated probability of the app being installed, the average empirical probability of installation, and the label, respectively. NCE is calculated by dividing the average log loss per impression by the average log loss per impression that would occur if the model predicted the background CTR (in our case, CVR) for every impression. In other words, NCE is the predictive log loss normalized by the entropy of the empirical probability of installation. The lower the NCE value, the better the model performance. In our experiments, we use log loss as a proxy evaluation metric for local validation because we can not access the ground-truth empirical CVR, \ud835\udc5d .", "4 DATA PREPARATION & PREPROCESSING": "", "4.1 Local Validation Strategy": "The dataset includes temporal information as the \ud835\udc53 1 variable, which indicates the date for each row. We aim to predict \ud835\udc5d \ud835\udc56 as accurately as possible for test data with \ud835\udc53 1 = 67. Therefore, to reflect recent temporal trends and to make the validation set's distribution mimic the test set's distribution, we select the data with \ud835\udc53 1 = 66 as a local validation set. The entire procedure of the pipeline is shown in Fig. 1. 1 https://recsys.acm.org/challenges 2 https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/discussion/324070 3 https://sharechat.com/recsys2023 3 RecSys '23, June 03-05, 2018, Woodstock, NY Hyeonwoo Kim and Wonsung Lee Fig. 1. Flow chart of our lightweight pipeline Data Preparation & Engineering Predrocessing Dealing with Noisy LightGBM Validation Stralegy Continuous Features TabNet Feature Selection with Frequency Encoding Adversarial Validation Encoding Others Fig. 2. AUC metrics of each feature in adversarial validation for detecting a covariate shift. 0.25 Feature", "4.2 Adversarial Validation": "In our preliminary experiments, we observed a severe discrepancy between the local validation score and the leaderboard score. In particular, this phenomenon was amplified when certain variables were added as features. This overfitting issue seems to be due to a covariate shift, the discrepancy between the distribution of train data and test data. To identify and address the problem, we employ an adversarial validation approach. The adversarial validation approach can be used to detect and address the covariate shift. This approach involves training a binary classifier to determine whether a sample belongs to the training or test set. When the classifier's performance is close to random guessing ( AUC = 0 . 5), it suggests that distinguishing between the training and test sets is challenging, indicating that the distribution of both is relatively consistent. On the other hand, if the classifier performs significantly better than random guessing, it suggests the discrepancy between the distribution of the training and test sets. We train an adversarial classifier for each feature to detect potential features that exhibit the covariate shift between train and test data. As shown in Fig. 2, some variables have very high AUC scores, and these variables seem to show the covariate shift that may cause the gap between validation performance and test performance. Therefore, we can exclude these features from model training to reduce the inconsistency between the local validation and the leaderboard.", "5 FEATURE ENGINEERING": "Based on the analysis in 4.2, we filter out the variables with AUC > = 0 . 75 (indicating a potential covariate shift). Next, we encode categorical features to informative continuous values to deal with high cardinality and facilitate effective tree splits for GBDT models. In the following paragraphs, we introduce how to deal with noisy continuous features and how to encode categorical features. Please refer to our source code 4 for other details of feature engineering. 4 https://github.com/choco9966/recsys-challenge-2023 4 Lightweight Boosting Models for User Response Prediction Using Adversarial Validation RecSys '23, June 03-05, 2018, Woodstock, NY Fig. 3. Pairwise correlation plot for continuous features: \ud835\udc53 42 \u223c \ud835\udc53 79 . 55", "5.1 Dealing with Noisy Continuous Features": "Fig. shows that some continuous variables exhibit a block structure indicating a strong correlation with each other. Based on this observation, we found a pattern presumed to be artificial noise injection. Specifically, some variables represent an arithmetic sequence of unique values. More concretely, given the ordered unique values { \ud835\udc63 1 , \ud835\udc63 2 , ...\ud835\udc63 \ud835\udc40 } for a particular feature, where \ud835\udc63 \ud835\udc5b -1 < \ud835\udc63 \ud835\udc5b for \ud835\udc5b = 2 , ..., \ud835\udc40 , the general formula for the \ud835\udc5b -th term is as follows: \ud835\udc63 \ud835\udc5b = \ud835\udc63 1 +( \ud835\udc5b -1 ) \u0394 . For example, variable groups ( \ud835\udc53 42, \ud835\udc53 52 \u223c \ud835\udc53 57, \ud835\udc53 74 \u223c \ud835\udc53 76) and ( \ud835\udc53 44 \u223c \ud835\udc53 50 and \ud835\udc53 71 \u223c \ud835\udc53 73) have \u0394 \u2243 0 . 0385 and \u0394 \u2243 0 . 5711, respectively. We denoise these feature values by dividing the corresponding \u0394 , converting a data type from float to integer. The transformed integer features are expected to be more descriptive and informative when crossing features.", "5.2 Encoding Categorical Features": "The dataset includes many categorical features with high cardinality. We use frequency encoding and CatBoost encoding to avoid the curse of dimensionality. Frequency encoding, a.k.a. count encoding, replaces a category value with its number of occurrences for a given categorical feature. This simple strategy can be effective when the frequency is somewhat related to the target variable. We compared the following three alternatives for frequency encoding: (1) the number of occurrences during the previous day, (2) the number of occurrences during the previous week, and (3) the number of occurrences up to one day ago. We selected the second one due to its highest performance. Next, we conduct CatBoost encoding, a target encoding variation that supports time-aware encoding and regularization to avoid over-fitting. Similar to the sliding window, the category of the target day was transformed after fitting the encoder based on the data up to the previous day. The operations were performed for the two target variables, click and install, respectively.", "6 MODELS": "We employ GBDT as our prediction model. Specifically, we use LightGBM, which has been proven to show state-of-theart performance in many previous competitions [10, 19]. We also tested other baseline models known to perform well in predicting tabular data, such as TabNet [1] and CatBoost. However, LightGBM was more robust and performed the 5 RecSys '23, June 03-05, 2018, Woodstock, NY Hyeonwoo Kim and Wonsung Lee Table 1. Performance of the prediction models. The best-performance model is denoted in bold. Fig. 4. LightGBM feature importance plot based on the number of tree splits. feat cllck_CE_f_15 install_CE install_CE_f4 113_15 click_CE f cllck_CE_f_4 f13_15 install CE f 2 cllck_CE click_CE_f_18 install_CE f 13 30000 50000 best in our experiments. The tuned hyperparameters of LightGBM are as follows: number of leaves = 491, max depth = -1, boosting type = gbdt, and number of iterations = 10 , 000 with early stopping rounds = 100. Note that we did not apply an ensemble technique that blends the prediction results of several different models because we focus on a lightweight solution for rapid prototyping.", "7 EXPERIMENTS": "To evaluate the effectiveness of our method, we conduct detailed experiments and illustrate the results in Table 1. By incorporating validated features, we can observe an improvement in the performance of our model. It is worth noting that CatBoost reported a good performance on local validation but poor performance on the leaderboard. Although both LightGBM and CatBoost belong to GBDT, in our study, LightGBM showed a much more robust performance than CatBoost. Fig. 4 shows the top 20 important features according to the LightGBM feature importance measure based on the number of times the feature is used in tree splitting. All experiments were conducted on virtual machines with 64 vCPUs, 120GB RAM, and NVIDIA RTX 3090 GPU.", "8 CONCLUSION": "This paper presents our approach to the ACM RecSys Challenge 2023. Our solution comprises adversarial validation, feature engineering, and a prediction model. In the adversarial validation phase, we detect and exclude potential 6 Lightweight Boosting Models for User Response Prediction Using Adversarial Validation RecSys '23, June 03-05, 2018, Woodstock, NY features exhibiting the covariate shift. Next, in the feature engineering phase, we focused on denoising noisy continuous features and transforming categorical features into informative continuous values by performing frequency or CatBoost encoding. We employ LightGBM as our primary prediction model with tuned hyperparameters, and the final model showed excellent performance on the leaderboard even without applying an additional ensemble method. The proposed lightweight solution is simple yet effective for the following reasons: 1) adversarial validation can filter out noninformative features in the early stage, and 2) it does not apply the ensemble method that often requires much effort to find the optimal configuration. We believe our solution can be used for rapid prototyping for CTR/CVR prediction tasks.", "REFERENCES": "[1] Sercan \u00d6 Arik and Tomas Pfister. 2021. Tabnet: Attentive interpretable tabular learning. In Proceedings of the AAAI conference on artificial intelligence , Vol. 35. 6679-6687. [2] Konrad Banachewicz, Luca Massaron, and Anthony Goldbloom. 2022. The Kaggle Book: Data analysis and machine learning for competitive data science . Packt Publishing Ltd. [3] James Bennett, Stan Lanning, et al. 2007. The netflix prize. In Proceedings of KDD cup and workshop , Vol. 2007. New York, 35. [4] Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining . 785-794. [5] Anna Veronika Dorogush, Vasily Ershov, and Andrey Gulin. 2018. CatBoost: gradient boosting with categorical features support. arXiv preprint arXiv:1810.11363 (2018). [6] L\u00e9o Grinsztajn, Edouard Oyallon, and Ga\u00ebl Varoquaux. 2022. Why do tree-based models still outperform deep learning on typical tabular data? Advances in Neural Information Processing Systems 35 (2022), 507-520. [7] L\u00e9o Grinsztajn, Edouard Oyallon, and Ga\u00ebl Varoquaux. 2022. Why do tree-based models still outperform deep learning on typical tabular data? Advances in Neural Information Processing Systems 35 (2022), 507-520. [8] Yulong Gu, Zhuoye Ding, Shuaiqiang Wang, Lixin Zou, Yiding Liu, and Dawei Yin. 2020. Deep multifaceted transformers for multi-objective ranking in large-scale e-commerce recommender systems. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management . 2493-2500. [9] Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, et al. 2014. Practical lessons from predicting clicks on ads at facebook. In Proceedings of the eighth international workshop on data mining for online advertising . 1-9. [10] Pawe\u0142 Jankiewicz, Liudmyla Kyrashchuk, Pawe\u0142 Sienkowski, and Magdalena W\u00f3jcik. 2019. Boosting algorithms for a session-based, context-aware recommender system in an online travel domain. In Proceedings of the Workshop on ACM Recommender Systems Challenge . 1-5. [11] Yuchin Juan, Yong Zhuang, Wei-Sheng Chin, and Chih-Jen Lin. 2016. Field-aware factorization machines for CTR prediction. In Proceedings of the 10th ACM conference on recommender systems . 43-50. [12] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: A highly efficient gradient boosting decision tree. Advances in neural information processing systems 30 (2017). [13] Duncan McElfresh, Sujay Khandagale, Jonathan Valverde, Ganesh Ramakrishnan, Micah Goldblum, Colin White, et al. 2023. When Do Neural Nets Outperform Boosted Trees on Tabular Data? arXiv preprint arXiv:2305.02997 (2023). [14] H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, et al. 2013. Ad click prediction: a view from the trenches. In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining . 1222-1230. [15] Steffen Rendle. 2010. Factorization machines. In 2010 IEEE International conference on data mining . IEEE, 995-1000. [16] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems 30 (2017). [17] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep & cross network for ad click predictions. In Proceedings of the ADKDD'17 . 1-7. [18] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1059-1068. [19] Zzh, Wei Zhang, and Wentao. 2022. Industrial Solution in Fashion-domain Recommendation by an Efficient Pipeline using GNN and Lightgbm. In Proceedings of the Recommender Systems Challenge 2022 . 45-49. 7"}
