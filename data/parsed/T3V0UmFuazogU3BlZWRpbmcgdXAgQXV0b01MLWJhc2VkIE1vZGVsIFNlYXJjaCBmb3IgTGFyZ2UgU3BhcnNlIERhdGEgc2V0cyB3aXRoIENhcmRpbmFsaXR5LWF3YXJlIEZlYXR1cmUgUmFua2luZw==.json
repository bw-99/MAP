{"OutRank: Speeding up AutoML-based Model Search for Large Sparse Data sets with Cardinality-aware Feature Ranking": "BLA\u017d \u0160KRLJ, Outbrain inc., US BLA\u017d MRAMOR, Outbrain inc., US The design of modern recommender systems relies on understanding which parts of the feature space are relevant for solving a given recommendation task. However, real-world data sets in this domain are often characterized by their large size, sparsity, and noise, making it challenging to identify meaningful signals. Feature ranking represents an efficient branch of algorithms that can help address these challenges by identifying the most informative features and facilitating the automated search for more compact and better-performing models (AutoML). We introduce OutRank, a system for versatile feature ranking and data quality-related anomaly detection. OutRank was built with categorical data in mind, utilizing a variant of mutual information that is normalized with regard to the noise produced by features of the same cardinality. We further extend the similarity measure by incorporating information on feature similarity and combined relevance. The proposed approach's feasibility is demonstrated by speeding up the state-of-the-art AutoML system on a synthetic data set with no performance loss. Furthermore, we considered a real-life click-through-rate prediction data set where it outperformed strong baselines such as random forest-based approaches. The proposed approach enables exploration of up to 300% larger feature spaces compared to AutoML-only approaches, enabling faster search for better models on off-the-shelf hardware. Additional Key Words and Phrases: Feature ranking, massive data sets, AutoML, recommender systems", "ACMReference Format:": "Bla\u017e \u0160krlj and Bla\u017e Mramor. 2023. OutRank: Speeding up AutoML-based Model Search for Large Sparse Data sets with Cardinality-aware Feature Ranking. ACM/IMS J. Data Sci. 37, 4, Article 111 (August 2023), 8 pages. https://doi.org/XXXXXXX.XXXXXXX", "1 INTRODUCTION AND PROBLEM OVERVIEW": "The design of modern recommender systems relies on the integration of different context types into complex feature spaces that enable high-quality recommendations [1]. Real-world data sets in this domain are often characterized by their large size, sparsity, and noise, making it challenging to identify meaningful signals efficiently. Models that are part of real-life recommender systems, on the other hand, need to be lightweight and efficient due to the scale at which they are deployed [13]. For this purpose, contemporary machine learning model/design flows are utilized and consist of multiple steps, including feature (pre)selection, model search/optimization and refinement [12]. A commonly considered light-weight type of algorithms used in recommender systems are factorization machine-based models [10]. Albeit versatile in production, these methods require computationally expensive procedures for finding optimal single or combined features that comprise the final model. Such compact and well-performing model configurations can be found by utilizing automated search systems [4, 17] (AutoML). These systems are capable of exploring both the Authors' addresses: Bla\u017e \u0160krlj, bskrlj@outbrain.com, Outbrain inc., New York, New York, US; Bla\u017e Mramor, bmramor@outbrain.com, Outbrain inc., New York, New York, US. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \u00a9 2023 Association for Computing Machinery. Manuscript submitted to ACM Manuscript submitted to ACM 1 2 Bla\u017e \u0160krlj and Bla\u017e Mramor space of algorithms and their configurations and have become ubiquitous in the design of performance factorization machines [11]. The caveat associated with considering AutoML systems is their computational complexity - search for optimal feature configurations is time-consuming and often requires dedicated hardware (or clusters of machines). This process can be, to some extent, complemented with a computationally more approachable branch of feature ranking algorithms [14-16]. Feature ranking is a technique that can help address these challenges by identifying the most informative features and thus speeding up AutoML. These algorithms have found their use across multiple domains, spanning from biomedicine [6] to recommender systems [16]. They enable fast estimation of features' relevances (and their interactions), and can be considered as a form of prior information for an AutoML-based model search. The remainder of this paper describes key properties of OutRank, a system for versatile feature ranking and dataquality-related anomaly detection. OutRank utilizes a variant of mutual information that is normalized with regards to the noise produced by features of the same cardinality , which in our use-cases outperforms other strong baselines, such as random forest-based ranking. Furthermore, the presented approach can scale to data sets comprising hundreds of millions of instances using commodity hardware. Complemented by probabilistic cardinality estimation and coverage profiling, OutRank enables efficient data pre-processing, profiling of new features, and pruning of the input feature space to speed up AutoML-based model searches. Further, we present 3MR (Minimum redundancy, maximum relevance, maximum relation) heuristic that enables computation of fast non-myopic estimates of feature importances - its utility is demonstrated on synthetic and real-life data, where it enables substantial speedups of an existing AutoML system (TPOT [7]) and is shown to offer better rankings compared to strong baselines such as Random forest-based [2] rankings on an internal data set related to conversion rate prediction.", "2 SYSTEM OVERVIEW": "The remainder of this section is structured as follows. We first discuss the general context/overview of OutRank. Next, we discuss the impact of cardinality on ranking and how it was overcome. Finally, the section is followed by an overview of how feature combinations and their redundancies are considered in ranking, resulting in the 3MR algorithm. We next discuss the system's architecture/overview. OutRank was built to facilitate the exploration of very large data sets (up to a billion instances in some cases) without any specialized hardware. The only resource-friendly approach to traversing and analyzing such data sets is by adopting batching - the data set is streamed into the engine (OutRank). Once enough instances are temporarily stored, feature construction and ranking take place. This step is responsible for producing relevant transformations of data (on-the-fly), resulting in large space savings (compared to pre-computing all feature transformations of relevance), and conducting ranking. OutRank was built to scale to large data sets (tens of millions of listings) and support different ranking heuristics (discussed in the following sections). An overview of OutRank's architecture is shown in Figure 1. This paper focuses on the novel contributions related to ranking features for sparse categorical data sets (a detailed discussion of OutRank's architecture is beyond the scope of this paper). However, the described overview should offer the reader the context in which such ranking is considered/used in practice. We next discuss overcoming the effect of high cardinality features . A common problem when dealing with data sets that are used for the construction of recommender systems is related to features' cardinalities - the input space consists of mostly categorical features that can be subject to varying amounts of unique (possible) values. Many unique values per feature are potentially problematic, as they decrease coverage per value (instances with a particular value) and can be harder to profile/assess when ranking for a downstream task such as modelling/transformation/further exploration. Mutual information (detailed overview in, e.g., [5]) is an efficient similarity measure particularly suitable for comparing discrete (categorical) random variables. We next describe the variant of this measure we identified as fast Manuscript submitted to ACM OutRank: Speeding up AutoML-based Model Search 3 Fig. 1. Overview of OutRank. Feature ranking and analysis are conducted for batches of data (the user parametrizes size) - once enough data is observed by the system, the final aggregate is obtained from intermediary scores and used to produce final feature scores. Data batch Quality check Feature importances Aggregation step Data batch ... Summary Checkpoints Once enough samples are parsed Feature statistics Feature construction Time Intermediary feature quality reports Coverage and cardinality analysis Data batch and representative of features' similarities. The key motivation is based on the fact that the cardinality of a feature of interest plays an important role - simultaneously, ranking features of different cardinalities can be sub-optimal and can result in biased final scores (we observed inflated scores of features that exhibit high cardinality). Based on the adopted notion of mutual information:  where \ud835\udc48 and \ud835\udc49 represent two variables of interest and \ud835\udc37 KL represents Kullback-Leibler divergence, we propose the following modification. To account for cardinality's impact, we observed that normalizing this score by the expected score obtained by aggregating MI scores across a collection of samples of a random variable of same cardinality has beneficial effects when differentiating between more and less important features. Hence, the mutual information-derived score we refer to as CardMI computed adheres to the following expression  where \ud835\udc35 represents the set of all data batches (row-indexes, orange in Figure 1) and \ud835\udc48,\ud835\udc49 represent two features under consideration. The \ud835\udc46 \ud835\udc4f represents a random sample of the same cardinality for a given batch of data (the number of such samples is a parameter). The aggregation function Aggregate combines the intermediary scores into a final one and optionally truncates them to [ 0 , 1 ] range. At the end of each run, resulting importance scores are scaled to 0-1 range (considering score vector x ) Scale ( x \ud835\udc56 ) = x \ud835\udc56 -min ( x ) max ( x ) -min ( x ) . Intuitively, subtraction of the expected noise is conducted to distil the signal at the batch level - the generated noise differs from batch to batch (so does the actual data). Further, OutRank out-of-the-box implements a collection of \"sanity-check\" features ; these features correspond to random noise of specific cardinality, constants and other types of noise for which expected ranking scores are known (and are either very low or high - if derived from the target variable directly). Comparison against controls of different cardinalities enables us to control the algorithm's performance with unit tests, offering fast insights into possible regression introduced during software updates. The main rationale for considering an MI-based score is its speed. The computational complexity of CardMI is O(| \ud835\udc39 | \u00b7 \ud835\udc4f \u00b7 \ud835\udc60 \u00b7 | \ud835\udc35 |) , where \ud835\udc60 is the number of random samples used for normalization and | \ud835\udc35 | batch size. Computing a single \ud835\udc40\ud835\udc3c estimate is fast for sparse data sets. Low computational complexity and high parallelizability within data batches (pairwise CardMI rankings) enabled the development of an extended algorithm that overcomes CardMI's myopic nature - lack of capability for accounting for interactions. This aspect is discussed next in more detail. Manuscript submitted to ACM 4 Bla\u017e \u0160krlj and Bla\u017e Mramor We next discuss approximating higher order interactions . The crux of many recommender systems is their capability to accurately profile and detect relevant higher-order interactions. These combinations of two or more features can indicate sparse yet highly relevant events that govern the success of a given system. The adopted paradigm of factorization machines enables explicit modelling of such interactions; however, identifying them effectively is an ongoing research endeavour. Combining insights used by this branch of algorithms ( hashing trick ) with the efficiency of feature ranking, OutRank enables fast profiling of tens of thousands of interactions based on millions of instances. The idea underlying interaction profiling includes two insights that allow scaling. First, as OutRank traversed the data set in batches, profiling different interactions for different batches can substantially reduce time complexity ( O(| \ud835\udc39 | 2 ) ). Each combined feature representing the interaction of multiple features is obtained by hashing existing value tuples (the data structure holding this information) into a single value, making the feature directly compatible with CarMI computation, i.e., Comb ( \ud835\udc39 1 , \ud835\udc39 2 , . . . , \ud835\udc39 \ud835\udc5b ) = Hash ( struct = ( \ud835\udc39 1 , \ud835\udc39 2 , . . . , \ud835\udc39 \ud835\udc5b )) . Here, Hash represents a fast hash function (xxHash in our case 1 ). Albeit fast hashing enables the construction of combined features, ranking, in this case, takes substantially longer, and can be prohibitively complex. To overcome this issue, we introduce the notion of feature buffers - fixed-sized sets of features at the batch level that represent random samples of the space of all possible (generated) combinations. Feature buffer is populated randomly per batch (in an idempotent manner), and its fixed size guarantees consistent (predictable) performance. As different combinations are \"sampled\" when considering different batches, with enough data, reliable estimates of higher-order interaction scores are obtained (not enough samples imply unreliable scores). This way, second and third-order (conjunctions) interactions are within reach for production-scale data sets. Apart from approximating the supervised effect of interactions (via hashing), OutRank can also compute lower-triangular similarity matrices that represent redundancies between pairs of features. This computational step is, similar to the supervised interaction one above, computationally expensive and is approximated in the same manner; only a subspace of possible combinations is considered per data batch - in the limit (=with enough data), enough samples of all combinations are obtained. In addition, the \"buffer size\", i.e. the number of combinations/features to be considered at most per batch, is parametrized - the lower the value, the more coarse-grained the approximation of similarities/interaction importance.", "2.1 3MR - Minimum Redundancy Maximum Relevance Maximum Relation extension": "Albeit able to account for cardinality-related issues better, the CardMI heuristic does not incorporate information about the feature's similarity to other features (it's myopic). To overcome this limitation, we introduce a computational step that recursively re-weights scores based on features' redundancies and relevance when they are present in interactions. The motivation for this comes from one of our major use cases for OutRank, speeding up the AutoML algorithms for model building. The idea/motivation is similar to mRMR [8] and similar [16] approaches but tailored to the use case of fast non-myopic feature ranking for categorical data. Further, more recent work on fast-mRMR [9] also demonstrated the scalability of this branch of algorithms, which is aligned with our findings/design. Re-weighting of features based on redundancies is the motivation behind the so-called MRMR heuristic [16]. On the other hand, the reason for re-weighting features based on the interaction relevance comes from the fact that the recommendation algorithms which we most often use in AutoML (FM, FFM, DeepFM) favour features that, in interactions, generate strong signals. To describe this heuristic, let us denote by S \ud835\udc56 \u2208 R with \ud835\udc56 \u2208 { 1 , ..., \ud835\udc41 } the scores of the features \ud835\udc53 \ud835\udc56 , \ud835\udc56 \u2208 { 1 , ..., \ud835\udc41 } computed by CardMI heuristic compared to the target. Furthermore, let R \ud835\udc56,\ud835\udc57 \u2208 R denote the CardMI scores where \ud835\udc45 \ud835\udc56,\ud835\udc57 is the score of \ud835\udc53 \ud835\udc56 with respect to \ud835\udc53 \ud835\udc57 . Finally, let C \ud835\udc56,\ud835\udc57 \u2208 R denote the CardMI scores of the interaction \ud835\udc53 \ud835\udc56 , \ud835\udc53 \ud835\udc57 with respect to 1 https://github.com/Cyan4973/xxHash Manuscript submitted to ACM OutRank: Speeding up AutoML-based Model Search 5 the target. Then the formula for the 3MR ranking can be given as a re-indexation (bijection) \ud835\udc39 : { 1 , ..., \ud835\udc41 } \u2192 { 1 , ..., \ud835\udc41 } such that \ud835\udc53 \ud835\udc56 is a higher ranked feature than \ud835\udc53 \ud835\udc57 , if \ud835\udc56 < \ud835\udc57 . The heuristic can be computed iteratively by first considering \ud835\udc39 ( 0 ) = argmax \ud835\udc56 = 1 ,...,\ud835\udc41 (S \ud835\udc56 ) , followed by  where ( \ud835\udc46\ud835\udc39 ) is a statistical function (e.g. mean, median, sum) and \ud835\udefc, \ud835\udefd > 0 are hyper-parameters. Note that the set \ud835\udc39 -1 { 1 , ..., \ud835\udc56 -1 } denotes all the features ranked above (better than) \ud835\udc56 and in (2) this corresponds to all already computed features. Also, note that setting \ud835\udefd = 0 brings us to the MRMR heuristic and setting \ud835\udefc = 0 makes the heuristic ignore redundancies and only consider relational information.", "3 EVALUATION": "To evaluate the feasibility of the presented ideas, we conducted two sets of experiments designed to illustrate the methods' capabilities. First, we consider the common data mining scenario where a practitioner considers existing state-of-the-art AutoML tools for solving a given learning (classification in this case) task at hand - we considered TPOT [7] system and explored CardMI's capability to speed it up by pruning irrelevant part of the space before model search. The second part of the evaluation concerns using the presented work on a real-life production AutoML, where the amounts of data are greater, and the amount of time spent on feature search sufficient to identify suitable models can only be achieved in a distributed computing environment (>10 machines running model search). We next discuss performance on a synthetic data set - speeding up state-of-the-art AutoML . The first experiment considers a well-known data set built to profile the quality of feature ranking algorithms - Madelon [3]. The data set consists of 4,400 instances and 500 features; it is an artificial data set containing data points grouped in 32 clusters placed on the vertices of a five-dimensional hypercube and randomly labelled +1 or -1. AutoML was re-run ten times (different random seeds) for each proportion of data (incrementally more features) to evaluate the performance/time relation of model search; each search was run for up to three generations with a population size of ten models. For this task, we used the CardMI computed in batches of 4196 instances - this is one of the most straightforward off-the-shelf use cases applicable to many realistic scenarios. The results of more than two thousand AutoML runs are summarized in Figure 4. The benchmark (Figure 2) illustrates the main motivation of this paper - first, running more expensive AutoML was only possible after the initial feature \"pre-selection\". Second, on many data sets, up to 50% time improvements were observed if considering smaller feature space (performance obtained by AutoML was within the margin of 0.5% F1). The experiment demonstrates that efficient feature ranking can serve as a viable initial step when considering more expensive AutoML model search - especially in higher-dimensional data sets, the performance benefits are substantial. We proceed with the performance on a real-life use case - click-through rate (CTR) model search . Apart from data quality feature screening , OutRank's feature ranking heuristics are valuable for speeding up our AutoML search. This can be done by dropping a proportion of irrelevant features and thus reducing the search space or by using top-ranked features as the seed model , effectively skipping multiple generations of expensive AutoML search. To find optimal heuristics, we need a data set with a sufficient number of features and a benchmark feature ranking showing their importance for AutoML model-building procedure. Since such an open-source data set does not exist, we took 1.5 mio instances of subsampled production CTR training data with about 10% positive labels and 100 features. Features Manuscript submitted to ACM 6 Bla\u017e \u0160krlj and Bla\u017e Mramor (a) Model search time w.r.t. size of the (prepruned) feature space. 0 20 40 60 80 100 Proportion of preserved features (%) 0 20 40 60 80 100 Time proportion (w.r.t. all features) (%) madelon 0 20 40 60 80 100 Proportion of preserved features (%) 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 AutoML's performance ( F 1 ) 0 20 40 60 80 100 Proportion of time spent for model search w.r.t. slowest run (%) 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 F1 Data (%) 0 10 20 30 40 50 (b) Relation between performances of best model and size of considered feature space. (c) Relation between F1 performance and AutoML's time to achieve it. Fig. 2. Visualization of the impact of OutRank-based pruning on AutoML's performance. Visualizations show distributions of compute times and corresponding performances for various degrees of feature pruning (fewer features are considered right to left). Overall, more than 3,000 AutoML runs were conducted (one point=one run), and indicate that up to 30% speedup can be obtained with minimal-to-no loss of performance (a,b,c). Further, considering all features from the get-go can have substantial memory overhead (requiring different hardware), offering another reason for fast feature pre-selection/denoising prior to more expensive AutoML-based model search. 0 20 40 60 80 cumulate-recall-singles random MRMR(RF)-median ( \u03b1 = 0 . 2 ; \u03b2 = 0 . 0 ) RF 3MR(RF)-median ( \u03b1 = 0 . 0 ; \u03b2 = 0 . 5 ) MRMR(CardMI)-q90 ( \u03b1 = 0 . 2 ; \u03b2 = 0 ) CardMI 3MR(CardMI)-mean ( \u03b1 = 0 . 2 ; \u03b2 = 1 ) (a) Performance of 3MR for the task of approximating single generation of search. 0 10 20 30 40 50 60 cumulate-recall random RF 3MR(RF)-median ( \u03b1 = 0 . 2 ; \u03b2 = 0 . 5 ) AutoML-SingleFeatureFMs CardMI MRMR(CardMI)-q90 ( \u03b1 = 1 . 0 ; \u03b2 = 0 . 0 ) 3MR(CardMI)-q90 ( \u03b1 = 0 . 2 ; \u03b2 = 0 . 5 ) (b) Performance of 3MR when approximating AutoML search trace (each generation). Fig. 3. Cumulative overview of the performance for two ranking tasks of interest. 3MR performs well for both tasks - both redundancy and relation/interaction ( \ud835\udefc, \ud835\udefd )terms are non-zero, indicating that both types of information play a meaningful role during ranking. were pre-selected to represent the heterogeneous nature of our data for the strength of their signal against the target, their cardinality, their correlations to other features and their number of missing values. An AutoML model search adding consecutively single features to a factorization machine gave us our main benchmark feature ranking (full AutoML run ranking). Another helpful feature ranking is the results of a single AutoML run, i.e. ranking based on the performance of a single-feature FM, which we currently use to speed up our search. Data for OutRank's feature ranking heuristics was ten times subsampled AutoML data. The basic featureranking heuristics that we compared were logistic regression (LR), random forest (RF), randomly shuffled (R) and above mentioned CradMI. Furthermore, we compared MRMR and 3MR, which had the redundancies and relations computed with CardMI (due to higher computational complexity), and the relevances computed with RF or CradMI. The SF function in 3MR was mean, median or 90th percentile. The results can be seen in Figures 3 and 4. For each \ud835\udc56 = 1 , ..., 100 we compare ranking \ud835\udc3a to a target ranking \ud835\udc39 based on recall \ud835\udc45 \ud835\udc56 : = # ( \ud835\udc39 -1 ( 1 ,...,\ud835\udc56 )\u2229 \ud835\udc3a -1 ( 1 ,...,\ud835\udc56 ) ) \ud835\udc56 , as in Fig. 4. Furthermore, by Manuscript submitted to ACM OutRank: Speeding up AutoML-based Model Search 7 0 20 40 60 80 100 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 recall index@k heuristic MRMR(CardMI) random 3MR(CardMI)-mean 3MR(CardMI)-median MRMR(RF) 3MR(RF)-median 3MR(CardMI)-q90 CardMI LogisticRegression-based RandomForest-based Consequent generation in search (a) Approximating a single AutoML generation (single-feature factorization machines) with different ranking algorithms. 0 5 10 15 20 25 30 35 Consequent generation in search 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 cropped index@k heuristic MRMR(CardMI) random 3MR(CardMI)-mean 3MR(CardMI)-median MRMR(RF) 3MR(RF)-median 3MR(CardMI)-q90 CardMI LogisticRegression-based AutoML-SingleFeatureFMs RandomForest-based (b) Approximating top features for each generation of model search with different feature ranking algorithms. Fig. 4. Visualizations showing the potential of 3MR heuristic (computed as part of OutRank) for approximating computationally expensive in-house AutoML-based search. Subfigure (a) demonstrates that up to 20 features can be reliably retrieved via feature ranking. Subfigure (b) demonstrates that approximating the full trace of model search (multiple generations) is a hard problem, where proposed feature ranking heuristics perform better than AutoML if run only for a single generation. taking the sum over \ud835\udc45 : = \u02dd \ud835\udc56 \ud835\udc45 \ud835\udc56 , we get a general ranking for each heuristic compared to the benchmark, as in Fig. 3. From Fig. 3a and b, we can see that against both benchmarks CardMI heuristic outperforms RF and that 3MR with the weight of the relation ( \ud835\udefd ) larger than the redundancies weight ( \ud835\udefc ) further improves the ranking. For full AutoML run benchmark, on the other hand, MRMR already has a better performance than CardMI, and 3MR is even better. For single AutoML run benchmark MRMR is slightly worse, while 3MR with a large \ud835\udefd is better. Considering only redundancies gives a worse result in line with expectations since the single AutoML run benchmark is myopic by nature. Figure 4 shows insights into performance of different heuristics on subsets of features. The results confirm our intuition that adding redundancies and relations in the computation of feature ranking for AutoML improves the performance of the ranking heuristic. For our use-case, the proposed 3MR algorithm offers a good trade-off between speed/performance, even if compared against strong baselines.", "4 CONCLUSIONS AND FURTHER WORK": "This work explored whether simple hash-based encoding can offer added value in profiling interaction. Hash-based encoding is a simple and efficient technique that allows us to encode the interaction between two or more features into a single feature. We demonstrated that CardMI heuristic, a variant of mutual information that incorporates features' cardinalities, offers pruned feature space that enables up to 30% faster AutoML model search (TPOT) with no loss of performance and up to 50% faster search with minimal performance loss ( \u2248 0.5% F1). Our results showed that even with simple hash-based encoding, we were able to achieve significant improvements in feature ranking compared to existing methods - including strong baselines such as Random Forest-based ranking. However, there are more complex schemes for encoding interactions that are also possible. For example, negations and conditionals instead of simple conjunctions can give rise to more complex features that are currently out of reach and might further boost the performance of feature profiling. The potential benefits of these more complex schemes for encoding interactions are clear, but they also come with added computational costs. The source of OutRank will be made available upon concluded internal review required for its release 2 . 2 https://github.com/outbrain/outrank Manuscript submitted to ACM 8 Bla\u017e \u0160krlj and Bla\u017e Mramor", "REFERENCES": "[1] Zeynep Batmaz, Ali Yurekli, Alper Bilge, and Cihan Kaleli. 2019. A review on deep learning for recommender systems: challenges and remedies. Artificial Intelligence Review 52 (2019), 1-37. [2] Leo Breiman. 2001. Random forests. Machine learning 45 (2001), 5-32. [3] Isabelle Guyon, Steve Gunn, Masoud Nikravesh, and Lofti A Zadeh. 2008. Feature extraction: foundations and applications . Vol. 207. Springer. [4] Xin He, Kaiyong Zhao, and Xiaowen Chu. 2021. AutoML: A survey of the state-of-the-art. Knowledge-Based Systems 212 (2021), 106622. [5] Alexander Kraskov, Harald St\u00f6gbauer, and Peter Grassberger. 2011. Erratum: estimating mutual information [Phys. Rev. E 69, 066138 (2004)]. Physical Review E 83, 1 (2011), 019903. [6] Lili Liu, Lei Chen, Yu-Hang Zhang, Lai Wei, Shiwen Cheng, Xiangyin Kong, Mingyue Zheng, Tao Huang, and Yu-Dong Cai. 2017. Analysis and prediction of drug-drug interaction by minimum redundancy maximum relevance and incremental feature selection. Journal of Biomolecular Structure and Dynamics 35, 2 (2017), 312-329. [7] Laurent Parmentier, Olivier Nicol, Laetitia Jourdan, and Marie-El\u00e9onore Kessaci. 2019. Tpot-sh: A faster optimization algorithm to solve the automl problem on large datasets. In 2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI) . IEEE, 471-478. [8] Hanchuan Peng, Fuhui Long, and Chris Ding. 2005. Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy. IEEE Transactions on pattern analysis and machine intelligence 27, 8 (2005), 1226-1238. [9] Sergio Ram\u00edrez-Gallego, Iago Lastra, David Mart\u00ednez-Rego, Ver\u00f3nica Bol\u00f3n-Canedo, Jos\u00e9 Manuel Ben\u00edtez, Francisco Herrera, and Amparo AlonsoBetanzos. 2017. Fast-mRMR: Fast minimum redundancy maximum relevance algorithm for high-dimensional big data. International Journal of Intelligent Systems 32, 2 (2017), 134-152. [10] Steffen Rendle. 2010. Factorization machines. In 2010 IEEE International conference on data mining . IEEE, 995-1000. [11] Lars Ropeid Selsaas, Bikash Agrawal, Chumming Rong, and Thomasz Wiktorski. 2015. AFFM: Auto feature engineering in field-aware factorization machines for predictive analytics. In 2015 IEEE International Conference on Data Mining Workshop (ICDMW) . IEEE, 1705-1709. [12] Kunal Shah, Akshaykumar Salunke, Saurabh Dongare, and Kisandas Antala. 2017. Recommender systems: An overview of different approaches to recommendations. In 2017 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS) . IEEE, 1-4. [13] Razieh Sheikhpour. 2023. A local spline regression-based framework for semi-supervised sparse feature selection. Knowledge-Based Systems (2023), 110265. [14] B Venkatesh and J Anuradha. 2019. A review of feature selection and its methods. Cybernetics and information technologies 19, 1 (2019), 3-26. [15] Jialei Wang, Peilin Zhao, Steven CH Hoi, and Rong Jin. 2013. Online feature selection and its applications. IEEE Transactions on knowledge and data engineering 26, 3 (2013), 698-710. [16] Zhenyu Zhao, Radhika Anand, and Mallory Wang. 2019. Maximum relevance and minimum redundancy feature selection methods for a marketing machine learning platform. In 2019 IEEE international conference on data science and advanced analytics (DSAA) . IEEE, 442-452. [17] Ruiqi Zheng, Liang Qu, Bin Cui, Yuhui Shi, and Hongzhi Yin. 2023. AutoML for Deep Recommender Systems: A Survey. ACM Transactions on Information Systems (2023). Manuscript submitted to ACM"}
