{"ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation": "Jianghao Lin chiangel@sjtu.edu.cn Shanghai Jiao Tong University Shanghai, China Rong Shan shanrong@sjtu.edu.cn Shanghai Jiao Tong University Shanghai, China Chenxu Zhu zhuchenxu1@huawei.com Huawei Noah's Ark Lab Shenzhen, China", "Kounianhua Du": "774581965@sjtu.edu.cn Shanghai Jiao Tong University Shanghai, China", "Ruiming Tang": "tangruiming@huawei.com Huawei Noah's Ark Lab Shenzhen, China", "Bo Chen": "chenbo116@huawei.com Huawei Noah's Ark Lab Shenzhen, China", "Yong Yu": "Shigang Quan quan123@sjtu.edu.cn Shanghai Jiao Tong University Shanghai, China", "Weinan Zhang \u2217": "yyu@sjtu.edu.cn Shanghai Jiao Tong University Shanghai, China", "ABSTRACT": "With large language models (LLMs) achieving remarkable breakthroughs in natural language processing (NLP) domains, LLMenhanced recommender systems have received much attention and have been actively explored currently. In this paper, we focus on adapting and empowering a pure large language model for zeroshot and few-shot recommendation tasks. First and foremost, we identify and formulate the lifelong sequential behavior incomprehension problem for LLMs in recommendation domains, i.e. , LLMs fail to extract useful information from a textual context of long user behavior sequence, even if the length of context is far from reaching the context limitation of LLMs. To address such an issue and improve the recommendation performance of LLMs, we propose a novel framework, namely R etrievale nhanced L arge La nguage models (ReLLa) for recommendation tasks in both zero-shot and few-shot settings. For zero-shot recommendation, we perform semantic user behavior retrieval (SUBR) to improve the data quality of testing samples, which greatly reduces the difficulty for LLMs to extract the essential knowledge from user behavior sequences. As for few-shot recommendation, we further design retrieval-enhanced instruction tuning (ReiT) by adopting SUBR as a data augmentation technique for training samples. Specifically, we develop a mixed training dataset consisting of both the original data samples and their retrieval-enhanced counterparts. We conduct extensive experiments on three real-world public datasets to demonstrate the superiority of ReLLa compared with existing baseline models, as wnzhang@sjtu.edu.cn Shanghai Jiao Tong University Shanghai, China well as its capability for lifelong sequential behavior comprehension. To be highlighted, with only less than 10% training samples, few-shot ReLLa can outperform traditional CTR models that are trained on the entire training set ( e.g. , DCNv2, DIN, SIM). The code is available 12 .", "CCS CONCEPTS": "\u00b7 Information systems \u2192 Recommender systems .", "KEYWORDS": "Large Language Models; Recommender Systems; User Modeling", "ACMReference Format:": "Jianghao Lin, Rong Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, Shigang Quan, Ruiming Tang, Yong Yu, and Weinan Zhang. 2024. ReLLa: Retrievalenhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation. In Proceedings of the ACM Web Conference 2024 (WWW '24), May 13-17, 2024, Singapore, Singapore. ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/3589334.3645467", "1 INTRODUCTION": "Recommender systems play a vital role in various online applications to alleviate the information overload problem and satisfy the users' information needs [25, 84, 85]. Besides, large language models (LLMs) have flourished in the natural language processing (NLP) domain, showing impressive capacities in generating human-like texts for a wide range of tasks [6, 77, 83, 93]. Consequently, recent works start to explore the potential of LLMs for recommender systems [3, 30, 46]. They adopt LLMs directly for various recommendation tasks ( e.g. , listwise ranking, pointwise scoring), and find out that large language models depict promising performance in zero-shot and few-shot settings for recommendation [3, 92]. 0.7700 0.7800 0.7900 0.8000 AUC SIM (full-shot) 0.6800 0.6900 0.7000 AUC Vicuna-13B (zero-shot) In this paper, we focus on adapting and empowering a pure large language model for recommendation tasks in zero-shot and fewshot settings. First, we identify the lifelong sequential behavior incomprehension problem , i.e. , LLMs fail to extract the useful information from a textual context of long user behavior sequence for recommendation tasks, even if the length of context is far from reaching the context limitation of LLMs . This problem is shown in Figure 1, where Vicuna-13B [12, 77] is a popular open-source large language model with a context window of 2048 tokens. As we can observe, the traditional recommendation model ( i.e. , SIM) enjoys steady performance gains as the length of involved user sequence \ud835\udc3e grows. However, the performance of Vicuna-13B reaches the peak at length \ud835\udc3e = 15 and starts to decrease with longer behavior sequence \ud835\udc3e > 15, even if the number of involved tokens is far less than the context window limitation ( i.e. , 2048 tokens). While in common NLP tasks, LLMs can definitely exhibit exceptional performance if given a similar length of context (around 600+ tokens). Therefore, we argue that such an incomprehension problem on long user behavior sequence is special for LLMs in recommendation domains, where it is a rather difficult reasoning task to infer the user's preference towards a certain candidate item based on the given user profile and behavior history. To address the lifelong sequential behavior incomprehension problem, we propose a novel framework to develop R etrievale nhanced L arge La nguage models (ReLLa) for recommendation tasks in both zero-shot and few-shot settings. For zero-shot recommendation , we propose to conduct semantic user behavior retrieval (SUBR) to replace the simply truncated top\ud835\udc3e recent behaviors with the top\ud835\udc3e semantically relevant behaviors towards the target item. In this way, we improve the quality of data samples and reduce the difficulty for LLMs to extract useful information from user behavior sequences, therefore alleviating the incomprehension problem. For few-shot recommendation , apart from applying SUBR to improve the data quality of samples, we propose to perform retrieval-enhanced instruction tuning (ReiT) to further promote the ability of LLMs to handle inputs with long behavior sequences. We apply SUBR on training samples as the data augmentation techniques to obtain a mixed training dataset of both original and retrieval-enhanced training data samples, which increases the robustness and generalization ability of LLMs. More surprisingly, with only few-shot training samples ( e.g. , 8,192 data instances in MovieLens-25M dataset), ReLLa can outperform full-shot traditional recommendation models ( e.g. , DCNv2 [82], DIN [99], and SIM [62]) that are trained with the entire training set ( e.g. , nearly 20M samples in MovieLens-25M dataset ). Main contributions of this paper are in three folds: \u00b7 To the best of our knowledge, we are the first to identify and well formulate the lifelong sequential behavior incomprehension problem for LLMs in recommendation, where LLMs are generally incomprehensible to a textual context of long user behavior sequence, even if the length of context is far from reaching the context limitation. \u00b7 We propose a novel ReLLa ( R etrievale nhanced L arge La nguage Models) framework to mitigate the incomprehension problem of LLMs on long user behavior sequences. We design semantic user behavior retrieval (SUBR) to improve the data quality of data samples for zero-shot recommendation, and further propose retrieval-enhanced instruction tuning (ReiT) to promote the fewshot recommendation performance with a mixture of original and retrieval-enhanced training samples. \u00b7 Extensive experiments on three real-world public datasets validate the effectiveness of our method compared with existing baselines. Note that the baseline models are trained in fullshot settings with the entire training set, while ReLLa is only trained with few-shot samples.", "2 PRELIMINARIES": "In this paper, we focus on the click-through rate (CTR) prediction, which serves as the core component in recommender systems to estimate a user's click probability towards a target item given a certain context [25, 48]. The training dataset for CTR prediction is denoted as {( \ud835\udc65 \ud835\udc56 , \ud835\udc66 \ud835\udc56 )} \ud835\udc41 \ud835\udc56 = 1 , where \ud835\udc41 is the number of data samples ( i.e. , \ud835\udc41 -shot). When adapting a pure large language model for such a pointwise scoring task, we need to clarify the following three key aspects: (1) what is the definition of zero-shot and few-shot recommendations, (2) how to formulate the textual input-output pairs, and (3) how to do pointwise scoring with LLMs.", "2.1 Zero-shot and Few-shot Recommendations": "Zero-shot recommendation implies that a model is directly employed for the target recommendation task without any tuning on the in-domain training data. Apparently, traditional recommendation models are incapable of accomplishing zero-shot recommendation tasks, since they are randomly initialized. However, LLMs possess a vast volume of open-world knowledge and logical reasoning abilities, which enable them to infer the user's preference towards a certain target item based on the profile of user/item. Few-shot recommendation refers to low-resource scenarios with \ud835\udc41 training data samples. \ud835\udc41 denotes the number of shots, which is ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation a relatively small number. This highly requires the data efficiency characteristic of an algorithm to fully exploit the limited number of training samples to achieve better recommendation performance. Extending from the definition of few-shot recommendation, we can therefore define full-shot recommendation as the setting where we train the model based on the entire training set.", "2.2 Textual Input-Output Pair Formulation": "For LLMs, we need to convert each data sample \ud835\udc65 \ud835\udc56 into textual sentences \ud835\udc65 \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 \ud835\udc56 via hard prompt templates. Similarly, the binary label \ud835\udc66 \ud835\udc56 \u2208 { 0 , 1 } is transformed into a pair of binary key answer words \ud835\udc66 \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 \ud835\udc56 \u2208 { 'Yes' , 'No' } . We give an illustrative example of the input-output pair ( \ud835\udc65 \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 \ud835\udc56 , \ud835\udc66 \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 \ud835\udc56 ) in Figure 2, where \ud835\udc65 \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 \ud835\udc56 contains the descriptive texts for user profile, user behavior sequence, target item and task description, respectively. I nput: The user is a male. His job is college/grad student. His age is 25-34. He watched the following movies in order in the past, and rated them: ['0. Pump Up the Volume (1990) (4 stars)', '1. Antz (1998) (4 stars)', \" 2. Devil's Own, The (1997) (5 stars)\" , '3. Crying Game, The (1992) (1 star)'] Based on the movies he has watched, deduce if he will like the movie ***Titanic (1997)***. Note that more stars the user rated the movie, the user like the movie more. You should ONLY tell me yes or no. Output: No. Notably, the predominant factor that determines the length of context is derived from the user behavior sequence, the length of which can varies from tens to hundreds. For each input \ud835\udc65 \ud835\udc56 , we truncate the user behavior sequence to length \ud835\udc3e . For example, the length of behavior sequence in Figure 2 is \ud835\udc3e = 4. While the common sequential CTR prediction settings usually truncate and adopt the most recent \ud835\udc3e behaviors , ReLLa propose to conduct semantic user behavior retrieval to construct textual inputs with the most relevant \ud835\udc3e behaviors towards the target item.", "2.3 Pointwise Scoring with LLMs": "The large language model takes as input the discrete tokens of \ud835\udc65 \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 \ud835\udc56 , and generate the next token \u02c6 \ud835\udc66 \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 \ud835\udc56 as the output, the process of which can be formulated as follows: where \ud835\udc49 is the vocabulary size, and \u02c6 \ud835\udc66 \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 \ud835\udc56 is the next predicted token sampled from the probability distribution \ud835\udc5d \ud835\udc56 . However, CTR prediction requires the model to do pointwise scoring, and the output should be floating-point number \u02c6 \ud835\udc66 \ud835\udc56 \u2208 [ 0 , 1 ] instead of a discrete token \u02c6 \ud835\udc66 \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 \ud835\udc56 . Therefore, following previous works [3, 97], we intercept the estimated scores \ud835\udc60 \ud835\udc56 \u2208 R \ud835\udc49 , and conduct a bidimensional softmax over the corresponding scores of the binary key answer words. Suppose the vocabulary indices for 'Yes' and 'No' are \ud835\udc4e and \ud835\udc4f , respectively. The pointwise scoring of LLMs for CTR prediction can be written as: LLM Semantic Vectors PCA Module I te m Pool Semantic Item Encoding Semantic User Behavior Retrieval (SUBR) Timeline Semantically Retrieved Top-K Behaviors Target Item It is worth noting that such an estimated click-through rate \u02c6 \ud835\udc66 \ud835\udc56 is only leveraged for evaluation on the testing set. We preserve the common instruction tuning and causal language modeling paradigm for LLMs if training is involved.", "3 METHODOLOGY": "In this section, we introduce the ReLLa ( R etrievale nhanced L arge La nguage Models) framework in details.", "3.1 Overview of ReLLa": "In the ReLLa framework, we develop two key techniques for LLMs in zero-shot and few-shot recommendations, respectively. For zero-shot recommendation, as illustrated in Figure 3, we propose to conduct semantic user behavior retrieval (SUBR) to improve the data quality of data samples. We first leverage the large language model to obtain the semantic vectors for each item. Then, for each textual data sample \ud835\udc65 \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 \ud835\udc56 , we retrieve the most semantically relevant \ud835\udc3e behaviors, which can substitute the original most recent \ud835\udc3e behaviors. For few-shot recommendation, as shown in Figure 5, we propose to perform retrieval-enhanced instruction tuning (ReiT) to promote the ability of LLMs to extract useful information from long behavior sequences. Notably, the semantic user behavior retrieval (SUBR) is adopted as the data augmentation technique to form the mixed training dataset. The mixture of both original and retrievalenhanced data samples introduces more variety and patterns in the training set, thus increasing the robustness and generalization ability of LLMs for lifelong sequential behavior comprehension. Although ReLLa is tuned in few-shot settings, we would like to again emphasize that other recommendation baseline models are trained in full-shot settings with the entire training set.", "3.2 Semantic User Behavior Retrieval": "In zero-shot settings, the parameters of LLMs cannot be tuned according to the in-domain training samples. Hence, as shown in Figure 3, semantic user behavior retrieval (SUBR) aims to improve the quality of each sample by replacing the simply truncated most recent \ud835\udc3e behaviors with the most semantically relevant \ud835\udc3e behaviors towards the target item. As suggested in previous works [62, 64], the retrieved user behaviors can denoise the user history and convey more clear and essential user interests for the target item, while preserving the original length of user sequence as the model input. Here is a movie. Its title is Toy Story (1995).\u00a0 The movie's genre is Animation.", "Figure 4: Illustration of descriptive text for an item (movie).": "Firstly, we conduct semantic item encoding to obtain the semantic vector for each item. For the \ud835\udc61 -th item in the pool, a descriptive text is constructed via hard prompt template (an example is given in Figure 4, and is then fed through LLM. We perform average pooling over all the hidden states from the last layer of LLM, resulting in a vector \ud835\udc62 \ud835\udc61 \u2208 R \ud835\udc37 , where \ud835\udc37 is the hidden size of LLM ( e.g. , 4096 for Vicuna-7B, and 5120 for Vicuna-13B). A principal component analysis (PCA) [73] module is further employed for both dimension reduction and denoising purposes, engendering the final semantic representation \ud835\udc63 \ud835\udc61 \u2208 R \ud835\udc51 , where we set \ud835\udc51 = 512. Now we can measure the semantic relevance between each pair of items via the cosine similarity between their corresponding semantic representations. Next, we can apply semantic user behavior retrieval on each testing sample to replace the original truncated top\ud835\udc3e recent behaviors with the top\ud835\udc3e semantically relevant behaviors towards the target item. In this way, we obtain a parallel retrieval-enhanced testing dataset with higher data quality, while keeping the length of input context roughly unchanged. Therefore, SUBR can improve the zero-shot recommendation performance, and mitigate the incomprehension problem on long user behavior sequences.", "3.3 Retrieval-enhanced Instruction Tuning": "As for few-shot recommendation, we denote the training dataset as {( \ud835\udc65 \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 \ud835\udc56 , \ud835\udc66 \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 \ud835\udc56 )} \ud835\udc41 \ud835\udc56 = 1 , where \ud835\udc41 is the number of shots ( i.e. , training samples). While previous works [3, 92] directly employ instruction tuning for LLMs over the converted textual input-output pairs, we argue that simple instruction tuning could potentially expose large language models to risks of overfitting and catastrophic forgetting on limited number of training data [37, 69]. To this end, we propose a novel retrieval-enhanced instruction tuning (ReiT), where semantic user behavior retrieval (SUBR) is adopted as the data augmentation technique to construct a mixed training dataset with enriched user behavior patterns. As shown in Figure 5, we apply SUBR on each training data to obtain its retrieval-enhanced counterpart \u02dc \ud835\udc65 \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 \ud835\udc56 . Next, we merge the original and retrieval-enhanced data instances to construct a mixed training dataset with total 2 \ud835\udc41 samples. Finally, we conduct instruction tuning for LLMs on the mixed training data. The pattern enrichment brought by SUBR can regularize and prevent the large language model from overfitting, thus promoting its robustness and generalization ability to effectively extract essential knowledge from a long user behavior sequence of length \ud835\udc3e . We leverage the causal language modeling objective for instruction tuning to retain the original model structure: LLM Mixed Dataset Data Samples with Top-K Recent Behaviors Data Samples with Top-K Relevant Behaviors SUBR Retrieval-enhanced Instruction Tuning (ReiT) I nstruction Tuning where \u0398 is the parameter of LLM, M is the mixed training dataset with total 2 \ud835\udc41 data samples, \ud835\udc66 \ud835\udc57 is the \ud835\udc57 -th token of the textual output \ud835\udc66 , and \ud835\udc66 < \ud835\udc57 denotes the tokens before \ud835\udc66 \ud835\udc57 . There is no randomly initialized prediction layer appended upon LLM for CTR prediction with binary cross-entropy (BCE) loss. The CTR estimation method for pointwise scoring with LLMs discussed in Section 2.3 is only used for evaluation on the testing set. While we maintain a mixed training dataset for instruction tuning, the testing set contains pure retrieval-enhanced data samples generated by SUBR, which is the same as zero-shot recommendation as described in Section 3.2. Moreover, we provide further discussion about ReiT to address readers' possible concerns as follows: \u00b7 Will ReiT cause the inconsistency between the training and testing data? Data augmentation is a common regularization technique, especially for low-resource few-shot settings in computer vision (CV) [4, 90] or natural language processing (NLP) [19, 38]. The inconsistency would not exist, as long as the augmentation algorithm is sound and reasonable. \u00b7 Which factor actually contribute to the performance improvement of ReiT? The doubled training samples, or the pattern enrichment? Both factors can lead to the final performance enhancement, but we argue that the pattern enrichment as regularization is a more important factor for model robustness. Empirical studies are provided in Section 4.5 to ablate and decouple these two factors.", "4 EXPERIMENT": "In this section, we conduct extensive experiments to answer the following research questions: RQ1 How does ReLLa perform compared to existing baselines? RQ2 Does ReLLa promote the lifelong sequential behavior comprehension ability of LLMs for recommendation tasks? RQ3 How does the number of shots \ud835\udc41 affect the performance? RQ4 What are the influences of different components for ReLLa? RQ5 How ReLLa help LLMs to better comprehend the user behavior sequence? Due to the page limitation, we further provide additional experiments in Appendix D to verify the following core points: \u00b7 The universality of the lifelong sequential behavior incomprehension problem and the generalization of our proposed ReLLa. \u00b7 Analysis about the model parameter and inference time. \u00b7 Ablation on PCA dimensionality and distance metrics for SUBR. \u00b7 Analysis of potential reasons for the incomprehension problem. ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation", "4.1 Experiment Setup": "4.1.1 Datasets. Weconductexperiments on three real-world datasets ( i.e. , BookCrossing 3 , MovieLens-1M 4 and MovieLens-25M 5 ). We show the dataset statistics in Table 1 and give detailed data preprocessing information in Appendix B due to page limitations. 4.1.2 Evaluation Metrics. To evaluate the performance of our methods, we leverage AUC (area under the ROC curve), Log Loss (binary cross-entropy loss) and ACC (accuracy score) as the evaluation metrics. In CTR prediction, slightly higher AUC or lower Log Loss (e.g., 0.001) can be regarded as significant improvement [45, 82]. 4.1.3 Baseline Models. The CTR baseline models can be mainly classified into two categories: (1) traditional CTR models that take one-hot encoded IDs as inputs, and (2) LM-based models that incorporate pretrained language models and formulate CTR prediction as either text classification or sequence-to-sequence problem. Traditional CTR models can be further categorized into (1) feature interaction models, and (2) user behavior models. We select DeepFM [25], AutoInt [74], and DCNv2 [82] as representative feature interaction models, and choose GRU4Rec [27], Caser [76], SASRec [35], DIN [99], and SIM [62] as representative user behavior models. We apply average pooling over users' historical behaviors, and regard the outputs as additional feature fields for the feature interaction models. SIM [62] is a classical sequential CTR model that leverages user behavior retrieval techniques to enhance the recommendation performance. We include it for fair comparison, since ReLLa incorporates semantic user behavior retrieval (SUBR). As for LM-based CTR models, we select CTR-BERT [55], PTab [50], and P5 [22] as the representative baselines. TALLRec [3] adopts the simple instruction tuning framework for LLMs, and we therefore include it in our ablation study in Section 4.5. 4.1.4 Implementation Details. We select Vicuna-13B [12] released by FastChat 6 as the base LLM for ReLLa. All the experiments are conducted on V100 GPUs. For training resource efficiency, 8-bit quantization and low-rank adaption (LoRA) [31] are adopted for parameter-efficient finetuning (PEFT). We follow previous works [3, 11] to set the configuration of LoRA, with LoRA rank as 8, LoRA alpha as 16, and LoRA dropout as 0.05. The LoRA update matrices are applied on the query and value projection matrices of attention blocks. During instruction tuning, we adopt AdamW [53] optimizer with weight decay set to 0. The model is trained with a batch size selected from { 128 , 256 } . The learning rate is initialized from { 1 \u00d7 10 -3 , 1 . 5 \u00d7 10 -3 } with linear scheduler. On BookCrossing dataset, the maximum training epoch is set to 10, while on MovieLens1M and MovieLens-25M datasets, the maximum epoch is set to 5. The configuration of baselines is in Appendix C. The hard prompt templates for textual input-output pairs and item descriptions for all three datasets are in Appendix A. Moreover, when constructing the hard prompt template for ReLLa, we remove all the pure ID fields, i.e. , User ID and ISBN fields on BookCrossing dataset, User ID , Movie ID , and Zipcode fields on MovieLens-1M dataset, User ID and Movie ID fields on MovieLens-25M dataset. The reason is that LLMs possess limited perceptual abilities for pure ID texts [46]. Other fields are leveraged as user profile or item information in the prompt, as described in Section 2.2 and Appendix A. Note that we do not discard any features for other CTR baseline models, i.e. , they take all the feature fields and user behavior sequences as inputs.", "4.2 Overall Performance (RQ1)": "We evaluate the performance of ReLLa in comparison to existing baseline models, and report the results in Table 2. Note that other recommendation baseline models are all trained in full-shot settings with the entire training set. We set the length of user behavior sequence \ud835\udc3e to 60/30/30 for BookCrossing/MovieLens1M/MovieLens-25M, respectively. For zero-shot recommendation, we observe that: \u00b7 The performance of Vicuna-7B is notably inferior to its 13B version on all three datasets. It demonstrates that a larger LLM possesses more excellent language comprehension and logical reasoning abilities, therefore leading to better zero-shot inference capability for user preference. \u00b7 ReLLa significantly outperforms Vicuna-13B for all three metrics on BookCrossing and MovieLens-1M datasets. Although the AUC performance of ReLLa degenerates on MovieLens-25M, ReLLa attains significant improvements in terms of pointwise metrics ( i.e. , Log Loss and ACC). such phenomena validate the effectiveness of SUBR in reducing the difficulty for LLMs to extract useful information from user behavior sequences. Also, the AUC degeneration of AUC on MovieLens-25M reveals the potential instability of zero-shot LLMs for recommendation. As for full-shot and few-shot settings, we can draw the following observations from Table 2: \u00b7 SIM achieves the best performance among all the baseline models. SIM applies user behavior retrieval to reduce the noise of user sequences, which is essentially beneficial for CTR prediction. Besides, LM-based CTR models ( i.e. , CTR-BERT, PTab, P5) perform worse than most of the ID-based traditional CTR models, which is consistent with the results reported in [42, 68]. These LM-based methods only incorporate small language models ( e.g. , BERT [4], T5 [67]) for pure text-based recommendation, and therefore result in inferior performance. \u00b7 ReLLa (few-shot) generally achieves significantly better performance over all the baseline models, except for few cases, which validates the effectiveness of our proposed retrieval-enhanced instruction tuning (ReiT). It is worth noting that ReLLa only utilizes less than 10% training samples for finetuning, while other baseline models are trained on the entire training set , e.g. , \ud835\udc41 = 65 , 536 for ReLLa and \ud835\udc41 = 19 , 349 , 912 for SIM on MovieLens-25M dataset. This demonstrates the superior data efficiency of ReLLa for sequential recommendation tasks. 0.7200 0.7300 0.7400 0.7500 AUC BookCrossing SIM (full-shot) ReLLa (tune #256) 10(256) 20(343) 30(401) 40(446) 50(481) 60(511) Length of User Behavior Sequence K (#Average Tokens) 0.7050 0.7100 0.7150 AUC Vicuna-13B (zero-shot) 0.7700 0.7800 0.7900 0.8000 AUC MovieLens-1M SIM (full-shot) ReLLa (tune #8192) 5(240) 10(333) 15(428) 20(518) 25(605) 30(688) Length of User Behavior Sequence K (#Average Tokens) 0.6800 0.6900 0.7000 AUC Vicuna-13B (zero-shot) 0.7800 0.8000 0.8200 0.8400 AUC MovieLens-25M SIM (full-shot) ReLLa (tune #8192) 5(191) 10(297) 15(404) 20(507) 25(606) 30(701) Length of User Behavior Sequence K (#Average Tokens) 0.7400 0.7450 0.7500 AUC Vicuna-13B (zero-shot)", "4.3 Sequential Behavior Comprehension (RQ2)": "We vary the length of user behavior sequence \ud835\udc3e to investigate its impact on CTR prediction performance, which can demonstrate the comprehension ability of a model towards user behavior sequences. Three different models, including SIM (full-shot), Vicuna13B (zero-shot) and ReLLa (few-shot), are evaluated with different \ud835\udc3e s. On BookCrossing dataset, \ud835\udc3e ranges in { 10 , 20 , 30 , 40 , 50 , 60 } , while on MovieLens-1M and MovieLens-25M datasets, \ud835\udc3e ranges in { 5 , 10 , 15 , 20 , 25 , 30 } . The numbers of shots are set to 256, 8192, 8192 for BookCrossing, MovieLens-1M, and MovieLens-25M, respectively ( i.e. , <1% few-shot setting). The results are shown in Figure 6, from which we obtain the following observations: \u00b7 However, the performance of Vicuna-13B (zero-shot) only arrives at the peak with \ud835\udc3e = 30 / 15 / 15 on BookCrossing/MovieLens1M/MovieLens-25M datasets, and then starts to decrease with further longer sequence. It is worth noting that the number of involved tokens ( i.e. , around 500/700/700 for three datasets respectively) is actually far from reaching the context limitation of Vicuna-13B ( i.e. , 2048 tokens). This indicates that it is non-trivial for LLMs to comprehend the textual context of long behavior sequences for recommendation, where a certain amount of indomain knowledge is required. \u00b7 As a traditional CTR prediction model, SIM (full-shot) [62] enjoys steady performance improvement as the length \ud835\udc3e grows. This is consistent with our common understanding, where longer user behavior sequences can introduce more useful information to better accomplish the recommendation tasks. \u00b7 ReLLa mitigates the incomprehension problem of LLMs on long user behavior sequences for recommendation. Compared with Vicuna-13B (zero-shot), whose performance drops when \ud835\udc3e > 30 on BookCrossing and \ud835\udc3e > 15 on MovieLens-1M and MovieLens25M, there are no performance turning points for ReLLa. Similar to SIM, the AUC performance of ReLLa achieves continuous improvement as \ud835\udc3e grows, validating the comprehension ability of ReLLa for the textual contexts with longer behavior sequences. ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation 128 256 512 1024 2048 4096 The Number of Shots N 0.7000 0.7200 0.7400 0.7600 AUC BookCrossing ReLLa (tune #N) SIM (tune #N) SIM (tune #15,942) 512 1024 2048 4096 8192 65536 The Number of Shots N 0.6600 0.6800 0.7000 0.7200 0.7400 0.7600 0.7800 0.8000 0.8200 AUC ReLLa (tune #N) SIM (tune #N) SIM (tune #776,007) MovieLens-1M 512 1024 2048 4096 8192 65536 The Number of Shots N 0.7000 0.7200 0.7400 0.7600 0.7800 0.8000 0.8200 0.8400 0.8600 AUC ReLLa (tune #N) SIM (tune #N) SIM (tune #19,349,912)", "MovieLens-25M": "Here is a movie. Its title is Thor: Ragnarok (2017). The movie's genre is Action. Figure 11: Examples of hard prompt templates of item descriptions for three datasets. The textual description is used to obtain the semantic item embedding from LLM, which will then be leveraged by SUBR. \u00b7 DeepFM [25]. On BookCrossing, the size of DNN layer is selected from {32, 64, 128}. The number of DNN layers is selected from {1, 2, 3}. On MovieLens-1M and MovieLens-25M, we choose the size of DNN layer from {128, 256} and the number of DNN layers from {3, 6, 9, 12}. \u00b7 AutoInt [74]. On BookCrossing, the number of attention layers is selected from {1, 2} and the attention size is set to 32. On MovieLens-1M and MovieLens-25M, the attention layers is selected from {3, 6, 9, 12} and the attention size is selected from {64, 128, 256}. The number of attention heads are all set to 1. \u00b7 DCNv2 [82]. On BookCrossing, the size of DNN layer is selected from {32, 64, 128}. The number of DNN layers and cross layers are selected from {1, 2, 3}. On MovieLens-1M and MovieLens-25M, we choose the size of DNN layers from {128, 256} and the number of DNN layers and cross layers are from {3, 6, 9, 12}. \u00b7 GRU4Rec [27]. The number of GRU layers is selected from {1, 2, 3}. On BookCrossing, the GRU hidden size and DNN hidden size is selected from {32, 64}. On MovieLens-1M and MovieLens-25M, the GRU hidden size and DNN hidden size is selected from {64, 128, 256}. \u00b7 Caser [76]. The number of vertical convolution kernels is selected from {2, 4, 8}. The number of horizontal convolution kernels is selected from {4, 8, 16}. The number of DNN layers is selected from {1,2,3}. The DNN hidden size is selected from {32, 64} on BookCrossing and {64, 128, 256} on MovieLens-1M and MovieLens-25M. \u00b7 SASRec [35]. The number of attention heads is selected from {1, 2, 4}. The number of attention layers is selected from {1, 2, 3}. The attention size is selected from {32, 64, 128} on BookCrossing and {64, 128, 256}. The number of DNN layers is selected from {1,2,3}. The DNN hidden size is selected from {32, 64} on BookCrossing and {64, 128, 256} on MovieLens-1M and MovieLens-25M. \u00b7 DIN [99]. The number of DIN attention layers and DNN layers are selected from {1, 2, 3}. The DNN hidden size is selected from {32, 64} on BookCrossing and {64, 128, 256} on MovieLens-1M and MovieLens-25M. \u00b7 SIM [62]. The number of attention layers and DNN layers are selected from {1, 2, 3}. The DNN hidden size is selected from {32, 64} on BookCrossing and {64, 128, 256} on MovieLens-1M and MovieLens-25M.", "4.4 Data Efficiency (RQ3)": "Focusing on few-shot settings, we investigate the data efficiency property by varying the number of shots \ud835\udc41 . In Figure 7, we report the AUC performance of ReLLa and SIM (the best full-shot baseline) with different \ud835\udc41 s. For BookCrossing dataset, \ud835\udc41 ranges in { 128 , 256 , 512 , 1024 , 2048 , 4096 } . For MovieLens-1M and MovieLens25M datasets, \ud835\udc41 ranges in { 512 , 1024 , 2048 , 4096 , 8192 , 65536 } . The length of user behavior sequence \ud835\udc3e is set to \ud835\udc3e = 60 / 30 / 30 for BookCrossing/MovieLens-1M/MovieLens-25M datasets, respectively. As depicted in Figure 7, both ReLLa and SIM attain performance enhancement as the number of shots \ud835\udc41 gradually grows. However, with the same number of shots \ud835\udc41 , ReLLa can outperform SIM significantly and consistently by a large margin. Moreover, when \ud835\udc41 is extremely small ( e.g. , 128 and 256) on BookCrossing dataset, SIM even fails to accomplish the CTR prediction task where AUC is merely around 0.5. With limited number of training samples, ReLLa shows remarkable data efficiency property and display considerable few-shot inference ability due to the intrinsic logical reasoning abilities and possession of open-world knowledge of LLMs.", "4.5 Ablation Study (RQ4)": "To analyze the efficacy of each component in our proposed ReLLa framework, we design the following model variants of ReLLa. We set \ud835\udc41 = 256 / 8192 / 8192 (<1% setting) and \ud835\udc3e = 60 / 30 / 30 for BookCrossing/MovieLens-1M/MovieLens-25M datasets, respectively. \u00b7 ReLLa (Ours) is the complete version of our proposed method. Thetraining data consists of both original and retrieval-enhanced samples, resulting in a mixed training dataset of 2 \ud835\udc41 samples. The testing set only contains pure retrieval-enhanced samples. \u00b7 ReLLa (w/o Mixture) . We only maintain the retrieval-enhanced data instances to construct the training dataset of \ud835\udc41 samples. The testing data is still all retrieval-enhanced samples. \u00b7 ReLLa (w/o Retrieval) . We remove the semantic user behavior retrieval for both training and testing samples. That is, training and testing data are all original samples without retrieval enhancements. The training set contains \ud835\udc41 training samples. This variant indicates the vanilla instruction tuning version over Vicuna-13B, which is similar to TALLRec [3]. \u00b7 ReLLa ( 1 2 \ud835\udc41 -shot) . We halve the number of shots \ud835\udc41 to 1 2 \ud835\udc41 , i.e. , from 256 to 128 on BookCrossing and from 8192 to 4096 on MovieLens-1M and MovieLens-25M. Therefore, the constructed mixed training set contains \ud835\udc41 training samples. This variant is intended to decouple and investigate the factors of doubled training samples and pattern enrichment. \u00b7 ReLLa (w/o IT) . We remove the instruction tuning, while preserving the retrieval-enhanced samples for testing data. This variant indicates the zero-shot version of our proposed ReLLa. \u00b7 ReLLa (w/o IT & Retrieval) . We remove both the instruction tuning and retrieval operation. Therefore, the testing data only contains original data samples. This variant indicates the zeroshot version of vanilla Vicuna-13B. The performance of these variants are presented in Table 3, from which we can draw the following observations: \u00b7 For ReLLa (w/o Mixture) and ReLLa (w/o Retrieval), their training and testing data comprise exactly the same type of samples, i.e. , either pure original samples or retrieval-enhanced samples respectively, which indicates that there is no data inconsistency between the training and testing phases. Nevertheless, both of them significantly underperform our proposed ReLLa by at least 1.12%, 0.99% and 1.95% on BookCrossing, MovieLens-1M and MovieLens-25M in AUC respectively. This highlights the importance of the data mixture strategy, the benefits of which can be broken down into two prominent factors: doubled training samples and pattern enrichment. Doubled training samples lead to a more thorough training process, while pattern enrichment can prevent the model from overfitting and therefore increase the model robustness. \u00b7 We introduce the variant ReLLa ( 1 2 \ud835\udc41 -shot) to further decouple and analyze the two factors mentioned above, i.e. , doubled training samples and pattern enrichment. Its total number of training samples is the same as those of ReLLa (w/o Mixture) and ReLLa (w/o Retrieval), except that ReLLa ( 1 2 \ud835\udc41 -shot) loses the sight of half truly training instances. In this case, ReLLa ( 1 2 \ud835\udc41 -shot) still outperforms ReLLa (w/o Mixture) and ReLLa (w/o Retrieval) with 0.21%, 0.16% and 0.48% relative AUC improvement, and achieves comparable or better performance in Log Loss and ACC. This indicates that pattern enrichment as regularization plays a more vital role that contributes to the performance improvement. \u00b7 Finally, comparing ReLLa (w/o IT) and ReLLa (w/o IT & Retrieval), which fall back into zero-shot settings, we can observe Kick-Ass 2 I r on Man 3 Thor: The Dark World Captain America Warrior Roman Holiday Vicuna-13B (Zero-shot) ReLLa (Zero-shot) ReLLa (few-shot) SUBR ReiT OR Thor: Ragnarok Target User Target Moive Attention Scores over User Behvaior Sequence that ReLLa (w/o IT) generally achieves significant improvements over ReLLa (w/o IT & Retrieval), except for the AUC metric on MovieLens-25M. This demonstrates that semantic user behavior retrieval (SUBR) improves the quality of data samples and makes the filtered behavior sequence more friendly for LLM to extract useful knowledge.", "4.6 Case Study (RQ5)": "In this section, we conduct case study to further analyze how can ReLLa help LLM better understand the long user behavior sequence. As shown in Figure 8, we select a testing sample from MovieLens25M dataset, and visualize the attention scores of target item over the user behavior sequence at the last hidden layer of three different models ( i.e. , Vicuna-13B, ReLLa (zero-shot), and ReLLa (few-shot)). The attention score for each historical item is computed by summing up the attention scores of every word token for the textual input of the corresponding item. In Figure 8, each historical item is represented as a rectangle with color ranging from yellow to green. The deeper green a rectangle possesses, the large attention score the corresponding historical item attains, thus contributing more to the final CTR estimation. For Vicuna-13B (zero-shot), the largest attentions fall on the movie Roman Holiday and Warrior , which have little relationship with the target movie Thor: Ragnarok , and thus the model fails to correctly infer the user's preference towards the target item. Equipped with semantic user behavior retrieval (SUBR), we can reduce the noise of user behavior sequence and bring in more relevant items. As shown in Figure 8, ReLLa (zero-shot) is able to put more attentions to superhero movies ( e.g. , Iron Man 3 ) that are semantically similar to the target item. However there are still outliers for ReLLa (zero-shot), e.g. , the movie Kick-Ass 2 is generally non-correlated to Thor: Ragnarok produced the Marvel. Next, by further applying retrieval-enhanced instruction tuning (ReiT), we can observe that the large attention weights of ReLLa (few-shot) all fall onto relevant superhero movies that are also produced by the Marvel. Therefore, we can conclude that our proposed SUBR and ReiT can help LLM to correctly grasp the correlation between the target item and historical items, thus better comprehending the user behavior sequence.", "5 RELATED WORK": "", "5.1 Traditional CTR Prediction": "CTR prediction serves as the key component for various online applications ( e.g. , recommender systems [84], advertising [59], and web search [17, 21, 47]). It aims to accurately estimate the user's click probability towards a certain target item in a given context [94]. Traditional CTR prediction models can be mainly classified into two categories: (1) feature interaction based models, and (2) sequential recommendation models. The feature interaction based models generally derive from POLY2 [8] and FM [72]. Their core idea is to capture the secondor high-order feature interaction patterns across multiple feature fields with different operators ( e.g. , product [9, 25, 66, 82], convolution [49, 87], and attention [74, 86]). For examples, DCN [81], xDeepFM [45], and DCNv2 [82] apply product-based feature crossing operation at each layer for explicit high-order feature interaction modeling. AutoInt [74] and InterHAt [44] adopt the attention mechanism for feature interactions, which provides additional explainable prediction via attention weights. The sequential recommendation model [61, 98, 99] focuses on user behavior modeling and seeks to dynamically capture users' interests towards a target item according to the given behavior history. They leverage different architectures ( e.g. , RNN [26, 27], CNN [76], attention [98, 99], memory bank [61, 71]) to handle the user behavior sequence for user preference modeling. For instances, GRU4Rec [27] adopt the gated recurrent unit (GRU) [14] to encode the user's sequential behaviors. Caser [76] introduces the convolution neural network (CNN) to model the union-level patterns among user behavior sequences.", "5.2 Language Models for Recommendation": "As suggested in previous work [46], the adaption of language models to the field of recommender systems can be generally categorized according to the roles they serve in the recommendation pipeline, i.e. , feature engineering [5, 7, 13, 39, 52, 57], feature encoder [20, 28, 29, 41, 56, 65, 78, 88, 89, 95], scoring/ranking function [3, 10, 24, 30, 32, 33, 36, 40, 43, 50, 54, 60, 79, 91, 96, 97]. For feature engineering, large language models (LLMs) accept the raw data ( e.g. , user profiles and item descriptions) as input, and generate supplementary text-based attributes as data augmentations with delicately designed prompts and templates. For example, KAR [85] utilizes the reasoning knowledge on user preferences and the factual knowledge on items by requesting LLMs with factorization prompting techniques. The obtained knowledge can serve as augmented features and promote the recommendation performance in a model-agnostic manner. GENRE [52] employs LLMs to obtain news summarization, synthetic news pieces, and user profiles. For feature encoder, LLMs are adopted as auxiliary textual feature encoders to (1) enrich the user/item representations with semantic information, and (2) enable cross-domain recommendation with the natural language interface. For instance, U-BERT [65] enhances the user representation by encoding review texts into dense vectors via BERT. UniSRec [29] and VQ-Rec [28] apply a fixed BERT as the encoder for item descriptive texts, in order to achieve unified cross-domain sequential recommendation. For scoring/ranking function, researchers explore the potential of LLMs to directly serve as the core scoring or ranking module for recommendation, instead of an assistant role for conventional recommendation models ( e.g. , feature engineering or feature encoder). In this case, LLMs are employed to accomplish either the item scoring task [3, 36, 40, 43, 50, 54, 96, 97], or item generation task [10, 24, 30, 32, 33, 60, 79, 91]. Also, various works [15, 16, 23, 51, 75, 92] attempt to utilize the multi-task capacity of LLMs, and instruct LLMs to solve the multiple tasks ( e.g. , both scoring and generation) through a unified language interface. In this paper, we mainly focus on the utilization of LLMs as the scoring/ranking functions, where the pointwise scoring task is adopted for CTR prediction. To the best of our knowledge, we are the first to identify and well formulate the incomprehension problem of LLMs on lifelong user behavior sequences when adopting LLMs for scoring and ranking tasks. A novel ReLLa framework is proposed to mitigate such an issue by introducing the retrieval techniques to promote comprehension ability of LLMs and thus enhance their recommendation performance.", "6 CONCLUSION": "In this paper, we focus on adapting and empowering LLMs as the scoring/ranking function for recommendation tasks. We first identify and formulate the incomprehension problem of LLMs on lifelong sequential behaviors, i.e. , LLMs fail to extract useful information from a textual context of long user behavior sequence, even if the length of context is far from reaching the context limitation of LLMs. Hence, we propose a novel ReLLa framework, where semantic user behavior retrieval (SUBR) and retrieval-enhanced instruction tuning (ReiT) are designed to address such an issue and therefore promote the recommendation performance. Extensive experiments validate the effectiveness of our proposed ReLLa compared with existing baselines. Specifically, leveraging only less than 10% training samples, few-shot ReLLa can outperform all the fullshot traditional CTR models that are trained on the entire training set. This demonstrate the superior data efficiency of ReLLa, as well as its comprehension ability towards long user behavior sequences.", "ACKNOWLEDGMENTS": "The Shanghai Jiao Tong University team is partially supported by National Key R&D Program of China (2022ZD0114804), Shanghai Municipal Science and Technology Major Project (2021SHZDZX0102) and National Natural Science Foundation of China (62177033, 62322603). The work is sponsored by Huawei Innovation Research Program. We thank MindSpore [1] for the partial support of this work, which is a new deep learning computing framework.", "REFERENCES": "[1] 2020. MindSpore. https://www.mindspore.cn/ [2] Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, M\u00e9rouane Debbah, \u00c9tienne Goffinet, Daniel Hesslow, Julien Launay, Quentin Malartic, et al. 2023. The falcon series of open language models. arXiv preprint arXiv:2311.16867 (2023). [3] Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023. Tallrec: An effective and efficient tuning framework to align large language model with recommendation. arXiv preprint arXiv:2305.00447 (2023). [4] David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin A Raffel. 2019. Mixmatch: A holistic approach to semi-supervised learning. Advances in neural information processing systems 32 (2019). [5] Vadim Borisov, Kathrin Se\u00dfler, Tobias Leemann, Martin Pawelczyk, and Gjergji Kasneci. 2022. Language models are realistic tabular data generators. arXiv preprint arXiv:2210.06280 (2022). [6] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901. [7] Aldo Gael Carranza, Rezsa Farahani, Natalia Ponomareva, Alex Kurakin, Matthew Jagielski, and Milad Nasr. 2023. Privacy-Preserving Recommender Systems with Synthetic Query Generation using Differentially Private Large Language Models. arXiv preprint arXiv:2305.05973 (2023). [8] Yin-Wen Chang, Cho-Jui Hsieh, Kai-Wei Chang, Michael Ringgaard, and Chih-Jen Lin. 2010. Training and testing low-degree polynomial data mappings via linear SVM. Journal of Machine Learning Research 11, 4 (2010). [9] Bo Chen, Yichao Wang, Zhirong Liu, Ruiming Tang, Wei Guo, Hongkun Zheng, Weiwei Yao, Muyu Zhang, and Xiuqiang He. 2021. Enhancing explicit and implicit feature interactions via information sharing for parallel deep ctr models. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management . 3757-3766. [10] Zheng Chen. 2023. PALR: Personalization Aware LLMs for Recommendation. arXiv preprint arXiv:2305.07622 (2023). [11] Zhenyi Lu Chenghao Fan and Jie Tian. 2023. Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model. https://github.com/Facico/ChineseVicuna [12] Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. 2023. Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality. https://lmsys.org/blog/2023-03-30-vicuna/ [13] Konstantina Christakopoulou, Alberto Lalama, Cj Adams, Iris Qu, Yifat Amir, Samer Chucri, Pierce Vollucci, Fabio Soldo, Dina Bseiso, Sarah Scodel, et al. 2023. Large Language Models for User Interest Journeys. arXiv preprint arXiv:2305.15498 (2023). [14] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555 (2014). [15] Zeyu Cui, Jianxin Ma, Chang Zhou, Jingren Zhou, and Hongxia Yang. 2022. M6-rec: Generative pretrained language models are open-ended recommender systems. arXiv preprint arXiv:2205.08084 (2022). [16] Sunhao Dai, Ninglu Shao, Haiyuan Zhao, Weijie Yu, Zihua Si, Chen Xu, Zhongxiang Sun, Xiao Zhang, and Jun Xu. 2023. Uncovering ChatGPT's Capabilities in Recommender Systems. arXiv preprint arXiv:2305.02182 (2023). [17] Xinyi Dai, Jianghao Lin, Weinan Zhang, Shuai Li, Weiwen Liu, Ruiming Tang, Xiuqiang He, Jianye Hao, Jun Wang, and Yong Yu. 2021. An adversarial imitation 16th international conference on data mining (ICDM) . IEEE, 1149-1154. [67] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research 21, 1 (2020), 5485-5551. [68] Shashank Rajput, Nikhil Mehta, Anima Singh, Raghunandan H Keshavan, Trung Vu, Lukasz Heldt, Lichan Hong, Yi Tay, Vinh Q Tran, Jonah Samost, et al. 2023. Recommender Systems with Generative Retrieval. arXiv preprint arXiv:2305.05065 (2023). [69] Vinay Venkatesh Ramasesh, Aitor Lewkowycz, and Ethan Dyer. 2021. Effect of scale on catastrophic forgetting in neural networks. In International Conference on Learning Representations . [70] Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint arXiv:1908.10084 (2019). [71] Kan Ren, Jiarui Qin, Yuchen Fang, Weinan Zhang, Lei Zheng, Weijie Bian, Guorui Zhou, Jian Xu, Yong Yu, Xiaoqiang Zhu, et al. 2019. Lifelong Sequential Modeling with Personalized Memorization for User Response Prediction. SIGIR . [72] Steffen Rendle. 2010. Factorization machines. In ICDM . [73] Jonathon Shlens. 2014. A tutorial on principal component analysis. arXiv preprint arXiv:1404.1100 (2014). [74] Weiping Song, Chence Shi, Zhiping Xiao, Zhijian Duan, Yewen Xu, Ming Zhang, and Jian Tang. 2019. Autoint: Automatic feature interaction learning via selfattentive neural networks. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management . 1161-1170. [75] Weiwei Sun, Lingyong Yan, Xinyu Ma, Pengjie Ren, Dawei Yin, and Zhaochun Ren. 2023. Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent. arXiv preprint arXiv:2304.09542 (2023). [76] Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation via convolutional sequence embedding. In Proceedings of the eleventh ACM international conference on web search and data mining . 565-573. [77] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023). [78] Jie Wang, Fajie Yuan, Mingyue Cheng, Joemon M Jose, Chenyun Yu, Beibei Kong, Xiangnan He, Zhijin Wang, Bo Hu, and Zang Li. 2022. TransRec: Learning Transferable Recommendation from Mixture-of-Modality Feedback. arXiv preprint arXiv:2206.06190 (2022). [79] Lei Wang and Ee-Peng Lim. 2023. Zero-Shot Next-Item Recommendation using Large Pretrained Language Models. arXiv preprint arXiv:2304.03153 (2023). [80] Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. 2022. Text embeddings by weakly-supervised contrastive pre-training. arXiv preprint arXiv:2212.03533 (2022). [81] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep & cross network for ad click predictions. In Proceedings of the ADKDD'17 . 1-7. [82] Ruoxi Wang, Rakesh Shivanna, Derek Cheng, Sagar Jain, Dong Lin, Lichan Hong, and Ed Chi. 2021. Dcn v2: Improved deep & cross network and practical lessons for web-scale learning to rank systems. In Proceedings of the Web Conference 2021 . 1785-1797. [83] Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang. 2023. Recmind: Large language model powered agent for recommendation. arXiv preprint arXiv:2308.14296 (2023). [84] Yunjia Xi, Jianghao Lin, Weiwen Liu, Xinyi Dai, Weinan Zhang, Rui Zhang, Ruiming Tang, and Yong Yu. 2023. A Bird's-eye View of Reranking: from List Level to Page Level. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining . 1075-1083. [85] Yunjia Xi, Weiwen Liu, Jianghao Lin, Jieming Zhu, Bo Chen, Ruiming Tang, Weinan Zhang, Rui Zhang, and Yong Yu. 2023. Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models. arXiv preprint arXiv:2306.10933 (2023). [86] Jun Xiao, Hao Ye, Xiangnan He, Hanwang Zhang, Fei Wu, and Tat-Seng Chua. 2017. Attentional factorization machines: learning the weight of feature interactions via attention networks. In Proceedings of the 26th International Joint Conference on Artificial Intelligence . 3119-3125. [87] Xin Xin, Bo Chen, Xiangnan He, Dong Wang, Yue Ding, and Joemon M Jose. 2019. CFM: Convolutional Factorization Machines for Context-Aware Recommendation.. In IJCAI , Vol. 19. 3926-3932. [88] Yang Yu, Fangzhao Wu, Chuhan Wu, Jingwei Yi, and Qi Liu. 2021. Tinynewsrec: Effective and efficient plm-based news recommendation. arXiv preprint arXiv:2112.00944 (2021). [89] Zheng Yuan, Fajie Yuan, Yu Song, Youhua Li, Junchen Fu, Fei Yang, Yunzhu Pan, and Yongxin Ni. 2023. Where to go next for recommender systems? id-vs. modality-based recommender models revisited. arXiv preprint arXiv:2303.13835 (2023). [90] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. 2017. mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412 (2017). [91] Jizhi Zhang, Keqin Bao, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023. Is chatgpt fair for recommendation? evaluating fairness in large language model recommendation. arXiv preprint arXiv:2305.07609 (2023). [92] Junjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. 2023. Recommendation as instruction following: A large language model empowered recommendation approach. arXiv preprint arXiv:2305.07001 (2023). [93] Kai Zhang, Fubang Zhao, Yangyang Kang, and Xiaozhong Liu. 2023. Memoryaugmented llm personalization with short-and long-term memory coordination. arXiv preprint arXiv:2309.11696 (2023). [94] Weinan Zhang, Jiarui Qin, Wei Guo, Ruiming Tang, and Xiuqiang He. 2021. Deep learning for click-through rate estimation. IJCAI (2021). [95] Xinyang Zhang, Yury Malkov, Omar Florez, Serim Park, Brian McWilliams, Jiawei Han, and Ahmed El-Kishky. 2022. TwHIN-BERT: a socially-enriched pretrained language model for multilingual Tweet representations. arXiv preprint arXiv:2209.07562 (2022). [96] Yuhui Zhang, Hao Ding, Zeren Shui, Yifei Ma, James Zou, Anoop Deoras, and Hao Wang. 2021. Language models as recommender systems: Evaluations and limitations. (2021). [97] Zizhuo Zhang and Bang Wang. 2023. Prompt learning for news recommendation. arXiv preprint arXiv:2304.05263 (2023). [98] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Deep interest evolution network for click-through rate prediction. In AAAI , Vol. 33. 5941-5948. [99] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1059-1068.", "A PROMPT ILLUSTRATION": "We demonstrate several examples to illustrate the hard prompt templates used for ReLLa on all three datasets. Figure 9 shows the textual input-output pairs without semantic user behavior retrieval (SUBR), where the user behavior sequence is truncated to most recent \ud835\udc3e ( e.g. , \ud835\udc3e = 4 in the figure). As is shown in Figure 10, after applying SUBR, the user behavior sequence will be replaced by most relevant \ud835\udc3e historical items towards the target item. For example, for MovieLens-25M dataset, historical behaviors retrieved by SUBR are all related to superheros or Marvel, which is highly correlated to the target movie 'Thor: Ragnaro'. Note that the user behavior sequence generated by SUBR keeps the chronological order in the original lifelong user sequence. Figure 4 demonstrates how we design prompts for item descriptions on the three datasets, which will be encoded by LLM for semantic user behavior retrieval (SUBR).", "B DATA PREPROCESSING": "Our experiments are conducted on three real-world public datasets ( i.e. , BookCrossing, MovieLens-1M and MovieLens-25M), and the statistics of the processed datasets are show in Table 1. MovieLens1M and MovieLens-25M datasets are split into training and testing sets with ratio of 8:1 according to the global timestamp [63]. Since BookCrossing dataset has no timestamps, following previous work [3], we divide it into training and testing sets with ratio of 9:1 by random split of users. Data samples with user behavior sequence length less than 5 are filtered on all three datasets. We describe more preprocessing details as follows: \u00b7 BookCrossing possesses user-book integer ratings ranging from 0 to 10. We consider samples with rating above 5 as positive, and the rest as negative. \u00b7 MovieLens-1M contains user-movie integer ratings ranging from 0 to 5. Samples with ratings of 4 and 5 are labeled as positive and the rest as negative. [85, 99]", "BookCrossing": "Here is a book. Its title is Jane Eyre. ISBN of the book is 0451523126. The author of the book is Charlotte. The publication year of the book is 1988. Its publisher is Signet Classics.", "I nput:": "The user watched the following movies in the past, and rated them: ['0. I ron Man 3 (2013) (4.0 stars)', '1. Avengers: Age of Ultron (2015) (4.5 stars)', '2. Thor (2011) (4.0 stars)', '3. Thor: The Dark World (2013) (4.0 stars)'] Based on the movies the user has watched, deduce if the user will like the movie ***Thor: Ragnarok (2017)***. Note that more stars the user rated the movie, the user liked the movie more. You should ONLY tell me yes or no. Output: Yes. Figure 10: Examples of hard prompt templates for three datasets with SUBR. The user behavior sequence is constructed by the most relevant \ud835\udc3e items.", "MovieLens-1M": "Here is a movie. Its title is Aliens (1986). The movie's genre is Fiction.", "C BASELINE IMPLEMENTATION": "In this section, we describe the hyperparameter configuration for the baseline models from two different categories: (1) traditional CTR models, and (2) LM-based models.", "C.1 Traditional CTR Models": "We choose the embedding size from {8, 16, 32} on BookCrossing dataset and {32, 64} on MovieLens-1M and MovieLens-25M datasets. The dropout rate is selected from {0.0, 0.1, 0.2}. The activation function is fixed to ReLU. The learning rate is set to 1 \u00d7 10 -3 and AdamW [53] optimizer is used. On BookCrossing, the batch size is selected from {32, 64}. On MovieLens-1M and MovieLens25M, the batch size is selected from {256, 512}. More model-specific hyperparameter settings are shown as follows:", "C.2 LM-based Models": "The structure of the pretrained language models is kept unchanged. AndAdamW[53]optimizeris used for all the baselines. The detailed training settings are as follows: \u00b7 CTR-BERT [55]. We maintain a two-tower model structure based on the BERT [18] model to encode the user and item information respectively. The total number of tuning epochs is set to 10. The batch size is set to 1024. The learning rate is set to 5 \u00d7 10 -5 with linear decay. The warmup ratio is 0.05. \u00b7 P5 [22] is a unified sequence-to-sequence framework with T5 [67] as the backbone pretrained language model for multiple recommendation tasks. In this paper, we leverage P5 for a single task only ( i.e. , CTR prediction). The total number of epochs is set to 10 with batch size of 32. The learning rate is selected from { 5 \u00d7 10 -4 , 1 \u00d7 10 -3 } with linear decay. The warmup ratio is 0.05. Following P5's official implementation, we also perform gradient clip with threshold equal to 1.0. \u00b7 PTab [50] adopts the common pretrain-finetune scheme based on the BERT [18] model. PTab first further pretrains the BERT model with the classical masked language modeling objective based on the textualized CTR data, and then finetunes BERT for downstream CTR prediction as a text classification problem. Following the original paper, we pretrain BERT for 10 epochs with batch size equal to 1024. The learning rate for pretraining is set to 5 \u00d7 10 -5 with linear decay. The warmup ratio is 0.05. As for finetuning, the total number of tuning epoch is set to 10 with batch size of 1024. The learning rate for finetuning is initialized at 5 \u00d7 10 -5 with linear decay. The warmup ratio is 0.01.", "D ADDITIONAL EXPERIMENTS": "In this section, we further provide additional experiments to verify the following core points: \u00b7 The universality of the lifelong sequential behavior incomprehension problem and the generalization of our proposed ReLLa. \u00b7 Analysis about the model parameter and inference time. \u00b7 Ablation on PCA dimensionality and distance metrics for SUBR. \u00b7 Analysis and discussion about the potential reason for the incomprehension problem.", "D.1 Universality & Generalization": "We validate the universality of the lifelong sequential behavior incomprehension problem and he generalization of our proposed ReLLa, by incorporating different backbone LLMs of different architectures and sizes including Falcon-7B [2] 7 , Mistral-7B [34] 8 , Vicuna-7B [12] 9 , Vicuna-13B [12] 10 , LLaMA-2-70B-Chat [77] 11 . D.1.1 Universality of the Incomprehension Problem. We first analyze the universality of lifelong sequential behavior incomprehension problem for different LLMs on MovieLens-1M dataset. We report the zero-shot AUC performance of different LLMs w.r.t. different length \ud835\udc3e of user behavior sequence ranging from {5, 10, 15, 20, 25, 30}. It is worth noting that we downsample the test set to 10,000 for LLaMA2-70B-chat due to the time consumption, while the other four LLMs are still tested on the whole test set. The results are given in Table 4. We can observe that the length of user sequence at which a peaking performance is reached is small and far from reaching the context limit for all the five LLMs. Therefore, we validate the universality of lifelong sequential behavior incomprehension problem when adapting LLMs to recommendation domains. Besides, there exists performance difference among different LLMs, which may be related to the inherent instruction-following capabilities of LLMs themselves. D.1.2 Generalization of ReLLa. We further investigate the generalization of our proposed ReLLa in terms of different backbone LLMs ( i.e. , model compatibility). We apply semantic user behavior retrieval (SUBR) and retrieval-enhanced instruction tuning (ReiT) on four LLMs, excluding LLaMA-2-70B-Chat due to the computational resource constraint. The finetuning configuration is set as the same as our previous experiment on Vicuna-13B. We set the length of user sequence to 30. Few-shot settings <1% and <10% indicate 8,192 and 65,536 training samples, respectively. We also provide the performance of the best baseline model (i.e., SIM) for both full-shot and few-shot settings. We report the results in Table 5, from which we have the following observations and discussions: \u00b7 Compared with the original LLMs, ReLLa can improve the recommendation performance in both zero-shot and few-shot settings consistently and significantly. \u00b7 Mistral-7B, Vicuna-7B and Vicuna-13B with ReiT (<10%) settings are able to significantly outperform full-shot SIM that is trained on the whole training set, which demonstrates the surprisingly high data efficiency property of ReLLa. \u00b7 Although Falcon-7B with ReiT (<10%) setting obtains much better performance than SIM under the same few-shot setting (<10%), it fails to defeat full-shot SIM as other three LLMs do. We think the main reasons are in two folds: \u00b7 While the peaking performance arrives with \ud835\udc3e =5 or 15 for zeroshot LLMs, the four LLMs gain much better recommendation performance with larger \ud835\udc3e =30 when equipped with ReLLa. Hence, we validate the generalization of ReLLa to address the user sequence incomprehension problem and improve the recommendation performance.", "D.2 Model Parameter & Inference Time": "We provide the complexity analysis on MovieLens-1M dataset by reporting the number of total parameters, the number of trainable parameters, and the averaged inference time per batch for both ReLLa and SIM (the best traditional recommendation baseline). We choose Vicuna-13B as the backbone LLM for ReLLa. The evaluation batch size is set to 512 and 4 for SIM and ReLLa, respectively. The run-time experiment is exclusively conducted on the same server with one GeForce RTX 4090 GPU. We report the results in Table 6. Although ReLLa achieves remarkable success on sequential recommendation in terms of both performance and sample efficiency, we have to admit that the inference speed is slower compared with traditional recommendation models. Hence, ReLLa is currently suitable for real-world applications with a high tolerance for latency, such as conversational search or conversational recommendation. Note that this computational limitation inherently stems from the large-scale property of LLMs. It is not unique to ReLLa but rather a common issue that our research community of LLM for recommendation should make joint efforts to overcome.", "D.3 Ablation on PCA & Distance Metric": "We conduct ablation study to investigate the impact of PCA dimensionality and distance metrics for SUBR, respectively. We choose Vicuna-13B as the backbone LLM for ReLLa. D.3.1 Impact of PCA Dimensionality. To offer a deeper insight into the impact of PCA dimensionality, we evaluate the performance of ReLLa w.r.t. different PCA dimensionalities on MovieLens-1M dataset under both zero-shot and few-shot (8192-shot, <1%) settings. The results are reported in Table 7. We can observe that PCA dimensionality 512 generally achieves the best performance. The dimension reduction brought by PCA also means a kind of semantic information loss. Hence, the smaller the dimensionality, the worse ReLLa performs. While dimensionality larger than 512 might lead to heavy cost of storage and computing, we consider 512 as a reasonable choice of PCA dimensionality to balance the performance and storage/computing cost. D.3.2 Impact of Distance Metric. We empirically choose the cosine distance as the default choice for ReLLa to measure the semantic relevance, as it has been widely used to evaluate textual similarity in the realm of natural language processing (NLP) [58, 70, 80]. To offer a deeper insight, we compare three different distance metrics: (1) cosine distance, (2) L2 distance, and (3) L1 distance. We report the performance of ReLLa w.r.t. different distance metrics in both zero-shot and few-shot (<1%) settings on MovieLens-1M dataset. The results are given in Table 8. We have the following discussions: \u00b7 Cosine similarity inherently normalizes the vectors. It focuses on the angular difference between vectors rather than their magnitude. This means that even if two vectors differ greatly in size, they can still have a high cosine similarity if they point in similar directions. \u00b7 In high-dimensional spaces, L1 and L2 distances tend to suffer from the \"curse of dimensionality\", where the distance between all points becomes similar as dimensions increase. This makes these distances less effective measures of similarity in high dimensions. Cosine similarity is not affected by this issue and therefore remains effective in high-dimensional spaces.", "D.4 Potential Reason for Incomprehension": "We give our in-depth analysis and conjecture about the potential reason for the incomprehension problem of LLMs in recommendation. We argue that the incomprehension problem arises from the fact that LLMs struggle to comprehend highly heterogeneous user behavior sequences and thus fail to extract meaningful information from them. The heterogeneity of a sequence can be defined as the diversity of user behaviors within that sequence, such as different item genres. The longer the user's behavior sequence, the higher the probability of it exhibiting a high level of heterogeneity, and consequently, the greater the difficulty for LLMs to comprehend. Based on the conjecture above, retrieval, as the core technique for ReLLa, is essentially a means of homogenizing the user sequence. It aggregates homogeneous behaviors that are similar to the target item into a certain sequence and removes those unrelated heterogeneous behaviors, thus improving the comprehension capability of LLMs for long user sequences. We provide an empirical study on MovieLens-1M dataset to demonstrate the homogenizing effect of retrieval. Here, we define the heterogeneity score as the number of unique movie genres in a given sequence of behaviors (i.e., movies). We illustrate two examples as follows: \u00b7 [ Fiction, Comedy, Comedy, Family ] \u2192 heterogeneity score=3 \u00b7 [ Fiction, Fiction, Child, Fiction ] \u2192 heterogeneity score=2 In Table 9, we report the averaged heterogeneity score of two sequence types w.r.t. different length \ud835\udc3e : (1) the sequence is constructed by top-recent behaviors. (2) the sequence consists of toprelevant behaviors generated by our proposed semantic user behavior retrieval (SUBR). From Table 9, we give the following discussions: \u00b7 We can see that the heterogeneity score gradually increases as the length \ud835\udc3e grows. We argue that LLMs might fail to comprehend the given sequence once the heterogeneity score exceeds a certain threshold, and therefore we observe the phenomenon that the performance of LLM only peaks at around \ud835\udc3e =15 as illustrated in Figure 1. \u00b7 When equipped with our proposed SUBR, the heterogeneity score of top-relevant sequences largely decreases compared with the top-recent sequences. The lower the heterogeneity level of the sequence, the easier it is for LLMs to comprehend, and consequently, the better performance ReLLa can achieve with a larger \ud835\udc3e ."}
