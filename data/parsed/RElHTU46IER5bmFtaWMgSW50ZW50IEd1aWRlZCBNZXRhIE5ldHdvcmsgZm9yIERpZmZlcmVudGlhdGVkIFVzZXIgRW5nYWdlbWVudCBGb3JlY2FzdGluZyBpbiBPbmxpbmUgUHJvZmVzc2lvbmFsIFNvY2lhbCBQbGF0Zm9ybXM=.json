{
  "DIGMN: Dynamic Intent Guided Meta Network for Differentiated User Engagement Forecasting in Online Professional Social Platforms": "Feifan Li ∗ feifan@mail.dlut.edu.cn Dalian University of Technology Qiang Fu qifu@microsoft.com Microsoft Research Shi Han shihan@microsoft.com Microsoft Research Lun Du † lun.du@microsoft.com Microsoft Research Yushu Du yusdu@linkedin.com LinkedIn Corporation",
  "Zi Li": "zili@linkedin.com LinkedIn Corporation",
  "ABSTRACT": "User engagement prediction plays a critical role in designing interaction strategies to grow user engagement and increase revenue in online social platforms. Through the in-depth analysis of the real-world data from the world's largest professional social platforms, i.e., LinkedIn, we find that users expose diverse engagement patterns, and a major reason for the differences in user engagement patterns is that users have different intents. That is, people have different intents when using LinkedIn, e.g., applying for jobs, building connections, or checking notifications, which shows quite different engagement patterns. Meanwhile, user intents and the corresponding engagement patterns may change over time. Although such pattern differences and dynamics are essential for user engagement prediction, differentiating user engagement patterns based on user dynamic intents for better user engagement forecasting has not received enough attention in previous works. In this paper, we proposed a D ynamic I ntent G uided M eta N etwork (DIGMN), which can explicitly model user intent varying with time and perform differentiated user engagement forecasting. Specifically, we derive some interpretable basic user intents as prior knowledge from data mining and introduce prior intents to explicitly model dynamic user intent. Furthermore, based on the dynamic user intent representations, we propose a meta-predictor to perform differentiated user engagement forecasting. Through a comprehensive evaluation of LinkedIn anonymous user data, our method outperforms stateof-the-art baselines significantly, i.e., 2.96% and 3.48% absolute error reduction, on coarse-grained and fine-grained user engagement ∗ Work done during an internship at LinkedIn. † Corresponding author Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WSDM '23, February 27-March 3, 2023, Singapore, Singapore © 2023 Association for Computing Machinery. ACM ISBN 978-1-4503-9407-9/23/02...$15.00 https://doi.org/10.1145/3539597.3570420 prediction tasks, respectively, demonstrating the effectiveness of our method.",
  "CCS CONCEPTS": "· Information systems → Enterprise applications ; · Computing methodologies → Neural networks ;",
  "KEYWORDS": "User Intent, User Engagement Forecasting, Meta Learning",
  "ACMReference Format:": "Feifan Li, Lun Du, Qiang Fu, Shi Han, Yushu Du, Guangming Lu, and Zi Li. 2023. DIGMN: Dynamic Intent Guided Meta Network for Differentiated User Engagement Forecasting in Online Professional Social Platforms. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (WSDM '23), February 27-March 3, 2023, Singapore, Singapore. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3539597.3570420",
  "1 INTRODUCTION": "Online professional social platforms like LinkedIn have become a significant part of today's lives. People use these platforms to socialize, apply for jobs, read industry news, etc. Maintaining a highlevel user engagement is vital for these platforms, which can lead to more revenue (e.g., more ad exposure). For the purpose of increasing user engagement in the future, these platforms need to formulate appropriate user interaction strategies, such as delivering content that satisfies user intents or interests. Accurate user engagement prediction is one of the core technologies for developing these strategies, which can help the platform conduct user modeling, understand user needs, and provide personalized services. Real-world users often exhibit different behaviors in online social platforms, leading to diverse engagement patterns. Through data mining and analysis in the scenario of LinkedIn, we found that the diversity of user engagement patterns is related to the multiple intents of users using LinkedIn, as shown in Figure 1. For instance, some users intend to look for jobs recently, and they will frequently visit LinkedIn to seek and apply for jobs, increasing their engagement level rapidly in a period. As another example, some users use LinkedIn to view industry news. Their engagement pattern Guangming Lu glu@linkedin.com LinkedIn Corporation WSDM'23, February 27-March 3, 2023, Singapore, Singapore Feifan Li et al. Figure 1: Example of different user engagement patterns with different user intents. Check Notifications Find New Jobs View Industry News Time # sessions ⋯⋯ Day 1 Day 2 Day 3 ⋯ Day 4 Day 1 Day 2 Day 3 ⋯ Day 4 Day 1 Day 2 Day 3 ⋯ Day 4 is usually maintained at a relatively high level because they regularly check the industry news on LinkedIn. These insights suggest that user intents can be signals to differentiate user engagement patterns. However, user intents are usually not directly observable because they exist implicitly in human consciousness. How to extract implicit user intents is a challenging problem. At the same time, the user's intent may change over time. For example, some users initially use LinkedIn to look for jobs, and when they finish looking for jobs, they may use LinkedIn to socialize (e.g., make new connections at a new company). Explicitly modeling dynamic user intent is vital. It can help the platform understand users' recent intents (or interests) and provide users with content that matches their intents to increase user engagement. Recently, there have been many works on user engagement forecasting in social network platforms. [1] firstly groups new users into some clusters and then uses an LSTM-based model to predict user churn rate. [2] constructs a user action graph to characterize and forecast new user engagement. [3] considers user interaction actions and builds a user graph that evolves to predict user engagement. Although engagement patterns vary between users, these works use a model with static parameters for all users to predict their future engagement, which cannot sufficiently model diverse user engagement patterns and perform differentiated user engagement forecasting. Meanwhile, some works show that user intent can impact user engagement. [4] shows that user intent can influence user engagement (e.g., usage time and return time) at Pinterest. [5] demonstrates that user primary intents are associated with how likely the user is to re-engage in activity-tracking applications. On the one hand, these works have limitations in extracting user intent. In [4], the user's intent is obtained through a survey when the app is just opened, which may affect the user's subsequent behaviors [6]. [5] adopts the activity that the user most commonly uses as a proxy for the user's intent. However, the user's intent may be diverse when using applications [7]. On the other hand, these works do not explicitly model changes in user intent over time. To address the above challenges, we first use Latent Dirichlet Allocation (LDA) [8] to perform user intent mining on large-scale session data and identify basic user intents. Then, we propose a Dynamic Intent Guided Meta Network (DIGMN), which can capture the user's dynamic intent and perform differentiated user engagement prediction. Specifically, DIGMN infers multiple user intents during each session based on similarity computation with the basic user intents and captures the variation of user intents over time by the sequence model. Besides, DIGMN contains a prediction network based on meta-learning, which adopts a dynamic intent guided attention mechanism to adjust network parameters by performing a linear combination of basic parameters shared by all users for differentiated user engagement forecasting. Extensive experiments conducted on coarse-grained and fine-grained user engagement forecasting tasks verify the effectiveness of our DIGMN method. The major contributions of this paper can be summarized as follows: · We find that user intent can be beneficial for differentiated user engagement forecasting in online professional social platforms. · We develop a D ynamic I ntent G uided M eta N etwork (DIGMN) which explicitly model user intent's evolution over time and leverage intent guided attention mechanism to adjust model parameters for differentiated user engagement modeling and forecasting. · Through evaluation experiments on anonymous data from LinkedIn, our proposed model DIGMN has improvements of 2.96% (Macro F1-score) and 3.48% (AUROC) on coarse-grained and fine-grained user engagement prediction tasks when compared to the state-of-the-art model, showing the effectiveness of our proposed method.",
  "2 RELATED WORK": "In this section, we present related work on user engagement forecasting, user intent modeling, and meta-learning for dynamic network parameters. Userengagementforecasting. Recently, there have been many works on user engagement predicting from different perspectives on the social platform. Such as user behaviors and social attributes [1], user action graphs [2], interaction actions between users [3], periodicity of user behaviors [9], and causal effects of social influence [10]. These works learn a model with static parameters for all users to make predictions, which cannot sufficiently model differentiated user engagement patterns. [11] leverages a decision tree model to divide users into disjoint groups and then learns a separate Logistic regression model for each group of users to predict user churn. However, such separate modeling compromises the model's ability to capture similarities between users. [12] adopts the matrix factorization to predict the personalized user's participation in mobile video. However, our scenario has a large amount of user behavior sequence data. This method can not effectively deal with the user's behavior sequence and its change over time. User intent modeling. Some previous works exploit LDA [2, 13, 14], n-gram [2, 15] and deep learning model [16, 17] to mine user intent from user behavior. At the same time, modeling user intents can help us understand user needs better and is significant in many scenarios: for instance, web searching [18, 19], e-commerce application [4], image sharing social platform [20], activity tracking application [5] and recommender systems [21-25]. However, to our best knowledge, no related work has explicitly modeled user intent and its variation for differentiated user engagement forecasting in online social platforms. Meta-learning for dynamic network parameters. Meta-learning (also known as learning to learn) can be used to learn dynamic model parameters, which is widely used in scenarios and tasks with DIGMN WSDM'23, February 27-March 3, 2023, Singapore, Singapore diverse data distributions. There are usually two ways to learn dynamic model parameters [26]: dynamically generate model parameters or dynamically adjust model parameters. For dynamically generating model parameters: [27] utilizes a meta-knowledge learner to generate model parameters for modeling diverse spatial-temporal correlations in urban traffic prediction. [28] adopts a meta-network to learn a personalized mapping function for each user in the crossdomain recommendation. [29], [30] and [31] adopt meta networks to generate dynamic parameters of scenario-specific models for CTR prediction. For dynamically adjusting model parameters: [32] incorporates meta-information learned from a supplementary neural network into a fixed base-level neural network to realize the generalization for each type of input image. [33], [34], and [35], in the light of different input images, use a separate network to learn different weights for adjusting the parameters of convolution kernels, which can obtain dynamic convolution kernels for feature extraction. However, no existing works utilize meta-learning for predicting user engagement with diverse patterns in online social platforms.",
  "3 PRELIMINARY": "In this section, we introduce the relevant definitions and formulate the user engagement forecasting tasks used in this work.",
  "3.1 Basic Definitions": "We define 𝑈 = { 𝑢 1 , 𝑢 2 , ..., 𝑢 𝑁 } as a set of different users and 𝐼 = { 𝑖 1 , 𝑖 2 , ..., 𝑖 𝑀 } as a set of different event types, where 𝑁, 𝑀 are the number of users and event types respectively. User event. The user's behaviors on the platform can be abstracted as events for collection. A user event 𝑒 can be denoted by 𝑒 = ( 𝑢, 𝑖, 𝑡 ) , where 𝑢 ∈ 𝑈 is the user, 𝑖 ∈ 𝐼 is the event type, and 𝑡 is the time when the event happens. We collect ten major event types on the platform, as shown in Table 1. These ten events can completely cover users' activities on the platform. Table 1: Types of user events we collect on the platform. User session. A user session can be viewed as a set of continuous browsing activities with gaps between full-page views not more than a threshold. Formally, a session can be denoted as S = ( 𝑢, c , E) , where 𝑢 ∈ 𝑈 is the user who starts the session, c is the session context information (e.g., the session start time, the session duration time and the software client) and E is the sequence of events that take place during the session. User engagement. User engagement measures how often and how long users interact with the website or application, reflecting how much value users get from the website or application. Different platforms use different metrics to track user engagement. In this paper, we adopt two metrics to measure the engagement of each user on LinkedIn: average active days (coarse-grained, which is the same as the definition of active rate in [2]) and average session numbers (fine-grained). The average session numbers ¯ 𝑠 = # 𝑣𝑎𝑙𝑖𝑑 𝑠𝑒𝑠𝑠𝑖𝑜𝑛𝑠 # 𝑡𝑜𝑡𝑎𝑙 𝑑𝑎𝑦𝑠 , where a valid session is a session that contains at least one event in Table 1. The average active days ¯ 𝑑 = # 𝑎𝑐𝑡𝑖𝑣𝑒 𝑑𝑎𝑦𝑠 # 𝑡𝑜𝑡𝑎𝑙 𝑑𝑎𝑦𝑠 , where an active day is defined as a day that the user has at least one valid session. Platform actions. Previous studies have demonstrated that user engagement on the platform can be increased through notifications [36, 37], incentives including badges [38, 39], etc. Therefore, we need to consider the impact of the interaction actions between the platform and the user when forecasting user engagement. For simplicity, we only consider the platform delivery messages. Formally, a platform delivery message can be denoted as D = ( 𝑢, 𝑤, 𝑟, 𝑡 ) , where 𝑢 ∈ 𝑈 is the user being delivered, 𝑤 is the way the message is delivered (i.e., email, SMS and in-app push), 𝑟 is the content of the delivery message (i.e., Feed relevant, Jobs relevant, PYMK relevant, Message relevant and others), 𝑡 is the delivery time.",
  "3.2 Task Formulation": "In this work, we predict the trend of user engagement instead of directly predicting the future engagement of users because, in actual business scenarios, we pay more attention to the change in user engagement. For example, when designing a platform message delivery strategy in the scenario of user retention, the change value ( Δ 𝑠 or Δ 𝑑 ) of the user engagement caused by the delivered message is an essential indicator of business decisions. Specifically, we define two user engagement trend forecasting tasks as follows: · Day-level Task (coarse-grained) : We predict the trend of the average active days of the user, which can be viewed as a 3-class (i.e., increase, decrease, or stay the same) classification task. · Session-level Task (fine-grained) : We predict the trend of the average session numbers of the user, which can be viewed as a 2class (i.e., decrease or not decrease) classification task. The reason for setting it as a binary classification task is that the number of user sessions has a broader distribution than the number of active days, and users with a large number of sessions are less likely to have the same number of sessions over a while. Based on the above definitions, for any user 𝑢 ∈ 𝑈 , given the user's macroscopic features 𝑴 𝑢 (e.g., the number of connections, the average number of sessions per day in the past period), session sequence 𝑺 𝑢 = < S 1 , S 2 , ..., S 𝑇 > , and the latest platform delivery message 𝑫 𝑢 in the past period, forecasting user engagement trend 𝑦 𝑢 in the next period can be formulated as follows:  where 𝑇 is the number of sessions, 𝑦 𝑢 is the user engagement trend label, and Θ is the parameters we need to learn.",
  "4 INTENT MINING": "In this section, we introduce how to perform user intent mining and show the basic user intents we obtain from data mining. We assume that every user has at least one intent within each session [40]. The user's intents are usually not directly observed WSDM'23, February 27-March 3, 2023, Singapore, Singapore Feifan Li et al. and exist implicitly in the user's consciousness. It is difficult for us to collect a large number of user behavior samples with user intent labels, so using unsupervised methods for user intent mining is a more feasible option. Intuitively, the user's intents influence the user's behaviors, and the user's behaviors constitute the set of events in the session. This process is similar to generating documents with an unsupervised topic model LDA. Like previous work [2], we treat each session as a document and each event type as a word, then apply LDA to mine basic user intents. We use Spark MLlib 1 to perform LDA on approximately 6 million anonymous user session data for intent mining. To determine the optimal number of intents with semantic meaning, we adopt perplexity as the evaluation metric to search for the optimal intent number in { 2 , 3 , 4 , ..., 10 } . When the number of intents equals 7, the LDA model has the least perplexity. These 7 topics can be regarded as 7 basic user intents (denoted as 𝒕 1 , 𝒕 2 , ..., 𝒕 7 ∈ R 10 ), each of which is composed of events with different weights (also can be view as probability) as shown in Figure 2. The meaning of each intent can be explained by the topweight events that make up them. For example, we can find that the two events with top weight making up intent 1 are PYMK and Profile View, indicating that the users want to expand their connections on LinkedIn. Figure 2: Basic user intents. LDA obtains 7 basic intents, and we show the event weights that compose them. Best viewed in color. Notification Search Profile View PYMK Jobs Message Feed Profile Edit Content Share Follow Intent 1 Intent 2 Intent 3 Intent 4 Intent 5 Intent 6 Intent 7",
  "5 DYNAMIC INTENT GUIDED META NETWORK": "In this section, we introduce our proposed model, DIGMN. The framework of our proposed model is illustrated in Figure 3. It consists of three main components: a behavior evolution layer, an intent evolution layer, and a meta-predictor.",
  "5.1 Behavior Evolution Layer": "Users' behaviors change over time, and the length of the behavior sequence of different users may be different. LSTM[41] has been widely used for modeling variable-length user behavioral sequences. In this paper, we utilize a 1-layer LSTM to model user behavior evolution. For each session S , we represent it by concatenating the session context features 𝒄 and session event frequency 𝝂 = ( 𝜈 1 , 𝜈 2 , ..., 𝜈 10 ) ∈ R 10 , where 𝜈 𝑖 is the frequency of event 𝑖 (e.g., if there are 100 events in a session, and the Feed event occurs 10 times, then 𝜈 1 = 1 https://spark.apache.org/mllib/ 10 / 100 = 0 . 1). We take 𝒔 = ( 𝝂 , 𝒄 ) as the input of the session LSTM unit at each timestep. Since the user's behavior sequences are of different lengths, we take the last timestep output of LSTM as the representation of the user's behavior features in the past period.",
  "5.2 Intent Evolution Layer": "A user may have multiple intents during one session. For example, the users can use LinkedIn to view updates on industry news (i.e., intent 3) and share content related to themself (i.e., intent 5) at the same time. We can infer the user's possible intents based on the events happening during this session. In this paper, we exploit a simple and effective way to infer user intent in each session. Given a session's event frequency 𝝂 and the basic user intents 𝒕 1 , 𝒕 2 , ..., 𝒕 7 obtained by LDA in the intent mining stage, we can infer the user intents 𝒊 = ( 𝑖 1 , 𝑖 2 , ..., 𝑖 7 ) during this session. To be specific, 𝑖 𝑘 is the cosine similarity between the session event frequency 𝝂 and the 𝑘 -th basic user intent 𝒕 𝑘 , which measures the degree to which the current session contains the 𝑘 -th intent and can be calculated as follows:  By performing the above intent extraction operation on each user session, we can obtain an intent sequence for each user with the same length as the user session sequence. Another 1-layer LSTM is adopted to model the variation of user intent over time. We take each session's intent representation 𝒊 as the input of the intent LSTM unit at each timestep. We also take the LSTM's last timestep output to represent the user's dynamic intent over the past period.",
  "5.3 Meta-Predictor": "Different users have different engagement patterns, and the user engagement pattern may change in different periods. Previous works [1-3] use a model with the static parameters Θ for different users to predict their future engagement in the social platforms, which can be formulated as 𝒚 = 𝐹 ( 𝒙 , Θ ) , where 𝒙 is the model input (i.e., user features) and 𝒚 is the model output. To make a good prediction, the model tends to capture the common patterns of all users, which is not optimal for modeling and predicting diverse user engagement patterns in real scenarios. The most straightforward idea is to learn a unique predictor for each user or a group of similar users. However, there is a certain similarity between users, while separate modeling may impair the model's ability to capture the similarity between users. Therefore, we need a predictor that can better model the diversity in user engagement patterns while capturing such similarity. Dynamic parameters neural networks have shown promising results in various real-world tasks and can dynamically adjust or generate model parameters Θ ∗ according to different inputs 𝒙 , which have a more powerful representation ability. It can be formulated as 𝒚 = 𝐹 ( 𝒙 , Θ ∗ ) = 𝐹 ( 𝒙 , 𝜙 ( 𝒙 , Θ )) , where 𝜙 (· , Θ ) is the operation that adjusts or generates model parameters according to input 𝒙 . Acommon technique in dynamic parameters neural networks is attention on parameters [33, 34]. It assumes that there are some basic learnable parameters with the same shape in the dynamic parameter layer. Given different inputs, the meta network can generate different attention weights to combine these basic learnable parameters DIGMN WSDM'23, February 27-March 3, 2023, Singapore, Singapore Figure 3: The framework of our proposed model. It consists of three main components: a behavior evolution layer, an intent evolution layer, and a meta-predictor. Best viewed in color. v 1 c 1 v 2 c 2 v T c T session LSTM session LSTM session LSTM ⋯ Compute Similarity with Priori LDA Intents intent LSTM intent LSTM ⋯ Session Event Frequency ( c ) Session Context Features ( ` ) Session Intents ( 9 ) User Macroscopic Features ( a ) b & b ' b 3 9 & 9 ' 9 3 Behavior Evolution Layer Intent Evolution Layer Output ReLU Meta-Predictor ⋮ ⋮ ×& intent LSTM Softmax l -th fully connected layer with dynamic parameters Linear Mapping Data flow Parameter adjustment M Meta Network d @ % @ % # connections average session time ⋮ Linear Mapping delivery method delivery time delivery content Platform Delivery Message ( e ) D in the dynamic parameter layer to obtain dynamic parameters and make transformations. In our scenario, the meta network can adjust the model parameters according to different user feature inputs for differentiated modeling. At the same time, all users share the basic learnable parameters of the dynamic parameter layer, which enables the model to capture the similarities between users. According to the previous analysis, we can use the user dynamic intent representation obtained from the intent evolution layer as the input signal to parameterized adjustment operation 𝜙 (· , Θ ) in the meta-network to perform differentiated user engagement forecasting. Specifically, we design a meta-predictor that contains a meta network and multiple stacked fully connected layers with dynamic parameters (FC-D layer), as illustrated in Figure 3. l -th fully connected layer with dynamic parameters F X = 3 ∗ 1 @ % Meta Network d @ % 3 1 h % Dynamic User Intent × 3 = h %4& 1 5.3.1 Fully Connected Layers with Dynamic Parameters . As illustrated in Figure 4, assuming that the 𝑙 -th FC-D layer transforms the input feature 𝒉 𝑙 ∈ R 𝑚 into 𝒉 𝑙 + 1 ∈ R 𝑛 , and correspondingly assuming there are 𝑑 basic learnable parameters 𝑾 𝑙 1 , 𝑾 𝑙 2 , ..., 𝑾 𝑙 𝑑 ∈ R ( 𝑚 ∗ 𝑛 ) in it, denoted as 𝑾 𝑙 = [ 𝑾 𝑙 1 , 𝑾 𝑙 2 , ..., 𝑾 𝑙 𝑑 ] 𝑇 ∈ R 𝑑 ×( 𝑚 ∗ 𝑛 ) . The 𝑙 -th FC-D layer computes the following transformation:  where b 𝑾 𝑙 ∈ R 𝑚 × 𝑛 , ˆ 𝒃 𝑙 ∈ R 𝑛 are the weights and bias of the 𝑙 -th FC-D layer adjusted by the meta network. 5.3.2 Meta Network . The adjustment process of b 𝑾 𝑙 in the meta network is shown in Figure 5. The combination weights 𝒂 = [ 𝑎 1 , ..., 𝑎 𝑑 ] 𝑇 ∈ R 𝑑 (which can be seen as meta-knowledge) of basic learnable parameters 𝑾 𝑙 is derived by applying a non-linear transformation and a Softmax operation to user dynamic intent (denoted as e 𝒊 ). In this paper, we utilize two fully connected layers with the ReLU activation function to perform non-transformation, which can be formulated as follows:  Figure 4: The 𝑙 -th fully connected layers with dynamic parameters. where 𝑾 1 , 𝑾 2 , 𝒃 1 , 𝒃 2 are learnable parameters. Then we can combine the basic learnable parameters 𝑾 𝑙 = [ 𝑾 𝑙 1 , 𝑾 𝑙 2 , ..., 𝑾 𝑙 𝑑 ] 𝑇 through 𝒂 , and obtain the adjusted transformation matrix b 𝑾 𝑙 of 𝑙 -th FC-D layer through the reshape operation:  ˆ 𝒃 𝑙 can be calculated in the similar way as b 𝑾 𝑙 . Each row of 𝑾 𝑙 (i.e., 𝑾 𝑙 𝑖 , 𝑖 = 1 , 2 , .., 𝑑 ) can be regarded as independent basic learnable parameters. b 𝑾 𝑙 is a linear combination of 𝑾 𝑙 1 , 𝑾 𝑙 2 , ..., 𝑾 𝑙 𝑑 , and we hope that 𝑾 𝑙 1 , 𝑾 𝑙 2 , ..., 𝑾 𝑙 𝑑 are as orthogonal as possible to reduce redundant information. [42] summarizes some orthogonal regularization methods for parameters, including \"selective\" Soft Orthogonality Regularization, which can be written as follows:  where 𝜆 is the regularization coefficient, 𝑰 ∈ R 𝑑 × 𝑑 is the identity matrix. Here we do not limit the norm of 𝑾 𝑙 𝑖 to 1, and adopt the WSDM'23, February 27-March 3, 2023, Singapore, Singapore Feifan Li et al. Meta Network Figure 5: Meta Network. F X = 3 ∗ 1 @ % F × g X = 3 ∗ 1 d @ % 3 1 l -th fully connected layer with dynamic parameters Reshape to matrix Non-linear Transformation Softmax Dynamic User Intent = following orthogonal regularization term:  where 1 ∈ R 𝑑 × 𝑑 is a matrix whose elements are all 1, ⊙ is Hadamard product, and 𝐿 is the number of FC-D layers.",
  "5.4 End-to-end model training": "We adopt an end-to-end learning strategy and use error backpropagation to train our proposed model. We choose cross-entropy as a classification loss function, which can be formulated as follows:  where 𝑛 is the number of samples, 𝑖 represents the 𝑖 -th sample, 𝑦 𝑖𝑐 equals to 1 if 𝑖 belongs to class 𝑐 otherwise 0, ˆ 𝑦 𝑖𝑐 is the predicted probability that sample 𝑖 belongs to class 𝑐 . After adding the regularization term for the parameters of the meta-predictor, the loss function can be written as:  where 𝛽 is the hyperparameter that trades off classification loss L 𝐶 and regularization term L 𝑅 .",
  "6 EVALUATION": "In this section, we describe the dataset used in this work and introduce the detailed experimental settings. Then, we show that DIGMN outperforms current state-of-the-art models on the user engagement prediction task, demonstrating the effectiveness of DIGMN. To be more specific, we aim to answer the following research questions: · RQ1 : Can DIGMN outperform state-of-the-art baselines in user engagement forecasting tasks at different granularities? · RQ2 : Does DIGMN perform better than a network with static parameters and a similar number of parameters? · RQ3 : How does each part in DIGMN affect the performance? · RQ4 : Is dynamic user intent a good signal to differentiate diverse user engagement patterns? · RQ5 : How do hyperparameters affect the performance? · RQ6 : What about the impact of using other methods to obtain user intent representations on DIGMN performance? · RQ7 : What is the influence of different methods implementing dynamic parameters on the prediction effect of DIGMN? · RQ8 : Can DIGMN learn interpretable user dynamic intent representations?",
  "6.1 Experimental Setup": "6.1.1 Datasets . To evaluate the performance of our proposed model, we conduct experiments on real-world anonymous users' data from LinkedIn. To protect user privacy, we collect coarsegrained behavioral data (only the types of events, as shown in Table 1, not detailed user behaviors) of random anonymous users during four weeks. We filter out users with less than 7 (median) sessions during the first two weeks to make the extracted dynamic intent information more meaningful. As shown in Table 2, the user engagement trend label 𝑦 is obtained by comparing the user engagement in the first two weeks (i.e., 𝑑 ℎ , 𝑠 ℎ ) and the following two weeks (i.e., 𝑑 𝑓 , 𝑠 𝑓 ). The label distribution of the day-level task is approximately 𝑦 = -1 : 𝑦 = 0 : 𝑦 = 1 ≈ 2 : 2 : 1, and the label distribution of the session-level task is approximately 𝑦 = 0 : 𝑦 = 1 ≈ 3 : 2. We randomly sample 200K users for each experiment and split them into three parts: 80% of the samples (i.e., users) for training, 10% for validation, and the rest 10% for testing. Table 2: Labels of user engagement forecasting tasks.  6.1.2 Evaluation Metrics. For the day-level task (3-class classification task), we adopt Macro F1-score as our metric following Liu et al.[2]'s work. Macro F1-score is the average F1-score for each class and can evaluate the classifier in the case of class imbalance. Furthermore, for the session-level task (2-class classification task), AUROC is adopted as our metric, which is a popular metric for the binary classification task. 6.1.3 Comparison Methods. We do not collect the interaction actions between users in this work. Considering comparability, we did not compare with the FATE [3] and CFChurn [10], which uses interaction behaviors between users to predict user engagement or user churn. We compare our proposed model against the following baselines: · Logistic Regression (LR) : We use user macroscopic features and the latest platform delivery message to make predictions. · XGBoost [43]: Use the same input features as Logistic Regression to classify. · Multilayer Perceptron (MLP) : We implement an MLP with two hidden layers using the same features as Logistic Regression and XGBoost as input. · Activity LSTM [1]: We count the number of events in Table 1 that occurred each day for the user in the past two weeks and get a time series 𝑨 ∈ R 10 × 14 as the input of the activity LSTM. · Temporal GCN-LSTM [2]: We treat events as actions and construct the user's action graph according to [2]. Temporal GCNLSTM applies GCN on the action graph to extract user finegrained features, then feeds it into LSTM to capture its temporal dynamics. · Deep Multi-channel [2]: To achieve the best performance, it combines user macroscopic features, the latest platform delivery DIGMN WSDM'23, February 27-March 3, 2023, Singapore, Singapore message, activity LSTM, and Temporal GCN-LSTM. It can be viewed as the state-of-the-art model for predicting user engagement that does not consider the interaction behaviors between users. 6.1.4 Evaluation Settings. The output dimension of the linear mapping layer is set to be half of the input dimension. The number of hidden units in session LSTM and intent LSTM is empirically set to 32. We implement DIGMN with 𝐿 FC-D layers, where 𝐿 is searched from 1 to 5. The hidden units of the non-linear transformation layer in the meta network are set to 32. The dimension of 𝒂 is searched from 2 to 10 and the hyperparameter 𝛽 is searched in [ 10 , 1 , 10 -1 , 10 -2 , 10 -3 , 10 -4 , 10 -5 , 0 ] . We adopt Adam [44] as the optimizer with an initial learning rate 10 -3 and learning rate decay half every 20 epochs. According to [45], the authors argue against using ℓ 2 weight decay and the orthogonal regularization term together, so we only use ℓ 2 weight decay for learnable parameters other than 𝑾 𝑙 ( 𝑙 = 1 , 2 , ..., 𝐿 ) in FC-D layers with a decay rate 10 -5 . Anearly stopping strategy is also used on the validation set to avoid overfitting. Our experiments are conducted on a single machine with a 2.4GHz 12-core CPU and 64GB of memory. Each experiment is repeated 5 times with different random seeds.",
  "6.2 Performance Comparison (RQ1, RQ2)": "Table 3 lists the experiment results of all compared methods. We observe that DIGMN performs best on both day-level and session-level user engagement prediction tasks, which shows the effectiveness of DIGMN. The possible reason for the poor performance of activity LSTM and Temporal GCN-LSTM on our dataset is that our user session data is sparse (each user averages around 2 sessions a day in our dataset, but 7 in Liu et al.[2]'s dataset), which results in sparse activity sequences and action graphs, reducing their performance. Compared with the FC layer, the FC-D layer used in DIGMN increases the learnable parameters. Take one FC-D layer as an example, assuming that it maps the input 𝒉 ∈ R 𝑚 to 𝒉 ′ ∈ R 𝑛 , then the learnable parameters of FC-D layer is 𝑑 ∗ 𝑚 ∗ 𝑛 (for brevity, ignoring bias). However, for the FC layer, its number of learnable parameters is 𝑚 ∗ 𝑛 . For comparability, we use the FC layers (Static) with the same shape or a similar number of parameters to replace the FC-D layers (Dynamic) in DIGMN. As shown in Table 4, we observe that DIGMN with dynamic parameters outperforms DIGMN with static parameters in two tasks, demonstrating the effectiveness of leveraging dynamic parameters network to achieve differentiated user engagement prediction.",
  "6.3 Model Ablation Study (RQ3, RQ4)": "We conduct the following ablation study on the session-level user engagement prediction task. We use an MLP with two hidden layers (# hidden units are 64 and 32) as the predictor to investigate the effectiveness of various components in our model. As shown in Figure 6(a), we find that simultaneously using the user's macroscopic features, platform delivery message, session features, and intent features can achieve the best results. We also study the influence of different adjust signals of DIGMN, as shown in Figure 6(b). We find that using intent as a parameter adjustment signal performs best, indicating that intent can distinguish Table 3: Performance comparison on the classification of user engagement trends at the day-level and the sessionlevel. AUROC 0.63 0.64 0.65 Component S+D M+S+D I+S+D M+I+S+D AUROC 0.63 0.64 0.65 0.66 Parameter adjustment signal M S I M+I M+S I+S M+I+S (a) Ablation study on different model (b) Ablation study on different parame- components. ter adjustment signals of DIGMN. Figure 6: Ablation studies of components and different parameter adjustment signals. 𝑀,𝐷,𝑆,𝐼 represent macroscopic features, the latest platform delivery message, session features, and intent features. different engagement levels well. Introducing too much information to adjust parameters may impair the model classification ability.",
  "6.4 Hyperparameter Sensitivity (RQ5)": "We conduct the following hyperparameter sensitivity study on the session-level user engagement prediction task. · Hyperparameter sensitivity of 𝒂 : As shown in Figure 7(a), we search for the optimal dimension of 𝒂 between 2 and 10, and find that when the dimension of 𝒂 is too small or too large, it will hurt the model's performance. The possible reason is that when the dimension of 𝒂 is small, the expressive ability of the model is limited and cannot sufficiently capture the diverse engagement patterns of users. However, when the dimension of 𝒂 is large, the number of parameters of the model will rapidly increase, which may cause overfitting and weaken generalization ability. On our dataset, the model performs best when the dimension of 𝒂 is equal to 4. · Hyperparameter sensitivity of 𝛽 : As illustrated in Figure 7(b), we adopt grid search in [ 10 , 1 , 10 -1 , 10 -2 , 10 -3 , 10 -4 , 10 -5 , 0 ] , and find that the model performs best when 𝛽 = 10 -2 . This indicates that too strong orthogonal constraints on the FC-D layer will damage the classification ability of the model, and adding proper orthogonal constraints to the FC-D layer can improve the model's performance. · Hyperparameter sensitivity of 𝐿 : As illustrated in Figure 7(c), we vary the number of FC-D layers (i.e., 𝐿 ) in the meta predictor WSDM'23, February 27-March 3, 2023, Singapore, Singapore Feifan Li et al. Table 4: Performance comparison of DIGMN with dynamic predictor and DIGMN with the static predictor. from 1 to 5 and find that the model achieves the best performance when 𝐿 = 3. The possible reason is that when the number of FC-D layers is small, the learning ability of the model is insufficient, and the model is prone to underfitting. In contrast, when the number of FC-D layers is large, the model is prone to overfitting, which damages the model's generalization ability. AUROC 0.645 0.650 0.655 Dimension of a 2 3 4 5 6 7 8 9 10 AUROC 0.635 0.640 0.645 0.650 0.655 0.660 β 10 1 10 -1 10 -2 10 -3 10 -4 10 -5 0 AUROC (a) Hyperparameter sensitivity of 𝒂 . 0.645 0.650 0.655 The number of L 1 2 3 4 5 (b) Hyperparameter sensitivity of 𝛽 . (c) Hyperparameter sensitivity of 𝐿 . Figure 7: Hyperparameter sensitivity.",
  "6.5 Further Analysis (RQ6, RQ7)": "In order to compare with other methods for obtaining representations of user intent, we replace the intent inference operation based on cosine similarity computation in the intent evolution layer with a linear mapping (end-to-end learning), which can be formulated as 𝒊 = tanh ( 𝑾𝝂 + 𝒃 ) , where 𝑾 ∈ R 10 × 7 , 𝒃 ∈ R 7 are learnable parameters, tanh (·) is hyperbolic tangent activation functions used to limit the output value between -1 and 1 (same range as cosine similarity). As shown in Table 5, we can observe that introducing basic prior user intents obtained by LDA to mine user intents in DIGMN performs better than directly learning the implicit intent representation. The possible reason is that the basic prior intents are learned on a larger amount of data, while the end-to-end learning user intent representation usually only uses a part of the data, and the former contains more information. Table 5: Prediction performance of different methods to extract session intents. There are usually two ways to implement dynamic parameters: one is to dynamically adjust the model's parameters (which we use in this paper), and the other is to generate the model's parameters directly. The latter method generate transform matrix b 𝑾 𝑙 of 𝑙 -th FC-D layer, which can be formulated as b 𝑾 𝑙 = Reshape ( 𝑾 4 ( ReLU ( 𝑾 3 e 𝒊 + 𝒃 3 )) + 𝒃 4 ) , where 𝑾 3 , 𝑾 4 , 𝒃 3 , 𝒃 4 are learnable parameters. As shown in Table 6, directly generating parameters of FC-D layers usually requires a meta network with more parameters. Meanwhile, during the training process, we find that directly generating model parameters is prone to overfitting which reduces the model's generalization ability. Table 6: Prediction performance of different methods to implement FC-D layer.",
  "6.6 Visualization (RQ8)": "We use PCA to reduce the dimensions of dynamic user intent representation from 32 to 3 and 2 in the test dataset of the session-level user engagement forecasting task. The label of each sample is the user's most frequent intent in the past two weeks. Figure 8(a) and 8(b) show that the intent evolution layer can learn meaningful and discriminative user dynamic intent representation. Subsequent meta-predictor can leverage user dynamic intent representation to adjust network parameters and perform differentiated user engagement prediction. (a) The distribution of user dynamic intent in 3-dimensional space. (b) The distribution of user dynamic intent in 2-dimensional space. ler Figure 8: The visualization of dynamic user intent representation. We apply zero-mean normalization to the input highdimensional vectors before using PCA for dimension reduction. Best viewed in color.",
  "7 CONCLUSIONS": "In this work, we use LDA on user session data to mine basic user intents. Meanwhile, we propose a dynamic intent guided meta network (DIGMN) to explicitly model user intent evolution over time and perform differentiated user engagement forecasting. Experiments on the real-world dataset from LinkedIn demonstrate the effectiveness of our method. Future work will focus on the interpretability of the method and apply our model to more business scenarios, such as the platform message delivery system. Besides, we will validate our method on more datasets.",
  "ACKNOWLEDGMENTS": "Thanks to Xu Chen and Yanbin Kang for their insightful discussions. Thanks to Lu Chen and Yihan Cao for their help in the data process and building the dataset. Thanks to Yiping Yuan, Huichao Xue, and Yanming Shen for their comprehensive review feedback. DIGMN WSDM'23, February 27-March 3, 2023, Singapore, Singapore",
  "REFERENCES": "[1] Carl Yang, Xiaolin Shi, Luo Jie, and Jiawei Han. I know you'll be back: Interpretable new user clustering and churn prediction on a mobile social application. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining , pages 914-922, 2018. [2] Yozen Liu, Xiaolin Shi, Lucas Pierce, and Xiang Ren. Characterizing and forecasting user engagement with in-app action graph: A case study of snapchat. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining , pages 2023-2031, 2019. [3] Xianfeng Tang, Yozen Liu, Neil Shah, Xiaolin Shi, Prasenjit Mitra, and Suhang Wang. Knowing your fate: Friendship, action and temporal explanations for user engagement prediction on social apps. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining , pages 2269-2279, 2020. [4] Caroline Lo, Dan Frankowski, and Jure Leskovec. Understanding behaviors that lead to purchasing: A case study of pinterest. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining , pages 531-540, 2016. [5] Zhiyuan Lin, Tim Althoff, and Jure Leskovec. I'll be back: on the multiple lives of users of a mobile activity tracking application. In Proceedings of the 2018 World Wide Web Conference , pages 1501-1511, 2018. [6] Vicki G Morwitz, Eric Johnson, and David Schmittlein. Does measuring intent change behavior? Journal of consumer research , 20(1):46-61, 1993. [7] Martin Fishbein and Icek Ajzen. Belief, attitude, intention, and behavior: An introduction to theory and research. Philosophy and Rhetoric , 10(2), 1977. [8] David M Blei, Andrew Y Ng, and Michael I Jordan. Latent dirichlet allocation. the Journal of machine Learning research , 3:993-1022, 2003. [9] Farhan Asif Chowdhury, Yozen Liu, Koustuv Saha, Nicholas Vincent, Leonardo Neves, Neil Shah, and Maarten W Bos. Ceam: The effectiveness of cyclic and ephemeral attention models of user behavior on social platforms. In Proceedings of the International AAAI Conference on Web and Social Media , volume 15, pages 117-128, 2021. [10] Guozhen Zhang, Jinwei Zeng, Zhengyue Zhao, Depeng Jin, and Yong Li. A counterfactual modeling framework for churn prediction. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining , pages 1424-1432, 2022. [11] Arno De Caigny, Kristof Coussement, and Koen W De Bock. A new hybrid classification algorithm for customer churn prediction based on logistic regression and decision trees. European Journal of Operational Research , 269(2):760-772, 2018. [12] Lin Yang, Mingxuan Yuan, Yanjiao Chen, Wei Wang, Qian Zhang, and Jia Zeng. Personalized user engagement modeling for mobile videos. Computer Networks , 126:256-267, 2017. [13] Guandong Xu, Yanchun Zhang, and Xun Yi. Modeling user behavior for web recommendation using lda model. In 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology , volume 3, pages 529-532. IEEE, 2008. [14] Mark J Carman, Fabio Crestani, Morgan Harvey, and Mark Baillie. Towards query log based personalization using topic models. In Proceedings of the 19th ACM international conference on Information and knowledge management , pages 1849-1852, 2010. [15] Jimmy Lin and W John Wilbur. Modeling actions of pubmed users with n-gram language models. Information retrieval , 12(4):487-503, 2009. [16] Pablo Loyola, Chen Liu, and Yu Hirate. Modeling user session and intent with an attention-based encoder-decoder architecture. In Proceedings of the Eleventh ACM Conference on Recommender Systems , pages 147-151, 2017. [17] Rakshit Agrawal, Anwar Habeeb, and Chih-Hsin Hsueh. Learning user intent from action sequences on interactive systems. In Workshops at the Thirty-Second AAAI Conference on Artificial Intelligence , 2018. [18] Qi Guo and Eugene Agichtein. Ready to buy or just browsing? detecting web searcher goals from interaction data. In Proceedings of the 33rd international ACMSIGIR conference on Research and development in information retrieval , pages 130-137, 2010. [19] Wenchao Gu, Yanlin Wang, Lun Du, Hongyu Zhang, Shi Han, Dongmei Zhang, and Michael Lyu. Accelerating code search with deep hashing and code classification. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 2534-2544, 2022. [20] Justin Cheng, Caroline Lo, and Jure Leskovec. Predicting intent using activity logs: How goal specificity and temporal range affect user behavior. In Proceedings of the 26th International Conference on World Wide Web Companion , pages 593-601, 2017. [21] Haoyang Li, Xin Wang, Ziwei Zhang, Jianxin Ma, Peng Cui, and Wenwu Zhu. Intention-aware sequential recommendation with structured intent transition. IEEE Transactions on Knowledge and Data Engineering , 2021. [22] Yongjun Chen, Zhiwei Liu, Jia Li, Julian McAuley, and Caiming Xiong. Intent contrastive learning for sequential recommendation. In Proceedings of the ACM Web Conference 2022 , pages 2172-2182, 2022.",
  "keywords_parsed": [
    "User Intent",
    " User Engagement Forecasting",
    " Meta Learning"
  ]
}