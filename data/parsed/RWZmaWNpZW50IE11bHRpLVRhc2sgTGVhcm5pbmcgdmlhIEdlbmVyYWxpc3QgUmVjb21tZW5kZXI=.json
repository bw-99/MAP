{"Efficient Multi-Task Learning via Generalist Recommender": "Luyang Wang luyang.wang@verizon.com Verizon Basking Ridge, NJ, USA Cangcheng Tang cangcheng.tang@verizon.com Verizon Boston, MA, USA Chongyang Zhang chongyang.zhang@intel.com Intel Corporation Santa Clara, CA, USA Jun Ruan jun.ruan@verizon.com Verizon Alpharetta, GA, USA Kai Huang kai.k.huang@intel.com Intel Corporation Santa Clara, CA, USA", "ABSTRACT": "Jason Dai jason.dai@intel.com Intel Corporation Santa Clara, CA, USA", "1 INTRODUCTION": "Multi-task learning (MTL) is a common machine learning technique that allows the model to share information across different tasks and improve the accuracy of recommendations for all of them. Many existing MTL implementations suffer from scalability issues as the training and inference performance can degrade with the increasing number of tasks, which can limit production use case scenarios for MTL-based recommender systems. Inspired by the recent advances of large language models, we developed an end-toend efficient and scalable Generalist Recommender (GRec). GRec takes comprehensive data signals by utilizing NLP heads, parallel Transformers, as well as a wide and deep structure to process multimodal inputs. These inputs are then combined and fed through a newly proposed task-sentence level routing mechanism to scale the model capabilities on multiple tasks without compromising performance. Offline evaluations and online experiments show that GRec significantly outperforms our previous recommender solutions. GRec has been successfully deployed on one of the largest telecom websites and apps, effectively managing high volumes of online traffic every day.", "CCS CONCEPTS": "\u00b7 Information systems \u2192 Recommender systems ; \u00b7 Computing methodologies \u2192 Neural networks .", "KEYWORDS": "Multi-Task Learning; Recommender Systems; Real-World Application", "ACMReference Format:": "Luyang Wang, Cangcheng Tang, Chongyang Zhang, Jun Ruan, Kai Huang, and Jason Dai. 2023. Efficient Multi-Task Learning via Generalist Recommender. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM '23), October 21-25, 2023, Birmingham, United Kingdom. ACM, New York, NY, USA, 5 pages. https: //doi.org/10.1145/3583780.3615229 This work is licensed under a Creative Commons Attribution International 4.0 License. CIKM '23, October 21-25, 2023, Birmingham, United Kingdom \u00a9 2023 Copyright held by the owner/author(s). ACM ISBN 979-8-4007-0124-5/23/10. https://doi.org/10.1145/3583780.3615229 Whendeveloping a recommender system (RS), the recommendation task can be viewed as a next-item prediction problem, where the goal is to optimize various performance metrics given by a set of user behavior and contextual information. There are a wide variety of performance metrics that can be optimized by RS, such as click through rate (CTR), add to cart rate (ATC), conversion rate (CVR), etc. Even the same performance metrics optimization can greatly differ depending on the context and specific use case scenarios. For example, predicting which smartphone a user would purchase next can be defined as a CVR task. Additionally, it can be subdivided into two distinct scenarios: acquiring a smartphone through a device trade-in flow or obtaining a smartphone by adding a new line to the wireless account. The recent development of MTL has demonstrated promising performance that allows one model to optimize across multiple tasks [14]. However, scaling challenges arise in many existing MTL architectures as training and inference speeds degrade when the number of tasks increases. Inference performance is particularly important in real-world recommender systems, and limitations in this aspect can restrict the application of existing MTL-based recommender systems when scaling to multiple tasks. As one of the largest telecommunication companies in the world, previously we have developed many single-task recommenders for individual use cases to optimize different performance metrics. This approach has led to several challenges. First, models working in silos may fail to consider the interconnection among various use cases, resulting in a narrow model vision and potential recommendation bias. Second, training data is sometimes sparse for certain tasks, such as CVR-related tasks. Insufficient training data presents challenges for models with large numbers of parameters to optimize. Third, maintaining multiple single-task recommenders can increase the complexity of ML operations. To overcome the above challenges, we proposed Generalist Recommender (GRec) that can handle multiple recommender tasks simultaneously. Taking inspiration from the recent development of LLMs [5], we applied the sparse mixture-of-experts [17] (sparse MoE) architecture and proposed a new task-sentence routing strategy, allowing our model to expand its capacity for cross-task generalization while maintaining promising inference performance. Our primary contributions can be summarized as follows: \u00b7 We proposed a novel recommender GRec which is able to generalize across a variety of recommendation tasks. CIKM '23, October 21-25, 2023, Birmingham, United Kingdom Luyang Wang et al. Figure 1: The framework of our GRec model. Sparse MoE Outputs Attention Pooling Task Embeddings Sequence Embeddings Wide and Deep Embeddings Parallel Transformer Wide and Deep Layer Task IDs Feature Input Sequence Input \u2026 Concatenate Item ID Item Feature Page ID \u00b7 We applied sparse MoE architecture and proposed a new task-sentence routing strategy to efficiently scale up GRec in real-world applications. \u00b7 We conducted experiments on a real-world large-scale digital recommender system, demonstrating that GRec delivers significant performance and efficiency gains.", "2 RELATED WORK": "Multi-Task Learning for Recommendation: To address the challenge of multiple objectives in personalized recommendation scenarios, such as clicking, adding to cart, and purchasing, many multi-task models [9, 13, 14, 24] have been proposed that can jointly learn from several tasks and improve the accuracy of recommendations. However, existing multi-task approaches usually serve for scenarios with a small number of tasks[24] and are not suitable for large-scale online recommendation [6, 7, 21, 23]. Due to the large number of task-specific parameters of existing models, the input modalities of these multi-task methods cannot be scaled up [23]. Large-Scale Applications of Multi-Task Methods: With the development of distributed machine learning systems [4], largescale models represented by LLMs are increasingly used in real-life applications, such as GPT-3 [1], PaLM [3], LLaMa [18]. In addition to recommendation systems, large-scale models with multi-task learning capabilities have also been applied to traditional machine learning tasks [10, 12, 17]. For example, Kudugunta et al. [10] proposed Task-MoE for multilingual machine translation tasks, which can extract smaller, ready-to-deploy sub-networks from large sparse models. With task-level routing, Task-MoE selects experts by task boundaries as opposed to making input-level decisions, significantly improving efficiency and scalability. Inspired by LLMs and Task-MoE, our GRec can select the required expert combination based on task and has the ability to deal with tasks of different modalities. Through extensive experiments on real-world largescale recommendation systems, we demonstrate that our GRec is indeed scalable and has impressive performance.", "3 MODEL ARCHITECTURE": "The overall architecture of our GRec is illustrated in Fig. 1, while this section provides an elaborate description of the pivotal components of GRec.", "3.1 Wide and Deep Layer": "A wide and deep structure [2] is used to process inputs of multimodalities, including categorical and numerical data, texts, and Figure 2: The architecture of wide and deep layer in GRec. Context Categorical Features Context Numerical Features Customer Search Item ID Item Categorical Features Item Numerical Feature Item Image Item Text Description Categorical Feature Encoder Normalization + FF Layer Search Transformer Encoder ID Encoder Categorical Feature Encoder Normalization + FF Layer Image Encoder Text Encoder CLIP Connector Context Categorical Embedding Context Numerical Output Item ID Embedding Item Categorical Embedding Item Numerical Output CLIP Output Context Embedding Search Embedding Cart Item Full Embedding * Step1 Feature Input * Step2 Feature Processing * Step3 Embedding Generation images, as shown in Fig. 2. Customer categorical features are encoded into embedding vectors and passed into the deep tower. Numerical features are processed using a feedforward layer to ensure the output dimension matches that of the deep tower. GRec passes search terms into a pre-trained transformer encoder to capture customer intent. On the item side, item meta features are utilized alongside item ID embedding to enrich the item encoding layer. Item categorical features are converted into embeddings (item deep component), while numerical features are normalized and passed into a feedforward layer (item wide component). GRec leveraged embedding input extracted from a pre-trained CLIP model [16] to encode item image and text description. Item ID embeddings, item wide and deep components, and CLIP model outputs are then concatenated to form a full item embedding vector.", "3.2 Parallel Transformer Layer": "Sequence data includes past devices that customers viewed and past pages they landed on our websites. GRec uses parallel attention and feedforward with residual connection to encode those sequences. This is an adaption from the Pathways Language Model [3], which contains below highlights: Multi-query single-key-value attention. Traditionally, the scaled dot-product attention [19] can be formulated as:  where \ud835\udc44 represents the queries, \ud835\udc3e the keys, \ud835\udc49 the values and \ud835\udc51 the dimension of latent vectors. Following [19], we use multi-head attention:  where the projection matrices \ud835\udc4a \ud835\udc44 , \ud835\udc4a \ud835\udc3e , \ud835\udc4a \ud835\udc49 \u2208 \ud835\udc45 \ud835\udc51 \u00d7 \ud835\udc51 , and \u210e is the number of heads. For a standard Transformer with h attention heads, the shape of the \ud835\udc44 , \ud835\udc3e , and \ud835\udc49 tensors is [ \u210e, \ud835\udc51 ] , where \ud835\udc51 is the attention head size. Different from the aforementioned multi-head attention mechanism, for different queries, we are using the same key and value. That is, the key/value projections are shared for each head, i.e. \ud835\udc3e and \ud835\udc49 are projected to [ 1 , \ud835\udc51 ] , but \ud835\udc44 is still projected to shape [ \u210e, \ud835\udc51 ] . This improves efficiency by reducing attention block size and computation complexity. Parallel Layer. Following [3], we use the parallel layer in each transformer block, which parallelizes the attention and feedforward layers. The formula of traditional transformer can be written as: \ud835\udc66 = \ud835\udc65 + MLP ( LayerNorm ( \ud835\udc65 + Attention ( LayerNorm ( \ud835\udc65 ))) (3) Efficient Multi-Task Learning via Generalist Recommender CIKM '23, October 21-25, 2023, Birmingham, United Kingdom whereas the formula of parallel transformer can be written as: \ud835\udc66 = \ud835\udc65 + MLP ( LayerNorm ( \ud835\udc65 )) + Attention ( LayerNorm ( \ud835\udc65 )) (4) This architecture is able to reduce model complexity and increase attention speed, especially at large scale [3].", "3.3 Task-Sentence MoE Layer": "To enhance GRec's capability to generalize across multiple recommendation task categories, we scale up GRec model parameters using the sparse MoE [17] structure. This structure is capable of activating a subset of expert layers depending on task categories, which allows multiple tasks to be combined and trained in one model. For the MoE layer, the gating function (also referred to as routing strategy) is critical, which indicates the weights of each expert in processing incoming tokens [11]. In multilingual translation, some common routing strategies for MoE include (i) token-level routing, (ii) sentence-level routing and (iii) task-level routing [10], as detailed below. Token-Level Routing. In token-level routing, each token is routed independently, as shown in Fig. 3 (a):  where \ud835\udc65 \ud835\udc60 is the input token to the MoE layer. Vector G \ud835\udc60,\ud835\udc38 is computed by a gating network (also referred as router). We use this vector to select a subset of experts to route the token. Sentence-Level Routing. As shown in Fig. 3 (b), all tokens from a sentence are routed to the same experts, and the gating vector is calculated by concatenating all token representations in a given sentence:  Task-Level Routing. Experts are selected by task boundaries. In multilingual translation, task boundaries can be defined by the target language or the language pair, the structure of task-level routing is shown in Fig. 3 (c). Task-level routing is formulated as follows:  where task id is a manually set input that represents the current task to be processed. Different from multilingual translation, in the field of recommendation, routing tasks can have multiple types, in our case, it has two types: flow and use cases. Customer digital interactions typically follow three flows: adding a line to an existing account (AAL), upgrading current devices (EUP), and prospect customers' acquisition of new services (NSE). Use cases here refer to the business goal that is being targeted, such as CTR and CVR. Pairing these task types will create too many different tasks, and these splits often imbalance the dataset and lead to unstable models. Referring to the routing strategies in multilingual translation, in GRec, we are introducing a new routing strategy: Task-Sentence level routing, which combines multiple task tokens into a sentence and then performs expert routing. In our case, we combine our main task (e.g., CTR, CVR) with the auxiliary task (e.g., EUP, AAL) as a task sentence (e.g., AAL+CVR, EUP+CTR) to feed into routing. With this approach, embeddings from different types of tasks are considered without creating too many task type pairs. We define each task based on user ordering flow (device upgrade, add a line, new customer, etc.) and targeted outcome (CTR, CTCVR, CVR, etc) pair, as shown in Fig. 3 (d). The formula of the task-sentence routing strategy is as follows:  After comparing the performance trade-offs between different routing strategies (as shown in Sec. 4), we adopt task-sentence level routing strategies in the GRec implementation.", "4 EXPERIMENTS": "In this section, we perform experiments to evaluate the performance of our proposed framework and compare routing strategies on speed and average precision. Experiments are conducted on public datasets and our internal transaction data. On the public dataset, we conduct separate experiments on sparse MoE in GRec to validate its scalability. On our internal transaction data, we conducted offline comparison on various routing strategies and use MMoE[14] as baseline. We also conducted online A/B testing of GRec over previous state-of-art method and achieved impressive performance in real-world large-scale recommender applications.", "4.1 Offline evaluation on AliExpress dataset": "Dataset: For the public dataset experiment, we conducted on AliExpress dataset [15], which is gathered from real-world traffic logs of research system. This dataset is collected from 5 countries: Russia (RU), Spain (ES), French (FR), Netherlands (NL), and America (US), which can be seen as 5 independent multi-task sub-datasets. Settings: On public dataset, the hyper-parameters shared by all models are set to the same values, the source and hyper-parameter settings are all listed in [20] to facilitate the reproduction of our experiments. Due to the large amount of data in the RU sub-dataset, we mainly conducted experiments on four other sub-datasets, taking the AUC [8] score as the metric. Note a slightly higher AUC at 0.1%-level is regarded as significant for the CTR task [22]. As shown in Fig. 4, as the number of selected experts (the \ud835\udc58 of top\ud835\udc58 router) increases and the total number of experts changes, the performance of the model will be improved. This means that we can not only improve performance by changing top\ud835\udc58 , but also by increasing the total number of experts. At the same time, when increasing the total number of experts, the FLOPs (floating point operations per second) of the model shows slight changes, further verifying the scalability of sparse MoE in recommendation tasks. This is also the reason why we apply sparse MoE in GRec. Table 1: Results on internal offline transaction dataset. CIKM '23, October 21-25, 2023, Birmingham, United Kingdom Luyang Wang et al. Figure 3: Differences between token-level, sentence-level, task-level and task-sentence-level sparse MoEs. Top-K Router Expert 0 Expert 1 Expert 2 Expert 3 Token Top-K Router Expert 0 Expert 1 Expert 2 Expert 3 Sentence Top-K Router Expert 0 Expert 1 Expert 2 Expert 3 Hidden States Top-K Router Expert 0 Expert 1 Expert 2 Expert 3 Hidden States task task1 task2 Selected route (a) Token-level (b) Sentence-level (c) Task-level (d) Task-sentence-level Table 2: Results on internal online A/B test. 0.65 0.70 0.75 0.80 0.85 0.90 2 4 6 8 AUC Number of selected experts NL ES FR US CTR CTCVR (a) 0.65 0.70 0.75 0.80 0.85 0.90 16 32 48 AUC Total number of experts NL ES FR US CTR CTCVR FLOPs (b) 7.27M 7.28M 7.29M Figure 4: The trend of AUC changes when the number of experts selected and the total number of experts are different.", "4.2 Offline evaluation of internal transaction dataset": "Dataset: For our internal experiment, GRec is trained on 3 months of customer transaction data, and test data is sampled on transactions that happened one week after the last day of training data. The two types of tasks are flows : EUP, AAL, NSE, and use cases : CTR, CTCVR, ATC, CVR. Training data are upsampled by tasks to ensure data balance. Settings: Different versions of sparse MoE models are tested, all versions pick top-4 routing on 8 experts, with expert capacity of 2 tokens and 2048 as the batch size. We evaluate model performance based on FLOPs and average precision for the given use cases. We analyze the impact of different sparse MoE routing strategies on model performance, comparing them not only against the baseline but also among themselves. Baseline: MMoE is used as the baseline model, and it is setup with 4 experts to match the top-4 routing in sparse MoE. The results are presented in Table 1. As the baseline, the MMoE strategy demonstrated lower performance in average precision (AP) and similar FLOPs consumption compared to GRec task-sentence level routing. When comparing MMoE with sparse-MoE, even though routing FLOPs are similar, training and inference time grow linearly on the expert number, as MMoE has to use all its experts instead of choosing top\ud835\udc58 flexibly. GRec task-sentence routing showed comparable performance to token-level routing, while exhibiting a notable 50% improvement in FLOPs. It effectively balanced model performance and efficiencies.", "4.3 Online A/B Testing evaluation": "For online measurement, we evaluated GRec in four different sets of use cases against previous state-of-art single-task recommender models. \u00b7 The first and second use cases are on the home page, where the recommendation task is defined as to improve the device click-through conversion rate (CTCVR) with different flows of upgrade (EUP) and add a line (AAL). \u00b7 The third and fourth use cases are on the interstitial page, where the recommendation task is defined as to improve accessory conversion with different flows of upgrade (EUP) and add a line (AAL). The single-task recommender is trained on the specific task only. Each use case was evaluated separately using the same amount of live traffic. Table 2 shows the results of online A/B testing. We observed significant improvements across all tasks during the online A/B testing period, and all reached statistical significance. It's worth noting that GRec achieved an even higher improvement on CVRrelated tasks over single task recommender, where conversionrelated tasks are relatively sparse and we see GRec benefited a lot from shared parameter learning from other tasks with more abundant training data such as CTR and ATC.", "5 CONCLUSION AND FUTURE WORKS": "In this paper, we purpose a new recommender model, GRec, which applies the sparse-MoE structure and utilizes our novel task-sentence routing strategy. Moreover, our model is designed to take inputs of multi-modalities, which facilitates generalizing tasks. In multiple production use cases, GRec has shown significantly improved performance over the baseline in both offline and online A/B testing settings. We demonstrate success deploying GRec in real-world large-scale recommender systems. Efficient Multi-Task Learning via Generalist Recommender CIKM '23, October 21-25, 2023, Birmingham, United Kingdom", "REFERENCES": "[1] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., Language models are few-shot learners , Advances in neural information processing systems, 33 (2020), pp. 18771901. [2] H.-T. Cheng, L. Koc, J. Harmsen, T. Shaked, T. Chandra, H. Aradhye, G. Anderson, G. Corrado, W. Chai, M. Ispir, et al., Wide & deep learning for recommender systems , in Proceedings of the 1st workshop on deep learning for recommender systems, 2016, pp. 7-10. [3] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, et al., Palm: Scaling language modeling with pathways , arXiv preprint arXiv:2204.02311, (2022). [4] J. Dean, G. Corrado, R. Monga, K. Chen, M. Devin, M. Mao, M. Ranzato, A. Senior, P. Tucker, K. Yang, et al., Large scale distributed deep networks , Advances in neural information processing systems, 25 (2012). [5] N. Du, Y. Huang, A. M. Dai, S. Tong, D. Lepikhin, Y. Xu, Y. Krikun, Maxim andd Zhou, A. W. Yu, O. Firat, B. Zoph, L. Fedus, M. Bosma, Z. Zhou, T. Wang, Y. E. Wang, K. Webster, M. Pellat, K. Robinson, K. Meler-Hellstern, T. Duke, L. Dixon, K. Zhang, Q. V. Le, Y. Wu, Z. Chen, and C. Cui, Glam: Efficient scaling of language models with mixture-of-experts , arxiv preprint arXiv:2112.06905, (2021). [6] H. Ehsan, M. A. Sharaf, and P. K. Chrysanthis, Muve: Efficient multi-objective view recommendation for visual data exploration , in 2016 IEEE 32nd International Conference on Data Engineering (ICDE), IEEE, 2016, pp. 731-742. [7] A. M. Elkahky, Y. Song, and X. He, A multi-view deep learning approach for cross domain user modeling in recommendation systems , in Proceedings of the 24th international conference on world wide web, 2015, pp. 278-288. [8] T. Fawcett, An introduction to roc analysis , Pattern recognition letters, 27 (2006), pp. 861-874. [9] R. A. Jacobs, M. I. Jordan, S. J. Nowlan, and G. E. Hinton, Adaptive mixtures of local experts , Neural computation, 3 (1991), pp. 79-87. [10] S. Kudugunta, Y. Huang, A. Bapna, M. Krikun, D. Lepikhin, M.-T. Luong, and O. Firat, Beyond distillation: Task-level mixture-of-experts for efficient inference , arXiv preprint arXiv:2110.03742, (2021). [11] D. Lepikhin, H. Lee, Y. Xu, D. Chen, O. Firat, Y. Huang, M. Krikun, N. Shazeer, and Z. Chen, Gshard: Scaling giant models with conditional computation and automatic sharding , arXiv preprint arXiv:2006.16668, (2020). [12] M. Long, Z. Cao, J. Wang, and P. S. Yu, Learning multiple tasks with multilinear relationship networks , Advances in neural information processing systems, 30 (2017). [13] J. Ma, Z. Zhao, J. Chen, A. Li, L. Hong, and E. H. Chi, Snr: Sub-network routing for flexible parameter sharing in multi-task learning , in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, 2019, pp. 216-223. [14] J. Ma, Z. Zhao, X. Yi, J. Chen, L. Hong, and E. H. Chi, Modeling task relationships in multi-task learning with multi-gate mixture-of-experts , in Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining, 2018, pp. 1930-1939. [15] pengcheng Li, R. Li, Q. Da, A.-X. Zeng, and L. Zhang, Improving multi-scenario learning to rank in e-commerce by exploiting task relationships in the label space , in proceedings of the 28th ACM International Conference on Information and Knowledge Management, CIKM 2020, Virtual Event, Ireland, October 19- 23,2019, New York,NY,USA, 2020, ACM. [16] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, et al., Learning transferable visual models from natural language supervision , in International conference on machine learning, PMLR, 2021, pp. 8748-8763. [17] N. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton, and J. Dean, Outrageously large neural networks: The sparsely-gated mixture-of-experts layer , arXiv preprint arXiv:1701.06538, (2017). [18] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozi\u00e8re, N. Goyal, E. Hambro, F. Azhar, et al., Llama: Open and efficient foundation language models , arXiv preprint arXiv:2302.13971, (2023). [19] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, \u0141. Kaiser, and I. Polosukhin, Attention is all you need , Advances in neural information processing systems, 30 (2017). [20] L. Wang, C. Tang, C. Zhang, J. Ruan, K. Huang, and J. Dai, Bigdlgrec , 2023, https://github.com/intel-analytics/BigDL/tree/main/python/friesian/ example/GRec. [21] N. Wang, H. Wang, Y. Jia, and Y. Yin, Explainable recommendation via multi-task learning in opinionated text data , in The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, 2018, pp. 165-174. [22] B. Yan, P. Wang, K. Zhang, W. Lin, K.-C. Lee, J. Xu, and B. Zheng, Learning effective and efficient embedding via an adaptively-masked twins-based layer , in Proceedings of the 30th ACM International Conference on Information & Knowledge Management, 2021, pp. 3568-3572. [23] Z. Zhao, L. Hong, L. Wei, J. Chen, A. Nath, S. Andrews, A. Kumthekar, M. Sathiamoorthy, X. Yi, and E. Chi, Recommending what video to watch next: a multitask ranking system , in Proceedings of the 13th ACM Conference on Recommender Systems, 2019, pp. 43-51. [24] Y. Zhu, Y. Liu, R. Xie, F. Zhuang, X. Hao, K. Ge, X. Zhang, L. Lin, and J. Cao, Learning to expand audience via meta hybrid experts and critics for recommendation and advertising , in Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, 2021, pp. 4005-4013."}
