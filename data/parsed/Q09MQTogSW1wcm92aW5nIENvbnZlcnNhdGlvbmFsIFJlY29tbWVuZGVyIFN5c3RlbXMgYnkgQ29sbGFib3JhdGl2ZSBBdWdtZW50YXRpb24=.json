{"title": "COLA: Improving Conversational Recommender Systems by Collaborative Augmentation", "authors": "Dongding Lin; Jian Wang; Wenjie Li", "pub_date": "2022-12-15", "abstract": "Conversational recommender systems (CRS) aim to employ natural language conversations to suggest suitable products to users. Understanding user preferences for prospective items and learning efficient item representations are crucial for CRS. Despite various attempts, earlier studies mostly learned item representations based on individual conversations, ignoring item popularity embodied among all others. Besides, they still need support in efficiently capturing user preferences since the information reflected in a single conversation is limited. Inspired by collaborative filtering, we propose a collaborative augmentation (COLA) method to simultaneously improve both item representation learning and user preference modeling to address these issues. We construct an interactive user-item graph from all conversations, which augments item representations with user-aware information, i.e., item popularity. To improve user preference modeling, we retrieve similar conversations from the training corpus, where the involved items and attributes that reflect the user's potential interests are used to augment the user representation through gate control. Extensive experiments on two benchmark datasets demonstrate the effectiveness of our method. Our code and data are available at https://github.com/DongdingLin/COLA.", "sections": [{"heading": "Introduction", "text": "With the rapid development of conversational systems, it is expected that recommender systems can employ natural language conversations to provide high-quality recommendations, namely Conversational Recommender Systems (CRS) (Christakopoulou, Radlinski, and Hofmann 2016;Li et al. 2018). Many researchers (Liao et al. 2019;Lei et al. 2020;Gao et al. 2021;Jannach et al. 2021;Ren et al. 2021;Zhou et al. 2022) have been attracted to explore CRS due to its high impact on e-commerce.\nIn the area of CRS, tremendous studies (Zhang et al. 2019a;Zhou et al. 2020a;Lu et al. 2021;Deng et al. 2021;Chen et al. 2019;Wang et al. 2021;Zhou et al. 2022) focus on how to learn good item representations and capture user preferences effectively expressed in natural language conversations. The proposed approaches include reinforcement learning (Zhang et al. 2019a;Deng et al. 2021), pretraining-finetuning (Chen et al. 2019;Wang et al. 2021), contrastive learning (Zhou et al. 2022), and so forth. However, these studies still suffer from several limitations. First, they mainly learn item representations based on individual conversations, ignoring the attribute of item popularity embodied among many conversations (users). It causes the system not effective enough to distinguish between popular items and others that may be only favored by a small group of users. Second, they still struggle to capture user preferences efficiently since the information in a single conversation that can reflect the user's interests in potential items is limited. To alleviate the above drawbacks, we expect to learn item representations and model user preferences collaboratively by considering their mutual impact. However, it is non-trivial since user-item interaction data is not directly available in CRS.\nIn this work, we propose a COLlaborative Augmentation (COLA) method to improve CRS, inspired by collaborative filtering (Schafer et al. 2007). Here, the item representations are augmented with user-aware information, i.e., the popularity embodied among all conversations. Similarly, the user representations are augmented with item-aware information that may reveal the user's potential interests. In particular, we first construct an interactive user-item graph by extracting the user-item pairs with liked or disliked relations involved in all conversations from the training corpus. The graph is encoded by an R-GCN (Schlichtkrull et al. 2018), where each item node aggregates liked and disliked information (i.e., item popularity) from different user nodes through message passing. We adopt the encoded output to augment item representations with an add operation. In light of the fact that in CRS, similar users converse with the system and provide similar feedback about items and attributes, we use the current conversation to retrieve similar conversations (i.e., similar users) from the training corpus using BM25 (Manning, Raghavan, and Sch\u00fctze 2008). Then, the contained items and related attributes in the top-n conversations that reveal the user's potential interests are aggregated through a self-attention mechanism. We employ the aggregated output to enhance the user representations with gate control.\nBased on user-item collaboratively-augmented representations, we make recommendations by matching the user with candidate items and selecting the top-k items as the recommended set. In the end, we adopt a widely-used backbone conversation generation model, following existing works (Liu et al. 2020;Zhou et al. 2022), to generate an appropriate utterance in response to the user.\nWe summarize the contributions of this paper as follows: \u2022 We propose a collaborative augmentation method to help learn item representations and model user preferences, which is simple but effective in improving existing CRS. \u2022 We construct an interactive user-item graph to introduce popularity-aware information for item representation learning and propose a retrieval-enhanced approach for user preference modeling. \u2022 Extensive experiments on two CRS benchmark datasets demonstrate that our method effectively performs better than various strong baseline models.", "publication_ref": ["b2", "b11", "b15", "b10", "b5", "b8", "b23", "b41", "b18", "b3", "b1", "b30", "b41", "b3", "b1", "b30", "b41", "b24", "b25", "b20", "b17", "b41"], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "Conversational Recommender Systems (CRS) (Jannach et al. 2021;Sun and Zhang 2018) have been an emerging research topic to provide high-quality recommendations through natural language conversations with users. In order to advance the research, various datasets have been released, such as REDIAL (Li et al. 2018), TG-REDIAL (Zhou et al. 2020c), INSPIRED (Hayati et al. 2020), DuRecDial (Liu et al. 2020(Liu et al. , 2021)), etc. Existing works are divided into recommendationbiased CRS (Christakopoulou, Radlinski, and Hofmann 2016;Sun and Zhang 2018;Zhou et al. 2020b;Li et al. 2021;Ren et al. 2021;Xie et al. 2021;Zhou et al. 2020a,c) and dialoguebiased CRS (Li et al. 2018;Chen et al. 2019;Liu et al. 2020;Ma, Takanobu, and Huang 2021). In this paper, we focus on the recommendation-biased CRS.\nExisting recommendation-biased CRSs mainly focus on how to learn item representations and model user preferences. To this end, various approaches have been proposed, including reinforcement learning (Zhang et al. 2019a;Deng et al. 2021), pretraining-finetuning (Chen et al. 2019;Wang et al. 2021) and contrastive learning (Zhou et al. 2022). To improve item representation learning, Li et al. (2018) and Zhou et al. (2020a) introduced domain knowledge graphs and modeled items in the graphs with R-GCN (Schlichtkrull et al. 2018). For the user preferences modeling, Xu et al. (2020) created the MGCConvRex corpus to help perform user memory reasoning. Xu et al. (2021) adapted both attribute-level and item-level feedback signals to identify the user's attitude towards an item more precisely. Besides, Li et al. (2022) focused on user-centric conversational recommendations with multi-aspect user modeling, e.g., the user's current conversation session and historical conversation sessions. For the recommendation, there are several studies that focus on asking item attributes (Lei et al. 2020), clarifying the user's requests (Ren et al. 2021) and recommendation strategies (Zhou et al. 2020b;Ma, Takanobu, and Huang 2021).", "publication_ref": ["b8", "b28", "b11", "b6", "b17", "b16", "b2", "b28", "b12", "b23", "b31", "b11", "b1", "b17", "b19", "b3", "b1", "b30", "b41", "b11", "b25", "b32", "b33", "b13", "b10", "b23", "b19"], "figure_ref": [], "table_ref": []}, {"heading": "Preliminaries", "text": "Task Definition Formally, let I = {e i } m i=1 denote the entire item set, H = {s t } n t=1 denote a conversation consisting of a list of utterances between a user (recommendation seeker) and a conversational recommender system, where s t is produced by either the user or the system. Given a conversation history, a CRS aims to select a set of candidate items I t that satisfy the user's requests from the entire item set, and then produce an appropriate utterance in response to the user. The system is required to capture user preferences expressed in historical utterances. In some cases, I t may be empty because the system needs to ask questions about item attributes to clarify the user's requests or interests.\nFundamental Framework Existing methods (Chen et al. 2019;Liao et al. 2019;Liu et al. 2020;Lu et al. 2021;Zhou et al. 2022) mainly divide CRS into two major modules: recommendation module and response generation module. The recommendation module aims to capture user preferences based on the conversation history and recommend suitable items accordingly. Based on the output of the recommendation module, the response generation module is utilized to generate natural language responses to interact with users. In general, the recommendation module is critical for the whole performance of CRS.\nMany prior works (Zhou et al. 2020a;Zhang et al. 2021;Lu et al. 2021;Zhou et al. 2022) have introduced external item-oriented knowledge graphs (KGs) to enrich the learned item representations. For example, one of the widely-used KGs is DBpedia (Auer et al. 2007), which provides structured knowledge facts about items. Each knowledge fact is formatted as a triple e 1 , r k , e 2 , where e 1 , e 2 \u2208 E denote entities (or items), r k denotes their relation. To better understand user preferences expressed in natural language conversations, several works (Zhou et al. 2020a;Lu et al. 2021) have introduced word-oriented or commonsense KGs, i.e., ConceptNet (Speer, Chin, and Havasi 2017). The Concept-Net provides commonsense relations between words (e.g., the antonyms relation between \"cheerful\" and \"miserable\"), which helps align semantics between word-level information in the conversations and entity-level information in itemoriented knowledge graphs. In ConceptNet, semantic facts are also stored in the form of w 1 , r c , w 2 , where w 1 , w 2 \u2208 V are words, r c denotes the relation between w 1 and w 2 .\nFollowing the above studies, we also adopt an itemoriented KG and a word-oriented KG as the external data to build our base CRS model. On top of that, we augment the item and user representations with our proposed approach.", "publication_ref": ["b1", "b15", "b17", "b18", "b41", "b36", "b18", "b41", "b0", "b18", "b27"], "figure_ref": [], "table_ref": []}, {"heading": "Proposed Method", "text": "In this section, we propose a COLlaborative Augmentation (COLA) method for CRS, the overview of which is shown in Figure 1. The key components of our COLA are highlighted in orange and blue dotted boxes, which stand for popularity-aware item representation augmentation and retrieval-enhanced user preference augmentation, respectively. Based on collaboratively augmented user and item representations, we follow the existing fundamental framework for recommendation and response generation.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Popularity-aware Item Representation Augmentation", "text": "Before we introduce item representation augmentation, we first adopt an item-oriented KG (e.g., DBpedia) to obtain base item representations following many existing works (Chen et al. 2019;Zhou et al. 2020a;Lu et al. 2021)  we employ an R-GCN (Schlichtkrull et al. 2018) to encode the item-oriented knowledge graph K. Formally, the representation of each entity e in the K is calculated as follows:\nk +1 e = ReLU( r\u2208R k e \u2208E r e 1 Z e,r W k,r k e + W k k e ),(1)\nwhere k e \u2208 R d is the node representation of e at theth layer, d is the embedding dimension. E r e denotes the set of neighboring nodes for e under the relation r. W k,r is a learnable relation-specific transformation matrix for the embeddings from neighboring nodes with relation r, W k is a learnable matrix for transforming the representations of nodes at the -th layer. Z e,r is a normalization factor. ReLU(\u2022) is an activation function. After aggregating the KG information, we adopt the output of R-GCN in Eq. 1 as the base item representations, denoted as\nE K = {k e,1 , k e,2 , \u2022 \u2022 \u2022 , k e,m },\nwhere m denotes the number of items.\nMore importantly, we aim to augment the base item representations with user-aware information, i.e., the popularity embodied among all conversations. Since natural language conversations between a user and the system contain specific key words (e.g., \"like\", \"enjoy\", \"dislike\", \"hate\", etc.) that reflect the user's attitudes towards items and related attributes, we extract all the user's liked and disliked items mentioned in user-system conversations. Based on the training corpus, we obtain various user-item pairs with liked or disliked relation and then construct an interactive user-item graph G (see Figure 1) accordingly. In the graph G, each edge between a user node and an item node represents the user's preferences (i.e., like or dislike), given by:\nG = u, r, e , u \u2208 U, e \u2208 I, r \u2208 R G ,(2)\nwhere U denotes all users, I denotes the entire item set, R G = {\"like\", \"dislike\"}. Intuitively, the item nodes liked by more users (or disliked by fewer users) are more popular than those liked by fewer users (or disliked by more users).\nTo obtain popularity-aware item representations, we adopt another R-GCN to encode the user-item graph G as follows:\nv +1 G,e = ReLU( r\u2208R G u\u2208G r e 1 Z e,r W G,r v u + W G v G,e ), (3) v +1 G,u = ReLU( r\u2208R G e\u2208G r u 1 Z u,r W G,r v e + W G v G,u ),(4)\nwhere v G,e , v G,u \u2208 R d is the -th layer's representation of item e and user u, respectively. G r e , G r u are the one-hop neighbor set of e and u under the relation r. W G,r and W G are trainable weights of layer . Z e,r and Z u,r are normalization factors. According to Eq. 3 and Eq. 4, each item node aggregates liked and disliked information (i.e., item popularity) from different user nodes through message passing. After computation, we adopt the item representations based on Eq. 3 as the popularity-aware item representations, denoted as\nE G = {v e,1 , v e,2 , \u2022 \u2022 \u2022 , v e,m }\n, where m denotes the number of items. Finally, we augment the base item representations E K with popularity-aware item representations E G by an element-wise add operation:\nE e,j = k e,j + v e,j(5)\nwhere\nk e,j \u2208 E K , v e,j \u2208 E G , j \u2208 [1, m].", "publication_ref": ["b1", "b18", "b25"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Retrieval-enhanced User Preference Augmentation", "text": "Prior to introducing user preference augmentation, we first briefly describe the basics of user preference modeling. The user's feedback about specific items is essential to capturing user preferences from natural language conversations. To this end, we extract the mentioned items involved in the conversation history and collect the representations of these items from the entire augmented item representations E e through a lookup operation, obtaining E (m) \u2208 R m \u00d7d , where m denotes the number of mentioned items in the conversation history, d denotes the embedding dimension. Then, to better understand user preferences expressed in natural language conversations, we adopt a word-oriented KG, i.e., Concept-Net, to help align semantics between word-level information in conversations and entity-level information in the itemoriented KG following existing works (Zhou et al. 2020a;Lu et al. 2021). In detail, we utilize a GCN (Zhang et al. 2019b) to encode the ConceptNet C. The representation of each word w in the C is calculated as follows:\nV +1 c = ReLU(D -1 2 AD -1 2 V c W +1 c ),(6)\nwhere V c \u2208 R V\u00d7d are the representations of nodes and W +1 c is a learnable matrix at the + 1-th layer. A is the adjacency matrix of the graph and D is a diagonal degree matrix with entries D[i, i] = \u03a3 j A[i, j]. We then adopt a simple lookup operation to obtain the representations of the contextual words (except stop words) in the conversation history that also appeared in the ConcepNet C, denoted as\nC (m) \u2208 R c \u00d7d\n, where c denotes the length of the conversation history, d denotes the embedding dimension.\nWith the obtained representations E (m) and C (m) , we investigate how to augment them with item-aware information that may reveal the user's potential interests. Intuitively, similar users converse with the system and provide similar feedback about items and attributes. As shown in Figure 1, we use the current conversation to retrieve similar conversations (i.e., similar users) from the training corpus using BM25 (Manning, Raghavan, and Sch\u00fctze 2008). Specifically, let all conversations in the training corpus be formed as D = {H i } N i=1 , where N denotes the total number of conversations. We extract the entities (items and attributes) involved in the current conversation as the query Q, then use the BM25 algorithm to retrieve similar conversations from D. We select the top-n conversations according to the similarity score between Q and each conversation in D. The contained entities (items and attributes) in the top-n conversations are denoted as E (r) . The above process is formulated as follows:\nE (r) = Top-n(BM25(Q, {H i } N i=1 ),(7)\nSimilarly, we collect the representations of E (r) from E e through a lookup operation, denoted as E (r) .\nGiven the representations C (m) , E (m) , and E (r) , we introduce how to incorporate them together to obtain the augmented user preference representations. First, since E (m) and E (r) are calculated through the same semantic space, we combine them with a concatenation operation and then apply a self-attention operation to capture the item-oriented user preferences, which is given by:\nE (mr) = [E (m) ; E (r) ],(8)\n\u03b1 = softmax(b 1 \u2022 tanh(W 1 E (mr) )), (9) v \u1ebd = \u03b1 \u2022 E (mr)(10)\nwhere [; ] denotes the concatenation operation, W 1 is a learnable parameter matrix, and b 1 is a learnable bias. Second, we employ a similar self-attention operation on C (m) to better capture the semantics of the contextual words in the conversations, which is given by:\n\u03b2 = softmax(b 2 \u2022 tanh(W 2 C (m) )), (11\n) v w = \u03b2 \u2022 C (m)(12)\nwhere \u03b2 denotes the attention weights reflecting the importance of each word, W 2 is a learnable parameter matrix, and b 2 is a learnable bias.\nIn the end, we fuse the item-oriented user representation and word-oriented user representation through a gate, obtaining the ultimate user preference representation E u , which is given by:\nE u = \u03b3 \u2022 v \u1ebd + (1 -\u03b3) \u2022 v w, (13\n) \u03b3 = \u03c3(W 3 [v \u1ebd; v w]), (14\n)\nwhere W 3 is a learnable parameter matrix, \u03c3 denotes the Sigmoid activation function.\n[; ] denotes the concatenation operation.", "publication_ref": ["b18"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Recommendation", "text": "Given the augmented user representation E u and all augmented item representations E e , we compute the probability that recommends j-th item to a user u as follows:\nP rec (j) = softmax(E u \u2022 E e,j ),(15)\nwhere E e,j is the item representation of j-th item based on E e . Following existing works (Zhou et al. 2020a(Zhou et al. , 2022)), we apply cross-entropy loss as the optimization objective to learn the model parameters:\nL rec = - N i=1 M j=1 y ij log(P (i) rec (j)),(16)\nwhere N is the number of conversations, and i is the index of a conversation. M is the number of items, and j is the index of an item. y ij denotes the item label. During inference, we utilize Eq. 15 to rank all candidate items from the item set I and select top-k items as the recommended set.", "publication_ref": ["b41"], "figure_ref": [], "table_ref": []}, {"heading": "Response Generation", "text": "Following existing works (Zhou et al. 2020a;Lu et al. 2021), we adopt the widely-used language generation model Transformer (Vaswani et al. 2017) as the backbone model for response generation. We first use a Transformer encoder to encode conversation history H, obtaining the hidden representations\nH = (h 1 , h 2 , \u2022 \u2022 \u2022 , h n ).\nThen, we adopt a Transformer decoder with the encoder-decoder attention mechanism, where the conditional generation distribution is approximated following Zhou et al. (2020a):\nP \u03b8 (y t |y <t ) = softmax(Ws t + b) (17) s t = Transformer(s t-1 , H, C (m) , E (mr) ) (18)\nwhere s t denotes decoder hidden state at t-th time step, W and b are trainable parameters. We train the Transfomer language model by minimizing the negative log-likelihood as follows:\nL gen = - 1 T T t=1 log P \u03b8 (y t |y <t ), (19\n)\nwhere T is the length of the response. During inference, we employ the trained model to generate an appropriate utterance word by word in response to the user.", "publication_ref": ["b18", "b29"], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Setup Datasets", "text": "We conduct experiments on two widely-used CRS datasets, namely REDIAL (Li et al. 2018)  For the REDIAL dataset, we directly utilize the annotated relations (\"like\" or \"dislike\") regarding the user's attitudes toward an item in each conversation. Then we extract various user-item pairs with like or dislike relations to construct an interactive user-item graph accordingly. For the TG-ReDial dataset, we automatically detect the like or dislike relations with a predefined keyword set (e.g., \"love\", \"fear\", etc.) from all conversation utterances. In addition, the items that are accepted by the user at the end of a conversation are viewed as the \"liked\" items, while the items that are rejected are viewed as \"disliked\" ones. Similarly, we construct another interactive user-item graph.", "publication_ref": ["b11"], "figure_ref": [], "table_ref": []}, {"heading": "Baseline Methods", "text": "We compare our method with several competitive baseline models: (1) ReDial (Li et al. 2018): It is the benchmark model released in the REDIAL dataset. Basically, it consists of a recommendation module based on auto-encoder (He, Zhuo, and Law 2017) and a response generation module using HRED (Serban et al. 2017). ( 2 5) KGSF (Zhou et al. 2020a): It employs mutual information maximization to align the semantics between words in the conversation and items in the knowledge graph. ( 6) NTRD (Liang et al. 2021): It decouples dialogue generation from item recommendation via a two-stage strategy, which makes the system more flexible and controllable. ( 7) CR-Walker (Ma, Takanobu, and Huang 2021): It performs tree-structured reasoning on knowledge graphs and generates informative dialog acts to guide response generation. ( 8) RevCore (Lu et al. 2021): It proposes a review-enhanced framework that uses item reviews to improve recommendation and response generation, where the item reviews are selected by sentiment-aware retrieval.\nFor a fair comparison, we adopt the implementations of all the above models implemented by the open-source CRS toolkit CRSLab (Zhou et al. 2021).", "publication_ref": ["b11", "b7", "b26", "b14", "b19", "b18", "b37"], "figure_ref": [], "table_ref": []}, {"heading": "Evaluation Metrics", "text": "Following many existing works, we evaluate the performance of a CRS model in terms of both recommendation and response generation. The automatic metrics for recommendation evaluation are Recall@k (R@k, k= 1, 10, 50) and Mean Reciprocal Rank@k (MRR@k, k= 1, 10, 50), which evaluate whether the model's recommended top-k items hit the ground truth items provided by human recommenders. The evaluation of response generation includes automatic and human evaluations. For automatic evaluation, we adopt the perplexity (PPL), BLEU-2,3 (Papineni et al. 2002) and Distinct n-gram (DIST-n, n = 2, 3, 4) (Chen et al. 2019;Zhou et al. 2020a). The perplexity is a measurement for the fluency of natural language, where lower perplexity refers to higher fluency. The BLEU-2,3 measure word overlaps of the generated responses and the ground truth responses. The DIST-n measures the diversity of the generated responses at the sentence-level. For human evaluation, we recruit three annotators to evaluate the generated responses manually. The annotators are required to rate a score in the range {0, 1, 2} to each generated response from fluency and informativeness, following (Zhou et al. 2020a;Zhang et al. 2021). We calculate the Fleiss's kappa (Fleiss 1971) to measure the inter-annotator agreement and adopt the average score of three annotators as the human evaluation result.", "publication_ref": ["b22", "b1", "b36", "b4"], "figure_ref": [], "table_ref": []}, {"heading": "Implementation Details", "text": "We implement our approach with Pytorch. The hidden dimension is set to 128 and 300 for the recommendation module and response generation module, respectively. For the BM25 algorithm, the number of the top conversations n is set to 1. The max length of conversation history is limited to 256. For both R-GCN and GCN, the number of layers is set to 2 in consideration of efficacy and efficiency. The embeddings of both RCGN and GCN are randomly initialized. The normalization factor of R-GCN is set to 1.0 by default. We use the pretrained 300-d word2vec (Mikolov et al. 2013) embeddingsfoot_0 for Transformer during response generation. During training, we use the Adam (Kingma and Ba 2015) optimizer with an initial learning rate of 0.001 and a gradient clipping strategy to restrict the gradients within [0, 0.1]. The batch size is set to 256. We train our model with 30 epochs for both recommendation and response generation. During testing, we use the greedy search algorithm to generate responses, where the max decoding length is set to 30.", "publication_ref": ["b21", "b9"], "figure_ref": [], "table_ref": []}, {"heading": "REDIAL TG-ReDial", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Model", "text": "R@1 R@10 R@50 MRR@1 MRR@10 MRR@50 R@1 R@10 R@50 MRR@1 MRR@10 MRR@50 ReDial 0.020 0.140 0.320 0.020 ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Results and Analysis Evaluation on Recommendation", "text": "The evaluation results of recommendation on the two datasets are reported in Table 2. The best result in terms of the corresponding metric is highlighted in boldface. The CR-Walker is not evaluated on the TG-ReDial dataset owing to a lack of pre-constructed reasoning trees. As shown in Table 2, the ReDial model performs inferior compared with other models since it utilized no external KG to enrich the item representations. By using an item-oriented KG (i.e., DBpedia) as external knowledge, KECRS achieves more accurate recommendations. Both KBRD and KGSF achieve significant improvements since they integrate recommendation and response generation through joint learning. Besides, RevCore performs better than other baseline models by utilizing item reviews to enhance item representations.\nAs shown in Table 2, we observe that our COLA outperforms all baseline models in terms of all metrics. For example, our model obtains 4.5% and 7.5% improvements compared to RevCore in terms of R@10 and R@50 on the REDIAL dataset, which shows our augmented item representations and user representations benefit the model to make more accurate recommendations. For the rank of the recommended items, our model also outperforms other models as shown by the MRR metrics on both two datasets. Additionally, we observe that all models obtain much lower recall scores on the TG-ReDial dataset compared to that on the REDIAL dataset. The reason is that the contextual items in conversations from the TG-ReDial dataset are much sparser than those in the REDIAL dataset, making it more challenging to capture user preferences and item representations and make recommendations accurately.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_2", "tab_2", "tab_2"]}, {"heading": "Ablation Study", "text": "We conducted an ablation study based on different variants of our model on the two datasets to verify the effectiveness of each component. We focus on the following components and set them for ablation experiments accordingly: (1) without the interactive user-item graph (w/o IG); (2) without the retrieved top-n conversations (w/o RT); (3) without the item-oriented KG (w/o DB), i.e., DBpedia; (4) without the word-oriented KG (w/o CN), i.e., ConceptNet.\nFrom the ablation study results reported in    Human Evaluation The human evaluation results are reported in Table 5. The Fless's kappa scores are mainly distributed in [0.4, 0.6], which denotes moderate inter-annotator agreement. We observe that the human evaluation scores of KGSF and RevCore are better than KECRS and KBRD, which demonstrate the effectiveness of using external KGs to bridge the semantic gap between items and natural language utterances. Our COLA performs the best in both metrics compared to all baseline models. By leveraging the augmented item representations and user representations, our model is able to capture user preferences effectively, which assists the model to recommend suitable items and then steer the model to generate more informative words and maintain the fluency of the generated responses.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_6"]}, {"heading": "Case Study", "text": "To present our COLA's recommendation and response generation qualities, we show an illustrative case in Figure 2. We observe that in the beginning, the user asks for a movie recommendation, and the system generates a question to clarify the user's interests. After obtaining the feedback that indicates the user likes a \"magic\" movie and is a fan of \"Harry Potter\", our COLA calculates the similarity between conversation history and the corpus with our retrieval-enhanced user preference augmentation module. With the top-1 retrieved conversation, our model better captures the user's potential interests, including the movie \"Pirates of the Caribbean\". Therefore, the system is able to recommend \"Pirates of the Caribbean\" with a higher probability. Ultimately, our model generates an appropriate response to complete the recommendation accordingly.", "publication_ref": [], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Conclusion", "text": "In this paper, we propose a collaborative augmentation (COLA) method to improve conversational recommender systems. Our COLA aims to augment item representations with user-aware information and user preference representations with item-aware information. In particular, we construct an interactive user-item graph to introduce popularity-aware information for item representation learning and propose a retrieval-enhanced approach for user preference modeling.\nExperimental results demonstrate that our method effectively outperforms various strong baseline models.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "DBpedia: A Nucleus for a Web of Open Data", "journal": "", "year": "2007", "authors": "S Auer; C Bizer; G Kobilarov; J Lehmann; R Cyganiak; Z G Ives"}, {"ref_id": "b1", "title": "Towards Knowledge-Based Recommender Dialog System", "journal": "", "year": "2019", "authors": "Q Chen; J Lin; Y Zhang; M Ding; Y Cen; H Yang; J Tang"}, {"ref_id": "b2", "title": "Towards Conversational Recommender Systems", "journal": "", "year": "2016", "authors": "K Christakopoulou; F Radlinski; K Hofmann"}, {"ref_id": "b3", "title": "Unified Conversational Recommendation Policy Learning via Graph-based Reinforcement Learning", "journal": "", "year": "2021", "authors": "Y Deng; Y Li; F Sun; B Ding; W Lam"}, {"ref_id": "b4", "title": "Measuring nominal scale agreement among many raters", "journal": "Psychological bulletin", "year": "1971", "authors": "J L Fleiss"}, {"ref_id": "b5", "title": "Advances and challenges in conversational recommender systems: A survey", "journal": "AI Open", "year": "2021", "authors": "C Gao; W Lei; X He; M De Rijke; T Chua"}, {"ref_id": "b6", "title": "INSPIRED: Toward Sociable Recommendation Dialog Systems", "journal": "", "year": "2020", "authors": "S A Hayati; D Kang; Q Zhu; W Shi; Z Yu"}, {"ref_id": "b7", "title": "Distributed-Representation Based Hybrid Recommender System with Short Item Descriptions", "journal": "", "year": "2017", "authors": "J He; H H Zhuo; J Law"}, {"ref_id": "b8", "title": "A Survey on Conversational Recommender Systems", "journal": "ACM Comput. Surv", "year": "2021", "authors": "D Jannach; A Manzoor; W Cai; L Chen"}, {"ref_id": "b9", "title": "Adam: A Method for Stochastic Optimization", "journal": "", "year": "2015", "authors": "D P Kingma; J Ba"}, {"ref_id": "b10", "title": "Interactive Path Reasoning on Graph for Conversational Recommendation", "journal": "", "year": "2020", "authors": "W Lei; G Zhang; X He; Y Miao; X Wang; L Chen; T Chua"}, {"ref_id": "b11", "title": "Towards Deep Conversational Recommendations", "journal": "", "year": "2018", "authors": "R Li; S E Kahou; H Schulz; V Michalski; L Charlin; C Pal"}, {"ref_id": "b12", "title": "Seamlessly Unifying Attributes and Items: Conversational Recommendation for Cold-start Users", "journal": "ACM Trans. Inf. Syst", "year": "2021", "authors": "S Li; W Lei; Q Wu; X He; P Jiang; T Chua"}, {"ref_id": "b13", "title": "User-Centric Conversational Recommendation with Multi-Aspect User Modeling", "journal": "", "year": "2022", "authors": "S Li; R Xie; Y Zhu; X Ao; F Zhuang; Q He"}, {"ref_id": "b14", "title": "Learning Neural Templates for Recommender Dialogue System", "journal": "", "year": "2021", "authors": "Z Liang; H Hu; C Xu; J Miao; Y He; Y Chen; X Geng; F Liang; D Jiang"}, {"ref_id": "b15", "title": "Deep Conversational Recommender in Travel", "journal": "", "year": "2019", "authors": "L Liao; R Takanobu; Y Ma; X Yang; M Huang; T Chua"}, {"ref_id": "b16", "title": "DuRec-Dial 2.0: A Bilingual Parallel Corpus for Conversational Recommendation", "journal": "", "year": "2021", "authors": "Z Liu; H Wang; Z Niu; H Wu; W Che"}, {"ref_id": "b17", "title": "Towards Conversational Recommendation over Multi-Type Dialogs", "journal": "", "year": "2020", "authors": "Z Liu; H Wang; Z Niu; H Wu; W Che; T Liu"}, {"ref_id": "b18", "title": "RevCore: Review-Augmented Conversational Recommendation", "journal": "", "year": "2021", "authors": "Y Lu; J Bao; Y Song; Z Ma; S Cui; Y Wu; X He"}, {"ref_id": "b19", "title": "CR-Walker: Tree-Structured Graph Reasoning and Dialog Acts for Conversational Recommendation", "journal": "", "year": "2021", "authors": "W Ma; R Takanobu; M Huang"}, {"ref_id": "b20", "title": "Introduction to information retrieval", "journal": "Cambridge University Press", "year": "2008", "authors": "C D Manning; P Raghavan; H Sch\u00fctze"}, {"ref_id": "b21", "title": "Distributed Representations of Words and Phrases and their Compositionality", "journal": "", "year": "2013", "authors": "T Mikolov; I Sutskever; K Chen; G S Corrado; J Dean"}, {"ref_id": "b22", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation", "journal": "", "year": "2002", "authors": "K Papineni; S Roukos; T Ward; W Zhu"}, {"ref_id": "b23", "title": "Learning to Ask Appropriate Questions in Conversational Recommendation", "journal": "", "year": "2021", "authors": "X Ren; H Yin; T Chen; H Wang; Z Huang; K Zheng"}, {"ref_id": "b24", "title": "Collaborative Filtering Recommender Systems", "journal": "Springer", "year": "2007", "authors": "J B Schafer; D Frankowski; J L Herlocker; S Sen"}, {"ref_id": "b25", "title": "Modeling Relational Data with Graph Convolutional Networks", "journal": "ESWC", "year": "2018", "authors": "M S Schlichtkrull; T N Kipf; P Bloem; R Van Den Berg; I Titov; M Welling"}, {"ref_id": "b26", "title": "A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues", "journal": "", "year": "2017", "authors": "I V Serban; A Sordoni; R Lowe; L Charlin; J Pineau; A C Courville; Y Bengio"}, {"ref_id": "b27", "title": "ConceptNet 5.5: An Open Multilingual Graph of General Knowledge", "journal": "", "year": "2017", "authors": "R Speer; J Chin; C Havasi"}, {"ref_id": "b28", "title": "Conversational Recommender System", "journal": "", "year": "2018", "authors": "Y Sun; Y Zhang"}, {"ref_id": "b29", "title": "Attention is All you Need", "journal": "", "year": "2017", "authors": "A Vaswani; N Shazeer; N Parmar; J Uszkoreit; L Jones; A N Gomez; L Kaiser; I Polosukhin"}, {"ref_id": "b30", "title": "Finetuning Large-Scale Pre-trained Language Models for Conversational Recommendation with Knowledge Graph", "journal": "", "year": "2021", "authors": "L Wang; H Hu; L Sha; C Xu; K Wong; D Jiang"}, {"ref_id": "b31", "title": "Comparisonbased Conversational Recommender System with Relative Bandit Feedback", "journal": "", "year": "2021", "authors": "Z Xie; T Yu; C Zhao; S Li"}, {"ref_id": "b32", "title": "User Memory Reasoning for Conversational Recommendation", "journal": "", "year": "2020", "authors": "H Xu; S Moon; H Liu; B Liu; P Shah; P S Yu"}, {"ref_id": "b33", "title": "Adapting User Preference to Online Feedback in Multi-round Conversational Recommendation", "journal": "", "year": "2021", "authors": "K Xu; J Yang; J Xu; S Gao; J Guo; J Wen"}, {"ref_id": "b34", "title": "Text-Based Interactive Recommendation via Constraint-Augmented Reinforcement Learning", "journal": "", "year": "2019", "authors": "R Zhang; T Yu; Y Shen; H Jin; C Chen"}, {"ref_id": "b35", "title": "Graph convolutional networks: a comprehensive review", "journal": "Computational Social Networks", "year": "2019", "authors": "S Zhang; H Tong; J Xu; R Maciejewski"}, {"ref_id": "b36", "title": "KECRS: Towards Knowledge-Enriched Conversational Recommendation System", "journal": "", "year": "2021", "authors": "T Zhang; Y Liu; P Zhong; C Zhang; H Wang; C Miao"}, {"ref_id": "b37", "title": "CRSLab: An Open-Source Toolkit for Building Conversational Recommender System", "journal": "", "year": "2021", "authors": "K Zhou; X Wang; Y Zhou; C Shang; Y Cheng; W X Zhao; Y Li; J Wen"}, {"ref_id": "b38", "title": "Improving Conversational Recommender Systems via Knowledge Graph based Semantic Fusion", "journal": "", "year": "2020", "authors": "K Zhou; W X Zhao; S Bian; Y Zhou; J Wen; J Yu"}, {"ref_id": "b39", "title": "Leveraging Historical Interaction Data for Improving Conversational Recommender System", "journal": "", "year": "2020", "authors": "K Zhou; W X Zhao; H Wang; S Wang; F Zhang; Z Wang; J Wen"}, {"ref_id": "b40", "title": "Towards Topic-Guided Conversational Recommender System", "journal": "", "year": "2020", "authors": "K Zhou; Y Zhou; W X Zhao; X Wang; J Wen"}, {"ref_id": "b41", "title": "C 2 -CRS: Coarse-to-Fine Contrastive Learning for Conversational Recommender System", "journal": "", "year": "2022", "authors": "Y Zhou; K Zhou; W X Zhao; C Wang; P Jiang; H Hu"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: Overview of our proposed collaborative augmentation (COLA) method for CRS.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": ") KBRD (Chen et al. 2019): It adopts an item-oriented knowledge graph to improve the semantics of contextual items in conversations and then employs a Transformer (Vaswani et al. 2017) for response generation. (3) TG-ReDial (Zhou et al. 2020c): It is the benchmark model released in the TG-ReDial dataset, which first predicts topics or items and then generates corresponding responses based on the predicted topics or items. (4) KECRS (Zhang et al. 2021): It introduces an external high-quality KG and is trained with Bag-of-Entity loss to better capture user preferences for conversational recommendation. (", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 :2Figure 2: An illustrative case produced by our COLA on the REDIAL dataset.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": ". Specifically,", "figure_data": "User-Item Interactive Graph \ud835\udca2Contained Entities(items and attributes)CeliaJulialikeEndgameThe BFGEndgamedislikeli k elikelikedislikeThe BFGMatrixThe Matrix ReloadedJackRGCNRGCNLion KingEntities (items and attributes)Movie Embeddings Movie Embeddings Item Representation \ud835\udc6c \",$Spider-ManMatrix, The \u2026Lookup TableSelf-AttentionMatching\ud835\udf0eUser Representation \ud835\udc6c !watch, great, \u2026Lookup TableSelf-AttentionWordsGCNResponse GenerationTransformerResponse System: Then I would recommendConversation HistorySpider-Man."}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Statistics of the REDIAL and TG-ReDial datasets.", "figure_data": "and TG-ReDial (Zhou et al.2020c). The REDIAL dataset is collected by crowd-sourcedworkers and contains 10,006 conversations about Englishmovies. The TG-ReDial dataset is constructed from 10,000conversations between a user and a recommender in a topic-guided way, with all topics concerning Chinese movies. Bothtwo datasets are split into training/validation/testing sets witha ratio of 8:1:1. Overall, the statistics of the REDIAL andTG-ReDial datasets are shown in Table 1.DatasetREDIAL TG-ReDial# Users9561,482# Conversations10,00610,000# Utterances182,150129,392# Items64,36233,834# Words / Utterance14.519.0# Items / Conversation4.23.0# Turns / Conversation15.012.0"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Evaluation results of recommendation on the REDIAL dataset and TG-ReDial dataset. The best results are highlighted in bold and the improvements are statistically significant compared to baselines (t-test with p-value < 0.05).", "figure_data": "0.0720.0750.000 0.0020.0130.0000.0020.004"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "", "figure_data": ", we"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Ablation results of recommendation on the REDIAL dataset and TG-ReDial dataset.", "figure_data": "observe that each component contributes to making moreaccurate recommendations. In particular, the performanceof COLA w/o DB drops sharply in both two datasets interms of all metrics. It shows that the external item-orientedKG is essential since it contains items' rich attributes thatbenefit the system to represent the items more effectively.Besides, the R@10 of COLA w/o IG declines by 4.5% onthe ReDial dataset, demonstrating that the item popularity-aware information benefits the system to augment item repre-sentations and make more accurate recommendations. TheR@10 of COLA w/o RT on the REDIAL dataset deceases by2.7%, which indicates that the retrieved conversations helpthe model to capture user preferences better and recommendappropriate items accordingly. The results of COLA w/o CNon two datasets verify that introducing a commonsense graphhelps recommendation since it aligns the semantics betweenword-level information in conversations and entity-level in-formation in item-oriented knowledge graphs.Evaluation on Response GenerationAutomatic Evaluation Our automatic evaluation results ofresponse generation on the REDIAL dataset and TG-ReDialdataset are reported in Table 4. The best result in terms ofthe corresponding metric is highlighted in boldface. The re-sults of the two models, TG-ReDial and CR-Walker, are notincluded in Table 4 since they utilize a pre-trained languagemodel for generation, which will bring an unfair comparison.On both two datasets, KECRS performs badly in comparisonto other models in terms of DIST-n since it tends to produce"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Automatic evaluation results of response generation on the REDIAL dataset and TG-ReDial dataset. The best results are highlighted in bold and the improvements are statistically significant compared to baselines (t-test with p-value < 0.05).", "figure_data": "ModelFluency\u03baInform.\u03baReDial1.310.410.890.48KBRD1.350.451.010.56KECRS1.400.471.270.51KGSF1.810.521.580.48RevCore1.880.481.640.59COLA (Ours)1.910.521.700.49"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Human evaluation results on the REDIAL dataset.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "k +1 e = ReLU( r\u2208R k e \u2208E r e 1 Z e,r W k,r k e + W k k e ),(1)", "formula_coordinates": [3.0, 63.59, 321.29, 228.91, 28.41]}, {"formula_id": "formula_1", "formula_text": "E K = {k e,1 , k e,2 , \u2022 \u2022 \u2022 , k e,m },", "formula_coordinates": [3.0, 169.02, 459.73, 124.73, 9.68]}, {"formula_id": "formula_2", "formula_text": "G = u, r, e , u \u2208 U, e \u2208 I, r \u2208 R G ,(2)", "formula_coordinates": [3.0, 100.16, 632.27, 192.34, 9.65]}, {"formula_id": "formula_3", "formula_text": "v +1 G,e = ReLU( r\u2208R G u\u2208G r e 1 Z e,r W G,r v u + W G v G,e ), (3) v +1 G,u = ReLU( r\u2208R G e\u2208G r u 1 Z u,r W G,r v e + W G v G,u ),(4)", "formula_coordinates": [3.0, 325.58, 296.7, 232.43, 60.45]}, {"formula_id": "formula_4", "formula_text": "E G = {v e,1 , v e,2 , \u2022 \u2022 \u2022 , v e,m }", "formula_coordinates": [3.0, 319.5, 464.56, 116.54, 9.68]}, {"formula_id": "formula_5", "formula_text": "E e,j = k e,j + v e,j(5)", "formula_coordinates": [3.0, 400.69, 513.48, 157.31, 9.68]}, {"formula_id": "formula_6", "formula_text": "k e,j \u2208 E K , v e,j \u2208 E G , j \u2208 [1, m].", "formula_coordinates": [3.0, 345.97, 529.51, 137.46, 9.68]}, {"formula_id": "formula_7", "formula_text": "V +1 c = ReLU(D -1 2 AD -1 2 V c W +1 c ),(6)", "formula_coordinates": [4.0, 92.86, 116.52, 199.64, 13.99]}, {"formula_id": "formula_8", "formula_text": "C (m) \u2208 R c \u00d7d", "formula_coordinates": [4.0, 54.0, 214.06, 58.88, 13.18]}, {"formula_id": "formula_9", "formula_text": "E (r) = Top-n(BM25(Q, {H i } N i=1 ),(7)", "formula_coordinates": [4.0, 101.71, 432.92, 190.79, 12.69]}, {"formula_id": "formula_10", "formula_text": "E (mr) = [E (m) ; E (r) ],(8)", "formula_coordinates": [4.0, 89.31, 560.91, 203.19, 9.99]}, {"formula_id": "formula_11", "formula_text": "\u03b1 = softmax(b 1 \u2022 tanh(W 1 E (mr) )), (9) v \u1ebd = \u03b1 \u2022 E (mr)(10)", "formula_coordinates": [4.0, 104.22, 577.4, 188.28, 25.18]}, {"formula_id": "formula_12", "formula_text": "\u03b2 = softmax(b 2 \u2022 tanh(W 2 C (m) )), (11", "formula_coordinates": [4.0, 103.6, 676.42, 184.75, 10.65]}, {"formula_id": "formula_13", "formula_text": ") v w = \u03b2 \u2022 C (m)(12)", "formula_coordinates": [4.0, 97.27, 676.77, 195.23, 24.84]}, {"formula_id": "formula_14", "formula_text": "E u = \u03b3 \u2022 v \u1ebd + (1 -\u03b3) \u2022 v w, (13", "formula_coordinates": [4.0, 381.5, 140.17, 172.35, 9.68]}, {"formula_id": "formula_15", "formula_text": ") \u03b3 = \u03c3(W 3 [v \u1ebd; v w]), (14", "formula_coordinates": [4.0, 388.52, 140.52, 169.48, 23.28]}, {"formula_id": "formula_16", "formula_text": ")", "formula_coordinates": [4.0, 553.85, 154.47, 4.15, 8.64]}, {"formula_id": "formula_17", "formula_text": "P rec (j) = softmax(E u \u2022 E e,j ),(15)", "formula_coordinates": [4.0, 375.86, 267.16, 182.14, 10.65]}, {"formula_id": "formula_18", "formula_text": "L rec = - N i=1 M j=1 y ij log(P (i) rec (j)),(16)", "formula_coordinates": [4.0, 368.28, 334.64, 189.72, 30.32]}, {"formula_id": "formula_19", "formula_text": "H = (h 1 , h 2 , \u2022 \u2022 \u2022 , h n ).", "formula_coordinates": [4.0, 362.82, 506.52, 94.91, 9.68]}, {"formula_id": "formula_20", "formula_text": "P \u03b8 (y t |y <t ) = softmax(Ws t + b) (17) s t = Transformer(s t-1 , H, C (m) , E (mr) ) (18)", "formula_coordinates": [4.0, 329.11, 556.69, 228.89, 23.93]}, {"formula_id": "formula_21", "formula_text": "L gen = - 1 T T t=1 log P \u03b8 (y t |y <t ), (19", "formula_coordinates": [4.0, 373.61, 636.1, 180.24, 30.2]}, {"formula_id": "formula_22", "formula_text": ")", "formula_coordinates": [4.0, 553.85, 646.83, 4.15, 8.64]}], "doi": ""}
