{"Scaling Session-Based Transformer Recommendations using Optimized Negative Sampling and Loss Functions": "Timo Wilm \u2217 timo.wilm@otto.de OTTO (GmbH & Co KG) Hamburg, Germany Philipp Normann \u2217 philipp.normann@otto.de OTTO (GmbH & Co KG) Hamburg, Germany Sophie Baumeister sophie.baumeister@otto.de OTTO (GmbH & Co KG) Hamburg, Germany", "ABSTRACT": "This work introduces TRON , a scalable session-based T ransformer R ecommender using O ptimized N egative-sampling. Motivated by the scalability and performance limitations of prevailing models such as SASRec and GRU4Rec + , TRON integrates top-k negative sampling and listwise loss functions to enhance its recommendation accuracy. Evaluations on relevant large-scale e-commerce datasets show that TRON improves upon the recommendation quality of current methods while maintaining training speeds similar to SASRec. A live A/B test yielded an 18.14% increase in click-through rate over SASRec, highlighting the potential of TRON in practical settings. For further research, we provide access to our source code 1 and an anonymized dataset 2 .", "CCS CONCEPTS": "\u00b7 Applied computing \u2192 Online shopping ; \u00b7 Information systems \u2192 Recommender systems ; \u00b7 Computing methodologies \u2192 Neural networks .", "KEYWORDS": "session-based, recommender systems, transformers, negative sampling, ranking loss function", "ACMReference Format:": "Timo Wilm, Philipp Normann, Sophie Baumeister, and Paul-Vincent Kobow. 2023. Scaling Session-Based Transformer Recommendations using Optimized Negative Sampling and Loss Functions. In Seventeenth ACM Conference on Recommender Systems (RecSys '23), September 18-22, 2023, Singapore, Singapore. ACM, New York, NY, USA, 4 pages. https://doi.org/10.1145/ 3604915.3610236 Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). ACM ISBN 979-8-4007-0241-9/23/09. https://doi.org/10.1145/3604915.3610236", "Paul-Vincent Kobow": "paul-vincent.kobow@otto.de OTTO (GmbH & Co KG) Hamburg, Germany", "1 INTRODUCTION": "Personalized real-time recommendations are a critical feature for e-commerce platforms such as OTTO . While recent advancements in deep learning models have offered promising results in sessionbased recommendations [5, 10, 13], established systems like RNN based GRU4Rec + [8] and transformer-based SASRec [10] often struggle to maintain accuracy and scalability when dealing with large item sets. To address these limitations, we introduce TRON, a session-based transformer recommendation system built upon the original SASRec, that uses top-k negative sampling and a listwise loss function to enhance accuracy and training time significantly.", "2 METHODS": "", "2.1 Negative Sampling": "Session-based recommendation systems predict the next item a user will interact with based on their previous activities within a session. A session is a sequence of user-item interactions, represented as \ud835\udc60 : = [ \ud835\udc56 1 , \ud835\udc56 2 , . . . , \ud835\udc56 \ud835\udc47 -1 , \ud835\udc56 \ud835\udc47 ] where \ud835\udc47 is the session length. The items a user has interacted with within a session are considered positive samples, denoted as P( \ud835\udc60 ) : = \ud835\udc47 -\ud835\udc58 = 1 { \ud835\udc56 \ud835\udc58 } . In contrast, items that the user has not interacted with are called negative samples, represented as N \ud835\udc60 : = I \\ P( \ud835\udc60 ) , where I is the total set of available items. Training a model to perform a next-item prediction across I is often unfeasible due to the large size of I in real-world scenarios. Consequently, a common approach is to train the model to distinguish between positive and negative samples, which can be achieved through negative sampling [15]. A major challenge in negative sampling is efficiency. Sampling directly from N \ud835\udc60 can be computationally expensive, as it requires the exclusion of items present in P( \ud835\udc60 ) . This issue becomes critical when increasing the number of negative samples, leading to extended training times [10]. An often utilized solution is to sample negatives according to a uniform distribution UI across the entire set of items I [8]. This strategy proves to be effective for large item sets, where the probability of mistakenly sampling a positive item as a negative is relatively small. Another strategy is to sample negatives from the empirical frequency FI of item interactions across all users. One method to efficiently and effectively sample negatives from FI , is in-batch negative sampling [9]. This method involves sampling negatives from the batch currently being processed. This is possible in GRU4Rec because, due to the way a batch is constructed, at each time step \ud835\udc61 , no other item from the session \ud835\udc60 except \ud835\udc56 \ud835\udc61 exists in the batch. For transformer-based models, such as SASRec, we have developed an efficient solution to employ in-batch negative sampling by excluding samples from \ud835\udc60 for batches that include all events of \ud835\udc60 . In practice, the combination of negative sampling from both UI and FI often results in enhanced model accuracy [8]. This can be achieved by sampling \ud835\udc58 negatives from UI and \ud835\udc5a negatives from FI . Consider a batch B : = [ \ud835\udc46 1 , \ud835\udc46 2 , . . . , \ud835\udc46 \ud835\udc4f ] that consists of \ud835\udc4f user sessions. At each time step \ud835\udc61 in each user session \ud835\udc60 , we sample UN \ud835\udc61 \ud835\udc60 : = [ \ud835\udc48 1 , \ud835\udc48 2 , . . . , \ud835\udc48 \ud835\udc58 ] and FN \ud835\udc61 \ud835\udc60 : = [ \ud835\udc39 1 , \ud835\udc39 2 , . . . , \ud835\udc39 \ud835\udc5a ] , where each \ud835\udc48 \ud835\udc56 is a sample from UI and each \ud835\udc39 \ud835\udc57 is a sample from FI . These samples are then concatenated to form a \ud835\udc58 + \ud835\udc5a dimensional random vector N \ud835\udc61 \ud835\udc60 : = \ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc50\ud835\udc4e\ud835\udc61 [FN \ud835\udc61 \ud835\udc60 , UN \ud835\udc61 \ud835\udc60 ] . The negative samples for the entire batch are represented as N . This sampling process can be performed in different ways: elementwise, sessionwise, or batchwise, or a combination of these methods. For the elementwise approach, N is a tensor of shape [ \ud835\udc4f,\ud835\udc47,\ud835\udc58 + \ud835\udc5a ] because negatives are sampled at each time step for each session. In sessionwise sampling, all negatives for a session are sampled at once, resulting in a tensor of shape [ \ud835\udc4f, 1 , \ud835\udc58 + \ud835\udc5a ] . With batchwise sampling, all negatives for a batch are sampled at once, leading to a tensor of shape [ 1 , 1 , \ud835\udc58 + \ud835\udc5a ] . These different sampling strategies have a significant impact on the speed of training. For instance, when a large number of negatives is used, the data transfers between the CPU and GPU can become a bottleneck, particularly with elementwise sampling. Employing sessionwise or batchwise sampling can mitigate this issue, allowing the use of more negative samples per time step while maintaining a training speed comparable to that of SASRec. TRON uses a combination of uniform batchwise and in-batch sessionwise negative sampling to maintain training speed while improving accuracy. To further optimize the negative sampling process and enhance recommendation performance TRON utilizes a top-k negative sampling strategy, which is inspired by a participant's idea from OTTO's RecSys competition on Kaggle 1 and is similar to dynamic negative item sampling [17]. This strategy focuses on updating the top-k negatives during training instead of updating the whole set of negative ratings. Initially, we sample a set of negative items N \ud835\udc61 \ud835\udc60 and obtain scores \ud835\udc5f \ud835\udc61 \ud835\udc60,\ud835\udc57 for each item \ud835\udc57 of session \ud835\udc60 at time step \ud835\udc61 in N \ud835\udc61 \ud835\udc60 . Applying the top-k function to the scored items, we select the top-k negatives KN \ud835\udc61 \ud835\udc60 : = \ud835\udc61\ud835\udc5c\ud835\udc5d\ud835\udc58 ([ \ud835\udc5f \ud835\udc61 \ud835\udc60, 1 , \ud835\udc5f \ud835\udc61 \ud835\udc60, 2 , . . . , \ud835\udc5f \ud835\udc61 \ud835\udc60, | N \ud835\udc61 \ud835\udc60 | ]) . These top-k items are then used for updates in the backpropagation step, while the rest are discarded. This strategy allows us to retain the benefits of a large negative sample set, which provides a broader context and helps in identifying harder negatives, while substantially reducing the computational load during backpropagation. By prioritizing the update of negatives that the model currently misranks as likely positives, we enhance the overall speed and accuracy of the recommender system.", "2.2 Loss Functions": "Finally, we evaluate pointwise, pairwise, and listwise ranking loss functions typically used in recommendation systems [4] to further enhance model accuracy. The pointwise loss function is binary cross-entropy (BCE) [10]. The pairwise loss function is Bayesian personalized ranking max (BPR-MAX) [8]. TRON uses sampled softmax (SSM) [2, 3], a listwise loss function with several beneficial properties, such as alleviating popularity bias and maximizing ranking metrics [16].", "3 EXPERIMENTAL SETUP": "In our evaluation, we assess the performance of our proposed model TRON, which is built upon the SASRec architecture, using three benchmark datasets: Diginetica [6], Yoochoose [1], and OTTO [14]. Each of these datasets presents increasing complexity regarding the number of events and the variety of item sets. We only use click events for our experiments, maintaining a minimum item support of five and a session length of at least two for all datasets [8]. We use a temporal train/test split method, using the last day (Yoochoose dataset) or the last week of data (Diginetica and OTTO datasets) to form the test sets. The remaining data is used for training. Table 1 provides an overview of the datasets used in our experiments. Recall@20 and MRR@20 are used as offline metrics [9]. We perform extensive assessments encompassing all events and items within the test set to ensure rigorous and dependable evaluations. We prioritize such comprehensive evaluations over sampling-based approaches because the latter have shown to be unreliable [11]. Weuse GRU4Rec + and SASRec as benchmark models. GRU4Rec + operates with a hidden size of 100. SASRec is configured with a hidden size of 200 across two layers. We introduce modifications to SASRec with two variant configurations: one with 512 uniform and 16 in-batch sessionwise negatives (SASRec M-Negs) and the other with 8192 uniform and 127 in-batch sessionwise negatives (SASRec L-Negs). Additionally, SASRec BPR-MAX adopts the BPRMAX loss, while SASRec SSM leverages an SSM loss function, both utilizing the same negative sampling strategy as SASRec L-Negs. Our proposed models TRON L-Negs and XL-Negs are both based on the SASRec architecture and use an SSM loss function. TRON L-Negs is configured with 8192 batchwise uniform and 127 in-batch sessionwise negatives, whereas TRON XL-Negs operates with 16384 batchwise uniform negatives and 127 in-batch sessionwise negatives. Both TRON models use a top-k negative sampling strategy only updating based on the top 100 negative ratings. All models are trained with a batch size of 128 using an NVIDIA Tesla V100 GPU.", "4 RESULTS": "The offline evaluation of our experiments compared to the benchmark models is presented in Table 2. The GRU4Rec + model outperforms SASRec across all datasets except MRR@20 on the Diginetica dataset. While previous studies on smaller datasets such as Diginetica indicated SASRec's superiority over GRU4Rec + [7, 12], our findings on larger datasets and realistic training times do not support this claim. This discrepancy could also be attributed to our extensive evaluation method, which avoids weaknesses associated with sampling-based evaluations [11] and does not solely rely on the last item of a session. SASRec M-Negs improves the accuracy of SASRec for the Diginetica and Yoochoose datasets but shows lower accuracy for the OTTO dataset while maintaining SASRec's original speed. SASRec L-Negs, on the other hand, exhibits slower training times across all datasets and only improves accuracy on Diginetica. This suggests that using additional negatives in a pointwise loss function such as BCE negatively impacts the model's accuracy. SASRec SSM shows promising results, outperforming GRU4Rec + on the Diginetica dataset and demonstrating competitive accuracy for the other two datasets. Our proposed model TRON shows superior accuracy across all datasets except for MRR@20 on the Yoochoose dataset while demonstrating faster training times than SASRec SSM due to batchwise and top-k negative sampling. TRON demonstrates improved scalability as the dataset grows larger, as evidenced by the decreasing relative slowdown compared to SASRec. On the OTTO dataset, TRON shows an accuracy increase of more than 6.5% in both Recall@20 and MRR@20, as well as a training speedup of 1090% compared to GRU4Rec + . Despite handling more negatives, TRON maintains 92% of SASRec's training speed. In the online experiment , we trained TRON XL-Negs, SASRec SSM, and SASRec on a private OTTO dataset from the two most recent weeks using the same preprocessing as described in Section 3. The Recall@20 for each epoch and model on the test set can be seen in Figure 1. The live improvement of TRON XL-Negs and SASRec SSM relative to SASRec measured from May 9 to May 17 2023 is shown in Figure 2. The results validate the effectiveness of 1 2 3 4 5 6 7 8 9 10 0 . 1 0 . 2 0 . 3 0 . 4 Epochs Recall@20 TRON XL-Negs SASRec SSM SASRec CTR carts units 0 10 20 30 Uplift in % TRON XL-Negs SASRec SSM TRON in a real-world e-commerce setting, showing an increase of 18.14% in click-through rate, 23.85% increase in add-to carts and 23.67% uplift in units compared to SASRec.", "5 CONCLUSION": "Our proposed TRON model significantly improves the accuracy and training time of transformer-based recommendation systems on large e-commerce datasets. This enhancement is achieved through the strategic optimization of negative sampling methods, utilization of listwise loss functions, and focusing on the most misranked negatives.", "6 SPEAKER BIO": "Timo Wilm , Philipp Normann , and Sophie Baumeister form a data science trio at OTTO 's recommendation team. Wilm and Normann are Senior Data Scientists with over five years of experience in e-commerce, specializing in the design and integration of cutting-edge deep learning models. Baumeister, a Junior Data Scientist, has been with the team for over one year. Together with their team, they are responsible for the development and maintenance of OTTO 's recommendation systems, which are used by millions of customers every day.", "REFERENCES": "[1] David Ben-Shimon, Alexander Tsikinovsky, Michael Friedmann, Bracha Shapira, Lior Rokach, and Johannes Hoerle. 2015. RecSys Challenge 2015 and the YOOCHOOSE Dataset. In Proceedings of the 9th ACM Conference on Recommender Systems . ACM, Vienna Austria, 357-358. https://doi.org/10.1145/2792838.2798723 [2] Yoshua Bengio and Jean-S\u00e9bastien Senecal. 2003. Quick Training of Probabilistic Neural Nets by Importance Sampling. In International Workshop on Artificial Intelligence and Statistics . PMLR, 17-24. https://proceedings.mlr.press/r4/bengio03a. html [3] Y. Bengio and J.-S. Senecal. 2008. Adaptive Importance Sampling to Accelerate Training of a Neural Probabilistic Language Model. IEEE Transactions on Neural Networks 19, 4 (April 2008), 713-722. https://doi.org/10.1109/TNN.2007.912312 [4] Wei Chen, Tie-Yan Liu, Yanyan Lan, Zhiming Ma, and Hang Li. 2009. Ranking measures and loss functions in learning to rank. In Proceedings of the 22nd International Conference on Neural Information Processing Systems (NIPS'09) . Curran Associates Inc., Red Hook, NY, USA, 315-323. https://dl.acm.org/doi/10.5555/ 2984093.2984129 [5] Gabriel De Souza Pereira Moreira, Sara Rabhi, Jeong Min Lee, Ronay Ak, and Even Oldridge. 2021. Transformers4Rec: Bridging the Gap between NLP and Sequential / Session-Based Recommendation. In Fifteenth ACM Conference on Recommender Systems . ACM, Amsterdam Netherlands, 143-153. https://doi.org/ Timo Wilm, Philipp Normann, Sophie Baumeister, and Paul-Vincent Kobow 10.1145/3460231.3474255 [6] DIGINETICA. 2016. CIKM Cup 2016 Track 2: Personalized E-Commerce Search Challenge. https://competitions.codalab.org/competitions/11161 [7] Zhankui He, Handong Zhao, Zhaowen Wang, Zhe Lin, Ajinkya Kale, and Julian Mcauley. 2022. Query-Aware Sequential Recommendation. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management . ACM, Atlanta GA USA, 4019-4023. https://doi.org/10.1145/3511808.3557677 [8] Bal\u00e1zs Hidasi and Alexandros Karatzoglou. 2018. Recurrent Neural Networks with Top-k Gains for Session-based Recommendations. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management . 843-852. https://doi.org/10.1145/3269206.3271761 [9] Bal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based Recommendations with Recurrent Neural Networks. In 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings , Yoshua Bengio and Yann LeCun (Eds.). https://doi.org/10.48550/arXiv.1511.06939 [10] W.KangandJ. McAuley. 2018. Self-Attentive Sequential Recommendation. In 2018 IEEE International Conference on Data Mining (ICDM) . IEEE Computer Society, Los Alamitos, CA, USA, 197-206. https://doi.org/10.1109/ICDM.2018.00035 [11] Walid Krichene and Steffen Rendle. 2020. On Sampled Metrics for Item Recommendation. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . ACM, Virtual Event CA USA, 1748-1757. https://doi.org/10.1145/3394486.3403226 [12] Ming Li, Ali Vardasbi, Andrew Yates, and Maarten de Rijke. 2023. Repetition and Exploration in Sequential Recommendation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '23) . Association for Computing Machinery, New York, NY, USA, 2532-2541. https://doi.org/10.1145/3539618.3591914 [13] M. Jeffrey Mei, Cole Zuber, and Yasaman Khazaeni. 2022. A Lightweight Transformer for Next-Item Product Recommendation. In Sixteenth ACM Conference on Recommender Systems . ACM, Seattle WA USA, 546-549. https: //doi.org/10.1145/3523227.3547491 [14] Philipp Normann, Sophie Baumeister, and Timo Wilm. 2023. OTTO Recommender Systems Dataset. https://doi.org/10.34740/KAGGLE/DSV/4991874 [15] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI '09) . AUAI Press, Arlington, Virginia, USA, 452-461. https://dl.acm.org/doi/10.5555/ 1795114.1795167 [16] Jiancan Wu, Xiang Wang, Xingyu Gao, Jiawei Chen, Hongcheng Fu, Tianyu Qiu, and Xiangnan He. 2022. On the Effectiveness of Sampled Softmax Loss for Item Recommendation. ArXiv abs/2201.02327 (2022). https://doi.org/10.48550/ARXIV. 2201.02327 [17] Weinan Zhang, Tianqi Chen, Jun Wang, and Yong Yu. 2013. Optimizing top-n collaborative filtering via dynamic negative item sampling. In Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval . ACM, Dublin Ireland, 785-788. https://doi.org/10.1145/ 2484028.2484126"}
