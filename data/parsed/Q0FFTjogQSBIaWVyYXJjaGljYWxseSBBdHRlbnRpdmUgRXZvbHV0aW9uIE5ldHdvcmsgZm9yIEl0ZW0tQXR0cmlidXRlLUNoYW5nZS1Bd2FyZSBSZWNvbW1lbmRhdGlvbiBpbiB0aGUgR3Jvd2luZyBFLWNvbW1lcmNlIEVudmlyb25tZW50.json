{"title": "CAEN: A Hierarchically Attentive Evolution Network for Item-Attribute-Change-Aware Recommendation in the Growing E-commerce Environment", "authors": "Rui Ma; Ning Liu; Jingsong Yuan; Huafeng Yang; Jiandong Zhang", "pub_date": "2022-08-29", "abstract": "Traditional recommendation systems mainly focus on modeling user interests. However, the dynamics of recommended items caused by attribute modifications (e.g. changes in prices) are also of great importance in real systems, especially in the fast-growing e-commerce environment, which may cause the users' demands to emerge, shift and disappear. Recent studies that make efforts on dynamic item representations treat the item attributes as side information but ignore its temporal dependency, or model the item evolution with a sequence of related users but do not consider item attributes. In this paper, we propose Core Attribute Evolution Network (CAEN), which partitions the user sequence according to the attribute value and thus models the item evolution over attribute dynamics with these users. Under this framework, we further devise a hierarchical attention mechanism that applies attribute-aware attention for user aggregation under each attribute, as well as personalized attention for activating similar users in assessing the matching degree between target user and item. Results from the extensive experiments over actual e-commerce datasets show that our approach outperforms the state-of-art methods and achieves significant improvements on the items with rapid changes over attributes, therefore helping the item recommendation to adapt to the growth of the e-commerce platform.", "sections": [{"heading": "INTRODUCTION", "text": "With the rapid technology development on the internet, logistics, and payments, products from different regions and industries are constantly gathered on worldwide e-commerce platforms and then served to online customers. To better match the users with satisfying products, recommendation systems that focus on Click-Through Rate (CTR) prediction play an indispensable role in these large-scale business platforms. Existing studies on CTR prediction [3,14,26,27] have intensively modeled the long and short-term, emerging or disappeared user interests, by leveraging their past sequential behaviors with advanced deep neural structures. These state-of-the-art methods work fine under a stable recommendation environment, but can hardly be applied to the growing e-commerce environment.\nIn e-commerce recommendation systems, recommended items may change rapidly due to outside interference. The interference includes both manual operations like claiming the free shipping promotion or modifying the selling price, and environmental factors like public festivals or natural disasters, which can therefore cause the users' preferences to emerge, shift, and disappear. For example in Figure 1, a high-priced product should have been recommended to people with high income, but once with a heavy discount, it could also meet the requirement of the price-sensitive customers. These active actions on items' core attributes from sellers can happen frequently and are encouraged by the platform operators, as they are helpful for the development of a commercial market. However, these changes could not be well captured by the structures that are based solely on users' past behaviors, which emphasizes the urgency of considering the item evolution in the growing e-commerce environment.\nRecently, research efforts have been made on the dynamic item representation [5,9,[17][18][19]. Some studies have reorganized the past user-item interaction data and make use of the users who have interacted with the target item. Specifically, Wang et al. [18] establish a long short-term memory network over the past interaction sequence of the item, Guo et al. [5] apply an attention network to extract the most similar users from the item interaction history according to the target user, and Li et al. [9] further propose a timeaware evolution layer, which can capture the rapid item changes in popularity. Li et al.'s work is typical for capturing the temporal changes of items as well as modeling the dynamic item representation. However, there remain two major challenges: A) The change of item attributes, which greatly affects users' decision-making outside their usual interests, should not be ignored. B) Modeling item evolution under interaction granularity (regarding one interaction between user and item as one state) results in information redundancy and unnecessary complexity. Applying recurrent networks upon highly similar interactive logs leads to poor computing efficiency, thus restricting the model capacity over the time span of item history.\nIn this paper, we propose Core Attributes Evolution Network (CAEN) to address the aforementioned challenges. The item behavior sequence, which is a set of users in chronological order that have interacted with the target item, is partitioned into several states according to the value of its item attribute. Then, the item evolution is modeled under such attribute dynamics with corresponding users. Under this framework, we further devise a hierarchical attention network that includes a two-stage attentive mechanism. The later stage applies a personalized attention layer, which activates similar users from interaction history in assessing the matching degree of the target user. More significantly, in the first stage, we apply an attribute-aware attention layer, which can accurately acquire the item representation of a certain time by putting more weights on the users that are attracted by the attribute of that time. Given that there is not yet a public dataset that includes attribute changes of recommended items, we conduct our experiment on an actual e-commerce dataset in Southeast Asia. Experiment results show that our proposed method can effectively improve recommendation performance, especially for the items with rapidly changing attributes. The main contributions of this work can be summarized below:\n\u2022 To the best of our knowledge, this is the first work to exploit item attribute evolution in CTR prediction. By capturing the item change over attribute dynamics, such a framework enables the personalized item recommendations to adapt to the frequent item attribute modification in the growing e-commerce environment. \u2022 We propose a hierarchical attention mechanism inside item evolution modeling. Underneath the personalized attention, attribute-aware attention is applied to improve the item representation learning by activating the interactions that are caused by the specific attribute. This mechanism is of particular benefit to our concept of attribute evolution modeling. \u2022 We evaluate the proposed method on a CTR prediction task over actual e-commerce datasets in Southeast Asia. Experiment results show that our method outperforms the state of the arts, especially on the items with rapid changes over attributes, demonstrating the effectiveness of capturing the dynamics in item recommendation.", "publication_ref": ["b2", "b13", "b25", "b26", "b4", "b8", "b16", "b17", "b18", "b17", "b4", "b8"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "RELATED WORK", "text": "Previous studies on personalized recommendation propose to leverage the past interactions between users and items. These methods mostly focus on modeling users' interests, while only a few consider the item attributes and dynamics.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Sequential Modeling on User Behavior", "text": "Early methods are mostly based on matrix factorization (MF) and Markov chains (MC) [2,11], however, these methods only consider the local patterns of adjacent behaviors. Recently, deep neural networks have attracted researchers' attention due to their advanced capabilities in sequence modeling, especially the recurrent neural networks (RNN) [1,6]. Further, parallel models, including convolutional neural network [15] and attention network [7,12,25], are proposed with better efficiency in dealing with long sequences. In addition, the graph neural network [22] is also applied in sequential recommendation thanks to its excellent representation capability on structured data. The above methods achieve satisfactory results over corresponding datasets, which are collected in relatively stable environments. However, in the growing e-commerce environment, recommended items can change rapidly and further affect users' preferences. These methods can be incompetent when dealing with ubiquitous changes.", "publication_ref": ["b1", "b10", "b0", "b5", "b14", "b6", "b11", "b24", "b21"], "figure_ref": [], "table_ref": []}, {"heading": "Modeling on Item Attributes and Dynamics", "text": "Recent work for item modeling in recommendations mainly includes two aspects: interaction behaviors and item attribute modeling. On the one hand, rich user-item interaction information can help to capture the item dynamics in a temporal evolution. Some studies [5,9,18] aims to extract dynamic representations of the item by modeling the sequential users who interact with it. On the other hand, item attributes are high-availability and high-value information for the recommendation system, thus they are widely used to mitigate the sparse interaction data problem. Recently, item attributes have been utilized as side information in both matrix factorization (MF) [23] and deep neural networks [13]. Moreover, some studies [17,24] exploit the correlation between an item and its attribute in user behavior sequence. Besides, Wu et al. [19] developed a multi-task framework to realize co-optimization of attribute inference and item recommendation for item embedding learning.\nHowever, the above methods do not consider the attribute changes of a particular item and the corresponding impact on the user. Therefore, we propose to model item evolution by capturing the dynamics of item attributes and leveraging the attributes to obtain a better representation in interactions behaviors modeling.", "publication_ref": ["b4", "b8", "b17", "b22", "b12", "b16", "b23", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "METHODOLOGY", "text": "In this section, we first specify the research problem and the preliminary. Then we present our whole framework of item attribute evolution network. Later, we expand how we organize and model the attribute-based state, and elucidate how we emphasize the impact of item attributes on user-item interactions through a hierarchical attention network. At the end of this section, we introduce the deployment of our method into downstream applications.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Problem Statement", "text": "In recommendation systems, the click-through rate \ud835\udc66, which is also the probability of interaction between the target user \ud835\udc62 and target item \ud835\udc56, is usually estimated by the information from four modules including the User Profile G 1 (\ud835\udc62), Item Profile G 2 (\ud835\udc56), User Behavior Modeling G 3 (\ud835\udc62), and the Item Behavior Modeling G 4 (\ud835\udc56), as shown on the right side of Figure 2. For target user \ud835\udc62 and target item \ud835\udc56, let I \ud835\udc62 = \ud835\udc56 1 \ud835\udc62 , \ud835\udc56 2 \ud835\udc62 , ..., \ud835\udc56 \ud835\udc41 \ud835\udc62 denote the \ud835\udc41 items that have interacted with user \ud835\udc62, and U \ud835\udc56 = \ud835\udc62 1 \ud835\udc56 , \ud835\udc62 2 \ud835\udc56 , ..., \ud835\udc62 \ud835\udc40 \ud835\udc56 denote the \ud835\udc40 users that have interacted with item \ud835\udc56. Therefore, the probability of interaction between \ud835\udc62 and \ud835\udc56 can be expressed as:\n\u0177 = \ud835\udc43 \ud835\udc50\ud835\udc61\ud835\udc5f (\ud835\udc62, \ud835\udc56) = F G 1 (\ud835\udc62), G 2 (\ud835\udc56), G 3 (I \ud835\udc62 ), G 4 (U \ud835\udc56 ) ,(1)\nwhere F denotes the top decision layer.\nIn this paper, we mainly focus on the module of Item Behavior Modeling G 4 (\ud835\udc56), which targets to leverage U \ud835\udc56 in an effective way to adapt to the item evolution over its attribute dynamics.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Core Attributes Evolution Framework", "text": "There are serveral attributes over a given item on the e-commerce platform, among which some attributes can significantly affect the users' behavior, and can also vary over time due to different reasons. These attributes are called the core attributes, which include price, promotion, free shipping, warranty service, etc.\nSince the items change along with their attributes, we propose to partition and model the lifecycle of these items based on their attribute variations. The framework of our CAEN is composed of 5 layers, 2 of which form the Hierarchical Attention Network (HAN) and will be mathematically expanded in the next subsection:\n\u2022 Attribute-Based State Partition Layer (SPL): In this layer, the lifecycle of the target item is partitioned into several states according to the change of its attribute value. A group of features under each state, i.e., the attribute value, users that have interacted with this item, as well as the time stamps under each state are organized to be embedded and fed into the next layer. \u2022 Attribute Attention Layer (AAL): This layer is applied in each state for aggregating the related users. Instead of a simple pooling structure or a multiple pooling strategy, an attentive pooling using attribute is applied to attach importance to the interactions that are attracted by the attribute, other than the constant user interests. Therefore, this layer outputs the representations of user groups under each attribute value, which can also be seen as the representations of each attribute state. \u2022 State Evolution Layer (SEL): Given that the item attributes are changed consecutively over time, item popularity is not only determined by its current attribute but also by its past. Here, GRU cells are applied over each attribute state to model the evolution of the target item. The output of AAL is input into a GRU cell, then the hidden state is regarded as the item representation under the corresponding attribute, and also passed to the next state. \u2022 Personalized Attention Layer (PAL): In this layer, the target user and current attribute are concatenated as query, while the item representations are concatenated with corresponding attributes as key. Therefore, the weights of attribute states are calculated by considering both the similarity between the target user and past users, as well as the similarity between current attributes and past attributes. \u2022 Frequency Extraction Layer (FEL): In addition to the personalized attention, this layer aims to capture the frequency of item attribute change, which quantifies the activity level of the seller's operation, and also indicates how much of a difference this core attribute evolution network will make.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Modeling over Attribute-Based State: Partition, Evolution, and Frequency Extraction", "text": "The layers of SPL, SEL, and FEL, work together for the attributebased state modeling. Among them, SEL is a commonly used layer, which can deal with sequences at any granularity. For example, most previous methods utilizing user behavior or item behavior  regard one user-item interaction as one state. However, in our method, SPL is first applied to partition the lifecycle of the target item based on the actions from sellers and platform operators on item core attributes. Therefore, it defines the granularity of the state that SEL works on. In SPL, the criterion for state partition can be customized according to the purposes and characteristics of the recommendation scenario. Here, for the sake of simplicity and interpretability, we take price as the representative in the following description.\ntiv(k) \u21b5(k 1) \u21b5(2) e\u21b5(2) eu(2) hu(2) etiv(2) etiv(k) etiv(k 1) hu(k 1) hu(k) e\u21b5(k) eu(k) eu(k 1) e\u21b5(k\nIn SPL, the users that have interacted with the target item \ud835\udc56 can be expressed as\nU \ud835\udc56 = U (1) \ud835\udc56 + U (2) \ud835\udc56 + ... + U (\ud835\udc58)\n\ud835\udc56 , where U (\ud835\udf05) \ud835\udc56 denotes those who interacted under the \ud835\udf05 th price state. Instead of regarding one user-item interaction as one state, a group of users U (\ud835\udf05) \ud835\udc56 are seen as one state of the item. Then after AAL, SEL models the evolution over user groups, which is also the dynamics of the item attribute. Besides, FEL extracts the frequency of item attribute change. Specifically, we deploy a recurrent network over the sequence composed of the time stamps of attribute changes.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Two-Stage Hierarchical Attention Network: User-Item Interaction under Specific Attributes", "text": "Inspired by a series of work [16,20,21], we build a hierarchical attention network throughout the item evolution modeling, which is a two-stage structure consisting of the Attribute Attention Layer as well as the Personalized Attention Layer, as mentioned in Section 3.2. In this subsection, we first introduce the mathematics of multihead attention, then elaborate on how we implement it into our hierarchical structure. \nFurthermore, linear projections are optionally applied on \ud835\udc44, \ud835\udc3e, \ud835\udc49 to achieve higher representation capacities, and multiple heads with different linear projections are applied to attend to information from different representation subspaces at different positions:\nMultiHead(\ud835\udc44, \ud835\udc3e, \ud835\udc49 ) = Concat(head 1 , ..., head \u210e )\ud835\udc4a \ud835\udc42 head \ud835\udc56 = Attention(\ud835\udc44\ud835\udc4a \ud835\udc44 \ud835\udc56 , \ud835\udc3e\ud835\udc4a \ud835\udc3e \ud835\udc56 , \ud835\udc49\ud835\udc4a \ud835\udc49 \ud835\udc56 ),(3)\nwhere the projections are parameter matrices\n\ud835\udc4a \ud835\udc44 \ud835\udc56 \u2208 R \ud835\udc51\u00d7\ud835\udc51 \ud835\udc58 , \ud835\udc4a \ud835\udc3e \ud835\udc56 \u2208 R \ud835\udc51\u00d7\ud835\udc51 \ud835\udc58 , \ud835\udc4a \ud835\udc49 \ud835\udc56 \u2208 R \ud835\udc51\u00d7\ud835\udc51 \ud835\udc63 , and \ud835\udc4a \ud835\udc42 \u2208 R \u210e\ud835\udc51 \ud835\udc63 \u00d7\ud835\udc51 .\nHere \ud835\udc51 denotes the model dimension.\n3.4.2 Hierarchical Attention Implementation. In Figure 3, the implementations of the two stages of our hierarchical attention mechanism are presented respectively:\nThe 1 st attentive layer corresponds to Attribute Attention Layer (AAL) in CAEN, which is applied on the bottom to aggregate the users under a specific attribute. Instead of simply applying average pooling over these users, an attention mechanism is used to find the users who are most representative of the attribute among the interaction history, which is, to put more weight on the users that are attracted by the attribute, but not the users that are consistently interested in this item. To achieve this, this layer is implemented as shown on the left of Figure 3. Query is the attribute embedding, value and key are both the embedding of the users who have  interacted with the target item under this attribute:\nQuery = \ud835\udf36 \ud835\udf05 , Key = \ud835\udc48 \ud835\udefc \ud835\udf05 , Value = \ud835\udc48 \ud835\udefc \ud835\udf05 ,\nwhere \ud835\udf36 \ud835\udf05 denotes the embedding of the \ud835\udf05 th attribute, and \ud835\udc48 \ud835\udefc \ud835\udf05 denotes the embedding matrix of the user sequences under the \ud835\udf05 th attribute:\n\ud835\udc48 \ud835\udefc \ud835\udf05 = ( \ud835\udc96 1 \ud835\udefc \ud835\udf05 , \ud835\udc96 2 \ud835\udefc \ud835\udf05 , ..., \ud835\udc96 \ud835\udc40 \ud835\udefc\ud835\udf05 \ud835\udefc \ud835\udf05\n).\nThe query and key are both projected into other spaces to obtain the appropriate similarity as attention weights. However, we keep value in its original representation space so that the output remains in the consistent space with user embedding, and thus can be compared with the target user in the following computations. Each attribute-aware attention works individually under each attribute \ud835\udefc 1 , \ud835\udefc 2 , ..., \ud835\udefc \ud835\udc58 , but shares the same parameter \ud835\udc4a \ud835\udc44 ,\ud835\udc4a \ud835\udc58 throughout this scheme. The 2 nd attentive layer corresponds to Personalized Attention Layer (PAL) in CAEN, which is applied on the top to extract information from the source past interactions according to the target one. To balance the impact from attribute and the impact from user in calculating the matching degree of past interactions on current one, attribute and user are combined to act as query and key. As shown on the right, value is the item representations under different attributes that are calculated from previous layers, key is the concatenation of the item representations and the attributes, and query is the concatenation of the target user and the current attribute: Query = Concat \ud835\udc96 \ud835\udc61 , \ud835\udf36 \ud835\udc61 , Key = Concat \ud835\udc3b \ud835\udf36 , \ud835\udc34 , Value = \ud835\udc3b \ud835\udf36 , where the \ud835\udc96 \ud835\udc61 denotes the embedding of the target user, \ud835\udf36 \ud835\udc61 denotes the embedding of the current attribute, \ud835\udc34 is the embedding matrix of past attributes\n\ud835\udc34 = ( \ud835\udf36 1 , \ud835\udf36 2 , ..., \ud835\udf36 \ud835\udc58 ),(4)\nand the \ud835\udc3b \ud835\udf36 is the matrix of item representations under the attribute sequence\n\ud835\udc3b \ud835\udf36 = ( \ud835\udc89 \ud835\udefc 1 , \ud835\udc89 \ud835\udefc 2 , ..., \ud835\udc89 \ud835\udefc \ud835\udc58 ),(5)\nin which the representations are obtained from the previous State Evolution Layer.", "publication_ref": ["b15", "b19", "b20"], "figure_ref": ["fig_3", "fig_3"], "table_ref": []}, {"heading": "Downstream Application Deployment", "text": "The item representation from our proposed CAEN can be integrated with various downstream application structures. Here, we take CTR prediction as the downstream task and apply a Multiple Layer Perceptron (MLP) to predict the probability of the target user clicking on the candidate item, as shown on the right side in Figure 2.ReLu activation is used within these layers and sigmoid activation is used at the top. Finally, the loss function is defined as the cross-entropy for CTR prediction task, which can be formulated as follow:\nL \ud835\udc50\ud835\udc61\ud835\udc5f = - \ud835\udc41 \ud835\udc60 \u2211\ufe01 \ud835\udc58=1 [\ud835\udc66 \ud835\udc58 log \u0177\ud835\udc58 + (1 -\ud835\udc66 \ud835\udc58 ) log(1 -\u0177\ud835\udc58 )],(6)\nwhere \ud835\udc41 \ud835\udc60 is the sample size of the training dataset, \ud835\udc66 \u2208 {0, 1} is the label whether the user clicked the item and \u0177\ud835\udc58 represents the predicted probability of the user clicking on the item.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "EXPERIMENTS", "text": "In this section, we introduce how we set up our experiments over the real-world dataset, and answer the following four research questions based on the experiment results:\n\u2022 RQ1: How does CAEN perform compared with the state-ofthe-art methods for sequential recommendations? \u2022 RQ2: How do different components in CAEN contribute to the recommendation performance? \u2022 RQ3: How does CAEN perform along with different methods based on user behaviors? \u2022 RQ4: How does CAEN perform on items with different levels of attribute dynamics compared to other baselines? \u2022 RQ5: How do the key hyper-parameters in CAEN affect its performance?", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Setups", "text": "4.1.1 Datasets. Since existing public datasets lack accurate records on item attributes, we collect a dataset from Lazada 1 , which is a fast-growing e-commerce platform in Southeast Asia. The dataset is obtained from 8-day item exposure logs from April 18, 2022 to April 25, 2022 in Indonesia, with labels that record whether the items are clicked or not. The dataset is downsampled, and negative sampled with a ratio of 1:5. The samples of the first seven days are used for training, and the samples of the last day are used for testing. In addition to these exposure logs, we record item attribute changes and item behaviors, i.e., user interactions, within 30 days before exposure. In our experiment, we choose price as attribute, then prepare relative features including discount rate, price level, and price ranking in the same category. The statistics of the processed datasets (after downsampling) are shown in Table 1. \u2022 SVD++ [8] treats user behaviors as a matrix, combining the neighborhood model as well as the latent factor models. \u2022 YoutubeNet [4] proposes to obtain user representations by averaging the embedding of items in users' past behaviors.\n\u2022 PNN [10] introduces a product layer upon YoutubeNet to capture the similarities between candidate items and the items in past behaviors. GROUP II includes five sequential modeling methods on only user behaviors:\n\u2022 GRU4Rec [6] adopts a gated recurrent unit for sequential user behavior modeling, which is known as one of the earliest works to introduce the RNN-based model for sequential recommendation.\n\u2022 Caser [15] is a CNN-based model and develops horizontal and vertical convolutional filters to capture the behavior patterns.\n\u2022 ATRANK [25] is an attention-based model that can utilize the correlation between users' heterogeneous behaviors.\n\u2022 DIEN [27] proposes an AUGRU to model the interest evolving process and activate specific interests for different target items, which integrates the RNN-based model and attentionbased model. \u2022 UB-GRUA [9] first applies GRU in user interest modeling and then uses multi-head attention to capture the interests most relevant to the target item. GROUP III includes four dual behavior models that have both user behavior modeling and item behavior modeling. For fairness, we adopt the same user behavior modeling method in all these models as well as CAEN.\n\u2022 Topo-LSTM [18] develops LSTM to capture item dynamics from item behavior sequences. \u2022 DIB [5] is an attention-like model, in which a dynamic item block searches for users who are similar to the target user from the item behaviors.\n\u2022 IB-GRUA uses GRU to model the temporal dependencies among item behaviors, and an attention mechanism to generate the personalized recommendation. \u2022 TIEN [9] further introduces a time-aware structure over IB-GRUA.\n4.1.3 Evaluation Metrics. We adopt two metrics to evaluate our proposed model from different perspectives, which are widely used in CTR prediction tasks. The first metric is AUC (Area Under ROC Curve), which indicates the pairwise ranking ability. Another metric is Logloss, also known as cross-entropy loss, which measures the likelihood of the output probability distribution and the true probability distribution. A larger AUC indicates better recommendation performance, but Logloss performs the opposite.", "publication_ref": ["b7", "b3", "b9", "b14", "b24", "b26", "b8", "b17", "b4", "b8"], "figure_ref": [], "table_ref": ["tab_2"]}, {"heading": "Implementation Details.", "text": "We implement all the models in Tensorflow and the implementation codes are released 2 . The embedding dimension of item ID and user ID is set as 32 for all methods. Besides, the embedding dimension of each item attribute and user profile is set as 32 and 16 respectively. The length of the user's behavior sequence is truncated to 20, and the number of hidden units in the decision layer is fixed as [1024, 512, 128] for all models.\nThe code of all baselines is from the authors or open resources. And these models are all optimized by Adam optimizer with cosine annealing, where the initial learning rate is set as 1 \u00d7 \ud835\udc52 -foot_3 and the minimum learning rate is set as 5 \u00d7 \ud835\udc52 -5 . The training batch size is 1024. For the conventional item behavior modeling method, the truncation length of the interaction behavior is set to 30. For our proposed model, the truncation length of the attribute states is 8, and the truncation length of the interactive behavior under each attribute is 50.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Overall Performance (RQ1)", "text": "Table 2 summarizes the overall performance of baselines and our method. In Group III, we use UB-GRUA for user behavior modeling, which has been proved to be the best model in the second group. According to the results, the models in Group II outperform most models in Group I with higher AUC and lower Logloss, which demonstrates the effectiveness of the state-of-the-art user behavior modeling. However, when further establishing an item behavior modeling module, existing methods in Group III do not always obtain better results. Among these dual behavior models, Topo-LSTM establishes an evolution network over the past interaction sequence of the item; DIB applies an attention network to extract the most similar users from a set of users in the item interaction history according to the target user; IB-GRUA can be seen as the combination of Topo-LSTM and DIB, which considers both the chronological order of past users and their similarity to the target user. These three methods are proposed with good results over datasets like Amazonfoot_2 and MovieLens 4 , which are collected in a relatively stable environment. However, they fail to be profitable in our fast-growing circumstance, with worse results than UB-GRUA. Different from these three methods, TIEN is the only one that gets equal or higher AUC than UB-GRUA. The result is rational since TIEN is the only one that does not just apply a symmetric structure in item behavior modeling compared to the user side, but tries to capture the item changes with a time-aware evolution model. Further, our proposed CAEN takes use of the field knowledge and models the item evolution over attribute changes, thus achieving a significantly higher AUC and lower Logloss than TIEN. This demonstrates that, it is more effective to model the item evolution under attribute granularity than that under interaction granularity and CAEN is the best fit for our fast-growing e-commerce environment.\nIt is also worth noting that the performance improvement by introducing item behavior modeling (CAEN vs. UB-GRUA) is at the same level as that by introducing user behavior modeling (UB-GRUA vs. PNN). More discussions are expanded in the following analysis.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_3"]}, {"heading": "Ablation Study (RQ2)", "text": "To figure out the contribution of each component to the performance of our CAEN, three variants of CAEN are implemented for ablation experiments: Note that Personalized Attention Layer (PAL) is reserved in all variants to obtain a personalized item representation. Table 3 presents the numerical results of ablation studies. By comparing the performances between CAEN and its variants, we observe that removing any component in CAEN will result in a performance decrease, which proves the effectiveness of each proposed layer. Firstly, the State Evolution Layer (SEL) is conducive to the item representation under each attribute by capturing the temporal dependency. This is because the item representation under each attribute is determined not only by the state of that time, but also by its past. Secondly, the attributes-aware attention mechanism in AAL can help to extract the interactions related to the item attribute, by putting more weight on users that are attracted by the attribute other than the users' constant interests, which also improves the performance significantly. Thirdly, the Frequency Extraction Layer (FEL) works like a \"supervisor of seller operation\", which models the evolution over the timestamp of attribute modification and captures the seller's operational activities, is also proved to be effective.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_5"]}, {"heading": "Practicability Study (RQ3)", "text": "To verify the practicability of the proposed item behavior modeling method, we implement CAEN as a configurable module into different user behavior modeling methods, and compare the performance of individual GRU4Rec, ATRANK, DIEN, UB-GRUA to those with CAEN. Results in Table 4 prove the effectiveness and practicability of our methods. CAEN can be applied together with the state-of-the-art user sequential modeling methods and further improve their recommendation accuracy, especially for UB-GRUA.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_6"]}, {"heading": "Performance on items with different levels of attribute dynamics (RQ4)", "text": "To further analyze the role of our method in the recommendation system of fast-growing e-commerce, we evaluate the model performances over items with different level of attribute dynamics. To be more specific, we classify the samples by the number of price states of the target item, then measure their Logloss respectively. Here, we use Logloss because AUC is a metric of ordering relation, which  4. As the number of price states increases from 1 to 8, the CTR prediction improvement caused by item behavior modeling increases under all methods. It happens because the items might be more popular (appear more times in the training dataset) while having more price states. This also indicates the importance of modeling on item behaviors as the item changes increase. Compared with other item behavior modeling methods, CAEN can always benefit from a larger number of price states thanks to the SEL and PAL, which could share information within different price states of one specific item. When the number of price states is 9, all other methods get a significant decrease than the number of price states as 8, even lower than the number of price states as 7, CAEN achieves better results than the number of price states as 7, with only a bit decrease than the number of price states as 8.", "publication_ref": [], "figure_ref": ["fig_4"], "table_ref": []}, {"heading": "Hyperparameter Analysis (RQ5)", "text": "We evaluate the effect of two critical hyper-parameters: the size of item representation \ud835\udc51 and the truncation length of item state \ud835\udc3f. Figure 5a presents the AUC under the size of item representation \ud835\udc51 in {8, 16, 32, 64, 128, 256}. As shown, the model performs better as \ud835\udc51 increases from 8 to 16, but then worse as \ud835\udc51 is further increased. Figure 5b presents the AUC under the truncation length in {1,2,3,4,5,6,7,8}. Increasing truncation length \ud835\udc3f of the item state from 1 to 3 significantly improves model performance. However, when \ud835\udc3f is larger or equal to 4, the performance stays at a lower level which is similar to the performance when \ud835\udc3f = 1. On one hand, considering more price states might also introduce noisy information. On the other hand, most of the samples are based on items that have a price change time less than or equal to 3, thus it is enough to take the latest 3 prices into account for them.", "publication_ref": [], "figure_ref": ["fig_6", "fig_6"], "table_ref": []}, {"heading": "CONCLUSIONS AND FUTURE WORK", "text": "In this paper, we propose a novel method CAEN, for the modeling of item evolution over item attributes. To the best of our knowledge, we are the first to model item dynamics from the perspective of attribute change. The sequence of users who have interacted with the target item is partitioned according to the value of item attribute, and a hierarchical attention network is devised over it and works throughout the item evolution modeling. Results from the extensive experiments over actual e-commerce datasets in Southeast Asia show that our approach is superior to the state-of-art baselines, especially on the items with changes over attributes, which helps item recommendation to adapt to the growth of e-commerce. This work still has some limitations. Firstly, studies have proposed CTR prediction schemes other than Equation (1). In the future, we will improve the downstream application of CAEN by regarding it as an enhanced item embedding method, thus it can be further used in more schemes. Secondly, recommended items may be affected by not only the manual operations on a single attribute, but also the manual operations on multiple attributes, and even the environmental factors. In the future, we will investigate how to capture the impact from multiple variables on user-item interactions, as well as the synergy among these variables.   ", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Sequential recommendation with user memory networks", "journal": "", "year": "2018", "authors": "Hongteng Xu Chen; Yongfeng Xu; Jiaxi Zhang; Yixin Tang; Zheng Cao; Hongyuan Qin;  Zha"}, {"ref_id": "b1", "title": "Where you like to go next: Successive point-of-interest recommendation", "journal": "", "year": "2013", "authors": "Chen Cheng; Haiqin Yang; Irwin Michael R Lyu;  King"}, {"ref_id": "b2", "title": "MEANTIME: Mixture of Attention Mechanisms with Multi-temporal Embeddings for Sequential Recommendation", "journal": "", "year": "2020", "authors": "Min Sung; Eunhyeok Cho; Sungjoo Park;  Yoo"}, {"ref_id": "b3", "title": "Deep neural networks for youtube recommendations", "journal": "", "year": "2016", "authors": "Paul Covington; Jay Adams; Emre Sargin"}, {"ref_id": "b4", "title": "Dynamic Item Block and Prediction Enhancing Block for Sequential Recommendation", "journal": "", "year": "2019", "authors": "Guibing Guo; Shichang Ouyang; Xiaodong He; Fajie Yuan; Xiaohua Liu"}, {"ref_id": "b5", "title": "Session-based Recommendations with Recurrent Neural Networks", "journal": "", "year": "2016-05-02", "authors": "Bal\u00e1zs Hidasi; Alexandros Karatzoglou; Linas Baltrunas; Domonkos Tikk"}, {"ref_id": "b6", "title": "Self-attentive sequential recommendation", "journal": "IEEE", "year": "2018", "authors": "Wang-Cheng Kang; Julian Mcauley"}, {"ref_id": "b7", "title": "Factorization meets the neighborhood: a multifaceted collaborative filtering model", "journal": "", "year": "2008", "authors": "Yehuda Koren"}, {"ref_id": "b8", "title": "Deep Time-Aware Item Evolution Network for Click-Through Rate Prediction", "journal": "", "year": "2020", "authors": "Xiang Li; Chao Wang; Bin Tong; Jiwei Tan; Xiaoyi Zeng; Tao Zhuang"}, {"ref_id": "b9", "title": "Product-based neural networks for user response prediction", "journal": "IEEE", "year": "2016", "authors": "Yanru Qu; Han Cai; Kan Ren; Weinan Zhang; Yong Yu; Ying Wen; Jun Wang"}, {"ref_id": "b10", "title": "Factorizing personalized markov chains for next-basket recommendation", "journal": "", "year": "2010", "authors": "Steffen Rendle; Christoph Freudenthaler; Lars Schmidt-Thieme"}, {"ref_id": "b11", "title": "BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer", "journal": "", "year": "2019", "authors": "Fei Sun; Jun Liu; Jian Wu; Changhua Pei; Xiao Lin; Wenwu Ou; Peng Jiang"}, {"ref_id": "b12", "title": "Attribute-aware deep attentive recommendation", "journal": "The Journal of Supercomputing", "year": "2021", "authors": "Xiaoxin Sun; Lisa Zhang; Yuling Wang; Mengying Yu; Minghao Yin; Bangzuo Zhang"}, {"ref_id": "b13", "title": "Dynamic Memory based Attention Network for Sequential Recommendation", "journal": "", "year": "2021", "authors": "Qiaoyu Tan; Jianwei Zhang; Ninghao Liu; Xiao Huang; Hongxia Yang; Jingren Zhou; Xia Hu"}, {"ref_id": "b14", "title": "Personalized top-n sequential recommendation via convolutional sequence embedding", "journal": "", "year": "2018", "authors": "Jiaxi Tang; Ke Wang"}, {"ref_id": "b15", "title": "Attention is all you need", "journal": "", "year": "2017", "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; \u0141ukasz Kaiser; Illia Polosukhin"}, {"ref_id": "b16", "title": "Make it a chorus: knowledge-and time-aware item modeling for sequential recommendation", "journal": "", "year": "2020", "authors": "Chenyang Wang; Min Zhang; Weizhi Ma; Yiqun Liu; Shaoping Ma"}, {"ref_id": "b17", "title": "Topological recurrent neural network for diffusion prediction", "journal": "IEEE", "year": "2017", "authors": "Jia Wang; Vincent W Zheng; Zemin Liu; Kevin Chen; -Chuan Chang"}, {"ref_id": "b18", "title": "Joint item recommendation and attribute inference: An adaptive graph convolutional network approach", "journal": "", "year": "2020", "authors": "Le Wu; Yonghui Yang; Kun Zhang; Richang Hong; Yanjie Fu; Meng Wang"}, {"ref_id": "b19", "title": "Hierarchical attention networks for document classification", "journal": "", "year": "2016", "authors": "Zichao Yang; Diyi Yang; Chris Dyer; Xiaodong He; Alex Smola; Eduard Hovy"}, {"ref_id": "b20", "title": "Sequential recommender system based on hierarchical attention network", "journal": "", "year": "2018", "authors": "Haochao Ying; Fuzhen Zhuang; Fuzheng Zhang; Yanchi Liu; Guandong Xu; Xing Xie; Hui Xiong; Jian Wu"}, {"ref_id": "b21", "title": "TAGNN: Target attentive graph neural networks for session-based recommendation", "journal": "", "year": "1921", "authors": "Feng Yu; Yanqiao Zhu; Qiang Liu; Shu Wu; Liang Wang; Tieniu Tan"}, {"ref_id": "b22", "title": "Attributes coupling based matrix factorization for item recommendation", "journal": "Applied Intelligence", "year": "2017", "authors": "Yonghong Yu; Can Wang; Hao Wang; Yang Gao"}, {"ref_id": "b23", "title": "ICAI-SR: Item Categorical Attribute Integrated Sequential Recommendation", "journal": "", "year": "2021", "authors": "Dongsheng Xu Yuan; Lingling Duan; Lei Tong; Cheng Shi;  Zhang"}, {"ref_id": "b24", "title": "Atrank: An attention-based user behavior modeling framework for recommendation", "journal": "", "year": "2018", "authors": "Chang Zhou; Jinze Bai; Junshuai Song; Xiaofei Liu; Zhengchao Zhao; Xiusi Chen; Jun Gao"}, {"ref_id": "b25", "title": "Deep interest evolution network for click-through rate prediction", "journal": "", "year": "2019", "authors": "Guorui Zhou; Na Mou; Ying Fan; Qi Pi; Weijie Bian; Chang Zhou; Xiaoqiang Zhu; Kun Gai"}, {"ref_id": "b26", "title": "Deep interest network for click-through rate prediction", "journal": "", "year": "2018", "authors": "Guorui Zhou; Xiaoqiang Zhu; Chenru Song; Ying Fan; Han Zhu; Xiao Ma; Yanghui Yan; Junqi Jin; Han Li; Kun Gai"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: An illustration of user preference shift caused by attribute change: Suppose that a luxury handbag is released with its original price, then gets a 40% discount off during a promotion campaign, and is finally set as 10% off. User A, B, C show different levels of preference for this handbag during periods with different prices.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "tivAttribute Attentive Layer (AAL)item behavior (user sequence) under different attribute periods target user", "figure_data": ""}, {"figure_label": "41", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "3. 4 . 141Multi-Head Attention Mechanism. We adopt scaled the dotproduct attention in the basic form of attention. With input including queries \ud835\udc44 and keys \ud835\udc3e of dimension \ud835\udc51 \ud835\udc58 , and values \ud835\udc49 of dimension \ud835\udc51 \ud835\udc63 , we can compute and scale the dot products of the query with all keys, then obtain the weights on values with a softmax function: Attention(\ud835\udc44, \ud835\udc3e, \ud835\udc49 ) = softmax \ud835\udc44\ud835\udc3e \ud835\udc47 \u221a\ufe01 \ud835\udc51 \ud835\udc58 \ud835\udc49 .", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 3 :3Figure 3: Hierarchical Attention Network includes two attentive layers corresponding to the Attribute Attention Layer (AAL) and the Personalized Attention Layer (PAL).", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 4 :4Figure 4: Performance on items with a different number of price states. The vertical axis is the Logloss decrease compared to UB-GRUA.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 5 :5Figure 5: Performance with different hyperparameters.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "The architecture of Core Attribute Evolution Network is presented, which corresponds to the Item Behavior Modeling Module on the right. The timeline of the item's lifecycle is partitioned into periods according to its price. Each period corresponds to an attribute state in the above architecture and is further transmitted to subsequent modeling.", "figure_data": "CTRSigmoidMLPConcat & FlattenFrequency Extraction Layer (FEL)\u2026Personalized Attentive Layer (PAL)e\u21b5\u2026Item ProfileUser ProfileUser BehaviorModuleModuleModule1)Attribute-BasedState Partition Layer (SPL)Embedding Layer\u2026currentitem profileuser profileuser behavior sequencesattributeFigure 2:"}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "The statistics of experimental datasets.", "figure_data": "DescriptionValue#users3.4 million#items3.1 million#samples363 million#category4,056avg. length of the attribute states2.734.1.2 Baselines. We consider three groups of competitive baselinesfor performance comparison as below.GROUP I includes three non-sequential methods based on user-item interactions:"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Overall performance of our method and baseline models on AUC and Logloss metrics. FMCG, FA, GM, EL represents four industry categories of items (fast-moving consumer goods, fashion, general merchandise, and electronics). The best results within groups are with underlines, the best results of all methods are in bold.", "figure_data": "GroupMethodoverall AUC Logloss AUC Logloss AUC Logloss AUC Logloss AUC Logloss FMCG FA GM ELSVD++0.6539 0.6689 0.6507 0.6412 0.6565 0.6764 0.6474 0.6716 0.6487 0.6657IYoutubeNet 0.6558 0.6746 0.6545 0.6447 0.6584 0.6804 0.6483 0.6825 0.6491 0.6775PNN0.6564 0.6650 0.6552 0.6351 0.6590 0.6726 0.6486 0.6688 0.6496 0.6640GRU4Rec 0.6579 0.6771 0.6565 0.6457 0.6607 0.6842 0.6500 0.6829 0.6511 0.6789Caser0.6593 0.6708 0.6580 0.6415 0.6623 0.6768 0.6509 0.6779 0.6519 0.6730IIATRANK 0.6565 0.6567 0.6556 0.6271 0.6591 0.6630 0.6489 0.6625 0.6499 0.6614DIEN0.6584 0.6606 0.6570 0.6320 0.6611 0.6679 0.6507 0.6644 0.6521 0.6588UB-GRUA 0.6620 0.6567 0.6618 0.6310 0.6645 0.6623 0.6539 0.6623 0.6558 0.6564Topo-LSTM 0.6586 0.6614 0.6574 0.6303 0.6616 0.6688 0.6500 0.6671 0.6511 0.6578IIIDIB IB-GRUA 0.6587 0.6571 0.6580 0.6291 0.6613 0.6625 0.6510 0.6644 0.6521 0.6595 0.6590 0.6685 0.6581 0.6383 0.6618 0.6745 0.6507 0.6765 0.6519 0.6689TIEN0.6622 0.6591 0.6616 0.6269 0.6651 0.6658 0.6533 0.6671 0.6556 0.6576OursCAEN0.6789 0.6282 0.6801 0.5999 0.6790 0.6371 0.6746 0.6283 0.6786 0.6214"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Performance of CAEN and its ablation models.", "figure_data": "Methodoverall AUC Logloss AUC Logloss AUC Logloss AUC Logloss AUC Logloss FMCG FA GM ELCAEN-NS 0.6616 0.6498 0.6612 0.6204 0.6643 0.6552 0.6534 0.6586 0.6552 0.6516CAEN-NH 0.6622 0.6472 0.6620 0.6189 0.6649 0.6528 0.6538 0.6550 0.6558 0.6473CAEN-NF 0.6622 0.6631 0.6616 0.6320 0.6650 0.6702 0.6536 0.6684 0.6556 0.6649CAEN0.6789 0.6282 0.6801 0.5999 0.6790 0.6371 0.6746 0.6283 0.6786 0.6214"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Performance of CAEN along with different user behavior sequential modeling.", "figure_data": "Methodoverall AUC Logloss AUC Logloss AUC Logloss AUC Logloss AUC Logloss FMCG FA GM ELGRU4Rec0.6579 0.6771 0.6565 0.6457 0.6607 0.6842 0.6500 0.6829 0.6511 0.6789GRU4Rec + CAEN 0.6589 0.6562 0.6576 0.6263 0.6617 0.6633 0.6509 0.6608 0.6536 0.6579Caser0.6593 0.6708 0.6580 0.6415 0.6623 0.6768 0.6509 0.6779 0.6519 0.6730Caser + CAEN0.6597 0.6771 0.6583 0.6440 0.6626 0.6828 0.6517 0.6881 0.6525 0.6782ATRANK0.6565 0.6567 0.6556 0.6271 0.6591 0.6630 0.6489 0.6625 0.6499 0.6614ATRANK + CAEN 0.6583 0.6549 0.6575 0.6274 0.6609 0.6615 0.6506 0.6582 0.6516 0.6583DIEN0.6584 0.6606 0.6570 0.6320 0.6611 0.6679 0.6507 0.6644 0.6521 0.6588DIEN + CAEN0.6598 0.6608 0.6584 0.6320 0.6627 0.6669 0.6515 0.6676 0.6529 0.6610UB-GRUA0.6620 0.6567 0.6618 0.6310 0.6645 0.6623 0.6539 0.6623 0.6558 0.6564UB-GRUA + CAEN 0.6789 0.6282 0.6801 0.5999 0.6790 0.6371 0.6746 0.6283 0.6786 0.6214is not appropriate for measuring the performance of a subset overthe whole dataset. Results are shown in Figure"}], "formulas": [{"formula_id": "formula_0", "formula_text": "\u0177 = \ud835\udc43 \ud835\udc50\ud835\udc61\ud835\udc5f (\ud835\udc62, \ud835\udc56) = F G 1 (\ud835\udc62), G 2 (\ud835\udc56), G 3 (I \ud835\udc62 ), G 4 (U \ud835\udc56 ) ,(1)", "formula_coordinates": [3.0, 84.26, 641.31, 209.78, 9.38]}, {"formula_id": "formula_1", "formula_text": "tiv(k) \u21b5(k 1) \u21b5(2) e\u21b5(2) eu(2) hu(2) etiv(2) etiv(k) etiv(k 1) hu(k 1) hu(k) e\u21b5(k) eu(k) eu(k 1) e\u21b5(k", "formula_coordinates": [4.0, 207.91, 184.47, 141.51, 85.31]}, {"formula_id": "formula_2", "formula_text": "U \ud835\udc56 = U (1) \ud835\udc56 + U (2) \ud835\udc56 + ... + U (\ud835\udc58)", "formula_coordinates": [4.0, 129.8, 458.21, 113.33, 13.12]}, {"formula_id": "formula_4", "formula_text": "MultiHead(\ud835\udc44, \ud835\udc3e, \ud835\udc49 ) = Concat(head 1 , ..., head \u210e )\ud835\udc4a \ud835\udc42 head \ud835\udc56 = Attention(\ud835\udc44\ud835\udc4a \ud835\udc44 \ud835\udc56 , \ud835\udc3e\ud835\udc4a \ud835\udc3e \ud835\udc56 , \ud835\udc49\ud835\udc4a \ud835\udc49 \ud835\udc56 ),(3)", "formula_coordinates": [4.0, 340.47, 493.68, 217.73, 27.25]}, {"formula_id": "formula_5", "formula_text": "\ud835\udc4a \ud835\udc44 \ud835\udc56 \u2208 R \ud835\udc51\u00d7\ud835\udc51 \ud835\udc58 , \ud835\udc4a \ud835\udc3e \ud835\udc56 \u2208 R \ud835\udc51\u00d7\ud835\udc51 \ud835\udc58 , \ud835\udc4a \ud835\udc49 \ud835\udc56 \u2208 R \ud835\udc51\u00d7\ud835\udc51 \ud835\udc63 , and \ud835\udc4a \ud835\udc42 \u2208 R \u210e\ud835\udc51 \ud835\udc63 \u00d7\ud835\udc51 .", "formula_coordinates": [4.0, 317.96, 527.83, 240.07, 23.97]}, {"formula_id": "formula_6", "formula_text": "Query = \ud835\udf36 \ud835\udf05 , Key = \ud835\udc48 \ud835\udefc \ud835\udf05 , Value = \ud835\udc48 \ud835\udefc \ud835\udf05 ,", "formula_coordinates": [5.0, 149.05, 415.13, 49.65, 36.1]}, {"formula_id": "formula_7", "formula_text": "\ud835\udc48 \ud835\udefc \ud835\udf05 = ( \ud835\udc96 1 \ud835\udefc \ud835\udf05 , \ud835\udc96 2 \ud835\udefc \ud835\udf05 , ..., \ud835\udc96 \ud835\udc40 \ud835\udefc\ud835\udf05 \ud835\udefc \ud835\udf05", "formula_coordinates": [5.0, 106.65, 497.3, 121.43, 11.64]}, {"formula_id": "formula_8", "formula_text": "\ud835\udc34 = ( \ud835\udf36 1 , \ud835\udf36 2 , ..., \ud835\udf36 \ud835\udc58 ),(4)", "formula_coordinates": [5.0, 383.8, 174.39, 174.4, 9.27]}, {"formula_id": "formula_9", "formula_text": "\ud835\udc3b \ud835\udf36 = ( \ud835\udc89 \ud835\udefc 1 , \ud835\udc89 \ud835\udefc 2 , ..., \ud835\udc89 \ud835\udefc \ud835\udc58 ),(5)", "formula_coordinates": [5.0, 376.01, 211.37, 182.19, 9.94]}, {"formula_id": "formula_10", "formula_text": "L \ud835\udc50\ud835\udc61\ud835\udc5f = - \ud835\udc41 \ud835\udc60 \u2211\ufe01 \ud835\udc58=1 [\ud835\udc66 \ud835\udc58 log \u0177\ud835\udc58 + (1 -\ud835\udc66 \ud835\udc58 ) log(1 -\u0177\ud835\udc58 )],(6)", "formula_coordinates": [5.0, 353.51, 362.92, 204.69, 25.72]}], "doi": "10.1145/3523227.3546773"}
