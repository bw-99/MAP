{
  "Entire Space Cascade Delayed Feedback Modeling for Effective Conversion Rate Prediction": "Yunfeng Zhao School of Software, Shandong University Jinan, China yunfengzhao@mail.sdu.edu.cn Xu Yan Alibaba Group Hangzhou, China wuyong.yx@taobao.com Xiaoqiang Gui School of Software, Shandong University Jinan, China x.q.gui@mail.sdu.edu.cn Shuguang Han Xiang-Rong Sheng Alibaba Group Hangzhou, China shuguang.sh@taobao.com xiangrong.sxr@taobao.com",
  "Guoxian Yu": "School of Software, Shandong University Jinan, China gxyu@sdu.edu.cn",
  "ABSTRACT": "Jufeng Chen Zhao Xu Bo Zheng Alibaba Group Hangzhou, China jufeng.cjf@taobao.com changgong.xz@taobao.com bozheng@taobao.com",
  "CCS CONCEPTS": "Conversion rate (CVR) prediction is an essential task for large-scale e-commerce platforms. However, refund behaviors frequently occur after conversion in online shopping systems, which drives us to pay attention to effective conversion for building healthier shopping services. This paper defines the probability of item purchasing without any subsequent refund as an effective conversion rate (ECVR). Asimple paradigm for ECVR prediction is to decompose it into two sub-tasks: CVR prediction and post-conversion refund rate (RFR) prediction. However, RFR prediction suffers from data sparsity (DS) and sample selection bias (SSB) issues, as the refund behaviors are only available after user purchase. Furthermore, there is delayed feedback in both conversion and refund events and they are sequentially dependent, named cascade delayed feedback (CDF), which significantly harms data freshness for model training. Previous studies mainly focus on tackling DS and SSB or delayed feedback for a single event. To jointly tackle these issues in ECVR prediction, we propose an Entire space CAscade Delayed feedback modeling (ECAD) method. Specifically, ECAD deals with DS and SSB by constructing two tasks including CVR prediction and conversion & refund rate (CVRFR) prediction using the entire space modeling framework. In addition, it carefully schedules auxiliary tasks to leverage both conversion and refund time within data to alleviate CDF. Experimental results on the offline industrial dataset and online A/B testing demonstrate the effectiveness of ECAD. In addition, ECAD has been deployed in one of the recommender systems in Alibaba, contributing to a significant improvement of ECVR. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CIKM '23, October 21-25, 2023, University of Birmingham and Eastside Rooms, UK © 2023 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM...$15.00 https://doi.org/XXXXXXX.XXXXXXX · Information systems → Recommendation systems .",
  "KEYWORDS": "Effective Conversion Rate Prediction, Cascade Delayed Feedback, Data Sparsity, Sample Selection Bias, Entire Space Modeling",
  "ACMReference Format:": "Yunfeng Zhao, Xu Yan, Xiaoqiang Gui, Shuguang Han, Xiang-Rong Sheng, Guoxian Yu, Jufeng Chen, Zhao Xu, and Bo Zheng. 2023. Entire Space Cascade Delayed Feedback Modeling for Effective Conversion Rate Prediction. In Proceedings of The 32nd ACM International Conference on Information and Knowledge Management (CIKM '23). ACM, New York, NY, USA, 7 pages. https://doi.org/XXXXXXX.XXXXXXX",
  "1 INTRODUCTION": "To facilitate an effective matching of user interest with millions of online products, e-commerce platforms usually spend a significant amount of effort on developing deep machine learning models such as the click-through rate (CTR) prediction model [15, 35] and the conversion rate (CVR) prediction model [1, 24]. Given the importance of conversions in online shopping services, we mainly focused on the realm of CVR prediction in this study. Researchers and practitioners have also proposed a variety of approaches for obtaining an accurate estimation of CVR [5, 11, 20, 21, 23, 24]. To tackle the problem of data sparsity (DS), Wen et al. [20, 21] utilized a series of post-click behaviors for supplementing the rare conversion event, which resulted in an improved performance on CVR prediction. Others dealt with the selection bias problem (SSB) in CVR prediction and proposed the entire space estimation method by jointly learning with multiple behavior prediction tasks [11, 23]. Moreover, unlike click behaviors, feedback labels for the conversion event cannot be collected within a short time as conversion may happen in days or even weeks afterward. This introduces a dilemma - to employ recent data with incomplete labels or to wait for more accurate labels. By assuming a stable delayed conversion pattern (e.g., the delay time for the final conversion remains steady), a delayed feedback model resolves this problem by utilizing the CIKM '23, October 21-25, 2023, University of Birmingham and Eastside Rooms, UK Zhao and Yan, et al. relationship between the ultimate conversion and the conversion time to correct the incomplete real-time labels [5, 24]. In real-world online shopping systems, we frequently observe refund requests as the purchased products may not truly fulfill users' real interests. To build a healthy e-commerce platform, we need a better understanding of effective conversions. Considering that user behaviors follow a sequential pattern of 𝑐𝑙𝑖𝑐𝑘 → 𝑐𝑜𝑛𝑣𝑒𝑟𝑠𝑖𝑜𝑛 → 𝑟𝑒𝑓 𝑢𝑛𝑑 , we define an effective conversion rate (ECVR) prediction problem: to forecast the probability that a product will eventually be purchased without a refund after the user clicks this product. However, both conversion and refund events suffer delay feedback, i.e. the conversion and refund events usually occur over a long period after the click and conversion events happened, respectively. A canonical manner to obtain the ECVR label is to set two label attribution windows to observe conversion and refund events separately, i.e. a conversion (refund) is attributed to positive if it happens within the corresponding attribution windows since click (conversion) occurs. Then, ECVR prediction can be achieved by directly training a prediction model (e.g. Embedding&MLP [34, 35] or Wide&Deep [3, 37]) using those samples. However, this strategy significantly compromises data freshness since the corresponding ECVR labels are determined by two attribution windows for observing conversion and refund events. Therefore, the latest data cannot be readily filled into the model, which cannot catch up with the dynamic change of data distribution [23, 28]. Furthermore, such a naive strategy treats both non-conversion samples and conversionwhile-refunded samples with equal importance, ignoring that they possess distinct information for ECVR prediction. To tackle the above issues, we can simply divide ECVR prediction into two sub-tasks: CVR prediction and post-conversion refund rate (RFR) prediction. Accordingly, the probability of ECVR 𝑝 𝑒𝑐𝑣𝑟 equals to 𝑝 𝑐𝑣𝑟 ∗ ( 1 -𝑝 𝑟 𝑓 𝑟 ) , where 𝑝 𝑐𝑣𝑟 and 𝑝 𝑟 𝑓 𝑟 represent the probabilities of CVR and RFR, respectively. In this way, the attribution window for each sub-task will be shorter compared to that of the ECVR task, alleviating the delayed feedback problem for ECVR prediction to some extent. Despite that, there still exist several major challenges if we simply model CVR prediction on top of the clicked samples, and RFR prediction with the conversion samples. Concretely, the first few challenges are DS [10] and SSB [29]. DS means that the RFR prediction model is built on top of the conversion samples, which are significantly less than the clicked samples (for training the CVR prediction model). As such, the limited supervised information makes it hard for the RFR predictor to learn sufficient knowledge for accurate prediction. SSB refers to the inconsistency of data distribution between the training and the testing space, i.e. the RFR predictor is trained using conversion samples but is deployed to make inferences on the entire space with all clicked samples, which hurts the model generalization ability. A common solution for DS and SSB is to employ the entire space modeling approach [11, 17]. In our case, we can utilize the clicked samples to jointly train RFR and CVR prediction models, which alleviates the DS and SSB problems for RFR (as mentioned, it is often trained only with the conversion samples). In addition, there is another big challenge, and we name it the Cascade Delayed Feedback (CDF) problem - both of them have delayed feedback issues, and RFR is further sequentially dependent on the CVR task. Although several approaches [2, 5-7, 9, 18, 24-27] have been proposed to tackle delayed feedback in CVR prediction, they only focus on one delay event and thus incapable to address CDF in the entire space modeling framework. To this end, we introduce an Entire space CAscade Delayed feedback modeling (ECAD) framework for ECVR prediction from the perspective of sequentially modeling CVR and RFR prediction in a sensible way. Specifically, we adopt an entire space modeling framework and construct two tasks: CVR and conversion & refund rate (CVRFR) prediction to help induce the RFR prediction model. In addition, we carefully design auxiliary tasks for CVR and CVRFR prediction using multi-task learning [30, 32] to handle the challenging CDF problem. Fig. 1 presents the overall schematic of ECAD and the main contribution of our work are summarized as follows: · To the best of our knowledge, this work makes the first step toward modeling ECVR prediction. We carefully divide this prediction into two sequentially dependent sub-tasks, i.e. CVR and RFR prediction, and point out a novel, thorny but untouched challenge of these two tasks, i.e. CDF problem. · We propose an Entire space CAscade Delayed feedback modeling (ECAD) approach for learning the ECVR prediction model that adopts an entire space modeling framework to address the SSB and DS problems. Besides, to tackle the CDF problem, ECAD carefully designs auxiliary tasks to leverage the conversion and refund time contained in delayed feedback data to advance the prediction performance. · Experimental results on the offline industrial dataset and online A/B testing clearly demonstrate the effectiveness of ECAD. Moreover, ECAD has been deployed in one of the production recommender systems in Alibaba, yielding a significant improvement of 5.21% ECVR.",
  "2 RELATED WORK": "Our work is closely associated with entire space modeling and delayed feedback modeling, and we discuss the previous research in the following two aspects. Entire Space Modeling . Data sparsity (DS) and sample selection bias (SSB) are two critical problems in recommender systems. In the last decade, many attempts have been made to solve these two challenges. Taking the CVR prediction task in recommender systems as an example, the user actions generally follow a sequential pattern of 𝑖𝑚𝑝𝑟𝑒𝑠𝑠𝑖𝑜𝑛 → 𝑐𝑙𝑖𝑐𝑘 → 𝑐𝑜𝑛𝑣𝑒𝑟𝑠𝑖𝑜𝑛 . The CVR predictor that outputs the post-click conversion rate is usually trained using the clicked samples but makes inferences on the entire space with all impression samples, resulting in SSB. In addition, the clicked samples for training the CVR predictor are scarce compared to impression samples for learning the click-through rate (CTR) one [14, 35], bringing DS. Early works only focused on a certain challenge, i.e. DS [10, 16, 19] or SSB [13, 31]. To combat these two challenges simultaneously, Ma et al. [11] proposed ESMM which utilizes two auxiliary tasks, i.e. CTR and click-through & conversion rate (CTCVR), to train the CVR model indirectly over the entire space of all impression samples and thus align to sample space of testing. Hence, the DS and SSB are alleviated simultaneously. The superiority of ESMM is further demonstrated in ESM 2 [21], AITM [22], ESCM 2 [17], HEROES [8] and DCMT [36]. In this paper, Entire Space Cascade Delayed Feedback Modeling for Effective Conversion Rate Prediction CIKM '23, October 21-25, 2023, University of Birmingham and Eastside Rooms, UK Figure 1: The overall schematic framework of ECAD, which consists of three parts: shared bottom layers, a delayed CVR model, and a delayed RFR model. The shared bottom layers take the sample features (i.e. discrete IDs) as input and output a fixedlength vector, and then feed this vector into the towers of delayed CVR and delayed RFR models to predict the corresponding probabilities. 𝑉 1 and 𝑊 1 denote the pre-defined windows for conversion and refund, respectively. Delayed CVR Model Delayed RFR Model Y1 y&z y&Z1 Y1&z loss loss 3 loss 4 loss 5 loss 6 loss 2 p(z=1,y=Ilx) p(w<Wily=1,x) p(y=Ilx) p(z-Ily=1,x) tower tower 2 tower 3 tower 4 tower 5 tower 6 Shared Bottom Layers we refer to the idea of ESMM to design two tasks (i.e., CVR and CVRFR prediction) for addressing the DS and SSB when learning the RFR prediction model, and then perform the ECVR prediction by the learnt CVR and RFR predictor. Note that we focus on the sequential pattern of actions 𝑐𝑙𝑖𝑐𝑘 → 𝑐𝑜𝑛𝑣𝑒𝑟𝑠𝑖𝑜𝑛 → 𝑟𝑒𝑓 𝑢𝑛𝑑 , thus the entire space consists of all clicked samples in our task. However, the above-mentioned entire space modeling methods ignore the delayed feedback in sequential actions, which significantly harms the data freshness. Delayed Feedback Modeling . There usually is a severe delayed feedback in CVR and RFR prediction, due to the fact that the conversion/refund action may occur hours or days later after the click/conversion event, which hurts the data freshness for training the predictor. A series of works [2, 5, 7, 9, 24-27] have been proposed to redesign the data pipeline and loss function to address the delayed feedback problem for online learning scenario with streaming training. In rough, the fake negatives are first labeled as negative ones to train the model and then duplicated as positive ones to train the model once the conversion happens within the attribution window. Furthermore, Gu et al. [5] proposed the Defer, which develops an effective offline training method that incorporates multi-task learning to harness the information inherent in conversion time for CVR prediction. However, these works only consider the delayed feedback problem in one event, which is distinct from our task, i.e. both conversion and refund events suffer the issue of delayed feedback, causing the Cascade Delayed Feedback (CDF) problem. Here, we adopt multi-task learning and carefully design auxiliary tasks to leverage both conversion and refund time contained in data for handling CDF in ECVR prediction. Note that we focus on how to deal with the CDF problem, but not on proposing an effective delayed feedback model for a single event.",
  "3 PRELIMINARY": "In this section, we first formulate the problem for ECVR prediction and then introduce how previous offline training methods address the delay feedback issue in detail.",
  "3.1 Problem Formulation": "Given a dataset D = {( x , 𝑦, 𝑧, ˆ 𝑦 )} 𝑁 , ( x , 𝑦, 𝑧, ˆ 𝑦 ) marks a sample and 𝑁 is the number of clicked samples, where x denotes the highdimensional feature vector consisting of multi-fields (e.g. user and item field), 𝑦 and 𝑧 are binary labels with 𝑦 = 1 or 𝑧 = 1 meaning the conversion or refund event occurs respectively, ˆ 𝑦 is the binary effective conversion label with ˆ 𝑦 = 1 indicating the sample is converted and no refunded (i.e. 𝑦 = 1 and 𝑧 = 0). Note that there is a sequential dependence between conversion and refund labels, i.e. the conversion event always precedes the refund action. Furthermore, both the conversion and refund events suffer from the delayed feedback problem, resulting in the label of many samples cannot be determined even for a long period, i.e. CDF problem. Denote the duration between the click and conversion and between the conversion and refund as 𝑤 and 𝑣 respectively, 𝑤 ( 𝑣 ) = +∞ means the sample x has no conversion (refund) eventually. A commonly-used manner to deal with the delayed feedback problem is setting a time of attribution window to observe the event. Specifically, let 𝑊 and 𝑉 be the attribution window of conversion and refund, respectively. If 𝑤 < 𝑊 ( 𝑣 < 𝑉 ) , the label of conversion (refund) is set to 1. Ourtask is to accurately estimate the probability of ECVR 𝑝 𝑒𝑐𝑣𝑟 = 𝑝 ( ˆ 𝑦 = 1 | x ) for the testing sample x . Anaive strategy to achieve this problem is learning the prediction model (e.g. Embedding&MLP [35] or Wide&Deep [3]) with input ( 𝑥, ˆ 𝑦 ) . However, this pattern would arise two concerns: (i) it takes too long for determining the ECVR label ˆ 𝑦 , i.e. 𝑊 + 𝑉 , which significantly harms the data freshness for learning the predictor; and (ii) non-conversion samples and samples that are converted but refunded have different knowledge for modeling ECVR, but they are treated equally in this manner. To tackle these issues, we transfer the 𝑝 𝑒𝑐𝑣𝑟 = 𝑝 ( ˆ 𝑦 = 1 | x ) = 𝑝 ( 𝑦 = 1 , 𝑧 = 0 | x ) into two associated probabilities, i.e. probability of CVR 𝑝 𝑐𝑣𝑟 = 𝑝 ( 𝑦 = 1 | x ) and probability of post-conversion RFR 𝑝 𝑟 𝑓 𝑟 = 𝑝 ( 𝑧 = 1 | 𝑦 = 1 , x ) in the follows:  In this way, the 𝑝 𝑒𝑐𝑣𝑟 for a given sample can be computed by the estimated 𝑝 𝑐𝑣𝑟 and 𝑝 𝑟 𝑓 𝑟 .",
  "3.2 Offline Delayed Feedback Modeling": "CVR and RFR prediction usually suffer from delayed feedback, thus corresponding labels of many samples can not be determined even for a long period. A naive strategy to deal with delayed feedback is to wait for the time of attribution window to ascertain the labels of samples and then utilize them for training the model. However, the CIKM '23, October 21-25, 2023, University of Birmingham and Eastside Rooms, UK Zhao and Yan, et al. data distribution is dynamically changing in recommender systems, e.g. new items or users join the platform. As such, the predictor should also be updated with recent samples near the end of training time to capture the distribution shift in data. To tackle this problem, Gu et al. [5] proposed an offline training approach named Defer additionally incorporating the knowledge contained within the recent samples to improve the CVR prediction model. Specifically, Defer employs a multi-task learning framework to advance model generalization utilizing the information included in the conversion time. The model has 𝑛 + 1 towers on top of the shared bottom layers, and an example of 𝑛 = 1 is presented in the left part of Fig. 1. One of the towers predicts 𝑝 ( 𝑦 = 1 | x ) , i.e. 𝑝 𝑐𝑣𝑟 , while others predict whether the conversion sample will convert within the predefined time windows 𝑊 1 , 𝑊 2 , · · · , 𝑊 𝑛 , i.e. 𝑝 ( 𝑤 < 𝑊 𝑖 | 𝑦 = 1 , x )( 𝑖 : 1 → 𝑛 ) , where 𝑊 𝑖 < 𝑊 (∀ 𝑖 ) . To update model in space with all samples, 𝑝 ( 𝑤 < 𝑊 𝑖 | 𝑦 = 1 , x ) is further transferred using 𝑝 ( 𝑦 = 1 | x ) as follows:  where 𝑝 ( 𝑤 < 𝑊 𝑖 , 𝑦 = 1 | x ) indicates the predicted probability of the sample x will convert within the pre-defined time windows 𝑊 𝑖 . Denoting 𝑦 𝑖 the label that whether sample x convert within 𝑊 𝑖 after click, the loss of Defer is computed as follows:  where 𝑙 (·) denotes the binary cross-entropy loss function. Due to recent samples that near the end of the training date may not have all 𝑛 + 1 labels, Defer only updates the corresponding parameters according to the observed labels. For a sample, if the predefined 𝑊 𝑖 + 1 , · · · , 𝑊 𝑛 windows have not reached, Defer only updates the parameters through losses computed by 𝑝 ( 𝑤 < 𝑊 1 , 𝑦 = 1 | x ) , · · · , 𝑝 ( 𝑤 < 𝑊 𝑖 , 𝑦 = 1 | x ) and corresponding observed labels 𝑦 1 , · · · , 𝑦 𝑖 while freezing the parameters of other towers. Note that the tower predicts 𝑝 ( 𝑦 = 1 | x ) will also be updated through the gradient of losses regarding 𝑝 ( 𝑤 < 𝑊 1 , 𝑦 = 1 | x ) , · · · , 𝑝 ( 𝑤 < 𝑊 𝑖 , 𝑦 = 1 | x ) . For example, assuming the attribution window 𝑊 as 3 days, and 1 day, 2 days as two extra time windows. For samples clicked on the 1st day from the last, Defer only updates the parameters from 𝑝 ( 𝑤 < 𝑊 1 , 𝑦 = 1 | x ) . As to samples clicked before the 2nd day from the last, all parameters are updated simultaneously. In addition, the delayed feedback problem in RFR prediction can also be alleviated with Defer using the conversion samples.",
  "4 THE PROPOSED APPROACH": "In this section, we first give a brief review of ECVR Modeling and Challenges and then detail the proposed Entire space CAscade Delayed feedback modeling (ECAD) method for ECVR prediction.",
  "4.1 ECVR Modeling and Challenges": "As mentioned in Section 3.1, it is profitable to decompose ECVR prediction into two sub-tasks, i.e. CVR and RFR prediction. An intuitive manner to fulfill this pattern is by constructing two independent models, in which one trained with clicked samples predicts the 𝑝 𝑐𝑣𝑟 = 𝑝 ( 𝑦 = 1 | x ) , while another updated with conversion samples estimates the 𝑝 𝑟 𝑓 𝑟 = 𝑝 ( 𝑧 = 1 | 𝑦 = 1 , x ) . Then those two probabilities are employed for computing the 𝑝 𝑒𝑐𝑣𝑟 = 𝑝 ( 𝑧 = 1 , 𝑦 = 0 | x ) using Eq. (1). However, this strategy for modeling ECVR prediction suffers from several problems (i.e. SSB, DS, and CDF) as mentioned in Section 1, making it sub-optimal.",
  "4.2 ECAD method": "To address the above issues, we propose an ECAD approach from the perspective of the entire space modeling to construct the CVR and CVRFR prediction tasks for easing the SSB and DS of RFR modeling. In addition, the CDF problem is tackled by incorporating both the knowledge of conversion and refund time contained in data for improving the generalization of models. The overall framework of ECAD is shown in Fig. 1, which consists of three parts: shared bottom layers, a delayed CVR model, and a delayed RFR model. Taking the canonically-used Embedding&MLP model architecture as an example, the shared bottom layers take the sample features (i.e. discrete IDs) as input and output a fixed-length vector, and then feed this vector into the towers of delayed CVR and delayed RFR models to predict the corresponding probabilities. The followings elaborate on how we build the ECAD model. 4.2.1 Prediction Model. The target of the prediction model is to estimate 𝑝 𝑒𝑐𝑣𝑟 = 𝑝 ( 𝑦 = 1 , 𝑧 = 0 | x ) by alternatively modeling 𝑝 𝑐𝑣𝑟 = 𝑝 ( 𝑦 = 1 | x ) and 𝑝 𝑟 𝑓 𝑟 = 𝑝 ( 𝑧 = 1 | 𝑦 = 1 , x ) using Eq. (1). However, this manner arises the SSB and DS problems for RFR prediction. To tackle these issues, we adopt the entire space modeling framework [11] for CVR and RFR prediction. Specifically, by exploiting the sequential dependence of 𝑐𝑙𝑖𝑐𝑘 → 𝑐𝑜𝑛𝑣𝑒𝑟𝑠𝑖𝑜𝑛 → 𝑟𝑒𝑓 𝑢𝑛𝑑 , we construct CVR and post-click conversion & refund rate (CVRFR) prediction tasks. Denote 𝑝 ( 𝑧 = 1 , 𝑦 = 1 | x ) as 𝑝 𝑐𝑣𝑟 𝑓 𝑟 of the sample x , then 𝑝 𝑟 𝑓 𝑟 can then be formulated as follows:  where 𝑝 ( 𝑧 = 1 , 𝑦 = 1 | x ) and 𝑝 ( 𝑦 = 1 | x ) are modeled on the entire space with click samples, thus tackling the SSB problem for modeling RFR prediction. Nevertheless, the 𝑝 𝑐𝑣𝑟 is small practically, thus 𝑝 𝑟 𝑓 𝑟 (i.e. 𝑝 𝑐𝑣𝑟 𝑓 𝑟 divided by 𝑝 𝑐𝑣𝑟 ) may be larger than 1, and then arise numerical instability. In our entire space modeling, the 𝑝 𝑐𝑣𝑟 𝑓 𝑟 is computed as 𝑝 𝑐𝑣𝑟 ∗ 𝑝 𝑟 𝑓 𝑟 , avoiding the problem of numerical instability. Furthermore, the embedding layers are shared within the bottom layers, which contribute most of the parameters in models, and learning it needs a huge number of samples. As such, the clicked samples (largely outnumber the conversion samples) are employed to help induce the RFR prediction model, alleviating the DS problem. Consisting of CVR and CVRFR prediction tasks, the learning objective is designed as follows:  where 𝑦 & 𝑧 returns 1 if 𝑦 = 1 and 𝑧 = 1, and 0 otherwise. Concretely, it corresponds to towers 2 and 3 and losses 2 and 3 in Fig. 1. However, these are still CDF problems not yet been handled. 4.2.2 Cascade Delayed Feedback Modeling. The CDF problem in our task refers to that the delayed feedback exists both in the sequentially dependent CVR and RFR prediction tasks. As such, it needs a longer attribution window to observe the corresponding labels for simultaneously modeling the CVR and RFR predictions using entire space modeling than individually achieving these two Entire Space Cascade Delayed Feedback Modeling for Effective Conversion Rate Prediction CIKM '23, October 21-25, 2023, University of Birmingham and Eastside Rooms, UK tasks. Hence, the CDF problem significantly harms the data freshness for training the predictor to capture the rapid distribution shift of data in the recommender system. To tackle this problem, we carefully design auxiliary tasks for incorporating the conversion and refund time to advance the generalization performance of predictors in a multi-task learning framework. Inspired by Defer [5], we employ the conversion and refund time contained within data for alleviating the delayed feedback problem in CVR and RFR prediction, respectively. Specifically, the 𝑛 + 𝑚 towers are built to predict whether the conversion sample will convert within the predefined time windows 𝑊 1 , 𝑊 2 , · · · , 𝑊 𝑛 (e.g. 𝑝 ( 𝑤 < 𝑊 𝑖 | 𝑦 = 1 , x )( 𝑖 : 1 → 𝑛 ) ), and whether the conversion but refunded sample will refund within the predefined time windows 𝑉 1 , 𝑉 2 , · · · , 𝑉 𝑚 (e.g. 𝑝 ( 𝑣 < 𝑉 𝑖 | 𝑧 = 1 , 𝑦 = 1 , x )( 𝑖 : 1 → 𝑚 ) ). To train the model with all samples, these probabilities are further multiplied by 𝑝 ( 𝑦 = 1 | x ) or 𝑝 ( 𝑧 = 1 , 𝑦 = 1 | x ) to obtain 𝑝 ( 𝑤 < 𝑊 𝑖 , 𝑦 = 1 | x ) and 𝑝 ( 𝑣 < 𝑉 𝑖 , 𝑧 = 1 , 𝑦 = 1 | x ) . Denote the label that whether sample x converts/refunds within 𝑊 𝑖 / 𝑉 𝑖 after click/conversion as 𝑦 𝑖 / 𝑧 𝑖 , Eq. (5) can be reformulated for achieving the CDF problem as follows:  In concrete, this model corresponds to towers 1~4 and losses 1~4 in Fig. 1. However, it cannot utilize the recently clicked samples whose CVR label 𝑦 has not been determined for learning the RFR prediction. To tackle this problem, we redesign the auxiliary tasks for the delayed RFR prediction model to excavate and leverage both the conversion and refund time for employing the recently clicked samples to boost the generalization performance. Specifically, we additionally add 𝑛 + 𝑛 ∗ 𝑚 towers for the delayed RFR prediction model, in which 𝑛 heads predict whether the conversion but refunded sample will convert within the predefined time windows 𝑊 1 , 𝑊 2 , · · · , 𝑊 𝑛 (e.g. 𝑝 ( 𝑤 < 𝑊 𝑖 | 𝑧 = 1 , 𝑦 = 1 , x )( 𝑖 : 1 → 𝑛 )) while other 𝑛 ∗ 𝑚 heads predict whether these samples will convert and refund with the predefined time windows 𝑊 1 , 𝑊 2 , · · · , 𝑊 𝑛 and 𝑉 1 , 𝑉 2 , · · · , 𝑉 𝑚 (i.e. 𝑝 ( 𝑣 < 𝑉 𝑗 , 𝑤 < 𝑊 𝑖 | 𝑧 = 1 , 𝑦 = 1 , x )( 𝑖 : 1 → 𝑛, 𝑗 : 1 → 𝑚 ) ), respectively. Then these probabilities are multiplied by 𝑝 ( 𝑧 = 1 , 𝑦 = 1 | x ) to model all the samples. Thus, Eq. (6) is further schemed as follows:  However, the total number of towers in the entire model would increase from 𝑛 + 𝑚 + 2 to 𝑛 ∗ 𝑚 + 2 𝑛 + 𝑚 + 2 when there are 𝑛 and 𝑚 pre-defined windows in the CVR and RFR tasks respectively, corresponding to Eq. (6) and Eq. (7). The excessive number of towers results in the model being too complex, thus harming its practicality. To address this problem, our ECAD further cuts 𝑛 ∗ 𝑚 towers that predict 𝑝 ( 𝑣 < 𝑉 𝑗 , 𝑤 < 𝑊 𝑖 | 𝑧 = 1 , 𝑦 = 1 , x ) and approximates these output using 𝑝 ( 𝑣 < 𝑉 𝑖 | 𝑧 = 1 , 𝑦 = 1 , x ) and 𝑝 ( 𝑤 < 𝑊 𝑗 , | 𝑧 = 1 , 𝑦 = 1 , x ) as follows:  We hypothesize conversion and refund time are independent for conversion but refunded samples, thus this equation holds and its effectiveness is demonstrated in later experiments. In this way, the number of towers is reduced to 2 𝑛 + 𝑚 + 2, which largely improves applicability, and we name this simplified method as ECAD-Lite. Note that samples near the end of the training date may not have all 𝑛 + 𝑚 + 2 labels (i.e. 𝑦 1 , 𝑦 2 , · · · , 𝑦 𝑛 , 𝑧 1 , 𝑧 2 , · · · , 𝑧 𝑚 , 𝑦, 𝑧 ), ECAD only updates corresponding parameters according to the observed labels.",
  "5 EXPERIMENT": "In this section, we conduct extensive experiments on the offline dataset and online A/B testing to validate the superiority of ECAD.",
  "5.1 Experimental Setup": "5.1.1 Dataset. As there is no public dataset for ECVR prediction under the CDF problem, we collect click traffic logs of 11 days from Alibaba's recommender system to build the production dataset with 0.56 billion samples, each with 209 features (e.g user and item features). Furthermore, the number of conversions, refunds, and effective conversions, are 3.75, 0.61, and 3.14 million, respectively. The samples in the first 10 days and 11th day are employed for training and testing respectively, and we randomly partition the testing set into 10 parts and report average evaluation results. In addition, the attribution windows for conversion and refund are both set as 3 days. For example, if a sample is clicked (converted) on 1st day, its CVR (RFR) label can be determined at the end of 3rd day. As such, for a sample clicked on 1st day, its ECVR label can be obtained at the end of 5th day. 5.1.2 Baseline. To perform a comprehensive comparison, we implemented and compared the following methods: (i) CVR-Base : A base model trained using the samples clicked before 2nd day from the last, predicting the 𝑝 𝑐𝑣𝑟 . (ii) RFR-Base : A base model trained using the samples which convert before 2nd day from the last, predicting the 𝑝 𝑟 𝑓 𝑟 . (iii) ECVR-Base : A base model trained using the samples clicked before the 4th day from the last, predicting the 𝑝 𝑒𝑐𝑣𝑟 . (iv) IM : Independent modeling (IM) employs the CVRBase and RFR-Base to achieve the ECVR prediction using Eq (1). (v) IM-Defer : It first utilizes Defer [5] to independently perform CVR and RFR modeling, and then estimates the 𝑝 𝑒𝑐𝑣𝑟 using Eq. (1). (vi) ESMM [11]: This model fulfills the CVR and RFR modeling in an entire space modeling manner. It is first trained using Eq. (5) on the samples clicked before the 4th day from the last and then predicts 𝑝 𝑒𝑐𝑣𝑟 using Eq. (1). (vii) ECAD : The proposed ECAD method first employs both the conversion and refund time to advance the model using Eq. (7), and then predicts 𝑝 𝑒𝑐𝑣𝑟 via Eq (1). (viii) ECAD-De : A degenerate version of ECAD, which is trained using Eq. (6). (ix) ECAD-Lite : A lite version of ECAD, which cuts down towers using CIKM '23, October 21-25, 2023, University of Birmingham and Eastside Rooms, UK Zhao and Yan, et al. Table 1: Performance of compared models on the production dataset in three tasks: CVR, RFR, and ECVR prediction. The best performance in each setting is bold-faced. ◦/· indicates that ECAD is statistically worse/better than the compared method by student pairwise 𝑡 -test at 95% confident level. Eq. (8). (x) ESMM-Oracle : An oracle version of ESMM, i.e. it can access CVR and RFR labels of all training samples, which provide the upper bound performance using the entire space modeling. the experimental results in Table 1. From this table, we have the following observations: All methods are implemented with Python 2.7 and Tensorflow 1.12 and follow an Embedding&MLP architecture. Specifically, CVRBase, RFR-Base, and ECVR-Base have one tower above the bottom layers for predicting the respective probability, while others have multiple towers on top of the shared bottom layers to predict the corresponding probability. For a fair comparison, all compared methods use the following configurations: the optimizer AdagradDecay [4], the learning rate 0.05, the bath size 256, the bottom layers and tower are configured as embedding layers and fully-connected layers with hidden size { 512 , 256 , 128 } respectively, and the activation functions Leaky ReLU [12]. Following [33], each method is trained with one epoch. Note that although there are several different works that focus on delayed feedback modeling [2, 6, 9, 24-27], we do not employ them as compared methods as we focus on how to deal with the CDF problems, but not on proposing an effective method to achieve delayed feedback in a single event. 5.1.3 Evaluation Metric. Following previous works [5, 24], we adopt two widely used metrics for evaluating offline experimental results. The first metric is the area under the ROC curve (AUC) which indicates the probability that a positive sample is ranked higher than a negative one (0.1% improvement on AUC in industrial datasets is deemed as significant [15, 35]). The second metric is the area under the precision-recall curve (PR-AUC), which is more sensitive than AUC in scenarios where negative samples significantly outnumber positive ones. Besides, We also report the relative improvement of methods over the base model in each task on AUC and PR-AUC [5]. Taking the relative improvement of ECAD on AUC (denoted as RI-AUC) in CVR prediction as an example, the RI-AUCECDA can be computed as follows:  Obviously, the method's performance improves as the relative improvement approaches 100%.",
  "5.2 Experimental Result": "We evaluate all compared approaches on the production dataset in three tasks (i.e. CVR, RFR, and ECVR prediction), and report (i) The proposed ECAD almost always manifests superior performance compared to other methods across various tasks and metrics except for the PRAUC metric in CVR prediction where it falls slightly behind IM-Defer, validating the superiority of ECAD. (ii) For CVR prediction, the big performance gap between delayed feedback modeling methods (ECAD, ECAD-Lite, ECAD-De, and IM-Defer) and approaches without delayed feedback modeling (IM and ESMM) proves the necessity for tackling the delayed feedback problem, which significantly compromises the data freshness for training the predictor. (iii) For RFR prediction, the entire space modeling strategies (ECAD, ECAD-Lite, ECAD-De, and ESMM) clearly outperform the independent modeling techniques (IM, IM-Defer) since the DS and SSB problem limit the supervised information and harm the model generalization, respectively. Besides, the results that IM-Defer is outperformed by ESMM demonstrate that the DS and SSB problems are more prominent for degrading the model performance than delayed feedback problems in RFR prediction. (iv) For ECVR prediction, ECVR-Base loses to all other approaches, which confirms the effectiveness of our strategy for ECVR prediction by decomposing it into two sub-tasks, alleviating the CDF problem and making full use of different knowledge between nonconversion and conversion but refunded samples. (v) ECAD and ECAD-Lite generally achieve better performance than ECAD-De especially in the RFR prediction, which confirms the effectiveness of our proposed techniques that employ both conversion and refund time contained within data for achieving the CDF problem in the RFR prediction, thus boosting the performance of predictors. Furthermore, there is a slight decrease in performance for ECAD-Lite compared to ECAD, which proves the validity of our probability approximation manner in Eq. (8) for simplifying the model architecture.",
  "5.3 Online A/B Testing": "The proposed ECAD approach for ECVR prediction is an offline training method, and we conduct online A/B testing to evaluate its effectiveness on our production systems that apply offline training. To get a stable conclusion, we observe the online experiments for 7 days, which showed that ECAD achieved a 5.21% improvement in Entire Space Cascade Delayed Feedback Modeling for Effective Conversion Rate Prediction CIKM '23, October 21-25, 2023, University of Birmingham and Eastside Rooms, UK ECVR compared to the ECVR-Base model, which can bring huge benefits to the e-commerce platform. Furthermore, the ECAD model has also been deployed on one of our recommender systems.",
  "6 CONCLUSION": "In this paper, we have investigated the practical but unexplored ECVR prediction task by partitioning it into two sub-tasks (i.e. CVR and RFR prediction) and pointed out a novel, thorny but untouched problem of cascade delayed feedback (CDF), where conversion and refund events both suffer the delayed feedback. To tackle these challenges, we propose an Entire space CAscade Delayed feedback modeling (ECAD) approach that adopts an entire space modeling framework to address the SSB and DS problems in learning RFR predictors. Furthermore, the auxiliary tasks are carefully designed to exploit both the conversion and refund time contained within the data to advance the performance of the method, alleviating the CDF. Experimental results on both the offline production dataset and online A/B testing validate the superiority of the proposed method. ECAD has been deployed in one of the recommender systems in Alibaba, bringing significant improvement of ECVR.",
  "REFERENCES": "[1] Zhangming Chan, Yu Zhang, Shuguang Han, Yong Bai, Xiang-Rong Sheng, Siyuan Lou, Jiacen Hu, Baolin Liu, Yuning Jiang, Jian Xu, et al. 2023. Capturing Conversion Rate Fluctuation during Sales Promotions: A Novel Historical Data Reuse Approach. In KDD . 1-11. [2] Yu Chen, Jiaqi Jin, Hui Zhao, Pengjie Wang, Guojun Liu, Jian Xu, and Bo Zheng. 2022. Asymptotically unbiased estimation for delayed feedback modeling via label correction. In The Web Conf. 369-379. [3] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al. 2016. Wide & deep learning for recommender systems. In Workshop on Deep Learning for Recommender Systems . 7-10. [4] John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. JMLR 12, 7 (2011), 2121-2159. [5] Siyu Gu, Xiang-Rong Sheng, Ying Fan, Guorui Zhou, and Xiaoqiang Zhu. 2021. Real negatives matter: Continuous training with real negatives for delayed feedback modeling. In KDD . 2890-2898. [6] Yilin Hou, Guangming Zhao, Chuanren Liu, Zhonglin Zu, and Xiaoqiang Zhu. 2021. Conversion prediction with delayed feedback: A multi-task learning approach. In ICDM . 191-199. [7] Zhigang Huangfu, Gong-Duo Zhang, Zhengwei Wu, Qintong Wu, Zhiqiang Zhang, Lihong Gu, Jun Zhou, and Jinjie Gu. 2022. A Multi-Task Learning Approach for Delayed Feedback Modeling. In The Web Conf. 116-120. [8] Jiarui Jin, Xianyu Chen, Weinan Zhang, Yuanbo Chen, Zaifan Jiang, Zekun Zhu, Zhewen Su, and Yong Yu. 2022. Multi-Scale User Behavior Network for Entire Space Multi-Task Learning. In CIKM . 874-883. [9] Sofia Ira Ktena, Alykhan Tejani, Lucas Theis, Pranay Kumar Myana, Deepak Dilipkumar, Ferenc Huszár, Steven Yoo, and Wenzhe Shi. 2019. Addressing delayed feedback for continuous training with neural networks in CTR prediction. In RecSys . 187-195. [10] Kuang-chih Lee, Burkay Orten, Ali Dasdan, and Wentong Li. 2012. Estimating conversion rate in display advertising from past erformance data. In KDD . 768776. [11] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun Gai. 2018. Entire space multi-task model: An effective approach for estimating post-click conversion rate. In SIGIR . 1137-1140. [12] Andrew L Maas, Awni Y Hannun, Andrew Y Ng, et al. 2013. Rectifier nonlinearities improve neural network acoustic models. In Workshop on ICML . [13] Rong Pan, Yunhong Zhou, Bin Cao, Nathan N Liu, Rajan Lukose, Martin Scholz, and Qiang Yang. 2008. One-class collaborative filtering. In ICDM . 502-511. [14] Matthew Richardson, Ewa Dominowska, and Robert Ragno. 2007. Predicting clicks: estimating the click-through rate for new ads. In WWW . 521-530. [15] Xiang-Rong Sheng, Jingyue Gao, Yueyao Cheng, Siran Yang, Shuguang Han, Hongbo Deng, Yuning Jiang, Jian Xu, and Bo Zheng. 2023. Joint Optimization of Ranking and Calibration with Contextualized Hybrid Model. In KDD . 1-9. [16] Yumin Su, Liang Zhang, Quanyu Dai, Bo Zhang, Jinyao Yan, Dan Wang, Yongjun Bao, Sulong Xu, Yang He, and Weipeng Yan. 2021. An attention-based model for conversion rate prediction with delayed feedback via post-click calibration. In IJCAI . 3522-3528. [17] Hao Wang, Tai-Wei Chang, Tianqiao Liu, Jianmin Huang, Zhichao Chen, Chao Yu, Ruopeng Li, and Wei Chu. 2022. ESCM2: Entire Space Counterfactual Multi-Task Model for Post-Click Conversion Rate Estimation. In SIGIR . 363-372. [18] Yanshi Wang, Jie Zhang, Qing Da, and Anxiang Zeng. 2020. Delayed feedback modeling for the entire space conversion rate prediction. arXiv preprint arXiv:2011.11826 (2020). [19] Gary M Weiss. 2004. Mining with rarity: a unifying framework. ACM Sigkdd Explorations Newsletter 6, 1 (2004), 7-19. [20] Hong Wen, Jing Zhang, Fuyu Lv, Wentian Bao, Tianyi Wang, and Zulong Chen. 2021. Hierarchically modeling micro and macro behaviors via multi-task learning for conversion rate prediction. In SIGIR . 2187-2191. [21] Hong Wen, Jing Zhang, Yuan Wang, Fuyu Lv, Wentian Bao, Quan Lin, and Keping Yang. 2020. Entire space multi-task modeling via post-click behavior decomposition for conversion rate prediction. In SIGIR . 2377-2386. [22] Dongbo Xi, Zhen Chen, Peng Yan, Yinger Zhang, Yongchun Zhu, Fuzhen Zhuang, and Yu Chen. 2021. Modeling the sequential dependence among audience multistep conversions with multi-task learning in targeted display advertising. In KDD . 3745-3755. [23] Zixuan Xu, Penghui Wei, Weimin Zhang, Shaoguo Liu, Liang Wang, and Bo Zheng. 2022. UKD: Debiasing Conversion Rate Estimation via Uncertainty-regularized Knowledge Distillation. In The Web Conf. 2078-2087. [24] Jia-Qi Yang, Xiang Li, Shuguang Han, Tao Zhuang, De-Chuan Zhan, Xiaoyi Zeng, and Bin Tong. 2021. Capturing delayed feedback in conversion rate prediction via elapsed-time sampling. In AAAI . 4582-4589. [25] Jia-Qi Yang and De-Chuan Zhan. 2022. Generalized Delayed Feedback Model with Post-Click Information in Recommender Systems. In NeurIPS . 26192-26203. [26] Shota Yasui and Masahiro Kato. 2022. Learning Classifiers under Delayed Feedback with a Time Window Assumption. In KDD . 2286-2295. [27] Shota Yasui, Gota Morishita, Fujita Komei, and Masashi Shibata. 2020. A feedback shift correction in predicting conversion rates under delayed feedback. In The Web Conf. 2740-2746. [28] Mao Ye, Ruichen Jiang, Haoxiang Wang, Dhruv Choudhary, Xiaocong Du, Bhargav Bhushanam, Aryan Mokhtari, Arun Kejariwal, and Qiang Liu. 2022. Future gradient descent for adapting the temporal shifting data distribution in online recommendation systems. In UAI . 2256-2266. [29] Bianca Zadrozny. 2004. Learning and evaluating classifiers under sample selection bias. In ICML . 114-121. [30] Wenhao Zhang, Wentian Bao, Xiao-Yang Liu, Keping Yang, Quan Lin, Hong Wen, and Ramin Ramezani. 2020. Large-scale causal approaches to debiasing post-click conversion rate estimation with multi-task learning. In The Web Conf. 2775-2781. [31] Weinan Zhang, Tianxiong Zhou, Jun Wang, and Jian Xu. 2016. Bid-aware gradient descent for unbiased learning with censored data in display advertising. In KDD . 665-674. [32] Yu Zhang and Qiang Yang. 2021. A survey on multi-task learning. TKDE 34, 12 (2021), 5586-5609. [33] Zhao-Yu Zhang, Xiang-Rong Sheng, Yujing Zhang, Biye Jiang, Shuguang Han, Hongbo Deng, and Bo Zheng. 2022. Towards Understanding the Overfitting Phenomenon of Deep Click-Through Rate Models. In CIKM . 2671-2680. [34] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Deep interest evolution network for click-through rate prediction. In AAAI . 5941-5948. [35] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In KDD . 1059-1068. [36] Feng Zhu, Mingjie Zhong, Xinxing Yang, Longfei Li, Lu Yu, Tiehua Zhang, Jun Zhou, Chaochao Chen, Fei Wu, Guanfeng Liu, et al. 2023. DCMT: A Direct EntireSpace Causal Multi-Task Framework for Post-Click Conversion Estimation. In ICDE . 1-13. [37] Jieming Zhu, Jinyang Liu, Shuai Yang, Qi Zhang, and Xiuqiang He. 2021. Open benchmarking for click-through rate prediction. In CIKM . 2759-2769.",
  "keywords_parsed": [
    "Effective Conversion Rate Prediction",
    "Cascade Delayed Feedback",
    "Data Sparsity",
    "Sample Selection Bias",
    "Entire Space Modeling"
  ],
  "references_parsed": [
    {
      "ref_id": "b1",
      "title": "Capturing Conversion Rate Fluctuation during Sales Promotions: A Novel Historical Data Reuse Approach"
    },
    {
      "ref_id": "b2",
      "title": "Asymptotically unbiased estimation for delayed feedback modeling via label correction"
    },
    {
      "ref_id": "b3",
      "title": "Wide & deep learning for recommender systems"
    },
    {
      "ref_id": "b4",
      "title": "Adaptive subgradient methods for online learning and stochastic optimization"
    },
    {
      "ref_id": "b5",
      "title": "Real negatives matter: Continuous training with real negatives for delayed feedback modeling"
    },
    {
      "ref_id": "b6",
      "title": "Conversion prediction with delayed feedback: A multi-task learning approach"
    },
    {
      "ref_id": "b7",
      "title": "A Multi-Task Learning Approach for Delayed Feedback Modeling"
    },
    {
      "ref_id": "b8",
      "title": "Multi-Scale User Behavior Network for Entire Space Multi-Task Learning"
    },
    {
      "ref_id": "b9",
      "title": "Addressing delayed feedback for continuous training with neural networks in CTR prediction"
    },
    {
      "ref_id": "b10",
      "title": "Estimating conversion rate in display advertising from past performance data"
    },
    {
      "ref_id": "b11",
      "title": "Entire space multi-task model: An effective approach for estimating post-click conversion rate"
    },
    {
      "ref_id": "b12",
      "title": "Rectifier nonlinearities improve neural network acoustic models"
    },
    {
      "ref_id": "b13",
      "title": "One-class collaborative filtering"
    },
    {
      "ref_id": "b14",
      "title": "Predicting clicks: estimating the click-through rate for new ads"
    },
    {
      "ref_id": "b15",
      "title": "Joint Optimization of Ranking and Calibration with Contextualized Hybrid Model"
    },
    {
      "ref_id": "b16",
      "title": "An attention-based model for conversion rate prediction with delayed feedback via post-click calibration"
    },
    {
      "ref_id": "b17",
      "title": "ESCM2: Entire Space Counterfactual Multi-Task Model for Post-Click Conversion Rate Estimation"
    },
    {
      "ref_id": "b18",
      "title": "Delayed feedback modeling for the entire space conversion rate prediction"
    },
    {
      "ref_id": "b19",
      "title": "Mining with rarity: a unifying framework"
    },
    {
      "ref_id": "b20",
      "title": "Hierarchically modeling micro and macro behaviors via multi-task learning for conversion rate prediction"
    },
    {
      "ref_id": "b21",
      "title": "Entire space multi-task modeling via post-click behavior decomposition for conversion rate prediction"
    },
    {
      "ref_id": "b22",
      "title": "Modeling the sequential dependence among audience multistep conversions with multi-task learning in targeted display advertising"
    },
    {
      "ref_id": "b23",
      "title": "UKD: Debiasing Conversion Rate Estimation via Uncertainty-regularized Knowledge Distillation"
    },
    {
      "ref_id": "b24",
      "title": "Capturing delayed feedback in conversion rate prediction via elapsed-time sampling"
    },
    {
      "ref_id": "b25",
      "title": "Generalized Delayed Feedback Model with Post-Click Information in Recommender Systems"
    },
    {
      "ref_id": "b26",
      "title": "Learning Classifiers under Delayed Feedback with a Time Window Assumption"
    },
    {
      "ref_id": "b27",
      "title": "A feedback shift correction in predicting conversion rates under delayed feedback"
    },
    {
      "ref_id": "b28",
      "title": "Future gradient descent for adapting the temporal shifting data distribution in online recommendation systems"
    },
    {
      "ref_id": "b29",
      "title": "Learning and evaluating classifiers under sample selection bias"
    },
    {
      "ref_id": "b30",
      "title": "Large-scale causal approaches to debiasing post-click conversion rate estimation with multi-task learning"
    },
    {
      "ref_id": "b31",
      "title": "Bid-aware gradient descent for unbiased learning with censored data in display advertising"
    },
    {
      "ref_id": "b32",
      "title": "A survey on multi-task learning"
    },
    {
      "ref_id": "b33",
      "title": "Towards Understanding the Overfitting Phenomenon of Deep Click-Through Rate Models"
    },
    {
      "ref_id": "b34",
      "title": "Deep interest evolution network for click-through rate prediction"
    },
    {
      "ref_id": "b35",
      "title": "Deep interest network for click-through rate prediction"
    },
    {
      "ref_id": "b36",
      "title": "DCMT: A Direct Entire-Space Causal Multi-Task Framework for Post-Click Conversion Estimation"
    },
    {
      "ref_id": "b37",
      "title": "Open benchmarking for click-through rate prediction"
    }
  ]
}