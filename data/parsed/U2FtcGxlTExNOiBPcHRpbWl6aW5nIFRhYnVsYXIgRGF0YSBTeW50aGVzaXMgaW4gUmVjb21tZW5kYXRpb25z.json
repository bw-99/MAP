{
  "SampleLLM: Optimizing Tabular Data Synthesis in Recommendations": "Jingtong Gao ∗ City University of Hong Kong Hong Kong, China jt.g@my.cityu.edu.hk Zhaocheng Du ∗ Huawei Noah's Ark Lab Shenzhen, China zhaochengdu@huawei.com Xiaopeng Li City University of Hong Kong Hong Kong, China xiaopli2-c@my.cityu.edu.hk Yichao Wang Huawei Noah's Ark Lab Shenzhen, China wangyichao5@huawei.com Xiangyang Li Huawei Noah's Ark Lab Shenzhen, China lixiangyang34@huawei.com Ruiming Tang † Huawei Noah's Ark Lab Shenzhen, China tangruiming@huawei.com",
  "Abstract": "Tabular data synthesis is crucial in machine learning, yet existing general methods-primarily based on statistical or deep learning models-are highly data-dependent and often fall short in recommender systems. This limitation arises from their difficulty in capturing complex distributions and understanding complicated feature relations from sparse and limited data, along with their inability to grasp semantic feature relations. Recently, Large Language Models (LLMs) have shown potential in generating synthetic data through few-shot learning and semantic understanding. However, they often suffer from inconsistent distribution and lack of diversity due to their inherent distribution disparity with the target dataset. To address these challenges and enhance tabular data synthesis for recommendation tasks, we propose a novel two-stage framework named SampleLLM to improve the quality of LLM-based tabular data synthesis for recommendations by ensuring better distribution alignment. In the first stage, SampleLLM employs LLMs with Chainof-Thought prompts and diverse exemplars to generate data that closely aligns with the target dataset distribution, even when input samples are limited. The second stage uses an advanced feature attribution-based importance sampling method to refine feature relationships within the synthetic data, reducing any distribution biases introduced by the LLM. Experimental results on three recommendation datasets, two general datasets, and online deployment illustrate that SampleLLM significantly surpasses existing methods ∗ These authors contributed equally to this work. † Corresponding authors. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WWW'25, April 28-May 02, 2025, Sydney, Australia. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-XXXX-X/18/06 https://doi.org/XXXXXXX.XXXXXXX Huifeng Guo Huawei Noah's Ark Lab Shenzhen, China huifeng.guo@huawei.com",
  "Xiangyu Zhao †": "City University of Hong Kong Hong Kong, China xianzhao@cityu.edu.hk for recommendation tasks and holds promise for a broader range of tabular data scenarios.",
  "CCS Concepts": "· Information systems → Data mining .",
  "Keywords": "Recommender System, Tabular data generation, Large Language Model",
  "ACMReference Format:": "Jingtong Gao, Zhaocheng Du, Xiaopeng Li, Yichao Wang, Xiangyang Li, Huifeng Guo, Ruiming Tang, and Xiangyu Zhao. 2018. SampleLLM: Optimizing Tabular Data Synthesis in Recommendations. In Proceedings of the ACM Web Conference 2025 (WWW '25). ACM, New York, NY, USA, 11 pages. https://doi.org/XXXXXXX.XXXXXXX",
  "1 Introduction": "Tabular data is integral to a wide array of machine learning applications across sectors like e-commerce and healthcare, underscoring its foundational importance [5, 12, 17, 20, 40]. This widespread reliance amplifies the urgent demand for high-quality synthetic tabular data, particularly in recommender systems, where data sparsity poses significant challenges [5, 21, 43]. Insufficient quality and volume of datasets critically impair the performance and efficiency of machine learning models [4]. Traditional tabular data synthesis methods [2, 13, 48], focusing on a wide range of general tasks, primarily rely on statistical and deep learning models, which are heavily data-dependent and effective with abundant data availability [14]. However, when applied to recommendation tasks, these methods not only struggle in scenarios characterized by inherent data sparsity and scarcity but also fail to capture the semantic relationships between features, which is proven to be more and more crucial in recommendation modeling [27, 35]. Consequently, there is a pressing need for innovative approaches capable of generating high-quality synthetic tabular WWW'25, April 28-May 02, 2025, Sydney, Australia. Gao et al. Figure 1: Visualization of LLM-generated and original tabular samples on the HELOC dataset reveals that the synthetic data lacks distribution alignment and diversity, clustering around a few centers within the original data distribution. -60 -40 -20 0 20 40 60 -20 0 20 40 60 Original LLM Generation data from minimal input while understanding semantic feature relations for recommendation tasks. The advent of Large Language Models (LLMs) has marked a shift in possibilities [52], offering new capabilities through fewshot learning and deep semantic understanding [6, 9, 37]. Despite their promise in synthetic data generation, LLMs frequently encounter challenges with inconsistent distributions and inaccurately modeled feature relationships [16, 34], both of which are critical for effective recommendation modeling [47, 60, 61]. These challenges arise from an intrinsic distribution mismatch between LLMs' inherent knowledge and target datasets. Moreover, when using limited exemplars, a simplistic random selection for few-shot learning might overlook important regions of the original dataset, leading to reduced output diversity, as demonstrated in Figure 1. To address these challenges, we propose SampleLLM, a novel two-stage framework designed to enhance the quality of LLM-based tabular data synthesis in recommendation tasks. The first stage utilizes LLMs with Chain-of-Thought prompts [51] and a curated selection of diverse exemplars to improve semantic understanding and feature relation modeling [33] in generating synthetic data with limited input samples. The second stage further integrates a feature attribution-based importance sampling technique to refine the synthetic data, reducing any distribution biases introduced by LLMs by employing a semi-independence assumption for feature interactions that could streamline computation while preserving the essential characteristics and relationships within the dataset. In summary, our contribution could be summarized as follows: · To the best of our knowledge, this is the first method to consider distribution alignment for LLM-based tabular data synthesis in recommendations. · We propose a comprehensive framework SampleLLM that combines a feature attribution-based importance sampling strategy for distribution alignment with advanced few-shot LLM generation techniques. This integration significantly enhances the utility and distribution consistency of the generated tabular data. · Experiments conducted on three widely used recommendation datasets, two general datasets, and through online deployment reveal that the synthetic tabular data generated by SampleLLM not only surpasses existing baselines in recommendation tasks but also shows promise for broader application in general tasks.",
  "2 Framework": "In this section, we first describe the problem formulation of the tabular data synthesis, and then provide an overview of SampleLLM and detail its key components.",
  "2.1 Problem Formulation": "The task of tabular data synthesis involves generating synthetic tabular data that closely resemble those in a given dataset. The synthetic data is used for various purposes, including augmenting training datasets and conducting experiments without exposing sensitive information. Formally, let D 𝑜 = { 𝒙 1 , 𝒙 2 , . . . , 𝒙 𝑁 } represent the original dataset with 𝑁 samples, where each 𝒙 𝑖 is a sample with 𝐾 attributes and one label 𝑦 𝑖 , i.e., 𝒙 𝑖 = { 𝑥 1 𝑖 , 𝑥 2 𝑖 , . . . , 𝑥 𝐾 𝑖 , 𝑦 𝑖 } . The objective is to develop a generative model 𝐺 that produces a synthetic dataset with 𝑇 samples D 𝑠 = { 𝒙 ′ 1 , 𝒙 ′ 2 , . . . , 𝒙 ′ 𝑇 } such that D 𝑠 exhibits similar statistical properties and distributional characteristics as D 𝑜 and could be applied to various tasks with similar performance. These requirements can be formalized as follows: · Distributional Similarity : The synthetic dataset D 𝑠 should follow the similar distribution as the original dataset D 𝑜 . This can be expressed as:  where 𝑃 D 𝑠 ( 𝑋 ) and 𝑃 D 𝑜 ( 𝑋 ) denote the probability distributions of the synthetic and original datasets, respectively. · Utility : The synthetic dataset D 𝑠 should be useful for the same downstream tasks as the original dataset D 𝑜 . If D 𝑠 is used to train a machine learning model M , the model's performance on downstream tasks should closely match that of a model trained on the original dataset D 𝑜 . Formally, this can be expressed as:  where 𝑈 (D 𝑜 , M) denotes the utility of D 𝑜 for model M . For simplicity, this aspect is referred to as Machine Learning Efficacy (MLE) utility [46, 54] in this paper. In addition, in terms of data enhancement [8, 13], we aim for the machine learning model M trained on the combined dataset D 𝑜 +D 𝑠 to achieve performance on downstream tasks that is comparable to or surpasses that of a model trained exclusively on the original dataset D 𝑜 . Formally, this can be expressed as:  For simplicity, this aspect is referred to as augumentation utility in this paper. By ensuring these properties, the synthetic dataset D 𝑠 can effectively supplement or substitute for the original dataset D 𝑜 in various applications, providing a valuable tool for data argumentation and analysis while preserving privacy and confidentiality.",
  "2.2 SampleLLM Overview": "As illustrated in Figure 2, SampleLLM consists of two stages. In the first stage, the designed instruction and sampled exemplars from the original dataset D 𝑜 are selected to serve as the input for the LLM, producing synthetic tabular data D 𝑠 ′ . In the second stage, a novel feature attribution-based importance sampling operation is performed to achieve further feature relation modeling and distributional alignment between the synthetic and original datasets, resulting in the final synthetic dataset D 𝑠 . Specifically, in the first stage, an instruction 𝐼 is designed to explain the data generation task to the LLM. This instruction is first selected from a set of manually crafted instructions based on performance criteria, and then refined by LLM with official SampleLLM: Optimizing Tabular Data Synthesis in Recommendations WWW'25, April 28-May 02, 2025, Sydney, Australia. Figure 2: The overall structure of SampleLLM. (a) In the first stage, a manually designed instruction and 𝑎 samples extracted with clustering sampling are used as inputs to the LLM, which generates 𝑏 synthetic samples. This process is repeated 𝑄 times. (b) In the second stage, a novel feature attribution-based importance sampling method is employed on the synthetic samples. Calculating Sample Weights Feature Groups Large Language Model (LLM) Instruction {(1,2,3),  (4),  (5), … } user_id movie_id genres rating 86 51 Drama 0 343 17 Action 0 2698 310 Musical 1 Answer: [Instruction     ] MovieLens-1M  dataset  is … ;  Here  are some  samples … ; Please  generate  10 samples … ; The format … [Examples       ] user_id is 1, movie_id is 51, … user_id is 312, movie_id is 56 … … Sure!, here are 10 generated samples similar to the given examples: user_id is 86, movie_id is 51, … user_id is 343, movie_id is 17, … … Interaction Attribution user_id movie_id genres rating 1 51 Drama 0 312 56 Musical 1 343 291 Drama 1 125 17 Action 0 86 139 Action 1 … Filtered by user_id movie_id genres rating 86 51 Drama 0 2698 310 Musical 1 (a) The First Stage of SampleLLM (b) The Second Stage of SampleLLM Original Tabular Dataset Cluster Sampling Generating Q Times Synthetic Tabular Data Final Synthetic Tabular Dataset Interaction Maps Overall Interaction Map Model on the Original Dataset Model on the Synthetic Dataset LLM Refinement Importance Sampling",
  "An simple example of the instruction": "The MovieLens IM movie dataset is stable benchmark dataset with million ratings from 6000 users on 4000 movies. Here are some samples of this dataset: {a Exemplars} rating",
  "2.3 Designed Instruction": "According to the format; distribution; content, column name and column relation of the above samples, as well as the provided descriptions and your logic and general knowledge; please generate {b} new data for data enhancement use in the same format directly. The new samples must not exist in the given data. The samples should also conform to the semantic meaning of each column provided by the column title and the internal logic in the feature combination. Figure 3: A simplified instruction example. documents and a small number of samples in a Chain-of-Thought (CoT) manner to extract key information. Following this, a cluster sampling method is applied to the original tabular data to generate 𝑎 exemplars represented by 𝐸 . This ensures that the data generated by the LLM is diverse and closely resembles the original distribution. By combining the instruction and exemplars as inputs, the LLM generates 𝑏 synthetic samples using a few-shot learning strategy. This process is repeated 𝑄 times to produce a total of 𝑏𝑄 synthetic samples, where 𝑎 , 𝑏 , and 𝑄 are hyper-parameters. In the second stage, an innovative importance sampling method is applied to the synthetic dataset D 𝑠 ′ to further align its distribution with that of the original data D 𝑜 . The weight of each sample is determined by the joint distribution probability of the features and labels under a semiindependent hypothesis where the non-independent feature groups are obtained through the overall interaction map of the original dataset and the discriminant probabilities of different labels are given by a predictive model trained on the corresponding dataset. Traditional statistical and deep learning models are predominantly data-driven, necessitating substantial volumes of samples to accurately model data distributions. This reliance significantly limits their effectiveness when dealing with recommendation tasks with small and sparse datasets, where synthetic data generation becomes crucial. Furthermore, when it comes to textual features, these models typically use ID encodings as input, hindering their ability to capture the semantic associations between features. To address these limitations, we leverage the general knowledge and semantic understanding capabilities of LLMs for data synthesis via few-shot learning. A pivotal component of this approach is the precise framing of the tabular data synthesis task within the prompt, referred to as the instruction, as illustrated in Figure 3. Here, we identify the most effective instruction from a set of manually crafted options tailored to each dataset. In our study, the final instruction for each dataset is selected from five custom-designed instructions. Specifically, for each dataset, 1% synthetic samples are generated and incorporated into the training set. The instruction that delivers the best performance is then established as the standard for that dataset. To further enhance the instruction with relevant knowledge, we input the manually curated instruction, along with official documents 𝑂 and a few data samples 𝑆 , into the LLM, which iteratively refines the instruction expression using a Chain-of-Thought process. This procedure is described as follows:  WWW'25, April 28-May 02, 2025, Sydney, Australia. Gao et al. where the maximum value of iteration times 𝑡 is fixed at 5. For simplicity, we denote the final output instruction as 𝐼 .",
  "2.4 Selecting Exemplars": "As the key to few-shot learning, exemplars are crucial for providing LLMs with a small number of examples that standardize the format, content, and distribution of LLM-generated samples. However, current studies [3] often select exemplars randomly from the original dataset. This approach may fail to capture the diverse distribution of the original data, especially since the number of exemplars is limited by the maximum input tokens of the LLM. Furthermore, the intrinsic distribution differences between LLM's inherent knowledge and target dataset exacerbate this issue. Consequently, as shown in Figure 1, significant distribution discrepancies are observed between the generated and original tabular samples. To address these problems, two alignment methods are applied in SampleLLM. The first method aims to maintain sample diversity during exemplar selection to avoid distribution concentration, as detailed below. The second method discussed further in Section 2.5, leverages a novel feature attribution-based importance sampling method to model critical feature relations and address the distribution differences caused by the LLM. To ensure exemplars reflect the diverse characteristics of the original data and mitigate the sample aggregation issue in LLM output, a simple clustering-based sampling method is first proposed in SampleLLM for exemplar selection. This approach is mathematically represented as follows:  Here, 𝑎 clusters { 𝑐𝑙𝑢 1 , 𝑐𝑙𝑢 2 , . . . , 𝑐𝑙𝑢 𝑎 } are derived from the original dataset D 𝑜 using a clustering algorithm ℎ -specifically, the K-means method. From each cluster, one exemplar is selected using method 𝑔 -in this case, random selection-to form an exemplar set 𝐸 . This approach ensures that each group of exemplars contains samples from diverse regions of the original dataset's distribution, thereby enhancing diversity and achieving better alignment with the distribution characteristics of the original data. As illustrated in Figure 2 (a), due to the maximum output token limitations in LLMs, the entire first stage of SampleLLM will iterate 𝑄 times, with 𝑏 samples generated by LLM each time, where 𝑄 and 𝑏 are hyper-parameters. After generation, the generated 𝑏𝑄 samples will be formatted in tabular form and aggregated together to form a temporary synthetic tabular dataset D 𝑠 ′ .",
  "2.5 Feature Attribution-based Importance Sampling": "Although cluster sampling methods are designed to mitigate discrepancies in data distributions, inherent differences caused by the LLM's input-output processing still result in a distribution gap and differentiated feature interaction frequency between the generated and the original data. This gap poses significant challenges in recommendation scenarios, where feature associations serve as a foundational modeling basis. To address these issues, SampleLLM employs a feature attribution-based importance sampling method to further refine the feature relation and alignment of distribution in D 𝑠 ′ with that in D 𝑜 [22, 44]. Our method is proposed because directly calculating the exact importance weights for tabular samples is challenging due to the high dimensionality of tabular data, which complicates the estimation of the joint distribution of the features and labels in samples:  One straightforward approach to simplify the calculation is to assume independence among all features:  However, this assumption often diverges significantly from reality, as it is generally impractical to assume complete independence among all features in most datasets. Consequently, this approach may lead to inaccuracies in estimating distribution probabilities, thereby complicating the data alignment process. Tomitigate these issues, SampleLLM adopts a semi-independence assumption where feature fields containing significant interactions (e.g., fields 1 and 8) are considered non-independent, while others are treated as independent. This balanced approach reduces computational overhead while minimizing calculation errors, enabling the computation of importance weights based on frequency statistics:  2.5.1 Feature Interaction Extraction. To determine the distribution probability of a sample within a specific dataset, as specified in Equation (8), it is essential to identify significant feature interactions. This paper introduces a feature attribution-based method for extracting such interactions. For a dataset D linked to a particular prediction task and a deep learning-based predictive model 𝑓 , we could quantify the importance of each feature to the output by approximating model performance degradation after ablating this feature with 1st-order Taylor approximation [49] as follows:  where 𝑥 𝑖 are features in 𝒙 , 𝑥 𝑏 𝑖 are non-informative features like zero feature or random feature and D 𝑏 is typically a randomly selected subset of D or a single sample containing all-zero values [11, 23]. This approach quantifies the importance of each feature to the output by approximating model performance change after setting an informative feature to non-informative. To attribute feature interactions, we extend 1st-order Taylor expansion to 2nd-order, capturing the importance of feature 𝑖 to the importance of feature 𝑗 . The resulting expression is:  Intuitively, this method measures feature interaction strength as approximated feature importance change when switching interaction from informative to non-informative.   By applying this interaction attribution method to sample samples from the training set, we could capture the complex interactions SampleLLM: Optimizing Tabular Data Synthesis in Recommendations WWW'25, April 28-May 02, 2025, Sydney, Australia. between feature fields across the entire dataset. Therefore, summing the absolute values of interaction maps 𝚪 ( 𝒙 ) for all samples yields a comprehensive matrix that highlights the most significant feature interactions in the whole dataset, irrespective of whether their impacts on the output are positive or negative:  Interaction values above a threshold, defined by a hyper-parameter 𝛾 , are then clustered to delineate independent and non-independent feature groups, further refining data alignment:   where the 𝑀𝑒𝑟𝑔𝑒 function aggregates all pairs with overlapping feature fields to form a feature group 𝒛 𝑡 (e.g., 𝒛 1 = { 𝑥 1 , 𝑥 3 , 𝑥 8 } ) with several feature fields, resulting in 𝑇 groups 𝐺𝑝 = { 𝒛 1 , . . . , 𝒛 𝑡 , . . . , 𝒛 𝑇 } where 𝑇 is determined by the aggregation process, ensuring 𝑇 ≤ 𝐾 . In this study, our objective is to align the distribution of the dataset D 𝑠 ′ with that of the original dataset D 𝑜 . Consequently, the feature groups are derived from D 𝑜 and are utilized for calculating the distribution probability of samples in both D 𝑜 and D 𝑠 ′ . This methodology facilitates a refined understanding of the underlying feature interactions, thus enhancing model interpretability and improving alignment between datasets. 2.5.2 Obtaining Discriminant Probability. As a dataset, each tabular sample contains not only a set of features but also a label. Therefore, another critical challenge in calculating the probability of a sample is obtaining the discriminant probability 𝑃 ( 𝑦 𝑖 | 𝑥 1 𝑖 , 𝑥 2 𝑖 , . . . , 𝑥 𝐾 𝑖 ) for each sample 𝒙 𝑖 = { 𝑥 1 𝑖 , 𝑥 2 𝑖 , . . . , 𝑥 𝐾 𝑖 , 𝑦 𝑖 } . In SampleLLM, this is achieved by training a task-specific predictive model M on the corresponding dataset:  For a specific task (e.g., binary classification), two predictive models M 𝑜 and M 𝑠 ′ are trained to predict the sample discriminant probabilities on D 𝑜 and D 𝑠 ′ , respectively. 2.5.3 Calculating Sample Weights. After obtaining the feature groups 𝐺𝑝 and discriminant models M 𝑜 and M 𝑠 ′ , the importance weights of samples can be derived using the following formula:   where the first term is an alternative expression of Equation (8), and the second term is used to calculate the importance weights based on the sample's distribution probability in both the original and the synthetic datasets. 𝑃 𝑑 () is the frequency of related features in dataset 𝑑 . Finally, after obtaining all synthetic samples' weights, the final synthetic tabular dataset D 𝑠 is created through an importance sampling on D 𝑠 ′ . The overall pseudo-code is also provided in Appendix A to further clarify the overall flow of SampleLLM. Table 1: Data Statistics.",
  "3 Experiments": "In this section, we conduct experiments on three recommendation datasets to address the following research questions: · RQ1: How does SampleLLM perform in comparison to other tabular data synthesis methods? · RQ2: How effective is the generated tabular data when used as a replacement for the original tabular data? · RQ3: What impact do cluster sampling and feature attributionbased importance sampling in SampleLLM have in the process of generating synthetic tabular data? Moreover, two extensive general datasets are also applied to validate SampleLLM's effectiveness in general tabular data-related tasks. In the following sections, we first describe the experimental setup used in this study in the following subsections. Subsequently, detailed analyses are provided for each research question based on our experimental results.",
  "3.1 Experimental Setup": "3.1.1 Dataset. We conducted experiments on three commonly used recommendation datasets with Click-Through Rate (CTR) prediction tasks [15, 31] to verify the validity of SampleLLM, i.e., ML-1M 1 , Amazon 2 and Douban 3 . In addition, a binary classification dataset HELOC 4 and a multi-classification dataset Covertype 5 are further applied for extended experiments to verify the potential of SampleLLM in general tasks. In accordance with previous studies [30, 56], each dataset is divided into training/validation/test sets in an 8:1:1 ratio. Data statistics could be found in Table 1. 3.1.2 Baselines. To verify the effectiveness of SampleLLM, a comprehensive comparison is conducted between SampleLLM and various baseline approaches: · CTGAN [54] utilizes a conditional generator and a mode-specific normalization method in synthetic tabular data generation to address the complexities of tabular data, including mixed data types and imbalanced categories. · TVAE [54], a Variational AutoEncoder (VAE) adapted for synthetic tabular data generation, leverages specialized preprocessing and a modified loss function to handle mixed data types. · TabDDPM [26] leverages a denoising diffusion probabilistic model to handle the inherent heterogeneity of tabular data, providing superior generative performance across benchmarks. · PATE-GAN [24] leverages the Private Aggregation of Teacher Ensembles (PATE) framework to introduce differential privacy 1 https://grouplens.org/datasets/movielens/1m/ 2 https://jmcauley.ucsd.edu/data/amazon/ 3 https://www.kaggle.com/datasets/fengzhujoey/douban-datasetratingreviewside- information 4 https://huggingface.co/datasets/mstz/heloc 5 https://archive.ics.uci.edu/dataset/31/covertype WWW'25, April 28-May 02, 2025, Sydney, Australia. Gao et al. Table 2: Augmentation utility. The boldface denotes the best score. The underline indicates the second-best score. The 'Original' method indicates training without synthetic data and is not considered in scoring. ↑ : higher is better; ↓ : lower is better. '*' indicates the statistically significant improvements (i.e., two-sided t-test with 𝑝 < 0 . 05 ) over the best baseline. guarantees into the Generative Adversarial Network (GAN) setting. By modifying the GAN discriminator with the PATE mechanism, PATE-GAN ensures that the synthetic data generated maintains privacy while preserving data utility. · ADS-GAN [55] is designed to generate synthetic data that closely approximate the joint distribution of variables in original datasets. Utilizing a conditional Generative Adversarial Network (GAN) framework, ADS-GAN ensures data anonymization by minimizing identifiability based on the probability of re-identification. 3.2.1 Augmentation Utility. As illustrated in Equation (3), the utility of synthetic data could be evaluated by the data enhancement effect after injecting synthetic data into the original data [8, 13]. Specifically, we generate 10% synthetic data for the training set using different baselines, and integrate them with the original training set for training. The performance of the final predictive model could, therefore, serve as evidence to measure the utility of the synthetic data. The experimental results are presented in Table 2. A case study is also provided in Appendix C for visualization analysis. · GReaT [4] leverages an auto-regressive generative LLM to synthesize realistic tabular data. This method efficiently models tabular data distributions by conditioning on any subset of features, allowing for flexible and authentic data generation. · REaLTabFormer [46] generates high-quality synthetic data for both non-relational and relational datasets. It employs an autoregressive model for parent tables and a sequence-to-sequence model for related child tables with GPT-2 LLM as backbone modules, ensuring realistic data relationships and preventing data copying through target masking and statistical bootstrapping. 3.1.3 Implementation Details. For ML-1M, Amazon, Douban and HELOC datasets, the widely used metrics of AUC and Logloss are deployed for evaluation [19, 25]. For Covertype whose task is multi-class classification, the widely used metrics of weighted Precision, Recall, and F1 score [18] are deployed for evaluation. For a fair comparison and clearly illustrate the effectiveness of each module in SampleLLM. A simple Deep Neural Network (DNN) is selected as the predictive model for all tasks. Specifically, for different datasets and tasks, we first carried out a grid search for network parameters to ensure prediction performance, in which the search range for the number of layers is {1-4} and the search range for the number of neurons per layer is {16,32,64,128}. The simple grid search is also applied in selecting other hyper-parameters such as learning rate and dropout rate in training. Meanwhile, the INT4 quantized version of Llama-3-70b-instruct-awq [1] is applied as the LLM backbone for the first stage of SampleLLM. In addition, we ran each experiment 10 times and reported the average performance.",
  "3.2 Overall Performance (RQ1, 2)": "This section gives overall performance comparisons between SampleLLM and various baselines on the augmentation utility and MLE utility as illustrated in Section 2.1 to answer the RQ1 and RQ2. From Table 2 we can conclude that: · For baselines without LLM in modeling, TabDDPM and TVAE outperform GAN-based models in most cases, verifying the effectiveness of more detailed modeling for distribution alignment in diffusion probabilistic models and VAE models. · For the ML-1M, Amazon, and Douban datasets, traditional models generally struggle to match the performance seen on the original data. However, they tend to perform better on the HELOC and Covertype datasets. This disparity highlights the importance of complex feature associations in recommendation modeling, which traditional models fail to capture due to their inability to understand semantic relationships. GReaT and REaLTabFormer outperform other baselines, showcasing LLMs' strength in modeling feature relations through semantic comprehension. Additionally, by utilizing alignment methods, SampleLLM achieves superior AUC and Logloss across all datasets. · SampleLLM outperforms all baselines in most cases, illustrating the effectiveness of LLM's semantic understanding in modeling feature relations and data distributions and the effectiveness of the feature attribution-based importance sampling method in further aligning the feature correlations and data distribution of the generated data with the original data. 3.2.2 MLE Utility. As illustrated in Equation (2), the utility of synthetic data could also be evaluated by supplanting the real data in training a predictive model. The corresponding evaluation method is referred to as Machine Learning Efficacy (MLE) utility [46, 54]. Specifically, to reduce the cost of training time, we generate 10% synthetic data for the training set using different baselines and directly use them as the training sets for model training. The performance of the final predictive model could, therefore, serve as evidence to measure the utility of the synthetic data. The experimental results are presented in Table 3. From Table 3 we can conclude that: SampleLLM: Optimizing Tabular Data Synthesis in Recommendations WWW'25, April 28-May 02, 2025, Sydney, Australia. Table 3: MLE utility. The boldface denotes the best score, and the underline indicates the second-best score. The 'Original' method indicates training with the original training set and is not considered in scoring. ↑ : higher is better; ↓ : lower is better. '*' indicates the statistically significant improvements (i.e., two-sided t-test with 𝑝 < 0 . 05 ) over the best baseline. Figure 4: Ablation study of augmentation utility on Douban. SampleLLM-LLM -CS -IS 0.8015 0.8020 0.8025 0.8030 (a) AUC. SampleLLM-LLM -CS -IS 0.5135 0.5140 0.5145 0.5150 (b) Logloss. · Almost all methods exhibit poorer performance compared to directly using the original training set ('Original'). This result is intuitive, as synthetic data cannot fully replicate or substitute the nuances of the original data. Interestingly, SampleLLM surpasses 'Original' on the HELOC dataset, likely due to the dataset's data scarcity. The model's convergence rate may remain similar on HELOC whether trained on the original training set or synthetic data. · The performance degradation across all methods is most pronounced on the ML-1M dataset. This is likely due to the discrete, sparse, and strongly correlated nature of the features in ML1M. Notably, SampleLLM outperforms other baselines across all datasets on both augmentation and MLE utility measures, demonstrating its suitability for tabular data synthesis on recommendations and even more various downstream tasks such as binary classification and multi-class classification.",
  "3.3 Ablation Study (RQ3)": "This section verifies the effectiveness of each module in SampleLLM through ablation experiments to answer RQ3. Specifically, we compare the augmentation utility of SampleLLM on the Douban dataset with the following substitutions: · w/o LLM (-LLM) : with TabDDPM, a non-LLM baseline as the alternative of the LLM in the first stage of SampleLLM; · w/o cluster sampling (-CS) : without cluster sampling in the first stage of SampleLLM. The exemplars are selected randomly. · w/o importance sampling (-IS) : without the feature attributionbased importance sampling in the second stage of SampleLLM. We also calculate their SDV similarity [42], a score measuring distribution similarity considering column shapes and pair trends. The result is shown in Table 4. Based on Figure 4 and Table 4, we could conclude that: · Replacing the LLM backbone in the first stage of SampleLLM with the TabDDPM results in a significant performance decline Table 4: SDV Similarity Score with the original dataset. for SampleLLM. This decline may be attributed to LLM's superior ability to model feature relations and joint distributions at the semantic level, which allows it to better approximate the sample distribution of the original data compared to baseline methods. This characteristic is crucial for ensuring the effectiveness of feature attribution-based importance sampling in the second stage of SampleLLM, as the distribution similarity between the two datasets positively impacts the effectiveness of the importance sampling method [10] when the sample amount is fixed. · Without the cluster sampling method in selecting exemplars at the first stage, SampleLLM also suffers from performance decline, indicating that selecting diverse exemplars is essential in LLM's few-shot learning process. · Without the feature attribution-based importance sampling in the second stage, SampleLLM's performance degenerates significantly, indicating that refining sample distribution and feature relation is vital in LLM-based tabular data synthesis. In order to further intuitively illustrate the effectiveness of different modules, a visualization analysis is conducted through the T-Distributed Stochastic Neighbor Embedding (TSNE) method for the synthetic tabular data generated by the above alternatives, as shown in Figure 5. From these subfigures, we could observe that: · As depicted in Figure 5(b), substituting the TabDDPM baseline model for the LLM in the first stage fundamentally results in a worse synthetic data distribution (especially in the middle part), despite the integration of feature attribution-based importance sampling in the subsequent stage. This observation substantiates our initial analysis. · As shown in Figure 5(c), the selection of random exemplars over those derived from cluster sampling leads to an overly concentrated synthetic data distribution in comparison with Figure 5(a) when generated through the LLM. · Although Figure 5(d) shows a relatively similar shape, the point density in different regions differs greatly from the original dataset. This demonstrates that, in the absence of feature attributionbased importance sampling, achieving a comprehensive alignment with the original dataset is challenging. WWW'25, April 28-May 02, 2025, Sydney, Australia. Gao et al. Figure 5: Visualization analysis of the ablation study. -60 -40 -20 0 20 40 60 -60 -40 -20 0 20 40 60 Original SampleLLM (a) SampleLLM. -60 -40 -20 0 20 40 60 -60 -40 -20 0 20 40 60 Original -LLM (b) -LLM. -60 -40 -20 0 20 40 60 -60 -40 -20 0 20 40 60 Original -CS (c) -CS. -60 -40 -20 0 20 40 60 -60 -40 -20 0 20 40 60 Original -IS (d) -IS.",
  "4 Online A/B Test": "The Huawei app advertising platform contends with the challenge of low recall rates for cold-start apps, primarily due to the sparse user interaction data resulting from limited exposure. This scarcity hinders existing models from achieving global optimality. To address this challenge, we implemented SampleLLM to generate synthetic interactions between users and cold-start apps. In the user profile generation phase, clustering sampling was employed to iteratively select user profile seeds, which were then utilized by the LLM to synthesize diverse user profiles, simulating app exposure across a wide range of user groups. The LLM further integrated these profiles with the cold-start app's features and descriptions to predict user click behaviors, preserving the result as a raw dataset for distribution alignment. Subsequently, we decomposed the complete feature sets into several strong interaction feature clusters using Hessian-based methods on a previously trained recommendation model. The distributions of these feature clusters were calculated based on occurrence frequency. This allows us to determine the importance weights of each synthetic sample, which serves as augmenting data to improve training for cold-start apps. For deployment, we downsampled one day's user data and clustered it into 1,000 groups using Spark. From each cluster, samples were selected as seeds according to cluster size for subsequent data synthesis. The selected user profiles, combined with app descriptions, served as seeds for Qwen2.5 to simulate user click behaviors on the apps. The synthesized samples were then assigned importance weights based on statistics extracted from the current day's recommendation model, ensuring alignment with real user behavior for non-cold-start apps. These synthetic samples are utilized as augmentation for the following week without further updates. We integrated the model trained with synthetic data as a new pipeline in the user-item recalling module. During the experimental phase, real cold-start samples were updated daily, while synthetic data received incremental updates weekly. The experiment lasted a total of one week and exhibited a 2% improvement in RPM (Revenue Per Mille), a 1.86% improvement in ECPM (Effective Cost Per Mille) in our cold-start scenario, thereby validating the method's effectiveness.",
  "5 Related Work": "Tabular data synthesis has evolved to address diverse needs across domains, initially through probabilistic models like the Synthetic Data Vault (SDV) [42] that focused on privacy and statistical integrity. The introduction of deep learning approaches, including GANs [24, 54, 55] and VAEs [54], has furthered this field, offering solutions to issues such as data scarcity and privacy. Models like CTGAN and TVAE [54] effectively handle specific challenges, including mixed data types, significantly enhancing the quality of synthetic datasets. Specialized techniques, such as TabDDPM [26], leverage models like denoising diffusion probabilistic models for better generative performance across benchmarks [44, 45]. However, these methods often require large datasets, limiting their effectiveness in data-scarce contexts, especially in recommendation scenarios [28, 32, 39, 62]. Moreover, they fail to capture the semantic associations between features [53, 63], which are increasingly important in recommendation modeling. The rise of transformer [58] architectures [50] and LLMs [7, 38, 41, 59] has introduced new possibilities for tabular data synthesis, thanks to LLMs' few-shot learning [6, 36, 57] and semantic understanding capabilities [29]. Methods like GReaT [4] and REaLTabFormer [46] have explored converting tabular data into natural language to leverage LLM strengths. Despite promising outcomes, these approaches often fail to address alignment issues between LLMs and target datasets, leading to distribution divergence. Instead, our proposed method, SampleLLM, addresses these shortcomings by combining few-shot learning with alignment techniques to better match distributions and feature relationships of generated and original datasets, thereby enhancing data utility and downstream task performance in recommendations.",
  "6 Conclusion": "In this paper, a two-stage LLM-based framework SampleLLM is proposed to integrate LLM with sampling methods for optimizing tabular data synthesis in recommendations. Specifically, a manually designed instruction, together with a group of exemplars generated through a cluster sampling method serves as the input prompt for few-shot learning via LLM. Then a novel feature attribution-based importance sampling method is proposed to serve as a second stage for further feature relation modeling and distribution alignment. By doing so, SampleLLM is able to generate synthetic tabular data with semantic understanding, higher utility, and distribution similarity. Experiments on three public recommendation datasets, two general datasets, and an online application demonstrate the effectiveness of the proposed SampleLLM.",
  "Acknowledgments": "This research was partially supported by Research Impact Fund (No.R1015-23), Collaborative Research Fund (No.C1043-24GF), APRC - CityU New Research Initiatives (No.9610565, Start-up Grant for New Faculty of CityU), Hong Kong ITC Innovation and Technology Fund Midstream Research Programme for Universities Project (No.ITS/034/22MS), and Huawei (Huawei Innovation Research Program). SampleLLM: Optimizing Tabular Data Synthesis in Recommendations WWW'25, April 28-May 02, 2025, Sydney, Australia.",
  "References": "[1] AI@Meta. 2024. Llama 3 Model Card. (2024). [2] MsAayushi Bansal, Dr Rewa Sharma, and Dr Mamta Kathuria. 2022. A systematic review on data scarcity problem in deep learning: solution and applications. ACM Computing Surveys (Csur) (2022), 1-29. [3] Vadim Borisov, Tobias Leemann, Kathrin Seßler, Johannes Haug, Martin Pawelczyk, and Gjergji Kasneci. 2022. Deep neural networks and tabular data: A survey. IEEE transactions on neural networks and learning systems (2022). [4] Vadim Borisov, Kathrin Seßler, Tobias Leemann, Martin Pawelczyk, and Gjergji Kasneci. 2022. Language models are realistic tabular data generators. arXiv preprint arXiv:2210.06280 (2022). [5] Stavroula Bourou, Andreas El Saer, Terpsichori-Helen Velivassaki, Artemis Voulkidis, and Theodore Zahariadis. 2021. A review of tabular data synthesis using GANs on an IDS dataset. Information (2021), 375. [6] Samuel Cahyawijaya, Holy Lovenia, and Pascale Fung. 2024. LLMs Are Few-Shot In-Context Low-Resource Language Learners. arXiv preprint arXiv:2403.16512 (2024). [7] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. 2024. A survey on evaluation of large language models. ACM Transactions on Intelligent Systems and Technology (2024), 1-45. [8] Subhajit Chatterjee, Debapriya Hazra, Yung-Cheol Byun, and Yong-Woon Kim. 2022. Enhancement of image classification using transfer learning and GANbased synthetic data augmentation. Mathematics (2022), 1541. [9] Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. 2022. A survey on in-context learning. arXiv preprint arXiv:2301.00234 (2022). [10] Víctor Elvira and Luca Martino. 2021. Advances in importance sampling. arXiv preprint arXiv:2102.05407 (2021). [11] Gabriel Erion, Joseph D Janizek, Pascal Sturmfels, Scott M Lundberg, and Su-In Lee. [n. d.]. Learning explainable models using attribution priors. ([n. d.]). [12] Sheikh Amir Fayaz, Majid Zaman, Sameer Kaul, and Muheet Ahmed Butt. 2022. Is deep learning on tabular data enough? An assessment. International Journal of Advanced Computer Science and Applications (2022). [13] Alvaro Figueira and Bruno Vaz. 2022. Survey on synthetic data generation, evaluation methods and GANs. Mathematics (2022), 2733. [14] Joao Fonseca and Fernando Bacao. 2023. Tabular and latent space synthetic data generation: a literature review. Journal of Big Data (2023), 115. [15] Zichuan Fu, Xiangyang Li, Chuhan Wu, Yichao Wang, Kuicai Dong, Xiangyu Zhao, Mengchen Zhao, Huifeng Guo, and Ruiming Tang. 2023. A unified framework for multi-domain ctr prediction via large language models. ACM Transactions on Information Systems (2023). [16] Jingtong Gao, Xiangyu Zhao, Bo Chen, Fan Yan, Huifeng Guo, and Ruiming Tang. 2023. AutoTransfer: instance transfer for cross-domain recommendations. In Proc. of SIGIR . 1478-1487. [17] Akash Goel, Amit Kumar Goel, and Adesh Kumar. 2023. The role of artificial neural network and machine learning in utilizing spatial information. Spatial Information Research (2023), 275-285. [18] Margherita Grandini, Enrico Bagli, and Giorgio Visani. 2020. Metrics for multiclass classification: an overview. arXiv preprint arXiv:2008.05756 (2020). [19] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247 (2017). [20] Omar Habibi, Mohammed Chemmakha, and Mohamed Lazaar. 2023. Imbalanced tabular data modelization using CTGAN and machine learning to improve IoT Botnet attacks detection. Engineering Applications of Artificial Intelligence (2023), 105669. [21] Mikel Hernadez, Gorka Epelde, Ane Alberdi, Rodrigo Cilla, and Debbie Rankin. 2023. Synthetic tabular data evaluation in the health domain covering resemblance, utility, and privacy dimensions. Methods of information in medicine (2023), e19-e38. [22] Joseph D. Janizek, Pascal Sturmfels, and Su-In Lee. 2021. Explaining Explanations: Axiomatic Feature Interactions for Deep Networks. Journal of Machine Learning Research (2021), 1-54. [23] Joseph D Janizek, Pascal Sturmfels, and Su-In Lee. 2021. Explaining explanations: Axiomatic feature interactions for deep networks. Journal of Machine Learning Research (2021), 1-54. [24] James Jordon, Jinsung Yoon, and Mihaela Van Der Schaar. 2018. PATE-GAN: Generating synthetic data with differential privacy guarantees. In Proc. of ICLR . [25] Kaitlin Kirasich, Trace Smith, and Bivin Sadler. 2018. Random forest vs logistic regression: binary classification for heterogeneous datasets. SMU Data Science Review (2018), 9. [26] Akim Kotelnikov, Dmitry Baranchuk, Ivan Rubachev, and Artem Babenko. 2023. Tabddpm: Modelling tabular data with diffusion models. In Proc. of ICML . 1756417579. [27] Jiacheng Li, Ming Wang, Jin Li, Jinmiao Fu, Xin Shen, Jingbo Shang, and Julian McAuley. 2023. Text is all you need: Learning language representations for sequential recommendation. In Proc. of KDD . 1258-1267. [28] Xinhang Li, Zhaopeng Qiu, Xiangyu Zhao, Zihao Wang, Yong Zhang, Chunxiao Xing, and Xian Wu. 2022. Gromov-wasserstein guided representation learning for cross-domain recommendation. In Proc. of CIKM . 1199-1208. [29] Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan, Guohong Liu, Jiacheng Liu, Wenxing Xu, Xiang Wang, Yi Sun, et al. 2024. Personal llm agents: Insights and survey about the capability, efficiency and security. arXiv preprint arXiv:2401.05459 (2024). [30] Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018. xdeepfm: Combining explicit and implicit feature interactions for recommender systems. In Proc. of KDD . 1754-1763. [31] Jiahao Liang, Xiangyu Zhao, Muyang Li, Zijian Zhang, Wanyu Wang, Haochen Liu, and Zitao Liu. 2023. Mmmlp: Multi-modal multilayer perceptron for sequential recommendations. In Proc. of WWW . 1109-1117. [32] Weilin Lin, Xiangyu Zhao, Yejing Wang, Tong Xu, and Xian Wu. 2022. AdaFS: Adaptive feature selection in deep recommender system. In Proc. of KDD . 33093317. [33] Weilin Lin, Xiangyu Zhao, Yejing Wang, Yuanshao Zhu, and Wanyu Wang. 2023. Autodenoise: Automatic data instance denoising for recommendations. In Proc. of WWW . 1003-1011. [34] Dugang Liu, Chaohua Yang, Xing Tang, Yejing Wang, Fuyuan Lyu, Weihong Luo, Xiuqiang He, Zhong Ming, and Xiangyu Zhao. 2024. MultiFS: Automated Multi-Scenario Feature Selection in Deep Recommender Systems. In Proc. of WSDM . 434-442. [35] Qidong Liu, Jiaxi Hu, Yutian Xiao, Xiangyu Zhao, Jingtong Gao, Wanyu Wang, Qing Li, and Jiliang Tang. 2024. Multimodal recommender systems: A survey. Comput. Surveys (2024), 1-17. [36] Qidong Liu, Xian Wu, Xiangyu Zhao, Yejing Wang, Zijian Zhang, Feng Tian, and Yefeng Zheng. 2024. Large Language Models Enhanced Sequential Recommendation for Long-tail User and Item. arXiv preprint arXiv:2405.20646 (2024). [37] Qidong Liu, Xian Wu, Xiangyu Zhao, Yuanshao Zhu, Derong Xu, Feng Tian, and Yefeng Zheng. 2024. When moe meets llms: Parameter efficient fine-tuning for multi-task medical applications. In Proc. of SIGIR . 1104-1114. [38] Qidong Liu, Xian Wu, Xiangyu Zhao, Yuanshao Zhu, Zijian Zhang, Feng Tian, and Yefeng Zheng. 2024. Large Language Model Distilling Medication Recommendation Model. CoRR (2024). [39] Ziru Liu, Jiejie Tian, Qingpeng Cai, Xiangyu Zhao, Jingtong Gao, Shuchang Liu, Dayou Chen, Tonghao He, Dong Zheng, Peng Jiang, et al. 2023. Multi-task recommendations with reinforcement learning. In Proc. of WWW . 1273-1282. [40] Duncan McElfresh, Sujay Khandagale, Jonathan Valverde, Vishak Prasad C, Ganesh Ramakrishnan, Micah Goldblum, and Colin White. 2024. When do neural nets outperform boosted trees on tabular data? Proc. of NeurIPS (2024). [41] Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Amatriain, and Jianfeng Gao. 2024. Large language models: A survey. arXiv preprint arXiv:2402.06196 (2024). [42] Neha Patki, Roy Wedge, and Kalyan Veeramachaneni. 2016. The synthetic data vault. In 2016 IEEE international conference on data science and advanced analytics (DSAA) . 399-410. [43] Zhaozhi Qian, Bogdan-Constantin Cebere, and Mihaela van der Schaar. 2023. Synthcity: facilitating innovative use cases of synthetic data in different data modalities. arXiv preprint arXiv:2301.07573 (2023). [44] Zhaozhi Qian, Bogdan-Constantin Cebere, and Mihaela van der Schaar. 2023. Synthcity: facilitating innovative use cases of synthetic data in different data modalities. [45] Zhaozhi Qian, Rob Davis, and Mihaela van der Schaar. 2024. Synthcity: a benchmark framework for diverse use cases of tabular synthetic data. Proc. of NeurIPS (2024). [46] Aivin V Solatorio and Olivier Dupriez. 2023. Realtabformer: Generating realistic relational and tabular data using transformers. arXiv preprint arXiv:2302.02041 (2023). [47] Fengyi Song, Bo Chen, Xiangyu Zhao, Huifeng Guo, and Ruiming Tang. 2022. Autoassign: Automatic shared embedding assignment in streaming recommendation. In Proc. of ICDM . 458-467. [48] Fahim Sufi. 2024. Addressing Data Scarcity in the Medical Domain: A GPT-Based Approach for Synthetic Data Generation and Feature Extraction. Information (2024), 264. [49] Mukund Sundararajan, Ankur Taly, and Qiqi Yan. 2016. Gradients of counterfactuals. arXiv preprint arXiv:1611.02639 (2016). [50] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Proc. of NeurIPS (2017). [51] Yuhao Wang, Xiangyu Zhao, Bo Chen, Qidong Liu, Huifeng Guo, Huanshuo Liu, Yichao Wang, Rui Zhang, and Ruiming Tang. 2023. PLATE: A prompt-enhanced paradigm for multi-scenario recommendations. In Proc. of SIGIR . 1498-1507. [52] Derong Xu, Wei Chen, Wenjun Peng, Chao Zhang, Tong Xu, Xiangyu Zhao, Xian Wu, Yefeng Zheng, Yang Wang, and Enhong Chen. 2024. Large language models for generative information extraction: A survey. Frontiers of Computer Science (2024), 186357. WWW'25, April 28-May 02, 2025, Sydney, Australia. Gao et al. [53] Derong Xu, Ziheng Zhang, Zhenxi Lin, Xian Wu, Zhihong Zhu, Tong Xu, Xiangyu Zhao, Yefeng Zheng, and Enhong Chen. 2024. Multi-perspective Improvement of Knowledge Graph Completion with Large Language Models. In Proc. of COLING . 11956-11968. [54] Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni. 2019. Modeling Tabular data using Conditional GAN. In Proc. of NeurIPS . [55] Jinsung Yoon, Lydia N Drumright, and Mihaela Van Der Schaar. 2020. Anonymization through data synthesis using generative adversarial networks (ads-gan). IEEE journal of biomedical and health informatics (2020), 2378-2388. [56] Guanghu Yuan, Fajie Yuan, Yudong Li, Beibei Kong, Shujie Li, Lei Chen, Min Yang, Chenyun Yu, Bo Hu, Zang Li, et al. 2022. Tenrec: A large-scale multipurpose benchmark dataset for recommender systems. Proc. of NeurIPS (2022), 1148011493. [57] Chao Zhang, Haoxin Zhang, Shiwei Wu, Di Wu, Tong Xu, Yan Gao, Yao Hu, and Enhong Chen. 2024. NoteLLM-2: Multimodal Large Representation Models for Recommendation. arXiv preprint arXiv:2405.16789 (2024). [58] Kesen Zhao, Lixin Zou, Xiangyu Zhao, Maolin Wang, and Dawei Yin. 2023. User retention-oriented recommendation with decision transformer. In Proc. of WWW . 1141-1149. [59] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023. A survey of large language models. arXiv preprint arXiv:2303.18223 (2023). [60] Xiangyu Zhao, Long Xia, Liang Zhang, Zhuoye Ding, Dawei Yin, and Jiliang Tang. 2018. Deep reinforcement learning for page-wise recommendations. In Proc. of RecSys . 95-103. [61] Xiangyu Zhao, Liang Zhang, Zhuoye Ding, Long Xia, Jiliang Tang, and Dawei Yin. 2018. Recommendations with negative feedback via pairwise deep reinforcement learning. In Proc. of KDD . 1040-1048. [62] Xiangyu Zhao, Xudong Zheng, Xiwang Yang, Xiaobing Liu, and Jiliang Tang. 2020. Jointly learning to recommend and advertise. In Proc. of KDD . 3319-3327. [63] Zhi Zheng, Zhaopeng Qiu, Hui Xiong, Xian Wu, Tong Xu, Enhong Chen, and Xiangyu Zhao. 2022. Ddr: Dialogue based doctor recommendation for online medical service. In Proc. of KDD . 4592-4600. SampleLLM: Optimizing Tabular Data Synthesis in Recommendations WWW'25, April 28-May 02, 2025, Sydney, Australia. Algorithm 1 The whole process of SampleLLM Input : The original tabular dataset D 𝑜 ; An LLM model 𝐿𝐿𝑀 ; Hyper-parameters 𝑎 , 𝑏 , 𝑄 , 𝛾 Output : The final synthetic tabular dataset D 𝑠 1: D 𝑠 ′ = [] 2: for Iteration in 1,..., 𝑄 do 3: Obtain instruction 𝐼 for D 𝑜 through Section 2.3 4: Obtain exemplar set 𝐸 with 𝑎 exemplars via Equation (5) 5: Obtain output synthetic data D 𝑡𝑚𝑝 with 𝑏 samples via 𝐿𝐿𝑀 ( 𝐼 + 𝐸 ) 6: D 𝑠 ′ = D 𝑠 ′ + D 𝑡𝑚𝑝 7: end for 8: Obtain 𝚪 D 𝑜 via Equation (10), (11) 9: Obtain feature groups 𝐺𝑝 via Equation (12) 10: Obtain discriminant probability M 𝑜 and M 𝑠 ′ via Equation (13) 11: Obtain sample weight 𝑤 for samples in D 𝑠 ′ via Equation (14) 12: Obtain D 𝑠 by processing importance sampling on D 𝑠 ′ with sample weight 𝑤 . Table 5: Feature groups. Note that only groups with more than one feature field are shown in the table for simplicity.",
  "A Pseudo-code of SampleLLM": "To elucidate the overall process of SampleLLM, we present the pseudo-code in Algorithm 1. Specifically, SampleLLM operates in two distinct stages. The first stage (i.e., lines 1-7) employs a cluster sampling technique for exemplar selection in LLM's few-shot learning, aimed at generating an initial synthetic tabular dataset, denoted as D 𝑠 ′ . In the second stage (i.e., lines 8-12), a novel feature attribution-based importance sampling method is proposed to enhance the modeling of feature relationships and achieve distribution alignment between the synthetic dataset D 𝑠 ′ and the original tabular dataset D 𝑜 . This process results in the final synthetic tabular dataset, D 𝑠 .",
  "B Overall Interaction Map and Feature Groups": "In this section, we present the overall interaction maps and feature groups for all five experimental datasets, as illustrated in Figure 6, and Table 5. It is important to note that the interaction maps and feature groups may exhibit slight variations from the provided figures and tables due to fluctuations in the performance of the predictive model trained on each dataset.",
  "C Case Study": "This section presents a case study using TSNE visualizations and SDV similarity [42], a score measuring distribution similarity considering column shapes and pair trends, to analyze the synthetic tabular data generated by high-performance baselines such as TVAE, Figure 6: Interaction maps for different datasets. The numbers on the axes represent the indices of the feature fields. 1 3 5 7 1 3 5 7 0.00 0.25 0.50 0.75 1.00 1.25 1e-6 (a) ML-1M. 1 3 1 3 0 1 2 3 1e-7 (b) Amazon. 1 3 5 1 3 5 0 1 2 3 1e-7 (c) Douban. 1 6 11 16 21 1 6 11 16 21 0 2 4 6 1e-6 (d) HELOC. 1 11 21 31 41 51 1 11 21 31 41 51 0.00000 0.00005 0.00010 0.00015 (e) Covertype. Table 6: SDV Similarity Score with the original dataset. Figure 7: Case study on HELOC dataset. -60 -40 -20 0 20 40 60 -60 -40 -20 0 20 40 Original SampleLLM (a) SampleLLM. -60 -40 -20 0 20 40 60 -60 -40 -20 0 20 40 Original TVAE (b) TVAE. -60 -40 -20 0 20 40 60 -60 -40 -20 0 20 40 Original TabDDPM (c) TabDDPM. -60 -40 -20 0 20 40 60 -60 -40 -20 0 20 40 Original REaLTabFormer (d) REaLTabFormer. TabDDPM, and REaLTabFormer, thereby highlighting the advantages of SampleLLM. As shown in Figure 7 and Table 6, TVAE and TabDDPM struggle to effectively replicate the original data distribution. Even with the incorporation of LLM, REaLTabFormer's distribution remains concentrated in several central regions, as noted in Figure 1. In contrast, SampleLLM demonstrates significant improvements in aligning with the original sample distribution by leveraging the few-shot learning capabilities of LLM and employing a novel two-stage alignment strategy.",
  "keywords_parsed": [
    "Recommender System",
    " Tabular data generation",
    " Large Language Model"
  ]
}