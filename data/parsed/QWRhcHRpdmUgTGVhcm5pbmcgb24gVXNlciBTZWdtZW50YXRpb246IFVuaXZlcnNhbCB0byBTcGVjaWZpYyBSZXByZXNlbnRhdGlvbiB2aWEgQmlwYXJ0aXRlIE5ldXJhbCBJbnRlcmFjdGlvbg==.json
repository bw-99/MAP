{
  "Adaptive Learning on User Segmentation: Universal to Specific Representation via Bipartite Neural Interaction*": "* Note: This work has been published in the proceedings of the 2nd International ACM SIGIR Conference on Information Retrieval in the Asia Pacific. Xiaoyu Tan ∗ INF Technology (Shanghai) Co., Ltd Shanghai, China Yongxin Deng ∗ Shanghai University of Engineering Science Shanghai, China Chao Qu ∗ INF Technology (Shanghai) Co., Ltd Shanghai, China Siqiao Xue Xiaoming Shi James Zhang Ant Group Shanghai, China",
  "ABSTRACT": "Recently, models for user representation learning have been widely applied in click-through-rate (CTR) and conversion-rate (CVR) prediction. Usually, the model learns a universal user representation as the input for subsequent scenario-specific models. However, in numerous industrial applications (e.g., recommendation and marketing), the business always operates such applications as various online activities among different user segmentation. These segmentation are always created by domain experts. Due to the difference in user distribution (i.e., user segmentation) and business objectives in subsequent tasks, learning solely on universal representation may lead to detrimental effects on both model performance and robustness. In this paper, we propose a novel learning framework that can first learn general universal user representation through information bottleneck. Then, merge and learn a segmentationspecific or a task-specific representation through neural interaction. We design the interactive learning process by leveraging a bipartite graph architecture to model the representation learning and merging between contextual clusters and each user segmentation. Our proposed method is evaluated in two open-source benchmarks, two offline business datasets, and deployed on two online marketing applications to predict users' CVR. The results demonstrate that our method can achieve superior performance and surpass the baseline methods.",
  "CCS CONCEPTS": "· Applied computing → Electronic data interchange ; Online shopping .",
  "KEYWORDS": "representation learning, adaptive learning, neural networks",
  "1 INTRODUCTION": "Probability prediction is a core technique in both recommendation systems and digital marketing systems. In industrial practice, clickthrough-rate (CTR), conversion-rate (CVR), and other customer ∗ Equally Contribution † Corresponding Author",
  "Xihe Qiu †": "qiuxihe1993@gmail.com Shanghai University of Engineering Science Shanghai, China behaviors should be accurately estimated to efficiently provide personalized service [9, 10, 20, 34]. It should be noted that the performance of these predictions is crucial not only for the quality of the system but also fundamentally determines the revenue of the service provider. Recently, there has been an increasing interest in leveraging machine learning (ML) based prediction models in practice. By gathering the data from the history log, a training dataset can be constructed with features and labels. Then, the model can be trained under a supervised learning manner to provide the prediction based on the data knowledge [38, 40]. Utilizing ML models in recommendation, advertisement, and other digital marketing systems has achieved astonishing performance improvement and has been recognized as a standard technique in this field [12, 36]. The growth of digital business has led to an increase in the number of customers and business types, making it increasingly difficult to maintain effective machine learning models. This challenge is even more challenging when the model needs to handle multiple, similar but different subsequent tasks within a large user space. One of the primary difficulties encountered is the diversity of user characteristics, which often results in multi-modal and long-tailed data distribution [27, 30]. Learning under such data distribution can significantly reduce performance and robustness of machine learning models, particularly when dealing with large and diverse user groups. Another issue is the distributional shift between training data and online inference data. Due to the business expansion, the user base is consistently expanding and changing. Training on historical data and inference on current scenarios is lack timeliness and may induce performance degradation [13, 41]. To ensure service quality under the aforementioned circumstance, business operators start to divide the users into different user segments under business logic and try to build an individual model on each segmentation. For example, operators may mainly segment the user into different user groups by daily activities on the platform and construct individual models on each user segmentation with different marketing settings [29, 42, 48]. Although this method can ensure stable performance on each user segmentation or each sub-tasks, it requires an intense workload and a long period to launch in real implementation. When the number of customers Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Xiaoyu Tan, Yongxin Deng, Chao Qu, Siqiao Xue, Xiaoming Shi, James Zhang, and Xihe Qiu is consistently expanding and can be subdivided into more user groups, it is impractical to build one model for each group. Another main issue of this method is that each model cannot utilize the meta knowledge learned from other user groups. Limited data for each user group may provide a narrow perspective of data information and reduce the generalization of the model. The key aspect of model performance under industry circumstances is representation. If we construct one model on all users, the model would utilize universal representation on all user segmentation and subsequent tasks. If we build one model on each user segmentation or task respectively, the model would leverage the segmentation-specific representation. The former representation contains meta-knowledge learned from all subsequent tasks but may ignore domain-specific details. The latter representation implements domain-specific details on limited data but abandons the meta-knowledge. From this perspective, the user segmentation created by business experts is actually exploiting the trade-off between universal and domain-specific representation with prior knowledge to guarantee service performance. So, can we reduce such exhausted exploitation to an end-to-end learning manner and further improve the performance using ML? In this paper, we proposed a novel learning framework that can learn both u niversal and g egmentations pecific r epresentation (USSR) in prediction tasks on all data. The USSR learning framework first learns a universal representation in a mixture of Gaussian latent space through information bottleneck. This representation is learned by first projecting user features into different clusters and then representing them in multi-variant Gaussian distribution. This representation can successively encounter the multi-modal and long-tail data distribution and encode the meta-knowledge by learning from all data [35]. Then, the model would learn segmentationspecific representation through neural interaction. Since each user segmentation is independent, defined by business operators, and includes domain-specific information, we design a bipartite neural interaction process to better incorporate prior knowledge from business logic and generate segmentation-specific representation from contextual clusters. Therefore, our proposed method cannot only learn a universal representation from a large dataset, but also adapt new user segmentation for subsequent tasks [14, 18]. We test our models in two Alipay CVR prediction tasks and deploy them as online services in two Alipay CVR prediction tasks for recommendation and marketing. The online results demonstrate that our proposed method can improve performance compared with single baseline models. We summarize our contribution as follows: · We propose a novel learning framework to learn universal representation and segmentation-specific representation in an end-to-end manner. · We test our framework on two open-source benchmarks and two CVR prediction offline datasets in Alipay. The evaluation demonstrates a significant improvement in predictive accuracy when compared to prior approaches. · We deploy the model as two online CVR prediction services in Alipay and demonstrate high effectiveness and efficiency in practice by observing the online CVR performance.",
  "2 RELATED WORK": "In the realm of recommendation systems and digital marketing, a multitude of approaches have been explored and applied across diverse domains, encompassing the web[6, 16, 33], books[31], tourism[11], movies[4], music[47], resource utilization[43], and more. The importance of constructing high-quality proprietary recommendation systems tailored to offer personalized suggestions across different application scenarios cannot be overstated. At the core of recommendation systems and digital marketing lie probability prediction techniques, with extensive research efforts dedicated to precisely estimating CTR, CVR, and other customer behaviors[44, 46]. Notably, [12] introduced DeepFM, an end-to-end learning model designed for CTR prediction. It deftly combines the recommendation prowess of Factorization Machines with the feature learning capabilities of deep learning, addressing the biases towards loworder and high-order features inherent in traditional algorithms. Similarly, [15] presented FiBiNET, which dynamically models feature importance and effectively learns feature interactions through bilinear functions, achieving outstanding performance in CTR prediction tasks. However, as user numbers and business diversity grow, data collection often introduces significant noise, leading to the degradation of prediction model performance. Furthermore, models trained on historical data may struggle to adapt to new scenarios, hampering their generalization abilities. Several prior works have made inroads into addressing these challenges. In contrast to previous approaches, [24] introduces a novel targeted double robust method named TDR to mitigate bias and variance issues stemming from error-filled models in existing recommendation systems. [48] presents URIPW, a method that confronts the challenge of noisy data due to implicit impression-revisit effects and selection bias. It achieves user retention modeling through a causal perspective by estimating revisit rates. Meanwhile, [37] introduces a pioneering deep learning framework to tackle complexity and non-linearity issues arising from sparse user history and significant delays between click and conversion behaviors. Moreover, [21] diverges from the norm by employing events, such as clicks and skips, rather than observed CTR, to predict ads when historical click records are lacking. [22] establishes a model for predicting advertisement CTRs using Logistic Regression, effectively representing and constructing conditions and vulnerabilities among variables. These prior research endeavors predominantly concentrate on mitigating data noise, addressing multimodality, managing long-tail distributions, and handling distribution shifts. Furthermore, some works divide users into different user segments and improve the performance of models in large-scale industrial recommendation scenarios by constructing individual models suitable for different user segments. For example, [5] analyzes user ratings and extracts word embedding representations to build reliable user segments. What distinguishes our work from this comprehensive backdrop is the introduction of a novel learning framework, USSR. This framework facilitates end-to-end learning of both general representations and fine-grained user-specific representations. Unlike prior efforts, which often necessitate a trade-off between the two, USSR initially Adaptive Learning on User Segmentation: Universal to Specific Representation via Bipartite Neural Interaction* * Note: This work has been published in the proceedings of the 2nd International ACM SIGIR Conference on Information Retrieval in the Asia Pacific. Conference acronym 'XX, June 03-05, 2018, Woodstock, NY leverages information bottleneck learning to extract general representations that encapsulate meta-knowledge derived from the entire dataset. Previous methods typically confined representation learning to individual datasets. USSR further distinguishes itself by employing a dual-part neural interaction mechanism to acquire user-specific representations, allowing for more effective integration of domain expert prior knowledge-an integration that has historically proven challenging. This enables our model to adapt dynamically to the evolving data landscape, a feat not easily accomplished by traditional representation learning methods. Our framework has been rigorously evaluated across multiple real-world business scenarios and has been successfully deployed in Alipay's online services. In contrast, previous representation learning research primarily remained confined to theoretical exploration and benchmark datasets. Notably, USSR significantly enhances prediction performance, surpassing approaches that exclusively focus on learning either general or user-specific representations. This underscores the advantages of simultaneously learning both types of representations, solidifying the uniqueness of our approach.",
  "3 METHODS": "The USSR learning framework first learns the universal representation of all data through information bottleneck on a mixture of Gaussian latent space. Then, the segmentation-specific representation would be learned by bipartite neural interaction between contextual representation and domain-specific representation. The architecture of the USSR framework used in CVR prediction tasks is shown in Figure 1.",
  "3.1 Preliminary": "For probability prediction in digital marketing tasks (e.g., CTR and CVRtasks), the model always observes a feature vector 𝑥 ∈ ❘ 𝑛 with 𝑛 dimension in dataset D . In practice, 𝑥 is always concatenated by user features, item features, and features from other domains. The model can be optimized by using cross-entropy loss on the training dataset between true labels 𝑦 and model prediction ˆ 𝑦 = 𝑓 ( 𝑥 ) :  The representation 𝑧 for each data 𝑥 can be learned either implicitly or explicitly [17, 19, 32, 39] by using numerous feature extraction or feature interaction techniques [12, 36, 38, 40]. To perform marketing operations, the operators may maintain multiple models { 𝑓 𝑖 : 𝑖 ∈ ( 1 ...𝑀 )} on 𝑀 different user segmentation with domainspecific feature 𝑑 𝑖 . The prediction result for each segmentation is separately predicted by the model ˆ 𝑦 𝑖 = 𝑓 𝑖 ( 𝑥 𝑖 ∥ 𝑑 𝑖 ) , where ∥ denotes the concatenation operation. These segmentation can indeed improve the overall performance but unfortunately, ignore the metaknowledge between different segmentation.",
  "3.2 Universal Representation": "The universal representation can be learned on all data with information bottleneck. This learning process would compress the information from all features and generate task-relevant representation [35]. The objective function of this learning process is:  where 𝛽 is Lagrange multiplier and 𝐼 represents the mutual information. By maximizing the objective function, the task-relevant information can be reserved and irrelevant information can be discarded. To capture the multi-modal distribution and potential distributional shift due to continual operation, we encode the user feature in a mixture of Gaussian latent space. We use 𝑞 ( 𝑐 | 𝑥 ) to map 𝑥 into 𝑐 clusters where 𝑐 is categorical variables. Then, the representation 𝑧 can be sampled from the Gaussian distribution with the parameter generated by model 𝑞 ( 𝑧 | 𝑥, 𝑐 = 𝑘 ) on component 𝑘 with a single multi-variant Gaussian encoder head. Each head has a specific prior normal distribution with parameters 𝜇 𝑧 ( 𝑐 ) and 𝜎 𝑧 ( 𝑐 ) , which represent the mean and variance, respectively. Therefore, the encoding process is to choose one Gaussian encoding head by learning a multi-layer perceptron with softmax layer output and represent the embedding using head-specific parameter 𝑧 ∼ N( 𝜇 𝑧 ( 𝑐 = 𝑘 ) , 𝜎 𝑧 ( 𝑐 = 𝑘 )) . After acquiring 𝑧 , we can use one decoder 𝑝 ( 𝑦 | 𝑧 ) to perform universal target prediction. However, the objective function shown in Eqn (2) is intractable and cannot be directly optimized. Instead, we corporate the aforementioned model structure and optimize the evidence lower bound by minimizing the following objective function:  where ˜ 𝑧 𝑘 ∼ 𝑞 ( 𝑧 | 𝑥, 𝑐 = 𝑘 ) and KL represents the KL-divergence between two distribution. To achieve an accurate and informative representation of complicated feature structures, variant feature interaction models can be implied as encoder and decoder of our framework. In our implementation, we utilize AutoInt [36] as the encoder.",
  "3.3 Segmentation-specific Representation": "Leveraging the universal representation acquired in Section 3.2 on all subsequent tasks is feasible but not accurate. In practical digital marketing scenarios, the operators always perform domain-specific marketing under different user segmentation and believe that such segmentation is marketing navigation to improve the total business performance (e.g., constructing different coupon sets based on age, gender, or phone systems). Incorporating prior knowledge into machine learning models has been shown to improve system performance. However, this often requires domain-specific modeling on different user distributions, which can be time-consuming [23, 28]. To better incorporate the prior knowledge from business experts and leverage the informative universal representation on domain-specific tasks, we design an adaptive neural interaction learning process similar to Kipf et al. [18] to perform representation interaction between universal representation and segmentationspecific knowledge. Since the user-segmentation defined by the operators can contain one or more contextual groups 𝑐 learned from Section 3.2, we construct the neural interaction process under a bipartite graph architecture [14]. Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Xiaoyu Tan, Yongxin Deng, Chao Qu, Siqiao Xue, Xiaoming Shi, James Zhang, and Xihe Qiu Figure 1: The architecture of USSR framework used in CVR prediction tasks. Feature 2 Task Leaner Universal CVR Predictor Interaction User OOO Decoder pCVR qy | x) User Attention Network Decoder pCVR OK Fund 02 K Coupon 2 K Decoder pCVR Task-specific Segmentation Specific CVR Predictor Gaussian Repr Suppose the whole user group is divided into 𝑀 user-segmentation with segmentation-specific features: { 𝑢 𝑚 : 𝑚 ∈ ( 1 ...𝑀 )} and the users can be represented into 𝐾 contextual groups with latent representation : { 𝑧 𝑘 : 𝑘 ∈ ( 1 ...𝐾 )} . The 𝑢 𝑚 can be defined at the domain level or user level and contains prior knowledge from experts. The neural interaction process under bipartite architecture requires edge encoder 𝑓 𝑒 , vortex encoder 𝑓 𝑣 , edge decoder ˆ 𝑓 𝑒 , and vortex decoder ˆ 𝑓 𝑣 .",
  "3.4 Adaptive Learning on Segmentation and Data Expansion": "We first use an edge encoder 𝑓 𝑒 to learn the first interactive representation of all possible interactions:  Then, the information can be summarized from both contextual and segmentation perspectives through vortex encoders:  Finally, the bipartite interaction architecture can be learned by edge encoder again and sparsely represented in 𝑒 𝑘,𝑚 through a softmax layer. By implementing the bipartite architecture, the segmentationspecific representation ˆ ℎ 𝑚 can be learned by edge decoder:  Based on the implementation details on subsequent tasks, the prediction can be made by one vortex decoder or 𝑀 decoders for each user-segmentation: { ˆ 𝑓 𝑣,𝑚 : 𝑚 ∈ ( 1 ...𝑀 )} . We recommend using multiple vortex decoders to achieve robust prediction results during the segmentation expansion: ˆ 𝑦 = ˆ 𝑓 𝑣,𝑚 ( ˆ ℎ 𝑚 ) . This architecture can be typically optimized following the cross-entropy loss between ˆ 𝑦 and true label 𝑦 introduced in equation 2. Real industry applications always require the models to have the elasticity to adapt data expansion [7]. Business operators also always create and update user segmentation based on their business understanding and marketing processes. The USSR learning framework can increase the capacity of universal representation by dynamic expansion on contextual clusters 𝑐 . The segmentationspecific representation can also be incrementally trained without influencing the model parameters. For the dynamic expansion of universal representation, we set threshold 𝑡 logit on the log-likelihood evaluation with equation 3 and threshold 𝑡 num on data numbers. If the evaluation result of new data is larger than 𝑡 logit , we put the data into a new data buffer D new. If the data number of D new is larger than 𝑡 num, we perform few shot iterative training through loss function:  The component 𝑞 ( 𝑧 | 𝑥, 𝑐 = 𝐾 + 1 ) can be initialized by 𝑞 ( 𝑧 | 𝑥, 𝑐 = 𝑙 ∗ ) where:  For the expansion of segmentation-specific representation, the whole process is controlled by business operators and the learning process can be disentangled from other representations. This can be achieved by first storing the segmentation-specific representation { ˆ ℎ 𝑚 : 𝑚 ∈ ( 1 , ..., 𝑀 )} in D and solely performing inference by ˆ 𝑓 𝑣,𝑚 . This process can also significantly reduce the model inference duration. Then, we can repeat the whole learning process of Section 3.3 to get a new segmentation-specific representation ˆ ℎ 𝑀 + 1 and new inference model ˆ 𝑓 𝑣,𝑀 + 1 . This process can ensure the new representation contains the meta-knowledge from all previous user segmentation but all previous representation remains the same. Adaptive Learning on User Segmentation: Universal to Specific Representation via Bipartite Neural Interaction* * Note: This work has been published in the proceedings of the 2nd International ACM SIGIR Conference on Information Retrieval in the Asia Pacific. Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Moreover, the robustness and stability of online performance can also be satisfied during the model industrial launch.",
  "4 EXPERIMENTS AND PERFORMANCE": "Our experiment aims to investigate the effectiveness of the proposed framework in benchmarks, real-world scenarios, and its potential for practical applications. The experiment can be divided into three main parts. Firstly, we evaluate the performance of our USSR framework on two widely used public datasets, Criteo[8] and Avazu[1], and compare it with state-of-the-art algorithms. Secondly, we assess the performance of the USSR framework on two distinct offline datasets derived from Alipay's industrial application. Lastly, to evaluate the framework's ability to adapt to real-time data (which we consider the most significant capability), we deploy the framework online on two Alipay services. The latter two parts of the experiment focus on different user group segmentation CVR prediction tasks in the Alipay Caifu and Jiebei scenarios. These scenarios face challenges such as lone-tile data distribution, expanding user space, and increasing user segmentation (e.g., one scenario contains more than 20 user segmentation). For these scenarios, due to the model deployment policies of the company and resources limitation, we only choose the model originally used in the online service, a universally trained AutoInt model [36], as our baseline method. For public evaluation, we choose multiple state-of-the-art methods as our baseline methods to fully evaluate our proposed algorithm.",
  "4.1 Evaluation on Public Datasets": "The Criteo dataset is a widely used public dataset for research and development in advertising recommendation systems and machine learning algorithms. It is provided by Criteo and contains anonymized online advertising transaction data, where each record consists of a series of features and labels. The features include anonymized user identifiers, properties of the ads (e.g., category, size, format), historical CTR of ads, contextual information of ad placements, etc. Specifically, it includes 13 dense features and 26 sparse features, and the label indicates whether the user clicked on the ad. The Avazu dataset, on the other hand, is a public dataset of online ad click data commonly used for CTR prediction and advertising recommendation machine learning algorithms. It contains billions of ad transaction records, where each record includes various features and labels. The features include user and ad information, such as anonymized user identifiers, ad IDs, ad categories, time, and geographic location of ad placements, primarily consisting of sparse features. The label represents whether the user clicked on the ad, used for building binary classification machine learning models. For our experiments, we used the datasets provided by PaddleRec[2, 3]. For the dense features in the dataset, we applied a logarithm transformation to restrict their range. As for the sparse features, we first calculated the frequency of each feature category occurring in the entire dataset. Then, we assigned integer indices to the categories based on their ranking in terms of frequency (the indices in the test set correspond to those in the training set, so in the actual processing, we concatenate the training and test sets Table 1: The experiment results of AUC on two public CTR tasks datasets compared with baseline methods. firstly, generate the indices, and then split them). Since the features in the dataset exhibit a long-tail distribution, we set an upper limit for the indices. Finally, we used these indices to generate embedding vectors for training. In this experiment, we conduct the comparative analysis between our proposed USSR and several state-of-the-art approaches that have been extensively employed in practical applications. Specifically, we consider DeepFM [12], xDeepFM [26], DCN[40], ONN[45] , FiGNN [25] , and AutoInt [36] as the benchmark methods for our evaluation. The experimental results in terms of Area Under the Curve (AUC) are presented in Table 1, along with the performance of some state-of-the-art models for comparison. Please note that for the evaluation on public datasets, we only tested the universal representation learning and segmentation-specific representation learning parts introduced in Section 3.2 and Section 3.3. The results of our study demonstrate that the USSR framework exhibits superior performance compared to other baseline models when employed on the Avazu dataset, yielding an AUC of 0.8133. This value significantly surpasses the majority of baseline methods, which generally yield AUC scores below 0.80. In the Criteo dataset experiment, our proposed method also demonstrates remarkable performance, surpassing an AUC score of around 0.81 and closely rivaling other state-of-the-art baseline methods, positioning it among the top-performing practical solutions available.",
  "4.2 Evaluation on Alipay Offline Datasets": "For the offline tests, we extracted the data from historical log records, including user features, user segmentation index, and CVR labels, over a span of 30 days. We randomly shuffled and split the dataset into a training set and a validation set, using 80% and 20% of the first 27 days of data, respectively. The remaining 3 days' data was kept as the test set. We trained the proposed model on the training set and evaluated its performance on the validation set. The test set remained unseen until the final evaluation. To prevent overfitting, we employed early stopping based on the performance on the validation set. Similar to the evaluation on public datasets, Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Xiaoyu Tan, Yongxin Deng, Chao Qu, Siqiao Xue, Xiaoming Shi, James Zhang, and Xihe Qiu Table 2: The experiment results of AUC on two offline CVR tasks datasets compared with baseline method. Table 3: The online results of CVR on two online CVR prediction services compared with baseline method. for the offline evaluation, we only tested the universal representation learning and segmentation-specific representation learning parts introduced in Section 3.2 and Section 3.3. The experimental results in terms of AUC are described in Table 2. Additionally, we reported the worst performance of the models among all available segmentations, which indicates the robustness of segmentationspecific training. Our results demonstrate that the USSR framework outperforms previous approaches in both overall and segmentationspecific performance measures in the offline tests.",
  "4.3 Evaluation on Alipay Online Scenarios": "We deployed the model online and monitored its performance for 7 days by serving 10% of online customers in two online scenarios. Our trained models only provided CVR prediction results, while item recommendation was handled by the Alipay internal online optimization service, which can set cost constraints [49]. To ensure a fair comparison, we set the cost constraint of the two models on the same scale. Similar to the offline tests, we compared the performance with the main operating model (i.e., AutoInt model), directly observed the mean CVR results of each service, and examined the robustness by reporting the worst performance of the USSR framework among all segmentations. The results are presented in Table 3. Based on the online performance, we observed that the trained models under the USSR framework achieved higher online performance and significant improvement even on the worst segmentation. Finally, the trained models passed the online A/B test and were deployed as the main models in these two scenarios.",
  "5 CONCLUSION": "In this paper, we propose a novel learning architecture that can perform universal representation and user-segmentation representation (USSR) learning adaptively in an end-to-end manner. Our proposed approach employs a deep information bottleneck to learn universal representation, while leveraging neural interaction to acquire segmentation-specific representation. Additionally, the framework dynamically expands the representation space to accommodate data expansion. To evaluate the effectiveness of our approach, we first evaluate and compare with other state-of-the-art methods on the open-source dataset. Then, we applied it to two distinct Alipay applications and deployed the models in two Alipay online services. The experiment results and online performance demonstrate that the USSR approach can adapt to different user groups and enhance its performance in an efficient end-to-end manner. The proposed approach has the potential to improve the performance of various applications in real-world settings. Future research may further explore the capabilities and limitations of the USSR approach and investigate its potential applications in various domains.",
  "REFERENCES": "[1] Avazu. 2015. Click-Through Rate Prediction, predict whether a mobile ad will be clicked. https://www.kaggle.com/c/avazu-ctr-prediction/data. [2] Baidu. 2020. An Open-Source Deep Learning Platform Originated from Industrial Practice, PaddlePaddle is dedicated to facilitating innovations and applications of deep learning. https://github.com/PaddlePaddle/PaddleRec. [3] Ran Bi, Tongtong Xu, Mingxue Xu, and Enhong Chen. 2022. PaddlePaddle: A Production-Oriented Deep Learning Platform Facilitating the Competency of Enterprises. In 2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys) . IEEE, 92-99. [4] Jesús Bobadilla, Francisco Serradilla, and Jesus Bernal. 2010. A new collaborative filtering metric that improves the behavior of recommender systems. KnowledgeBased Systems 23, 6 (2010), 520-528. [5] Ludovico Boratto, Salvatore Carta, Gianni Fenu, and Roberto Saia. 2016. Using neural word embeddings to model user behavior and detect user segments. Knowledge-based systems 108 (2016), 5-14. [6] Giovanna Castellano, Anna Maria Fanelli, and Maria Alessandra Torsello. 2011. NEWER: A system for NEuro-fuzzy WEb Recommendation. Applied Soft Computing 11, 1 (2011), 793-806. [7] Ding Chong and Hapzi Ali. 2022. LITERATURE REVIEW: COMPETITIVE STRATEGY, COMPETITIVE ADVANTAGES, AND MARKETING PERFORMANCE ON E-COMMERCE SHOPEE INDONESIA. Dinasti International Journal of Digital Business Management 3, 2 (2022), 299-309. [8] Criteo. 2014. Display Advertising Challenge Predict click-through rates on display ads. https://www.kaggle.com/competitions/criteo-display-ad-challenge/data. [9] Sahraoui Dhelim, Nyothiri Aung, Mohammed Amine Bouras, Huansheng Ning, and Erik Cambria. 2022. A survey on personality-aware recommendation systems. Artificial Intelligence Review (2022), 1-46. [10] Chen Gao, Xiang Wang, Xiangnan He, and Yong Li. 2022. Graph neural networks for recommender system. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining . 1623-1625. [11] Ángel García-Crespo, José Luis López-Cuadrado, Ricardo Colomo-Palacios, Israel González-Carrasco, and Belén Ruiz-Mezcua. 2011. Sem-Fit: A semantic based expert system to provide recommendations in the tourism domain. Expert systems with applications 38, 10 (2011), 13310-13319. [12] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247 (2017). [13] DanHendrycksandKevinGimpel. 2016. A baseline for detecting misclassified and out-of-distribution examples in neural networks. arXiv preprint arXiv:1610.02136 (2016). [14] Junjie Huang, Huawei Shen, Qi Cao, Shuchang Tao, and Xueqi Cheng. 2021. Signed Bipartite Graph Neural Networks. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management . 740-749. [15] Tongwen Huang, Zhiqi Zhang, and Junlin Zhang. 2019. FiBiNET: combining feature importance and bilinear feature interaction for click-through rate prediction. In Proceedings of the 13th ACM Conference on Recommender Systems . 169-177. [16] Caigao Jiang, Siqiao Xue, James Zhang, Lingyue Liu, Zhibo Zhu, and Hongyan Hao. 2022. Learning Large-scale Universal User Representation with Sparse Mixture of Experts. ICML Workshop on Pre-training (2022). [17] Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013). [18] Thomas Kipf, Ethan Fetaya, Kuan-Chieh Wang, Max Welling, and Richard Zemel. 2018. Neural relational inference for interacting systems. In International conference on machine learning . PMLR, 2688-2697. [19] Thomas N Kipf and Max Welling. 2016. Variational graph auto-encoders. arXiv preprint arXiv:1611.07308 (2016). [20] Hyeyoung Ko, Suyeon Lee, Yoonseo Park, and Anna Choi. 2022. A survey of recommendation systems: recommendation models, techniques, and application fields. Electronics 11, 1 (2022), 141. Adaptive Learning on User Segmentation: Universal to Specific Representation via Bipartite Neural Interaction* * Note: This work has been published in the proceedings of the 2nd International ACM SIGIR Conference on Information Retrieval in the Asia Pacific. Conference acronym 'XX, June 03-05, 2018, Woodstock, NY [21] Alexander Kolesnikov, Yury Logachev, and Valeriy Topinskiy. 2012. Predicting CTR of new ads via click prediction. In Proceedings of the 21st ACM international conference on Information and knowledge management . 2547-2550. [22] Rohit Kumar, Sneha Manjunath Naik, Vani D Naik, Smita Shiralli, VG Sunil, and Moula Husain. 2015. Predicting clicks: CTR estimation of advertisements using logistic regression classifier. In 2015 IEEE international advance computing conference (IACC) . IEEE, 1134-1138. [23] Hoyeop Lee, Jinbae Im, Seongwon Jang, Hyunsouk Cho, and Sehee Chung. 2019. Melu: Meta-learned user preference estimator for cold-start recommendation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 1073-1082. [24] Haoxuan Li, Yan Lyu, Chunyuan Zheng, and Peng Wu. 2023. TDR-CL: Targeted Doubly Robust Collaborative Learning for Debiased Recommendations. In The Eleventh International Conference on Learning Representations . [25] Zekun Li, Zeyu Cui, Shu Wu, Xiaoyu Zhang, and Liang Wang. 2019. Fi-gnn: Modeling feature interactions via graph neural networks for ctr prediction. In Proceedings of the 28th ACM international conference on information and knowledge management . 539-548. [26] Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018. xdeepfm: Combining explicit and implicit feature interactions for recommender systems. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1754-1763. [27] Siyi Liu and Yujia Zheng. 2020. Long-tail session-based recommendation. In Proceedings of the 14th ACM Conference on Recommender Systems . 509-514. [28] Yuanfu Lu, Yuan Fang, and Chuan Shi. 2020. Meta-learning on heterogeneous information networks for cold-start recommendation. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 1563-1573. [29] Sanjay Mohapatra and Sanjay Mohapatra. 2013. E-commerce Strategy . Springer. [30] Gal Oestreicher-Singer and Arun Sundararajan. 2012. Recommendation networks and the long tail of electronic commerce. Mis quarterly (2012), 65-83. [31] Carlos Porcel, Juan Manuel Moreno, and Enrique Herrera-Viedma. 2009. A multidisciplinar recommender system to advice research resources in university digital libraries. Expert systems with applications 36, 10 (2009), 12520-12528. [32] Yunchen Pu, Zhe Gan, Ricardo Henao, Xin Yuan, Chunyuan Li, Andrew Stevens, and Lawrence Carin. 2016. Variational autoencoder for deep learning of images, labels and captions. Advances in neural information processing systems 29 (2016). [33] Chao Qu, Xiaoyu Tan, Siqiao Xue, Xiaoming Shi, James Zhang, and Hongyuan Mei. 2023. Bellman Meets Hawkes: Model-Based Reinforcement Learning via Temporal Point Processes. In AAAI 2023 . AAAI Press. https://arxiv.org/abs/2201. 12569 [34] Nur W Rahayu, Ridi Ferdiana, and Sri S Kusumawardani. 2022. A systematic review of ontology use in E-Learning recommender system. Computers and Education: Artificial Intelligence (2022), 100047. [35] Dushyant Rao, Francesco Visin, Andrei Rusu, Razvan Pascanu, Yee Whye Teh, and Raia Hadsell. 2019. Continual unsupervised representation learning. Advances in Neural Information Processing Systems 32 (2019). [36] Weiping Song, Chence Shi, Zhiping Xiao, Zhijian Duan, Yewen Xu, Ming Zhang, and Jian Tang. 2019. Autoint: Automatic feature interaction learning via selfattentive neural networks. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management . 1161-1170. [37] Yumin Su, Liang Zhang, Quanyu Dai, Bo Zhang, Jinyao Yan, Dan Wang, Yongjun Bao, Sulong Xu, Yang He, and Weipeng Yan. 2021. An attention-based model for conversion rate prediction with delayed feedback via post-click calibration. In Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence . 3522-3528. [38] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM international conference on information and knowledge management . 1441-1450. [39] Arash Vahdat and Jan Kautz. 2020. NVAE: A deep hierarchical variational autoencoder. Advances in neural information processing systems 33 (2020), 19667-19679. [40] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep & cross network for ad click predictions. In Proceedings of the ADKDD'17 . 1-7. [41] Wenjie Wang, Xinyu Lin, Fuli Feng, Xiangnan He, Min Lin, and Tat-Seng Chua. 2022. Causal representation learning for out-of-distribution recommendation. In Proceedings of the ACM Web Conference 2022 . 3562-3571. [42] Xiaohui Wu, Jun Yan, Ning Liu, Shuicheng Yan, Ying Chen, and Zheng Chen. 2009. Probabilistic latent semantic user segmentation for behavioral targeted advertising. In Proceedings of the Third International Workshop on Data Mining and Audience Intelligence for Advertising . 10-17. [43] Siqiao Xue, Chao Qu, Xiaoming Shi, Cong Liao, Shiyi Zhu, Xiaoyu Tan, Lintao Ma, Shiyu Wang, Shijun Wang, Yun Hu, Lei Lei, Yangfei Zheng, Jianguo Li, and James Zhang. 2022. A Meta Reinforcement Learning Approach for Predictive Autoscaling in the Cloud. In KDD '22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022 , Aidong Zhang and Huzefa Rangwala (Eds.). ACM, 4290-4299. https: //doi.org/10.1145/3534678.3539063 [44] Siqiao Xue, Xiaoming Shi, Y James Zhang, and Hongyuan Mei. 2022. HYPRO: A Hybridly Normalized Probabilistic Model for Long-Horizon Prediction of Event Sequences. In Advances in Neural Information Processing Systems . https://arxiv. org/abs/2210.01753 [45] Yi Yang, Baile Xu, Shaofeng Shen, Furao Shen, and Jian Zhao. 2020. Operationaware neural networks for user response prediction. Neural Networks 121 (2020), 161-168. [46] Yanwu Yang and Panyu Zhai. 2022. Click-through rate prediction in online advertising: A literature review. Information Processing & Management 59, 2 (2022), 102853. https://doi.org/10.1016/j.ipm.2021.102853 [47] Kazuyoshi Yoshii, Masataka Goto, Kazunori Komatani, Tetsuya Ogata, and Hiroshi G Okuno. 2008. An efficient hybrid music recommender system using an incrementally trainable probabilistic generative model. IEEE Transactions on Audio, Speech, and Language Processing 16, 2 (2008), 435-447. [48] Yang Zhang, Dong Wang, Qiang Li, Yue Shen, Ziqi Liu, Xiaodong Zeng, Zhiqiang Zhang, Jinjie Gu, and Derek F Wong. 2021. User Retention: A Causal Approach with Triple Task Modeling.. In IJCAI . 3399-3405. [49] Jun Zhou, Yang Bao, Hua Wu, and Zhigang Hua. 2021. Antopt: A multi-functional large-scale decision optimization platform. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management . 4833-4837. Received 20 February 2007; revised 12 March 2009; accepted 5 June 2009",
  "keywords_parsed": [
    "representation learning",
    " adaptive learning",
    " neural networks"
  ]
}