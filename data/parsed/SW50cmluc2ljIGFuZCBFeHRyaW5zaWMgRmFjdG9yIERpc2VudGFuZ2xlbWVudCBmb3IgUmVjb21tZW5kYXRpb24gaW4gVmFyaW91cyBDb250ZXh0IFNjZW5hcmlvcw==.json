{
  "Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios": "YIXIN SU âˆ—â€  , School of Computer Science and Technology, Huazhong University of Science and Technology, China WEI JIANG âˆ— , Alibaba Group, China FANGQUAN LIN, Alibaba Group, China CHENG YANG, Alibaba Group, China SARAH M. ERFANI, The University of Melbourne, Australia JUNHAO GAN, The University of Melbourne, Australia YUNXIANG ZHAO â€¡ , Laboratory of Advanced Biotechnology, Beijing Institute of Biotechnology, China RUIXUAN LI, School of Computer Science and Technology, Huazhong University of Science and Technology, China RUI ZHANG â€¡ , School of Computer Science and Technology, Huazhong University of Science and Technology (www.ruizhang.info), China In recommender systems, the patterns of user behaviors (e.g., purchase, click) may vary greatly in different contexts (e.g., time and location). This is because user behavior is jointly determined by two types of factors: intrinsic factors , which reflect consistent user preference, and extrinsic factors , which reflect external incentives that may vary in different contexts. Differentiating between intrinsic and extrinsic factors helps learn user behaviors better. However, existing studies have only considered differentiating them from a single, predefined context (e.g., time or location), ignoring the fact that a user's extrinsic factors may be influenced by the interplay of various contexts at the same time. In this paper, we propose the Intrinsic-Extrinsic Disentangled Recommendation (IEDR) model, a generic framework that differentiates intrinsic from extrinsic factors considering various contexts simultaneously, enabling more accurate differentiation of factors and hence the improvement of recommendation accuracy. IEDR contains a context-invariant contrastive learning component to capture intrinsic factors, and a disentanglement component to extract extrinsic factors under the interplay of various contexts. The two components work together to achieve effective factor learning. âˆ— Both authors contributed equally to this research. â€  Yixin Su did this work when he was an intern at Alibaba Group. â€¡ Corresponding authors. Authors' Contact Information: Yixin Su, yixin.su@outlook.com, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; Wei Jiang, wwjiangwei@hotmail.com, Alibaba Group, Hangzhou, China; Fangquan Lin, fangquan.linfq@alibaba-inc.com, Alibaba Group, Hangzhou, China; Cheng Yang, charis.yangc@ alibaba-inc.com, Alibaba Group, Hangzhou, China; Sarah M. Erfani, sarah.erfani@unimelb.edu.au, The University of Melbourne, Melbourne, Australia; Junhao Gan, junhao.gan@unimelb.edu.au, The University of Melbourne, Melbourne, Australia; Yunxiang Zhao, zhaoyx1993@163.com, Laboratory of Advanced Biotechnology, Beijing Institute of Biotechnology, Beijing, China; Ruixuan Li, rxli@hust.edu.cn, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; Rui Zhang, rayteam@yeah.net, School of Computer Science and Technology, Huazhong University of Science and Technology (www.ruizhang.info), Wuhan, China. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Â© 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM 1558-2868/2025/1-ART1 https://doi.org/10.1145/3722553 ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:2 Su, et al. Extensive experiments on real-world datasets demonstrate IEDR's effectiveness in learning disentangled factors and significantly improving recommendation accuracy by up to 4% in NDCG. CCS Concepts: Â· Information systems â†’ Recommender systems ; Data mining ; Personalization ; Â· Computing methodologies â†’ Knowledge representation and reasoning . Additional Key Words and Phrases: Recommender Systems, Intrinsic and Extrinsic Factors, Contrastive Learning, Disentanglement, Mutual Information",
  "ACMReference Format:": "Yixin Su, Wei Jiang, Fangquan Lin, Cheng Yang, Sarah M. Erfani, Junhao Gan, Yunxiang Zhao, Ruixuan Li, and Rui Zhang. 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios. ACM Trans. Inf. Syst. 1, 1, Article 1 (January 2025), 33 pages. https://doi.org/10.1145/3722553",
  "1 Introduction": "Recommender systems [20, 27, 39, 58] aim to predict the probability of a user's behavior (e.g., purchase, click) on a given item. This is a challenging task since a user's behavior may vary significantly across different contexts (e.g., time, location, and social setting). For example, considering the context of social settings (e.g., alone vs. with friends), when recommending food, a user may prefer healthy food like steamed vegetables and salad when being alone, but may prefer more diverse food suitable for sharing like hot pot or pizza when gathering with friends. This context-dependent variation in user behaviors underscores their complex nature. Psychological research has devoted great efforts to understanding this phenomenon, and reveals that user behaviors are influenced by two types of factors: intrinsic and extrinsic factors [3, 35], distinguished by whether they can be influenced by context changes. An intrinsic factor, which is often stable for a user across different contexts, is an internal motivation for inherent satisfaction. In our food recommendation example, the preference for healthy food when eating alone could be driven by intrinsic factors such as personal health goals or taste preferences. In contrast, an extrinsic factor, which is an external motivation stimulated by the contexts, often varies when contexts change [26]. The choice of more diverse food when gathering with friends could be influenced by extrinsic factors such as the social setting. Therefore, to better understand user behaviors and provide more accurate recommendations, it is crucial yet challenging for recommender systems to effectively capture and differentiate between intrinsic and extrinsic factors in various contexts. Existing studies that aim to differentiate between intrinsic and extrinsic factors consider only a single, pre-defined context, e.g., time [9, 53] or location [13, 16]. However, in reality, user behaviors are often influenced by the interplay of various contexts simultaneously. These methods may not be able to accurately capture user behaviors , especially when contexts change (an example will be given in the next paragraph). Moreover, these methods are designed specifically for the pre-defined context. For example, Li et al. [16] leverages location context to differentiate intrinsic and extrinsic factors. They incorporate a context-specific assumption into their model that the choice of a long geographical distance place is more influenced by intrinsic factors and vice versa. Consequently, it is difficult to extend these methods to scenarios where multiple types of contexts may affect the result. For instance, this location-specific assumption cannot be adapted to a social setting context. Given these limitations, in this paper, we aim to capture and differentiate between intrinsic and extrinsic factors from various contexts, thereby enhancing the ability to learn user behaviors. To this end, we adopt an approach from a more fundamental perspective without introducing any context-specific assumptions. Under this general context condition, we first define intrinsic and extrinsic factors by focusing on whether these factors vary when contexts change. Following this definition, we propose an Intrinsic-Extrinsic Disentangled Recommendation (IEDR) model, a general framework that can effectively capture the interplay of various contexts and differentiate ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:3 About Bob: Â· Generally prefers healthy food Â· May have diverse food when with friends",
  "Factor learning from only social events context:": "Â· Intrinsic factor :  prefer warm healthy food Â· Extrinsic factor : prefer diverse food with friends Bob's behaviors collected in dataset:",
  "(Ours) Factor learning from varied-contexts (social events & weather):": ":  prefer healthy food Â· Intrinsic factor Â· Extrinsic factor : prefer diverse food with friends; prefer warm food in cold weather Fig. 1. An example to compare existing work (consider only the context of social settings) and our approach (consider various contexts) in learning intrinsic and extrinsic factors. The upper part shows the preference fact (upper left) and observed behaviors (upper right) of a user Bob. The bottom part shows the possible factor learning results and corresponding recommendations of existing work (bottom left) and our approach (bottom right). Alone With Friends Hot Weather (Recommended) Ceaser Salad Barbecue, Cold beer intrinsic and extrinsic factors within them. To illustrate the importance of accurately differentiating between intrinsic and extrinsic factors in scenarios with various contexts, consider the example in Figure 1. A user called Bob generally prefers healthy food but enjoys diverse food when gathering with friends (top left of the figure). The dataset happens to only contain Bob's behaviors in cold weather (top right of the figure), where Bob has steamed vegetables (warm healthy food) when alone and hot pot (diverse option) with friends. Existing models differentiate between intrinsic and extrinsic factors from only one of the contexts, such as social settings (i.e., alone vs. with friends) in this example. They might incorrectly identify warm food preference as Bob's intrinsic factor (lower left of the figure). This is because the model treats the weather context (i.e., cold vs. hot) as a regular feature rather than a context used for factor differentiation. The weather-dependent influence may show similar patterns across different social settings (e.g., warm foods are chosen either when alone or with friends), leading to weather-dependent extrinsic factors being mistakenly identified as intrinsic factors. In contrast, our model considers various contexts for differentiating the factors (lower right of the figure). Since a strong correlation may exist between weather and warm/cold food choices (e.g., most users may choose warm food in cold weather and cold food in hot weather), our model captures such weather-dependent preferences as extrinsic factors. Bob's choices of warm food all occur in cold weather, fitting well with the weather-dependent preference pattern (i.e., preferring warm food in cold weather). Therefore, our model can accurately capture such choices as being influenced by extrinsic factors. When in hot weather scenarios (shown in the bottom two tables of the figure), existing models (left table) may incorrectly recommend hot food due to misidentified intrinsic factors. In comparison, our model (right table) adapts to the weather context, recommending more suitable cold options like Caesar salad and cold beer. The IEDR framework consists of two main modules: a recommendation prediction (RP) module and a contrastive intrinsic-extrinsic disentangling (CIED) module. To better capture the interplay among different contexts, the RP module constructs various contexts into a graph structure, where each context is represented as a node and their interplay (interactions) is represented as edges, and a complete graph is constructed. By applying graph learning algorithms to this context graph, the model can comprehensively learn the complex relationships and mutual influences between contexts, enabling it to obtain more informative context representations. Similarly, user and item ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:4 Su, et al. representations are obtained from their respective attributes (e.g., user gender, item category). The core innovation of IEDR lies in the CIED module, which leverages the synergy between a context-invariant contrastive learning component and a mutual information minimization-based disentangling component to effectively differentiate intrinsic and extrinsic factors into disentangled representations. The contrastive learning component captures user preference that is stable across contexts by contrasting user representations under different contextual conditions. Concurrently, the disentangling component employs a bidirectional mutual information minimization scheme to separate the extrinsic factors that vary with different contexts from the intrinsic factors. By jointly optimizing these two components, IEDR ensures that the learned intrinsic factors are not only stable across different contexts but also well-separated from the extrinsic factors. This innovative approach enables IEDR to effectively learn disentangled intrinsic and extrinsic factors, capturing the complex user behavior patterns for recommendation in various context scenarios. In this paper, we make the following contributions: Â· We formally define intrinsic and extrinsic factors for recommender systems. Based on this definition, we propose IEDR, a novel framework that effectively learns intrinsic and extrinsic factors for more accurate recommendations. This is achieved by introducing two key components: a context-invariant contrastive learning component and a mutual information minimizationbased disentangling component. These components work together to effectively capture the two types of factors from the interplay of various contexts. The implementation of IEDR is available at https://github.com/ethanmock/IEDR. Â· Wetheoretically analyze the proposed methods from an information theory perspective, providing insights into the effectiveness of our approach. We also identify key challenges and propose principled solutions to avoid degenerating results and ensure robust disentanglement, thereby improving recommendation accuracy and stability. Â· Extensive experiments on real-world datasets demonstrate that (1) IEDR significantly outperforms state-of-the-art methods by up to 4% in NDCG, and (2) the proposed CIED module effectively learns disentangled intrinsic and extrinsic factors, leading to improved recommendation accuracy.",
  "2 Related Work": "This section summarizes the current research progress related to our work on factor disentanglement, feature interactions in recommender systems, and contrastive learning.",
  "2.1 Factor disentanglement": "Intrinsic and extrinsic factors are considered as two basic factors for individual decision-making in psychological research [3, 26, 35]. Recent recommender systems have borrowed the idea of capturing these two factors to achieve more accurate recommendations. For example, in the sequential recommendation, Hidasi et al. [13] leverage the recurrent neural networks to capture users' long- and short-term (LS-term) interests from their interacted item sequences. Yu et al. [53] propose a time-aware controller to capture the differences between LS-term interests for more accurate interest learning. Zheng et al. [56] further emphasize the disentanglement between the LS-term interests at different time scales to differentiate the LS-term interests. Ning et al. [23] demonstrate the effectiveness of embedding disentanglement by separating inter-domain and intradomain knowledge. Wang et al. [41] propose a Causal Disentangled Recommendation framework to handle user preference shifts by modeling the interaction generation procedure using a causal graph. In point-of-interest recommendation, studies are leveraging spatial context to capture the intrinsic and extrinsic factors [16, 45]. However, all of the above studies focus on specific contexts. As a result, their factor learning approaches are hard to apply to other recommendation domains, which ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:5 may result in a suboptimal solution if other contexts jointly influence these factors. Some studies learn users' various factors without knowing the meaning of each factor (i.e., implicit factor). They first define the number of factors (e.g., 4) to be learned, and then disentangle the representations of each pair of factors [21, 42]. Compared to previous studies that focus on specific contexts or learn implicit factors, our IEDR model provides a generic framework to explicitly learn intrinsic and extrinsic factors from various contexts, enabling effective modeling of the complex interplay between stable user preference and various contextual influences in real-world recommendation scenarios.",
  "2.2 Feature interaction modeling": "Many recommender systems leverage feature interactions to improve recommendation accuracy. One of the most common techniques is the factorization machine (FM) [25], which models feature interactions through dot product and achieves great success. Recent studies extend FM with deep neural networks for more powerful feature interaction modeling [12, 31, 46, 52]. The Wide & Deep model (WDL) [7] proposes a framework that combines shallow and deep modeling of features for recommendation. [11] combines FM and WDL by replacing the shallow part of WDL with an FM model. [30] leverages the relation reasoning power of graph neural networks for feature interaction modeling. We are the first work to represent various contexts as a feature graph, and leverage graph neural networks to capture the interplay of the contexts in a feature interaction modeling paradigm for unified context learning.",
  "2.3 Contrastive learning": "Contrastive learning has achieved great success in computer vision [6], neural language processing [24], graph learning [5, 55] and music learning [47]. Recently, contrastive learning has attracted attention in recommender systems. Yao et al. [48] conduct contrastive learning on users and items respectively on a two-tower framework to learn robust user and item representations. In addition, Wu et al. [44] propose a contrastive learning framework on a user-item bipartite graph to capture robust high-degree relationships between users and items. Ye et al. [49] leverage contrastive learning on perturbed embeddings to improve the robustness of neural graph collaborative filtering. Wang et al. [36] propose a general framework called ContraRec that unifies two kinds of contrastive learning tasks, context-target contrast and context-context contrast, for sequential recommendation. Some studies enhance recommendation through contrastive learning by mitigating popularity bias and promoting long-tail items with noise-based embedding augmentations [50, 51]. Zhang et al. [54] propose AdvInfoNCE to handle false negatives and improve generalization. Cai et al. [4] introduce LightGCL, using singular value decomposition to refine semantic structures and improve robustness. NCL incorporates structural and semantic neighbors as positive pairs for better useritem relationship learning [19]. The CETN model [17] addresses the challenge of capturing diverse and homogeneous feature interactions across semantic spaces by employing contrastive learning and self-supervised signals. These works use contrastive learning to enhance recommendation by addressing bias, improving robustness, and promoting long-tail items. Unlike previous works, we propose a context-invariant contrastive learning approach to capture stable intrinsic factors across various contexts, which is integrated with a mutual information minimization scheme to disentangle context-specific extrinsic factors.",
  "3 Preliminary": "In this section, we introduce two key techniques that lay the foundation for our proposed method: the Statistical Interaction Graph Network (SIGN) [30] for effective feature interaction modeling, and ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:6 Su, et al. the Variational Contrastive Log-ratio Upper Bound (vCLUB) [8] for mutual information estimation and minimization.",
  "3.1 Statistical Interaction Graph Network (SIGN)": "The statistical interaction graph network (SIGN) [30] explicitly models feature interactions through a graph neural network. Given a set of features (e.g., user/item attributes) of each data sample, Z = { ğ‘§ 1 , ğ‘§ 2 , ..., ğ‘§ ğ‘› } , SIGN regards Z as a feature graph G(Z , E) , where Z is the node set that each feature ğ‘§ ğ‘– is a node, and E is the edge set containing all the combinations of pairwise feature interactions, with each feature interaction âŸ¨ ğ‘§ ğ‘– , ğ‘§ ğ‘— âŸ© being an edge linking to corresponding nodes. Accordingly, user representation learning becomes a graph learning problem. In SIGN, first, each feature ğ‘§ ğ‘– is mapped into a feature embedding ğ’› ğ‘– âˆˆ R ğ‘‘ of ğ‘‘ dimensions as the node embedding. The embeddings are first randomly initialized and are updated through training. Then, SIGN learns the graph representation (e.g., a vector) using a function ğ‘“ :  where ğœ™ and ğœ“ are aggregation functions (e.g., element-wise mean), â„ (Â·) : R 2 Ã— ğ‘‘ â†’ R ğ‘‘ is an MLP that models each feature interaction, ğ‘’ ğ‘– ğ‘— âˆˆ { 0 , 1 } is the edge indicator (since we use all pairwise feature interactions, ğ‘’ ğ‘– ğ‘— = 1 for all edges). ğ‘“ outputs the modeled graph representation ğ’– âˆˆ R ğ‘‘ of ğ‘‘ dimensions.",
  "3.2 Variational Contrastive Log-ratio Upper Bound (vCLUB) of Mutual Information": "Given a set of sample pairs {( ğ´ ğ‘– , ğµ ğ‘– )} ğ‘ ğ‘– = 1 drawn from an unknown distribution ğ‘ ( ğ´, ğµ ) of random variables ğ´ and ğµ . The vCLUB method [8] derives the upper bound of their mutual information I( ğ´, ğµ ) as:  where ğ‘ ( ğ´, ğµ ) is the joint distribution, ğ‘ ( ğ´ ) ğ‘ ( ğµ ) is the marginal distribution, ğ‘ ğœƒ ( ğ´ | ğµ ) is a variational distribution of parameter ğœ½ (e.g., an MLP) to predict ğ´ given ğµ . In an application of mutual information minimization, we aim to reduce the correlation between ğ´ ğ‘– and ğµ ğ‘– by selecting an optimal parameter ğˆ of the joint variational distribution ğ‘ ğœ ( ğ´, ğµ ) . vCLUB performs mutual information estimation and minimization in two steps iteratively. In the first step, to ensure Equation (1) holds as the upper bound, ğœ½ is trained to make the log-likelihood function L( ğ´, ğµ ) : = 1 ğ‘ Ë ğ‘ ğ‘– = 1 log ğ‘ ğœƒ ( ğ´ ğ‘– | ğµ ğ‘– ) maximized (Theorem 3.2 of [8]). In the second step, ğœ½ is frozen, and other parameters ( ğˆ ) are trained to minimize I vCLUB ( ğ´ ; ğµ ) so that the mutual information is minimized.",
  "4 Problem Statement and Definitions": "Let U , V , and C denote the user set, item set, and context set, respectively. Each user ğ‘¢ âˆˆ U consists a set of user features ğ‘¢ = { ğ‘§ ğ‘¢ 1 , ğ‘§ ğ‘¢ 2 , ..., ğ‘§ ğ‘¢ ğ‘ } (e.g., user ID, gender). Similarly, each item ğ‘£ âˆˆ V is represented by a set of item features ğ‘£ = { ğ‘§ ğ‘£ 1 , ğ‘§ ğ‘£ 2 , ..., ğ‘§ ğ‘£ ğ‘ } (e.g., branch, color). A context ğ‘ âˆˆ C is a set of context features ğ‘ = { ğ‘§ ğ‘ 1 , ğ‘§ ğ‘ 2 , ..., ğ‘§ ğ‘ ğ‘š } , denoting the context state when a user selects an item (e.g., weather, daytime). Let D be a dataset containing ğ‘ instances (i.e., data samples) of ( ğ‘¢, ğ‘£, ğ‘ ) , with a corresponding label ğ‘¦ âˆˆ { 1 , 0 } indicating whether or not the user ğ‘¢ selects the item ğ‘£ under the context ğ‘ . The recommendation task can be formulated as predicting the selection probability ğ‘¦ â€² = ğ‘ ( ğ‘¢, ğ‘£, ğ‘ ) . In our proposed IEDR model, the intrinsic factor ğ’ ğ‘–ğ‘› and the extrinsic factor ğ’ ğ‘’ğ‘¥ are explicitly inferred for both users and items, and jointly leveraged to perform the prediction. Next, we formally define intrinsic and extrinsic factors. We believe these two factors exist from both users' and items' perspectives. This is reasonable since a user selecting an item not only ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:7 relates to the factors (motivations) of users, e.g., prefer healthy food (intrinsic factor) on weekdays (extrinsic factor), but also relates to the factors (attractiveness) of items, e.g., the Caesar salad is healthy (intrinsic factor) and is chosen more often when the weather is hot (extrinsic factor). In the following, we define intrinsic and extrinsic factors from the users' perspective only, as they are similar from the items' perspective. Definition 1. ( Intrinsic Factor and Extrinsic Factor ) Consider a user ğ‘¢ and a set of contexts C ; an intrinsic factor of the user is a factor that is invariant to the contexts in C , i.e., ğ‘“ ğ‘–ğ‘› ( ğ‘¢, ğ‘ ) = ğ‘“ ğ‘–ğ‘› ( ğ‘¢, ğ‘ â€² ) , where ğ‘“ ğ‘–ğ‘› is a function learning intrinsic factor representations, and ğ‘ and ğ‘ â€² are two arbitrary contexts in C . On the other hand, an extrinsic factor of the user is a factor that is different from its corresponding intrinsic factor, i.e., I( ğ‘“ ğ‘–ğ‘› ( ğ‘¢, ğ‘ ) , ğ‘“ ğ‘’ğ‘¥ ( ğ‘¢, ğ‘ )) = 0 , where I computes the mutual information and ğ‘“ ğ‘’ğ‘¥ learns extrinsic factor representations. Also, the extrinsic factor changes w.r.t. the context, i.e., there exist contexts ğ‘ and ğ‘ â€² in C such that ğ‘“ ğ‘’ğ‘¥ ( ğ‘¢, ğ‘ ) â‰  ğ‘“ ğ‘’ğ‘¥ ( ğ‘¢, ğ‘ â€² ) . In the definition, ğ‘“ ğ‘–ğ‘› ( ğ‘¢, ğ‘ ) = ğ‘“ ğ‘–ğ‘› ( ğ‘¢, ğ‘ â€² ) shows the invariance of intrinsic factors.On the other hand, ğ‘“ ğ‘’ğ‘¥ ( ğ‘¢, ğ‘ ) â‰  ğ‘“ ğ‘’ğ‘¥ ( ğ‘¢, ğ‘ â€² ) shows that the extrinsic factors can be different if the contexts are different. In previous research (both in psychology [3, 35] and in recommender systems [13, 53]), intrinsic and extrinsic factors are considered all the factors influencing user behavior, and learning these two factors in a disentangled way has proven effective to analyze these behaviors [56]. Therefore, it leads to our factor learning objective based on Definition 1: leveraging the context-invariant property to ensure that ğ‘“ ğ‘–ğ‘› captures intrinsic factors, and disentangling the outputs of ğ‘“ ğ‘–ğ‘› ( ğ‘¢, ğ‘ ) and ğ‘“ ğ‘’ğ‘¥ ( ğ‘¢, ğ‘ ) to ensure ğ‘“ ğ‘’ğ‘¥ captures extrinsic factors (detailed in Section 5.2).",
  "5 Intrinsic-Extrinsic Disentangled Recommendation Model": "To effectively learn and disentangle intrinsic and extrinsic factors from various contexts, we propose our Intrinsic-Extrinsic Disentangled Recommendation (IEDR) Model. The overview of our model is visualized in Figure 2. More specifically, our proposed IEDR model consists of the following two modules, which will be detailed in the next subsections: Â· A recommendation prediction (RP) module that takes a user and an item as input, and combines them with a set of contexts, to generate intrinsic and extrinsic factor representations for both the user and the item. The predicted probability ğ‘¦ â€² is then jointly learned from these representations. Â· A contrastive intrinsic-extrinsic disentangling (CIED) module is applied to both the user and the item sides to support the intrinsic and extrinsic factor learning. The module contains a context-invariant contrastive learning component and a disentangling component, to ensure the learned factors satisfy Definition 1. For clarity and ease of understanding, Table 1 summarizes the key notations used throughout the IEDR model.",
  "5.1 Recommendation Prediction (RP) Module": "The recommendation prediction (RP) module is a symmetric structure that generates user intrinsic and extrinsic factor representations ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’ ğ‘¢ ğ‘’ğ‘¥ ) from the user side, and generates item intrinsic and extrinsic factor representations ( ğ’ ğ‘£ ğ‘–ğ‘› , ğ’ ğ‘£ ğ‘’ğ‘¥ ) from the item side. On the user side, we first generate a user representation and a context representation based on user features and context features, respectively. Here, we use the SIGN model [30] to generate the representations (see Section 3.1 for details). SIGN has been proven effective in user/item/context representation learning through modeling feature interactions via graph neural networks. More formally, let ğ‘“ ğ‘¢ ( ğ‘¢ ) : R ğ‘ Ã— ğ‘‘ â†’ R ğ‘‘ be the function for SIGN-based feature modeling, where ğ‘ is the number of user features. ğ‘“ ğ‘¢ ( ğ‘¢ ) first maps each user feature ğ‘§ ğ‘¢ ğ‘– âˆˆ ğ‘¢ into a ğ‘‘ -dimensional feature embedding ğ’› ğ‘¢ ğ‘– . Then, it models these feature ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:8 Su, et al. Table 1. Summary of notations used in the IEDR model. Fig. 2. An Overview of IEDR. It is a symmetric structure on the user side and the item side. The middle part (the black arrows) represents the recommendation prediction (RP) module (Section 5.1). It generates the intrinsic and extrinsic factor representations ( ğ’ ğ‘–ğ‘› and ğ’ ğ‘’ğ‘¥ ) for producing the recommendation prediction ğ‘¦ â€² . The side parts are two contrastive intrinsic-extrinsic disentangling (CIED) modules. Each CIED includes a context-invariant contrastive learning component (the red arrows, Section 5.2.1), and a disentangling component (the blue arrows, Section 5.2.2) to ensure the success of the factor learning. The losses generated through these modules ( L ğ‘…ğ‘ƒ , L ğ¶ğ¼ğ¶ğ¿ , L ğ‘ğ‘– -ğ‘ğ‘ğ‘ğ‘Ÿ , L ğ·ğ‘–ğ‘  ) will be optimized as a two-step multi-task training (Section 5.3.2). RP CIED (user side) CIED (item side) + ğ‘£ğ‘– ğ‘ğ‘– + ğ‘¢ğ‘– ğ‘ğ‘– ğ‘ ğ‘¢ 2 ğ‘“ ğ‘¢ ğ‘–ğ‘’ ğ‘“ ğ‘£ ğ‘–ğ‘’ ğ‘œ ğ‘¢ ğ‘–ğ‘› ğ‘œ ğ‘¢ ğ‘’ğ‘¥ ğ‘œ ğ‘£ ğ‘’ğ‘¥ ğ‘œ ğ‘£ ğ‘–ğ‘› îˆ¸ ğ‘¢ ğ¶ğ¼ğ¶ğ¿ îˆ¸ ğ‘¢ ğ‘ğ‘– - ğ‘ğ‘ğ‘ğ‘Ÿ îˆ¸ ğ‘¢ ğ·ğ‘–ğ‘  îˆ¸ ğ‘£ ğ¶ğ¼ğ¶ğ¿ îˆ¸ ğ‘£ ğ‘ğ‘– - ğ‘ğ‘ğ‘ğ‘Ÿ îˆ¸ ğ‘£ ğ·ğ‘–ğ‘  ğ‘¦ â€² ğ‘– Contrastive Learning Disentanglement Contrastive Learning Disentanglement + ğ‘£ğ‘– ğ‘ğ‘— + ğ‘£â„“ ğ‘ğ‘– ğ‘¦ğ‘– îˆ¸ ğ‘…ğ‘ƒ + ğ‘¢ğ‘– ğ‘ğ‘— + ğ‘¢â„“ ğ‘ğ‘– ğ‘ ğ‘¢ 1 ğ‘ ğ‘¢ 2 ğ‘ ğ‘¢ 2 ğ‘ ğ‘¢ 1 ğ‘ ğ‘¢ 1 ğ‘ ğ‘£ 1 ğ‘ ğ‘£ 1 ğ‘ ğ‘£ 1 ğ‘ ğ‘£ 2 ğ‘ ğ‘£ 2 ğ‘ ğ‘£ 2 ğ‘¢ğ‘– ğ‘ğ‘– ğ‘£ğ‘– User Side Item Side embeddings to output the user representation ğ’– . Similarly, SIGN learns context representation ğ’„ through ğ‘“ ğ‘ . Next, a factor generation function ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– , ğ’„ ) : R 2 Ã— ğ‘‘ â†’ R 2 Ã— ğ‘‘ (e.g., a neural network) takes the user representation and the context representation as input, and simultaneously generates a user intrinsic representation ğ’ ğ‘¢ ğ‘–ğ‘› and a user extrinsic representations ğ’ ğ‘¢ ğ‘’ğ‘¥ . Here, the output is a 2 ğ‘‘ -dimensional vector, with the first ğ‘‘ -dimensional terms as ğ’ ğ‘¢ ğ‘–ğ‘› and the rest as ğ’ ğ‘¢ ğ‘’ğ‘¥ . Note that without our CIED module (Section 5.2), ğ’ ğ‘¢ ğ‘–ğ‘› and ğ’ ğ‘¢ ğ‘’ğ‘¥ are entangled. Currently, we name them ğ’ ğ‘¢ ğ‘–ğ‘› and ğ’ ğ‘¢ ğ‘’ğ‘¥ to make it consistent with the following description. When equipped with CIED module, ğ’ ğ‘¢ ğ‘–ğ‘› and ğ’ ğ‘¢ ğ‘’ğ‘¥ will be disentangled and represent intrinsic and extrinsic factors respectively. On the item side, a similar module structure is adopted. We use a different SIGN-based function for the item representation learning ğ’— = ğ‘“ ğ‘£ ( ğ‘£ ) , while using the same context representation as that on the user side. A factor-generating function ğ‘“ ğ‘£ ğ‘–ğ‘’ ( ğ’— , ğ’„ ) is applied to obtain the item intrinsic factor representation ğ’ ğ‘£ ğ‘–ğ‘› and extrinsic factor representation ğ’ ğ‘£ ğ‘’ğ‘¥ . ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:9 Finally, we learn the prediction ğ‘¦ â€² = ğ‘“ ğ‘ğ‘Ÿğ‘’ğ‘‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’ ğ‘¢ ğ‘’ğ‘¥ , ğ’ ğ‘£ ğ‘–ğ‘› , ğ’ ğ‘£ ğ‘’ğ‘¥ ) . We linearly combine the learned factors and use the dot product as the prediction function: ğ‘“ ğ‘ğ‘Ÿğ‘’ğ‘‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’ ğ‘¢ ğ‘’ğ‘¥ , ğ’ ğ‘£ ğ‘–ğ‘› , ğ’ ğ‘£ ğ‘’ğ‘¥ ) = ( ğ’ ğ‘¢ ğ‘–ğ‘› + ğ’ ğ‘¢ ğ‘’ğ‘¥ ) âŠ¤ ( ğ’ ğ‘£ ğ‘–ğ‘› + ğ’ ğ‘£ ğ‘’ğ‘¥ ) . A cross-entropy loss function is adopted to minimize the prediction error: L RP ( ğ‘¢, ğ‘£, ğ‘ ) : = -ğ‘¦ log ( ğ‘¦ â€² ) + ( 1 -ğ‘¦ ) log ( 1 -ğ‘¦ â€² ) .",
  "5.2 Contrastive Intrinsic-Extrinsic Disentangling (CIED) Module": "The CIED module is designed to capture intrinsic and extrinsic factors from the representations generated by the RP module. The key idea is to integrate a context-invariant contrastive learning objective with a mutual information minimization scheme to simultaneously capture intrinsic factors that are stable across contexts and extrinsic factors that vary with different contextual conditions. Specifically, CIED consists of two interrelated components: (1) a context-invariant contrastive learning component that encourages the model to learn intrinsic factors by contrasting user representations across different contexts, and (2) a bidirectional disentangling component that further separates the extrinsic factors from the learned intrinsic factors via a bidirectional mutual information minimization scheme. Next, we describe the two components in detail. 5.2.1 Context-Invariant Contrastive Learning Component. The context-invariant contrastive learning component is designed to learn intrinsic representations that are invariant across different contexts. The core idea is to maximize the agreement between the intrinsic representation pairs generated from the same user under different contexts (positive pairs), while minimizing the agreement between those generated from different users under the same context (negative pairs). This contrastive objective encourages the model to capture the shared information across contexts as the intrinsic representation. More formally, we represent the intrinsic representations with the subscript ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘– ğ‘— if it is generated through user ğ‘¢ ğ‘– (from ğ‘– -th data sample) and context ğ‘ ğ‘— (from ğ‘— -th data sample), i.e., ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘– ğ‘— = ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– ğ‘– , ğ’„ ğ‘— ) . Inspired by InfoNCE [24], for the ğ‘– -th data sample ( ğ‘¢ ğ‘– , ğ‘£ ğ‘– , ğ‘ ğ‘– ) âˆˆ D , we calculate the objective function as follows:  where ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘– ğ‘— is generated from a user ğ‘¢ ğ‘– and an arbitrary context ğ‘ ğ‘— , sim (Â·) is the cosine similarity, and ğœ is a temperature value. The objective function is intuitive: one user should have the same intrinsic factor in different contexts, while different users can have their own personalized interests (different intrinsic factors). 5.2.2 Disentangling Component. To capture both the intrinsic and extrinsic factors, we need to disentangle extrinsic factors from intrinsic factors. The vCLUB method [8] can perform disentanglement through mutual information minimization. However, typical vCLUB is an asymmetric method, which may be less robust and lead to unsatisfactory disentanglement (detailed in Section 6.4). Therefore, we propose a bidirectional vCLUB approach that simultaneously minimizes the mutual information between intrinsic and extrinsic factors in both directions, leading to more robust and effective disentanglement. In the bidirectional vCLUB, two variational distributions (e.g., approximated via neural networks) ğ‘ ğ‘¢ 1 ( ğ’ ğ‘¢ ğ‘’ğ‘¥ | ğ’ ğ‘¢ ğ‘–ğ‘› ; ğœ½ ğ‘¢ 1 ) and ğ‘ ğ‘¢ 2 ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’ ğ‘¢ ğ‘’ğ‘¥ ; ğœ½ ğ‘¢ 2 ) are proposed with parameters ğœ½ ğ‘¢ 1 and ğœ½ ğ‘¢ 2 , to predict the two types of factors, respectively. Then a bidirectional vCLUB-based mutual information upper bound ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:10 Su, et al. can be obtained as: 1  By minimizing the upper bound I bi-vCLUB ( ğ’ ğ‘¢ ğ‘–ğ‘› ; ğ’ ğ‘¢ ğ‘’ğ‘¥ ) as above, we minimize the mutual information between ğ’ ğ‘¢ ğ‘–ğ‘› and ğ’ ğ‘¢ ğ‘’ğ‘¥ . Experimental results in Section 7.3.2 show that vCLUB is more robust and achieves better factor learning. The optimization of the disentangling component is conducted in two iteratively steps. In the first step, we estimate the upper bound by training ğœ½ ğ‘¢ 1 and ğœ½ ğ‘¢ 2 to minimize the loss function L ğ‘¢ ğ‘ğ‘– -ğ‘ğ‘ğ‘ğ‘Ÿ ( ğ‘¢ ğ‘– , ğ‘ ğ‘– ) : = -1 2 GLYPH<16> log ğ‘ ğ‘¢ 1 GLYPH<0> ( ğ’ ğ‘¢ ğ‘’ğ‘¥ ) ğ‘–ğ‘– | ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘–ğ‘– GLYPH<1> + log ğ‘ ğ‘¢ 2 GLYPH<0> ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘–ğ‘– | ( ğ’ ğ‘¢ ğ‘’ğ‘¥ ) ğ‘–ğ‘– GLYPH<1> GLYPH<17> . Following [8], we use the mean squared error to optimize ğ‘ ğ‘¢ 1 and ğ‘ ğ‘¢ 2 . In the second step, we freeze ğœ½ ğ‘¢ 1 and ğœ½ ğ‘¢ 2 , and minimize the mutual information of ğ’ ğ‘¢ ğ‘–ğ‘› and ğ’ ğ‘¢ ğ‘’ğ‘¥ by training other parameters to minimize the upper bound L ğ‘¢ ğ·ğ‘–ğ‘  ( ğ‘¢ ğ‘– , ğ‘ ğ‘– ) = I bi-vCLUB GLYPH<0> ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘–ğ‘– ; ( ğ’ ğ‘¢ ğ‘’ğ‘¥ ) ğ‘–ğ‘– GLYPH<1> . The context-invariant contrastive learning and disentanglement components in CIED are designed to work synergistically to learn meaningful intrinsic and extrinsic factors in the recommendation setting of various contexts. The contrastive learning component first learns context-invariant intrinsic factors by contrasting user representations across different contexts. These learned intrinsic factors then serve as a starting point for the disentanglement component to further separate the extrinsic factors via bidirectional mutual information minimization. The seamless integration of these two components is crucial for the effectiveness of IEDR. By first learning context-invariant factors and then disentangling them from the extrinsic factors, CIED can effectively capture the complex user behavior patterns influenced by various contextual conditions. Unlike existing methods, IEDR ensures context-agnostic learning of intrinsic and extrinsic factors in recommendations in scenarios of various contexts, and uniquely considers the interplay between these factors across various contexts, enhancing the model's effectiveness in complex, dynamic recommendation scenarios.",
  "5.3 Implementation Details": "5.3.1 Iterative Optimization Procedure. The CIED module is implemented as an iterative optimization procedure that alternates between the context-invariant contrastive learning and the disentanglement components. In each iteration, the contrastive learning component first updates the model parameters to learn context-invariant intrinsic factors. Specifically, for each user ğ‘¢ ğ‘– and context ğ‘ ğ‘– in the current batch, we generate a positive pair ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘– ğ‘— by either (1) randomly sampling a context ğ‘ ğ‘— from the same batch, or (2) applying a high dropout rate to the original context representation ğ‘ ğ‘– . We also generate ğ¿ negative pairs ( ğ’ ğ‘¢ ğ‘–ğ‘› ) â„“ğ‘– by randomly sampling ğ¿ users from the same batch. The contrastive loss L ğ‘¢ CICL ( ğ‘¢ ğ‘– , ğ‘ ğ‘– ) (Equation 2) is then computed and minimized to update the model parameters. The learned intrinsic factors ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘–ğ‘– are then fed into the disentangling component, which estimates and minimizes the mutual information between the intrinsic and extrinsic factors. We introduce two variational distributions ğ‘ 1 ğ‘¢ ( ğ’ ğ‘¢ ğ‘’ğ‘¥ | ğ’ ğ‘¢ ğ‘–ğ‘› ; ğœ½ 1 ğ‘¢ ) and ğ‘ 2 ğ‘¢ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’ ğ‘¢ ğ‘’ğ‘¥ ; ğœ½ ğ‘¢ 2 ) , parameterized by ğœ½ ğ‘¢ 1 and ğœ½ 2 ğ‘¢ , to estimate the bidirectional mutual information upper bound I bi-vCLUB ( ğ’ ğ‘¢ ğ‘–ğ‘› ; ğ’ ğ‘¢ ğ‘’ğ‘¥ ) (Equation 3). The disentangling component is optimized in a two-step procedure: (1) estimating the mutual information upper bound by optimizing ğœ½ 1 ğ‘¢ and ğœ½ 2 ğ‘¢ to minimize the loss L ğ‘ğ‘– -ğ‘ğ‘ğ‘ğ‘Ÿ ğ‘¢ ( ğ‘¢ ğ‘– , ğ‘ ğ‘– ) , 1 I bi-vCLUB ( ğ’ ğ‘¢ ğ‘–ğ‘› ; ğ’ ğ‘¢ ğ‘’ğ‘¥ ) is the average of two vCLUB-based upper bounds of different directions. Therefore, it is obvious that I bi-vCLUB ( ğ’ ğ‘¢ ğ‘–ğ‘› ; ğ’ ğ‘¢ ğ‘’ğ‘¥ ) is still an upper bound of I( ğ’ ğ‘¢ ğ‘–ğ‘› ; ğ’ ğ‘¢ ğ‘’ğ‘¥ ) . ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:11 and (2) minimizing the mutual information by optimizing the other parameters to minimize the upper bound L ğ·ğ‘–ğ‘  ğ‘¢ ( ğ‘¢ ğ‘– , ğ‘ ğ‘– ) . The updated extrinsic factors ( ğ’ ğ‘¢ ğ‘’ğ‘¥ ) ğ‘–ğ‘– are then used to refine the intrinsic factors in the next iteration of contrastive learning. This iterative process continues until convergence or a maximum number of iterations is reached. 5.3.2 Multi-task Training. Weperform a two-step multi-task training to minimize the empirical risk of multiple components in IEDR. The two steps run alternatively until convergence. Appendix B provides the pseudo-code of the training procedure. In the first step, we freeze all the parameters except for ğœ½ ğ‘¢ 1 , ğœ½ ğ‘¢ 2 , ğœ½ ğ‘£ 1 , and ğœ½ ğ‘£ 2 , where ğœ½ ğ‘£ 1 , ğœ½ ğ‘£ 2 are the parameters of ğ‘ ğ‘£ 1 ( ğ’ ğ‘£ ğ‘’ğ‘¥ | ğ’ ğ‘£ ğ‘–ğ‘› ; ğœ½ ğ‘£ 1 ) and ğ‘ ğ‘£ 2 ( ğ’ ğ‘£ ğ‘–ğ‘› | ğ’ ğ‘£ ğ‘’ğ‘¥ ; ğœ½ ğ‘£ 2 ) in the disentangling component on the item side. We then minimize R( ğœ½ ğ‘¢ 1 , ğœ½ ğ‘¢ 2 , ğœ½ ğ‘£ 1 , ğœ½ ğ‘£ 2 ) = 1 ğ‘ Ë ğ‘ ğ‘– = 1 GLYPH<0> L ğ‘¢ ğ‘ğ‘– -ğ‘ğ‘ğ‘ğ‘Ÿ ( ğ‘¢ ğ‘– , ğ‘ ğ‘– )+ GLYPH<1> L ğ‘£ ğ‘ğ‘– -ğ‘ğ‘ğ‘ğ‘Ÿ ( ğ‘£ ğ‘– , ğ‘ ğ‘– ) . In the second step, we freeze ğœ½ ğ‘¢ 1 , ğœ½ ğ‘¢ 2 , ğœ½ ğ‘£ 1 , and ğœ½ ğ‘£ 2 , and minimize the following function:  where L ğ‘£ ğ‘ğ‘– -ğ‘ğ‘ğ‘ğ‘Ÿ , L ğ‘£ CICL , and L ğ‘£ ğ·ğ‘–ğ‘  are the losses on the item side, ğœ† 1 and ğœ† 2 are the weight factors, and ğ are all the trainable parameters except for ğœ½ ğ‘¢ 1 , ğœ½ ğ‘¢ 2 , ğœ½ ğ‘£ 1 , and ğœ½ ğ‘£ 2 . The multi-task training procedure ensures that the model learns to accurately predict recommendations while simultaneously learning disentangled intrinsic and extrinsic factors. The contrastive learning and disentanglement losses are integrated into the overall training objective, allowing the model to capture the complex user behavior patterns influenced by various contextual conditions.",
  "6 Discussion": "In this section, we provide theoretical and practical discussions of IEDR from multiple perspectives, including the information theory foundation, time complexity analysis, trivial solution prevention, and potential problems of the vCLUB method used in the disentanglement component.",
  "6.1 Theoretical Analysis: Context-invariant Contrastive Learning in Information Theory": "In this section, we reason the context-invariant contrastive learning from the perspective of information theory. As formally defined in Theorem 1, optimizing Equation (2) is equivalent to maximizing the mutual information between the intrinsic representations and user representations, and simultaneously minimizing the mutual information between the intrinsic representations and the context representations. The theorem on the item side can be derived in the same fashion. The proof of this equivalence can be found in Appendix A. Theorem 1 (E/q.sc_u.scivalence of contrastive loss L ğ‘¢ CICL ). Optimizing the contrastive loss is equivalent to solving:  Theorem 1 provides the perspective from information theory to understand the context-invariant contrastive learning procedure: the information of users that is not influenced by contexts (i.e., intrinsic factors) is kept in ğ’ ğ‘¢ ğ‘–ğ‘› . ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:12 Su, et al.",
  "6.2 Time Complexity Analysis": "The time complexity of IEDR is comparable to feature interaction-based recommender systems (e.g., AutoInt [28], SIGN [30]). The overhead of the alternative optimizing procedure for the disentanglement component is marginal in the whole optimizing procedure. Specifically, the most time-consuming computations are the feature interaction learning to get user, item, and context representations, which need to conduct interaction modeling on every pair of feature interactions. This procedure has also been done on other feature interaction-based models. Therefore, the time complexity of the proposed module is comparable with those methods. Our model takes additional computations on the contrastive learning component (CICL) and the disentangling component: (1) For the CICL component, we do not need to perform the feature interaction modeling again, but reuse the generated user, item and context representations, which saves the majority of the overhead. We only need to perform ğ‘“ ğ‘–ğ‘’ ğ¿ + 1 times, where ğ¿ is the number of negative samples and ğ‘“ ğ‘–ğ‘’ is a one-hidden layer MLP. (2) For the disentangling component, we reuse the generated user/item/context representations as well. The first step in the two-step learning takes very little overhead. This is because this step only tries to optimize the parameters of the functions ğ‘ 1 and ğ‘ 2 (Equation (3)), which are two MLPs with one hidden layer. For each data sample, we only run ğ‘ 1 and ğ‘ 2 once using ğ’ ğ‘–ğ‘› and ğ’ ğ‘’ğ‘¥ . In summary, since all of the computations above do not need to perform feature interaction modeling (the most time-consuming procedure in all feature interaction-based models), the small imposed overhead is acceptable considering the effectiveness of our model in capturing accurate intrinsic and extrinsic factors. More empirical analysis can be found in Section 7.8.",
  "6.3 Preventing the Trivial Solution of CIED": "The two components in the CIED module, the contrastive learning component and the disentangling component, jointly ensure the success of the intrinsic and extrinsic factor representation learning. However, CIED may fall into a trivial solution: ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– , ğ’„ ) maps ğ‘¢ to ğ’ ğ‘¢ ğ‘–ğ‘› without considering ğ‘ , and maps ğ‘ to ğ’ ğ‘¢ ğ‘’ğ‘¥ without considering ğ‘¢ . Although this trivial solution minimizes L CICL ( ğ‘¢, ğ‘ ) and L ğ·ğ‘–ğ‘  ( ğ‘¢, ğ‘ ) , ğ’ ğ‘¢ ğ‘–ğ‘› (resp. ğ’ ğ‘¢ ğ‘’ğ‘¥ ) is not the intrinsic (resp. extrinsic) factor, but just a mapping of the user information (resp. context information). We prove that this trivial solution can be avoided by setting ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– , ğ’„ ) as a non-linear function, leading ğ’– and ğ’„ to statistically interact. 6.3.1 Statistical Interaction. We first introduce the statistical interaction (or non-additive interaction), which ensures a joint influence of several variables on an output variable is not additive [34]. Based on [29], ğ¹ ( ğ‘¿ ) shows statistical interaction between variables ğ‘¥ ğ‘– and ğ‘¥ ğ‘— if âˆ€ ğ‘“ \\ ğ‘– , ğ‘“ \\ ğ‘— , ğ¹ ( ğ‘¿ ) cannot be expressed as:  More generally, if using ğ’— ğ‘– âˆˆ R ğ‘‘ to describe the ğ‘– -th variable with a ğ‘‘ -dimension vector [25, 30], e.g., variable embedding, each variable can be described in a vector form ğ’– ğ‘– = ğ‘¥ ğ‘– ğ’— ğ‘– . Then, we define the pairwise statistical interaction in vector form by changing the Equation (5) into:  6.3.2 Preventing the Trivial Solution. Based on the definition of statistical interaction, we can express the trivial solution as that ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– , ğ’„ ) learns no statistical interaction between ğ’– and ğ’„ :  where ğ‘“ 1 outputs ğ’ ğ‘¢ ğ‘–ğ‘› , ğ‘“ 2 outputs ğ’ ğ‘¢ ğ‘’ğ‘¥ , and ğœ† are weight scalars. ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:13 To prevent the trivial solution, we need to ensure that function ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– , ğ’„ ) cannot be modeled in the form of Equation (6). Therefore, if ğ’– and ğ’„ are modeled as a statistical interaction in ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– , ğ’„ ) , the trivial solution can be prevented. Since ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– , ğ’„ ) only takes ğ’– and ğ’„ as inputs, we just need ğ‘“ ğ‘¢ ğ‘–ğ‘’ to be a non-additive model. That is, ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– , ğ’„ ) should contain a third term ğ‘“ 3 ( ğ’– , ğ’„ ) :  where ğ‘“ 3 is a non-additive model and ğœ† 3 â‰  0. Therefore, in the optimized situation, ğ’ ğ‘¢ ğ‘–ğ‘› = ğœ† 1 ğ‘“ 1 ( ğ’– ) learns part of the information from users that do not interact with context information. ğ’ ğ‘¢ ğ‘’ğ‘¥ = ğœ† 2 ğ‘“ 2 ( ğ’„ ) + ğœ† 3 ğ‘“ 3 ( ğ’– , ğ’„ ) learns the context information ( ğ‘“ 2 ( ğ’„ ) ) and the information that changes given different contexts ( ğ‘“ 3 ( ğ’– , ğ’„ ) ). In Section 7.9, we empirically analyze how the trivial solution will influence the prediction performance.",
  "6.4 Potential Problems of the Asymmetric vCLUB Method": "The vCLUB-based mutual information minimization method proposed in [8] is an asymmetric method. In this section, we explain the possible reason that vCLUB is less robust and performs worse than our proposed bidirectional vCLUB method ( BiDis ). Directly applying vCLUB leads to the parameter ğœ½ ğ‘¢ 1 of a variational distribution ğ‘ ğ‘¢ 1 ( ğ’ ğ‘¢ ğ‘’ğ‘¥ | ğ’ ğ‘¢ ğ‘–ğ‘› ; ğœ½ ğ‘¢ 1 ) being trained to approach the vCLUB-based upper bound in Equation (1) (Step 1). Then, ğœ½ ğ‘¢ 1 is frozen, and ğ’ ğ‘¢ ğ‘’ğ‘¥ , ğ’ ğ‘¢ ğ‘–ğ‘› are trained to minimize I( ğ’ ğ‘¢ ğ‘–ğ‘› ; ğ’ ğ‘¢ ğ‘’ğ‘¥ ) via minimizing the upper bound I vCLUB ( ğ’ ğ‘¢ ğ‘–ğ‘› ; ğ’ ğ‘¢ ğ‘’ğ‘¥ ) (Step 2). However, this way of minimizing mutual information may result in an unexpected outcome: the mutual information may be minimized via making ğ’ ğ‘¢ ğ‘–ğ‘› contain as little information as possible. To better illustrate the possible outcome, we design ğ‘ ğ‘¢ 1 as a linear function which is well trained in Step 1 to ensure Equation (1) is an upper bound of I( ğ’ ğ‘¢ ğ‘–ğ‘› ; ğ’ ğ‘¢ ğ‘’ğ‘¥ ) . Figure 3 shows how the unexpected result may occur. In Step 2, ğ’ ğ‘¢ ğ‘’ğ‘¥ , ğ’ ğ‘¢ ğ‘–ğ‘› will be trained to minimize Equation (1). To achieve this goal, it ensures ğ‘ ğ‘¢ 1 cannot predict ğ’ ğ‘¢ ğ‘’ğ‘¥ given the corresponding ğ’ ğ‘¢ ğ‘–ğ‘› from the joint distribution (the first term of Equation (1)), and at the same time ensures the output of ğ‘ ğ‘¢ 1 is similar to the other ğ’ ğ‘¢ ğ‘’ğ‘¥ 's from the marginal distribution (the second term of Equation (1)). From ğ’ ğ‘¢ ğ‘–ğ‘› perspective (blue circles), the goal can be achieved by pushing the ğ’ ğ‘¢ ğ‘–ğ‘› to move from its original position (optimizing the first term of Equation (1)), and move towards the mean of the other ğ’ ğ‘¢ ğ‘–ğ‘› 's (optimizing the second term of Equation (1)). From ğ’ ğ‘¢ ğ‘’ğ‘¥ perspective (red circles), the goal can be achieved by pushing the ğ’ ğ‘¢ ğ‘’ğ‘¥ away from its original position (optimizing the first term of Equation (1)) and the mean of the other ğ’ ğ‘¢ ğ‘’ğ‘¥ 's (optimizing the second term of Equation (1)). This clusters all the ğ’ ğ‘¢ ğ‘–ğ‘› 's together, making ğ’ ğ‘¢ ğ‘–ğ‘› 's contain less information, while all the ğ’ ğ‘¢ ğ‘’ğ‘¥ 's try to split away from each other, making ğ’ ğ‘¢ ğ‘’ğ‘¥ 's contain more information. The mutual information minimization procedure is like 'transferring' the information from ğ’ ğ‘¢ ğ‘–ğ‘› 's to ğ’ ğ‘¢ ğ‘’ğ‘¥ 's, which is not what we expect. BiDis , however, is a symmetric disentangling method on ğ’ ğ‘¢ ğ‘–ğ‘› 's and ğ’ ğ‘¢ ğ‘’ğ‘¥ 's that does not result in this issue. This may be why vCLUB performs worse and is less robust than our proposed symmetrical disentangling component.",
  "7 Experiments": "We conduct extensive experiments to demonstrate the effectiveness of our model. In this section, we focus on 1) the recommendation performance of IEDR compared to the state-of-the-art methods; 2) the effectiveness of each component in IEDR; and 3) the ability to disentangle intrinsic and extrinsic factors of IEDR. ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:14 Su, et al. Fig. 3. An illustrative example demonstrating the potential problem of asymmetric learning in vCLUB. The blue circles are intrinsic representations, and the red circles are extrinsic representations. The dotted arrows are the directions that vCLUB will push ğ’ ğ‘¢ ğ‘–ğ‘› and ğ’ ğ‘¢ ğ‘’ğ‘¥ to move toward their space. ğ‘ ğ‘¢ 1 (fixed) ğ‘œ ğ‘¢ ğ‘–ğ‘› ğ‘œ ğ‘¢ ğ‘’ğ‘¥ Training Direction Training Direction",
  "7.1 Experimental Setting": "This section demonstrates the detailed experimental setting to evaluate our method, including the datasets, the baseline methods, and the implementation details. 7.1.1 Datasets. We evaluate our models in two scenarios with various contexts: a mobile app recommendation and a restaurant recommendation. In the mobile app recommendation, we use the Frappe [1] dataset that records mobile app usage logs. Each data sample logs users' app usage in a certain context (e.g., weather, time, location). In the restaurant recommendation, we use the Yelp dataset [43]. Each data sample records users' reviews of local restaurants. Due to the fact that a user usually goes to restaurants in the same city, geographic isolation appears in the dataset. Therefore, we select the records in New York City. We regard each record as a data sample that the user has been to the restaurant. We leverage the user/item features and context features (e.g., day of the week) to predict whether a user will go to a given restaurant in a specific context. We also evaluate our model on two Amazon datasets (Movies and CDs) [22], which have been used in sequential recommendation tasks [53]. The datasets contain user-item interactions with timestamps. For the sequential recommendation, we use the same IEDR model structure as that for the Frappe and Yelp datasets, but modify the data input to fit our model. More specifically, we do not directly learn behavior sequences, but consider each behavior as a data sample with time context information. That is, we consider the bucketed timestamp of each user behavior as a time context (we consider one month as a categorized time context). Therefore, behaviors in the same time interval have the same time context, indicating that these behaviors share some similar short-term (extrinsic) interests (e.g., item popularity). Note that our experiments are to evaluate our key motivation: learning better intrinsic/extrinsic factor representations. Therefore, our chosen four datasets have high-quality user feedback (e.g., review/comment-based), which is more suitable than other datasets that are larger but less accurate (e.g., click-through-based). For each dataset, the users that have more than 5 records (Frappe and Yelp) or more than 20 records (Movies and CDs) are chosen. We use the last and the second last record of each user for testing validation, respectively. The rest are for training. Each of these data samples is considered a positive sample ( ğ‘¦ = 1). For each positive data sample in the training set, we randomly sample 2 items (but keep the user and contexts) as negative samples ( ğ‘¦ = 0), meaning the user did not select the 2 items in that context. For each test/validation data sample, we randomly choose 99 items as negative samples to ensure a more robust evaluation. The statistics of the datasets are shown in Table 2. 7.1.2 Baseline methods. IEDR models the feature interactions of users, items, and contexts. Therefore, we compare our model with competitive feature interaction-based recommendation methods. ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:15 Table 2. Dataset statistics. 'Count' refers to the number of users/items, and 'Features' represents the number of different features (for User and Item, the number of features excludes the user/item IDs). Table 3. Comparing the prediction performance (in percentage) with the baselines. The best-performing results are in bold and the second best are underlined. The Improv and p-value rows show the relative improvements and the statistical significance of IEDR over the best-performed baselines, respectively. The methods include attentional factorization machine (AFM) [46], neural factorization machine (NFM) [12], self-attention-based feature interaction model (AutoInt) [28], deep factorization machine (DeepFM) [11], wide & deep model (WDL) [7], improved deep & cross network (DCNv2) [40], input-aware factorization machine (IFM) [52], model-agnostic contrastive learning for CTR (CL4CTR) [37], and adaptive learning via Euler's formula (EulerNet) [33]. We implement these methods using the DeepCTR package or their officially released code. The above methods model all the factors in a unified representation without considering the factors that affect user behavior. Meanwhile, we compare IEDR with the methods that learn implicit factors. They are disentangled variational auto-encoder for recommendation (DisRec) [21] and disentangled graph collaborative filtering (DGCF) [42]. We implement these methods based on their released code. Note that since DisRec and DGCF models do not consider any feature, their task is to simply predict whether a user will select an item. IERD and other baseline models, however, consider the user-item interactions in specific contexts (a user's behavior in selecting an item may be different in different contexts). For DisRec and DGCF, to prevent the test data samples from appearing in the training set, we remove the data samples from the training set that appear in the test set (with different contexts in other models). For a fair comparison, we set the factor number to 4 for DisRec and DGCF. For sequential recommendation baselines, we compare our model with the models that consider LS-term ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:16 Su, et al. interests. They are session-based recommender systems with recurrent neural networks (GRU4Rec) [13], Short-term and Long-term preference Integrated Recommender system (SLI-Rec) [53], and Contrastive learning framework of Long and Short-term interests for Recommendation (CLSR) [56]. We use the same MLP structure for feature interaction modeling and the same embedding size for features as our IEDR model. 7.1.3 Implementation details. In IEDR, all the MLPs have the same hidden structure: one hidden layer of 128 dimensions and a ReLU activation after that. The input and output sizes of MLPs vary based on their needs. We set the embedding dimension to 32 for all the features. ğ‘“ ğ‘–ğ‘’ is an MLP that outputs a 64-dimension vector, with the first 32 dimensions being the intrinsic factor representation and the last 32 dimensions being the extrinsic factor representation. For the second (dropout-based) negative context-generating method in the context-invariant contrastive learning component, the dropout rate is set to 0.5. The number of negative pairs for contrastive learning is 40 for each data sample (note that the actual negative pairs will be doubled since both ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘–ğ‘– and ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘– ğ‘— will generate 40 negative pairs). The temperature ğœ is set to 0.5. In the disentangling component, ğ‘ 1 and ğ‘ 2 are MLPs that output vectors that have the same dimension of intrinsic/extrinsic factor representations. The number of negative samples of the bidirectional vCLUB-based method is 5 for each direction. We set ğœ† 1 to 0.1 for the Frappe dataset and 0.01 for the Yelp dataset, and set ğœ† 2 to 0.1 for both datasets. The ğœ† 1 and ğœ† 2 are both 0.01 for the Movies and the CDs datasets. The model structure of IEDR and its variations used in the experiments are detailed in Table 10 and Table 11. Note that the component structures of variations are the same as the IEDR if not specified.",
  "7.2 Overall Performance": "We evaluate the recommendation performance of our model, by comparing it with various baselines in two scenarios. In the first scenario, we learn intrinsic and extrinsic factors from various contexts. In the second scenario, we learn the factors from a specific (time) context and compare our model with sequential recommendation baselines. We use three common evaluation metrics for recommender systems: NDCG@ ğ‘˜ , Recall@ ğ‘˜ with ğ‘˜ being 5 and 10, and AUC. 7.2.1 Factor Learning from Specific Context. We then evaluate IEDR on two Amazon datasets (Movies and CDs) [22] that contain only the time context. We compare with the state-of-the-art sequential recommendation baselines GRU4Rec [13], LSI-Rec [53], CLSR [56] and AutoMLP [18], that learn long-short term interests from the item sequences ordered by the time (discussed in Section 2). Also, we compare with state-of-the-art general sequential recommendation baselines, BERT4Rec [32], SASRec [15], S3Rec [57], TiSASRec [38]. In IEDR, we use the same model structure as that for the Frappe and Yelp datasets, but modify the data input to fit our model. More specifically, without directly learning behavior sequences, IEDR considers each behavior as a data sample with time context information, where the time context is the bucketed timestamp of each user behavior (one month as a categorized time context). We also run the best-performing baselines from Table 3 on the Amazon datasets. The experimental results are reported in Table 4. From these results, we can see that our model achieves competitive accuracy compared to the sequential recommendation baselines. This proves the ability of our model to achieve state-of-theart recommendation accuracy in the context-specific scenario, even compared with the models designed for the context. Moreover, our IEDR is more versatile and can be applied to various contexts. Finally, the feature interaction-based baselines do not disentangle intrinsic and extrinsic factors. Therefore, they perform worse than our models and sequential recommendation baselines on the Amazon datasets. ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:17 Table 4. Comparing the performance of IEDR and the baselines on time context-specific scenarios.",
  "7.3 Effectiveness of Our Model's Components": "This section evaluates the components of IEDR. We only demonstrate the results in NDCG@10 since metrics show similar trends. 7.3.1 Ablation Study of Contrastive Intrinsic-Extrinsic Disentangling Module. To evaluate the contribution of the Contrastive Intrinsic-Extrinsic Disentangling (CIED) module, we compare IEDR against three variants: noDis (removes the disentanglement component), noCL (removes the contextinvariant contrastive learning component), and noCIED (removes both components). The experiments are conducted on the Frappe and Yelp datasets, and the results are presented in Figure 4. The results highlight the synergistic contribution of the two components in IEDR. 1) IEDR achieves the best performance on both datasets (74.11 on Frappe and 53.05 on Yelp), with improvements over noCIED of 4.06 points on Frappe and 2.99 points on Yelp, exceeding the combined individual improvements of noDis and noCL . This indicates a cumulative effect, where the disentanglement component and CICL reinforce each other, ensuring stable intrinsic factors and effective separation of extrinsic factors. 2) The small improvement of noCL over noCIED on Frappe (0.16 points) highlights the limitations of relying solely on implicit factor disentanglement, particularly in datasets dominated by context features. These findings emphasize the importance of explicit factor learning through CICL, which ensures robust disentanglement and overall performance gains. 7.3.2 Disentangling Component Evaluation. Wepropose a bidirectional vCLUB-based disentangling method ( BiDis ) to disentangle the intrinsic and extrinsic factors. In this section, we compare our BiDis method with the original vCLUB method ( vCLUB ) [8] in model performance. The results in Figure 5 highlight the superiority of our BiDis method over vCLUB in both performance and robustness. BiDis leverages bidirectional mutual information minimization, ensuring a more thorough and balanced disentanglement of intrinsic and extrinsic factors, as discussed in Section 5.2.2. This bidirectional approach avoids the instability and noise issues associated with vCLUB's asymmetric optimization, resulting in more robust and consistent performance across datasets. Additionally, the visualization in Section 7.5.1 further demonstrates that BiDis produces clearer and more distinct factor separation, underscoring its effectiveness in real-world recommendation scenarios. ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:18 Su, et al. Fig. 4. Ablation studies results with different component(s) removed. IEDR noDis noCL noCIED 70 72 74 Components NDCG@10 Frappe IEDR noDis noCL noCIED 51 52 53 Components Yelp Fig. 5. The performance and variance statistics of vCLUB and BiDis. vCLUB BiDis 70 72 74 Disentangling method NDCG@10 Frappe vCLUB BiDis 50 51 52 53 Disentangling method Yelp 7.3.3 Other Feature Modeling Methods. In the RP module, although we use a SIGN-based method [30] to learn user, item, and context features, the module can use any feature modeling method. Here, we use other methods to evaluate whether our model still performs well. Specifically, we run our model with the other three variations using different feature modeling methods: 1) averaging feature embeddings ( MEAN ); 2) adding an MLP on top of the averaged feature embedding ( MLP ); and 3) modeling and aggregating feature interactions through a Bi-interaction layer proposed in [12] ( BI ). The results are shown in Figure 6. We report the results of each variation with and without the Fig. 6. Model performance when equipped with different feature modeling methods. SIGN AVG MLP BI 66 68 70 72 74 Feature method NDCG@10 Frappe w CIED w/o CIED SIGN AVG MLP BI 50 52 54 Feature method Yelp w CIED w/o CIED ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:19 Table 5. Comparing the performance of IEDR ğ‘ ğ‘ with different dropout rates (for NegGen2 ). CIED module. From this figure, we can see that when equipped with the CIED module, all feature modeling methods perform better than those without the module. It shows that our proposed CIED module can learn intrinsic and extrinsic factors for more accurate recommendations when different feature modeling methods are applied. Meanwhile, the feature modeling methods can impact the performance. MEAN is just a linear aggregation of features, resulting in the worst performance. Both MLP and BI have better feature modeling ability and hence have better performance than MEAN . The SIGN-based feature modeling ( SIGN ) is the state-of-the-art feature interaction modeling method and archives the best performance.",
  "7.4 Comparing the Impact of Different Contrastive Learning Variations": "To learn intrinsic factors, we propose a context-invariant contrastive learning method. However, directly generating intrinsic factor representations through user information seems to be a more direct way, i.e., ğ’ ğ‘¢ ğ‘–ğ‘› = ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– ) . However, we argue that the intrinsic factors learned this way could not guarantee the effectiveness of intrinsic factor learning. This is because the information in the learned intrinsic factor representations can vary with different contexts, since these factors have never been modeled w.r.t. the contexts. In this section, we empirically evaluate our argument and show that our context-invariant contrastive learning method generates more accurate recommendations. To do so, we design a variation (IEDR ğ‘ ğ‘ ) by splitting the intrinsic-extrinsic factor generation into two functions: ğ’ ğ‘¢ ğ‘–ğ‘› = ğ‘“ ğ‘¢ ğ‘–ğ‘› ( ğ’– ) , and ğ’ ğ‘¢ ğ‘’ğ‘¥ = ğ‘“ ğ‘¢ ğ‘’ğ‘¥ ( ğ’– , ğ’„ ) . Both ğ‘“ ğ‘–ğ‘› and ğ‘“ ğ‘’ğ‘¥ have the same structure as ğ‘“ ğ‘–ğ‘’ , with the output dimension being a half to ensure the consistency of the factor representation dimension. The contrastive learning component does not consider context information but uses a standard InfoNCE-based contrastive learning for learning robust user/item representations following [48]. Table 5 illustrates the results of IEDR ğ‘ ğ‘ compared to our model with IEDR ğ‘ ğ‘ using different dropout rates ( ğ‘ = 0 . 1 and ğ‘ = 0 . 5) in the contrastive learning component, and different component combinations ( noDis , noCL , noCIED ). The experiment demonstrates that our model outperforms the variation in recommendation accuracy. This proves that IEDR ğ‘ ğ‘ cannot ensure successful intrinsic factor learning and hence incurs a worse recommendation accuracy. Unlike IEDR, IEDR ğ‘ ğ‘ gains better performance with a lower dropout rate. This is because, in IEDR ğ‘ ğ‘ , the dropout generates views representing the same user instead of different users, which is consistent with the conclusion in [10].",
  "7.5 Disentanglement Verification": "This section verifies the intrinsic and extrinsic factor disentangling ability of IEDR, including a visualization of the learned intrinsic and extrinsic representations and a case study to show the differences between these factors in users' decision-making. ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:20 Su, et al. Table 6. Items (in category) of the highest intrinsic and extrinsic scores for different users in Weekday. 7.5.1 Intrinsic and Extrinsic Representation Visualization. This section provides intrinsic and extrinsic representation visualizations of our model and three variations: 1) the contrastive learning component is removed ( noCL ); 2) the disentangling component is removed ( noDis ); and 3) the asymmetric disentanglement method ( vCLUB ) is used. Figure 7 compares these results. We include our main observations below: Â· The intrinsic and extrinsic factors are perfectly disentangled with our CIED module ( IEDR ). Â· Without the disentangling component ( noDis ), the intrinsic and extrinsic disentangling procedure may not succeed. This is because there is no restriction on extrinsic representations. Therefore, the extrinsic representations can contain any information, including the information of the intrinsic factor. Â· noCL has worse disentangling performance than IEDR , either. This is because the factors disentangled in noCL are implicit. The implicit factors only ensure the disentanglement between the factors of the same data sample, but not between the factors of other data samples. For example, some context information may be stored in the intrinsic representation in data sample 1 but be stored in the extrinsic representation in data sample 2. Â· noCIED performs worst among all variations, which is reasonable since it does not distinguish the intrinsic and extrinsic representations. Â· vCLUB performs disentanglement, but is not very stable in some situations. This is consistent with our analysis in Section 6.4. 7.5.2 Case Study. We conducted a case study to analyze the differences between the learned intrinsic and extrinsic factors. We randomly choose a user from the Frappe dataset and generate the intrinsic matching scores (the dot product of the user's intrinsic representation and the items' (apps) intrinsic representations) in two different contexts (Weekday and Weekend). The same for the extrinsic matching scores. We sort the matching scores for the intrinsic and extrinsic factors, respectively, and list the top 100 items. The results are in Figure 8. Note that the top 100 items for intrinsic and extrinsic factors are different. According to Figure 8, from weekday to weekend, the extrinsic scores vary a lot, while the intrinsic scores remain invariant. These observations demonstrate that, in different contexts, the user has different intrinsic factors, as well as consistent intrinsic factors. ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:21 Fig. 7. The complete intrinsic-extrinsic disentanglement visualizations in t-SNE. The blue dots are intrinsic representations, and the red dots are extrinsic representations. User Item Frappe IEDR User Item User Item Frappe noCL User Item Frappe noCIED User Item Frappe vCLUB User Item Yelp IEDR User Item Yelp noDis User Item Yelp noCL User Item Yelp noCIED User Item Yelp vCLUB Frappe noDis Fig. 8. A user's top 100 intrinsic and extrinsic scores in different contexts (Weekend vs. Weekday). 0 20 40 60 80 100 Items 20 30 40 50 60 70 80 90 Score Intrinsic Weekend Intrinsic Weekday Extrinsic Weekend Extrinsic Weekday Then, we show how intrinsic and extrinsic factors may have different impacts on users' choices. Table 6 lists the categories of the items with the 10 highest intrinsic/extrinsic scores for two users, respectively. we can observe that users have individual intrinsic interests that indicate their real ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:22 Su, et al. hobbits, e.g., User1 prefers sports and fitness apps, while User2 prefers gaming apps. On the other hand, extrinsic factors give a higher rank to the items based on the contexts (Weekday), e.g., Tools (Google Search) and Communication (Gmail) rank highest in User1 's extrinsic scores.",
  "7.6 Different Negative Context Generation Methods": "Table 7. Comparing the performance of IEDR using different negative context generating methods (for the contrastive learning component). We propose two negative context-generating methods in the contrastive learning component: 1) sample other contexts; 2) use a large dropout rate on the original context. We evaluate the two methods in this section. Table 7 shows the results of our model when using only NegGens1 , only NegGens2 , and NegGen1&2 . We can see that NegGen1 results in a better performance than using NegGen2 . This is because NegGen1 uses true context representations, which are consistent with what may appear in the test samples. Meanwhile, we see that NegGen1&2 results in the best performance. This is because NegGen2 provides more unseen (randomly generated) context representations, which strengthens the generalization ability of our model. Next, we evaluate NegGen2 with different dropout rates in Figure 9. The best performance can be achieved when the dropout rates range from 0.5 to 0.7. This is consistent with our claim in Section 5.2.1. The reason is that a small dropout rate (e.g., 0.1) pushes the generated context representation too close to the original one; hence it cannot be considered a different context. However, a relatively large dropout rate (e.g., 0.9) loses too much information; hence, it is no longer a valid context representation. In addition, for NegGen1&2 of all the dropout rates, the results consistently outperform those that only use NegGen2 . Fig. 9. The performance of different dropout rates for method 2 ( NegGen2 ). 0.1 0.3 0.5 0.7 0.9 70 75 80 85 Dropout Rate Frappe NegGen2 NegGen1&2 0.1 0.3 0.5 0.7 0.9 50 52 54 56 Dropout Rate Yelp NegGen2 NegGen1&2",
  "7.7 Effectiveness of Model Hyperparameters": "We evaluate our model with different hyperparameter settings, including embedding dimensions, number of negative samples, and loss weight values. Below, we summarize our observations. ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:23 7.7.1 Embedding Dimension. We run our model with different feature embedding dimensions. The results are in Figure 10. The embedding dimension poses a trade-off between the expression ability and efficiency. From the figure, we can see that larger dimensions result in better recommendation accuracy. However, the improvement is not significant when the dimension is larger than 32. A larger dimension may even reduce the performance due to the overfitting problem (e.g., dimension 256 for the Frappe dataset). Fig. 10. The performance of different embedding dimensions. 8 32 64 128 256 66 68 70 72 74 Embedding dimension Frappe 8 32 64 128 256 50 52 Embedding dimension Yelp 7.7.2 The Number of Negative Sample and Loss Weight. The contrastive learning and disentangling components are both contrastive-based methods that require negative sampling. This section evaluates how the number of negative samples influences performance. We also compare the influence of different loss weights of the two components. We run our model with different negative sample numbers and loss weights for the two components, respectively. From Figure 11, we can see that a large loss weight, or a large number of negative samples does not necessarily result in a better performance. Both components should be fine tuned to generate the best outcome. Generally, a very large or small loss weight may make the multi-task training unbalanced, harming the final performance. For the number of negative samples, a small number will make contrastive learning insufficient, while a large number may cause overfitting. Fig. 11. The performance of different numbers of negative samples and the loss weights in the risk minimization function for the contrastive learning component (left) and the disentangling component (right), respectively. 0.001 0.01 0.1 1 10 1 1 10 40 80 160 Negative Samples 66.73 68.16 71.98 66.42 58.91 68.31 69.76 73.59 67.02 59.42 69.58 70.1 74.11 69.42 60.71 68.49 69.29 73.97 68.29 60.35 68.03 68.89 73.92 68.07 61.05 0.001 0.01 0.1 1 10 2 1 5 10 40 80 71.81 72.55 73.35 72.23 67.56 71.2 72.85 74.11 72.06 67.28 70.08 72.54 73.43 72.19 67.82 72.19 72.85 73.96 72.87 67.76 71.94 73.49 73.71 72.46 67.99 60 65 70 ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:24 Su, et al. Table 8. The overall time consumption of different models in one batch training. Table 9. The time consumption of critical procedures in IEDR in one batch training.",
  "7.8 Empirical Analysis of Time Complexity": "We summarize the overall time consumption of IEDR and several feature interaction-based baseline models in Table 8. The results are recorded by running the models for one batch (batch size 1024) on the Frappe dataset on a machine with CPU:12th Gen Intel(R) Core(TM) i9-12900K, RAM: 32GB, GPU: NVIDIA GeForce RTX 3090. We can see that our model's overall time consumption is only slightly higher than the other baselines. Next, we summarize the time cost of critical procedures in IEDR in Table 9. The first four rows are model forwarding procedures, and the last two rows are model (alternative) optimizing procedures. Table 9 shows the feature interaction modeling procedure takes most of the time, which is consistent with our analysis in Section 6.2. CICL and disentangling forward procedures (rows 2-4) do not pose a large overhead since they reuse the feature interaction modeling results. Optimization (step 1) updates the parameters of the model's disentangling component ( ğ‘ 1 and ğ‘ 2 ), which produces little overhead (2.21 ms) and is negligible in the whole procedure.",
  "7.9 Empirical Analysis of Falling Into Trivial Solutions": "As discussed in Section 6.3, our model may fall into a trivial solution if ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– , ğ’„ ) is a linear mapping method. To evaluate how the trivial solution influences our model in learning the factors, we run our model with ğ‘“ ğ‘–ğ‘’ being linear. Specifically, we concatenate ğ’– and ğ’„ and feed them into an MLP without a hidden layer or activation (a linear mapping), making it easy to fall into the trivial solution. We call this variation Linear . Then, we avoid this by simply adding a nonlinear activation function (ReLU) activation after the linear mapping. We call this variation Nonlinear . Figure 12 shows the weight values of ğ‘“ ğ‘–ğ‘’ of the two variations. The color shows the weights mapping from user/context representations to intrinsic/extrinsic representations. The darker the color, the larger the weight (the more information of user/context is mapped into intrinsic/extrinsic representations). The figure shows that in the Linear variation, user information is largely mapped into intrinsic representation (user-intrinsic block) but not extrinsic representation (user-extrinsic block). Context information is largely mapped into extrinsic representation (context-extrinsic block) but not intrinsic representation (context-intrinsic block). This means that the Linear variation falls ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:25 Fig. 12. Visualization of ğ‘“ ğ‘–ğ‘’ weights for the Linear and Nonlinear models. Intrinsic Extrinsic User Context Linear Intrinsic Extrinsic User Context Nonlinear into the trivial solution. On the contrary, in the Nonlinear variation, user information is mapped into extrinsic representation (user-extrinsic block), showing that the extrinsic representation contains both user and context information. Figure 13 shows the performance of the two variations. We can see that the Linear model performs worse than the Nonlinear model. It proves that learning intrinsic and extrinsic factors results in a better performance than simply mapping user and context information into two representations, respectively (the trivial solution). Fig. 13. Comparing the performance of the Linear and Nonlinear models on different datasets. 64 66 68 70 Linear Nonlinear Frappe 47 48 49 50 Linear Nonlinear Yelp",
  "8 Conclusion": "To enhance recommendation accuracy, we proposed IEDR, a novel framework that effectively differentiates and captures intrinsic and extrinsic factors from the interplay of various contexts. IEDR leverages a context-invariant contrastive learning component and a mutual information minimization-based disentangling component to capture consistent user preference and external motivation that may vary across contexts. Extensive experiments on real-world datasets demonstrated IEDR's effectiveness in learning disentangled factors and significantly improving recommendation accuracy by up to 4% in NDCG. Following this work, we may explore learning more fine-grained intrinsic and extrinsic factors (e.g., multiple intrinsic factors) so that can capture nuanced user interests and generalize our methods to broader applications, e.g., improving the diversity of recommendations. Also, we may explore how to disentangle intrinsic and extrinsic factors when context features are not available.",
  "Acknowledgments": "This work was financially supported by the National Natural Science Foundation of China (Grant No. 62436003 and 62306333), ARC Discovery Project (Grant No. DP230102908 to Junhao Gan), and ARC Discovery Early Career Researcher Award (DECRA) (Grant No. DE220100680 to Sarah M. Erfani). ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:26 Su, et al.",
  "References": "[1] Linas Baltrunas, Karen Church, Alexandros Karatzoglou, and Nuria Oliver. 2015. Frappe: Understanding the Usage and Perception of Mobile App Recommendations In-the-wild. arXiv preprint arXiv:1505.03014 (2015). [2] Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeshwar, Sherjil Ozair, Yoshua Bengio, Aaron Courville, and Devon Hjelm. 2018. Mutual Information Neural Estimation. In ICML . 531-540. [3] Roland BÃ©nabou and Jean Tirole. 2003. Intrinsic and Extrinsic Motivation. The Review of Economic Studies (2003), 489-520. [4] Xuheng Cai, Chao Huang, Lianghao Xia, and Xubin Ren. 2023. LightGCL: Simple Yet Effective Hraph Contrastive Learning for Recommendation. In ICLR . [5] Han Chen, Ziwen Zhao, Yuhua Li, Yixiong Zou, Ruixuan Li, and Rui Zhang. 2023. CSGCL: Community-strengthenhanced Graph Contrastive Learning. In IJCAI . 2059-2067. [6] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. A Simple Framework for Contrastive Learning of Visual Representations. In ICML . 1597-1607. [7] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al. 2016. Wide & Deep Learning for Recommender Systems. In Recsys . 7-10. [8] Pengyu Cheng, Weituo Hao, Shuyang Dai, Jiachang Liu, Zhe Gan, and Lawrence Carin. 2020. Club: A Contrastive Log-ratio Upper Bound of Mutual Information. In ICML . PMLR, 1779-1788. [9] Jiasheng Duan, Peng-Fei Zhang, Ruihong Qiu, and Zi Huang. 2023. Long Short-term Enhanced Memory for Sequential Recommendation. World Wide Web 26, 2 (2023), 561-583. [10] Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021. SimCSE: Simple Contrastive Learning of Sentence Embeddings. In EMNLP . 6894-6910. [11] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a Factorization-machine based Neural Network for CTR Prediction. In IJCAI . 1725-1731. [12] Xiangnan He and Tat-Seng Chua. 2017. Neural Factorization Machines for Sparse Predictive Analytics. In SIGIR . 355-364. [13] BalÃ¡zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based Recommendations with Recurrent Neural Networks. In ICLR . 1-10. [14] R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam Trischler, and Yoshua Bengio. 2019. Learning Deep Representations by Mutual Information Estimation and Maximization. In ICLR . 1-14. [15] Wang-Cheng Kang and Julian McAuley. 2018. Self-Attentive Sequential Recommendation. In ICDM . IEEE, 197-206. [16] Huayu Li, Yong Ge, Defu Lian, and Hao Liu. 2017. Learning User's Intrinsic and Extrinsic Interests for Point-of-Interest Recommendation: A Unified Approach.. In IJCAI . 2117-2123. [17] Honghao Li, Lei Sang, Yi Zhang, Xuyun Zhang, and Yiwen Zhang. 2024. CETN: Contrast-enhanced Through Network for Click-Through Rate Prediction. TOIS 43, 1 (2024), 1-34. [18] Muyang Li, Zijian Zhang, Xiangyu Zhao, Wanyu Wang, Minghao Zhao, Runze Wu, and Ruocheng Guo. 2023. Automlp: Automated MLP for Sequential Recommendations. In WWW . 1190-1198. [19] Zihan Lin, Changxin Tian, Yupeng Hou, and Wayne Xin Zhao. 2022. Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning. In WWW . 2320-2329. [20] Qijiong Liu, Jieming Zhu, Yanting Yang, Quanyu Dai, Zhaocheng Du, Xiao-Ming Wu, Zhou Zhao, Rui Zhang, and Zhenhua Dong. 2024. Multimodal Pretraining, Adaptation, and Generation for Recommendation: A Survey. In SIGKDD . 6566-6576. [21] Jianxin Ma, Chang Zhou, Peng Cui, Hongxia Yang, and Wenwu Zhu. 2019. Learning Disentangled Representations for Recommendation. In NeurIPS . 5712-5723. [22] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel. 2015. Image-based Recommendations on Styles and Substitutes. In SIGIR . 43-52. [23] Wentao Ning, Xiao Yan, Weiwen Liu, Reynold Cheng, Rui Zhang, and Bo Tang. 2023. Multi-domain Recommendation with Embedding Disentangling and Domain Alignment. In CIKM . 1917-1927. [24] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018. Representation Learning with Contrastive Predictive Coding. arXiv preprint arXiv:1807.03748 (2018). [25] Steffen Rendle. 2010. Factorization Machines. In ICDM . 995-1000. [26] Richard M Ryan and Edward L Deci. 2000. Intrinsic and Extrinsic Motivations: Classic Definitions and New Directions. Contemporary Educational Psychology (2000), 54-67. [27] Xiaoteng Shen, Rui Zhang, Xiaoyan Zhao, Jieming Zhu, and Xi Xiao. 2024. PMG: Personalized Multimodal Generation with Large Language Models. In WWW . 3833-3843. [28] Weiping Song, Chence Shi, Zhiping Xiao, Zhijian Duan, Yewen Xu, Ming Zhang, and Jian Tang. 2019. Autoint: Automatic Feature Interaction Learning via Self-attentive Neural Networks. In CIKM . 1161-1170. ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:27 [29] Daria Sorokina, Rich Caruana, Mirek Riedewald, and Daniel Fink. 2008. Detecting Statistical Interactions with Additive Groves of Trees. In ICML . 1000-1007. [30] Yixin Su, Rui Zhang, Sarah Erfani, and Zhenghua Xu. 2021. Detecting Beneficial Feature Interactions for Recommender Systems. In AAAI . 4357-4365. [31] Yixin Su, Rui Zhang, Sarah M. Erfani, and Junhao Gan. 2021. Neural graph matching based collaborative filtering. In SIGIR . 849-858. [32] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer. In CIKM . 1441-1450. [33] Zhen Tian, Ting Bai, Wayne Xin Zhao, Ji-Rong Wen, and Zhao Cao. 2023. EulerNet: Adaptive Feature Interaction Learning via Euler's Formula for CTR Prediction. In SIGIR . 1376-1385. [34] Michael Tsang, Hanpeng Liu, Sanjay Purushotham, Pavankumar Murali, and Yan Liu. 2018. Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability. In NeurIPS . 5804-5813. [35] Robert J Vallerand. 1997. Toward a Hierarchical Model of Intrinsic and Extrinsic Motivation. Advances in Experimental Social Psychology (1997), 271-360. [36] Chenyang Wang, Weizhi Ma, Chong Chen, Min Zhang, Yiqun Liu, and Shaoping Ma. 2023. Sequential Recommendation with Multiple Contrast Signals. TOIS 41, 1 (2023), 1-27. [37] Fangye Wang, Yingxu Wang, Dongsheng Li, Hansu Gu, Tun Lu, Peng Zhang, and Ning Gu. 2023. Cl4ctr: A Contrastive Learning Framework for CTR Prediction. In WSDM . 805-813. [38] Jianling Wang, Raphael Louca, Diane Hu, Caitlin Cellier, James Caverlee, and Liangjie Hong. 2020. Time to Shop for Valentine's Day: Shopping Occasions and Sequential Recommendation in E-commerce. In WSDM . 645-653. [39] Jinpeng Wang, Ziyun Zeng, Yunxiao Wang, Yuting Wang, Xingyu Lu, Tianxiang Li, Jun Yuan, Rui Zhang, Hai-Tao Zheng, and Shu-Tao Xia. 2023. MISSRec: Pre-training and Transferring Multi-modal Interest-aware Sequence Representation for Recommendation. In MM . 6548-6557. [40] Ruoxi Wang, Rakesh Shivanna, Derek Cheng, Sagar Jain, Dong Lin, Lichan Hong, and Ed Chi. 2021. DCN V2: Improved Deep & Cross Network and Practical Lessons for Web-scale Learning to Rank Systems. In WWW . 1785-1797. [41] Wenjie Wang, Xinyu Lin, Liuhui Wang, Fuli Feng, Yunshan Ma, and Tat-Seng Chua. 2023. Causal Disentangled Recommendation Against User Preference Shifts. TOIS 42, 1 (2023), 1-27. [42] Xiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, and Tat-Seng Chua. 2020. Disentangled Graph Collaborative Filtering. In SIGIR . 1001-1010. [43] Jiancan Wu, Xiangnan He, Xiang Wang, Qifan Wang, Weijian Chen, Jianxun Lian, and Xing Xie. 2022. Graph Convolution Machine for Context-aware Recommender System. Frontiers of Computer Science (2022), 1-12. [44] Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, and Xing Xie. 2021. Self-supervised Graph Learning for Recommendation. In SIGIR . 726-735. [45] Yuxia Wu, Ke Li, Guoshuai Zhao, and QIAN Xueming. 2020. Personalized Long-and Short-term Preference Learning for Next POI Recommendation. TKDE (2020), 2301-2304. [46] Jun Xiao, Hao Ye, Xiangnan He, Hanwang Zhang, Fei Wu, and Tat-Seng Chua. 2017. Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks. In IJCAI . 3119-3125. [47] Dong Yao, Zhou Zhao, Shengyu Zhang, Jieming Zhu, Yudong Zhu, Rui Zhang, and Xiuqiang He. 2022. Contrastive Learning with Positive-negative Frame Mask for Music Representation. In WWW . 2906-2915. [48] Tiansheng Yao, Xinyang Yi, Derek Zhiyuan Cheng, Felix Yu, Ting Chen, Aditya Menon, Lichan Hong, Ed H Chi, Steve Tjoa, Jieqi Kang, et al. 2021. Self-supervised Learning for Large-scale Item Recommendations. In CIKM . 4321-4330. [49] Haibo Ye, Xinjie Li, Yuan Yao, and Hanghang Tong. 2023. Towards Robust Neural Graph Collaborative Filtering via Structure Denoising and Embedding Perturbation. TOIS 41, 3 (2023), 1-28. [50] Junliang Yu, Xin Xia, Tong Chen, Lizhen Cui, Nguyen Quoc Viet Hung, and Hongzhi Yin. 2023. XSimGCL: Towards Extremely Simple Graph Contrastive Learning for Recommendation. TKDE 36, 2 (2023), 913-926. [51] Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Lizhen Cui, and Quoc Viet Hung Nguyen. 2022. Are Graph Augmentations Necessary? Simple Graph Contrastive Learning for Recommendation. In SIGIR . 1294-1303. [52] Yantao Yu, Zhen Wang, and Bo Yuan. 2019. An Input-aware Factorization Machine for Sparse Prediction.. In IJCAI . 1466-1472. [53] Zeping Yu, Jianxun Lian, Ahmad Mahmoody, Gongshen Liu, and Xing Xie. 2019. Adaptive User Modeling with Long and Short-Term Preferences for Personalized Recommendation. In IJCAI . 4213-4219. [54] An Zhang, Leheng Sheng, Zhibo Cai, Xiang Wang, and Tat-Seng Chua. 2024. Empowering Collaborative Filtering with Principled Adversarial Contrastive Loss. In NeurIPS . 6242-6266. [55] Rui Zhang, Bayu Distiawan Trisedya, Miao Li, Yong Jiang, and Jianzhong Qi. 2022. A Benchmark and Comprehensive Survey on Knowledge Graph Entity Alignment via Representation Learning. VLDB 31, 5 (2022), 1143-1168. [56] Yu Zheng, Chen Gao, Jianxin Chang, Yanan Niu, Yang Song, Depeng Jin, and Yong Li. 2022. Disentangling Long and Short-Term Interests for Recommendation. In WWW . 2256-2267. ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:28 Su, et al. [57] Kun Zhou, Hui Wang, Wayne Xin Zhao, Yutao Zhu, Sirui Wang, Fuzheng Zhang, Zhongyuan Wang, and Ji-Rong Wen. 2020. S3-rec: Self-supervised Learning for Sequential Recommendation with Mutual Information Maximization. In CIKM . 1893-1902. [58] Jieming Zhu, Quanyu Dai, Liangcai Su, Rong Ma, Jinyang Liu, Guohao Cai, Xi Xiao, and Rui Zhang. 2022. Bars: Towards open Benchmarking for Recommender Systems. In SIGIR . 2912-2923. ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:1",
  "A Proof of Theorem 1": "Proof. Since the mutual information is not explicitly intractable, we approximate the right side of Equation (4) with a lower bound (i.e., MINE [2]) and an upper bound (i.e., CLUB [8]) of mutual information, respectively. More formally,   With the approximated terms above, proving Equation. (4) turns to verify:  By minimizing L CICL , we aim to make ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘–ğ‘– similar to ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘– ğ‘— . This procedure can be interpreted in probability as: increasing the probability of ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– ğ‘– , ğ’„ ğ‘— ) to predict ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘–ğ‘– . Therefore, maximizing the exp ( sim (( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘–ğ‘– , ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘– ğ‘— )/ ğœ ) in Equation (2) is equivalent to maximizing ğ‘ (( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘–ğ‘– | ğ’– ğ‘– , ğ’„ ğ‘— ) (exp (Â·) is monotone increasing so that does not influence the conclusion). Similar to the above conclusion, minimizing exp ( sim (( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘–ğ‘– , ( ğ’ ğ‘¢ ğ‘–ğ‘› ) â„“ğ‘– )/ ğœ ) is equivalent to minimizing ğ‘ (( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘–ğ‘– | ğ’– â„“ , ğ’„ ğ‘– ) . Therefore, we have     Equation (2) only samples one context ğ‘ ğ‘— for each data point. However, during the training, all contexts in C are expected to be sampled. If we count all contexts, we have  = E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )]-E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’„ ) log E ğ‘ ( ğ’– ) [ ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] . Equation (9) is the probability form of the objective function of the context-invariant counteractive learning component (Equation (2)). Equation (9) maximizes the likelihood ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ ) given the joint distribution of users and intrinsic factors, with the marginal distribution of contexts. Meanwhile, it ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:2 Su, et al. minimizes the likelihood ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ ) given the joint distribution of contexts and intrinsic factors, with the marginal distribution of the user. 2 From Equation (9), we further have: E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] -E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’„ ) log E ğ‘ ( ğ’– ) [ ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] (a) = E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] -E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’„ ) ğ‘ ( ğ’– ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] = E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] -E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’„ ) ğ‘ ( ğ’– ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] + GLYPH<0> E ğ‘ ( ğ’– ) [ log ğ‘ ( ğ’– )] -E ğ‘ ( ğ’– ) [ log ğ‘ ( ğ’– )] GLYPH<1> = E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ ) ğ‘ ( ğ’– )] -E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’„ ) ğ‘ ( ğ’– ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] -E ğ‘ ( ğ’– ) [ log ğ‘ ( ğ’– )] = E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– | ğ’„ )] -E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’„ ) ğ‘ ( ğ’– ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] -E ğ‘ ( ğ’– ) [ log ğ‘ ( ğ’– )] = E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– | ğ’„ )] -E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’„ ) ğ‘ ( ğ’– ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] -E ğ‘ ( ğ’– ) [ log ğ‘ ( ğ’– )] + GLYPH<16> E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘ ( ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] -E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘ ( ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] GLYPH<17> = E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– | ğ’„ )] -E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘ ( ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] -E ğ‘ ( ğ’– ) [ log ğ‘ ( ğ’– )] -E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’„ ) ğ‘ ( ğ’– ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] + E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘ ( ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] = E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– | ğ’„ )] -E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘ ( ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– | ğ’„ )] -GLYPH<16> E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’„ ) ğ‘ ( ğ’– ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] -E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘ ( ğ’– ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] GLYPH<17> = E ğ‘ ( ğ’„ ) GLYPH<16> E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– | ğ’„ )] -E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘ ( ğ’– ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’– | ğ’„ )] GLYPH<17> -E ğ‘ ( ğ’– ) GLYPH<16> E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› , ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] -E ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘ ( ğ’„ ) [ log ğ‘ ( ğ’ ğ‘¢ ğ‘–ğ‘› | ğ’– , ğ’„ )] GLYPH<17> . (10) (a): In the second term, pushing the log inside the expectation does not change the minimizer. Comparing Equation (7) and the first term of Equation (10), they both act like classifiers whose objectives maximize the expected log-ratio of the joint distribution over the product of marginal distributions [14]. Therefore, maximizing this term in Equation (10) will have the same effect as maximizing Equation (7). We can interpret the first term of Equation (10) as maximizing the mutual information between users and the corresponding intrinsic factor, conditioned on a given context. Similarly, maximizing the negative of the second term of Equation (10) will have the same effect of minimizing Equation (8), which can be interpreted as minimizing the mutual information between contexts and the corresponding intrinsic factors, conditioned on a given user. Therefore, we can conclude that:  â–¡ 2 Note that only if ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– , ğ’„ ) is a many-to-one (or one-to-one) mapping then Equation (9) and Equation (2) will be equivalent. Otherwise, given a sample pair ( ğ’– , ğ’„ ), ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– , ğ’„ ) may have different ğ’ ğ‘¢ ğ‘–ğ‘› outputs (i.e., one-to-many). In this situation, the first term of Equation (9) cannot guarantee that the same user with different context will have the same intrinsic factor (i.e., they may have various intrinsic factor representations while still meet the objective of the first term of Equation (9)). We use an MLP as ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– , ğ’„ ) , which is a many-to-one mapping function. Therefore, we can ensure the equivalence between Equation (9) and Equation (2). ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:3 Table 10. Implementation details of different variations on the recommendation prediction module. '-' represent the operation is the same as our original IEDR setting. Table 11. Implementation details of different variations of the contrastive intrinsic-extrinsic disentanglement module. '-' represents the operation as the same as our original IEDR setting. Ã— represents the variation that does not contain the component.",
  "B Algorithm": "This section provides the training process of our IEDR model in Algorithm 1. In each epoch, we use the batch stochastic gradient descent method. 3 Here we use user representation learning as an example. The item and context learning have the same structure. ğœ™,ğœ“ are both element-wise averaging functions and âŠ™ is the element-wise product. 4 Here we use user factor learning as an example. â—¦ is a flexible operation to combine two vectors, i.e., â—¦ is an element-wise product for the Frappe dataset, and an element-wise summation for the Yelp dataset. [Â· , Â· ] is the concatenation operation. is a linear transformation matrix, ğœ is a ReLU activation. ğ‘¾ 5 For IEDR ğ‘ ğ‘ , the positive samples ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘ are generated through a dropout of the intrinsic representation of the user, and the negative samples ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘ are generated through a dropout of intrinsic representations of random users. ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:4 Su, et al.",
  "Algorithm 1 Batch stochastic gradient descent training of IEDR.": "1: Input: D = {( ğ‘¢ ğ‘– , ğ‘£ ğ‘– , ğ‘ ğ‘– )} ğ‘– = 1: ğ‘ with the corresponding true label ğ‘¦ ğ‘– for each data sample. 2: Hyperparameters: ğµ : batch size; ğ¿ : negative sample number for the context-invariant contrastive learning component; ğ¿ ğ‘‘ğ‘–ğ‘  : negative sample number for the disentangling component. 3: Parameters: ğœ½ ğ‘¢ 1 , ğœ½ ğ‘¢ 2 , ğœ½ ğ‘£ 1 , ğœ½ ğ‘£ 2 : parameters for ğ‘ ğ‘¢ 1 , ğ‘ ğ‘¢ 2 , ğ‘ ğ‘£ 2 , ğ‘ ğ‘£ 2 , respectively; ğ : parameters of IEDR except for ğœ½ ğ‘¢ 1 , ğœ½ ğ‘¢ 2 , ğœ½ ğ‘£ 1 , ğœ½ ğ‘£ 2 . 4: function ContrastiveLearning_User( {( ğ’– ğ‘– , ğ’„ ğ‘– )} ğ‘– = 1: ğµ ) 5: for ğ‘– = 1 , ..., ğµ do 6: ğ‘¢ ğ‘¢ ğ‘–ğ‘› ğ‘–ğ‘’ ğ’„ ğ’ ğ’– ğ‘– ğ‘– ğ‘–ğ‘– ( ( â† ) ) ğ‘“ , 7: ğ¶ğ‘œğ‘›ğ‘¡ğ‘’ğ‘¥ğ‘¡ğºğ‘’ğ‘› â† ğ‘…ğ‘ğ‘›ğ‘‘ğ‘œğ‘šğ¶â„ğ‘œğ‘–ğ‘ğ‘’ ( ğ‘ğ‘’ğ‘”ğºğ‘’ğ‘› 1 , ğ‘ğ‘’ğ‘”ğºğ‘’ğ‘› 2 ) 8: ğ‘ ğ‘— â† ğ¶ğ‘œğ‘›ğ‘¡ğ‘’ğ‘¥ğ‘¡ğºğ‘’ğ‘› ( ğ‘ ğ‘– ) 9: ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘– ğ‘— â† ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– ğ‘– , ğ’„ ğ‘— ) 10: for â„“ = 1 , ..., ğ¿ do 11: ğ‘¢ â„“ 1 â† ğ‘Ÿğ‘ğ‘›ğ‘‘ğ‘œğ‘šğ¶â„ğ‘œğ‘–ğ‘ğ‘’ ({ ğ‘¢ ğ‘– } ğ‘– = 1: ğµ ) , ( ğ’ ğ‘¢ ğ‘–ğ‘› ) â„“ 1 ğ‘– = ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– â„“ 1 , ğ’„ ğ‘– ) 12: ğ‘¢ â„“ 2 â† ğ‘Ÿğ‘ğ‘›ğ‘‘ğ‘œğ‘šğ¶â„ğ‘œğ‘–ğ‘ğ‘’ ({ ğ‘¢ ğ‘– } ğ‘– = 1: ğµ ) , ( ğ’ ğ‘¢ ğ‘–ğ‘› ) â„“ 2 ğ‘— = ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– â„“ 2 , ğ’„ ğ‘— ) 13: end for 14: L ğ¶ğ¼ğ¶ğ¿ ( ğ‘¢ ğ‘– , ğ‘ ğ‘– ) â† Equation (4) based on the above positive and negative samples 15: 16: 17: 18: end for return ğ‘ğ‘£ğ‘’ğ‘Ÿğ‘ğ‘”ğ‘’ ({L ğ¶ğ¼ğ¶ğ¿ ( ğ‘¢ ğ‘– , ğ‘ ğ‘– )} ğ‘– = 1: ğµ ) end function function ContrastiveLearning_Item( {( ğ’— ğ‘– , ğ’„ ğ‘– )} ğ‘– = 1: ğµ ) 19: Symmetric to ContrastiveLearning_User.",
  "20: end function": "21: function Disentanglement_User( {( ğ’– ğ‘– , ğ’„ ğ‘– )} ğ‘– = 1: ğµ ) 22: 23: 24: 25: 26: 27: 28: 29: 30: for ğ‘– = 1 , ..., ğµ do ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘–ğ‘– , ( ğ’ ğ‘¢ ğ‘’ğ‘¥ ) ğ‘–ğ‘– â† ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– ğ‘– , ğ’„ ğ‘– ) ( ğ‘¢ ğ‘¢ ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘’ğ‘¥ ğ’ ğ’ ğ’ ) â† ( ) ) (( â†’ ğ‘ğ‘œğ‘  ğ‘ ğ‘ â†’ ğ‘›ğ‘’ğ‘” for ğ‘–ğ‘– â† â† ğ‘— = ( ğ’ ( ğ’ ğ‘¢ ğ‘–ğ‘› ğ‘¢ ğ‘’ğ‘¥ ğ‘ â†’ ğ‘›ğ‘’ğ‘” 31: ğœƒ 1 (( ğ‘€ğ‘†ğ¸ 0 , ğ‘ ğ‘¢ ğ‘’ğ‘¥ ğ’ â† ğ‘›ğ‘’ğ‘” 1 â† , ..., ğ¿ ) ğ‘‘ğ‘–ğ‘  , ğ’ ( ğ‘¢ ğ‘Ÿ ) ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘Ÿ â† â† ğ‘–ğ‘› ) ğ‘–ğ‘– ğ‘¢ ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘–ğ‘› ğ‘–ğ‘– , ğ‘–ğ‘– ) â† ( ğ‘¢ ğ‘ğ‘Ÿğ‘’ğ‘‘ , 0 do â† ) ğ‘’ğ‘¥ ğ‘Ÿ = ğ‘ ğ‘ ğ‘Ÿğ‘ğ‘›ğ‘‘ğ‘œğ‘šğ¶â„ğ‘œğ‘–ğ‘ğ‘’ (( ğœƒ ğ‘ ğ‘ ğœƒ â† ğ‘’ğ‘¥ ğ‘–ğ‘– ) ) ğ’ ğ‘ğ‘œğ‘  , ğ‘ GLYPH<0> ğ’ ğ‘¢ ğ‘¢ 1 + + ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘–ğ‘› ) ğ’ ) ) ( ğ‘€ğ‘†ğ¸ ğ‘Ÿ (( ğ‘€ğ‘†ğ¸ ğ’ (( ğ’ , ğ‘¢ ğ‘’ğ‘¥ ğ‘–ğ‘› ) ğ‘¢ ğ‘–ğ‘› ğ‘–ğ‘– ğ‘–ğ‘– ) â†’ ğ‘›ğ‘’ğ‘” â† ğ‘›ğ‘’ğ‘” â† ğ‘›ğ‘’ğ‘” ğ‘ 32: end for 33: (L ğ‘ğ‘– -ğ‘ğ‘ğ‘ğ‘Ÿ ) ğ‘– â† 1 2 ( ğ‘ â†’ ğ‘ğ‘œğ‘  + ğ‘ â† ğ‘ğ‘œğ‘  ) â†’ â† (L ğ‘ + ğ‘ ğ‘ ( - ( ) â† ğ‘‘ğ‘–ğ‘  â†’ ğ‘›ğ‘’ğ‘” ğ‘›ğ‘’ğ‘” 1 34: ğ·ğ‘–ğ‘  ğ‘– ğ‘ğ‘œğ‘  2 ğ‘Ÿ ( , , ğ’ ( ğ‘¢ ğ‘’ğ‘¥ ğ’ + ğ‘¢ ğ‘–ğ‘› â† ğ‘¢ 2 ğ‘’ğ‘¥ (( ğ’ ğ‘€ğ‘†ğ¸ { ( ) (( ğ’ , ) ğ‘¢ ğ‘–ğ‘› = ) ) ğ‘ ğœƒ 2 ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘Ÿ ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘Ÿ â† ğ‘ğ‘œğ‘  35: end for 36: return ğ‘ğ‘£ğ‘’ğ‘Ÿğ‘ğ‘”ğ‘’ ({(L ğ‘ğ‘– -ğ‘ğ‘ğ‘ğ‘Ÿ ) ğ‘– } ğ‘– = 1: ğµ ) , ğ‘ğ‘£ğ‘’ğ‘Ÿğ‘ğ‘”ğ‘’ ({(L ğ·ğ‘–ğ‘  ) ğ‘– } ğ‘– = 1: ğµ ) 37: end function 38: function Disentanglement_Item( {( ğ’— ğ‘– , ğ’„ ğ‘– )} ğ‘– = 1: ğµ ) 39: Symmetric to Disentanglement_User. 40: end function 41: )) ) ) ğ‘ ğ‘–ğ‘– (( ğ‘–ğ‘– ğ’ ( ) ğ‘¢ ğ‘–ğ‘› ğ’ ğ’ ğ‘¢ ğ‘’ğ‘¥ ğ‘¢ ğ‘’ğ‘¥ ) ) ğ‘–ğ‘– ) ğ‘Ÿ ) ğ‘–ğ‘– , GLYPH<1> GLYPH<0> ğ‘ ğ‘ ( ğ’ } ğ‘– = ğ‘¢ ğ‘–ğ‘› âŠ² Generate positive samples. ) ) ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘–ğ‘– âŠ² Generate negative samples. 1: ğµ GLYPH<1> âŠ² Generate positive samples. âŠ² Generate negative samples. ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025. Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios 1:5",
  "Algorithm 1 Batch stochastic gradient descent training of IEDR (continued).": "42: ğ‘ â„ğ‘¢ğ‘“ ğ‘“ ğ‘™ğ‘’ ({( ğ‘¢ ğ‘– , ğ‘£ ğ‘– , ğ‘ ğ‘– )} ğ‘– = 1: ğ‘ ) 43: for each batch {( ğ‘¢ ğ‘– , ğ‘£ ğ‘– , ğ‘ ğ‘– )} ğ‘– = 1: ğµ do 44: for ğ‘– = 1 , ..., ğµ do âŠ² Line 45-47 are the recommendation prediction module. 45: ğ’– ğ‘– â† ğ‘“ ğ‘¢ ( ğ‘¢ ğ‘– ) , ğ’— ğ‘– â† ğ‘“ ğ‘£ ( ğ‘£ ğ‘– ) , ğ’„ ğ‘– â† ğ‘“ ğ‘ ( ğ‘ ğ‘– ) 46: ( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘–ğ‘– , ( ğ’ ğ‘¢ ğ‘’ğ‘¥ ) ğ‘–ğ‘– â† ğ‘“ ğ‘¢ ğ‘–ğ‘’ ( ğ’– ğ‘– , ğ’„ ğ‘– ) , ( ğ’ ğ‘£ ğ‘–ğ‘› ) ğ‘–ğ‘– , ( ğ’ ğ‘£ ğ‘’ğ‘¥ ) ğ‘–ğ‘– â† ğ‘“ ğ‘£ ğ‘–ğ‘’ ( ğ’— ğ‘– , ğ’„ ğ‘– ) 47: ğ‘¦ â€² ğ‘– â† ğ‘“ ğ‘ğ‘Ÿğ‘’ğ‘‘ (( ğ’ ğ‘¢ ğ‘–ğ‘› ) ğ‘–ğ‘– , ( ğ’ ğ‘¢ ğ‘’ğ‘¥ ) ğ‘–ğ‘– , ( ğ’ ğ‘£ ğ‘–ğ‘› ) ğ‘–ğ‘– , ( ğ’ ğ‘£ ğ‘’ğ‘¥ ) ğ‘–ğ‘– ) 48: (L ğ‘…ğ‘ƒ ) ğ‘– â† ğ¶ğ‘Ÿğ‘œğ‘ ğ‘ ğ¸ğ‘›ğ‘¡ğ‘Ÿğ‘œğ‘ğ‘¦ ( ğ‘¦ â€² ğ‘– , ğ‘¦ ğ‘– ) 49: end for 50: L ğ‘…ğ‘ƒ â† ğ‘ğ‘£ğ‘’ğ‘Ÿğ‘ğ‘”ğ‘’ ({L ğ‘…ğ‘ƒ ) ğ‘– } ğ‘– = 1: ğµ 51: L ğ‘¢ ğ¶ğ¼ğ¶ğ¿ â† ContrastiveLearning_User ({( ğ’– ğ‘– , ğ’„ ğ‘– )} ğ‘– = 1: ğµ ) 52: L ğ‘£ ğ¶ğ¼ğ¶ğ¿ â† ContrastiveLearning_Item ({( ğ’— ğ‘– , ğ’„ ğ‘– )} ğ‘– = 1: ğµ ) 53: L ğ‘¢ ğ‘ğ‘– -ğ‘ğ‘ğ‘ğ‘Ÿ , L ğ‘¢ ğ·ğ‘–ğ‘  â† Disentanglement_User ({( ğ’– ğ‘– , ğ’„ ğ‘– )} ğ‘– = 1: ğµ ) 54: L ğ‘£ ğ‘ğ‘– -ğ‘ğ‘ğ‘ğ‘Ÿ , L ğ‘£ ğ·ğ‘–ğ‘  â† Disentanglement_Item ({( ğ’— ğ‘– , ğ’„ ğ‘– )} ğ‘– = 1: ğµ ) 55: Freeze ğ , update ğœ½ ğ‘¢ 1 , ğœ½ ğ‘¢ 2 , ğœ½ ğ‘£ 1 , ğœ½ ğ‘£ 2 through minimizing R( ğœ½ ğ‘¢ 1 , ğœ½ ğ‘¢ 2 , ğœ½ ğ‘£ 1 , ğœ½ ğ‘£ 2 ) âŠ² Step 1 56: Freeze ğœ½ ğ‘¢ 1 , ğœ½ ğ‘¢ 2 , ğœ½ ğ‘£ 1 , ğœ½ ğ‘£ 2 , update ğ through minimizing R( ğ ) âŠ² Step 2 57: end for ACM Trans. Inf. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2025.",
  "keywords_parsed": [],
  "references_parsed": [
    {
      "ref_id": "b1",
      "title": "Frappe: Understanding the Usage and Perception of Mobile App Recommendations In-the-wild"
    },
    {
      "ref_id": "b2",
      "title": "Mutual Information Neural Estimation"
    },
    {
      "ref_id": "b3",
      "title": "Intrinsic and Extrinsic Motivation"
    },
    {
      "ref_id": "b4",
      "title": "LightGCL: Simple Yet Effective Hraph Contrastive Learning for Recommendation"
    },
    {
      "ref_id": "b5",
      "title": "CSGCL: Community-strengthenhanced Graph Contrastive Learning"
    },
    {
      "ref_id": "b6",
      "title": "A Simple Framework for Contrastive Learning of Visual Representations"
    },
    {
      "ref_id": "b7",
      "title": "Wide & Deep Learning for Recommender Systems"
    },
    {
      "ref_id": "b8",
      "title": "Club: A Contrastive Log-ratio Upper Bound of Mutual Information"
    },
    {
      "ref_id": "b9",
      "title": "Long Short-term Enhanced Memory for Sequential Recommendation"
    },
    {
      "ref_id": "b10",
      "title": "SimCSE: Simple Contrastive Learning of Sentence Embeddings"
    },
    {
      "ref_id": "b11",
      "title": "DeepFM: a Factorization-machine based Neural Network for CTR Prediction"
    },
    {
      "ref_id": "b12",
      "title": "Neural Factorization Machines for Sparse Predictive Analytics"
    },
    {
      "ref_id": "b13",
      "title": "Session-based Recommendations with Recurrent Neural Networks"
    },
    {
      "ref_id": "b14",
      "title": "Learning Deep Representations by Mutual Information Estimation and Maximization"
    },
    {
      "ref_id": "b15",
      "title": "Self-Attentive Sequential Recommendation"
    },
    {
      "ref_id": "b16",
      "title": "Learning User's Intrinsic and Extrinsic Interests for Point-of-Interest Recommendation: A Unified Approach."
    },
    {
      "ref_id": "b17",
      "title": "CETN: Contrast-enhanced Through Network for Click-Through Rate Prediction"
    },
    {
      "ref_id": "b18",
      "title": "Automlp: Automated MLP for Sequential Recommendations"
    },
    {
      "ref_id": "b19",
      "title": "Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning"
    },
    {
      "ref_id": "b20",
      "title": "Multimodal Pretraining, Adaptation, and Generation for Recommendation: A Survey"
    },
    {
      "ref_id": "b21",
      "title": "Learning Disentangled Representations for Recommendation"
    },
    {
      "ref_id": "b22",
      "title": "Image-based Recommendations on Styles and Substitutes"
    },
    {
      "ref_id": "b23",
      "title": "Multi-domain Recommendation with Embedding Disentangling and Domain Alignment"
    },
    {
      "ref_id": "b24",
      "title": "Representation Learning with Contrastive Predictive Coding"
    },
    {
      "ref_id": "b25",
      "title": "Factorization Machines"
    },
    {
      "ref_id": "b26",
      "title": "Intrinsic and Extrinsic Motivations: Classic Definitions and New Directions"
    },
    {
      "ref_id": "b27",
      "title": "PMG: Personalized Multimodal Generation with Large Language Models"
    },
    {
      "ref_id": "b28",
      "title": "Autoint: Automatic Feature Interaction Learning via Self-attentive Neural Networks"
    },
    {
      "ref_id": "b29",
      "title": "Detecting Statistical Interactions with Additive Groves of Trees"
    },
    {
      "ref_id": "b30",
      "title": "Detecting Beneficial Feature Interactions for Recommender Systems"
    },
    {
      "ref_id": "b31",
      "title": "Neural graph matching based collaborative filtering"
    },
    {
      "ref_id": "b32",
      "title": "BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer"
    },
    {
      "ref_id": "b33",
      "title": "EulerNet: Adaptive Feature Interaction Learning via Euler's Formula for CTR Prediction"
    },
    {
      "ref_id": "b34",
      "title": "Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability"
    },
    {
      "ref_id": "b35",
      "title": "Toward a Hierarchical Model of Intrinsic and Extrinsic Motivation"
    },
    {
      "ref_id": "b36",
      "title": "Sequential Recommendation with Multiple Contrast Signals"
    },
    {
      "ref_id": "b37",
      "title": "Cl4ctr: A Contrastive Learning Framework for CTR Prediction"
    },
    {
      "ref_id": "b38",
      "title": "Time to Shop for Valentine's Day: Shopping Occasions and Sequential Recommendation in E-commerce"
    },
    {
      "ref_id": "b39",
      "title": "MISSRec: Pre-training and Transferring Multi-modal Interest-aware Sequence Representation for Recommendation"
    },
    {
      "ref_id": "b40",
      "title": "DCN V2: Improved Deep & Cross Network and Practical Lessons for Web-scale Learning to Rank Systems"
    },
    {
      "ref_id": "b41",
      "title": "Causal Disentangled Recommendation Against User Preference Shifts"
    },
    {
      "ref_id": "b42",
      "title": "Disentangled Graph Collaborative Filtering"
    },
    {
      "ref_id": "b43",
      "title": "Graph Convolution Machine for Context-aware Recommender System"
    },
    {
      "ref_id": "b44",
      "title": "Self-supervised Graph Learning for Recommendation"
    },
    {
      "ref_id": "b45",
      "title": "Personalized Long-and Short-term Preference Learning for Next POI Recommendation"
    },
    {
      "ref_id": "b46",
      "title": "Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks"
    },
    {
      "ref_id": "b47",
      "title": "Contrastive Learning with Positive-negative Frame Mask for Music Representation"
    },
    {
      "ref_id": "b48",
      "title": "Self-supervised Learning for Large-scale Item Recommendations"
    },
    {
      "ref_id": "b49",
      "title": "Towards Robust Neural Graph Collaborative Filtering via Structure Denoising and Embedding Perturbation"
    },
    {
      "ref_id": "b50",
      "title": "XSimGCL: Towards Extremely Simple Graph Contrastive Learning for Recommendation"
    },
    {
      "ref_id": "b51",
      "title": "Are Graph Augmentations Necessary? Simple Graph Contrastive Learning for Recommendation"
    },
    {
      "ref_id": "b52",
      "title": "An Input-aware Factorization Machine for Sparse Prediction."
    },
    {
      "ref_id": "b53",
      "title": "Adaptive User Modeling with Long and Short-Term Preferences for Personalized Recommendation"
    },
    {
      "ref_id": "b54",
      "title": "Empowering Collaborative Filtering with Principled Adversarial Contrastive Loss"
    },
    {
      "ref_id": "b55",
      "title": "A Benchmark and Comprehensive Survey on Knowledge Graph Entity Alignment via Representation Learning"
    },
    {
      "ref_id": "b56",
      "title": "Disentangling Long and Short-Term Interests for Recommendation"
    },
    {
      "ref_id": "b57",
      "title": "S3-rec: Self-supervised Learning for Sequential Recommendation with Mutual Information Maximization"
    },
    {
      "ref_id": "b58",
      "title": "Bars: Towards open Benchmarking for Recommender Systems"
    }
  ]
}