{"Multi-Behavior Collaborative Filtering with Partial Order Graph Convolutional Networks": "Yijie Zhang \u2217 Jinan University Guangzhou, China wingszhangyijie@gmail.com Qijie Shen Alibaba Group Hangzhou, China qijie.sqj@alibaba-inc.com Senzhang Wang Central South University Changsha, China szwang@csu.edu.cn", "Yuanchen Bei \u2217": "", "Hao Chen \u2217": "Zhejiang University Hangzhou, China yuanchenbei@zju.edu.cn Zheng Yuan The Hong Kong Polytechnic University Hong Kong, China yzheng.yuan@connect.polyu.hk The Hong Kong Polytechnic University Hong Kong, China sundaychenhao@gmail.com Huan Gong National University of Defense Technology Changsha, China gongh15@outlook.com Feiran Huang \u2020 Jinan University Guangzhou, China huangfr@jnu.edu.cn", "ABSTRACT": "Representing information of multiple behaviors in the single graph collaborative filtering (CF) vector has been a long-standing challenge. This is because different behaviors naturally form separate behavior graphs and learn separate CF embeddings. Existing models merge the separate embeddings by appointing the CF embeddings for some behaviors as the primary embedding and utilizing other auxiliaries to enhance the primary embedding. However, this approach often results in the joint embedding performing well on the main tasks but poorly on the auxiliary ones. To address the problem arising from the separate behavior graphs, we propose the concept of Partial Order Recommendation Graphs (POG) . POG defines the partial order relation of multiple behaviors and models behavior combinations as weighted edges to merge separate behavior graphs into a joint POG. Theoretical proof verifies that POG can be generalized to any given set of multiple behaviors. Based on POG, we propose the tailored Partial Order Graph Convolutional Networks (POGCN) that convolute neighbors' information while considering the behavior relations between users and items. POGCN also introduces a partial-order BPR sampling strategy for efficient and effective multiple-behavior CF training. POGCNhasbeensuccessfully deployed on the homepage of Alibaba Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. KDD '24, August 25-29, 2024, Barcelona, Spain Xiao Huang The Hong Kong Polytechnic University Hong Kong, China xiaohuang@comp.polyu.edu.hk for two months, providing recommendation services for over one billion users. Extensive offline experiments conducted on three public benchmark datasets demonstrate that POGCN outperforms stateof-the-art multi-behavior baselines across all types of behaviors. Furthermore, online A/B tests confirm the superiority of POGCN in billion-scale recommender systems.", "CCS CONCEPTS": "\u00b7 Information systems \u2192 Retrieval models and ranking ; \u00b7 Human-centered computing \u2192 Collaborative filtering .", "KEYWORDS": "recommender systems, multi-behavior recommendation, graph collaborative filtering", "ACMReference Format:": "Yijie Zhang, Yuanchen Bei, Hao Chen, Qijie Shen, Zheng Yuan, Huan Gong, Senzhang Wang, Feiran Huang, and Xiao Huang. 2024. Multi-Behavior Collaborative Filtering with Partial Order Graph Convolutional Networks. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '24), August 25-29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671569", "1 INTRODUCTION": "Graph-based collaborative filtering (CF) models [16, 45, 50] have emerged as the state-of-the-art in predicting user-item interactions, particularly for single behaviors like clicks [8, 18, 49, 58]. However, in real-world recommender systems, there are other behaviors equally crucial as clicks, such as favors and purchases, which greatly impact user retention and platform revenue [24, 53]. Nonetheless, CF models focused on a single behavior may not perform well for other behaviors. For example, graph embeddings trained on click data often yield suboptimal results for favor and purchase recommendations, and vice versa. This phenomenon requires modern Click 0.06 0.07 0.08 0.09 0.10 Recall@20 LightGCN GHCF POGCN Cart 0.120 0.125 0.130 0.135 0.140 0.145 0.150 0.155 0.160 LightGCN GHCF POGCN Buy 0.15 0.16 0.17 0.18 0.19 0.20 0.21 LightGCN GHCF POGCN recommender systems to train respective CF embeddings for every behavior, leading to considerable time, cost, and storage burdens. Hence, it is crucial to design an effective multi-behavior graphbased CF model that can efficiently recommend multiple behaviors using a single CF embedding. Existing multi-behavior CF models usually merge the separate embeddings by affording certain behaviors higher priority and serving others as secondary to enhance the primary embedding. For instance, NMTR [14], which extends the neural CF model [19], considers purchasing behavior as the primary behavior and incorporates other behaviors to enhance purchasing predictions. Similarly, MB-CGCN[12] builds upon NMTR by integrating LightGCN [18] to improve graph embeddings for purchasing by leveraging click and cart addition embeddings. On the other hand, IMGCF [64] adopts a different approach by learning separate embeddings for each behavior graph and then averaging these for multi-behavior recommendations. GHCF [6] introduces a unique weighting strategy for combining embeddings from different behavior graphs. Another line of multi-behavior research, Click Through Rate (CTR) prediction models like ESMM [34], MMOE [33], and PLE [41] relies on designing complex MLP structures to deal with the multi-behavior recommendation but they fail to represent users and items with single embedding vectors. However, current multi-behavior collaborative filtering (CF) models still learn the embedding of different behaviors separately, raising severe seesaw problems. The merged embedding may perform well on the priority behavior but sacrifice recommendation performance on the auxiliaries. As shown in Figure.1, LightGCN performs well on click recommendations but performs significantly worse on the other two behaviors. On the other hand, GHCF, which treats 'buy' as the priority, outperforms LightGCN in add-to-cart and purchase recommendations. However, GHCF fails in recommending clicks. In practical applications, all types of behaviors have significant implications for user experience and platform revenue. As stated, predicting clicks affects user intentions such as activation, while add-to-cart and purchasing impact the platform's revenue. Therefore, it is crucial to model the separate multi-behaviors in a joint structure and thus train single embedding naturally. However, encoding the separate multiple behaviors into a joint structure poses the following three challenges: \u00b7 Separate Graphs : The current graph concept cannot represent multiple behaviors within one graph. Defining a suitable joint graph to simultaneously organize arbitrary multiple behaviors is challenging. \u00b7 Complicated Behavior Relations : Multiple behaviors can have complex combinations. For instance, users may directly purchase items without favoriting or adding them to the cart. Alternatively, they may add several items to carts before making a purchase. Thus, modeling the combination of behaviors is more difficult than modeling individual behaviors. \u00b7 Behavior Combination Ordering : Existing models only provide the order of behaviors. It's challenging to determine the order of behavior combinations such as comparing the order of 'buy', 'click&favor&cart', and 'buy&click'. In this paper, we tackle the above three challenges by upgrading the infrastructure of multiple behavior graph collaborative filtering and introducing the general Partial Order Recommendation Graph (POG) to merge separate multi-behavior graphs into a unified one. Specifically, POG utilizes a 'graded partial order set' to model all the potential behavior combinations between users and items. Consequently, POG is able to convert any behavior combination into a joint weighted graph. With the help of POG, we propose tailored Partial Order Graph Convolutional Networks (POGCN) to train a single embedding that can benefit multi-behavior recommendation simultaneously. Additionally, we simplify the original multiple-behavior BPR sampling process by developing a tailored partial order BPR sampling strategy. As depicted in Figure.1, POGCN naturally resolves the seesaw problem and improves the recommendation performance on 'click', 'cart', and 'buy' simultaneously. Our paper's primary contributions can be summarized as follows: \u00b7 We formally define the partial order recommendation graph to describe the complicated behavior combinations for the seesaw phenomenon in multi-behavior recommendation naturally. Moreover, we prove the completeness of the definition of the POG that can deal with arbitrary multiple behaviors. \u00b7 We propose a novel partial order graph convolutional network to learn representative single embedding for multibehavior CF tasks. Besides, we propose a simplified partial order BPR sampling strategy 1 . \u00b7 POGCN has been serving as a core recall model at the homepage of one of the biggest e-commerce platforms-Alibaba, offering accurate and suitable recommendations to over one billion users. \u00b7 Extensive experiments on three benchmark datasets present that POGCN outperforms the state-of-the-art multi-behavior collaborative filtering methods for above 16.84% Recall, and 19.67% NDCG on average. Online A/B test also demonstrates that POGCN brings 2.02% UCTR and 2.84% GMV improvement in industrial platforms.", "2 PRELIMINARY": "In this section, we begin by defining the problem of multi-behavior collaborative filtering. We then proceed to introduce the definition of the partial order of behaviors and subsequently define the partial order for combinations of behaviors. Finally, we provide the definition of the graph that will be used in subsequent sections, which includes the 'separate behavior graph', the 'behavior combination graph', and our 'partial order recommendation graph (POG)'.", "2.1 Notations and Problem Definition": "Notations . We use U , I , B , and C to represent the sets of users, items, behaviors, and behavior combination set, respectively. Here, \ud835\udc40 represents the number of users, \ud835\udc41 represents the number of items, \ud835\udc3e represents the number of behavior categories, and \ud835\udc3b represents the number of behavior combinations. Given R as the set of all interactions of all behaviors, R \ud835\udc58 denotes the interactions of the \ud835\udc58 -th behavior. Then, describing from the behavior aspect, for each behavior, we have a matrix \ud835\udc79 \ud835\udc58 to describe the interaction of the \ud835\udc58 -th behavior. Specifically, \ud835\udc79 \ud835\udc58 \ud835\udc62\ud835\udc56 = 1 if user \ud835\udc62 and item \ud835\udc56 have the \ud835\udc58 -th behavior, and \ud835\udc79 \ud835\udc58 \ud835\udc62\ud835\udc56 = 0 if user \ud835\udc62 and item \ud835\udc56 do not have the \ud835\udc58 -th behavior. Describing from the users and item interaction aspect, \ud835\udc69 \ud835\udc62\ud835\udc56 = { \ud835\udc4f \ud835\udc62\ud835\udc56, 1 , . . . , \ud835\udc4f \ud835\udc62\ud835\udc56,\ud835\udc3e \ud835\udc62\ud835\udc56 } denotes the set of behaviors between user \ud835\udc62 and item \ud835\udc56 , and \ud835\udc3e \ud835\udc62\ud835\udc56 denotes the number of behaviors between user \ud835\udc62 and item \ud835\udc56 , where \ud835\udc4f \ud835\udc62\ud835\udc56, 1 , . . . , \ud835\udc4f \ud835\udc62\ud835\udc56,\ud835\udc3e \ud835\udc62\ud835\udc56 \u2208 B , and \ud835\udc69 \ud835\udc62\ud835\udc56 is an element of the behavior combination set C . Multi-Behavior Collaborative Filtering . The ultimate objective of the multi-behavior (embedding-based) collaborative filtering [18, 19, 46] model is to acquire a single representation embedding for each user and item, denoted as \ud835\udc6c U and \ud835\udc6c I . On a micro level, we utilize \ud835\udc86 \ud835\udc62 and \ud835\udc86 \ud835\udc56 to represent the trained embedding vectors for user \ud835\udc62 \u2208 U and item \ud835\udc56 \u2208 I . During the inference step, the relationship between a given user and item pair can be calculated by multiplying their embeddings, \u02c6 \ud835\udc4c \ud835\udc62\ud835\udc56 = \ud835\udc86 \u22a4 \ud835\udc62 \u00b7 \ud835\udc86 \ud835\udc56 . Subsequently, for any given user, the online recommender system will rank all the items to filter the most relevant ones. The filtered items for user \ud835\udc62 can be formally defined as, where \ud835\udc41 top represents the hyperparameter that controls the number of filtered items. During the evaluation process, the recommender system assesses the recommendation performance of all behaviors based on \u02c6 Y \ud835\udc62 .", "2.2 Definition of Behavior Relations": "Partial order of Behaviors . The purpose of proposing a partial order is to address situations where the recommender system cannot determine the order of two or more behaviors. For example, consider the comparison of 'favorite', 'share', and 'adding cart'. Previously, the order of behavior definitions would typically treat 'favorite', 'share', and 'adding cart' as the same behavior, such as 'indirect behavior', without being able to distinguish between different behaviors. On the other hand, our proposed partial order of behaviors can accommodate ambiguous orders. Definition 1 ( Partial Order of Behaviors ) . We define a binary relation \u2264 \ud835\udc4f on behavior set B , such that for all behaviors \ud835\udc65,\ud835\udc66, \ud835\udc67 \u2208 B , the following conditions are satisfied: \u00b7 Reflexivity: For every \ud835\udc65 \u2208 B , \ud835\udc65 \u2264 \ud835\udc4f \ud835\udc65 . \u00b7 Anti-symmetry: For all \ud835\udc65,\ud835\udc66 \u2208 B , if \ud835\udc65 \u2264 \ud835\udc4f \ud835\udc66 and \ud835\udc66 \u2264 \ud835\udc4f \ud835\udc65 , then \ud835\udc65 = \ud835\udc66 . \u00b7 Transitivity: For all \ud835\udc65,\ud835\udc66, \ud835\udc67 \u2208 B , if \ud835\udc65 \u2264 \ud835\udc4f \ud835\udc66 and \ud835\udc66 \u2264 \ud835\udc4f \ud835\udc67 , then \ud835\udc65 \u2264 \ud835\udc4f \ud835\udc67 . After the definition of the partial order of behaviors, the above example can be expressed as the following relation: \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58 \u2264 \ud835\udc4f \ud835\udc60\u210e\ud835\udc4e\ud835\udc5f\ud835\udc52, \ud835\udc53 \ud835\udc4e\ud835\udc63\ud835\udc5c\ud835\udc5f\ud835\udc56\ud835\udc61\ud835\udc52, \ud835\udc4e\ud835\udc51\ud835\udc51\ud835\udc56\ud835\udc5b\ud835\udc54 \ud835\udc50\ud835\udc4e\ud835\udc5f\ud835\udc61 \u2264 \ud835\udc4f \ud835\udc4f\ud835\udc62\ud835\udc66, where ' \ud835\udc60\u210e\ud835\udc4e\ud835\udc5f\ud835\udc52, \ud835\udc53 \ud835\udc4e\ud835\udc63\ud835\udc5c\ud835\udc5f\ud835\udc56\ud835\udc61\ud835\udc52, \ud835\udc4e\ud835\udc51\ud835\udc51\ud835\udc56\ud835\udc5b\ud835\udc54 \ud835\udc50\ud835\udc4e\ud835\udc5f\ud835\udc61 ' can be called the incomparable relationship in the definition of partial order. Rank Functions of Behaviors . By defining the partial order of behaviors, we can establish the partial order of behavior combinations based on the nature of the partial order set. To facilitate subsequent numerical computations, we also need to introduce the concept of graded partial order of behaviors. Definition 2 ( Graded Partial Order of Behavior ) . The graded partial order of behavior is defined as a partial order set (B , \u2264 \ud835\udc4f ) , augmented with a rank function \ud835\udf0c \ud835\udc4f : B \u2192 N + , where N + represents the set of positive natural numbers. The function \ud835\udf0c \ud835\udc4f satisfies the following conditions: \u00b7 Order-Preserving : For all \ud835\udc65,\ud835\udc66 \u2208 B , if \ud835\udc65 \u2264 \ud835\udc4f \ud835\udc66 , then \ud835\udf0c \ud835\udc4f ( \ud835\udc65 ) \u2264 \ud835\udf0c \ud835\udc4f ( \ud835\udc66 ) . \u00b7 Covering Condition : For all \ud835\udc65,\ud835\udc66 \u2208 B , if \ud835\udc66 covers \ud835\udc65 (i.e., there is no \ud835\udc67 \u2208 B such that \ud835\udc65 \u2264 \ud835\udc4f \ud835\udc67 \u2264 \ud835\udc4f \ud835\udc66, and \ud835\udc67 \u2260 \ud835\udc65, \ud835\udc67 \u2260 \ud835\udc66 ), then \ud835\udf0c \ud835\udc4f ( \ud835\udc66 ) = \ud835\udf0c \ud835\udc4f ( \ud835\udc65 ) + 1. With the definition of a graded partial order of behavior, any arbitrary partial order of behaviors can be represented by a corresponding positive integer. In subsection A.1, we provide the proof of completeness for the grade partial order of behavior combinations to showcase the generality of our definition.", "2.3 Definition of Graphs": "In this subsection, we formally define the graphs that will be used in the proceeding contents, which are also presented in Figure 2. We begin by discussing the separate behavior graph utilized in related works. Then, we propose the behavior combination graph to depict all combinations of behaviors in a single graph. Finally, we present the partial order graph to assign a rank value to each combination. Separate Behavior Graphs. Separate behavior graphs utilize \ud835\udc3e different graphs to describe each users' behavior, namely G \ud835\udc60\ud835\udc52\ud835\udc5d = {G 1 , \u00b7 \u00b7 \u00b7 , G \ud835\udc3e } . For different behaviors \ud835\udc58 , we have corresponding historical interaction information R \ud835\udc58 between users and items. Therefore, we can represent the corresponding behavior graph of behavior \ud835\udc58 as G \ud835\udc58 = (U , I , R \ud835\udc58 ) . Besides, we utilize \ud835\udc79 \ud835\udc58 to denote the interaction matrix of \ud835\udc58 -th behavior between users and items. Behavior Combination Graph. The behavior combination graph's edges describe the combined behavior situations \ud835\udc69 \ud835\udc62\ud835\udc56 , representing the set of behaviors occurring between user \ud835\udc62 and item \ud835\udc56 . For instance, if user \ud835\udc62 clicks and buys item \ud835\udc56 , then the edge between user \ud835\udc62 and item \ud835\udc56 is \ud835\udc69 \ud835\udc62\ud835\udc56 = { \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58, \ud835\udc4f\ud835\udc62\ud835\udc66 } . In this context, we define the behavior combination graph as G \ud835\udc50\ud835\udc5c\ud835\udc5a = (U , I , R) . Partial Order Recommendation Graph. Since the edges in the behavior combination graph represent discrete set values that cannot be ordered as continuous values, we utilize the rank function in Definition 2 to convert these discrete sets into ordered sets. We refer to this graph as a behavior combination partial order graph or simply a Partial Order Recommendation Graph (POG) . Partial Order Graph Separate Behavior Graphs Behavior Combination Graph CFB Click Graph (C) CB F C CF FB C 5 2 1 3 6 1 Favor Graph (F) Buy Graph (B) User Item Behavior Interaction Step1 Step2 Formally, it is defined as G po = (U , I , \ud835\udf0c \ud835\udc50 (R)) , where \ud835\udf0c \ud835\udc50 (\u00b7) denotes the rank function to convert the behavior combinations to integers. \ud835\udc79 denotes the interaction matrix of the partial order graph between users and items.", "3 METHODOLOGY": "In this section, we begin by explaining the process of generating the Partial Order Recommendation Graph (POG) from the original separate behavior graphs. Subsequently, we delve into the graph convolution on the POG. Lastly, we provide the formula for the partial order BPR loss for multi-behavior recommendation.", "3.1 Construction of POG": "The construction of POG involves one predefinition and one converting step. In the predefinition step, the partial order of behaviors and the partial order of behavior combinations are defined. As depicted in Figure 2, once the orders are defined, separate behavior graphs can be transformed into a behavior combination graph, and subsequently into the partial order recommendation graph. 3.1.1 Predefinition. As defined in Definition 1, exports from recommender systems can first define the partial order of behaviors in a customized mode. As shown in Figure 2, considering three behaviors B = { \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58, \ud835\udc53 \ud835\udc4e\ud835\udc63\ud835\udc5c\ud835\udc5f, \ud835\udc4f\ud835\udc62\ud835\udc66 } , their partial order \u2264 \ud835\udc4f can be defined as ' \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58 \u2264 \ud835\udc4f \ud835\udc53 \ud835\udc4e\ud835\udc63\ud835\udc5c\ud835\udc5f \u2264 \ud835\udc4f \ud835\udc4f\ud835\udc62\ud835\udc66 '. Then, with Definition 2, we can define the rank function \ud835\udf0c \ud835\udc50 to map any behavior combination C \ud835\udc56 (subset of the behavior set B ) to an integer. Specifically, the rank of each set can be defined using the following binary comparison strategy \u2264 \ud835\udc50 : Definition 3 ( Behavior Combination Binary Relation ) . We define a new binary relation \u2264 \ud835\udc50 between C \ud835\udc56 and C \ud835\udc57 . C \ud835\udc56 and C \ud835\udc57 represent the behavior combination. For convenience, we define \ud835\udc53 ( \ud835\udc58, C \ud835\udc56 ) as the function that returns the number of \ud835\udc58 -ranked behavior ( \ud835\udf0c \ud835\udc4f ( \ud835\udc4f \ud835\udc60 ) = \ud835\udc58 ) in C \ud835\udc56 . \ud835\udc53 ( \ud835\udc58, C \ud835\udc56 ) can be formally defined as \ud835\udc53 ( \ud835\udc58, C \ud835\udc56 ) = |{ \ud835\udc4f \ud835\udc60 | \ud835\udf0c \ud835\udc4f ( \ud835\udc4f \ud835\udc60 ) = \ud835\udc58, \ud835\udc4f \ud835\udc60 \u2208 C \ud835\udc56 }| , where | \u00b7 | denotes the number count function. The relation between behavior combinations can be computed in the following recursion formula: (1) Equality Check: If C \ud835\udc56 = C \ud835\udc57 , then C \ud835\udc56 \u2264 \ud835\udc50 C \ud835\udc57 ; otherwise, let \ud835\udc58 be the max value of \ud835\udf0c \ud835\udc4f , and proceed to the next step. (2) Behavior Intensity Count Comparison: If \ud835\udc53 ( \ud835\udc58, C \ud835\udc56 ) < \ud835\udc53 ( \ud835\udc58, C \ud835\udc57 ) (or \ud835\udc53 ( \ud835\udc58, C \ud835\udc57 ) < \ud835\udc53 ( \ud835\udc58, C \ud835\udc56 ) ), then C \ud835\udc56 \u2264 \ud835\udc50 C \ud835\udc57 (or C \ud835\udc57 \u2264 \ud835\udc50 C \ud835\udc56 ); otherwise, proceed to the next step. (3) Decrease Intensity: Decrease \ud835\udc58 by 1 (i.e., \ud835\udc58 = \ud835\udc58 -1) and repeat from step 2 until \ud835\udc58 = 1. (4) Incomparability Determination: If \ud835\udc58 = 1 and \ud835\udc53 ( \ud835\udc58, C \ud835\udc56 ) = \ud835\udc53 ( \ud835\udc58, C \ud835\udc57 ) , then C \ud835\udc56 and C \ud835\udc57 are considered incomparable. With the above definition of 'Behavior Combination Binary Relation', we have the following corollary to demonstrate that the behavior combination set C can also have a rank function to map any given behavior combination to an integer: Corollary 1. The set (C , \u2264 \ud835\udc50 ) , when equipped with a rank function \ud835\udf0c \ud835\udc50 : C \u2192 N + , constitutes a graded partial order set. A detailed proof of Corollary 1, under complex situations, can be found in Appendix A.1. Rank function example. Figure 2 presents a specific example of a rank function. For convenience, we use the abbreviations 'B', 'F', and 'C' to represent 'buy', 'favor', and 'click' respectively in the presentation of the rank function. Given the partial order set and Definition 3, the rank function of the partial order recommendation graph can be defined as follows: \ud835\udf0c \ud835\udc50 ({ C, F, B }) = 7, \ud835\udf0c \ud835\udc50 ({ F, B }) = 6, \ud835\udf0c \ud835\udc50 ({ C, B }) = 5, \ud835\udf0c \ud835\udc50 ({ B }) = 4, \ud835\udf0c \ud835\udc50 ({ C, F }) = 3, \ud835\udf0c \ud835\udc50 ({ F }) = 2, \ud835\udf0c \ud835\udc50 ({ C }) = 1. By examining the rank function, we can observe that 'buy' is the most important behavior, and therefore, combinations that include 'buy' have a higher rank than those without it. Furthermore, based on the comparison of the most important behavior 'buy', { B, F } has a higher rank than { B, C } because 'favor' is considered more important than 'click'. 3.1.2 POG Converting. Figure 2 illustrates the entire process of converting the graph from separate behavior graphs to the behavior combination graph and then to the partial order recommendation graph. In summary, the behavior combination graph combines all the edges from the separate behavior graphs, where each edge represents a set of behaviors between a specific user and item pair. Afterward, the partial order recommendation graph assigns an integer weight to the set of behaviors, resulting in a unified weighted graph. Specifically, given the definition of the behavior combination between user \ud835\udc62 and item \ud835\udc56 as \ud835\udc69 \ud835\udc62\ud835\udc56 and the rank function \ud835\udf0c \ud835\udc50 (\u00b7) , then the interaction matrix of the partial order recommendation graph can be defined as: where \ud835\udf0f > 0 represents the temperature coefficient [4, 42] used to adjust the importance weight of various behavior combinations. When \ud835\udf0f is increased, the distance between behavior combinations also increases, while decreasing \ud835\udf0f results in a smaller distance between combinations. If \ud835\udf0f = 0, the partial order interaction matrix assigns a value of 1 to all interacting user-item pairs, indicating that all behavior combinations are considered equally important.", "3.2 Partial Order Graph Convolutional Networks": "In contrast to GHCF [6], MB-CGCN [12], and IMGCF [64], POGCN train a single graph-based CF embedding on the POG. In this section, we first present POGCN in matrix format and then provide the message passing formula to enhance its applicability in the industry. For any given user \ud835\udc62 and item \ud835\udc56 , we first initialized the original embedding vectors \ud835\udc86 ( 0 ) \ud835\udc62 , \ud835\udc86 ( 0 ) \ud835\udc56 \u2208 R \ud835\udc51 , where \ud835\udc51 represents the dimension of the vectors. Then we have an original embedding matrix for all users and items: \ud835\udc6c ( 0 ) = [ \ud835\udc86 ( 0 ) \ud835\udc62 1 , . . . , \ud835\udc86 ( 0 ) \ud835\udc62 \ud835\udc40 , \ud835\udc86 ( 0 ) \ud835\udc56 1 , . . . , \ud835\udc86 ( 0 ) \ud835\udc56 \ud835\udc41 ] \ud835\udc47 . Matrix Form . Given the interaction matrix of partial order recommendation graph \ud835\udc79 , we extend the interaction matrix to define the partial order adjacent matrix: then we are able to obtain the partial order graph convolution formula as: where \ud835\udc6b \u2208 R ( \ud835\udc40 + \ud835\udc41 ) \u00d7 ( \ud835\udc40 + \ud835\udc41 ) is a degree matrix, and \ud835\udc6b \ud835\udc56\ud835\udc56 = \u02dd \ud835\udc57 \ud835\udc68 \ud835\udc56 \ud835\udc57 , which denotes the sum of \ud835\udc56 -th row value of the partial order adjacent matrix \ud835\udc68 . With the above definition, the final partial order embedding matrix can be computed as follows: After the graph convolution, POGCN will naturally get a single CF embedding to achieve the CF task defined in EQ. (1). Message Passing Form . The partial order recommendation graph can also be done in a neighbor-wise message passing form. Specifically, the \ud835\udc59 -th message passing of user \ud835\udc62 and item \ud835\udc56 can be given as: where N \ud835\udc62 and N \ud835\udc56 represent the sets of neighboring nodes for user \ud835\udc62 and item \ud835\udc56 , respectively. \u02dd \ud835\udc61 \ud835\udc79 \ud835\udc62\ud835\udc61 and \u02dd \ud835\udc61 \ud835\udc79 \ud835\udc61\ud835\udc56 are the sums of the \ud835\udc62 -th row and the \ud835\udc56 -th column in the partial order interaction matrix \ud835\udc79 , respectively. \ud835\udc79 \ud835\udc62\ud835\udc56 \u221a \u02dd \ud835\udc61 \ud835\udc79 \ud835\udc62\ud835\udc61 \u221a \u02dd \ud835\udc61 \ud835\udc79 \ud835\udc61\ud835\udc56 is the Laplace normalization of message passing in order to avoid numerical instabilities and exploding/vanishing gradients [26]. After performing \ud835\udc3f rounds of propagation, we take the average of the obtained partial order embeddings at each layer to obtain the final representation: where \ud835\udc86 \ud835\udc62 and \ud835\udc86 \ud835\udc56 represent the final POGCN embedding of user \ud835\udc62 and item \ud835\udc56 respectively.", "3.3 Partial Order Training Strategy": "Bayesian Personalized Ranking (BPR) has been extensively applied in collaborative filtering. Traditional BPR mainly concentrates on training with a single behavior. In this subsection, we introduce an extension called partial order BPR, which aims to achieve efficient and effective multi-behavior collaborative filtering. Traditional Multi-behavior BPR . Intuitively, one traditional way to combine the BPR loss for multiple behaviors is to apply BPR separately for each behavior and then assign different weights to each behavior. This can be represented as follows: where \ud835\udc79 \ud835\udc58 \ud835\udc62\ud835\udc56 = 1 indicates that user \ud835\udc62 and item \ud835\udc56 have the \ud835\udc58 -th behavior, while \ud835\udc79 \ud835\udc58 \ud835\udc62\ud835\udc57 = 0 indicates that user \ud835\udc62 and item \ud835\udc57 do not have the \ud835\udc58 -th behavior. \ud835\udefc \ud835\udc58 denotes the weight of the \ud835\udc58 -th behavior. However, the traditional multi-behavior BPR solution has the following limitations: 1. High training cost : Performing BPR training requires computing the embedding for one user and two items, and then performing backpropagation. Therefore, performing traditional multi-behavior BPR will incorporate \ud835\udc3e times of computational cost of single-behavior BPR, thus increasing the computational complexity. 2. Manual weighting : In traditional solutions, experts have to manually assign the weight, which cannot automatically adapt according to the importance of behavior combinations. Our POBPR . To overcome these challenges, we propose leveraging a Multinomial Distribution [35] \ud835\udc43 (C) = \ud835\udc43 ( \ud835\udc5d 1 , \u00b7 \u00b7 \u00b7 , \ud835\udc5d \ud835\udc3b ) for all \ud835\udc3b possible behavior combinations, allowing for the sampling of combinations based on their relevance and frequency. Specifically, for any given behavior combination C \u210e , the sampling probability is determined as follows: where \ud835\udc5b\ud835\udc62\ud835\udc5a (C \ud835\udc57 ) counts the occurrences of each behavior combination C \ud835\udc57 , and \ud835\udefe is a temperature coefficient [4, 42] that moderates the influence of the rank value of each behavior combination. With the above definition of the categorical distribution, we can provide the complete formula for the POBPR loss as follows: \u00b7 RQ1: Does POGCN outperform current state-of-the-art recommendation models? \u00b7 RQ2: Whataretheeffects of different components in POGCN? \u00b7 RQ3: How do key hyper-parameters impact POGCN? \u00b7 RQ4: How does POGCN perform on real-world industrial recommender systems?", "4.1 Experimental Setup": "4.1.1 Datasets. We conduct comprehensive experiments on three widely used benchmark datasets Beibei [14], Taobao [69], and Tenrec [60] including both e-commerce and content recommendation scenarios for offline evaluation to verify the effectiveness and universality of POGCN. The statistics of these datasets are shown in Table 2. In order to avoid the cold start situation of interaction, following previous works [18, 46], we filter out at least 10 interactive items and users to conduct the experiments. Dataset statistics are demonstrated in Table 2. We further describe the details of these datasets in Appendix B.1. \uf8f0 \uf8fb where E C \u210e \u223c \ud835\udc43 ( C) represents the expectation over the distribution of behavior combinations, D + \u210e denotes the sets of positive user-item pairs under the behavior combination C \u210e , and D \ud835\udc62 denotes the set of negative items under all interactions of user \ud835\udc62 . We further demonstrate the equivalence between the POBPR and the original separate formula of multi-behavior in terms of the maximum likelihood in Appendix A.2.", "4 EXPERIMENTS": "In this section, we conduct both offline and online experiments, aiming to answer the following research questions. 4.1.2 Compared Baselines. To comprehensively verify the effectiveness of POGCN. We compare our proposed POGCN with six multi-behavior CF models, three multi-task recommendation models, and four single-behavior CF models. (I) Multi-behavior CF models : MC-BPR [32], NMTR [14], GHCF [6], MB-GMN [53], MBCGCN [12], and IMGCF [64]. (II) Multi-task recommendation models : ESMM [34], MMoE [33], and PLE [41]. (III) Single-behavior CFmodels : MF-BPR [36], NCF [19], NGCF [46], and LightGCN [18]. The details of these baseline models are left in Appendix B.2. 4.1.3 Implementation Details. For all models, the embedding size is fixed to 64 and the embedding parameters are initialized with the normal distribution. The learning rate of POGCN is searched from {1 \u00d7 10 -3 , 5 \u00d7 10 -4 , 1 \u00d7 10 -4 }, the regularization term is searched from {1 \u00d7 10 -4 , 5 \u00d7 10 -5 , 1 \u00d7 10 -5 }, \ud835\udf0f is searched from [0.2, 1.0] in Taobao and Tenrec with a step of 0.2, and searched from [1.0, 5.0] in Beibei with a step of 1.0, \ud835\udefe is searched from [0.2, 2.0] with a step of 0.2. The batch size is set to 1024 for all models and the Adam optimizer [25] is used. For multi-behavior CF models, we adopt the partial order relation ' click \u2264 cart \u2264 buy ', ' click \u2264 cart, favor \u2264 buy ', and ' click \u2264 like \u2264 share, follow ' for Beibei, Taobao, and Tenrec. For multi-task recommendation models, due to their specific designs for prediction tasks, we replace their backbone with LightGCN to enhance their performance in CF tasks. 4.1.4 Evaluation Metrics. Our evaluation adopts a full-ranking evaluation approach, following the state-of-the-art studies [18, 28, 46]. To evaluate the effectiveness of top-ranked articles, we employ Recall@20 and NDCG@20 as our primary metrics for each type of behavior. In order to facilitate the overall comparison across all types of behaviors, we further adopt the mean metric performance of all behaviors for evaluation. Note that we ran all the experiments five times with different random seeds and reported the average results to prevent extreme cases.", "4.2 Main Results (RQ1)": "In this subsection, we compare our proposed POGCN with stateof-the-art baseline models on the three experimental datasets. The comparison results with multi-behavior CF and CTR models are reported in Table 1, and the comparison results with single-behavior CF models are illustrated in Table 3. From the results, we can have the following observations: POGCN can achieve significant improvements across all types of behaviors over state-of-the-art methods. From Table 1, we observe that POGCN achieves the highest Recall and NDCG performance across all types of behaviors than both current multi-behavior CF models and multi-behavior recommendation models, with mean NDCG improvements of 15.80%, 7.49%, and 35.74% on Beibei, Taobao, and Tenrec respectively. Furthermore, from Table 3, we can find that POGCN can also generally obtain the best performance through simultaneous multi-behavior learning than single-behavior models with separate training for each behavior. The results verify that POGCN can get better multi-behavior CF recommendation results. The multi-behavior CF models will negatively affect the performance on click behavior. Comparing the multi-behavior CF models in Table 1 and the traditional single-behavior CF models in Table 3, we can find that the multi-behavior CF models can obtain relatively better results in multiple behaviors recommendation, while they have a performance drop in the click behavior recommendation than the traditional single-behavior CF models. Single-behavior CF models only perform effectively on the click behavior, yielding suboptimal results on other behaviors because they lack training on such data. The multi-behavior CTR recommendation methods are unsuitable for CF tasks. From the results, we can find that the state-of-the-art multi-behavior recommendation models in CTR scenarios have suboptimal performance in CF scenarios, even if they are equipped with the state-of-the-art LightGCN backbone. Therefore, it is meaningful to design a multi-behavior CF method with our proposed POG and POGCN, which can achieve the best Click Cart Buy 0.06 0.09 0.12 0.15 0.18 0.21 Recall@20-Beibei Click Cart Buy 0.06 0.07 0.08 0.09 0.10 0.11 NDCG@20-Beibei Click Cart Favor Buy 0.02 0.03 0.04 0.05 0.06 0.07 Recall@20-Taobao Click Cart Favor Buy 0.010 0.016 0.022 0.028 0.034 NDCG@20-Taobao w/o PO-all w/o POG w/o POBPR POGCN performance for multiple behavior recommendations simultaneously in the collaborative filtering setting. Therefore, it is crucial to propose a multi-behavior model in the CF scenario, which is the motivation of our proposed POGCN.", "4.3 Ablation Study (RQ2)": "In this section, we investigate the effectiveness of the designed components in our method with three model variants: (1) w/o POall , which remove all partial order components. We substitute the POG with the interaction graph and treat all interactions with same weight. We also substitute POBPR with traditional BPR sampling. (2) w/o POG , which treats all nodes in the graph with equal weight during graph convolution. (3) w/o POBPR , which utilize traditional BPR sampling instead of POBPR. We perform ablation studies on Beibei and Taobao datasets, and the outcomes are presented in Figure 3. Based on the figure, we make the following observations: Partial order relation is important for multi-behavior CF recommendation . Substituting the POG and POBPR with the interaction graph and traditional BPR sampling will significantly decrease the CF recommendation performance on all behaviors. This phenomenon verifies that Partial order relation provides a better description of multiple behaviors. POG and POBPR are necessary for multi-behavior CF recommendation . From Figure 3, we observe that both POG and POBPR have a positive impact on the performance of multiple behaviors, indicating the importance of constructing customized convolution and training structures.", "4.4 Parameter Study (RQ3)": "In this subsection, we aim to study the impact of key hyper-parameters \ud835\udf0f and \ud835\udc5f in POGCN. 4.4.1 Effect of POG Parameter \ud835\udf0f . Weinvestigate the effect of the parameter \ud835\udf0f of the importance degree between different behaviors with the range of [1.0, 5.0] with a step size of 1.0 for Beibei, and with the range of [0.2, 1.0] with a step size of 0.2 for Taobao. As illustrated in the upper side of Figure 4, the best value of \ud835\udf0f for Beibei is 3.0, while the best \ud835\udf0f value for Taobao is 0.2. Therefore, the 1 2 3 4 5 0.082 0.083 0.084 0.085 0.086 0.087 0.088 NDCG Beibei 0.2 0.4 0.6 0.8 1.0 0.0237 0.0238 0.0239 0.0240 Taobao 0.5 1.0 1.5 2.0 0.080 0.082 0.084 0.086 0.088 0.090 NDCG 0.5 1.0 1.5 2.0 0.0234 0.0236 0.0238 0.0240 0.0242 selection of parameter \ud835\udf0f should be considered carefully for better POGCN performance. 4.4.2 Effect of Sampling Parameter \ud835\udefe . We also evaluate the impact of different partial order sampling values of \ud835\udefe , with the range of [0.2, 2.0] with a step size of 0.2. From the second row of Figure 4, we can find that the too-small \ud835\udefe value will lead to too similar between different behaviors and lead to suboptimal performance. The selection of the \ud835\udefe value is contingent upon the specific characteristics of each dataset, necessitating a careful choice to optimize performance. For instance, an \ud835\udefe value of 1.4 is well-suited for the Beibei dataset, whereas a lower value of 0.6 is preferable for the Taobao dataset.", "4.5 Online Evaluation (RQ4)": "Weconducted an online A/B test on the homepage of Alibaba. In this experiment, our model served as a recall model, replacing the existing online best-performed graph-based recall model-LightGCN. In addition to clicking behavior, POGCN also considers three other valuable behaviors: 'adding to cart', 'favoring', and 'buying'. Table 4 presents the average relative performance variation over a successive month for about 1 billion users and 0.2 billion items. From the results, we observe that POGCN shows performance improvements of + 1 . 69% in CVR, + 2 . 84% in GMV, and + 1 . 62% in StayTime compared to LightGCN. This indicates that considering deep behaviors such as 'adding to cart', 'favor', and 'buy' can enhance the interaction depth and recommendation conversion, thereby increasing the intent of purchasing and viewing more items. Besides, equipped with POGCN, the recommender system is able to provide more accurate recommendations to users, leading to a + 2 . 83% increase in PCTR and + 2 . 02% improvement in UCTR. POGCN achieves this through the simultaneous optimization of multiple types of behaviors, thereby enhancing user willingness to click more recommended items. Therefore, all the A/B testing results validate that \ud835\udc43\ud835\udc42\ud835\udc3a and the equipped \ud835\udc43\ud835\udc42\ud835\udc3a\ud835\udc36\ud835\udc41 are more suitable than the state-of-the-art online graph collaborative filtering models.", "5 RELATED WORKS": "", "5.1 Graph Collaborative Filtering": "In recent years, graph neural networks (GNNs) have achieved superior performance on a wide range of relation modeling tasks [11, 43, 44, 63], such as link prediction [2, 40, 51, 61], node classification [9, 17, 26, 37], and anomaly detection [3, 54, 55, 62]. As a mainstream link prediction task, there have been extensive works for graph collaborative filtering based on the power of GNNs [7, 15]. Representatively, NGCF [46] employs a GNN propagation mechanism that bridges users to items and users to users, extracting graph embeddings for each entity. Moreover, LightGCN[18] simplifies the approach by omitting the non-linear parametered operators of NGCF and instead, aggregates the layer-wise embeddings through a weighted summation. Recent studies have further incorporated data augmentation and self-supervised learning techniques to bolster the performance of graph collaborative filtering models [15, 59]. Notably, SGL [49] pioneers the integration of self-supervised learning on the user-item graph by generating diverse node perspectives. It leverages contrastive learning to align these multiple views of identical nodes, while simultaneously reducing the alignment with nodes that are distinct. NCL [30] further refines the neighbor set by incorporating semantic neighbors, guided by the principles of contrastive learning. Meanwhile, SimGCL [58] offers a streamlined yet potent graph contrastive learning approach through the strategic elimination of extraneous augmentations. However, these models mainly focus on the scenario of a single type of interaction behavior, without the consideration of how to use multiple interaction behaviors for the recommendation.", "5.2 Multi-Behavior Collaborative Filtering": "Collaborative filtering recommendation was originally designed for single-behavior recommendations [22, 27, 39]. Examples of such recommendations include sequence-based [10, 21, 56, 66] and graphbased [18, 29, 46, 68]. However, in real-world scenarios, users and items exhibit multiple interaction behaviors [20], such as clicks, purchases, or ratings, instead of focusing solely on a single behavior like clicks [12, 24, 67]. Recent efforts for multi-behavior collaborative filtering mainly focus on utilizing information from multiple types of behaviors for user modeling to enhance recommendation performance for sparse target behaviors, such as using data from clicks, carts, and purchases to model interactions in the purchase behavior domain [47, 48, 52]. Representatively, NMTR [14] incorporates a multi-task learning framework that acknowledges the cascading relationship among different user behaviors, allowing for more accurate modeling of user preferences based on a comprehensive set of interactions for target behavior recommendations. Recently, MB-CGCN [12] further employs a sequence of GCN blocks that correspond to different user behaviors to capture the complex dependencies between different user behaviors like views, clicks, and purchases. It enhances recommendation performance by exploiting the cascading nature of these behaviors, where each behavior's embeddings are transformed and used as input for the next behavior's embedding learning. Nevertheless, these studies mainly focus on utilizing all types of behaviors to enhance the target behavior performance, while the simultaneous optimization of multiple behaviors has been highly neglected, resulting in poor performance for non-target behaviors.", "5.3 Multi-Task Recommendation": "Multi-task recommendation aims to effectively model relationships between different recommendation tasks in a multi-task learning framework [13, 31, 57, 65]. These models have achieved state-ofthe-art performance in the ranking and prediction stage of recommender systems, such as simultaneously predicting the clickthrough rate (CTR) and conversion rate (CVR) [1, 34, 38]. The most common method of multi-task learning is Shared Bottom [5], which uses the coupled input to predict each task individually. ESMM [34] utilizes a novel structure that models CVR over the entire space of impressions by employing auxiliary tasks of predicting click-through rate and click-through&conversion rate. MoE [23], MMoE [33] utilizes a mixture of experts architecture, where each \"expert\" is a specialized network in a shared structure, and multiple gating networks then learn to weigh the contribution of each expert for a given task. Further, PLE [41] separates shared and task-specific components, employing multi-level experts and gating networks, and introducing a novel progressive separation routing mechanism. This allows PLE to extract deeper, more relevant knowledge for each specific task while mitigating harmful interference between tasks. However, these models are mainly designed for the prediction stage of recommendations. As the previous analyses, they lack the capability to be adopted in the collaborative filtering stage.", "6 CONCLUSION": "In this paper, we study the seesaw recommendation problem in current multi-behavior CF models. To this end, we introduce the Partial Order Recommendation Graphs (POG) and Partial Order Graph Convolutional Networks (POGCN) , which has significantly advanced the field of multi-behavior collaborative filtering for recommender systems. POGCN offers an update in the infrastructure of multibehavior CF tasks and presents a groundbreaking solution to the longstanding issue of effectively representing diverse user interactions within a single CF framework. Demonstrating superior performance in both offline experiments on three benchmark datasets and online A/B tests on the industrial system, and practically serving over a billion users in a major shopping platform, POGCN not only elevates the capability of recommendation research but also paves the way for future research and optimizations in the realm of large-scale multi-behavior recommender systems.", "ACKNOWLEDGMENTS": "This work was supported in part by the National Natural Science Foundation of China (Grant No. 62272200, U22A2095, 61932010).", "REFERENCES": "[1] Yuanchen Bei, Hao Chen, Shengyuan Chen, Xiao Huang, Sheng Zhou, and Feiran Huang. 2023. Non-Recursive Cluster-Scale Graph Interacted Model for ClickThrough Rate Prediction. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management . 3748-3752. [2] Yuanchen Bei, Hao Xu, Sheng Zhou, Huixuan Chi, Haishuai Wang, Mengdi Zhang, Zhao Li, and Jiajun Bu. 2024. CPDG: A Contrastive Pre-Training Method for Dynamic Graph Neural Networks. In ICDE . [3] Yuanchen Bei, Sheng Zhou, Qiaoyu Tan, Hao Xu, Hao Chen, Zhao Li, and Jiajun Bu. 2023. Reinforcement Neighborhood Selection for Unsupervised Graph Anomaly Detection. In 2023 IEEE International Conference on Data Mining (ICDM) . IEEE, 11-20. [4] Dimitris Bertsimas and John Tsitsiklis. 1993. Simulated annealing. Statistical science 8, 1 (1993), 10-15. [5] Rich Caruana. 1997. Multitask learning. Machine learning 28 (1997), 41-75. [6] Chong Chen, Weizhi Ma, Min Zhang, Zhaowei Wang, Xiuqiang He, Chenyang Wang, Yiqun Liu, and Shaoping Ma. 2021. Graph heterogeneous multi-relational recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 35. 3958-3966. [7] Chaochao Chen, Huiwen Wu, Jiajie Su, Lingjuan Lyu, Xiaolin Zheng, and Li Wang. 2022. Differential private knowledge transfer for privacy-preserving cross-domain recommendation. In Proceedings of the ACM Web Conference 2022 . 1455-1465. [8] Hao Chen, Yuanchen Bei, Qijie Shen, Yue Xu, Sheng Zhou, Wenbing Huang, Feiran Huang, Senzhang Wang, and Xiao Huang. 2024. Macro graph neural networks for online billion-scale recommender systems. In Proceedings of the ACM on Web Conference 2024 . 3598-3608. [9] Hao Chen, Zhong Huang, Yue Xu, Zengde Deng, Feiran Huang, Peng He, and Zhoujun Li. 2022. Neighbor enhanced graph convolutional networks for node classification and recommendation. Knowledge-Based Systems 246 (2022), 108594. [10] Hao Chen, Zefan Wang, Feiran Huang, Xiao Huang, Yue Xu, Yishi Lin, Peng He, and Zhoujun Li. 2022. Generative adversarial framework for cold-start item recommendation. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval . 2565-2571. [11] Hao Chen, Yue Xu, Feiran Huang, Zengde Deng, Wenbing Huang, Senzhang Wang, Peng He, and Zhoujun Li. 2020. Label-Aware Graph Convolutional Networks. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management . 1977-1980. [12] Zhiyong Cheng, Sai Han, Fan Liu, Lei Zhu, Zan Gao, and Yuxin Peng. 2023. Multi-Behavior Recommendation with Cascading Graph Convolution Networks. In Proceedings of the ACM Web Conference 2023 . 1181-1189. [13] Michael Crawshaw. 2020. Multi-task learning with deep neural networks: A survey. arXiv preprint arXiv:2009.09796 (2020). [14] Chen Gao, Xiangnan He, Dahua Gan, Xiangning Chen, Fuli Feng, Yong Li, TatSeng Chua, and Depeng Jin. 2019. Neural multi-task recommendation from multi-behavior data. In 2019 IEEE 35th international conference on data engineering (ICDE) . IEEE, 1554-1557. [15] Chen Gao, Yu Zheng, Nian Li, Yinfeng Li, Yingrong Qin, Jinghua Piao, Yuhan Quan, Jianxin Chang, Depeng Jin, Xiangnan He, et al. 2023. A survey of graph neural networks for recommender systems: Challenges, methods, and directions. ACM Transactions on Recommender Systems 1, 1 (2023), 1-51. [16] Qingyu Guo, Fuzhen Zhuang, Chuan Qin, Hengshu Zhu, Xing Xie, Hui Xiong, and Qing He. 2020. A survey on knowledge graph-based recommender systems. IEEE Transactions on Knowledge and Data Engineering 34, 8 (2020), 3549-3568. [17] Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In Advances in Neural Information Processing Systems , Vol. 30. [18] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang. 2020. Lightgcn: Simplifying and powering graph convolution network for recommendation. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval . 639-648. [19] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web . 173-182. [20] Chao Huang. 2021. Recent Advances in Heterogeneous Relation Learning for Recommendation. In Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21 . 4442-4449. Survey Track. [21] Feiran Huang, Zefan Wang, Xiao Huang, Yufeng Qian, Zhetao Li, and Hao Chen. 2023. Aligning Distillation For Cold-Start Item Recommendation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1147-1157. [22] Feiran Huang, Zhenghang Yang, Junyi Jiang, Yuanchen Bei, Yijie Zhang, and Hao Chen. 2024. Large Language Model Interaction Simulator for Cold-Start Item Recommendation. arXiv preprint arXiv:2402.09176 (2024). [23] Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. 1991. Adaptive mixtures of local experts. Neural computation 3, 1 (1991), 79-87. [24] Bowen Jin, Chen Gao, Xiangnan He, Depeng Jin, and Yong Li. 2020. Multibehavior recommendation with graph convolutional networks. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval . 659-668. [25] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014). [26] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In International Conference on Learning Representations . [27] Yehuda Koren, Steffen Rendle, and Robert Bell. 2021. Advances in collaborative filtering. Recommender systems handbook (2021), 91-142. [28] Walid Krichene and Steffen Rendle. 2020. On sampled metrics for item recommendation. In Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining . 1748-1757. [29] Fake Lin, Ziwei Zhao, Xi Zhu, Da Zhang, Shitian Shen, Xueying Li, Tong Xu, Suojuan Zhang, and Enhong Chen. 2024. When Box Meets Graph Neural Network in Tag-aware Recommendation. arXiv preprint arXiv:2406.12020 (2024). [30] Zihan Lin, Changxin Tian, Yupeng Hou, and Wayne Xin Zhao. 2022. Improving graph collaborative filtering with neighborhood-enriched contrastive learning. In Proceedings of the ACM web conference 2022 . 2320-2329. [31] Qi Liu, Zhilong Zhou, Gangwei Jiang, Tiezheng Ge, and Defu Lian. 2023. Deep Task-specific Bottom Representation Network for Multi-Task Recommendation. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management . 1637-1646. [32] Babak Loni, Roberto Pagano, Martha Larson, and Alan Hanjalic. 2016. Bayesian personalized ranking with multi-channel user feedback. In Proceedings of the 10th ACM conference on recommender systems . 361-364. [33] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed H Chi. 2018. Modeling task relationships in multi-task learning with multi-gate mixture-ofexperts. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1930-1939. [34] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun Gai. 2018. Entire space multi-task model: An effective approach for estimating post-click conversion rate. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval . 1137-1140. [35] Kevin P Murphy. 2012. Machine learning: a probabilistic perspective . MIT press. [36] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence . 452-461. [37] Yu Rong, Wenbing Huang, Tingyang Xu, and Junzhou Huang. 2020. DropEdge: Towards Deep Graph Convolutional Networks on Node Classification. In International Conference on Learning Representations . [38] Liangcai Su, Junwei Pan, Ximei Wang, Xi Xiao, Shijie Quan, Xihua Chen, and Jie Jiang. 2024. STEM: Unleashing the Power of Embeddings for Multi-task Recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 38. 9002-9010. [39] Xiaoyuan Su and Taghi M Khoshgoftaar. 2009. A survey of collaborative filtering techniques. Advances in artificial intelligence 2009 (2009). [40] Qiaoyu Tan, Xin Zhang, Xiao Huang, Hao Chen, Jundong Li, and Xia Hu. 2023. Collaborative graph neural networks for attributed network embedding. IEEE Transactions on Knowledge and Data Engineering (2023). [41] Hongyan Tang, Junning Liu, Ming Zhao, and Xudong Gong. 2020. Progressive layered extraction (ple): A novel multi-task learning (mtl) model for personalized recommendations. In Proceedings of the 14th ACM Conference on Recommender Systems . 269-278. [42] Peter JM Van Laarhoven, Emile HL Aarts, Peter JM van Laarhoven, and Emile HL Aarts. 1987. Simulated annealing . Springer. [43] Binwu Wang, Pengkun Wang, Yudong Zhang, Xu Wang, Zhengyang Zhou, Lei Bai, and Yang Wang. 2024. Towards Dynamic Spatial-Temporal Graph Learning: A Decoupled Perspective. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 38. 9089-9097. [44] Binwu Wang, Yudong Zhang, Xu Wang, Pengkun Wang, Zhengyang Zhou, Lei Bai, and Yang Wang. 2023. Pattern expansion and consolidation on evolving graphs for continual traffic prediction. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 2223-2232. [45] Shoujin Wang, Liang Hu, Yan Wang, Xiangnan He, Quan Z. Sheng, Mehmet A. Orgun, Longbing Cao, Francesco Ricci, and Philip S. Yu. 2021. Graph Learning based Recommender Systems: A Review. In Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21 . 4644-4652. Survey Track. [46] Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural graph collaborative filtering. In Proceedings of the 42nd international ACM SIGIR conference on Research and development in Information Retrieval . 165-174. [47] Yuhao Wang, Ha Tsz Lam, Yi Wong, Ziru Liu, Xiangyu Zhao, Yichao Wang, Bo Chen, Huifeng Guo, and Ruiming Tang. 2023. Multi-Task Deep Recommender Systems: A Survey. arXiv preprint arXiv:2302.03525 (2023). [48] Wei Wei, Chao Huang, Lianghao Xia, Yong Xu, Jiashu Zhao, and Dawei Yin. 2022. Contrastive meta learning with behavior multiplicity for recommendation. In Proceedings of the fifteenth ACM international conference on web search and data mining . 1120-1128. [49] Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, and Xing Xie. 2021. Self-supervised graph learning for recommendation. In Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval . 726-735. [50] Shiwen Wu, Fei Sun, Wentao Zhang, Xu Xie, and Bin Cui. 2022. Graph neural networks in recommender systems: a survey. Comput. Surveys 55, 5 (2022), 1-37. [51] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. 2020. A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems 32, 1 (2020), 4-24. [52] Lianghao Xia, Chao Huang, Yong Xu, Peng Dai, Bo Zhang, and Liefeng Bo. 2020. Multiplex behavioral relation learning for recommendation via memory augmented transformer network. In Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval . 2397-2406. [53] Lianghao Xia, Yong Xu, Chao Huang, Peng Dai, and Liefeng Bo. 2021. Graph meta network for multi-behavior recommendation. In Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval . 757-766. [54] Chunjing Xiao, Zehua Gou, Wenxin Tai, Kunpeng Zhang, and Fan Zhou. 2023. Imputation-based Time-Series Anomaly Detection with Conditional WeightIncremental Diffusion Models. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 2742-2751. [55] Chunjing Xiao, Xovee Xu, Yue Lei, Kunpeng Zhang, Siyuan Liu, and Fan Zhou. 2023. Counterfactual graph learning for anomaly detection on attributed networks. IEEE Transactions on Knowledge and Data Engineering (2023). [56] Yue Xu, Hao Chen, Zefan Wang, Jianwen Yin, Qijie Shen, Dimin Wang, Feiran Huang, Lixiang Lai, Tao Zhuang, Junfeng Ge, and Xia Hu. 2023. Multi-Factor Sequential Re-Ranking with Perception-Aware Diversification. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 5327-5337. [57] Mingshi Yan, Zhiyong Cheng, Chen Gao, Jing Sun, Fan Liu, Fuming Sun, and Haojie Li. 2023. Cascading residual graph convolutional network for multibehavior recommendation. ACM Transactions on Information Systems (2023). [58] Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Lizhen Cui, and Quoc Viet Hung Nguyen. 2022. Are graph augmentations necessary? simple graph contrastive learning for recommendation. In Proceedings of the 45th international ACM SIGIR conference on research and development in information retrieval . 1294-1303. [59] Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Jundong Li, and Zi Huang. 2023. Self-supervised learning for recommender systems: A survey. IEEE Transactions on Knowledge and Data Engineering (2023). [60] Guanghu Yuan, Fajie Yuan, Yudong Li, Beibei Kong, Shujie Li, Lei Chen, Min Yang, Chenyun Yu, Bo Hu, Zang Li, et al. 2022. Tenrec: A Large-scale Multipurpose Benchmark Dataset for Recommender Systems. Advances in Neural Information Processing Systems 35 (2022), 11480-11493. [61] Muhan Zhang and Yixin Chen. 2018. Link prediction based on graph neural networks. Advances in neural information processing systems 31 (2018). [62] Qinggang Zhang, Junnan Dong, Keyu Duan, Xiao Huang, Yezi Liu, and Linchuan Xu. 2022. Contrastive knowledge graph error detection. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management . 2590-2599. [63] Qinggang Zhang, Junnan Dong, Qiaoyu Tan, and Xiao Huang. 2023. Integrating entity attributes for error-aware knowledge graph embedding. IEEE Transactions on Knowledge and Data Engineering (2023). [64] Yijie Zhang, Yuanchen Bei, Shiqi Yang, Hao Chen, Zhiqing Li, Lijia Chen, and Feiran Huang. 2023. Alleviating Behavior Data Imbalance for Multi-Behavior Graph Collaborative Filtering. In 2023 IEEE International Conference on Data Mining Workshops (ICDMW) . [65] Yu Zhang and Qiang Yang. 2021. A survey on multi-task learning. IEEE Transactions on Knowledge and Data Engineering 34, 12 (2021), 5586-5609. [66] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1059-1068. [67] Huachi Zhou, Jiaqi Fan, Xiao Huang, Ka Ho Li, Zhenyu Tang, and Dahai Yu. 2022. Multi-interest refinement by collaborative attributes modeling for clickthrough rate prediction. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management . 4732-4736. [68] Huachi Zhou, Qiaoyu Tan, Xiao Huang, Kaixiong Zhou, and Xiaoling Wang. 2021. Temporal augmented graph neural networks for session-based recommendations. In Proceedings of the 44th International ACM SIGIR conference on research and development in information retrieval . 1798-1802. [69] Han Zhu, Xiang Li, Pengye Zhang, Guozheng Li, Jie He, Han Li, and Kun Gai. 2018. Learning tree-based deep model for recommender systems. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 1079-1088.", "A THEORETICAL DETAILS": "", "A.1 Completeness Proof of Partial Order of Behavior Combination": "Proof. We aim to construct a rank function that maps the subsets partitioned from the set C by the binary relation \u2264 \ud835\udc50 to a positive integer, thereby establishing (C , \u2264 \ud835\udc50 ) as a graded partial order set. Define C \ud835\udc56 < \ud835\udc50 C \ud835\udc57 if C \ud835\udc56 \u2264 \ud835\udc50 C \ud835\udc57 and C \ud835\udc56 \u2260 C \ud835\udc57 . Consider an arbitrary element C \ud835\udc56 from C . Using the binary relation, we partition C into three subsets: \u00b7 \ud835\udc3f \ud835\udc50 , containing all C \ud835\udc57 such that C \ud835\udc57 < \ud835\udc50 C \ud835\udc56 , \u00b7 \ud835\udc38 \ud835\udc50 , containing all C \ud835\udc57 such that C \ud835\udc57 = C \ud835\udc56 or C \ud835\udc56 and C \ud835\udc57 are incomparable, \u00b7 \ud835\udc3a \ud835\udc50 , containing all C \ud835\udc57 such that C \ud835\udc56 < \ud835\udc50 C \ud835\udc57 . According to Definition 3, for any C \ud835\udc57 1 \u2208 \ud835\udc3f \ud835\udc50 , C \ud835\udc57 2 \u2208 \ud835\udc38 \ud835\udc50 , and C \ud835\udc57 3 \u2208 \ud835\udc3a \ud835\udc50 , it holds that C \ud835\udc57 1 < \ud835\udc50 C \ud835\udc57 2 < \ud835\udc50 C \ud835\udc57 3 . Elements in \ud835\udc38 \ud835\udc50 are considered of equal significance. This partitioning process is then recursively applied to \ud835\udc3f \ud835\udc50 and \ud835\udc3a \ud835\udc50 until these sets are empty. Ultimately, we obtain the final partition: \ud835\udc38 \ud835\udc50 1 , \ud835\udc38 \ud835\udc50 2 , . . . , \ud835\udc38 \ud835\udc50 \ud835\udc5b , satisfying C \ud835\udc57 1 < \ud835\udc50 C \ud835\udc57 2 < \ud835\udc50 \u00b7 \u00b7 \u00b7 < \ud835\udc50 C \ud835\udc57 \ud835\udc5b for any C \ud835\udc57 1 \u2208 \ud835\udc38 \ud835\udc50 1 , C \ud835\udc57 2 \u2208 \ud835\udc38 \ud835\udc50 2 , . . . , C \ud835\udc57 \ud835\udc5b \u2208 \ud835\udc38 \ud835\udc50 \ud835\udc5b . Define \ud835\udf0c \ud835\udc50 (C \ud835\udc57 \ud835\udc58 ) = \ud835\udc58 for all C \ud835\udc57 \ud835\udc58 \u2208 \ud835\udc38 \ud835\udc50 \ud835\udc58 and \ud835\udc58 = 1 , 2 , . . . , \ud835\udc5b . It is evident that (C , \u2264 \ud835\udc50 ) equipped with \ud835\udf0c \ud835\udc50 satisfies Definition 2. \u25a1", "A.2 Equivalence Explanation of POBPR": "Here, we will explain that such a distribution change is equivalent to transforming the coefficients in the case where behavior combinations are treated as multi-tasks. We have the likelihood function, following BPR [36]: where D + \u210e = {( \ud835\udc62, \ud835\udc56 )| \ud835\udc69 \ud835\udc62\ud835\udc56 = C \u210e } represent the interaction set of behavior combination C \u210e . For the sake of following discussion, we let \ud835\udc5d ( \ud835\udc56 > \ud835\udc62 \ud835\udc57 | \ud835\udf03 ) : = \ud835\udf0e ( \u02c6 \ud835\udc4c \ud835\udc62\ud835\udc56 ( \ud835\udf03 ) -\u02c6 \ud835\udc4c \ud835\udc62\ud835\udc57 ( \ud835\udf03 )) , and can get the partial order BPR loss function: where \ud835\udefc \u210e \u221d \ud835\udc43 (C \u210e ) is the coefficient of the behavior combination C \u210e task. So when we change \ud835\udefe , the coefficients in the multi-task loss function will also change equivalently.", "B EXPERIMENTAL DETAILS": "", "B.1 Dataset Details": "We adopt three publicly available datasets for offline evaluation. The detailed description of the datasets is as follows: \u00b7 Beibei 2 [14] is gathered from Beibei platform, one of China's premier e-commerce platforms specializing in baby products. It encompasses the interactions of 21,716 users and 7,977 items, with three types of user-item behaviors: click, cart, and buy. \u00b7 Taobao 3 [69] is a wide used multi-behavior dataset provided by Alibaba, one of the biggest e-commerce platforms in China. It contains the activities (including clicks, carts, favors, and buys) of 26,213 users toward 64,822 items between Nov. 2017 and Dec. 2017. \u00b7 Tenrec 4 [60] is a content recommendation dataset collected from two different feeds recommendation apps of Tencent. We utilize the video scenario subset for experiments, with 19,035 users, 15,539 items, and four types of user-item behaviors: click, like, share, and follow.", "B.2 Baseline Details": "We compare our proposed POGCN with thirteen representative state-of-the-art models into three main categories as follows: (I) Multi-behavior CF models : \u00b7 MC-BPR [32] utilizes multi-behavior weight to modulate the importance of different behaviors in the BPR loss function. \u00b7 NMTR [14] is an expansion of NCF [19] in multi-behavior recommendation, adhering to the cascade rule. \u00b7 GHCF [6] is a graph-based approach for enhancing target behavior recommendation through multi-task learning. \u00b7 MB-GMN [53] is a graph meta-learning based CF model to improve target behavior recommendations. \u00b7 MB-CGCN [12] combines multi-behavior cascade rule to enhance graph convolution networks for the target behavior recommendation. \u00b7 IMGCF [64] employs a multi-task learning paradigm for collaborative filtering on multi-behavior graphs, enhancing sparse behavior learning by leveraging information from behaviors with ample data.", "(II) Multi-task recommendation models :": "\u00b7 ESMM [34] employs a feature representation transfer learning strategy for multi-task CTR recommendations. \u00b7 MMoE [33] adapts the MoE structure to multi-task learning by sharing the expert submodels across all tasks, while also having a gating network trained to optimize each task. \u00b7 PLE [41] is a progressive layered extraction model with a novel sharing structure design for multi-task CTR recommendations.", "(III) Single-behavior CF models :": "\u00b7 MF-BPR [36] is a widely used matrix factorization strategy with the assumption that the positive items should score higher than negative ones. \u00b7 NCF [19] is a CF model that leverages a multi-layer perceptron to learn the user-item interaction function. \u00b7 NGCF [46] explicitly encodes the collaborative signal in the form of high-order connectivities by performing graph embedding propagation. \u00b7 LightGCN [18] is a simplified variant of NGCF by including only the most essential components."}
