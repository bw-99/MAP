{"Gradient Coordination for Quantifying and Maximizing Knowledge Transference in Multi-Task Learning": "Xuanhua Yang, Jianxin Zhao, Shaoguo Liu \u2217 , Liang Wang and Bo Zheng Alibaba Group, Beijing, China {xuanhua.yxh,zhaojianxin.zjx,shaoguo.lsg,liangbo.wl,bozheng}@alibaba-inc.com", "ABSTRACT": "Multi-task learning (MTL) has been widely applied in online advertising and recommender systems. To address the negative transfer issue, recent studies have proposed optimization methods that thoroughly focus on the gradient alignment of directions or magnitudes. However, since prior study has proven that both general and specific knowledge exist in the limited shared capacity, overemphasizing on gradient alignment may crowd out task-specific knowledge, and vice versa. In this paper, we propose a transference-driven approach CoGrad that adaptively maximizes knowledge transference via Co ordinated Grad ient modification. We explicitly quantify the transference as loss reduction from one task to another, and then derive an auxiliary gradient from optimizing it. We perform the optimization by incorporating this gradient into original task gradients, making the model automatically maximize inter-task transfer and minimize individual losses. Thus, CoGrad can harmonize between general and specific knowledge to boost overall performance. Besides, we introduce an efficient approximation of the Hessian matrix, making CoGrad computationally efficient and simple to implement. Both offline and online experiments verify that CoGrad significantly outperforms previous methods.", "1 INTRODUCTION": "In online advertising and recommender systems, multi-task learning (MTL) has been proven to be extremely effective to simultaneously predict multiple user behaviours (e.g., clicking, viewing and buying) [16, 17]. As Fig. 2 (a) shown, popular backbones of MTL involve shared modules for encoding multi-behaviour representations and several specialized heads to output task-specific predictions. In contrast to single-task learning (STL), shared modules are regarded as the key components for reciprocal benefits across tasks. The most crucial issue induced by encoding general knowledge is negative transfer [12]. As seen in Fig. 1(a), compared to STL, the CTR 1 task performance decreases (i.e., negative transfer ) while the CVR task achieves improvement. The similar phenomena are also observed in [8, 14]. Recently, several optimization methods that modify task gradients based on gradient alignment strategies have been proposed to address this issue. PCGrad [18] and GradVac [15] modify the gradient directions to maintain the directional consistency to enhance transference. GradNorm [2] and MetaBalance [5] homogenize gradient magnitudes to prevent shared modules from being dominated by certain tasks of larger gradient magnitudes. MGDA [13] and CAGrad [9] utilize Pareto solution to manipulate both the directions and magnitudes to mitigate gradient conflict. (a) Comparing STL vs MTL Negative Transfer 0.86 MTL 1xParam MTL 2xParam STL 1xParam 1 0.82 CTR Task CVR lask (b) Gradient cosine similarity during training 1 0.25 0.20 0.15 300k 40Ok 50Ok Traning However, since prior study has demonstrated that both general and specific knowledge exists in a competitive manner in shared modules [14], overemphasizing on the gradient alignment may crowd out the specific knowledge that is also useful for individual task. For example, direction-based methods usually align gradients by raising the cosine similarity, as it is regarded to be highly related with transference [18]. Yet, this could even degrade overall performance when dealing with two weakly correlated tasks. On the other hand, in our settings, we observed that the cosine similarity rises in early training but then diminishes (shown in Fig. 1(b)). This implies that MTL models are prone to encoding specific knowledge, which may in turn consume capacity budgets of general information. Consequently, over-encoding either general or specific knowledge could decrease overall performance. To address this, a straightforward way is to expand the shared parameters. However, due to the model's tendency for specificity, this may make it more likely to learn specific rather than general knowledge. This is supported by the observation that expanding parameters increases CTR performance but decreases CVR in Fig. 1(a). Therefore, it is challenging to coordinate the encoding of general and specific knowledge. In this paper, we propose a transference-driven approach CoGrad that adaptively maximizes knowledge transference via Co ordinated Grad ient modification. Specifically, we theoretically quantify the inter-task transfer as the loss reduction of one task induced by the update from another task gradient. Then, we optimize this quantification to derive an auxiliary gradient, and incorporate it into original task gradients. In this way, CoGrad can maximize intertask transfer while simultaneously minimize individual losses. Thus, CoGrad achieves the harmonization between general and specific knowledge, improving overall performance. Besides, CoGrad contains a Hessian matrix, resulting in expensive computations. We additionally introduce an efficient Hessian matrix approximation to make CoGrad computationally efficient and simple to implement in industrial applications. Our contributions are: \u00b7 To our knowledge, we are the first to explicitly quantify intertask transfer and utilize it for gradient modulation, which has promising applications for MTL. update Knowledge for all PCGrad MetaBalance CAGrad [Knowledge lor= Knowledge lor j Task Task Specific Modules Directions Magnitudes Pareto (b) Previous work Shared Modules 4] Max Transfer Max Transfer Min and Max Coordination Min Loss Min Loss Input Features Transference-Driven (a) Base MTL CoGrad (Ours) \u00b7 Weproposeatransference-driven gradient modulation method ( CoGrad ) that can adaptively maximize inter-task transfer, which is also computationally efficient. \u00b7 Experiments show that CoGrad outperforms prior baselines. Our empirical analysis verifies that CoGrad can effectively harmonize general and specific knowledge.", "2 PROBLEM FORMULATION": "In multi-task recommendation, considering a set of \ud835\udc47 tasks T = { \ud835\udc61 } \ud835\udc47 \ud835\udc61 = 1 , and the training dataset D = {( \ud835\udc65 \ud835\udc5b , { \ud835\udc66 \ud835\udc61 \ud835\udc5b } \ud835\udc61 \u2208T )} | D | \ud835\udc5b = 1 , where \ud835\udc65 \ud835\udc5b and \ud835\udc66 \ud835\udc61 \ud835\udc5b represent the feature vectors (including user features, item features and context features) and binary user feedback label (whether or not a user has clicked, viewed, bought, etc.) of \ud835\udc5b \ud835\udc61\u210e instance, respectively. We denote the \ud835\udc61 \ud835\udc61\u210e task dataset as D \ud835\udc61 = { \ud835\udc65 \ud835\udc5b , \ud835\udc66 \ud835\udc61 \ud835\udc5b } | D | \ud835\udc5b = 1 . Let \ud835\udc73 \ud835\udc61 (D \ud835\udc61 ; \ud835\udf03, \ud835\udf19 \ud835\udc61 ) denote the loss on D \ud835\udc61 for task \ud835\udc61 , where \ud835\udf03 and \ud835\udf19 \ud835\udc61 represent shared and specific parameters, respectively. The standard MTL loss is aggregated as a weighted sum formulation: Here, we omitted the regularization term and { \ud835\udc64 \ud835\udc61 } \ud835\udc47 \ud835\udc61 = 1 represent weights for scaling task losses. All parameters are updated as: MTL achieves knowledge transference by iterating Eq. 2. Instead of modifying the gradient magnitudes or directions as most prior methods, we attempt to explicitly quantify the inter-task transfer to guide the optimization in Eq. 2.", "3 PROPOSED APPROACH": "During iterating \ud835\udf03 , we expect that the gradient update from one task will minimize its own loss as well as help reduce the loss of another task as much as possible. We achieve this challenging goal via quantifying and maximizing knowledge transference to perform our optimization. We will elaborate our approach in this section. For simplicity, we use \ud835\udc73 \ud835\udc61 ( \ud835\udf03 ) and \ud835\udc88 \ud835\udc61 ( \ud835\udf03 ) to denote \ud835\udc73 \ud835\udc61 (D \ud835\udc61 ; \ud835\udf03, \ud835\udf19 \ud835\udc61 ) and \u2207 \ud835\udf03 \ud835\udc73 \ud835\udc61 (D \ud835\udc61 ; \ud835\udf03, \ud835\udf19 \ud835\udc61 ) respectively.", "Algorithm 1: Training Algorithm for CoGrad": "Input: Training dataset D , initial parameters { \ud835\udf03 } \u222a { \ud835\udf19 \ud835\udc56 } \ud835\udc56 \u2208T , learning rate \ud835\udf02 , { \ud835\udc64 \ud835\udc56 } \ud835\udc56 \u2208T for scaling task losses, { \ud835\udefe \ud835\udc56 } \ud835\udc56 \u2208T for controlling the strength of maximizing transference. 1 while Not converged do 2 Sample a batch of samples B from D ; 3 Update task-specific parameters: 4 \ud835\udf19 \ud835\udc58 + 1 \ud835\udc56 = \ud835\udf19 \ud835\udc58 \ud835\udc56 - \ud835\udf02 \u2207 \ud835\udf19\ud835\udc56 \ud835\udc73 \ud835\udc56 ( B ; \ud835\udf03 \ud835\udc58 , \ud835\udf19 \ud835\udc58 \ud835\udc56 ) , \u2200 \ud835\udc56 \u2208 T ; 5 CoGrad optimization for shared parameters : 6 Compute each task gradient on \ud835\udf03 : 7 \ud835\udc88 \ud835\udc56 ( \ud835\udf03 \ud835\udc58 ) = \u2207 \ud835\udf03 \ud835\udc73 \ud835\udc56 ( B ; \ud835\udf03 \ud835\udc58 , \ud835\udf19 \ud835\udc58 \ud835\udc56 ) , \u2200 \ud835\udc56 \u2208 T ; 8 Compute CoGrad , \u2200 \ud835\udc56 \u2208 T : 9 b \ud835\udc88 \ud835\udc56 ( \ud835\udf03 \ud835\udc58 ) = \ud835\udc88 \ud835\udc56 ( \ud835\udf03 \ud835\udc58 ) - \u02dd \ud835\udc57 \u2260 \ud835\udc56,\ud835\udc57 \u2208T \ud835\udefe \ud835\udc57 \ud835\udc88 \ud835\udc56 ( \ud835\udf03 \ud835\udc58 ) \u2299 \ud835\udc88 \ud835\udc56 ( \ud835\udf03 \ud835\udc58 ) \u2299 \ud835\udc88 \ud835\udc57 ( \ud835\udf03 \ud835\udc58 ) ; 10 Update shared parameters \ud835\udf03 : 11 \ud835\udf03 \ud835\udc58 + 1 = \ud835\udf03 \ud835\udc58 - \ud835\udf02 \u02dd \ud835\udc56 \u2208T \ud835\udc64 \ud835\udc56 b \ud835\udc88 \ud835\udc56 ( \ud835\udf03 \ud835\udc58 ) ; 12 end", "3.1 Quantifying Knowledge Transference": "Quantifying knowledge transference in MTL has huge potential to enhance generalization. Prior work [3] has measured the intertask affinity for grouping tasks. Inspired by this, we define the quantification of transfer from task \ud835\udc56 to \ud835\udc57 ( \ud835\udc56, \ud835\udc57 \u2208 T ) as the loss reduction of task \ud835\udc57 induced by the update from task \ud835\udc56 gradient. Specifically, assuming that the shared parameters \ud835\udf03 is updated by task \ud835\udc56 at time-step \ud835\udc58 with learning rate \ud835\udefe \ud835\udc56 > 0 , we have: Then, we use \ud835\udf03 \ud835\udc58 + \ud835\udf0f \ud835\udc56 to examine the impacts on task \ud835\udc57 loss by comparing the loss changes of task \ud835\udc57 before and after, formulated as: Plugging Eq.(4) into Eq.(5) and making a first-order Taylor series expansion of \ud835\udc73 \ud835\udc57 ( \ud835\udf03 \ud835\udc58 + \ud835\udf0f \ud835\udc56 ) yields: Notice that, \ud835\udc88 \ud835\udc47 \ud835\udc56 ( \ud835\udf03 \ud835\udc58 ) \ud835\udc88 \ud835\udc57 ( \ud835\udf03 \ud835\udc58 ) shows that larger inner product value means better transference, which may explain the observation in Fig. 1(b) that cosine similarity has a tendency to increase in the early training. Eq. 6 also implies that improving gradient inter product can enhance transference. This is relatively consistent with previous work [12, 15, 18], justifying our quantification. Since \u0394 \ud835\udc58 \ud835\udc73 \ud835\udc56 \u2192 \ud835\udc57 reflects the impacts from task \ud835\udc56 to \ud835\udc57 , it can be regarded as the quantification of inter-task ( \ud835\udc56 \u2192 \ud835\udc57 ) transfer. Next, we introduce how to use this quantification to perform a coordinated optimization that can harmonize general and specific knowledge.", "3.2 Coordinated Gradient Modulation": "3.2.1 Maximizing Inter-Task Transfer . We maximize the intertask transfer \u0394 \ud835\udc58 \ud835\udc73 \ud835\udc56 \u2192 \ud835\udc57 (Eq. 5) to derive the optimization gradient. Here, we fix task \ud835\udc56 since we merely consider the impacts from task \ud835\udc56 to \ud835\udc57 (i.e., approximating \u2207 \ud835\udf03 \ud835\udf03 \ud835\udc58 + \ud835\udf0f \ud835\udc56 as 1 . 0 ) and yield: Making a first-order Taylor series expansion of \ud835\udc88 \ud835\udc57 ( \ud835\udf03 \ud835\udc58 + \ud835\udf0f \ud835\udc56 ) yields: where \ud835\udc6f \ud835\udc57 ( \ud835\udf03 \ud835\udc58 ) is the Hessian matrix of \ud835\udc73 \ud835\udc57 ( \ud835\udf03 \ud835\udc58 ) . 3.2.2 GeneralandSpecificKnowledgeHarmonization . Here, -\u2207 \ud835\udf03 \u0394 \ud835\udc73 \ud835\udc58 \ud835\udc56 \u2192 \ud835\udc57 can represent the gradient for maximizing transference from task \ud835\udc56 to \ud835\udc57 . Then, we incorporate it into the original gradient \ud835\udc88 \ud835\udc57 ( \ud835\udf03 \ud835\udc58 ) (See Eq. 9), leading to both maximizing transference from task \ud835\udc56 to \ud835\udc57 (second term in Eq. 9) and minimizing the individual loss of task \ud835\udc57 (first term in Eq. 9), as illustrated in Fig. 2(c): where the hyper-parameter \ud835\udefe \ud835\udc56 can be regarded as the balance degree between maximizing transference and minimizing specific losses. In fact, CoGrad is insensitive to \ud835\udefe \ud835\udc56 as discussed in section 3.4.2. We can obtain the counterpart for task \ud835\udc56 in the same way. Based on this, we introduce a more general formulation as:", "3.3 Maximizing Transference Approximation": "Due to the Hessian matrix \ud835\udc6f \ud835\udc57 ( \ud835\udf03 \ud835\udc58 ) in Eq. 8, calculating the gradient \u2207 \ud835\udf03 \u0394 \ud835\udc58 \ud835\udc73 \ud835\udc56 \u2192 \ud835\udc57 for maximizing transference is too expensive both in storages and computations. Alternatively, we introduce an applicable approximator in [19] (see Eq. 11), where the approximation accuracy has been theoretically and empirically guaranteed. where \u2299 is Hadamard product (i.e., element-wise product) and \ud835\udf06 \ud835\udc58 is a hyper-parameter. According to [19], we fix \ud835\udf06 \ud835\udc58 to 1.0 in our method. We plug Eq. 11 into Eq. 10, leading to a simple and efficient training process of CoGrad as elaborated in Alg. 1.", "3.4 Discussion": "MBalance ). Other hyper-parameters in baselines are carefully tuned based on original researches. Our hyper-parameters { \ud835\udefe \ud835\udc50\ud835\udc61\ud835\udc5f , \ud835\udefe \ud835\udc50\ud835\udc63\ud835\udc5f } are set to { 0 . 003 , 0 . 001 } (Ecomm) and { 0 . 01 , 0 . 005 } (Ali-CCP).", "4 EXPERIMENTS": "", "4.1 Experimental Setup": "4.1.1 Datasets . We conduct the offline experiments on two industrial datasets. The first is a public dataset named Ali-CCP [11], which contains behaviors of clicking and buying. The second dataset including other another conversion behavior (i.e., viewing commodity details page) is collected from our large-scale E-commerce adverting platform, named Ecomm . We split each dataset into training/validation/test sets by timestamp with 4:1:1 proportion. Table 1 lists the statistics. 4.1.2 Competitors . Wecompare CoGrad with the previous stateof-the-art gradient modulation techniques by using Shared Bottom [1] and MMOE [10] as two fundamental MTL architectures: (1) PCGrad [18] aggressively projects task gradients based on directional consistency. (2) MetaBalance [5] ( MBalance for short) adaptively homogenizes gradient magnitudes to prevent model from being dominated by certain tasks. (3) CAGrad [9] searches around the average gradients to maximize the worst task performance. (4) Seq.Rept [7] uses inner-loops trajectory with sequential tasks to maximize gradient alignment. ) [7] We use AUC (Ali-CCP) and Group AUC of users (an industrial metric in [4] for Ecomm) as the evaluation metrics. To ensure fair comparison, the feature embedding size is fixed to 8 for all methods (including STL) and each network contains three hidden layers with {512,256,128} for Ecomm and {128,64,32} for Ali-CCP. The first two layers are shared and the last is specific in MTL models. And for MMOE, we set three experts. We use Adam [6] optimizer with 1024 (Ecomm) and 256 (Ali-CCP) batch size and 0.001 (Ecomm) and 0.005 (Ali-CCP) learning rate. The loss scaling weights are set by a heuristic way based on priori statistical cross-entropy (excluding", "4.2 Results and Discussion": "3.4.1 ConnectionswithMeta-Learning . Sequential Reptile ( Seq.Rept resembles our method in terms of a balance in general and specific information. Seq.Rept aligns task gradients using meta-learning based on inner-loops trajectory with all tasks sequentially. Informally, Seq.Rept is very similar to CoGrad under conditions with two tasks and two inter-steps. These connections also help the comprehension of our approach. However, when facing with more tasks, Seq.Rept becomes computationally expensive due to the inter and outer loops, while CoGrad remains efficient with negligible computation increase. Moreover, it is also business-sensible to explicitly quantify and maximize inter-task transfer. Thereby, CoGrad is more practical in industrial applications. 3.4.2 Hyper-ParametersSelection . Ourmethodintroduces new hyper-parameters { \ud835\udefe \ud835\udc57 } \ud835\udc57 \u2208T in Eq. 10, which control the strength of maximizing inter-task transfer during optimization iterations. From our theoretical derivation, we can regard \ud835\udefe \ud835\udc57 as the virtual learning rate for updating parameters of task \ud835\udc57 . Thus, selecting a reasonably tiny value suffices. Moreover, We also empirically find that the performance is insensitive to the hyper-parameters, and they only have a small impact on convergence speed. 4.2.1 Main Results . Table 2 shows the results of all methods on production and public datasets. For both datasets, all MTL methods outperform Single DNN on the CVR task while perform slightly worse on the CTR task. This is because that the data sparsity problem [11] makes it difficult to fit a single CVR model, but the CTR can learn effectively due to the adequate data. Compared to Shared Bottom -based methods, MMOE -based ones perform marginally better on the CTR but worse on the CVR. This is consistent with our perspective that the explicit CTR-specific experts help encode more CTR-specific knowledge, but take over the capacity budgets for encoding CVR-specific or general knowledge. CAGrad , which focuses on the worst task, and Seq.Rept , which considers individual tasks, outperform previous methods towards preventing negative transfer. This implies that general and specific knowledge are equally important in shared modules. Benefiting from the transference-driven technique, which harmonizes both general and specific knowledge, CoGrad significantly surpasses all baselines on the CVR, and meanwhile, achieves comparable CTR performance compared to STL. Notice that, compared to Seq.Rept, the improvement of CoGrad seems minor on Ecomm dataset. Firstly, achieving industrial 0.1 AUC gain is remarkable [11]. Secondly, as discussed in section 3.4.1, CoGrad resembles Seq.Reqt in two-task settings. However, CoGrad is more efficient in computation and simple to implement, both of which are crucial in large-scale applications.", "4.3 Further Analysis": "4.3.1 Robustness on capacity size . We double the size of first hidden layer to examine the robustness w.r.t. the capacity size with Shared Bottom . In base model, expanding capacity tends to mitigate negative transfer on the CTR at the cost of hurting the CVR (shown in Table 3). CoGrad , however, improves CTR performance while maintaining CVR unaffected. This verifies that CoGrad is strongly robust that can adaptively maximize knowledge transference.", "4.3.2 Visualization of general and specific knowledge har-": "monization . We investigate the ability of general and specific knowledge harmonization with the help of the pretrain-finetune paradigm. We freeze the total shared parameters of the trained model and connect the last shared layer to a trainable linear layer. We then fine-tune this linear layer for each task to learn the hidden units weights of the last shared layer (128 dimensions). The intuition behind this is that if both tasks consider one unit to be important, their normalized weights should be close, and vice versa. Ultimately, We compute the weights (normalized) difference (i.e., CTR weights minus CVR weights), leading to a distribution (smoothed) as illustrated in Fig. 3(a). The knowledge is considered to be more general when the difference is closer to zero, and more specific when the difference is further away from zero. First, this visualization demonstrates that the shared modules indeed contain general and specific knowledge, which is consistent with [14]. Second, the area on the right side of zero (i.e., important knowledge for CTR task) is slightly smaller than that on the left side. This provides an explanation for the observation that CVR gained 1 Methods GAUC ctr GAUC cvr Size 512 \u00d7 Size 1024 \u00d7 ( \u0394 ) Size 512 \u00d7 Size 1024 \u00d7 ( \u0394 ) Shared Bottom 76.01 76.05 ( \u2191 0.04) 78.97 78.81 ( \u2193 0.16) + CoGrad 76.17 76.23 ( \u2191 0.06) 79.61 79.63 ( \u2191 0.02) CVR-Specific Knowledge CTR-Specific Knowledge General Knowledge (b) (a) 259 0.40 Shared Bottom S8+MBalance Shared Bottom SB+KBalance SB+PCGrad SB+CoGrad SB+PCGrad SB+CoGrad 20% 0.35 15% 1 0.30 10% 0.25 5% 0.20 0% 0.15 0.5 0.0 0.5 1.0 Weights difference Traning steps significantly from MTL while CTR was negatively affected. Third, the direction-based method ( PCGrad ) indeed increases the general knowledge by enforcing the gradient alignment, yet hinders the encoding of some specific knowledge. This supports our perspective described in the introduction that enforcing the gradient alignment may crowd out specific knowledge. Ultimately, compared to base MTL, CoGrad improves the general knowledge while it also maintains adequate specific knowledge. This verifies that CoGrad can effectively harmonize general and specific knowledge. 4.3.3 Impacts on gradient similarity . Fig. 3(b) shows the gradient cosine similarity of all methods during training. Compared to the base model, magnitude-based method ( Mbalance ) performs no improvement on the similarity, and direction-based method ( PCGrad ) achieves the most efficiency on gradient similarity. Considering the main results in Table 2, we can validate that the cosine similarity is indeed related to the performance. However, their correlation is not exactly positive. CoGrad implicitly aligns gradients by the transference-driven technique, increasing cosine similarity to a certain level. Combining this with Fig. 3(a), we can confirm that CoGrad can automatically enhance the encoding of general knowledge to an appropriate degree, without over-encoding.", "4.4 Online A/B Test": "We conduct online experiments on our advertising system for 15 days compared to a well-trained MTL model. We use metrics including \ud835\udc36\ud835\udc47\ud835\udc45 = #click #impression , \ud835\udc36\ud835\udc43\ud835\udc36 = cost of advertisers #click , \ud835\udc36\ud835\udc49\ud835\udc45 = #view #click , and \ud835\udc36\ud835\udc43\ud835\udc34 = cost of advertisers #view . A higher CTR/CVR and a lower CPC/CPA indicate better performance. In large-scale industrial applications, achieving 1% gains is a significant improvement. CoGrad increases CTR and CVR by 2.03% and 4.75% , respectively, and reduces CPC and CPA by 1.64% and 5.23% . verifying its effectiveness in industry.", "5 CONCLUSION": "We propose CoGrad , a transference-driven approach that can automatically maximize inter-task transfer via coordinated gradient modification. It quantifies the transference and performs an optimization by maximizing this quantification and simultaneously minimizing task-specific losses, harmonizing both general and specific knowledge in shared modules to improve overall performance. Both offline and online experiments verify its effectiveness.", "REFERENCES": "[1] Rich Caruana. 1997. Multitask learning. Machine learning 28, 1 (1997), 41-75. [2] Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, and Andrew Rabinovich. 2018. Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks. In International conference on machine learning . PMLR, 794-803. [3] Christopher Fifty, Ehsan Amid, Zhe Zhao, Tianhe Yu, Rohan Anil, and Chelsea Finn. 2021. Efficiently Identifying Task Groupings for Multi-Task Learning. In Neural Information Processing Systems . [4] Ruining He and Julian McAuley. 2016. Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering. In proceedings of the 25th international conference on world wide web . 507-517. [5] Yun He, Xue Feng, Cheng Cheng, Geng Ji, Yunsong Guo, and James Caverlee. 2022. Metabalance: improving multi-task recommendations via adapting gradient magnitudes of auxiliary tasks. In Proceedings of the ACM Web Conference 2022 . 2205-2215. [6] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014). [7] Seanie Lee, Hae Beom Lee, Juho Lee, and Sung Ju Hwang. 2021. Sequential Reptile: Inter-Task Gradient Alignment for Multilingual Learning. arXiv preprint arXiv:2110.02600 (2021). [8] Zihan Lin, Xuanhua Yang, Shaoguo Liu, Xiaoyu Peng, Wayne Xin Zhao, Liang Wang, and Bo Zheng. 2022. Personalized Inter-Task Contrastive Learning for CTR&CVR Joint Estimation. arXiv preprint arXiv:2208.13442 (2022). [9] Bo Liu, Xingchao Liu, Xiaojie Jin, Peter Stone, and Qiang Liu. 2021. Conflictaverse gradient descent for multi-task learning. Advances in Neural Information Processing Systems 34 (2021), 18878-18890. [10] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed H Chi. 2018. Modeling task relationships in multi-task learning with multi-gate mixture-ofexperts. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1930-1939. [11] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun Gai. 2018. Entire space multi-task model: An effective approach for estimating post-click conversion rate. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval . 1137-1140. [12] Sebastian Ruder. 2017. An overview of multi-task learning in deep neural networks. arXiv preprint arXiv:1706.05098 (2017). [13] Ozan Sener and Vladlen Koltun. 2018. Multi-task learning as multi-objective optimization. Advances in neural information processing systems 31 (2018). [14] Zirui Wang, Zachary C Lipton, and Yulia Tsvetkov. 2020. On negative interference in multilingual models: Findings and a meta-learning treatment. arXiv preprint arXiv:2010.03017 (2020). [15] Zirui Wang, Yulia Tsvetkov, Orhan Firat, and Yuan Cao. 2020. Gradient vaccine: Investigating and improving multi-task optimization in massively multilingual models. arXiv preprint arXiv:2010.05874 (2020). [16] Penghui Wei, Weimin Zhang, Zixuan Xu, Shaoguo Liu, Kuang-chih Lee, and Bo Zheng. 2021. AutoHERI: Automated Hierarchical Representation Integration for Post-Click Conversion Rate Estimation. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management . 3528-3532. [17] Hong Wen, Jing Zhang, Fuyu Lv, Wentian Bao, Tianyi Wang, and Zulong Chen. 2021. Hierarchically modeling micro and macro behaviors via multi-task learning for conversion rate prediction. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval . 2187-2191. [18] Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, and Chelsea Finn. 2020. Gradient surgery for multi-task learning. Advances in Neural Information Processing Systems 33 (2020), 5824-5836. [19] Shuxin Zheng, Qi Meng, Taifeng Wang, Wei Chen, Nenghai Yu, Zhi-Ming Ma, and Tie-Yan Liu. 2017. Asynchronous stochastic gradient descent with delay compensation. In International Conference on Machine Learning . PMLR, 41204129."}
