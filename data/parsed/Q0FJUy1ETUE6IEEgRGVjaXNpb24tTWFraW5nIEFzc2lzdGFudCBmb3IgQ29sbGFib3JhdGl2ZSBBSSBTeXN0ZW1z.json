{"title": "CAIS-DMA: A Decision-Making Assistant for Collaborative AI Systems", "authors": "Diaeddin Rimawi; Antonio Liotta; Marco Todescato; Barbara Russo", "pub_date": "2023-11-08", "abstract": "A Collaborative Artificial Intelligence System (CAIS) is a cyber-physical system that learns actions in collaboration with humans in a shared environment to achieve a common goal. In particular, a CAIS is equipped with an AI model to support the decision-making process of this collaboration. When an event degrades the performance of CAIS (i.e., a disruptive event), this decision-making process may be hampered or even stopped. Thus, it is of paramount importance to monitor the learning of the AI model, and eventually support its decision-making process in such circumstances. This paper introduces a new methodology to automatically support the decision-making process in CAIS when the system experiences performance degradation after a disruptive event. To this aim, we develop a framework that consists of three components: one manages or simulates CAIS's environment and disruptive events, the second automates the decision-making process, and the third provides a visual analysis of CAIS behavior. Overall, our framework automatically monitors the decision-making process, intervenes whenever a performance degradation occurs, and recommends the next action. We demonstrate our framework by implementing an example with a realworld collaborative robot, where the framework recommends the next action that balances between minimizing the recovery time (i.e., resilience), and minimizing the energy adverse effects (i.e., greenness).", "sections": [{"heading": "Introduction", "text": "A Cyber-Physical System (CPS) has heterogeneous hardware-software components that collaborate to deliver real-time services, [13]. The complexity of CPS varies from one domain to the other. A Collaborative Artificial Intelligence System (CAIS) is an example of a CPS that works together with humans to achieve a common goal, [1]. The core component of CAIS responsible for decision-making is its Artificial Intelligence (AI) model. The AI model is responsible for making decisions to control the collaboration between the system and the human. In general, AI model's training can be either from historical data (offline learning) or iterative during run-time (online learning), [15]. In CAIS context, the AI model learns from the human in an online learning mode. Online learning can be affected by environmental changes (i.e., disruptive events) that may hamper the ability of the system to take real-time decisions. For instance, disruptive events may affect the learning data, and thus, it may affect the AI model prediction accuracy and the reliability of the system, [2]. Therefore, it is of paramount importance to provide CAISs with a recovery instrument that automatically supports the decision-making process in case of disruptive events. The instrument needs to monitor the system performance, detect performance degradation, mitigate the cause through feasible recovery actions, and recover the system performance to an acceptable performance level, [4,6,15].\nIn this paper, we introduce our framework the Collaborative Artificial Intelligence System Decision-Making Assistant (CAIS-DMA), which automatically orchestrates the decision-making process between CAIS and humans when CAIS's performance degrades. The framework is developed to be equipped as a CAIS component, monitors its performance under a disruptive event, and automatically intervenes when a performance degradation occurs. The framework intervention aims to recover CAIS from performance degradation to an acceptable performance level. The recovery is achieved by supporting CAIS's AI model in restoring its accuracy as fast as possible, to ensure the real-time service delivery of CAIS. To this aim, CAIS-DMA is equipped with three extendable components: i) Simulator, ii) Actuator, and iii) Monitoring component. The simulator simulates the run-time environment of CAIS's AI model and the human role in an online learning dataset. Then, it allows us to enforce the disruptive event effect on the dataset, and stream the data to the AI model in the expected structure. On the other hand, the actuator monitors CAIS's performance and invokes the measurement mechanism to recommend the next action in case of performance degradation. Finally, the monitoring component provides a toolbox for CAIS's managers to tune the framework components' configurations, and illustrates CAIS's behavior through a visual analysis representation.\nAdditionally, we demonstrate CAIS-DMA in a real-world demonstrator, in which we implement CAIS-DMA to assist a collaborative robot in recovering from performance degradation after a disruptive event occurs. In this demonstration, CAIS-DMA will assist the robot in taking the next action that ensures fast recovery from the disruptive event (resilience). However, this implies additional energy consumption, which increases the energy adverse effects and lowers CAIS's greenness. Thus, we leverage our approach that balances the two properties. Our approach is GResilience [13,15], a measurement mechanism to find the action that best trade-off between greenness and resilience. GResilience is equipped with two independent techniques: i) a weighted sum optimization model, and ii) a game theory model leveraging \"The Battle of Sexes\" game.\nOur major contribution in this paper can be summarized as follows:\n1. We introduce CAIS-DMA our novel framework to assist CAIS's managers in simulating, actuating, and monitoring their systems. CAIS-DMA simulator supports creating a working environment with potential disruptive events, which allows testing CAIS's AI model responsible for the collaboration between the system and the human, without risking draining CAIS's resources. Additionally, the framework actuator automatically supports CAIS's decisionmaking by recommending the next action that achieves the selection criteria (through the selection mechanisms). Finally, CAIS-DMA provides a visual analysis monitoring component to monitor CAIS's performance. 2. We design CAIS-DMA components to be extendable, where the developers can customize the framework components to represent different CAISs.\nThe simulator can simulate different CAISs environments including the disruptive events they may be exposed to. Additionally, the actuator can be extended with new selection mechanisms and new recovery actions to recommend from. As for the monitoring component, it can tune the framework configurations to run different environmental settings. 3. We show how CAIS-DMA can be equipped with CAIS, by demonstrating the development process with a real-world collaborative robot. In our application, we support action selection by recommending the action that best trade-off between greenness and resilience. Specifically, we wrap the GResilience [13,15] as the measurement mechanism, to automatically support decision-making.\nThe rest of this paper is structured as follows. In Sec. 2 we provide a background about the performance states, resilience, greenness, and the GResilience approach. In Sec. 3 we discuss CAIS-DMA architecture. In Sec. 4 we discuss how CAIS-DMA can automatically support the decision-making process in onlinelearning-based CAIS. In Sec. 5 we demonstrate the development process of equipping CAIS-DMA with CAIS. In Sec. 6 we discuss the paper threats to validity. In Sec.7 we discuss the related work. Finally, in Sec. 8 we state our conclusion and discuss our future work.", "publication_ref": ["b12", "b0", "b14", "b1", "b3", "b5", "b14", "b12", "b14", "b12", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "Background", "text": "By principle, the online learning model eventually readjusts to the environmental changes after enough training, [15]. Thus, CAIS's AI model, which is an online-learning-based model, learns based on accumulated data between normal and disruptive environmental settings. Hence, when fixing the disruption event CAIS's performance will face another performance degradation, due to the training data used while being under disruption. Fig. to an acceptable performance level. Thus, it is important to define how to measure performance in order to understand what state the system is in. In this paper, we focus on CAIS's AI model's ability for autonomous decision-making, and we consider the autonomous decision-making ratio in a windows of time as our performance measurement. As a result, we search for the action that both minimizes the time to restore the autonomous decision-making ratio from degradation to an acceptable level and minimizes the energy adverse effect. Thus, we consider two non-functional properties of CAIS: resilience and greenness. The rest of this section discusses what they represent based on the GResilience measurement mechanism leveraged in our demonstration.", "publication_ref": ["b14"], "figure_ref": [], "table_ref": []}, {"heading": "Resilience", "text": "We consider resilience as a non-functional property that is concerned about recovering the system performance from a performance degradation to an acceptable performance level. Thus, we measure it by the action's Estimated Time (ET). Eq. ( 1), uses the exponential smoothing as an estimation technique to find the next iteration i + 1 ET for action a (ET i+1 a ), where (DT i a -ET i a ) is the error with the actual time from the previous iteration i, and \u03b1 is the smoothing constant.\nET i+1 a = ET i a + \u03b1 \u2022 (DT i a -ET i a )(1)", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Greenness", "text": "System greenness is a non-functional property concerned with the efficient usage of energy while minimizing its adverse effects, [8]. One of the energy adverse effects we consider to measure CAIS greenness is the CO 2 footprint, which may increase when the CAIS's AI makes decisions to autonomously operate while still under disruption. On the other hand, we can not drain human resources all the time by continuously moving to the learning mode. Thus, we constrain the human measurements with a maximum number of human iterations. To compute the system greenness we consider two variables: i) Estimated CO 2 Footprint Pr Pr Pr a1(q) a1(q) a1(q) P 2 r (a1), P 2 g (a1) P 1 r (a1), P 1 g (a2) pP 2 r (a1) + (1 -p)P 1 r (a1)\na2(1 -q) a2(1 -q) a2(1 -q) P 1 r (a2), P 1 g (a1) P 2 r (a2), P 2 g (a2)\npP 1 r (a2) + (1 -p)P 2 r (a2) Pg Expected Payoff Pg Expected Payoff Pg Expected Payoff qP 2 g (a1) + (1 -q)P 1 g (a1) qP 1 g (a2) + (1 -q)P 2 g (a2)\n(ECF) of an action, and ii) the human labor cost as Number of Human Interactions (NHI) remaining for the action. As for ET, the ECF is estimated using the exponential smoothing, Eq (2). ECF a is the ECF for action a for an iteration i, DCF a is the actual carbon footprint of an iteration, and \u03b1 is the smoothing constant. Eq. ( 3) shows the N HI a which is the NHI for an iteration, N HI max is the maximum allowed NHI, and N HI a is the NHI required to complete action a.\nECF i+1 a = ECF i a + \u03b1 \u2022 (DCF i a -ECF i a )(2)\nN HI i+1 a = N HI max -N HI i a -N HI a(3)", "publication_ref": ["b7"], "figure_ref": [], "table_ref": []}, {"heading": "GResilience Measurement Mechanism", "text": "The GResilience (GR) approach [13,15] provides CAIS with an automated instrument to support decision-making during disruption. GR aims to find the action that best trade-off between greenness and resilience. It solves the trading off problem by forming the problem into two independent mechanisms: 1. Multi-Objective Optimization using the Weighted Sum Model (GR-WSM):\nWhere it combines both the resilience and the greenness measures into a single score per action. Then the model chooses the action with the highest score. Eq.( 4), shows the global score equation (S()) for the action a, where w R and w G are the weights of resilience and greenness respectively. \u03f5 is the confidence level of the AI model (\u03f5 \u2208 [0, 1]): the higher the value the more we trust the AI to continue operating. Thus, \u03f5 multiplies the inverse of the resilience measure, and 1 -\u03f5 multiplies the summation of the greenness measures. Each resulting measure is then normalized (N ()). Finally, we search for the action that maximizes S(a).\nS(a) = w R \u2022 \u03f5 \u2022 N (ET -1 ) + w G \u2022 (1 -\u03f5) \u2022 {N (N HI) + N (ECF -1 )} (4)\n2. Game Theory by leveraging \"The Battle of Sexes\" game into building The GResilience Game (GRG): A collaborative game where each of the players has a preferred option, while they share a common goal (i.e., recovering the system). The game treats resilience and greenness properties as two game players (P r the resilience player and P g the greenness player), and each of the players has an independent way to measure its payoff. Same as \"The Battle of Sexes\" the GRG has two Pure Strategies Nash Equilibria (PSNE), in which the two players agree on the same action. GRG may have another Mixed Strategy Nash Equilibrium (MSNE) based on the probability of each player's action. Eq. ( 5) shows the expressions to find the P r and P g payoffs, where \u03b1 is the matching factor that is a smaller value in case the players land on different actions and a larger value in case they match. Table 1, shows two PSNEs where both players choose the same action and a possible MSNE based on the probability of each player's action, [13,16]. In the MSNE, P r chooses a 1 with probability q and a 2 with probability 1 -q, while P g chooses a 1 with probability p and a 2 with probability 1 -p, which results to the expected payoff described in Table 1. Thus, to find the probability q (resp. p) with MSNE, we equal the expected payoffs of P g (resp. P r ) for a 1 and a 2 and solve the resulting equation for q (resp. p).\nP \u03b1 r (a) = \u03f5 \u2022 \u03b1 \u2022 ET -1 , P \u03b1 g (a) = (1 -\u03f5) \u2022 \u03b1 \u2022 N HI -1 \u2022 ECF -1(5)\n3 Framework Architecture -CAIS-DMA\nThe CAIS-DMA operates as an assistant to support CAIS's AI model responsible for the collaboration actions between the system and the human during the first disruptive state (Fig. 1). It aims to assist the AI model until it reaches the recovered state. The framework consists of three components: i) a data simulator, ii) a decision-making actuator, and iii) a monitoring component. Fig. 2, shows the three components interacting with the CAIS under the disruptive event. The rest of the section will discuss each of CAIS-DMA's components.", "publication_ref": ["b12", "b14", "b12", "b15"], "figure_ref": ["fig_0"], "table_ref": ["tab_1", "tab_1"]}, {"heading": "Simulator", "text": "The goal of the simulator component is to simulate the learning data of CAIS's AI model, editing the data to represent a specific disruptive event effect and structure it as expected by the AI model. To this aim, the simulator consists of two packages:\n1. Adapters: An extendable package that contains the adaptation classes. These classes prepare the dataset and restructure it to adapt the AI model's expected input. Moreover, it adds a data field for human representation. The human field is assumed to be the ground truth of the specific data instance. This field is important to simulate the human action for the specific data instance. 2. Disruptors: The disruptors package is an extendable package, where it allows multiple disruptors. Each disruptor aims to simulate a disruptive event effect on the data, and it is important to note that the disruptors affect only the data and not the system itself.\nAfter data preparation, the simulator streams the data instances to the AI model using the Data Feeder. The data feeder is responsible for sorting the data and streaming them over to the AI model. It streams the data in three states: i) Steady State, where it streams the data without disruptions, ii) Disruption State, where it streams the data with the disruptive effect, and iii) Final State, where it streams again the data without disruptions (to simulate the disruptive event fix). By default, the data are split into thirds, unless defined otherwise in the framework configurations.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Actuator", "text": "The actuator component has two main functionalities: i) Monitoring the AI model performance, and ii) Supporting the AI model decision-making. The following summarizes these functionalities:\n1. Performance Monitor. This package monitors the AI model's decisions and measures its performance based on the autonomous decisions made for a window of time. Algo. 1, shows the algorithm we use to measure CAIS's AI model performance. The algorithm first initializes the variables, measures the performance, invokes CAIS-DMA decision mechanisms, and executes the final decision (recommended action). Where ADR is the autonomous decision ratio, ADRT is the ADR threshold that defines what an acceptable performance level, D is the AI's decision (chosen/recommended action), \u03f5 is the AI model confidence level towards the decision D, W is the time window size, Q is a queue that stores the last W decisions. 2. Support Decision-Making. In case of performance degradation the performance monitor invokes a decision-making mechanism to recommend the action to be executed. All feasible actions are defined in the actions package including their properties, for example, their execution time. The decisionmaking mechanisms represent different techniques for decision-making, such as the GResilience measurement mechanism which recommends the action that best trade-off between greenness and resilience. Other measurement mechanisms can be defined in this package to support the different nature of CAIS under test. case \"Autonomous\": Q.enqueue(1)", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "12:", "text": "case \"Human\": Q.enqueue(0)\n13: \nADR \u2190 Q.sum()/W \u25b7", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Monitoring Component", "text": "The monitoring component is a web-based application, which provides a toolbox for the framework users to visually analyze CAIS performance during run-time, and tunes the framework variables to run experiments over CAIS under test.\nThrough visual analysis, we can monitor the performance anomalies caused by the disruptive event(s), where for each experiment it plots the performance behavior per each window of time. While through the experiment tuning, we can customize an experiment by setting the experiment configurations, like the number of iterations, the dataset, the adapters to use, the disruptors, what decisionmaking mechanism to apply, and the actions set to recommend from.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Support Decision Making Process with CAIS-DMA", "text": "The AI model of CAIS is responsible for controlling the collaboration between the human and the system. It decides whether to run autonomous actions by the system or ask the human to perform the action and update the AI model with the new learning. Fig. 3, shows the online learning flow diagram of CAIS, where it starts by receiving a new data stream, preprocessing the data, and then estimating the prediction probability (i.e., the confidence level \u03f5, where \u03f5 \u2208 [0, 1]) using the AI model to perform a specific task. If the prediction probability is more than the predefined minimum probability (min(prob)), the decision will be to perform autonomous actions, through predicting and performing the task by the system itself. Otherwise, it asks the human to perform the task, by entering into a learning mode and updating the AI model with the new data.\nTo support the decision-making process, CAIS-DMA monitors the estimated probability of the online learning process to measure CAIS's performance. This measurement helps CAIS-DMA to automatically detect disruptive events that lead to performance degradation. If performance degradation is detected, CAIS-DMA calls the decision measurement mechanism, which, in turn, considers \u03f5 with the feasible actions to measure the action that best trade-off between the predefined non-functional properties. In online learning, CAIS-DAM selects between Finally, CAIS managers have the flexibility to update the AI model with the new prediction or not. If they decide to update the AI model, this reduces CAIS dependability on CAIS-DMA, allowing the system to live under disruption without the framework support, however, it causes a higher probability to face another disruptive state after fixing the disruptive event, due to the accumulative learning. While, if they avoid updating the AI model, this means discarding learning from disruptive data, which reduces the chances of being disrupted again after fixing the disruptive event, but increases the dependability over CAIS-DMA during the disruptive state.", "publication_ref": [], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "First Application and Evaluation", "text": "To understand if CAIS-DMA supports the decision-making of CAIS to recover from performance degradation caused by disruptive events, we aim to answer the following research questions:\n-RQ1: What is the software development process of CAIS-DMA to automatically support the decision-making of CAIS? To answer this question, we will demonstrate development process decisions to successfully design an application of CAIS-DMA, using both its simulator and actuator to automatically support the decision-making of CAIS. -RQ2: What are the extendable components of CAIS-DMA that allow wider support for decision-making? To answer this question, we will consider CAIS-DMA architecture with the online learning process to reflect on a real-world demonstrator, showing the framework components to be extended in order to complete a full application. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Application Context -CORAL", "text": "Our demonstrator is a collaborative robot named \"CORALfoot_0 \". Fig. 4, shows CORAL, which consists of a robotic arm installed above a conveyor belt that transfers objects of multiple colors. The robot detects the objects using an RGB camera installed on top of the conveyor belt. The detected object is streamed to an online learning model to be classified based on its color. The classifier monitors human movements by tracking the human skeleton. The human movement helps the classifier to label the object class with the target box.", "publication_ref": [], "figure_ref": ["fig_3"], "table_ref": []}, {"heading": "Equipping CORAL with CAIS-DMA", "text": "CAIS-DMA framework is built using Python3, and its available on GitHubfoot_1 . Fig. 5, shows CORAL online learning associated with CAIS-DMA. The online learning of CORAL starts when a new object is detected, the detected object is streamed to the preprocessing step. The preprocessor extracts the object histogram and passes it to estimate the class probability. If \u03f5 \u2265 min(prob) (min(prob) = 0.4 in the case of CORAL) the classifier predicts the object's box and asks the robotic arm to pick the object to the predicted box. Otherwise, the classifier notifies the human to classify the object and update the model with the new labeled object. To the aim of building a successful application using CAIS-DMA, we illustrate the software development process of building a green resilient CORAL. The process milestones are: i) Defining the performance measurements, ii) Understanding the dataset structure the AI model expects, iii) Listing the disruptive events that may lead to performance degradation, iv) Creating a set of all feasible recovery actions, v) Defining the non-functional properties the actions have to balance, vi) Setting the decision-making measurement mechanisms, vii) Storing the collected decisions, and finally, viii) Updating the AI model with the decision. The rest of this section summarizes the decisions with respect to CORAL: Cubes Colors Dataset. As illustrated CORAL's learning starts when a new object is detected over the conveyor belt. The detected object is streamed into a JSON-structured instance. This instance is then processed by the learner preprocessing step. CAIS-DMA simulator's goal is to simulate the input data (i.e., the cube images in this case), thus, we created the Cubes Colors Dataset, a set of cubes images taken from the RGB camera installed above the conveyor belt of CORAL, to have a real-world dataset from the application itself. Finally, we create an adapter that prepares the images to be streamed in the same structure CORAL's AI model expects.\nDisruptive Event. One of the disruptive events that lead to performance degradation for online learners depending on computer vision to produce the learning data, is disrupting the vision itself. Thus, in this application, we simulate the environmental effect of losing the lights above the conveyor belt, which, in turn, leads to darker images. As we are using the simulator to produce images' darkness, this gives us the flexibility to simulate the disruptive event effect from dimming the lights to losing the lights completely. The effect of darkness hampers online learning as it produces different histograms than the training data before the disruptive event, which disrupts the decision-making and eventually leads to performance degradation (low autonomous classification ratio). Recovery Actions. The online learning classifier of CORAL is moving between two states: i) the learning state, where it asks the human to classify the object, and ii) the operating state, where it predicts the cube box and places it using the arm. Both of these states are considered as the decision actions, and the iterative execution of these actions will eventually lead to recovery from the performance degradation. However, choosing which action to execute will depend on the action that best trade-off between the non-functional properties selected in the measurement mechanism. To summarize, in our application we consider two feasible recovery actions from the light disruption: action1 ) ask the arm to classify the cube, and action2 ) learn from the human classification of the cube. Greenness and Resilience. The main goal of this application is to restore CAIS performance from degradation to an acceptable performance state. In other words, ensure the resilience property of CAIS. Although choosing the fastest action all the time may restore CAIS performance faster, it leads to higher energy consumption, which increases the energy adverse effects. Increasing the energy adverse effects reduces CAIS greenness, thus, it is important to find the action that balances CAIS's greenness and resilience. Hence we use ECF and NHI to measure greenness and ET to measure resilience. GResilience Measurement Mechanism. The GResilience approach aims to recommend the next action that best trade-off between greenness and resilience to CAIS's performance to an acceptable performance state. The approach defines two techniques to find the next action, either by recommending the action with the highest combined score of resilience and greenness through optimization, or by considering the two properties as game theory players in a collaborative game of common goal (Sec. 2).\nStoring the Results. To be able to revisit the results, analyze them, and support CAIS's managers in making decisions based on these results, it is important to structure these results in a readable and productive way. In our application we dump the decisions into a Comma-Separated Values (CSV) structure, in which we record timestamped data that contains the selected action, the measurements (ET, ECF, and NHI), and if this decision is made autonomously by CORAL, or it is overridden through CAIS-DMA.\nUpdate the AI Model. Finally, CAIS managers need to decide whether to update the AI model with CAIS-DMA results or not. Based on our observation, updating the AI model leads to faster recovery during the disruption state, in other words, CAIS learns to live in the darkness. However, this leads to a second disruptive state after fixing the disruptive event. On the other hand, not updating the AI model, leads to higher dependency on CAIS-DMA during a disruptive state, making it difficult to learn to live in the darkness. While, after fixing the disruptive event it is faster to return to the steady state again. We recommend running both options under simulation and taking the decision of updating the AI model or not based on the CAIS under test.", "publication_ref": [], "figure_ref": ["fig_4"], "table_ref": []}, {"heading": "Takeaways", "text": "In this application, we equipped our real-world demonstrator (CORAL) with CAIS-DMA. The implementation process of our application helps address our research questions as follows: Answer to RQ1. The answer to this research question aims to demonstrate the development process for CAISs managers. In particular, the managers need to define the measures that are relevant to observing CAIS's performance, and what are the events that may lead to performance degradation. Then, they have to address the feasible recovery actions, and the recommendation criteria for the next action. In this application, we show an application of the development process decisions based on CORAL, where we used CAIS-DMA to simulate CORAL's working environment and the effect of losing the light on the vision sensor of CORAL. Then we implemented CAIS-DMA actuator to recover CORAL by balancing between greenness and resilience, and finally, we monitored CORAL behavior to understand the performance behavior during the different states. Answer to RQ2. This question provides CAIS's developers with the main extendable packages to consider during implementation. Starting with the simulator, in our application, we created a dataset of images to simulate CORAL's environment, however, the developers can customize the simulator to simulate their own dataset. They just need to provide the adapter class and the disruptor to feed the data to CAIS under test. Additionally, the mechanisms and the recovery action packages in the actuator component are also extendable to different measurement mechanisms and recovery actions. Finally, CAIS-DMA is full of utilities and toolboxes to automate running experiments, visual analysis, and sorting the dataset instances.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Threats to Validity", "text": "Wieringa et al. [17] define validity as the support degree to a fallible inference.\nOur paper introduces an architectural explanation of CAIS-DMA, to automatically support decision-making of CAIS during disruptive state. The threats to the internal validity in our paper are represented in the degree of support to the architectural explanation, where we have selected the GResilience approach throughout the explanation. In this respect, we did not consider the human cost and energy in the overall measurement, which left to future work. Threats to external validity are related to the degree of support for the generalization of the architectural explanation to a theoretical population. Which in our case is related to the application implementation that has been applied to the specific domain of CAIS, and CORAL robot. However, the framework itself is designed to be general.\nFinally, conclusion validity, which represents the degree of support of a statistical inference from a sample to a study population. It is important to state that the nature of our framework is mainly exploratory, and generalization beyond the CORAL application is needed for consolidating our claims. Thus, we plan to run more experiments with another real-world demonstrator we have in-house and with simulators.", "publication_ref": ["b16"], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "We have reviewed existing literature according to three lines of research: i) The non-functional properties to balance, specifically resilience and greenness, ii) The trading off techniques using optimization and game theory, iii) The decisionmaking support framework in CAIS context. In the following, we illustrate a brief overview of them. Resilience and Greenness. Methods and frameworks aim to build a resilient system have been discussed extensively by the literature, like using a multi-agent model by Janu\u00e1rio et al. [7], tri-optimization model by Liu et al. [9], and deep learning model by Zarandi et al. [19], to mention a few. The major goal of these methods is to restore the system performance from degradation caused by disruptive events to acceptable performance. The disruptive events are different depending on the system itself, for example, the disruptive event can be a security vulnerability of the system [9,19], a defect in the software or hardware parts [7], or caused by humans [15]. In this paper, we add an additional requirement to restore the system's performance. We are interested in restoring the performance while monitoring and controlling the energy adverse effects, which is how Kharchenko et al. [8] define greenness. Studies have discussed greenness as a default result of building a resilient system, such as, Pandey et al. [11]. Other studies seek to find a trading-off between greenness and resilience, [10,15].\nOptimization and Game Theory. In the greenness and resilience context, Mohammed et al. [10], propose a solution to optimize supply chain network distribution using the eco-gresilient model, which trades off between three objectives, specifically economical, green, and resilient. They used the proposed solution to find the best number of facilities in the supply network section. Game theory is a decision-making process with multiple actors. For instance, Xu et al. [18], defined a collaborative game to support the decision process for a recommendation system for users' satisfaction. To the best of our knowledge, using game theory to trade off non-functional properties is a novel idea that we have sketched in our previous work, [15]. In this current paper, we have built a novel framework that operationalizes our initial idea and we have exemplified it to CORAL. We have further worked on a case study on CORAL, which is now under submission, [14].\nDecision-Making Assistant. Various studies handle the automatic support of decision-making frameworks in CAIS context, by considering humans as the ground truth of the system's actions. They build specific knowledge about human actions and then use the knowledge to support decision-making by inferring human actions. For example, Chen et al. [3], build a computation model to assess the human trust in CAIS autonomous actions, and then it uses this assessment to automatically support decision-making with the action that maximizes the trust value. Other studies predict human actions using AI-based techniques, such as Ghadirzadeh et al. [5], using deep reinforcement learning, and Quintas et al. [12], who built an AI-agent that monitors human actions and generates descriptive scenarios to automatically support CAIS's decisions. As there are several frameworks to support decision-making, to our knowledge none of these frameworks provide extendable components backed with the toolbox and utilities needed, to first, simulate the system environment, second, automatically support decision-making through different decision-making mechanisms, and third visually analyze different experimental configurations, which make our framework (CAIS-DMA) a novel framework in that sense.", "publication_ref": ["b6", "b8", "b18", "b8", "b18", "b6", "b14", "b7", "b10", "b14", "b17", "b14", "b13", "b2", "b4", "b11"], "figure_ref": [], "table_ref": []}, {"heading": "Conclusion and Future Work", "text": "Conclusion. In this paper, we introduce our novel extendable framework CAIS-DMA to automatically support CAIS decision-making in an online learning process. CAIS-DMA aims to deal with different learning situations, for this reason, it contains a simulator, actuator, and monitoring component. The framework simulates CAIS environment and represents the potential disruptive events that face the specific CAIS. It monitors CAIS's performance to detect any performance degradation to automatically support the decision-making to recommend the actions that help in restoring the performance to an acceptable level. CAIS-DMA monitors the decision made by CAIS's AI model and overrides the selected action, by the action that best trade-off between the non-functional properties defined through measurement mechanisms. Additionally, CAIS-DMA supports running different experiments on CAIS's AI model through different experiment configurations and provides a visual analysis of the performance behavior. Finally, we demonstrate the framework through a real-world demonstrator, showing the implementation steps and the framework's extendable components. Future Work. This framework allows us to conduct a wider range of experiments with simulated data. Thus, we plan to run an experiment to compare the results from the simulation and the real-world case. Secondly, we plan to extend the framework in order to explore other non-functional properties such as safety. For instance, we can create a disruptive event that simulates an attack that alters the safe distance between the human and the robotic arm. In this case, we will study the actions that trade-off between human safety and system performance. Moreover, we plan to use the measurement mechanism results as reinforcement learning of the system that rewards recommended decisions.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Risk-driven compliance assurance for collaborative ai systems: A vision paper", "journal": "Springer", "year": "2021", "authors": "M Camilli; M Felderer; A Giusti; D T Matt; A Perini; B Russo; A Susi"}, {"ref_id": "b1", "title": "Microservices Integrated Performance and Reliability Testing", "journal": "ACM/IEEE", "year": "2022", "authors": "M Camilli; A Guerriero; A Janes; B Russo; S Russo"}, {"ref_id": "b2", "title": "Trust-aware decision making for human-robot collaboration: Model learning and planning", "journal": "ACM Transactions on Human-Robot Interaction (THRI)", "year": "2020", "authors": "M Chen; S Nikolaidis; H Soh; D Hsu; S Srinivasa"}, {"ref_id": "b3", "title": "Discussing resilience in the context of cyber physical systems", "journal": "Comput. Ind. Eng", "year": "2021", "authors": "S Colabianchi; F Costantino; G D Gravio; F Nonino; R Patriarca"}, {"ref_id": "b4", "title": "Humancentered collaborative robots with deep reinforcement learning", "journal": "IEEE Robotics and Automation Letters", "year": "2020", "authors": "A Ghadirzadeh; X Chen; W Yin; Z Yi; M Bj\u00f6rkman; D Kragic"}, {"ref_id": "b5", "title": "Generic metrics and quantitative approaches for system resilience as a function of time", "journal": "Reliability Engineering & System Safety", "year": "2012", "authors": "D Henry; J E Ramirez-Marquez"}, {"ref_id": "b6", "title": "A Distributed Multi-Agent Framework for Resilience Enhancement in Cyber-Physical Systems", "journal": "IEEE Access", "year": "2019", "authors": "F Janu\u00e1rio; A Cardoso; P Gil"}, {"ref_id": "b7", "title": "Concepts of green IT engineering: taxonomy, principles and implementation", "journal": "Springer", "year": "2017", "authors": "V Kharchenko; O Illiashenko"}, {"ref_id": "b8", "title": "A Distributionally Robust Scheme for Critical Component Identification to Bolster Cyber-Physical Resilience of Power Systems", "journal": "", "year": "2022", "authors": "Z Liu; L Wang"}, {"ref_id": "b9", "title": "Eco-Gresilient: Coalescing Ingredient of Economic, Green and Resilience in Supply Chain Network Design", "journal": "SciTePress", "year": "2018-01-24", "authors": "A Mohammed; I Harris; R Nujoom"}, {"ref_id": "b10", "title": "GreenTPU: Predictive Design Paradigm for Improving Timing Error Resilience of a Near-Threshold Tensor Processing Unit", "journal": "IEEE Trans. Very Large Scale Integr. Syst", "year": "2020", "authors": "P Pandey; P Basu; K Chakraborty; S Roy"}, {"ref_id": "b11", "title": "Toward a contextaware human-robot interaction framework based on cognitive development", "journal": "IEEE Transactions on Systems, Man, and Cybernetics: Systems", "year": "2018", "authors": "J Quintas; G S Martins; L Santos; P Menezes; J Dias"}, {"ref_id": "b12", "title": "Green Resilience of Cyber-Physical Systems", "journal": "IEEE", "year": "2022", "authors": "D Rimawi"}, {"ref_id": "b13", "title": "GResilience: Find a Tradeoff between Greenness and Resilience in Collaborative AI Systems", "journal": "", "year": "2023", "authors": "D Rimawi; A Liotta; M Todescato; B Russo"}, {"ref_id": "b14", "title": "GResilience: Trading Off Between the Greenness and the Resilience of Collaborative AI Systems", "journal": "Springer Nature Switzerland", "year": "2023", "authors": "D Rimawi; A Liotta; M Todescato; B Russo"}, {"ref_id": "b15", "title": "Cheating and enforcement in asymmetric rank-order tournaments", "journal": "Southern Economic Journal", "year": "2010", "authors": "C J Stowe; S M Gilpatric"}, {"ref_id": "b16", "title": "Six strategies for generalizing software engineering theories", "journal": "Science of computer programming", "year": "2015", "authors": "R Wieringa; M Daneva"}, {"ref_id": "b17", "title": "User participation in collaborative filtering-based recommendation systems: A game theoretic approach", "journal": "IEEE transactions on cybernetics", "year": "2018", "authors": "L Xu; C Jiang; Y Chen; Y Ren; K R Liu"}, {"ref_id": "b18", "title": "Detection and Identification of Cyber-Attacks in Cyber-Physical Systems Based on Machine Learning Methods", "journal": "", "year": "2020-12", "authors": "Z N Zarandi; I Sharifi"}], "figures": [{"figure_label": "2", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Fig. 2 .2Fig. 2. CAIS-DMA Architecture", "figure_data": ""}, {"figure_label": "17", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Algorithm 1 7 :17Performance Measurement Algorithm 1: W \u2190 W indowSize \u25b7 Variables Initialization 2: ADRT \u2190 ADRT hreshold 3: Q \u2190 Queue() 4: for i = 0 \u2192 W do 5: while True do \u25b7 Keep Monitoring The CAIS's AI Decisions 8: D, \u03f5 \u2190 ReadDecisionAndP robability() \u25b7 D: AI Decision, \u03f5: Confident Level", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Fig. 3 .3Fig. 3. Online Learning with CAIS-DMA", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Fig. 4 .4Fig. 4. Collaborative Robot Learning from Demonstrations -CORAL", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Fig. 5 .5Fig. 5. Equipping CORAL with CAIS-DMA, Simulate Cubes Colors Dataset, Support Decision Making using GResilience Mechanism, and Analyze Performance", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "The GResilience Game General Payoff Matrix", "figure_data": "Pg Pg Pga1(p) a1(p) a1(p)a2(1 -p) a2(1 -p) a2(1 -p)Pr Expected Payoff Pr Expected Payoff Pr Expected Payoff"}], "formulas": [{"formula_id": "formula_0", "formula_text": "ET i+1 a = ET i a + \u03b1 \u2022 (DT i a -ET i a )(1)", "formula_coordinates": [4.0, 235.76, 540.04, 244.83, 12.69]}, {"formula_id": "formula_1", "formula_text": "pP 1 r (a2) + (1 -p)P 2 r (a2) Pg Expected Payoff Pg Expected Payoff Pg Expected Payoff qP 2 g (a1) + (1 -q)P 1 g (a1) qP 1 g (a2) + (1 -q)P 2 g (a2)", "formula_coordinates": [5.0, 145.03, 192.41, 338.48, 23.7]}, {"formula_id": "formula_2", "formula_text": "ECF i+1 a = ECF i a + \u03b1 \u2022 (DCF i a -ECF i a )(2)", "formula_coordinates": [5.0, 218.93, 336.14, 261.67, 12.69]}, {"formula_id": "formula_3", "formula_text": "N HI i+1 a = N HI max -N HI i a -N HI a(3)", "formula_coordinates": [5.0, 223.62, 353.53, 256.97, 12.69]}, {"formula_id": "formula_4", "formula_text": "S(a) = w R \u2022 \u03f5 \u2022 N (ET -1 ) + w G \u2022 (1 -\u03f5) \u2022 {N (N HI) + N (ECF -1 )} (4)", "formula_coordinates": [5.0, 164.52, 585.39, 316.07, 11.72]}, {"formula_id": "formula_5", "formula_text": "P \u03b1 r (a) = \u03f5 \u2022 \u03b1 \u2022 ET -1 , P \u03b1 g (a) = (1 -\u03f5) \u2022 \u03b1 \u2022 N HI -1 \u2022 ECF -1(5)", "formula_coordinates": [6.0, 184.56, 487.9, 296.03, 12.69]}, {"formula_id": "formula_6", "formula_text": "ADR \u2190 Q.sum()/W \u25b7", "formula_coordinates": [8.0, 162.43, 232.01, 260.85, 6.12]}], "doi": ""}
