{"DPAN: Dynamic Preference-based and Attribute-aware Network for Relevant Recommendations": "Wei Dai, Yingmin Su, Xiaofeng Pan Yufeng Wang njuptdavid@163.com,guansuzai@126.com,pxfvintage@163.com Taobao & Tmall Group China", "Zhenyu Zhu, Nan Xu, Chengjun Mao": "{zzy234691,xiruo.xn,chengjun.mcj}@taobao.com Taobao & Tmall Group China", "ABSTRACT": "In e-commerce platforms, the relevant recommendation is a unique scenario providing related items for a trigger item that users are interested in. However, users' preferences for the similarity and diversity of recommendation results are dynamic and vary under different conditions. Moreover, individual item-level diversity is too coarse-grained since all recommended items are related to the trigger item. Thus, the two main challenges are to learn fine-grained representations of similarity and diversity and capture users' dynamic preferences for them under different conditions. To address these challenges, we propose a novel method called the Dynamic Preference-based and Attribute-aware Network (DPAN) for predicting Click-Through Rate (CTR) in relevant recommendations. Specifically, based on Attribute-aware Activation Values Generation (AAVG), Bi-dimensional Compression-based Re-expression (BCR) is designed to obtain similarity and diversity representations of user interests and item information. Then Shallow and Deep Union-based Fusion (SDUF) is proposed to capture users' dynamic preferences for the diverse degree of recommendation results according to various conditions. DPAN has demonstrated its effectiveness through extensive offline experiments and online A/B testing, resulting in a significant 7.62% improvement in CTR. Currently, DPAN has been successfully deployed on our e-commerce platform serving the primary traffic for relevant recommendations. The code of DPAN has been made publicly available 1 .", "CCS CONCEPTS": "", "\u00b7 Information systems \u2192 Recommender systems .": "", "KEYWORDS": "Click-Through Rate Prediction, Relevant Recommendation, Dynamic Neural Network, Attribute-aware Recommendation 1 https://github.com/DavidNeson/DPAN \u00a9 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0124-5/23/10...$15.00 https://doi.org/10.1145/3583780.3615218 wfwang@njupt.edu.cn Nanjing University of Posts and Telecommunications China", "Bo Cao": "zhizhao.cb@taobao.com Taobao & Tmall Group China", "ACMReference Format:": "Wei Dai, Yingmin Su, Xiaofeng Pan, Yufeng Wang, Zhenyu Zhu, Nan Xu, Chengjun Mao, and Bo Cao. 2023. DPAN: Dynamic Preference-based and Attribute-aware Network for Relevant Recommendations. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM '23), October 21-25, 2023, Birmingham, United Kingdom. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3583780.3615218", "1 INTRODUCTION": "In e-commerce platforms, users' instant interest can be explicitly induced with a trigger item, and follow-up related target items are recommended in relevant recommendations [8]. As shown in Figure 1, users may click on a trigger item from different channels such as the Search Result Page (SRP) or Homepage Guess You Like (GUL), and then navigate to the detail page. As users scroll down to browse more information, relevant recommendations are displayed. The correlation between the target items and the trigger is ensured by matching algorithms. Our paper focuses on optimizing the ClickThrough Rate (CTR) prediction of relevant recommendations. Search Guess You Like \u2026 2022 new summer backpack for middle school girls \u00a5 69.8 Relevant Recommendation \u2026 2022 new summer backpack for middle school girls \u00a5 69.8 click and enter the detail page scroll down and view the relevant items \u2026 Trigger Item Target Items With the progress of deep learning, CTR prediction has been studied from various aspects, including feature interaction [1, 4, 9, 10], sequential modeling [6, 7, 17, 18], and dynamic neural networks [2, 3, 13, 15, 16]. However, most of them neglect users' interests in the trigger, leading to unsatisfactory user experiences if directly applied to relevant recommendations. Only a few studies have focused on joint modeling with the trigger. For example, R3S [11] considers trigger articles' semantic relevance and information gain to provide users with more articles. DIHN [8] predicts the user's real intent on the trigger and adaptively extracts instant interest from historical behaviors regarding the trigger and the target. However, existing works overlook users' changing preferences for similarity and diversity in relevant recommendations under different conditions. Moreover, measuring diversity at the individual item level is too coarse as all target items are related to the trigger. For instance, when users click from SRP, they may prefer items with the same shop and category or similar images and titles to the trigger, indicating a preference for similarity. Conversely, when users click from GUL, they may prefer diversity and choose items with different attributes, such as different categories or brands compared to the trigger. Hence, modeling faces two challenges: learning attribute-aware representations of similarity and diversity, and capturing users' dynamic preferences under various conditions. We propose the Dynamic Preference-based and Attribute-aware Network (DPAN) to tackle the above challenges. Firstly, DPAN leverages rich attribute information (e.g., category, brand, price, and title) to generate activation values for each attribute sequence via Attribute-aware Activation Values Generation (AAVG). Then, Bidimensional Compression-based Re-expression (BCR) is employed after AAVG to obtain fine-grained similarity and diversity representations of user interests and item information. As users' intentions (e.g., buying or browsing) may change under different conditions, leading to varying preferences for similarity and diversity of recommendations, we propose the Shallow and Deep Union-based Fusion (SDUF) to capture users' dynamic preferences adaptively. Our main contributions are summarized as follows: \u00b7 We propose a novel CTR model named DPAN to satisfy users' dynamic preferences for similarity and diversity of relevant recommendations through learning attribute-aware representations. \u00b7 We design the Bi-dimensional Compression-based Reexpression to obtain the similarity and diversity representations of user interests and item information through mining information at the attribute level, and the Shallow and Deep Union-based Fusion to capture users' dynamic preferences in varying conditions. \u00b7 We conduct extensive offline experiments and online A/B testing in the industrial environment. Our results demonstrate the superior effectiveness of DPAN compared to SOTA models.", "2 PROPOSED METHOD": "", "2.1 Overall Architecture": "Figure 2 illustrates the overall architecture of DPAN. Firstly, all input features are transformed into embeddings by a feature embedding layer, including: 1) trigger item \ud835\udc86 \ud835\udc61\ud835\udc5f = [ \ud835\udc82 \ud835\udc61\ud835\udc5f 1 , ..., \ud835\udc82 \ud835\udc61\ud835\udc5f \ud835\udc3e ] , where \ud835\udc82 \ud835\udc61\ud835\udc5f \ud835\udc58 , \u2200 \ud835\udc58 \u2208 [ 1 , \ud835\udc3e ] denotes the embedding of the trigger's \ud835\udc58 -th attribute, and \ud835\udc3e is the number of attributes; 2) target item \ud835\udc86 \ud835\udc61\ud835\udc4e = [ \ud835\udc82 \ud835\udc61\ud835\udc4e 1 , ..., \ud835\udc82 \ud835\udc61\ud835\udc4e \ud835\udc3e ] ; 3) user behavior sequence \ud835\udc86 \ud835\udc60 = { \ud835\udc86 \ud835\udc60 1 , ..., \ud835\udc86 \ud835\udc60 \ud835\udc47 } , where \ud835\udc86 \ud835\udc60 \ud835\udc56 = [ \ud835\udc82 \ud835\udc60 \ud835\udc56 1 , ..., \ud835\udc82 \ud835\udc60 \ud835\udc56\ud835\udc3e ] , \u2200 \ud835\udc56 \u2208 [ 1 , \ud835\udc47 ] denotes the \ud835\udc56 -th behavior in sequence and \ud835\udc47 is the truncated sequence length; 4) user profile \ud835\udc86 \ud835\udc62 ; and 5) context information \ud835\udc86 \ud835\udc50 , such as the trigger's located channel, users' browsing time, and promotion events [5, 6]. Subsequently, the behavior sequence is split into several attribute sequences. Each attribute sequence is activated by the trigger and the target respectively, generating corresponding activation values through Attribute-aware Activation Values Generation (AAVG). Then AAVG output is processed using Bi-dimensional Compression-based Re-expression (BCR) to learn similarity and diversity representations of user interests and item information. Finally, with the aggregated representations of similarity and diversity obtained through a Multi-Layer Perceptron (MLP) as input, dynamic preference results are obtained via Shallow and Deep Union-based Fusion (SDUF) under various conditions.", "2.2 Attribute-aware Activation Values Generation": "Firstly, \ud835\udc86 \ud835\udc60 is divided into \ud835\udc3e attribute sequences, denoted as \ud835\udc82 \ud835\udc60 \ud835\udc58 = { \ud835\udc82 \ud835\udc60 1 \ud835\udc58 , ..., \ud835\udc82 \ud835\udc60 \ud835\udc47\ud835\udc58 } for the \ud835\udc58 -th attribute. Then, \ud835\udc82 \ud835\udc60 \ud835\udc56\ud835\udc58 , the embedding of the \ud835\udc56 -th element in \ud835\udc82 \ud835\udc60 \ud835\udc58 , is activated by \ud835\udc82 \ud835\udc61\ud835\udc5f \ud835\udc58 and \ud835\udc82 \ud835\udc61\ud835\udc4e \ud835\udc58 respectively via DIN's [18] activation unit to calculate corresponding activation values, namely \ud835\udc64 \ud835\udc61\ud835\udc5f \ud835\udc56\ud835\udc58 and \ud835\udc64 \ud835\udc61\ud835\udc4e \ud835\udc56\ud835\udc58 . All activation units share the same structures and parameters for the same attribute, and the Hadamard product is adopted for attribute crossing. We also feed \ud835\udc82 \ud835\udc61\ud835\udc5f \ud835\udc58 and \ud835\udc82 \ud835\udc61\ud835\udc4e \ud835\udc58 into the activation unit to calculate \u02c6 \ud835\udc66 \ud835\udc58 , predicting whether the \ud835\udc58 -th attribute is clicked. Accordingly, we formulate the auxiliary loss as: where D is the training set with |D| samples, with \ud835\udc99 as the input and \ud835\udc66 \u2208 { 0 , 1 } as the label of whether the target is clicked. The auxiliary loss for each attribute is added to the final loss with a zoom factor \ud835\udefc . Further, we calculate the dual activation score as \ud835\udc64 \ud835\udc61\ud835\udc61 \ud835\udc56\ud835\udc58 = \ud835\udc64 \ud835\udc61\ud835\udc5f \ud835\udc56\ud835\udc58 \u00b7 \ud835\udc64 \ud835\udc61\ud835\udc4e \ud835\udc56\ud835\udc58 , which will be high if \ud835\udc82 \ud835\udc60 \ud835\udc56\ud835\udc58 is highly correlated with the corresponding attribute of the trigger and the target simultaneously.", "2.3 Bi-dimensional Compression-based Re-expression": "After AAVG, we devise Bi-dimensional Compression-based Reexpression (BCR) to learn similarity and diversity representations of user interests and item information at the attribute level. To elaborate, we compress along the attribute dimension in User Interests Embedding Module (UIEM) to derive user interests representations and compress along the sequence dimension in Item Information Embedding Module (IIEM) to capture item information representations. UIEM . The overall correlation between the target and each sequence item is obtained by averaging the target-activated scores of each attribute, i.e., compressing along the attribute dimension. UIEM focuses on the user behaviors with higher correlation scores and obtains the representation of user interests towards the target via weighted sum pooling. Behaviors with higher relevance to the target receive higher weights and dominate the representation of user interests. Thus the diversity representation of user interests, which varies over different target items, is calculated as follows, In order to obtain the similarity representation of user interests, UIEM captures items that are related to both the trigger and the target in the behavior sequence, so the target-activated scores are replaced by dual-activated scores, which are calculated as follows: It is noteworthy that only behaviors that are related to both the trigger and the target at the same time will receive higher weights, thus ensuring the similarity between user interests and the trigger. IIEM . Users have varying levels of attention toward different attributes. To determine the user's preference score for each attribute, the target-activated scores of all items in each attribute sequence are averaged, i.e., compressing along the sequence dimension. IIEM assigns higher weights to attributes with higher scores and re-expresses the target via weighted sum pooling, Seq 1 Seq 2 Seq T User Similarity User Diversity Attributes Compression Behavior sequence I C B \u2026 Behavior Sequence Feature Embedding Layer I C B I C B User Profile Context Trigger Target I I I I \u2026 I Trigger ItemId ItemId Sequence Activation Unit Activation Unit Activation Unit Auxiliary Loss Item \u2026 \u2026 Auxiliary Loss Cate Auxiliary Loss Brand \ud835\udc64 !\" \ud835\udc64 !! K attributes \u2026 \u2026 share Target ItemId \ud835\udc64 !# I I Cross Linear Activation Unit MLPlayer Similarity Item Cate Brand Crossed attributes Item Cate Brand Target attributes Item Similarity Item Diversity Sequence Compression MLP layer Diversity Conditional Input \ud835\udc7e \ud835\udc94 \ud835\udc7e % & \ud835\udc7e ' & \ud835\udc7e ! \" FC FC FC 1- Reshape Shallow Union Deep Union Parameter Generation Parameter Generation Network Concatenation Layer MLP Layer Output Attribute-aware Activation Values Generation IIEM Shallow and Deep Union-based Fusion Seq Item 2 Seq Item 1 Seq Item T \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 ItemId CateId BrandId \u2026 UIEM Bi-dimensional Compression-based Re-expression \u2026 \u2026 Note that with the trigger information excluded, Equation 4 reexpress the target according to the rich user behaviors, making \ud835\udc97 \ud835\udc51\ud835\udc56\ud835\udc63 \ud835\udc3c a diversity representation of item information. where \ud835\udc7e \ud835\udc60 denotes parameters of the shallow union network, and \ud835\udc7e \ud835\udc51 1 , \ud835\udc7e \ud835\udc51 2 , ..., \ud835\udc7e \ud835\udc51 \ud835\udc3f are parameters for the deep union network. For similarity, we take into account users' focus on both the trigger and the target attributes. We replace the target-activated scores with dual-activated scores and assign weights to the crossed attributes of the trigger and the target, as shown below: These crossed attributes are shared with the crossed attributes in the activation unit. The similarity representation of item information incorporates both the trigger and the target information, while also being influenced by users' preferences for different attributes.", "2.4 Shallow and Deep Union-based Fusion": "Following BCR, the similarity and diversity representations of user interests and item information are combined via different MLPs to generate the aggregated similarity and diversity representations with the same dimension, denoted as \ud835\udc97 \ud835\udc60\ud835\udc56\ud835\udc5a and \ud835\udc97 \ud835\udc51\ud835\udc56\ud835\udc63 . To capture users' dynamic preferences, we designed Shallow and Deep Union based-Fusion (SDUF), which includes a shallow union network, and a deep union network of \ud835\udc3f Fully-Connected Layers. The aggregated representations are fed into these networks to generate fusion representations in both low-dimensional and high-dimensional spaces. The parameters of these two networks are dynamically generated through a parameter generation network [13, 15]. To generate parameters for the union networks, we input conditional information \ud835\udc89 \ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc51 (e.g., context and trigger information) into the parameter generation network. Note that target information cannot be used as conditional input since it represents posterior knowledge. Then a series of parameters is generated as follows: The shallow union network combines the similarity and diversity representations using the element-wise product with \ud835\udc7e \ud835\udc60 as follows: In the deep union network, \ud835\udc97 \ud835\udc60\ud835\udc56\ud835\udc5a and \ud835\udc97 \ud835\udc51\ud835\udc56\ud835\udc63 are concatenated as input \ud835\udc89 0 = [ \ud835\udc97 \ud835\udc60\ud835\udc56\ud835\udc5a , \ud835\udc97 \ud835\udc51\ud835\udc56\ud835\udc63 ] \u2208 R \ud835\udc51 0 . We reshape \ud835\udc7e \ud835\udc51 \ud835\udc59 to obtain \ud835\udc59 -th layer's parameters, i.e., \ud835\udc7e \ud835\udc59 = \ud835\udc5f\ud835\udc52\ud835\udc60\u210e\ud835\udc4e\ud835\udc5d\ud835\udc52 ( \ud835\udc7e \ud835\udc51 \ud835\udc59 ) \u2208 R \ud835\udc51 \ud835\udc59 -1 \u00d7 \ud835\udc51 \ud835\udc59 . The \ud835\udc59 -th layer's output is calculated as \ud835\udc89 \ud835\udc59 = \ud835\udf0e ( \ud835\udc89 \ud835\udc59 -1 \ud835\udc7e \ud835\udc59 ) , and we use the \ud835\udc3f -th layer's output as the result of the deep union network, i.e., \ud835\udc97 \ud835\udc51\ud835\udc62 = \ud835\udc89 \ud835\udc3f . Finally, the results of SDUF, along with input features (i.e., \ud835\udc86 \ud835\udc61\ud835\udc5f , \ud835\udc86 \ud835\udc61\ud835\udc4e , \ud835\udc86 \ud835\udc62 and \ud835\udc86 \ud835\udc50 ), are combined and fed into the final scoring network through an MLP with Sigmoid activation for resulting click probability. The widely-used logloss is used for training, and auxiliary losses in Equation 1 are also incorporated into the final loss.", "3 EXPERIMENTS": "", "3.1 Experimental Setup": "Dataset . To the best of our knowledge, there are no public datasets available for relevant recommendations. Therefore, we obtained our proprietary industrial dataset by collecting logs from our platform's relevant recommendation scenario between 05/01 and 05/14, 2022. To mitigate the impact of invalid impressions caused by users quickly scrolling through the page, we treat clicked items as positive samples, while non-clicked items around the clicked items as negative samples in sample selection. The detailed statistics are shown in Table 1. Then we split the dataset into two non-overlapping parts for training (05/01-05/13) and testing (05/14). Competitors . DIN [18] and DIEN [17] aim to extract users' (evolving) interests with respect to the target. DHAN [12] captures users' interests in different attributes through multi-dimensional hierarchical structures. To ensure fair comparisons, we incorporate the trigger information into the above methods via the activation calculation between the trigger and users' historical behaviors. In relevant recommendations, R3S [11] effectively extracts information between the target and the trigger, but it neglects the modeling of sequential behaviors. Thus, we implement R3S+DIN for comparison. DIHN [8] fuses the trigger and the target embeddings based on the users' intent on the trigger and then extracts users' interests from historical behaviors through hybrid interest extraction. Experimental Settings . We implemented all methods using TensorFlow 1.12, with a mini-batch size of 1024, and Adagrad optimizer with a learning rate of 0.01. For DPAN, we set the zoom factor \ud835\udefc to 0.1, the truncated user sequence length \ud835\udc47 to 50, and the embedding size for each attribute to 16. The attributes used include item, brand, category, price, and title. The dimension of aggregated representations is 128. The conditional input consists of the channel, browsing time, and trigger information. In the deep union network, \ud835\udc3f is set to 2 and the number of layers is [256, 128]. We take AUC as the evaluation metric and use RelaImpr [14] to measure relative improvements.", "3.2 Comparison Experiments": "The offline comparison results are presented in Table 2 and the major observations are summarized as follows. 1) DHANemployed hierarchical structures to capture important attribute information and outperformed traditional sequential modeling methods such as DIN and DIEN, which indicated the efficacy of utilizing attribute information. 2) R3S+DIN achieved 4.54% improvement over DIN by extracting interaction features between the target and the trigger. DIHN captured users' intent on the trigger and achieved runnerup performance. Both of them highlight the importance of trigger information. 3) DPAN uses BCR to learn precise representations of similarity and diversity over attribute-aware values generated by AAVG and then uses SDUF to dynamically capture users' preferences under varying conditions, achieving the best result. Compared with DIHN focusing on the extent of users' interests in the trigger to generate users' dynamic interests representations, DPAN emphasizes users' preferences for recommendations' diversity and similarity under various conditions and then fuses these representations dynamically. In our online relevant recommendation scenario, we conducted a rigorous half-month A/B testing with roughly equal traffic for both experiments, reaching over 600,000 users daily. As a result, DPAN outperformed DIN with a significant 7.62% increase in CTR.", "3.3 Ablation Study": "Results in Table 3 demonstrate the impact of removing each module. 1) Auxiliary Loss of AAVG : Removing the auxiliary losses resulted in a decline in AUC indicating that these losses help in better learning of embeddings for each attribute. 2) Attributes of AAVG : To demonstrate the importance of multiple attributes, we reserved only the item as a basic attribute. The reduction in AUC highlights the necessity to leverage rich attribute information. 3) Similarity Representations of BCR : With diversity representations reserved as the fundamental information for sequential recommendations, we investigate the influences of similarity representations of user interests and item information by removing each separately. The noticeable decline of the AUC underscores the importance of these similarity representations in capturing the user's instant interest, which is necessary for satisfying their preferences. 4) Union Networks of SDUF : We analyzed the effect of shallow and deep union networks by removing each separately. Both networks provide additional information for learning users' preferences, and the deep union network had a relatively larger impact.", "3.4 Case Study": "2.36 2.48 1.94 1.89 0 0.5 1 1.5 2 2.5 3 Baseline-DIN DPAN a) Exposed category numbers per user channel-GUL channel-SRP 6.64 7.39 6.92 7.18 6.2 6.4 6.6 6.8 7 7.2 7.4 7.6 Baseline-DIN DPAN b) Exposed brand numbers per user channel-GUL channel-SRP In this section, we measure the model's ability to capture users' preferences for recommendation results' similarity and diversity by computing the exposed category and brand numbers per user. As there are many conditional factors influencing users' dynamic preferences, our analysis primarily focuses on the variations observed under different channels. As shown in Figure 3, DPAN is capable of providing items with a wider range of categories and brands when users navigate from GUL. This aligns with our expectations, as users clicking from GUL are more likely to seek out diverse options, whereas those clicking from SRP typically have a specific purchase in mind and tend to compare similar items, and DPAN's recommendations become more convergent in this case. In contrast, DIN, the baseline model, fails to provide such dynamic recommendations, resulting in inferior performance.", "4 CONCLUSION": "In this paper, we present the Dynamic Preference-based and Attribute-aware Network (DPAN) for relevant recommendations. Through attribute-aware Bi-dimensional Compression-based Reexpression and Shallow and Deep Union-based Fusion, DPAN demonstrates its superiority in satisfying users' dynamic preferences for recommendation results' similarity and diversity under various conditions. Extensive offline experiments and online A/B testing confirm the effectiveness of DPAN for relevant recommendations.", "REFERENCES": "[1] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247 (2017). [2] Yizeng Han, Gao Huang, Shiji Song, Le Yang, Honghui Wang, and Yulin Wang. 2021. Dynamic neural networks: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence (2021). [3] Ming Li, Naiyin Liu, Xiaofeng Pan, Yang Huang, Ningning Li, Yingmin Su, Chengjun Mao, and Bo Cao. 2023. FAN: Fatigue-Aware Network for ClickThrough Rate Prediction in E-commerce Recommendation. In International Conference on Database Systems for Advanced Applications . Springer, 502-514. [4] Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018. xdeepfm: Combining explicit and implicit feature interactions for recommender systems. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1754-1763. [5] Xiaofeng Pan, Ming Li, Jing Zhang, Keren Yu, Hong Wen, Luping Wang, Chengjun Mao, and Bo Cao. 2022. Metacvr: Conversion rate prediction via meta learning in small-scale recommendation scenarios. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval . 2110-2114. [6] Xiaofeng Pan, Yibin Shen, Jing Zhang, Xu He, Yang Huang, Hong Wen, Chengjun Mao, and Bo Cao. 2023. MOEF: Modeling Occasion Evolution in Frequency Domain for Promotion-Aware Click-Through Rate Prediction. In International Conference on Database Systems for Advanced Applications . Springer, 330-340. [7] Qi Pi, Guorui Zhou, Yujing Zhang, Zhe Wang, Lejian Ren, Ying Fan, Xiaoqiang Zhu, and Kun Gai. 2020. Search-based user interest modeling with lifelong sequential behavior data for click-through rate prediction. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management . 2685-2692. [8] Qijie Shen, Hong Wen, Wanjie Tao, Jing Zhang, Fuyu Lv, Zulong Chen, and Zhao Li. 2022. Deep Interest Highlight Network for Click-Through Rate Prediction in Trigger-Induced Recommendation. In Proceedings of the ACM Web Conference 2022 . 422-430. [9] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep & cross network for ad click predictions. In Proceedings of the ADKDD'17 . 1-7. [10] Ruoxi Wang, Rakesh Shivanna, Derek Cheng, Sagar Jain, Dong Lin, Lichan Hong, and Ed Chi. 2021. Dcn v2: Improved deep & cross network and practical lessons for web-scale learning to rank systems. In Proceedings of the Web Conference 2021 . 1785-1797. [11] Ruobing Xie, Rui Wang, Shaoliang Zhang, Zhihong Yang, Feng Xia, and Leyu Lin. 2021. Real-time Relevant Recommendation Suggestion. In Proceedings of the 14th ACM International Conference on Web Search and Data Mining . 112-120. [12] Weinan Xu, Hengxu He, Minshi Tan, Yunming Li, Jun Lang, and Dongbai Guo. 2020. Deep interest with hierarchical attention network for click-through rate prediction. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval . 1905-1908. [13] Bencheng Yan, Pengjie Wang, Kai Zhang, Feng Li, Jian Xu, and Bo Zheng. 2022. APG: Adaptive Parameter Generation Network for Click-Through Rate Prediction. arXiv preprint arXiv:2203.16218 (2022). [14] Ling Yan, Wu-Jun Li, Gui-Rong Xue, and Dingyi Han. 2014. Coupled group lasso for web-scale ctr prediction in display advertising. In International Conference on Machine Learning . PMLR, 802-810. [15] Xuanhua Yang, Xiaoyu Peng, Penghui Wei, Shaoguo Liu, Liang Wang, and Bo Zheng. 2022. AdaSparse: Learning Adaptively Sparse Structures for Multi-Domain Click-Through Rate Prediction. arXiv preprint arXiv:2206.13108 (2022). [16] Qianqian Zhang, Xinru Liao, Quan Liu, Jian Xu, and Bo Zheng. 2022. Leaving No One Behind: A Multi-Scenario Multi-Task Meta Learning Approach for Advertiser Modeling. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining . 1368-1376. [17] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Deep interest evolution network for click-through rate prediction. In Proceedings of the AAAI conference on artificial intelligence , Vol. 33. 5941-5948. [18] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1059-1068."}
