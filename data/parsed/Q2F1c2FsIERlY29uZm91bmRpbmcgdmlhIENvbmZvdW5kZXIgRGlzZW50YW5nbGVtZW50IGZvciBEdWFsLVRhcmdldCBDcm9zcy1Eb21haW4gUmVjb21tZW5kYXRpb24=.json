{"Causal Deconfounding via Confounder Disentanglement for Dual-Target Cross-Domain Recommendation": "JIAJIE ZHU and YAN WANG \u2217 , Macquarie University, Australia FENG ZHU, Ant Group, China ZHU SUN, Singapore University of Technology and Design, Singapore, Singapore In recent years, dual-target Cross-Domain Recommendation (CDR) has been proposed to capture comprehensive user preferences in order to ultimately enhance the recommendation accuracy in both data-richer and data-sparser domains simultaneously. However, in addition to users' true preferences, the user-item interactions might also be affected by confounders (e.g., free shipping, sales promotion). As a result, dual-target CDR has to meet two challenges: (1) how to effectively decouple observed confounders, including single-domain confounders and cross-domain confounders, and (2) how to preserve the positive effects of observed confounders on predicted interactions, while eliminating their negative effects on capturing comprehensive user preferences. To address the above two challenges, we propose a C ausal D econfounding framework via C onfounder D isentanglement for dual-target C rossD omain R ecommendation, called CD2CDR. In CD2CDR, we first propose a confounder disentanglement module to effectively decouple observed single-domain and cross-domain confounders. We then propose a causal deconfounding module to preserve the positive effects of such observed confounders and eliminate their negative effects via backdoor adjustment, thereby enhancing the recommendation accuracy in each domain. Extensive experiments conducted on seven real-world datasets demonstrate that CD2CDR significantly outperforms the state-of-the-art methods. CCS Concepts: \u00b7 Information systems \u2192 Recommender systems ; \u00b7 Computing methodologies \u2192 Neural networks . Additional Key Words and Phrases: Cross-Domain Recommendation, Confounder Disentanglement, Causal Deconfounding", "ACMReference Format:": "Jiajie Zhu, Yan Wang, Feng Zhu, and Zhu Sun. 2018. Causal Deconfounding via Confounder Disentanglement for Dual-Target Cross-Domain Recommendation. J. ACM 37, 4, Article 111 (August 2018), 31 pages. https://doi.org/XXXXXXX.XXXXXXX", "1 Introduction": "Cross-Domain Recommendation (CDR) aims to transfer valuable information from a relatively data-richer source domain to a relatively data-sparser target domain to improve recommendation performance, forming single-target CDR [93]. Effective CDR requires the source and target domains to share certain relatedness while maintaining distinctions in user intents, user behaviors, or item categories [43]. For instance, on e-commerce platforms like Taobao 1 , different purchase scenarios, such as 'what to take when travelling' and 'how to dress up for a party', share overlapping user interests (e.g., Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Manuscript submitted to ACM User Preference original price over budget Confounder User-Item Interaction (a) Causal graph for recommendation sales promotion sales promotion A CDC's positive impact (highlighted in green color) on predicting interaction serves as a catalyst serves as a catalyst like like discounted price over budget discounted price within budget The recommendation process of RS is affected by a CDC's negative impact (highlighted in red color) (1) RS perceives sales promotion as user preference (2) RS selects items with sales promotion However, such biased recommendations do not align with Alice's preferences 'add to favorite' domain 'purchase' domain purchase an item add an item to favorite Legend negative impact of a confounder (3) RS mistakenly recommends such items primary cause secondary cause positive impact of a confounder C Z Y Alice (a buyer) dress #1 dress #2 dress #3 dress #4 (d) (e) same item offered at the same price by different sellers in 'purchase' domain tend to purchase with free shipping without free shipping An SDC's positive impact (highlighted in green color) on predicting interaction serves as a catalyst The recommendation process of RS is affected by an SDC's negative impact (highlighted in red color) (1) RS perceives free shipping as user preference (2) RS selects an item with free shipping However, such biased recommendation do not align with Alice's preference (3) RS mistakenly recommends such item tend to purchase (b) (c) finding suitable clothing or accessories), while maintaining distinctions in user intents, such as practicality for travel and aesthetics for parties [12, 88]. Similarly, on Tmall 2 , behaviors such as 'add to favorite' and 'purchase' can be regarded as business domains, both reflecting user interest but differing in their focus as exploration- and purchase-oriented actions, respectively [32, 86]. In contrast, on Amazon, domains often refer to different item categories (e.g., 'movie' and 'book') that share user interests in certain features (e.g., genres or styles), while differing in domain-specific item features and user preferences [5, 57]. These relatedness and distinctions together define the principle of domains, thereby ensuring CDR's adaptability to diverse recommendation scenarios. In addition, on top of the same above-mentioned principle of domains, Dual-Target CDR [96] has been proposed to capture comprehensive user preferences, and thus enhance the recommendation accuracy in both data-richer and data-sparser domains simultaneously, which are source domains and target domains as well. However, in addition to users' true preferences, the user-item interactions might also be affected by confounding factors. A confounding factor, termed as confounder in causal inference [14, 101], affects both the treatment and the outcome [42, 69], which can be broadly interpreted as user preference and user-item interaction respectively (see Fig. 1(a)) in the context of recommender systems (RSs) [16, 100]. In the dual-target CDR scenario, observed confounders can be divided into two types, i.e., single-domain confounder (SDC) and cross-domain confounder (CDC). SDC only affects user preference and user-item interaction in one specific domain and has been widely studied in the existing literature [63, 85]. By contrast, CDC affects both domains, which, however, has been overlooked in existing dual-target CDR methods. Essentially, SDC is a simplified version of CDC. Below we first briefly review SDCs and then provide an in-depth analysis of CDCs, both illustrated with examples from Tmall, where 'purchase' and 'add to favorite' are regarded as two domains, as they align with the principle of domains. SDCs have both positive and negative impacts on predicting user-item interactions in their corresponding domain. For instance, as shown in Figs. 1(b)-1(c), 'free shipping' is an SDC in the 'purchase' domain. Consider a scenario where the same item is offered at the same price by different sellers. One seller provides free shipping, while the other provides shipping with an additional cost. Thus, the offer with free shipping positively influences Alice's decision to purchase the item with free shipping. As for negative impact, a data-driven RS improperly perceives 'free shipping' (i.e., an SDC shown in Fig. 1(c)) as Alice's preference in the 'purchase' domain. As a result, the data-driven RS mistakenly recommends an item with free shipping that Alice does not actually like to her. This misalignment, referred to as confounding bias [31], results in biased recommendations. In fact, the confounding biases also exist in cross-domain scenarios. More importantly, CDCs have both positive and negative impacts on predicting user-item interactions in both domains. For example, as illustrated in Figs. 1(d)-1(e), 'sales promotion' is a CDC, because it simultaneously affects 'purchase' and 'add to favorite' domains. On the one hand, this 'sales promotion' CDC has a positive impact. In fact, while Alice's true preference is the primary cause of her behaviors in both domains, 'sales promotion' is a secondary cause that serves as a catalyst. With a new sales promotion on dresses #1 and #2, both of which Alice likes but previously found over her budget, she immediately purchases dress #1 that has become affordable within her budget. By contrast, since the discounted price of dress #2 is still over her budget, she adds it to favorite for future consideration, looking forward to a further price reduction. On the other hand, this 'sales promotion' CDC has a negative impact too. As depicted in Fig. 1(e), a data-driven RS improperly perceives 'sales promotion' (i.e., a CDC) as Alice's preference in both domains. As a result, the data-driven RS mistakenly recommends dresses #3 and #4 with sales promotion to Alice, but Alice actually does not like them. Based on the above discussion, an effective dual-target CDR should deconfound both observed single-domain and cross-domain confounders , which includes three tasks, namely, (1) identify and decouple such observed confounders, (2) preserve their positive impacts on predicted interactions, and (3) eliminate their negative impacts on user preferences [76]. However, existing dual-target CDR approaches overlook the above observations. Thus, a novel dual-target CDR model should be proposed to incorporate such insights for comprehensively understanding user-item interactions. To effectively advance dual-target CDR, the following two key challenges need to be addressed. CH1. How to effectively decouple observed cross-domain confounders in addition to single-domain confounders to comprehensively understand user-item interactions in dual-target CDR? The existing dual-target CDR methods either employ graph clustering strategy [33] and variational information bottleneck [3], or identify unobserved domain-specific confounders first, and then utilize causal techniques, e.g., inverse propensity score (IPS) estimators [32] and invariant learning [86], to obtain debiased representations (it is worth mentioning that domain-specific confounders in existing works are different from SDCs in our work, see Section 2.2 for elaboration). However, none of them explicitly decouples observed CDCs, and thus it is hard to obtain a comprehensive understanding of user-item interactions in each domain. CH2. How to preserve the positive impacts of observed confounders on predicted interactions, while eliminating their negative impacts on capturing comprehensive user preferences, thereby enhancing the recommendation accuracy in both domains? Most existing causal methods [68, 73] tend to eliminate the confounders' negative impacts, in order to obtain the debiased comprehensive user preferences for recommendation. However, most of them overlook the confounders' positive impacts, and thus limit their efficacy in enhancing the recommendation accuracy [79]. Our Approach and Contributions. To address the above two challenges, we propose a novel causal deconfounding framework via confounder disentanglement for dual-target CDR. To the best of our knowledge, this is the first work in the literature that explicitly decouples observed CDCs, and incorporates observed confounders' positive impacts into debiased comprehensive user preferences for dual-target CDR. The characteristics and contributions of our framework can be summarized as follows: \u00b7 We first propose a C ausal D econfounding framework via C onfounder D isentanglement for dual-target C rossD omain R ecommendation, called CD2CDR, which can disentangle two types of observed confounders (i.e., SDCs and CDCs), eliminate their negative impacts to obtain debiased preferences, and preserve such confounders' positive impacts, thereby enhancing the recommendation accuracy in both domains; \u00b7 To address CH1 , we propose a confounder disentanglement module to effectively disentangle observed SDCs and CDCs. In this module, we devise a dual adversarial structure to disentangle SDCs in each domain and apply half-sibling regression to decouple CDCs, thus obtaining a comprehensive understanding of user-item interactions in each of both domains; \u00b7 To address CH2 , we propose a causal deconfounding module to deconfound disentangled observed SDCs and CDCs via backdoor adjustment. Specifically, we design a confounder selection function to mitigate such observed confounders' negative effects, thereby recovering debiased comprehensive user preferences. We then incorporate the observed confounders' positive effects into such debiased user preferences to enhance the recommendation accuracy in both domains; \u00b7 Extensive experiments conducted on seven real-world datasets demonstrate that our CD2CDR outperforms the best-performing state-of-the-art baseline with an average increase of 6.17% and 8.23% w.r.t. HR@10 and NDCG@10, respectively.", "2 Related Work": "", "2.1 Single-Target and Dual-Target CDR": "Single-Target CDR. Single-Target CDR [96] focuses on addressing the data sparsity problem by utilizing the abundant information available in a data-richer domain to improve the recommendation performance in a data-sparser domain. The existing single-target CDR approaches can be divided into two categories: (1) content-based transfer, and (2) feature-based transfer [96]. Content-based transfer [26] leverages user/item attributes and textual information to establish links across domains. By contrast, feature-based transfer [13, 23] employs machine learning techniques to extract user/item embeddings or rating patterns [77] for cross-domain transfer. Dual-Target CDR. Unlike single-target CDR, dual-target CDR [93] aims to enhance the recommendation accuracy in both data-richer and data-sparser domains by bidirectionally sharing knowledge, providing a basis for its expansion into Multi-Target CDR [17, 97]. The existing dual-target CDR methods can be roughly classified into two classes: (1) conventional methods, and (2) disentanglement-based methods. Conventional methods utilize two base encoders to transform each domain's interaction data into embeddings, which are then symmetrically incorporated through various transfer layers [30, 39]. By contrast, disentanglement-based methods employ variational autoencoder (VAE) [2] or other decoupling approaches [81] to disentangle domain-shared user preferences for common knowledge transfer, and then incorporate such preferences with decoupled domain-specific or domain-independent user preferences to capture comprehensive user preferences. However, these methods overlook that, in addition to users' true preferences, users' final decisions are also influenced by confounders, which limits their ability to accurately predict user-item interactions, leading to suboptimal recommendation results.", "2.2 Deconfounded Recommendation": "In recent years, causal learning [70, 72] has been introduced into RSs due to its ability to effectively tackle confounding problems arising from confounders, which can be classified into two types: observed confounders and unobserved confounders. For observed confounders, the existing deconfounded RSs adopt inverse propensity weighting (IPW) [54] or backdoor adjustment [63] to address the observed specific confounders, such as item popularity [85] and video duration [22, 79]. For unobserved confounders, the existing deconfounded RSs either add additional assumptions [36, 37] or infer substitutes for confounders [67, 80] to alleviate the confounding bias. Moreover, recent research efforts have extended confounder debiasing into CDR scenarios, focusing mainly on unobserved confounders. The unobserved confounders can be further categorized into two classes: domain-specific confounders (e.g., purchase-guided domain setting) and general confounders (e.g., the display position of items) [32]. Both classes cannot be captured from the datasets, and thus they are different from the observed SDCs and CDCs. Most of existing approaches tend to remove the negative influences of domain-specific confounders [32, 86] or general confounders [74, 89], but overlook the positive influences of such confounders, leading to an incomplete understanding of user-item interactions. In contrast to unobserved confounders [24, 34], which are hidden and often difficult to estimate, observed confounders can be explicitly decoupled. As long as observed confounders are accurately disentangled, they can facilitate the design of effective deconfounding module for more precise deconfounding. However, none of existing approaches explicitly decouples observed CDCs, and preserves the positive influences of observed confounders on predicted interactions, and thus it is hard to achieve a comprehensive understanding of user-item interactions.", "2.3 Disentangled Recommendation": "Disentangled representation learning (DRL) has recently gained increasing interest in RSs, aiming to decouple users' true preferences from confounding factors for more robust recommendation. For example, MacridVAE [44] models disentangled embeddings of user intentions from user-item interactions at both macro- and micro-level to reduce the impact of confounding factors. Moreover, DICE [91] tends to decouple users' interests and conformity to extract the desired causes of user-item interactions for robust recommendation. In addition, DRL has also been effectively applied to multi-interest recommendation [4], where the goal is to identify and separate users' diverse preference facets. One key challenge in this area is the collapse issue, where initially distinct interest embeddings become increasingly similar during training, resulting in a loss of diversity and a failure to capture users' multifaceted preferences. To address this challenge, researchers have proposed various disentanglement-based strategies, which can be broadly classified into two groups [11]. The first group of approaches primarily tackles the collapse issue through statistical regularization, aiming to enforce diversity among interest embeddings. Rather than modeling semantic differences directly, these approaches impose various mathematical constraints on the learning process to discourage homogeneity in the representation space. For instance, REMI [71] enhances multi-interest representation learning by introducing an interest-aware hard negative mining strategy alongside routing regularization, effectively preventing the routing collapse in capsule networks. Furthermore, VALID [60] achieves disentanglement within the regularization framework by iteratively refining personalized item clusters via latent attention. The second group of approaches mainly handle the collapse issue through representation-guided refinement, focusing on optimizing the bidirectional relationships between interest embeddings and their corresponding items. For example, DisMIR [45] leverages disentanglement techniques to separate user intentions within sequential behavior patterns, applying self-supervised learning in the latent space to maintain interest diversity and prevent representation collapse over time. Moreover, Re4 [84] disentangles user interests by implementing backward flows from interests to items. In addition to multi-interest recommendation, DRL has also been applied to causal recommendation. Existing disentanglement-based methods [65] first decouple the semantic-aware intent embeddings, and then employ causal intervention [40, 76] to alleviate the confounding bias. Unlike prior works [8], our work focuses on decoupling both observed SDCs and CDCs.", "2.4 Deconfounded Domain Generalization": "Domain generalization [62, 92] aims to train models on labeled data from source domains to enhance their generalization ability across unseen target domains by learning domain-invariant feature representations. However, confounders influencing both features and labels can undermine such representations, preventing models from capturing the true causal effects. In recent years, causal inference techniques [56, 82] have been employed to address these confounding problems in domain generalization, thereby enhancing the model's ability to generalize accurately across varied domains. For instance, a line of existing works [41, 87] simply adopts the average value of all domain features in each domain as the confounder, and employs backdoor adjustment to capture the true causality. Another line of works incorporates interventional pseudo-correlation augmentation [50] or adversarial training [61] to remove the confounders to better generalize to the unseen domain. There is also another line of works that exploits the instrumental variables [78] or learns substitutes [25] to eliminate the unobserved confounders and capture the invariant features for domain generalization. However, most of existing works either neglect domain-variant features or use off-the-shelf features as confounders instead of explicitly decoupling such confounders, leading to degraded deconfounding performance.", "3 Preliminaries": "", "3.1 Problem Definition": "For improved readability, in Table 1, we present the important notations used in this paper. The paper explores a fully overlapping dual-target CDR scenario in the domains \ud835\udc37 \ud835\udc34 and \ud835\udc37 \ud835\udc35 , with a common user set U , the size of which is denoted as \ud835\udc5a = |U| . Let V \ud835\udc34 (of size \ud835\udc5b \ud835\udc34 = |V \ud835\udc34 | ) and V \ud835\udc35 (of size \ud835\udc5b \ud835\udc35 = |V \ud835\udc35 | ) denote the item sets in the domains Manuscript submitted to ACM domain-shared user preferences domain-specific user preferences (b) \u02c6 A ij y Domain B sha Z A ind Z B ind Z A spe Z B spe Z A sd C B sd C cd C A v E B v E \u02c6 B ik y (a) sha Z A spe Z B spe Z A ind Z B ind Z comprehensive user preferences * A u E * B u E A sd C B sd C single-domain confounders cd C cross-domain confounders A v E B v E \u02c6 A ij y \u02c6 B ik y item embeddings predicted interactions \u02c6 A ij y Domain A Domain B sha Z A ind Z B ind Z A spe Z B spe Z A sd C B sd C cd C A v E B v E \u02c6 B ik y * A u E * A u E * B u E * B u E Domain A domain-independent user preferences unblocked backdoor path, i.e., negative effect path backdoor adjustment positive effect path other causal relationship Legend \ud835\udc37 \ud835\udc34 and \ud835\udc37 \ud835\udc35 , respectively. The raw feature vector of each item in \ud835\udc37 \ud835\udc34 (or \ud835\udc37 \ud835\udc35 ) is defined as E \ud835\udc34 \ud835\udc63\ud835\udc5f \u2208 R \ud835\udc51 \ud835\udc34 (or E \ud835\udc35 \ud835\udc63\ud835\udc5f \u2208 R \ud835\udc51 \ud835\udc35 ), where \ud835\udc51 \ud835\udc34 (or \ud835\udc51 \ud835\udc35 ) is the dimensionality of features. The interaction matrices are denoted as R \ud835\udc34 \u2208 { 0 , 1 } \ud835\udc5a \u00d7 \ud835\udc5b \ud835\udc34 and R \ud835\udc35 \u2208 { 0 , 1 } \ud835\udc5a \u00d7 \ud835\udc5b \ud835\udc35 in \ud835\udc37 \ud835\udc34 and \ud835\udc37 \ud835\udc35 , respectively. To improve the performance of dual-target CDR, it is crucial to explicitly consider the impacts of observed confounders. These confounders include single-domain confounders C \ud835\udc60\ud835\udc51 and cross-domain confounders C \ud835\udc50\ud835\udc51 , both of which simultaneously influence user preferences and user-item interactions. Addressing the impacts of these confounders necessitates significant adjustments to existing dual-target CDR models. Hence, it would be beneficial to propose a novel deconfounding framework that is highly extendable and compatible with most off-the-shelf dual-target CDR models. For this purpose, since DIDA-CDR [98] is a representative and state-of-the-art dual-target CDR model, we choose it as the foundation for our problem definition. DIDA-CDR has effectively decoupled three essential components of user preferences for modeling comprehensive user preferences E \u2217 \ud835\udc62 , thus achieving good recommendation results in each domain. These three components include: (1) domain-shared user preferences Z \ud835\udc60\u210e\ud835\udc4e , which have the same meaning in each of both domains. For instance, users might prefer items in the sports 'category', which is the domain-shared preference covering both the 'purchase' and 'add to favorite' domains, reflecting consistent preferences across both domains. (2) domain-specific user preferences Z \ud835\udc60\ud835\udc5d\ud835\udc52 , which are unique to one domain. For example, in the 'add to favorite' domain, users might prefer 'luxurious' items that they cannot afford to purchase but still wish to add them to favorite, while in the 'purchase' domain, users might prefer 'practical' items that offer good value for money. (3) domain-independent user preferences Z \ud835\udc56\ud835\udc5b\ud835\udc51 , which are seemingly common in both domains but have different meanings in each domain [98]. For instance, in the 'purchase' domain, a preference for 'professional features' refers to choosing Manuscript submitted to ACM items that are specialized and match the user's current skill level or needs. Specifically, a beginner photography enthusiast might purchase an entry-level professional digital camera, which can mount different lenses for learning photography, emphasizing practicality and suitability for immediate use. By contrast, in the 'add to favorite' domain, a preference for 'professional features' reflects an aspiration for high-end items with advanced features, such as professional lenses, which are added to favorite for potential future use when the photography enthusiast's skills improve. Unlike domain-specific user preferences that only exist in their corresponding domain, domain-independent user preferences exist in both domains but have different meanings in each domain. Based on the above notations, the problem of Causal Deconfounding for Dual-Target CDR is defined as follows. Causal Deconfounding for Dual-Target CDR. Given the domain-specific and comprehensive user preferences (i.e., Z \ud835\udc60\ud835\udc5d\ud835\udc52 and E \u2217 \ud835\udc62 ) in each domain, the goal of causal deconfounding for dual-target CDR is to decouple observed single-domain confounders C \ud835\udc60\ud835\udc51 and cross-domain confounders C \ud835\udc50\ud835\udc51 , eliminate such observed confounders' negative effects to obtain debiased comprehensive user preferences, and incorporate these confounders' positive effects into such debiased preferences to achieve a comprehensive understanding of user-item interactions, thus enhancing the recommendation accuracy in both domains.", "3.2 Causal Graph": "A causal graph, i.e., a directed acyclic graph (DAG), where edges represent causal relationships between variables. Taking cross-domain confounders C \ud835\udc50\ud835\udc51 as an example, as illustrated in Fig. 2, they affect predicted interactions \u02c6 \ud835\udc66 via two types of paths: C \ud835\udc50\ud835\udc51 \u2192 \u02c6 \ud835\udc66 and C \ud835\udc50\ud835\udc51 \u2192 Z \ud835\udc60\u210e\ud835\udc4e \u2192 E \u2217 \ud835\udc62 \u2192 \u02c6 \ud835\udc66 . The first type of path reveals that C \ud835\udc50\ud835\udc51 , even if not the primary cause, i.e., users' true preferences, still have a direct positive impact on predicted interactions. The second type of path indicates that the negative impact of C \ud835\udc50\ud835\udc51 on domain-shared user preferences Z \ud835\udc60\u210e\ud835\udc4e induces confounding bias in both domains. Such confounding bias, in turn, skews comprehensive user preferences E \u2217 \ud835\udc62 , because Z \ud835\udc60\u210e\ud835\udc4e is an essential component for capturing E \u2217 \ud835\udc62 [98]. If the backdoor path C \ud835\udc50\ud835\udc51 \u2192 Z \ud835\udc60\u210e\ud835\udc4e is not blocked, C \ud835\udc50\ud835\udc51 will result in capturing biased comprehensive user preferences, thus yielding inaccurate recommendation results [79]. Similarly, single-domain confounders C \ud835\udc60\ud835\udc51 also have both positive and negative effects on predicted interactions and user preferences, respectively, thus the backdoor path C \ud835\udc60\ud835\udc51 \u2192 Z \ud835\udc60\ud835\udc5d\ud835\udc52 in each domain should be blocked too. Overall, the causal graph in Fig. 2 provides a detailed view of how user preferences, observed confounders, and user-item interactions are causally related in dual-target CDR. In this study, we focus on addressing the confounding bias introduced by observed confounders in cross-domain settings. Firstly, we effectively decouple observed single-domain and cross-domain confounders. Secondly, we perform backdoor adjustment to preserve the positive direct effects of such observed confounders on predicted interactions and eliminate their negative effects on capturing comprehensive user preferences. These steps mitigate confounding biases to a large extent, enable a comprehensive understanding of user-item interactions, and thus improve the recommendation performance in both domains.", "3.3 Connection with Existing Works and Our Novel Insights": "Our proposed CD2CDR is the first work to explicitly decouple observed cross-domain confounders and incorporate the observed confounders' positive impacts into debiased comprehensive user preferences for dual-target CDR. Our study indicates that the proposed framework not only builds on existing works, but also provides several novel insights [7]. Below, we analyze the remaining gaps in existing works, and explain how CD2CDR addresses these gaps and introduces novel insights: Manuscript submitted to ACM Domain A content information item features embedding layer in domain A / B BERT (a) Data Pre-Processing Graph Propagation initial embeddings of common users initial item embeddings in domain A / B user-item interactions Domain B sha Z A ind Z B ind Z A spe Z B spe Z * A u E * B u E A v E B v E (b) Backbone Pre-Training Phase 1: User Preferences Disentanglement Pre-Training (c) Single-Domain Confounder Disentanglement B spe Z A spe Z Generator Discriminator \u02c6 A spe Z \u02c6 B spe Z A / B ? 1 S Generator T B H Discriminator A H B spe Z A spe Z A sd C B sd C \u02c6 A ij y Domain A Domain B sha Z A ind Z B ind Z A spe Z B spe Z A sd C B sd C cd C A v E B v E \u02c6 B ik y * A u E * B u E Generator T Generator S 1 GAN L 2 GAN L cyc L A / B ? minus equals Backdoor Adjustment A v E B v E A sd C B sd C cd C * A u E * B u E Phase 3: Causal Deconfounding and Cross-domain Recommendation Confounder Selection MLP MLP \u02c6 A ij y A ij y Training Prediction \u02c6 B ik y B ik y Training * A u E * B u E A sd C B sd C sha Z A ind Z A spe Z sha Z B ind Z B spe Z cd C (d) Cross-Domain Confounder Disentanglement half-sibling regression Capturing Domain A Domain B Phase 2: Confounder Disentanglement interaction matrices in domain A / B concat fusion item embeddings data flow user embeddings data flow (e) Causal Deconfounding for CDR 2 3 4 5 6 6 5 1 2 3 4 1 2 for         and 1 GAN L 2 GAN L 3 4 1 2 for 5 6 cyc L Legend User Preference Disentanglement Prediction \u00b7 Neglecting observed confounders in user preference modeling: Existing approaches [2, 81] often emphasize decoupling essential components of user preferences to capture comprehensive user preferences, overlooking the impact of observed confounders on predicted interactions, which can lead to biased user preferences. In contrast, our CD2CDR addresses this gap by disentangling observed confounders and modeling the intricate causal relationships among such confounders, user preferences, and user-item interactions. \u00b7 Suboptimal deconfounding due to lack of explicit decoupling of cross-domain confounders: Existing approaches either use off-the-shelf features as confounders [41, 87] or neglect the need for decoupling cross-domain confounders [32, 86], resulting in suboptimal deconfounding performance. By contrast, our CD2CDR focuses on the explicit decoupling of both single-domain and cross-domain confounders, introducing a new perspective on deconfounding in cross-domain settings. \u00b7 Overlooking the positive impacts of observed confounders: Existing approaches [63, 85] generally focus on intervening in the causal relationships that lead to bias and apply backdoor adjustment to remove these negative impacts, aiming to obtain debiased comprehensive user preferences. However, they often overlook the positive impacts of such confounders on predicted interactions. In contrast, although our model also utilizes backdoor adjustment, which is one of the widely used causal intervention techniques, we incorporate these positive impacts into the debiased comprehensive user preferences. It is worth noting that while backdoor adjustment itself is not our contribution, our novelty lies in the way we leverage it to selectively preserve the positive impacts of the observed confounders and eliminate their negative impacts, thereby achieving a more comprehensive understanding of user-item interactions.", "4 The Proposed Model": "", "4.1 Overview of CD2CDR": "To enhance the recommendation accuracy in both domains, we propose a novel C ausal D econfounding framework via C onfounder D isentanglement for dual-target C rossD omain R ecommendation, called CD2CDR. As depicted in Manuscript submitted to ACM Fig. 3, the framework can be divided into three phases, i.e., Phase 1: User Preference Disentanglement Pre-Training, Phase 2: Confounder Disentanglement, and Phase 3: Causal Deconfounding and Cross-Domain Recommendation. In Phase 1 , we obtain disentangled domain-independent and domain-specific user preferences in each domain and domain-shared user preferences by pre-training the backbone introduced in [98]. In Phase 2 , we first extract the SDCs in each domain by bidirectionally transforming domain-specific user preferences decoupled in Phase 1. Then, we distill confounding factors that jointly influence comprehensive user preferences in each of both domains as CDCs by adopting half-sibling regression [55]. In Phase 3 , we utilize the backdoor adjustment to deconfound the observed confounders disentangled in Phase 2 . Specifically, we design a confounder selection function to mitigate negative effects of such confounders on user preferences, thus recovering debiased comprehensive user preferences. We then incorporate the observed confounders' positive effects into such debiased preferences to predict user-item interactions via a multi-layer perceptron (MLP) in each of both domains.", "4.2 Phase 1: User Preference Disentanglement Pre-Training": "Accurate disentanglement of user preferences is vital to ensure the robustness of subsequent confounder disentanglement process. Since the method introduced in [98] excels at decoupling three essential components of user preferences for modeling comprehensive user preferences, our CD2CDR adopts it as the backbone for user preference disentanglement. To extract more accurate disentangled user preferences, we consider multi-source content information of users and items, e.g., user reviews and item details. Taking domain \ud835\udc34 as an example, for each categorical feature field of an item (e.g., brand and category), we distill a set of unique features, which are then encoded into vectors using either one-hot or multi-hot encoding. Next, these encoded vectors are concatenated to form the raw feature vector for each item. We then transform the raw feature vectors of items E \ud835\udc34 \ud835\udc63\ud835\udc5f \u2208 R \ud835\udc51 \ud835\udc34 into the dense embeddings E \ud835\udc34 \ud835\udc63\ud835\udc51 \u2208 R \ud835\udc51 as follows: where W \ud835\udc34 \ud835\udc5f\ud835\udc51 \u2208 R \ud835\udc51 \ud835\udc34 \u00d7 \ud835\udc51 \ud835\udc51 is a trainable mapping matrix. \ud835\udc51 \ud835\udc51 denotes the dimensionality of dense embeddings. Then, for a user \ud835\udc62 \ud835\udc56 , we collect all the user's reviews into a user text document. For an item \ud835\udc63 \ud835\udc57 , we collect its title and all reviews on the item into an item text document. Next, we adopt a pre-trained BERT [6] to map the documents of all users and items in the training set into user text embeddings E \ud835\udc34 \ud835\udc62\ud835\udc61 and item text embeddings E \ud835\udc34 \ud835\udc63\ud835\udc61 , respectively. Finally, we concatenate E \ud835\udc34 \ud835\udc63\ud835\udc51 and E \ud835\udc34 \ud835\udc63\ud835\udc61 to form combined item embeddings E \ud835\udc34 \ud835\udc63\ud835\udc50 . We then transform E \ud835\udc34 \ud835\udc62\ud835\udc61 , E \ud835\udc34 \ud835\udc63\ud835\udc50 into fixed-size initial user embeddings E \ud835\udc34 \ud835\udc62\ud835\udc56 and initial item embedding E \ud835\udc34 \ud835\udc63\ud835\udc56 in domain \ud835\udc34 as follows: where \ud835\udeff \ud835\udc34 \ud835\udc62 and \ud835\udeff \ud835\udc34 \ud835\udc63 are the mapping functions of MLP layers. Similarly, we can obtain initial user embeddings E \ud835\udc35 \ud835\udc62\ud835\udc56 and initial item embeddings E \ud835\udc35 \ud835\udc63\ud835\udc56 in domain \ud835\udc35 . We then leverage such initial embeddings and the interaction matrices as inputs to pre-train the backbone. Specifically, we aggregate interaction data within each domain to build two heterogeneous graphs, which allow us to learn coarse user and item embeddings for each domain. Next, we apply linear interpolation to the user embeddings of both domains to generate augmented user representations, augmenting the sparser domain. With these coarse user embeddings and augmented user representations, we then employ a user preference disentanglement module, guided by a domain classifier, to decouple domain-independent, domain-specific, and domain-shared user preferences, namely, Z \ud835\udc56\ud835\udc5b\ud835\udc51 , Z \ud835\udc60\ud835\udc5d\ud835\udc52 , and Z \ud835\udc60\u210e\ud835\udc4e (for more information, please refer to [98]). By incorporating the above three components of user preferences using attention mechanism in accordance with DIDA-CDR [98], we can obtain comprehensive user preferences E \u2217 \ud835\udc62 . Manuscript submitted to ACM", "4.3 Phase 2: Confounder Disentanglement": "Since user-item interactions are also influenced by observed confounders apart from comprehensive user preferences, we propose to decouple SDCs and CDCs, as detailed in the following subsections. 4.3.1 Single-Domain Confounder Disentanglement . To explore the SDCs, we utilize bi-directional domain transformation to decouple them from previously obtained domain-specific user preferences. If such SDCs are not identified and explicitly decoupled, their negative effects on domain-specific user preferences can hardly be eliminated. By contrast, if they are well disentangled, the causal deconfounding module can utilize backdoor adjustment to remove the confounding bias, thus obtaining debiased domain-specific user preferences. Inspired by CycleGAN [99], we devise a dual adversarial structure, which consists of two domain transformation generators and two discriminators, to disentangle SDCs in each domain. Specifically, we aim to learn two generators, i.e., \ud835\udc46 (\u00b7) : \ud835\udc37 \ud835\udc34 \u2192 \ud835\udc37 \ud835\udc35 and \ud835\udc47 (\u00b7) : \ud835\udc37 \ud835\udc35 \u2192 \ud835\udc37 \ud835\udc34 , to transform domain-specific user preferences in each domain. Taking domain \ud835\udc35 as an example, the generator \ud835\udc46 (\u00b7) takes the domain-specific user preferences Z \ud835\udc34 \ud835\udc60\ud835\udc5d\ud835\udc52 of common users in \ud835\udc37 \ud835\udc34 as inputs to generate \u02c6 Z \ud835\udc35 \ud835\udc60\ud835\udc5d\ud835\udc52 = \ud835\udc46 ( Z \ud835\udc34 \ud835\udc60\ud835\udc5d\ud835\udc52 ) that look similar to domain-specific user preferences in domain \ud835\udc35 , i.e., Z \ud835\udc35 \ud835\udc60\ud835\udc5d\ud835\udc52 . However, if there are still differences between the simulated preferences \u02c6 Z \ud835\udc35 \ud835\udc60\ud835\udc5d\ud835\udc52 and the original ones Z \ud835\udc35 \ud835\udc60\ud835\udc5d\ud835\udc52 , such differences are not characteristics of domain-specific user preferences in domain \ud835\udc35 , but should be considered as SDCs [82]. To ensure that the generator \ud835\udc46 (\u00b7) is proficient at domain-specific preference simulation, we introduce a discriminator \ud835\udc3b \ud835\udc35 (\u00b7) to recognize which domain the domain-specific user preferences come from. In the adversarial learning paradigm, the discriminator is expected to improve the ability to differentiate domain-specific user preferences in each domain to achieve better discriminative performance, while the generator is supposed to generate indistinguishable simulations of these domain-specific preferences to confuse such discriminator [58]. For training the generator \ud835\udc46 (\u00b7) and the corresponding discriminator \ud835\udc3b \ud835\udc35 (\u00b7) , we adopt the adversarial loss [15], which can be expressed as follows: where E is the expectation, and P \ud835\udc34 , P \ud835\udc35 denote the feature distribution of domain \ud835\udc34 and domain \ud835\udc35 , respectively. Similarly, for training the generator \ud835\udc47 (\u00b7) and the corresponding discriminator \ud835\udc3b \ud835\udc34 (\u00b7) , we adopt the adversarial loss L \ud835\udc3a\ud835\udc34\ud835\udc41 2 ( \ud835\udc47, \ud835\udc3b \ud835\udc34 , \ud835\udc37 \ud835\udc35 , \ud835\udc37 \ud835\udc34 ) . However, relying solely on adversarial loss is insufficient to ensure that a user's domainspecific preferences remain aligned with the user's preferences after transformation. If transformed domain-specific user preferences no longer reflect the user's preferences, then such transformation becomes meaningless, serving merely to confuse the discriminator. Hence, the generators should maintain cycle consistency, i.e., Z \ud835\udc34 \ud835\udc60\ud835\udc5d\ud835\udc52 \u2192 \ud835\udc46 ( Z \ud835\udc34 \ud835\udc60\ud835\udc5d\ud835\udc52 ) \u2192 \ud835\udc47 ( \ud835\udc46 ( Z \ud835\udc34 \ud835\udc60\ud835\udc5d\ud835\udc52 )) \u2248 Z \ud835\udc34 \ud835\udc60\ud835\udc5d\ud835\udc52 and Z \ud835\udc35 \ud835\udc60\ud835\udc5d\ud835\udc52 \u2192 \ud835\udc47 ( Z \ud835\udc35 \ud835\udc60\ud835\udc5d\ud835\udc52 ) \u2192 \ud835\udc46 ( \ud835\udc47 ( Z \ud835\udc35 \ud835\udc60\ud835\udc5d\ud835\udc52 )) \u2248 Z \ud835\udc35 \ud835\udc60\ud835\udc5d\ud835\udc52 during the training process (see L \ud835\udc50\ud835\udc66\ud835\udc50 in Fig. 3(c)). To this end, we apply a cycle consistency loss, which is represented as follows: Moreover, the total objective function for training the generators and discriminators can be formulated as follows: where \ud835\udf06 controls the importance of cycle consistency loss relative to adversarial losses. Following the method introduced in [82], upon training completion, we calculate the differences between the domain-specific user preferences after transformation and the original ones as candidate SDCs. Even though confounding bias may still exist in the original domain-specific user preferences, the differences calculation helps to decouple candidate SDCs. By performing deconfounding on these decoupled confounders, the impact of such biases can be mitigated to a large extent. The differences are defined as follows: Recall the causal graph in Fig. 2(a), the negative effects of single-domain confounders C \ud835\udc60\ud835\udc51 on domain-specific user preferences Z \ud835\udc60\ud835\udc5d\ud835\udc52 result in confounding bias, leading to inaccurate estimation of Z \ud835\udc60\ud835\udc5d\ud835\udc52 . For example, as depicted in Fig. 1(c), in the 'purchase' domain, a data-driven RS improperly perceives the 'free shipping' (i.e., an SDC), as Alice's 'purchase' domain preference, resulting in biased recommendation. Since our well-trained generator excels at simulating Alice's 'purchase' domain preferences based on her 'add to favorite' domain preferences, if there are still differences as per Eq. (6), this indicates such differences are not Alice's 'purchase' domain preferences but rather SDCs independent of her preferences. Such SDCs (e.g., 'free shipping'), previously entangled with Alice's 'purchase' domain preferences, are decoupled through our SDC disentanglement process. Note that this process specifically targets biased domain-specific user preferences, because unbiased ones are not entangled with such SDCs. Thus, although this process decouples SDCs from biased domain-specific user preferences, this does not imply a causal relationship Z \ud835\udc60\ud835\udc5d\ud835\udc52 \u2192 C \ud835\udc60\ud835\udc51 in the causal graph, because SDCs are not generated by such biased domain-specific user preferences. To distill representative SDCs and reduce redundancy, we apply K-means clustering on candidate single-domain confounders \u02c6 C \ud835\udc34 \ud835\udc60\ud835\udc51 (or \u02c6 C \ud835\udc35 \ud835\udc60\ud835\udc51 ) and choose \ud835\udc3d \ud835\udc34 \ud835\udc60\ud835\udc51 (or \ud835\udc3d \ud835\udc35 \ud835\udc60\ud835\udc51 ) cluster centroids to form the potential SDC subspace C \ud835\udc34 \ud835\udc60\ud835\udc51 (or C \ud835\udc35 \ud835\udc60\ud835\udc51 ). 4.3.2 Cross-Domain Confounder Disentanglement . In addition to SDCs, it is more important to identify confounding factors that simultaneously affect user-item interactions in both domains. Inspired by the method introduced in [82], we employ half-sibling regression to disentangle CDCs from the previously obtained comprehensive user preferences in both domains. Half-sibling regression excels at capturing the influence of confounding factors that simultaneously affect multiple observed variables [55], and thus it is well suited for decoupling CDCs in dual-target CDR. As illustrated in Fig. 2(a), C \ud835\udc50\ud835\udc51 \u2192 E \u2217 \ud835\udc34 \ud835\udc62 and C \ud835\udc50\ud835\udc51 \u2192 E \u2217 \ud835\udc35 \ud835\udc62 indicate that CDCs indirectly influence the comprehensive user preferences in each of both domains via C \ud835\udc50\ud835\udc51 \u2192 Z \ud835\udc60\u210e\ud835\udc4e \u2192 E \u2217 \ud835\udc34 \ud835\udc62 and C \ud835\udc50\ud835\udc51 \u2192 Z \ud835\udc60\u210e\ud835\udc4e \u2192 E \u2217 \ud835\udc35 \ud835\udc62 . The core idea of half-sibling regression is: if E \u2217 \ud835\udc34 \ud835\udc62 and C \ud835\udc35 \ud835\udc60\ud835\udc51 are independent, then predicting E \u2217 \ud835\udc35 \ud835\udc62 based on E \u2217 \ud835\udc34 \ud835\udc62 becomes a method to selectively capture the influence of C \ud835\udc50\ud835\udc51 on E \u2217 \ud835\udc35 \ud835\udc62 (see Fig. 3(d)). Similarly, predicting E \u2217 \ud835\udc34 \ud835\udc62 based on E \u2217 \ud835\udc35 \ud835\udc62 serves to capture the influence of C \ud835\udc50\ud835\udc51 on E \u2217 \ud835\udc34 \ud835\udc62 (for more information, please refer to [55]). Therefore, we can apply half-sibling regression to decouple C \ud835\udc50\ud835\udc51 from E \u2217 \ud835\udc34 \ud835\udc62 and E \u2217 \ud835\udc35 \ud835\udc62 . Taking the regression from domain \ud835\udc34 to domain \ud835\udc35 as an example, our goal is to estimate a transformation matrix W \ud835\udc34 \u2192 \ud835\udc35 such that: using ridge regression, and regression results are expressed as: where \ud835\udefc denotes the regularization parameter. We assume that E \u2217 \ud835\udc34 \ud835\udc62 and C \ud835\udc35 \ud835\udc60\ud835\udc51 are independent, because E \u2217 \ud835\udc34 \ud835\udc62 are comprehensive user preferences in domain \ud835\udc34 , while C \ud835\udc35 \ud835\udc60\ud835\udc51 are SDCs specific to domain \ud835\udc35 . When we estimate a transformation matrix W \ud835\udc34 \u2192 \ud835\udc35 to predict E \u2217 \ud835\udc35 \ud835\udc62 using E \u2217 \ud835\udc34 \ud835\udc62 , the influence of C \ud835\udc35 \ud835\udc60\ud835\udc51 on E \u2217 \ud835\udc35 \ud835\udc62 will not be captured. This is because E \u2217 \ud835\udc34 \ud835\udc62 are Manuscript submitted to ACM independent from C \ud835\udc35 \ud835\udc60\ud835\udc51 , and as a result, utilizing E \u2217 \ud835\udc34 \ud835\udc62 cannot predict C \ud835\udc35 \ud835\udc60\ud835\udc51 and the influence of C \ud835\udc35 \ud835\udc60\ud835\udc51 on E \u2217 \ud835\udc35 \ud835\udc62 . By contrast, the influence of C \ud835\udc50\ud835\udc51 on E \u2217 \ud835\udc35 \ud835\udc62 will be captured, because C \ud835\udc50\ud835\udc51 simultaneously affect E \u2217 \ud835\udc34 \ud835\udc62 and E \u2217 \ud835\udc35 \ud835\udc62 , which means the regression results will only capture C \ud835\udc50\ud835\udc51 . Hence, the regression results can be identified as candidate cross-domain confounders: Similarly, we can obtain the regression results from domain \ud835\udc35 to domain \ud835\udc34 , denoted as \u02c6 C \ud835\udc35 \u2192 \ud835\udc34 \ud835\udc50\ud835\udc51 . For cross-domain confounders, K-means clustering is also employed on the candidate cross-domain confounders \u02c6 C \ud835\udc34 \u2192 \ud835\udc35 \ud835\udc50\ud835\udc51 and \u02c6 C \ud835\udc35 \u2192 \ud835\udc34 \ud835\udc50\ud835\udc51 , with the \ud835\udc3d \ud835\udc50\ud835\udc51 cluster centroids forming the potential CDC subspace C \ud835\udc50\ud835\udc51 .", "4.4 Phase 3: Causal Deconfounding and Cross-Domain Recommendation": "After the confounder disentanglement, we obtain the potential SDC subspaces C \ud835\udc34 \ud835\udc60\ud835\udc51 and C \ud835\udc35 \ud835\udc60\ud835\udc51 , and potential CDC subspace C \ud835\udc50\ud835\udc51 . From a causal perspective, if the backdoor paths (i.e., C \ud835\udc60\ud835\udc51 \u2192 Z \ud835\udc60\ud835\udc5d\ud835\udc52 and C \ud835\udc50\ud835\udc51 \u2192 Z \ud835\udc60\u210e\ud835\udc4e ) are not blocked, the observed confounders \ud835\udc36 will simultaneously influence user preferences \ud835\udc4d and user-item interactions \ud835\udc4c (see Fig. 1(a)), and thus cause biased estimation of comprehensive user preferences. To this end, we perform the do -calculus intervention based on backdoor adjustment [102] to block the backdoor paths \ud835\udc36 \u2192 \ud835\udc4d and enable our model to more accurately estimate the direct effect \ud835\udc4d \u2192 \ud835\udc4c (also see Fig. 1(a)). Formally, the conventional likelihood \ud835\udc43 ( \ud835\udc4c | \ud835\udc4d ) is defined as: where \ud835\udc50 denotes a specific confounder selected from the confounder space C . By applying the do -calculus, we exclude all influences directed towards the intervened variable (i.e., \ud835\udc4d ), and then we have: For brevity, the detailed proof of the transformations \ud835\udc43 ( \ud835\udc4c | \ud835\udc51\ud835\udc5c ( \ud835\udc4d ) , \ud835\udc50 ) = \ud835\udc43 ( \ud835\udc4c | \ud835\udc4d,\ud835\udc50 ) and \ud835\udc43 ( \ud835\udc50 | \ud835\udc51\ud835\udc5c ( \ud835\udc4d )) = \ud835\udc43 ( \ud835\udc50 ) is omitted, which can be found in [51]. In fact, transforming \ud835\udc43 ( \ud835\udc50 | \ud835\udc51\ud835\udc5c ( \ud835\udc4d )) into the prior probability of confounders \ud835\udc43 ( \ud835\udc50 ) blocks backdoor paths \ud835\udc36 \u2192 \ud835\udc4d . As a result, \ud835\udc43 ( \ud835\udc4c | \ud835\udc51\ud835\udc5c ( \ud835\udc4d )) mainly focus on modeling the direct effect \ud835\udc4d \u2192 \ud835\udc4c . Specifically, we implement the backdoor adjustment by modeling \ud835\udc43 ( \ud835\udc4c | \ud835\udc4d,\ud835\udc50 ) with an interaction prediction network, which is expressed as follows: where \ud835\udc53 (\u00b7) denotes a neural network, namely, MLP, to predict the probabilities of user-item interactions [21]. E \u2217 \ud835\udc62 and E \ud835\udc63 are comprehensive user preferences and pre-trained item embeddings obtained by the backbone in Phase 1, respectively. In other words, based on two subspaces of disentangled observed confounders in domain \ud835\udc34 and domain \ud835\udc35 , i.e., C \ud835\udc34 = C \ud835\udc34 \ud835\udc60\ud835\udc51 \u222a C \ud835\udc50\ud835\udc51 and C \ud835\udc35 = C \ud835\udc35 \ud835\udc60\ud835\udc51 \u222a C \ud835\udc50\ud835\udc51 , we apply backdoor adjustment to rectify the biased recommendations in each domain using Eq. (12). Since the decoupled observed confounders are incorporated as part of the input to MLP, the direct influence of such confounders on user-item interactions \ud835\udc36 \u2192 \ud835\udc4c is also considered. Moreover, inspired by [82], we devise a confounder selection function to effectively control decoupled confounders for more accurate deconfounding. Taking domain \ud835\udc34 as an example, the confounder selection function is defined as follows: where c \u2032 denotes any confounder selected from confounder subspace C \ud835\udc34 and \u00b7 is the dot product. W \ud835\udc34 \ud835\udc62 , W \ud835\udc34 \ud835\udc62\ud835\udc50 , W \ud835\udc34 \ud835\udc63 , W \ud835\udc34 \ud835\udc63\ud835\udc50 are trainable matrices for embedding transformation. We then formulate the expectation E \ud835\udc50 [ \ud835\udc53 ( E \u2217 \ud835\udc62 , E \ud835\udc63 , c )] as follows: where W \ud835\udc53 \ud835\udc50 is the weight matrix of the fully connected (FC) layer and | | is the concatenation operator. In practice, we assume a uniform distribution for the prior probability \ud835\udc5d ( \ud835\udc50 ) . In addition, Q \ud835\udc34 \ud835\udc56\ud835\udc5b = W \ud835\udc53 \ud835\udc50 ( E \u2217 \ud835\udc34 \ud835\udc62 | | E \ud835\udc34 \ud835\udc63 | | \u02dd \ud835\udc50 \ud835\udc5d ( \ud835\udc50 ) c \ud835\udf19 ( E \u2217 \ud835\udc34 \ud835\udc62 , E \ud835\udc34 \ud835\udc63 , c ) denotes the input for MLP in domain \ud835\udc34 . Moreover, the predicted interaction \u02c6 \ud835\udc66 \ud835\udc34 \ud835\udc56 \ud835\udc57 between an user \ud835\udc62 \ud835\udc56 and an item \ud835\udc63 \ud835\udc57 in domain \ud835\udc34 is represented as follows: where \ud835\udeff \ud835\udc34 \ud835\udc59 is the mapping function for \ud835\udc59 -th MLP layer, and there are \ud835\udc59 MLP layers including \ud835\udeff \ud835\udc34 \ud835\udc5c\ud835\udc62\ud835\udc61 in domain \ud835\udc34 . Similarly, the predicted interaction \u02c6 \ud835\udc66 \ud835\udc35 \ud835\udc56 \ud835\udc57 in domain \ud835\udc35 can be obtained. The essence of our causal deconfounding module lies in blocking the backdoor paths \ud835\udc36 \u2192 \ud835\udc4d , allowing the model to concentrate on the direct effects of users' true preferences on the predicted interactions \ud835\udc4d \u2192 \ud835\udc4c , and disregard the interference of observed confounders on these preferences. Specifically, the confounder selection function assigns different weights to the potential observed confounders, mitigates the effects of those irrelevant or harmful confounders to the prediction task, and enhances the direct effects of beneficial confounders on predicted interactions. Therefore, this module enables the model to eliminate the negative effects of such observed confounders to learn debiased comprehensive user preferences, and preserve the positive effects of these confounders on predicted interactions, thereby achieving a more comprehensive understanding of user-item interactions in both domains. Finally, we employ cross-entropy loss to fine-tune the user preference disentanglement backbone \ud835\udc54 (\u00b7) and the interaction prediction network \ud835\udc53 (\u00b7) . To be specific, the final objective function in domain \ud835\udc34 can be defined as follows: where \u02c6 \ud835\udc66 and \ud835\udc66 are the predicted interaction and corresponding observed interaction, respectively. \u2113 ( \u02c6 \ud835\udc66,\ud835\udc66 ) denotes the cross-entropy loss function. Y \ud835\udc34 + denotes the observed interaction set, and Y \ud835\udc34 -corresponds to a specific quantity of negative samples, which are randomly selected from unseen user-item interaction set in domain \ud835\udc34 to mitigate the over-fitting. During the fine-tuning process, \ud835\udc54 (\u00b7) serves as the backbone, with the original prediction module being replaced by the interaction prediction network \ud835\udc53 (\u00b7) . Likewise, we can obtain the objective function and predicted user-item interaction \u02c6 \ud835\udc66 \ud835\udc35 \ud835\udc56\ud835\udc58 in domain \ud835\udc35 .", "4.5 Time Complexity Analysis": "Our CD2CDR mainly focuses on four modules: (1) Graph Propagation, (2) User Preference Disentanglement, (3) Confounder Disentanglement, and (4) Causal Deconfounding and Cross-domain Recommendation. While the first two modules are part of backbone model [98], the latter two constitute our novel framework. For simplicity and consistency, we assume that all embedding dimensions are \ud835\udc51 and the number of layers in each network structure within each module is \ud835\udc3f [90]. The time complexity for each module can be analyzed as follows: (1) Graph Propagation: Assuming the graph has ( \ud835\udc5a + \ud835\udc5b ) nodes, where \ud835\udc5a and \ud835\udc5b are the number of users and items, respectively. In addition, assuming the average number of neighboring nodes for each node is \u00af \ud835\udc41 , the time complexity for the graph propagation process per node is \ud835\udc42 ( \u00af \ud835\udc41\ud835\udc51 ) . The total time complexity for graph propagation, using a graph convolutional network (GCN) with \ud835\udc3f layers, is \ud835\udc42 ( \ud835\udc3f ( \ud835\udc5a + \ud835\udc5b ) \u00af \ud835\udc41\ud835\udc51 ) . Given that \u00af \ud835\udc41 \u226a ( \ud835\udc5a + \ud835\udc5b ) , this simplifies to \ud835\udc42 ( \ud835\udc3f ( \ud835\udc5a + \ud835\udc5b ) \ud835\udc51 ) . (2) User Preference Disentanglement: Next, we conduct user preference disentanglement using an architecture similar to the VAE encoder. Given that this module is implemented with an MLP consisting of \ud835\udc3f layers, the time complexity of user preference disentanglement is approximately \ud835\udc42 ( \ud835\udc3f\ud835\udc5a\ud835\udc51 2 ) . The time complexity of domain classifier can be ignored as it is relatively simple compared to main disentanglement module. (3) Confounder Disentanglement: Then, we perform the confounder disentanglement module, which involves SDC and CDC disentanglement. For SDC disentanglement, we implement a structure similar to CycleGAN, using an MLP with \ud835\udc3f layers to decouple candidate SDCs. The time complexity of SDC disentanglement can be roughly estimated as \ud835\udc42 ( \ud835\udc3f\ud835\udc51 2 \ud835\udc5a ) . For CDC disentanglement, ridge regression is used to calculate a transformation matrix W \ud835\udc34 \u2192 \ud835\udc35 for obtaining candidate CDCs. The estimated time complexity is \ud835\udc42 ( \ud835\udc5a\ud835\udc51 2 + \ud835\udc51 3 ) . Considering \ud835\udc51 \u226a \ud835\udc5a , it simplifies to \ud835\udc42 ( \ud835\udc5a\ud835\udc51 2 ) . To identify representative SDCs and CDCs and eliminate redundancy, we perform K-means clustering on the candidate SDCs and CDCs. Given that the number of cluster centroids is \ud835\udc3d , the time complexity for the K-means clustering is estimated to be \ud835\udc42 ( \ud835\udc5a\ud835\udc51\ud835\udc3d ) . Thus, the overall time complexity for the confounder disentanglement module is \ud835\udc42 ( \ud835\udc3f\ud835\udc51 2 \ud835\udc5a + \ud835\udc5a\ud835\udc51 2 + \ud835\udc5a\ud835\udc51\ud835\udc3d ) , which simplifies to \ud835\udc42 ( \ud835\udc5a\ud835\udc51 ( \ud835\udc3f\ud835\udc51 + \ud835\udc3d )) . (4) Causal Deconfounding and Cross-domain Recommendation: Finally, we utilize the confounder selection function to effectively control the decoupled observed confounders, achieving more accurate deconfounding with a time complexity of approximately \ud835\udc42 ( \ud835\udc5a\ud835\udc5b\ud835\udc3d\ud835\udc51 ) . Subsequently, we concatenate the user embeddings, item embeddings, and selected confounders, feeding them into the MLP for prediction. Given that the prediction module consists of \ud835\udc3f MLP layers, the time complexity can be estimated as \ud835\udc42 ( \ud835\udc3f\ud835\udc5a\ud835\udc5b\ud835\udc51 2 ) . Thus, the overall time complexity for the causal deconfounding and cross-domain recommendation module is \ud835\udc42 ( \ud835\udc5a\ud835\udc5b\ud835\udc3d\ud835\udc51 + \ud835\udc3f\ud835\udc5a\ud835\udc5b\ud835\udc51 2 ) , which simplifies to \ud835\udc42 ( \ud835\udc5a\ud835\udc5b\ud835\udc51 ( \ud835\udc3d + \ud835\udc3f\ud835\udc51 )) . Overall, the time complexity of our CD2CDR can be approximated as \ud835\udc42 ( \ud835\udc5a\ud835\udc5b\ud835\udc51 2 ( \ud835\udc3d + \ud835\udc3f )) , where \ud835\udc3d is the number of cluster centroids, and \ud835\udc5a and \ud835\udc5b are the number of users and items, respectively. This approximation is based on combining the time complexities of all four modules and simplifying by focusing on the dominant terms. The overall time complexity exhibits a non-linear relationship with the number of users, items, observed confounders, and embedding dimensions.", "5 Experiments and Analysis": "Extensive experiments are conducted on seven real-world datasets to answer the following four research questions: \u00b7 RQ1. How does our model perform in comparison with state-of-the-art baseline models (see Section 5.2)? \u00b7 RQ2. Howdodifferent components, namely, confounder disentanglement, causal deconfounding and cycle consistency loss, influence the recommendation accuracy of our model (see Section 5.3)? \u00b7 RQ3. How do different backbone models impact the recommendation accuracy of our model (see Section 5.4)? \u00b7 RQ4. How do different hyper-parameter settings affect the recommendation accuracy of our model (see Section 5.5)?", "5.1 Experimental Settings": "5.1.1 Experimental Datasets . Semantic information, such as item titles containing details about free shipping, sales promotion, category, and brand, helps to disentangle user preferences and observed confounders. In e-commerce scenarios, semantic information is easily accessible and crucial for gaining a more comprehensive understanding of user-item interactions. To comprehensively evaluate our CD2CDR model, we conduct experiments in two distinct recommendation scenarios: (1) CDR with fully overlapping user sets and (2) cross-system recommendation (CSR) with only overlapping items and completely non-overlapping users. For the CDR scenario, we select two real-world e-commerce datasets that provide rich semantic information, ratings, reviews and item metadata, namely, Rec-Tmall 3 dataset [19] and Amazon dataset [2]. For Amazon dataset, we choose two relevant domains, namely, Amazon-Electronics and Amazon-Cloth. Similarly, for Rec-Tmall dataset, we select three relevant behaviors as business domains, namely, Add to Favorite, Purchase, and Add to Cart 4 . In the Tmall-Favorite domain, most users engage in exploration-oriented behaviors, adding items they find appealing to their favorites without an immediate intent to purchase. In contrast, the Tmall-Purchase and Tmall-Cart domains reflect purchase-oriented behaviors, where users are more likely to select items that match their true preferences and may result in actual purchases. By defining these distinct behaviors as domains, we broaden the concept of domains to encompass varying user intents, thereby enhancing the flexibility of our CDR framework for broader application scenarios [32]. For the CSR scenario, we utilize two widely-used movie recommendation datasets: MovieLens 20M [18] and DoubanMovie [95]. These datasets contain ratings and side information on common movies from different user communities, creating a scenario where user sets are completely non-overlapping while item sets are partially overlapping. This cross-system setting broadens our experimental scope beyond CDR to a more challenging CSR scenario that better testifies the effectiveness of our CD2CDR. 5.1.2 Experimental Tasks . We construct four experimental tasks: three dual-target CDR tasks using e-commerce datasets and one CSR task using movie datasets. All tasks involve transforming explicit ratings into implicit feedback. For the CDR scenario, we design three tasks with fully overlapping user sets: (1) Tmall-Favorite and Tmall-Purchase, (2) Tmall-Favorite and Tmall-Cart, and (3) Amazon-Elec and Amazon-Cloth. These tasks are chosen to test the model's ability to handle diverse recommendations across different user interactions and preferences in e-commerce settings. For Task #1, users and items with fewer than 20 interactions are removed from Tmall-Favorite, and those with fewer than 5 interactions are filtered out from Tmall-Purchase. For the Task #2 and Task #3, users and items with fewer than 20 interactions in Task #2 and those with fewer than 5 interactions in Task #3 are filtered out. In line with the preprocessing operation taken for the two Amazon subsets in DisenCDR [2], we also conduct the same operation on three Rec-Tmall subsets to remove the cold-start item entry for testing. For the CSR scenario (Task #4: MovieLens and Douban-Movie), we follow the filtering approach in [77, 93], retaining users and items with at least 5 interactions in Douban-Movie and extracting a subset of 10,000 users with at least 5 interactions from MovieLens 20M. We then identify common items across the two datasets, enabling knowledge transfer through overlapping items despite having completely non-overlapping users. The statistics are shown in Table 2. 5.1.3 Parameter Settings . The settings of our backbone DIDA-CDR are consistent with those listed in its original paper [98], including the number of GCN layers, embedding dimension and information fusion approach, etc. In the interaction prediction network, the structure is \ud835\udc52 \u2192 32 \u2192 16 \u2192 \ud835\udc5e , where \ud835\udc52 is the combined size after the mapping of FC layer in Eq. (14), and \ud835\udc5e is the output size, i.e., the dimension of latent factors. We vary \ud835\udc52 in the range of { 64 , 128 } and \ud835\udc5e in the range of { 8 , 16 } , and finally set \ud835\udc52 = 128 and \ud835\udc5e = 8. The initial parameters for all the above layers are set following a Gaussian distribution \ud835\udc4b \u223c N( 0 , 0 . 01 ) . In line with the approach used in GA-DTCDR [95], for each observed interaction, we randomly select 7 non-interacted items to serve as negative examples. For a fair comparison, we employ grid search to fine-tune the parameters of all models. Specifically, we select the learning rate in { 0 . 01 , 0 . 005 , 0 . 001 , 0 . 0005 , 0 . 0001 } . Moreover, we adopt the Adam optimizer [27] for all models with a batch size of 1024. In addition, we keep the number of cluster centroids \ud835\udc3d \ud835\udc34 \ud835\udc60\ud835\udc51 = \ud835\udc3d \ud835\udc35 \ud835\udc60\ud835\udc51 = \ud835\udc3d \ud835\udc50\ud835\udc51 and vary them in { 2 , 5 , 10 , 20 , 50 } . Furthermore, we investigate the weight of cycle consistency loss \ud835\udf06 in { 0 . 1 , 1 , 2 , 5 , 10 } , and the regularization parameter \ud835\udefc in { 0 . 1 , 1 , 10 , 20 , 50 } . The influence of the above parameters on our CD2CDR is particularly discussed in Section 5.5. 5.1.4 Model Training . Since our CD2CDR can be divided into three phases, we first pre-train the backbone of our model with 50 epochs 5 to obtain disentangled user preferences and comprehensive user preferences. Next, we train the generators and discriminators in the dual adversarial structure with 30 epochs to decouple SDCs, apply half-sibling regression, a computational method inherently without a training process [55], to decouple CDCs, and then save cluster centroids of both SDCs and CDCs. Finally, we replace the prediction module in the backbone with the interaction prediction network to fine-tune the overall CD2CDR with 20 epochs. To enhance the stability of our model training in the dual adversarial structure, inspired by [99], we replace the negative log-likelihood objective with a least-squares loss for the adversarial losses L \ud835\udc3a\ud835\udc34\ud835\udc41 1 ( \ud835\udc46, \ud835\udc3b \ud835\udc35 , \ud835\udc37 \ud835\udc34 , \ud835\udc37 \ud835\udc35 ) and L \ud835\udc3a\ud835\udc34\ud835\udc41 2 ( \ud835\udc47, \ud835\udc3b \ud835\udc34 , \ud835\udc37 \ud835\udc35 , \ud835\udc37 \ud835\udc34 ) . This replacement enables the generator to produce higher-quality outputs and improves training stability. The reasons are as follows. Firstly, the least-squares loss penalizes generated samples far from the decision boundary, guiding the generator to adjust these samples closer to the boundary. This process reduces the discrepancy between generated and real data distributions, improving the quality of generated samples. Secondly, the distance-based penalization produces more gradients to guide the generator's updates, mitigating the gradient vanishing issue and thereby stabilizing the generator's learning process. For further details, please refer to [48]. Taking L \ud835\udc3a\ud835\udc34\ud835\udc41 1 ( \ud835\udc46, \ud835\udc3b \ud835\udc35 , \ud835\udc37 \ud835\udc34 , \ud835\udc37 \ud835\udc35 ) as an example, the generator \ud835\udc46 (\u00b7) is trained to minimize E Z \ud835\udc34 \ud835\udc60\ud835\udc5d\ud835\udc52 \u223c P \ud835\udc34 [( \ud835\udc3b \ud835\udc35 ( \ud835\udc46 ( Z \ud835\udc34 \ud835\udc60\ud835\udc5d\ud835\udc52 )) -1 ) 2 ] , while the corresponding discriminator \ud835\udc3b \ud835\udc35 (\u00b7) is trained to minimize E Z \ud835\udc35 \ud835\udc60\ud835\udc5d\ud835\udc52 \u223c P \ud835\udc35 [( \ud835\udc3b \ud835\udc35 ( Z \ud835\udc35 \ud835\udc60\ud835\udc5d\ud835\udc52 ) -1 ) 2 ] + E Z \ud835\udc34 \ud835\udc60\ud835\udc5d\ud835\udc52 \u223c P \ud835\udc34 [ \ud835\udc3b \ud835\udc35 ( \ud835\udc46 ( Z \ud835\udc34 \ud835\udc60\ud835\udc5d\ud835\udc52 )) 2 ] . Likewise, L \ud835\udc3a\ud835\udc34\ud835\udc41 2 ( \ud835\udc47, \ud835\udc3b \ud835\udc34 , \ud835\udc37 \ud835\udc35 , \ud835\udc37 \ud835\udc34 ) is optimized in a similar manner. In addition, we adjust the weight of the cycle consistency loss to balance the adversarial process and the cycle consistency constraint, ensuring stable convergence of the dual adversarial training. Detailed results of this weight adjustment can be found in Section 5.3.3 and Section 5.5.2. During each epoch, we shuffle and split the training data for both domains into batches. We then iterate through batches, training on domain A and domain B in parallel. This approach allows the model to learn from both domains within the same epoch, ensuring that the model parameters are updated based on information from both domains. This form of joint learning helps improve the generalization performance across domains. Note that Eq. (5) and Eq. (16) are not optimized jointly. Since observed confounders are no longer entangled with debiased user preferences after deconfounding, the joint optimization of Eq. (5) and Eq. (16) for decoupling these confounders from such preferences becomes redundant. For a fair comparison, other baselines are trained for 100 epochs to confirm their convergence. 5.1.5 Evaluation Metrics . Given the widespread use of leave-one-out approach in baselines, e.g., GA-DTCDR [95] and DisenCDR [2], we adopt it as well to validate the recommendation accuracy of our CD2CDR and baselines. Moreover, the test set is created by the final interaction of each user, while the training set is formed by the remaining interaction records of each user. In line with the methods introduced in [2, 3], for every interaction in the test set, we randomly select 999 non-interacted items as negative samples for the test user, and then predict scores for a total of 1000 items to perform ranking. The leave-one-out approach mainly uses Hit Ratio (HR) and Normalized Discounted Cumulative Gain (NDCG), which are commonly adopted in ranking evaluations [97]. In our experiments, these metrics are applied to validate the recommendation accuracy within top-10 rankings, and all experiments are conducted five times with average results reported in this paper. 5.1.6 Comparison Methods . We choose seventeen state-of-the-art baseline models to conduct a comparison against the proposed CD2CDR. We then categorize the seventeen baseline models into four groups: (I) Single-Domain Recommendation (SDR), (II) Single-Target CDR, (III) Disentanglement-Based Dual-Target CDR, and (IV) Debiasing Dual-Target CDR. To the best of our knowledge, our CD2CDR is the first Deconfounding Dual-Target CDR model in the literature. Thus, we select three representative Debiasing Dual-Target CDR approaches as alternatives for Deconfounding Dual-Target CDR baselines. Moreover, although there are some methods that identify unobserved domain-specific confounders and even unobserved general confounders, or utilize backdoor adjustment in the single-domain manner, they are not selected as baseline models. This is because they focus on different settings, i.e., domain generalization [35, 86], CDSR [74, 83, 89], click-through rate (CTR) prediction [49, 66] and different item groups [63, 85], respectively, from our model. Furthermore, in Table 3, we present an in-depth analysis of embedding strategies and main ideas of seventeen baselines and our CD2CDR. Detailed descriptions of these baselines are listed as follows. \u00b7 NGCF [64] (I) is a classic recommendation framework based on a graph neural network that encodes collaborative signals through high-order connectivities using stacked embedding propagation layers. \u00b7 LightGCN [20] (I) is a representative recommendation model that simplifies the GCN by using linear message propagation to learn user and item embeddings through neighborhood aggregation. \u00b7 DCCF [52] (I) is a state-of-the-art framework for disentangling user intent in collaborative filtering by adaptively integrating self-supervised augmentation, leveraging global context and cross-view contrastive learning to enhance generalization and robustness in graph-based recommendation. Manuscript submitted to ACM \u00b7 BPR_EMCDR [46] (II) utilizes Bayesian Personalized Ranking model (BPR) [53] as its matrix factorization model and maps the latent factors of common users/items across different domains for effective knowledge transfer. \u00b7 BPR_DCDCSR [94] (II) integrates the latent factors from both domains by considering the sparsity degrees of individual users/items in each domain, creating more accurate benchmark factors to guide the deep neural network to map the latent factors across domains. \u00b7 CUT [29] (II) is a state-of-the-art single-target CDR model, which uses the user similarity in the target domain as a filter for collaborative information from the source domain. Through a user transformation layer and contrastive loss, CUT constrains user representations to preserve user relationships in the target domain during information transfer. \u00b7 BiTGCF [39] (III) combines high-order feature propagation on user-item graphs with a novel knowledge transfer mechanism, effectively balancing users' common features with domain-specific features across domains. \u00b7 GA-DTCDR [95] (III) generates more representative user/item embeddings by constructing heterogeneous graphs from two domains and applies an element-wise attention mechanism to combine the embeddings of common users to enhance the recommendation accuracy in both domains. \u00b7 DisenCDR [2] (III) uses two mutual-information-based regularizers to decouple domain-shared and domain-specific information, transferring only domain-shared information across domains to improve recommendation performance. \u00b7 CausalCDR [28] (III) incorporates causality into CDR by using causal embeddings to model the joint distribution of interactions and utilizes an adversarial domain classifier to decouple the domain-specific and domain-shared features. \u00b7 GDCCDR [38] (III) leverages two distinct contrastive learning-based constraints for feature disentanglement: one preserves domain-invariant features across domains, and the other disentangles domain-specific features via mutual information, with meta-networks supporting the personalized transfer of domain-invariant features. \u00b7 CrossAug [47] (III) uses intra- and inter-domain data augmentation based on cross-reconstructed representations, while utilizing Householder transformations for domain-shared center alignment to mitigate the domain shift. \u00b7 HJID [9] (III) uses a hierarchical subspace disentanglement method to split user representations into generic shallow and domain-specific deep subspaces, utilizing a causal data generation graph to decouple domain-shared and domainspecific latent factors, thus enhancing robustness against distribution shifts across domains. \u00b7 DIDA-CDR [98] (III) is a state-of-the-art disentanglement-based dual-target CDR model that uniquely decouples domain-independent user preferences, as well as domain-shared and domain-specific user preferences, to capture more comprehensive user preferences for recommendation. \u00b7 SCDGN [33] (IV) builds a cross-domain user-cluster graph and employs a debiasing graph convolutional layer to extract and transfer unbiased graph knowledge between domains. \u00b7 CDRIB [3] (IV) devises two information bottleneck regularizers to simultaneously model user-item interactions within and across domains, aiming to debias the user and item representations. \u00b7 IPSCDR [32] (IV) employs a generalized IPS estimator to mitigate selection bias in cross-domain contexts and devises three types of restrictions to learn propensity scores in the presence of unobserved domain-specific confounders. Since it is model-agnostic, for a fair comparison, we implement IPSCDR using the same state-of-the-art backbone (i.e., DIDA-CDR) as employed in our proposed CD2CDR. Overall, our baselines cover both single-domain and cross-domain recommendation models. In the experiments, we use our CD2CDR framework to extend all the above Disentanglement-Based Dual-Target CDR baselines. Experimental results (see Section 5.4) demonstrate that CD2CDR is highly extendable and compatible with most off-the-shelf disentanglement-based dual-target CDR backbones, making it suitable for a wide range of recommendation scenarios.", "5.2 Performance Comparison (for RQ1)": "Table 4 displays a comparative analysis of the performance 6 of different methods across all four tasks using HR@10 and NDCG@10 as evaluation metrics. It is worth mentioning that the Single-Target CDR baseline models are trained in both domains, but only their results in the data-sparser domain are reported, because they are designed to enhance the recommendation accuracy in the data-sparser domain. We can observe from Table 4: (1) Our CD2CDR improves Disentanglement-Based Dual-Target CDR baselines by an average of 16.73% and 18.40% w.r.t. HR@10 and NDCG@10, respectively. Among this type of baselines, BiTGCF [39] performs well on the RecTmall dataset, outperforming GA-DTCDR [95] and DisenCDR [2], but still falls short compared to CrossAug [47]. CrossAug, which utilizes cross-domain data augmentation and domain-shared center alignment, achieves competitive performance comparable to Debiasing Dual-Target CDR baselines. However, our CD2CDR still outperforms CrossAug by 11.95% and 13.17% w.r.t. HR@10 and NDCG@10, respectively. This is because, in addition to the user preference disentanglement, we adopt the confounder disentanglement, which effectively decouples observed SDCs and CDCs. By decoupling these confounders, we account for the fact that user interactions are not solely driven by their true preferences but also by observed confounders. Such confounders' positive influences can be secondary causes for user-item interactions, while their negative influences will result in capturing biased comprehensive user preferences. Effectively decoupling such observed confounders allows us to consider a more comprehensive range of factors affecting user-item interactions, thereby achieving better recommendation performance in both domains; (2) Our CD2CDR improves Debiasing Dual-Target CDR baselines by an average of 13.03% and 14.85% w.r.t. HR@10 and NDCG@10, respectively. This demonstrates that deconfounding the observed confounders in each of both domains effectively benefits the prediction of user-item interactions in dual-target CDR; (3) Our CD2CDR improves the best-performing baseline, i.e., IPSCDR [32], which is implemented with the same backbone as our model. Specifically, our CD2CDR outperforms IPSCDR with an average increase of 6.17% and 8.23% w.r.t. HR@10 and NDCG@10, respectively. This is because our CD2CDR particularly takes observed CDCs into consideration and our causal deconfounding module can not only eliminate observed confounders' negative effects on user preferences, but also preserve their positive effects on predicted interactions, thus gaining a more comprehensive understanding of user-item interactions; (4) In the challenging CSR scenario (Task #4) where user sets are completely non-overlapping, our CD2CDR still shows strong performance, outperforming the best-performing baseline model by an average of 4.75% and 6.33% w.r.t. HR@10 and NDCG@10, respectively. This demonstrates that our model adapts effectively to item-wise knowledge transfer through common items across different systems, and can extract item embeddings that are not entangled with observed confounders, enabling more accurate matching with comprehensive user preferences despite the absence of user overlap. This evaluation in the cross-system context extends our experimental scope beyond CDR scenarios, further validating the robustness and effectiveness of our model in more challenging CSR settings.", "5.3 Ablation Study (for RQ2)": "To highlight the significance of each component in enhancing the recommendation accuracy of our model, we reconstruct our CD2CDR into four variants and perform an ablation study for all four tasks.", "Disentanglement-Based Dual-Target CDR Baselines": "5.3.1 Impact of Confounder Disentanglement . We modify our proposed CD2CDR to form two variants, namely CD2CDR_Cross and CD2CDR_Single , by removing the SDC disentanglement and CDC disentanglement, respectively. From Table 5, we can observe that with SDC disentanglement module, our proposed CD2CDR outperforms CD2CDR_Cross with an average improvement of 5.49 %. This shows that the dual adversarial structure can effectively disentangle observed SDCs, and SDCs play an important role in predicting user-item interactions in each domain. In addition, our proposed CD2CDR improves CD2CDR_Single by an average increase of 4.23%. This indicates that half-sibling regression is well suited for decoupling observed CDCs, which are essential factors for achieving a comprehensive understanding of user-item interactions in both domains. Overall, our confounder disentanglement module can explicitly decouple more accurate observed confounders, especially the CDCs, thus enable our model to obtain better recommendation performance via accurate causal deconfounding. 5.3.2 Impact of Causal Deconfounding . Moreover, another variant, namely CD2CDR_Coarse , directly incorporates decoupled observed confounders with biased comprehensive user preferences in each domain and does not include the causal deconfounding module. From Table 5, we can observe that without the causal deconfounding module, the recommendation accuracy of CD2CDR_Coarse drops by 21.35% on average, making it less effective compared to the Debiasing Dual-Target CDR baselines. This shows that the causal deconfounding module indeed helps the model control the negative effects of SDCs and CDCs on user preferences. By recovering debiased comprehensive user preferences and then incorporating the positive effects of SDCs and CDCs into such preferences, the module enables the model to obtain the better recommendation accuracy in both domains. 5.3.3 Impact of Cycle Consistency Loss . In addition, we construct another variant, namely CD2CDR_Cycle , by removing the cycle consistency loss in the SDC disentanglement module. From Table 5, we can observe that our CD2CDRimproves CD2CDR_Cycle by an average of 1.01%. This demonstrates that the cycle consistency loss effectively preserves users' domain-specific preferences during the transformation process, ensuring the transformed preferences accurately reflect the original user preferences rather than merely confusing the discriminator. By incorporating the cycle consistency loss to stabilize the adversarial loss, our model can more accurately disentangle SDCs, providing strong support for explicitly considering the impact of observed confounders on user preferences and user-item interactions. Overall, our ablation study demonstrates the importance of each component in our CD2CDR model. Similar trends are observed in the CSR scenario (Task #4) where knowledge transfer relies on common items, further confirming the effectiveness of these components across different systems. Manuscript submitted to ACM 30 CDC Disentanglement 25 SDC Disentanglement 20 1 15 10 CyclecD2cDR Single Cross Coarse CDZCDR CDZCDR CDZCDR CDZCDR 5.3.4 Empirical Analysis of Time Complexity . To comprehensively evaluate the trade-off between effectiveness and efficiency of our model and its variants, we further conduct an empirical analysis of their time complexity. Fig. 4 illustrates the average time consumption of the confounder disentanglement phase across all four tasks. In Fig. 4, the time of confounder disentanglement phrase is divided into CDC disentanglement time (implemented via half-sibling regression) and SDC disentanglement time (implemented through dual adversarial training). As shown in Fig. 4, CD2CDR_Cross consumes significantly less time compared to other variants since it only employs half-sibling regression, which inherently requires no iterative training as mentioned in Section 5.1.4. However, this computational efficiency comes with a performance degradation of 5.49% in recommendation metrics. In contrast, CD2CDR_Single requires approximately 10 times more computational time since it relies solely on the dual adversarial structure, which demands multiple training epochs to converge, yet still underperforms our CD2CDR by 4.23% in recommendation metrics. In addition, CD2CDR_Coarse shows comparable time consumption to CD2CDR as it uses identical confounder disentanglement processes, despite suffering a substantial 21.35% performance drop. Notably, CD2CDR_Cycle consumes more time than our CD2CDR despite removing the cycle consistency loss, while also showing 1.01% lower performance. The increased time consumption occurs because without the stabilizing effect of cycle consistency loss, the adversarial training requires more iterations to reach convergence. Moreover, the absence of cycle consistency loss leads to less accurate SDC disentanglement, which explains the observed performance degradation. It is worth noting that the confounder disentanglement phase represents only a fraction of the overall computational cost in the entire training pipeline (as discussed in Section 4.5). Despite the differences in how CD2CDR and its variants implement confounder disentanglement and causal deconfounding, the major computational cost for both CD2CDR and its variants typically comes from the shared pretraining phase and final recommendation phase. As a result, the time differences observed in confounder disentanglement have a relatively limited impact on total training time. Based on the above analysis, CD2CDR achieves a good balance between effectiveness and efficiency, providing superior recommendation performance with reasonable computational requirements.", "5.4 Impact of Different Backbones (for RQ3)": ", Since our CD2CDR can be easily combined with disentanglement-based dual-target CDR backbone models, in addition to DIDA-CDR [98], we select all the other representative and state-of-the-art models from this group as backbones to form the following seven variants, namely, BiTGCF_CD2CDR , GA-DTCDR_CD2CDR , DisenCDR_CD2CDR CausalCDR_CD2CDR , GDCCDR_CD2CDR , CrossAug_CD2CDR and HJID_CD2CDR . Our aim is to demonstrate the flexibility and effectiveness of our CD2CDR by integrating it with various representative and state-of-the-art disentanglement-based dual-target CDR backbone models, thereby highlighting its generalizability and extendability Manuscript submitted to ACM Tmall-Favorite Tmall-Purchase 0 0 . 04 0 . 08 0 . 12 0 . 16 0 . 2 HR@10 (a) Tmall-Favorite Tmall-Purchase 0 0 . 02 0 . 04 0 . 06 0 . 08 0 . 1 NGCG@10 BiTGCF_CD2CDR GA-DTCDR_CD2CDR DisenCDR_CD2CDR CausalCDR_CD2CDR GDCCDR_CD2CDR CrossAug_CD2CDR HJID_CD2CDR Our CD2CDR (b) across diverse CDR scenarios. The performance comparison of our CD2CDR and its seven variants 7 with corresponding backbones is shown in Fig. 5. We find that when our model employs DIDA-CDR as the backbone, it improves the above seven variants, namely, BiTGCF_CD2CDR , GA-DTCDR_CD2CDR , DisenCDR_CD2CDR , CausalCDR_CD2CDR , GDCCDR_CD2CDR , CrossAug_CD2CDR and HJID_CD2CDR by an average of 7.97%, 16.87%, 11.42%, 7.74%, 5.09%, 4.47% and 2.34%, respectively. This improvement can be attributed to the ability of DIDA-CDR to effectively decouple three components of user preferences for modeling more accurate comprehensive user preferences. Notably, the ability of DIDA-CDR aligns well with the requirements of our CD2CDR, which relies on this precise disentanglement to accurately decouple observed confounders. In addition, our model, when combined with various backbones, consistently outperforms these backbones in their original form with an average improvement of 9.05% and 8.04% w.r.t. HR@10 and NDCG@10, respectively. This not only shows the superior efficacy of CD2CDR in improving recommendation performance in both domains, but also shows its generalizability to various CDR models.", "5.5 Parameter Sensitivity (for RQ4)": "5.5.1 Impact of the number of cluster centroids \ud835\udc3d . To explore the impact of number of cluster centroids \ud835\udc3d on the efficacy of our proposed CD2CDR, we keep \ud835\udc3d \ud835\udc34 \ud835\udc60\ud835\udc51 = \ud835\udc3d \ud835\udc35 \ud835\udc60\ud835\udc51 = \ud835\udc3d \ud835\udc50\ud835\udc51 and vary them in { 2 , 5 , 10 , 20 , 50 } . The corresponding experimental results are depicted in Figs. 6(a)-6(b). We can observe that as \ud835\udc3d increases, the recommendation performance initially improves but gradually plateaus beyond 10. This suggests that there is a threshold for \ud835\udc3d , which may vary in different datasets. Beyond this threshold, additional cluster centroids do not significantly improve the recommendation performance. In other words, once \ud835\udc3d reaches this threshold, the potential confounders represented by these cluster centroids are comprehensive enough for effective deconfounding. With the aim of achieving a balance between model complexity and recommendation accuracy, we finally set \ud835\udc3d \ud835\udc34 \ud835\udc60\ud835\udc51 = \ud835\udc3d \ud835\udc35 \ud835\udc60\ud835\udc51 = \ud835\udc3d \ud835\udc50\ud835\udc51 = 10 in all three tasks. In particular, the comprehensive confounder disentanglement significantly contributes to more accurate estimation of Eq. (12). More importantly, the experimental results show that our confounder disentanglement module can form effective confounder spaces, where even basic clustering techniques can easily identify key confounders, thereby yielding promising deconfounding results. 5.5.2 Impact of the weight of cycle consistency loss \ud835\udf06 . To examine the impact of the weight of cycle consistency loss \ud835\udf06 on the recommendation performance of our model, we test \ud835\udf06 with values from { 0 . 1 , 1 , 2 , 5 , 10 } . The experimental results are depicted in Figs. 6(c)-(d). We can observe that smaller values of \ud835\udf06 (e.g., 0.1 or 1) allow the adversarial losses to play a dominant role during training, driving the generator to better align the distributions of domain-specific user preferences across domains. Meanwhile, the cycle consistency loss still enforces moderate consistency, ensuring the transformation remains meaningful. In contrast, when \ud835\udf06 is set to larger values (e.g., 5 or 10), the cycle consistency loss 2 5 10 20 50 0 . 1 0 . 14 0 . 18 \ud835\udc3d HR@10 Tmall-Favorite Tmall-Purchase (a) 2 5 10 20 50 0 . 05 0 . 075 0 . 1 \ud835\udc3d NDCG@10 Tmall-Favorite Tmall-Purchase (b) 0.1 1 2 5 10 0 . 1 0 . 14 0 . 18 \ud835\udf06 HR@10 Tmall-Favorite Tmall-Purchase (c) 0.1 1 2 5 10 0 . 05 0 . 075 0 . 1 \ud835\udf06 NDCG@10 Tmall-Favorite Tmall-Purchase (d) 0.1 1 10 20 50 0 . 1 0 . 14 0 . 18 \ud835\udefc HR@10 Tmall-Favorite Tmall-Purchase (e) 0.1 1 10 20 50 0 . 05 0 . 075 0 . 1 \ud835\udefc NDCG@10 Tmall-Favorite Tmall-Purchase (f) becomes overly influential. As a result, the generator focuses primarily on minimizing cycle consistency loss, prioritizing outputs that closely resemble the inputs, rather than using feedback from the discriminator to refine cross-domain transformations. This weakens the discriminator's ability to guide the generator towards producing domain-specific user preferences that are indistinguishable from those in the target domain. Therefore, we select \ud835\udf06 = 1 to ensure a proper balance between the optimization of adversarial losses and cycle consistency loss. 5.5.3 Impact of the regularization parameter \ud835\udefc . To analyze the impact of the regularization parameter \ud835\udefc on decoupling candidate CDCs, we test \ud835\udefc with values from { 0 . 1 , 1 , 10 , 20 , 50 } . The results are shown in Figs. 6(e)-6(f). We can observe that small values of \ud835\udefc (e.g., 0.1) lead to insufficient regularization, making the regression overly sensitive to noise. By contrast, large \ud835\udefc values (e.g., 20 or 50) place too much emphasis on the regularization term, leading the model to underfit important features related to the CDCs. This weakens the model's ability to effectively decouple candidate CDCs. As shown in Figs. 6(e)-6(f), when \ud835\udefc = 1, our CD2CDR achieves the best trade-off between stabilizing numerical computations and maintaining the accuracy of decoupling candidate CDCs, thereby enhancing the effectiveness of subsequent deconfounding in cross-domain settings.", "5.6 Discussion": "5.6.1 Analysis of experimental results . The experimental results indicate that (1) Our CD2CDR consistently improves seventeen baselines. The improvements are primarily due to our proposed confounder disentanglement module and causal deconfounding module. The confounder disentanglement module, designed with the dual adversarial structure and half-sibling regression, efficiently decouples observed SDCs and CDCs. The causal deconfounding module uses backdoor adjustment to deconfound such decoupled observed confounders and incorporates their positive effects into debiased comprehensive user preferences, enhancing the recommendation accuracy in both domains. By contrast, the baseline models either ignore CDCs or only consider the negative effects of observed confounders, limiting their ability to achieve a comprehensive understanding of user-item interactions and thus leading to degraded recommendation performance; (2) Our CD2CDR is tailored for dual-target CDR to deconfound observed SDCs and CDCs from a causal Manuscript submitted to ACM perspective. Through comprehensive ablation studies, we highlight the impact of each module in accurately modeling the causal relationships among observed confounders, user preferences, and user-item interactions; (3) Our CD2CDR is a robust dual-target CDR framework capable of integrating with various state-of-the-art disentanglement-based backbone models, thereby highlighting its generalizability and extendability across diverse CDR scenarios. As demonstrated in Section 5.4, we combined our CD2CDR framework with several state-of-the-art disentanglement-based dual-target CDR backbones, resulting in an average improvement of 9.05% and 8.04% w.r.t HR@10 and NDCG@10, respectively. This indicates that with our framework, existing disentanglement-based dual-target CDR models can be extended for effective deconfounding, which is influential in developing more advanced CDR models; (4) Our CD2CDR demonstrates adaptability to the more challenging CSR scenario. In this scenario, our model also achieves significant improvements over baselines. This adaptability stems from our model's ability to extract more accurate item representations by handling observed confounders such as item popularity. For example, when an item is frequently interacted with, a data-driven RS improperly perceives the item's popularity as its intrinsic properties, creating biased item representations. In contrast to the above negative effect, item popularity can also serve as a secondary cause for predicting user-item interactions, which represents a positive effect. By effectively disentangling and then deconfounding observed confounders to preserve their positive effects while mitigating negative effects, our model enhances the recommendation accuracy in CSR scenarios where only item-wise knowledge transfer is possible. 5.6.2 Analysis of disentangled confounders . Beyond the quantitative evaluation, we conduct an in-depth analysis of how disentangled confounders affect recommendation results in dual-target CDR. The fundamental distinction between SDCs and CDCs lies in their scope of influence: SDCs exclusively affect user preferences and user-item interactions within a specific domain, while CDCs simultaneously influence both domains. Through our dual adversarial structure and half-sibling regression approach, we effectively decouple these confounders from user preferences for subsequent deconfounding steps. Furthermore, these disentangled confounders reveal important insights about confounding biases in dual-target CDR. Both SDCs and CDCs significantly affect user preference modeling and recommendation accuracy in different ways. Specifically, SDCs are mistakenly incorporated as part of domain-specific user preferences, distorting the preference representation. For example, 'free shipping' (an SDC) might be incorrectly identified as a user's true preference in the 'purchase' domain, leading to biased recommendations. Similarly, CDCs are incorrectly treated as domain-shared user preferences, creating confounding biases that affect both domains. Since domain-shared preferences represent user interests common to both domains, these biases distort the essential knowledge transfer across domains, resulting in inaccurate recommendations on both domains. In addition, these disentangled confounders also carry valuable information that directly influences user-item interactions through causal paths. For instance, while 'sales promotion' (a CDC) should not be misinterpreted as a user's true preference, it acts as a secondary cause that genuinely affects user behavior on both domains. The quality of confounder disentanglement directly determines the effectiveness of subsequent deconfounding steps. With well-disentangled confounders, our backdoor adjustment effectively eliminates their negative influence on user preference modeling, resulting in debiased comprehensive user preferences. Meanwhile, our confounder selection function preserves their positive direct effects on predicting user-item interactions. Our causal deconfounding approach, which removes negative effects while retaining positive ones, significantly enhances recommendation accuracy. This is achieved by providing a more comprehensive understanding of user-item interactions both within and across domains, particularly in scenarios where confounding effects are prominent. Similar principles of confounder disentanglement Manuscript submitted to ACM and causal deconfounding apply in the CSR scenario where item-wise knowledge transfer is crucial. In this scenario, observed confounders like item popularity similarly distort item representations, requiring proper disentangling and then deconfounding as we have analyzed in Section 5.6.1. 5.6.3 Limitations and future work . A limitation of this work is its focus on a dual-target CDR scenario, which does not fully address the multi-domain causal effects presented in real-world applications. In practice, users often interact across numerous domains simultaneously, creating intricate causal effect networks where user preferences in one domain may influence behaviors across multiple other domains through various direct and indirect pathways. Our current dual-target CDR framework may not be able to capture these complex multi-domain interaction patterns, potentially overlooking intricate multi-domain causal effects that exist in multi-target CDR. In addition, as briefly discussed in Section 4.3.1, our model faces challenges in eliminating residual confounding bias embedded in the original domain-specific user preferences. While our model mitigates these biases to a large extent, some deeply embedded confounders may still persist and affect deconfounding effectiveness. Moreover, our model focuses exclusively on observed confounders that can be explicitly decoupled from observed signals. However, in real-world recommendation scenarios, there exist unobserved confounders that cannot be directly disentangled from available data, such as environmental factors. These unobserved confounders may introduce additional bias into the recommendation process, posing a significant challenge for accurate recommendations. To address this challenge, we need to exploit instrumental variables [78] or learn substitutes for unobserved confounders [25]. We will leave the exploration of unobserved confounders and corresponding deconfounding strategies as one of our future research directions. In the future, we intend to extend our framework to account for multi-domain causal impacts to better reflect realworld scenarios, conduct real-world deployment validation, and enhance scalability to large-scale datasets. Meanwhile, we plan to explore unobserved confounders, and develop more sophisticated causal inference techniques to mitigate the residual confounding bias and other types of biases. Moreover, we intend to explore replacing our current BERT-based text encoding with more advanced large language models (LLMs) [59]. LLMs can generate higher-quality content representations from user reviews and item details, potentially leading to more accurate user, item, and confounder representations, thereby enhancing both the confounder disentanglement process and overall recommendation performance. Furthermore, we plan to explore simplified frameworks for causal deconfounding in CDR through, for example, knowledge distillation techniques [1, 75], where a simplified student model is trained to replicate the causal reasoning capabilities of more complex model. This approach could help achieve similar or better performance with fewer modules and hyperparameters, thereby reducing model complexity and implementation difficulty.", "6 Conclusion": "In this paper, we have proposed a novel Causal Deconfounding framework via Confounder Disentanglement for dual-target CDR, called CD2CDR. CD2CDR not only effectively decouples observed single-domain and cross-domain confounders, but also preserves the positive direct effects of such observed confounders on predicted interactions and eliminates their negative effects on capturing comprehensive user preferences, thereby enhancing the recommendation accuracy in both domains simultaneously. Moreover, we have conducted extensive experiments on seven real-world datasets, which demonstrates that our CD2CDR significantly outperforms the state-of-the-art methods.", "Acknowledgments": "This work is supported by ARC Discovery Project DP230100676.", "References": "[1] Zhicheng An, Zhexu Gu, Li Yu, Ke Tu, Zhengwei Wu, Binbin Hu, Zhiqiang Zhang, Lihong Gu, and Jinjie Gu. 2024. DDCDR: A Disentangle-based Distillation Framework for Cross-Domain Recommendation. In KDD . 4764-4773. [2] Jiangxia Cao, Xixun Lin, Xin Cong, Jing Ya, Tingwen Liu, and Bin Wang. 2022. DisenCDR: Learning Disentangled Representations for Cross-Domain Recommendation. In SIGIR . 267-277. [3] Jiangxia Cao, Jiawei Sheng, Xin Cong, Tingwen Liu, and Bin Wang. 2022. Cross-Domain Recommendation to Cold-Start Users via Variational Information Bottleneck. In ICDE . 2209-2223. [4] Wanyu Chen, Pengjie Ren, Fei Cai, Fei Sun, and Maarten De Rijke. 2021. Multi-interest Diversification for End-to-end Sequential Recommendation. ACM TOIS 40, 1 (2021), 1-30. [5] Xu Chen, Ya Zhang, Ivor W Tsang, Yuangang Pan, and Jingchao Su. 2023. Toward Equivalent Transformation of User Preferences in Cross Domain Recommendation. ACM TOIS 41, 1 (2023), 1-31. [6] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL-HLT . 4171-4186. [7] Pengfei Ding, Yan Wang, Guanfeng Liu, Nan Wang, and Xiaofang Zhou. 2025. Few-Shot Causal Representation Learning for Out-of-Distribution Generalization on Heterogeneous Graphs. IEEE TKDE 37, 4 (2025), 1804-1818. [8] Jing Du, Zesheng Ye, Bin Guo, Zhiwen Yu, Jia Wu, Jian Yang, Michael Sheng, and Lina Yao. 2024. Towards Robust Cross-Domain Recommendation with Joint Identifiability of User Preference. arXiv preprint arXiv:2411.17361 (2024). [9] Jing Du, Zesheng Ye, Bin Guo, Zhiwen Yu, and Lina Yao. 2024. Identifiability of Cross-Domain Recommendation via Causal Subspace Disentanglement. In SIGIR . 2091-2101. [10] Xiaoyu Du, Zike Wu, Fuli Feng, Xiangnan He, and Jinhui Tang. 2022. Invariant Representation Learning for Multimedia Recommendation. In MM . 619-628. [11] Yingpeng Du, Ziyan Wang, Zhu Sun, Yining Ma, Hongzhi Liu, and Jie Zhang. 2024. Disentangled Multi-interest Representation Learning for Sequential Recommendation. In KDD . 677-688. [12] Zhengxiao Du, Xiaowei Wang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Sequential Scenario-Specific Meta Learner for Online Recommendation. In KDD . 2895-2904. [13] Wenjing Fu, Zhaohui Peng, Senzhang Wang, Yang Xu, and Jin Li. 2019. Deeply Fusing Reviews and Contents for Cold Start Users in Cross-Domain Recommendation Systems. In AAAI . 94-101. [14] Chen Gao, Yu Zheng, Wenjie Wang, Fuli Feng, Xiangnan He, and Yong Li. 2022. Causal Inference in Recommender Systems: A Survey and Future Directions. ACM TOIS 42, 4 (2022), 1-32. [15] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative Adversarial Nets. In NIPS . 2672-2680. [16] Sindhu CM Gowda, Shalmali Joshi, Haoran Zhang, and Marzyeh Ghassemi. 2021. Pulling Up by the Causal Bootstraps: Causal Data Augmentation for Pre-training Debiasing. In CIKM . 606-616. [17] Xiaobo Guo, Shaoshuai Li, Naicheng Guo, Jiangxia Cao, Xiaolei Liu, Qiongxu Ma, Runsheng Gan, and Yunan Zhao. 2023. Disentangled Representations Learning for Multi-target Cross-domain Recommendation. ACM TOIS 41, 4 (2023), 1-27. [18] F Maxwell Harper and Joseph A Konstan. 2015. The MovieLens Datasets: History and Context. ACM TIIS 5, 4 (2015), 1-19. [19] Tianqi He, Kaiyuan Li, Shan Chen, Haitao Wang, Qiang Liu, Xingxing Wang, and Dong Wang. 2023. DMBIN: A Dual Multi-behavior Interest Network for Click-Through Rate Prediction via Contrastive Learning. In SIGIR . 1366-1375. [20] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang. 2020. LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation. In SIGIR . 639-648. [21] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In WWW . 173-182. [22] Xiangnan He, Yang Zhang, Fuli Feng, Chonggang Song, Lingling Yi, Guohui Ling, and Yongdong Zhang. 2023. Addressing Confounding Feature Issue for Causal Recommendation. ACM TOIS 41, 3 (2023), 1-23. [23] Guangneng Hu, Yu Zhang, and Qiang Yang. 2019. Transfer Meets Hybrid: A Synthetic Approach for Cross-Domain Collaborative Filtering with Text. In TheWebConf . 2822-2829. [24] Zhirong Huang, Shichao Zhang, Debo Cheng, Jiuyong Li, Lin Liu, and Guixian Zhang. 2024. Multi-Cause Deconfounding for Recommender Systems with Latent Confounders. arXiv preprint arXiv:2410.12366 (2024). [25] Xuanyu Jin, Ni Li, Wanzeng Kong, Jiajia Tang, and Bing Yang. 2024. Unbiased Semantic Representation Learning Based on Causal Disentanglement for Domain Generalization. ACM TOMM 20, 8 (2024), 1551-6857. [26] Heishiro Kanagawa, Hayato Kobayashi, Nobuyuki Shimizu, Yukihiro Tagami, and Taiji Suzuki. 2019. Cross-domain Recommendation via Deep Domain Adaptation. In ECIR . 20-29. Manuscript submitted to ACM [27] Diederik P Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In ICLR . [28] Fengxin Li, Hongyan Liu, Jun He, and Xiaoyong Du. 2024. CausalCDR: Causal Embedding Learning for Cross-domain Recommendation. In SDM . 553-561. [29] Hanyu Li, Weizhi Ma, Peijie Sun, Jiayu Li, Cunxiang Yin, Yancheng He, Guoqiang Xu, Min Zhang, and Shaoping Ma. 2024. Aiming at the Target: Filter Collaborative Information for Cross-Domain Recommendation. In SIGIR . 2081-2090. [30] Pan Li and Alexander Tuzhilin. 2020. DDTCDR: Deep Dual Transfer Cross Domain Recommendation. In WSDM . 331-339. [31] Qian Li, Xiangmeng Wang, Zhichao Wang, and Guandong Xu. 2023. Be Causal: De-Biasing Social Network Confounding in Recommendation. ACM TKDD 17, 1 (2023), 1-23. [32] Siqing Li, Liuyi Yao, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Tonglei Guo, Bolin Ding, and Ji-Rong Wen. 2021. Debiasing Learning based Cross-domain Recommendation. In KDD . 3190-3199. [33] Zhi Li, Daichi Amagata, Yihong Zhang, Takahiro Hara, Shuichiro Haruta, Kei Yonekawa, and Mori Kurokawa. 2022. Debiasing Graph Transfer Learning via Item Semantic Clustering for Cross-Domain Recommendations. In BigData . 762-769. [34] Yuliang Liang, Enneng Yang, Guibing Guo, Wei Cai, Linying Jiang, and Xingwei Wang. 2024. Deconfounding User Preference in Recommendation Systems through Implicit and Explicit Feedback. ACM TKDD 18, 8 (2024), 1-18. [35] Ziqian Lin, Hao Ding, Nghia Trong Hoang, Branislav Kveton, Anoop Deoras, and Hao Wang. 2024. Pre-trained Recommender Systems: A Causal Debiasing Perspective. In WSDM . 424-433. [36] Dugang Liu, Pengxiang Cheng, Hong Zhu, Zhenhua Dong, Xiuqiang He, Weike Pan, and Zhong Ming. 2021. Mitigating Confounding Bias in Recommendation via Information Bottleneck. In RecSys . 351-360. [37] Dugang Liu, Pengxiang Cheng, Hong Zhu, Zhenhua Dong, Xiuqiang He, Weike Pan, and Zhong Ming. 2023. Debiased Representation Learning in Recommendation via Information Bottleneck. ACM TORS 1, 1 (2023), 1-27. [38] Jing Liu, Lele Sun, Weizhi Nie, Peiguang Jing, and Yuting Su. 2024. Graph Disentangled Contrastive Learning with Personalized Transfer for Cross-Domain Recommendation. In AAAI . 8769-8777. [39] Meng Liu, Jianjun Li, Guohui Li, and Peng Pan. 2020. Cross Domain Recommendation via Bi-directional Transfer Graph Collaborative Filtering Networks. In CIKM . 885-894. [40] Xu Liu, Tong Yu, Kaige Xie, Junda Wu, and Shuai Li. 2024. Interact with the Explanations: Causal Debiased Explainable Recommendation System. In WSDM . 472-481. [41] Yuchen Liu, Yabo Chen, Wenrui Dai, Chenglin Li, Junni Zou, and Hongkai Xiong. 2022. Causal Intervention for Generalizable Face Anti-Spoofing. In ICME . 01-06. [42] Huishi Luo, Fuzhen Zhuang, Ruobing Xie, Hengshu Zhu, Deqing Wang, Zhulin An, and Yongjun Xu. 2024. A Survey on Causal Inference for Recommendation. The Innovation 5, 2 (2024), 100590. [43] Linhao Luo, Yumeng Li, Buyu Gao, Shuai Tang, Sinan Wang, Jiancheng Li, Tanchao Zhu, Jiancai Liu, Zhao Li, and Shirui Pan. 2023. MAMDR: A Model Agnostic Learning Framework for Multi-Domain Recommendation. In ICDE . 3079-3092. Jianxin Ma, Chang Zhou, Peng Cui, Hongxia Yang, and Wenwu Zhu. 2019. Learning Disentangled Representations for Recommendation. In [44] NeurIPS . 5711-5722. [45] Jianxin Ma, Chang Zhou, Hongxia Yang, Peng Cui, Xin Wang, and Wenwu Zhu. 2020. Disentangled Self-Supervision in Sequential Recommenders. In KDD . 483-491. [46] Tong Man, Huawei Shen, Xiaolong Jin, and Xueqi Cheng. 2017. Cross-Domain Recommendation: An Embedding and Mapping Approach. In IJCAI . 2464-2470. [47] Qingyang Mao, Qi Liu, Zhi Li, Likang Wu, Bing Lv, and Zheng Zhang. 2024. Cross-reconstructed Augmentation for Dual-target Cross-domain Recommendation. In SIGIR . 2352-2356. [48] Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang, and Stephen Paul Smolley. 2017. Least Squares Generative Adversarial Networks. In ICCV . 2794-2802. [49] Kong Menglin, Jia Wang, Yushan Pan, Haiyang Zhang, and Muzhou Hou. 2024. C 2 DR: Robust Cross-Domain Recommendation based on Causal Disentanglement. In WSDM . 341-349. [50] Cheng Ouyang, Chen Chen, Surui Li, Zeju Li, Chen Qin, Wenjia Bai, and Daniel Rueckert. 2022. Causality-Inspired Single-Source Domain Generalization for Medical Image Segmentation. IEEE TMI 42, 4 (2022), 1095-1106. [51] Judea Pearl and Dana Mackenzie. 2018. The Book of Why: The New Science of Cause and Effect . Basic books. [52] Xubin Ren, Lianghao Xia, Jiashu Zhao, Dawei Yin, and Chao Huang. 2023. Disentangled Contrastive Collaborative Filtering. In SIGIR . 1137-1146. [53] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In UAI . 452-461. [54] Masahiro Sato, Sho Takemori, Janmajay Singh, and Tomoko Ohkuma. 2020. Unbiased Learning for the Causal Effect of Recommendation. In RecSys . 378-387. [55] Bernhard Sch\u00f6lkopf, David W Hogg, Dun Wang, Daniel Foreman-Mackey, Dominik Janzing, Carl-Johann Simon-Gabriel, and Jonas Peters. 2016. Modeling Confounding by Half-Sibling Regression. PNAS 113, 27 (2016), 7391-7398. [56] Paras Sheth, Raha Moraffah, K Sel\u00e7uk Candan, Adrienne Raglin, and Huan Liu. 2022. Domain Generalization-A Causal Perspective. arXiv preprint arXiv:2209.15177 (2022). Manuscript submitted to ACM [57] Zijian Song, Wenhan Zhang, Lifang Deng, Jiandong Zhang, Zhihua Wu, Kaigui Bian, and Bin Cui. 2024. Mitigating Negative Transfer in Cross-Domain Recommendation via Knowledge Transferability Enhancement. In KDD . 2745-2754. [58] Hongzu Su, Jingjing Li, Zhekai Du, Lei Zhu, Ke Lu, and Heng Tao Shen. 2023. Cross-domain Recommendation via Dual Adversarial Adaptation. ACM TOIS 42, 3 (2023), 1-26. [59] Zhu Sun, Hongyang Liu, Xinghua Qu, Kaidong Feng, Yan Wang, and Yew Soon Ong. 2024. Large Language Models for Intent-Driven Session Recommendations. In SIGIR . 324-334. [60] Nhu-Thuat Tran and Hady W Lauw. 2023. Multi-Representation Variational Autoencoder via Iterative Latent Attention and Implicit Differentiation. In CIKM . 2462-2471. [61] Junyan Wang, Yiqi Jiang, Yang Long, Xiuyu Sun, Maurice Pagnucco, and Yang Song. 2023. Deconfounding Causal Inference for Zero-Shot Action Recognition. IEEE TMM 26 (2023), 3976-3986. [62] Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, Tao Qin, Wang Lu, Yiqiang Chen, Wenjun Zeng, and S Yu Philip. 2022. Generalizing to Unseen Domains: A Survey on Domain Generalization. IEEE TKDE 35, 8 (2022), 8052-8072. [63] Wenjie Wang, Fuli Feng, Xiangnan He, Xiang Wang, and Tat-Seng Chua. 2021. Deconfounded Recommendation for Alleviating Bias Amplification. In KDD . 1717-1725. [64] Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural Graph Collaborative Filtering. In SIGIR . 165-174. [65] Xiangmeng Wang, Qian Li, Dianer Yu, Peng Cui, Zhichao Wang, and Guandong Xu. 2022. Causal Disentanglement for Semantics-Aware Intent Learning in Recommendation. IEEE TKDE 35, 10 (2022), 9836-9849. [66] Yichao Wang, Huifeng Guo, Bo Chen, Weiwen Liu, Zhirong Liu, Qi Zhang, Zhicheng He, Hongkun Zheng, Weiwei Yao, Muyu Zhang, et al. 2022. CausalInt: Causal Inspired Intervention for Multi-Scenario Recommendation. In KDD . 4090-4099. [67] Yixin Wang, Dawen Liang, Laurent Charlin, and David M Blei. 2020. Causal Inference for Recommender Systems. In RecSys . 426-431. [68] Zhenlei Wang, Shiqi Shen, Zhipeng Wang, Bo Chen, Xu Chen, and Ji-Rong Wen. 2022. Unbiased Sequential Recommendation with Latent Confounders. In TheWebConf . 2195-2204. [69] Anpeng Wu, Kun Kuang, Ruoxuan Xiong, and Fei Wu. 2025. Instrumental Variables in Causal Inference and Machine Learning: A Survey. Comput. Surveys (2025). [70] Peng Wu, Haoxuan Li, Yuhao Deng, Wenjie Hu, Quanyu Dai, Zhenhua Dong, Jie Sun, Rui Zhang, and Xiao-Hua Zhou. 2022. On the Opportunity of Causal Learning in Recommendation Systems: Foundation, Estimation, Prediction and Challenges. In IJCAI . 5646-5653. [71] Yueqi Xie, Jingqi Gao, Peilin Zhou, Qichen Ye, Yining Hua, Jae Boum Kim, Fangzhao Wu, and Sunghun Kim. 2023. Rethinking Multi-Interest Learning for Candidate Matching in Recommender Systems. In RecSys . 283-293. [72] Shuyuan Xu, Jianchao Ji, Yunqi Li, Yingqiang Ge, Juntao Tan, and Yongfeng Zhang. 2025. Causal Inference for Recommendation: Foundations, Methods and Applications. ACM TIST 16, 3 (2025), 1-51. [73] Shuyuan Xu, Juntao Tan, Shelby Heinecke, Vena Jia Li, and Yongfeng Zhang. 2023. Deconfounded Causal Collaborative Filtering. ACM TORS 1, 4 (2023), 1-25. [74] Wujiang Xu, Qitian Wu, Runzhong Wang, Mingming Ha, Qiongxu Ma, Linxun Chen, Bing Han, and Junchi Yan. 2024. Rethinking Cross-Domain Sequential Recommendation under Open-World Assumptions. In TheWebConf . 3173-3184. [75] Wei Yang, Jie Yang, and Yuan Liu. 2023. Multimodal Optimal Transport Knowledge Distillation for Cross-domain Recommendation. In CIKM . 2959-2968. [76] Dianer Yu, Qian Li, Xiangmeng Wang, and Guandong Xu. 2023. Deconfounded Recommendation via Causal Intervention. Neurocomputing (2023), 128-139. [77] Feng Yuan, Lina Yao, and Boualem Benatallah. 2019. DARec: Deep Domain Adaptation for Cross-Domain Recommendation via Transferring Rating Patterns. In IJCAI . 4227-4233. [78] Junkun Yuan, Xu Ma, Ruoxuan Xiong, Mingming Gong, Xiangyu Liu, Fei Wu, Lanfen Lin, and Kun Kuang. 2023. Instrumental Variable-Driven Domain Generalization with Unobserved Confounders. ACM TKDD 17, 8 (2023), 1-21. [79] Ruohan Zhan, Changhua Pei, Qiang Su, Jianfeng Wen, Xueliang Wang, Guanyu Mu, Dong Zheng, Peng Jiang, and Kun Gai. 2022. Deconfounding Duration Bias in Watch-time Prediction for Video Recommendation. In KDD . 4472-4481. [80] Qing Zhang, Xiaoying Zhang, Yang Liu, Hongning Wang, Min Gao, Jiheng Zhang, and Ruocheng Guo. 2023. Debiasing Recommendation by Learning Identifiable Latent Confounders. In KDD . 3353-3363. [81] Ruohan Zhang, Tianzi Zang, Yanmin Zhu, Chunyang Wang, Ke Wang, and Jiadi Yu. 2023. Disentangled Contrastive Learning for Cross-Domain Recommendation. In DASFAA . 163-178. [82] Shengyu Zhang, Xusheng Feng, Wenyan Fan, Wenjing Fang, Fuli Feng, Wei Ji, Shuo Li, Li Wang, Shanshan Zhao, Zhou Zhao, et al. 2023. Video-Audio Domain Generalization via Confounder Disentanglement. In AAAI . 15322-15330. [83] Shengyu Zhang, Qiaowei Miao, Ping Nie, Mengze Li, Zhengyu Chen, Fuli Feng, Kun Kuang, and Fei Wu. 2024. Transferring Causal Mechanism over Meta-representations for Target-unknown Cross-domain Recommendation. ACM TOIS 42, 4 (2024), 1-27. [84] Shengyu Zhang, Lingxiao Yang, Dong Yao, Yujie Lu, Fuli Feng, Zhou Zhao, Tat-Seng Chua, and Fei Wu. 2022. Re4: Learning to Re-contrast, Re-attend, Re-construct for Multi-interest Recommendation. In TheWebConf . 2216-2226. [85] Yang Zhang, Fuli Feng, Xiangnan He, Tianxin Wei, Chonggang Song, Guohui Ling, and Yongdong Zhang. 2021. Causal Intervention for Leveraging Popularity Bias in Recommendation. In SIGIR . 11-20. Manuscript submitted to ACM [86] Yang Zhang, Yue Shen, Dong Wang, Jinjie Gu, and Guannan Zhang. 2023. Connecting Unseen Domains: Cross-Domain Invariant Learning in Recommendation. In SIGIR . 1894-1898. [87] Yi-Fan Zhang, Zhang Zhang, Da Li, Zhen Jia, Liang Wang, and Tieniu Tan. 2022. Learning Domain Invariant Representations for Generalizable Person Re-Identification. IEEE TIP 32 (2022), 509-523. [88] Zeyu Zhang, Heyang Gao, Hao Yang, and Xu Chen. 2023. Hierarchical Invariant Learning for Domain Generalization Recommendation. In KDD . 3470-3479. [89] Chuang Zhao, Xinyu Li, Ming He, Hongke Zhao, and Jianping Fan. 2023. Sequential Recommendation via an Adaptive Cross-domain Knowledge Decomposition. In CIKM . 3453-3463. [90] Chuang Zhao, Hongke Zhao, Xiaomeng Li, Ming He, Jiahui Wang, and Jianping Fan. 2023. Cross-Domain Recommendation via Progressive Structural Alignment. IEEE TKDE 36, 6 (2023), 2401-2415. [91] Yu Zheng, Chen Gao, Xiang Li, Xiangnan He, Yong Li, and Depeng Jin. 2021. Disentangling User Interest and Conformity for Recommendation with Causal Embedding. In TheWebConf . 2980-2991. [92] Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and Chen Change Loy. 2022. Domain Generalization: A Survey. IEEE TPAMI 45, 4 (2022), 4396-4415. [93] Feng Zhu, Chaochao Chen, Yan Wang, Guanfeng Liu, and Xiaolin Zheng. 2019. DTCDR: A Framework for Dual-Target Cross-Domain Recommendation. In CIKM . 1533-1542. [94] Feng Zhu, Yan Wang, Chaochao Chen, Guanfeng Liu, Mehmet Orgun, and Jia Wu. 2018. A Deep Framework for Cross-Domain and Cross-System Recommendations. In IJCAI . 3711-3717. [95] Feng Zhu, Yan Wang, Chaochao Chen, Guanfeng Liu, and Xiaolin Zheng. 2020. A Graphical and Attentional Framework for Dual-Target Cross-Domain Recommendation. In IJCAI . 3001-3008. [96] Feng Zhu, Yan Wang, Chaochao Chen, Jun Zhou, Longfei Li, and Guanfeng Liu. 2021. Cross-Domain Recommendation: Challenges, Progress, and Prospects. In IJCAI . 4721-4728. [97] Feng Zhu, Yan Wang, Jun Zhou, Chaochao Chen, Longfei Li, and Guanfeng Liu. 2021. A Unified Framework for Cross-Domain and Cross-System Recommendations. IEEE TKDE 35, 2 (2021), 1171-1184. [98] Jiajie Zhu, Yan Wang, Feng Zhu, and Zhu Sun. 2023. Domain Disentanglement with Interpolative Data Augmentation for Dual-Target Cross-Domain Recommendation. In RecSys . 515-527. [99] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. 2017. Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks. In ICCV . 2223-2232. [100] Xinyuan Zhu, Yang Zhang, Xun Yang, Dingxian Wang, and Fuli Feng. 2024. Mitigating Hidden Confounding Effects for Causal Recommendation. IEEE TKDE 36, 9 (2024), 4794-4805. [101] Yaochen Zhu, Jing Ma, and Jundong Li. 2023. Causal Inference in Recommender Systems: A Survey of Strategies for Bias Mitigation, Explanation, and Generalization. arXiv preprint arXiv:2301.00910 (2023). [102] Yaochen Zhu, Xubin Ren, Jing Yi, and Zhenzhong Chen. 2022. Deep Deconfounded Content-based Tag Recommendation for UGC with Causal Intervention. arXiv preprint arXiv:2205.14380 (2022)."}
