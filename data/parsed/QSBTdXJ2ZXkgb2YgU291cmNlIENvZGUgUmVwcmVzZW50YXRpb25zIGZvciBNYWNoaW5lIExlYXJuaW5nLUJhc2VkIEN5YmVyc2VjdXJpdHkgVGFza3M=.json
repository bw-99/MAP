{"A Survey of Source Code Representations for Machine Learning-Based Cybersecurity Tasks": "BEATRICE CASEY, University of Notre Dame, Notre Dame, United States JOANNA C. S. SANTOS, University of Notre Dame, Notre Dame, United States GEORGE PERRY, University of Notre Dame, Notre Dame, United States Machine learning techniques for cybersecurity-related software engineering tasks are becoming increasingly popular. The representation of source code is a key portion of the technique that can impact the way the model is able to learn the features of the source code. With an increasing number of these techniques being developed, it is valuable to see the current state of the fi eld to better understand what exists and what is not there yet. This article presents a study of these existing machine learning based approaches and demonstrates what type of representations were used for di ff erent cybersecurity tasks and programming languages. Additionally, we study what types of models are used with di ff erent representations. We have found that graph-based representations are the most popular category of representation, and tokenizers and Abstract Syntax Trees (ASTs) are the two most popular representations overall (e.g., AST and tokenizers are the representations with the highest count of papers, whereas graph-based representations is the category with the highest count of papers). We also found that the most popular cybersecurity task is vulnerability detection, and the language that is covered by the most techniques is C. Finally, we found that sequence-based models are the most popular category of models, and Support Vector Machines are the most popular model overall.", "CCS Concepts: \u00b7 General and reference \u2192 Surveys and overviews;": "Additional Key Words and Phrases: Source code representation, machine learning for software security, systematic literature review", "ACMReference Format:": "Beatrice Casey, Joanna C. S. Santos, and George Perry. 2025. A Survey of Source Code Representations for Machine Learning-Based Cybersecurity Tasks. ACM Comput. Surv. 57, 8, Article 217 (April 2025), 41 pages. https://doi.org/10.1145/3721977", "1 Introduction": "Software vulnerabilities are defects that a ff ect a software system's intended security properties [1] which allow attackers to perform malicious actions. As our lives become more attached to technology, software vendors are increasingly pressured into engineering secure software systems-that is, taking proactive measures of preventing/repairing vulnerabilities prior to deploying the systems into production. There are several practices to address security concerns before software release in each phase of the software development lifecycle. In the requirements phase, misuse/abuse cases [2, 3] and threat modeling [4] are useful to better understand the security requirements by Authors' Contact Information: Beatrice Casey, University of Notre Dame, Notre Dame, Indiana, United States; e-mail: bcasey6@nd.edu; Joanna C. S. Santos, University of Notre Dame, Notre Dame, Indiana, United States; e-mail: joannacss@nd. edu; George Perry, University of Notre Dame, Notre Dame, Indiana, United States; e-mail: gperry@nd.edu. This work is licensed under a Creative Commons Attribution 4.0 International License. \u00a9 2025 Copyright held by the owner/author(s). ACM 0360-0300/2025/04-ART217 https://doi.org/10.1145/3721977 identifying the potential threats to the system and possible ways to mitigate them. During the design phase, architectural risk analysis [5] can be used to assess the likelihood of exploitation of an asset and security tactics and patterns [6] can be applied in the design of the software as a proven solution that works under a context. At the implementation phase, secure code reviews can be performed to systematically examine the source code with the goal of identifying and fi xing vulnerabilities [7]. In the testing phase, penetration testing aims to exercise the software in many ways in an attempt to break it and discover vulnerabilities [8] and static/dynamic analysis tools can be used to identify potential vulnerabilities in the source code [9, 10]. Although these practices can help improve a software system's security, it can be error prone and time consuming for engineers to perform them. For example, fi nding vulnerabilities in code can be di ffi cult for engineers, especially when they do not know what to look for [7]. With the advances of machine learning (ML) , prior works have applied ML techniques to several of these cybersecurity tasks, such as vulnerability detection [11-16], malware detection [17-26] and malicious behavior detection [27]. These techniques are valuable because they can help improve the security of code that is released and speed up otherwise error-prone and time-consuming tasks. For example, a model that detects vulnerabilities prior to deployment would save time and money, and increase the security of the system as a whole, particularly since developers are oftentimes unaware when a vulnerability exists in code until it is exploited or found by security analysts [28]. ML models are unable to understand raw source code-that is, source code in an unprocessed form. As ML models rely on numerical data to adjust the weights necessary for learning, source code must be represented in a form that e ff ectively captures both its structural and semantic information. This transformation allows the model to understand and learn from the underlying patterns in the code. Thus, source code representation is a crucial part during the development of ML-based techniques because di ff erent representations will o ff er di ff erent information that the model learns from to perform their task [29]. There are many ways in which source code can be represented-for example, as an Abstract Syntax Tree (AST) [12, 16, 30-34], Control Flow Graph (CFG) [12, 13, 35-37], or tokenized [11, 15, 38-40], among others. Although prior works [41-48] have introduced novel source code representations for di ff erent cybersecurity tasks, there is no current understanding of what representations exist and are commonly used, as well as the cybersecurity tasks the model is being used for. Furthermore, many of these ML-based techniques are only tested on or made for a particular programming language, and there is no current understanding of the languages that are covered by these techniques. Understanding the available source code representations and what they o ff er will allow researchers to identify which representation they may want to use based on what task they aim to complete. Additionally, understanding the relationship between cybersecurity tasks and representations will allow researchers to either choose a representation that has previously been used for a particular task or test if a di ff erent representation would be more suitable. In this article, we conduct a Systematic Literature Review (SLR) by following the guidelines by Kitchenham and Charters [49] to understand the current state of the art of source code representation for ML-based techniques for cybersecurity tasks. We investigate the popularity of certain representations and cybersecurity tasks, the programming languages covered by existing techniques, and the common types of ML models used with di ff erent representations. We also investigate relationships between representations and cybersecurity tasks. The goal of the study is to allow researchers to understand the gaps in this domain, particularly if there are certain cybersecurity tasks, or languages that are neglected by existing techniques. Additionally, we study and contrast existing representations. The contributions of this article are as follows: (1) an examination of the state of the art of MLbased cybersecurity tasks; (2) an investigation of source code representations, and their relationships to cybersecurity tasks and models; (3) the identi fi cation of the programming languages that are covered/not covered by existing ML-based techniques; and (4) a comparison of the di ff erent source code representations. The article's artifacts, including datasets, code, and additional resources, are available on GitHub: https://github.com/s2e-lab/code-representation-slr. The rest of this article is organized as follows. Section 2 provides the de fi nitions of terms that are relevant for understanding our work. Section 3 describes related work. Section 4 explains the methodology of this SLR. Sections 5 through 9 share the results of this work. Section 10 explains threats to validity, and Section 11 provides a discussion and conclusion of our fi ndings.", "2 Background": "This section discusses core terminology such that the article can be understood by a broader audience.", "2.1 ML for Secure So ft ware Engineering": "Along with developing new code of good quality, software engineers are responsible for discovering and resolving bugs, defects, vulnerabilities, and any other issues that could arise in source code. These tasks can be di ffi cult, error prone, time consuming, and tedious [7]. Following the de fi nition of Kemmerer [50], a cybersecurity task is a task that is aimed at thwarting would-be intruders. Thus, the cybersecurity tasks that software engineers work on today involve resolving and identifying code that could allow an attacker to take advantage of a system. With the recent advances of ML, several prior works identi fi ed ways in which ML could assist software engineers in these cybersecurity tasks [51]. In particular, given how negatively vulnerabilities and other security-related issues impact companies, researchers started looking into how ML can help mitigate these issues and overall improve the quality of source code that is put out to the public.", "2.2 Source Code Representations and Code Embeddings": "A source code representation captures the source code's syntax and semantics such that the model is able to learn the key features. There are many ways a piece of source code can be represented. For example, given the structured nature of source code, prior works captured this structure by representing it as a graph [52]. Other works [38, 53, 54] used Natural Language Processing (NLP) techniques on source code to leverage technology and knowledge that already exists. These representations o ff er di ff erent information about the source code and thus impact what the model can learn about it. For example, NLP techniques do not o ff er structural information, but they provide semantic information. Therefore, the model will learn the semantic relationships, but not the structural relationships in the code. ML models learn from vector embeddings , which is a low-dimensional way to represent highdimensional data. In the case of learning source code, the embeddings are created from the source code representation. The source code representation is the fi rst level of abstraction for the original source code. This is what is considered as the feature extraction phase. In this phase, the original high-dimensional data are transformed into lower-dimensional data, which represents the key features of the data. The feature extraction is aimed at preserving as much of the information about the original data as possible [55]. The vector embeddings are the second level of abstraction and are what allows us to perform ML techniques on the representations by transforming the representation to the numerical form that machines are able to understand [56]. In this literature review, we focus only on the fi rst level of abstraction (i.e., source code representation). There are a multitude of techniques to create these embeddings. From the realm of NLP work, the embeddings are usually created by using the word 2 vec model [57], which takes tokens and converts them to numerical vectors. Inspired by this methodology, researchers have found a way to take a graph and create these vector embeddings ( graph 2 vec [58]). This technique is what is typically used to generate embeddings from the tree or graph structures generated by these source code representations. G raph 2 vec implements ideas from doc 2 vec and word 2 vec , and treats a whole graph as a document and the subgraphs as words [58]. Additionally, other works have looked at how to create embeddings straight from source code and created techniques such as code 2 vec [59] and G raph C ode 2V ec [60].", "3 Related Work": "To the best of our knowledge, this is the fi rst-of-its-kind SLR that focuses on the representations of source code used in ML-based techniques for cybersecurity tasks. There are a number of papers [6169] that perform either a systematic mapping study or a survey of the literature in ML for software engineering, with some papers focusing on vulnerability detection, analysis, or assessment. All of these papers primarily focus on the ML models used, but few mention or give detailed descriptions of the representations used in these e ff orts. Additionally, some of the papers focus only on deep learning techniques [64-66]. Unlike these prior works, our survey article has its primary focus on the topic of representations used for ML for security-related tasks. Gha ff arian and Shahriari [70] surveyed techniques used for vulnerability analysis and outlined four main categories that the approaches of these techniques fall under: software metrics , anomaly detection , vulnerable code pattern recognition , and miscellaneous . Similarly, Nazim et al. [63] analyzed deep learning models for vulnerable code detection. Their study examined the di ff erent dataset types used to train deep learning models (synthetic, semi-synthetic, real data, etc.), the evaluation metrics used to assess performance, as well as the di ff erent source code representations used. Unlike these prior works, we look beyond vulnerability analysis and detection, and instead look at all security-related software engineering tasks. We also have a broader scope because we look at all types of ML models, not just deep learning models. Wu [71] performed a literature review on NLP techniques for vulnerability detection. While this paper does give a brief overview of di ff erent types of representations, its focus is on NLP techniques, particularly NLP models that are focused for code intelligence, such as CodeBERT and CodeXGlue, in the instance of vulnerability detection. Chen and Monperrus [72] perform a similar literature review, investigating word embedding techniques on programs. In this survey, the authors explore di ff erent granularities of embeddings from di ff erent papers and show visualizations of the di ff erent embeddings. We focus on a wide array of security-related tasks, as well as many representations and how they can impact the model's ability to learn vulnerabilities. Kotti et al. [73] performed a tertiary study on ML for software engineering. This paper evaluated 83 reviews, or surveys, on the fi eld of ML for software engineering. While our article focuses on security-related software engineering tasks, Kotti et al. [73] investigated all ML-based software engineering tasks. Additionally, while this paper is a broader analysis of the software engineering tasks that ML covers, our article focuses primarily on the representations of source code used to perform a security task. Two papers create a taxonomy for software engineering tasks and ML, with one paper focusing broadly on software engineering challenges for ML systems [74], and the other focusing on software vulnerability detection and ML approaches [75]. Neither of these papers delve into source code representation e ff orts and what information they o ff er. However, Hanif et al. [75] do mention the importance of representation in the ML pipeline. Unlike these studies, our article focuses on the representations used, rather than just the models, and focuses on a wide array of security tasks. Usman et al. [76] performed a survey on representation learning e ff orts in cybersecurity. However, this paper does not focus on the representation of source code, but rather di ff erent ML algorithms used for cybersecurity issues, as well as datasets and how industry utilizes these di ff erent e ff orts to improve their cybersecurity. Similarly, Macas et al. [77] created a survey on deep learning techniques for cybersecurity. This article focuses on deep learning techniques to analyze internet tra ffi c. It provides insights and future directions in this area of deep learning to analyze internet tra ffi c for cybersecurity.", "4 Methodology": "We followed the guidelines outlined by Kitchenham and Charters [49] to conduct our SLR, which involves three major activities: planning , conducting , and reporting the review. During the planning phase, we de fi ned this study's research questions and the search query used to fi nd papers. During the conducting phase, we searched three library sources and downloaded all the papers we found into CSV fi les. We then applied our inclusion and exclusion criteria in three phases to eliminate papers until we got to the fi nal group of papers that are included in this study. Two reviewers independently read each paper and performed an analysis, extracting the information that is relevant to the research questions we developed in the planning phase. We reviewed and resolved discrepancies to get the fi nal analyses. We calculated Cohen's kappa to evaluate the reliability of our evaluation. Our score of 0.97 indicates that we had a near-perfect agreement in our analysis. Finally, during the reporting phase, we analyzed our data and organized it so that we could answer the research questions we posed.", "4.1 Research Qu estions": "Through this SLR, we aim to answer fi ve research questions. RQ1: What are the most commonly used source code representations? In this fi rst question, we investigate the source code representations that were used for solving security problems. We aim to understand which source code representations are more popular and compare their tradeo ff s. RQ2: Do certain cybersecurity tasks only or mostly use one type of source code representation? In this question, we investigate what source code representations are being used for each cybersecurity task and whether certain representations are favored for speci fi c tasks. Along with this, we want to investigate why it would be the case that a particular representation is preferred for a task. RQ3: What cybersecurity tasks are covered by the techniques that have been created? We investigate how these tasks fi t into the software development lifecycle to identify how these techniques would be used during software development. Furthermore, we describe and fi nd every cybersecurity-related task so that we provide a clearer picture of the task and its importance in the realm of software security. RQ4: What programming languages are predominantly targeted by the ML-based techniques for cybersecurity tasks? Given the vast number of programming languages used in practice, we investigate what languages the source code analyzed by these techniques is written. This question helps reveal any gaps in the coverage of programming languages by these techniques. RQ5: What models are commonly used with di ff erent representations? In this last question, we study which source code representations are used for di ff erent model types. By examining the frequency co-occurrence between models and representations, we aim to understand common trends and preferences in the design of ML-based techniques. This analysis helps identify potential gaps and opportunities for improvement in how models are paired with speci fi c representations.", "4.2 Search Method": "We used the following search string to fi nd all primary studies related to the representation(s) of source code for ML-based cybersecurity tasks: ('machine learning' OR 'deep learning' OR 'artificial intelligence') AND ('security' OR 'vulnerability') AND ('code') . While this is a very general search string, which resulted in a total of 67,512 papers, we decided that rather than having a speci fi c string that may miss a category of software security tasks or representations, we would make a general string and manually eliminate any papers that do not meet our inclusion criteria, or fi t our exclusion criteria. We searched three databases to fi nd relevant papers: the ACM Digital Library , 1 IEEE Xplore , 2 and Springer Link . 3 We also searched nine ML and NLP conferences which are considered to be A* conferences by the CORE conference ranker. These nine conferences are National Conference of the American Association for Artificial Intelligence (AAAI) , Conference on Learning Theory (COLT) , International Conference on Learning Representations (ICLR) , International Conference on Machine Learning (ICML) , International Joint Conference on Artificial Intelligence (IJCAI) , Advances in Neural Information Processing Systems (NeurIPS, formerly known as NIPS) , Association for Computational Linguistics (ACL) , 4 Empirical Methods in Natural Language Processing (EMNLP) , and International Conference on the Principles of Knowledge Representation and Reasoning (KR) . We did not search papers published at the International Joint Conference on Autonomous Agents and Multiagent Systems (previously the International Conference on Multiagent Systems, ICMAS, changed in 2000), the ACM International Conference on Knowledge Discovery and Data Mining , or the IEEE International Conference on Data Mining because these conferences' proceedings were included in the ACM and IEEE libraries.", "4.3 Inclusion and Exclusion Criteria": "Table 1 lists the inclusion/exclusion criteria applied to the papers in multiple stages to eliminate papers irrelevant for this study. We limited our search to papers published between January 2012 and May 2023. Our inclusion criteria focused on ML-based techniques for cybersecurity that involved representing source code. We eliminated duplicate studies, works not in English, and any papers that were not full papers, such as books, short papers (i.e., papers with less than fi ve full pages of text, not including references), and tutorials. We also disregarded any papers that did not represent the source code itself (e.g., papers that dealt with binary fi les, extracting from the Android Manifest), as we are interested in only understanding the representation of raw source code.", "Inclusion Criteria": "", "Exclusion Criteria": "I1 Written between 2012 and May 2023 I2 A full paper I3 Focused on ML for cybersecurity tasks I4 Contains information regarding the source code's representation E1 Duplicated studies E2 Books, reference work entries, reference works E3 Position papers, short papers, tool demo papers, keynotes, reviews, tutorials, and panel discussions E4 Studies not in English E5 Survey/comparative studies.", "4.4 Paper Selection": "Figure 1 shows the number of papers that made it through each stage of the selection process. We started out with 67,512 total primary studies. We fi rst excluded duplicate studies and studies that were outside the year range of 2012 to May 2023 (criterion I1), as well as non-full papers (criterion E1). This resulted in 52,836 papers. Subsequently, we inspected each paper's title, keywords, and abstract to include/exclude papers based on whether they fi t our criteria. After this search, we were left with 520 papers. We then applied the same criteria on these 520 papers, this time by reading the full paper. This left us with the 141 papers that are included in this survey.", "4.5 Data Extraction": "As we went through the papers, we extracted the key information we were looking for to answer our research questions: the representation used, the cybersecurity task it was completing, the programming languages the technique was designed for or tested on, and the model type used in the work. When determining the representation used, we used a one-paper-to-many-representations approach based on what the paper claims to be the representation(s) used. In other words, we consider every representation that a paper explicitly uses to train/ fi ne-tune their model(s) as a separate, valid representation. However, in the case a paper employs one or more representations solely as internal steps to derive a fi nal representation, then we treat only the fi nal representation as the representation used. For example, if a paper re fi nes an initial CFG through multiple transformations to produce a regular expression to represent the code, we capture only regular expression as the representation being used by the paper. Besides capturing the preceding metadata to directly answer our fi ve research questions, we conducted a comprehensive analysis of the performance of the source code representation(s). Speci fi cally, we went through the reported results in each paper, extracting the metrics provided. This allowed us to aggregate the data and compare the performance of di ff erent source code representations across various cybersecurity tasks.", "5 RQ1 Results: What Are the Commonly Used Source Code Representations?": "Table 2 summarizes the source code representations used/described by the surveyed papers. Similar to a prior work [64], we organized these representations into four categories: graph based , tree based , lexical , and miscellaneous . We found that the three most commonly used source code representations are a tokenizer , an AST , and code metrics . We also found two papers [51, 178] that used a slightly modi fi ed AST version to represent source code (we denoted them as AST+ in Table 2). Although more rare, some papers [21, 87, 92] represented code as an image analysis, and performed an image analysis of source code to identify patterns that are associated with vulnerabilities or malware. The following subsections give a detailed explanation of what each representation is and the information it carries out to the embeddings.", "5.1 Tree-Based Source Code Representations": "Tree-based representations are those that demonstrate the hierarchical nature of source code [64]. 5.1.1 Abstract Syntax Tree. An AST is a tree representation of source code that provides information about code elements (e.g., variables) and their structural relationship [63, 181]. It was the most popular representation (used by 32 papers). Although 1 paper [168] used code 2 vec [182] as a way to generate source code embeddings, the basis of their model is an AST; the source code is represented as an AST before the vectors are generated. Using the information from an AST, models can capture general structural code patterns, since ASTs abstract away the low-level syntax details of the underlying programming language of the code [12]. This reduces learning e ff ort and allows for ASTs to be used for multiple tasks [59]. Embeddings for ASTs can be generated in di ff erent ways. Typically, the node and path are what form the embedding so that the relationship between two nodes can be e ff ectively captured by the embedding [59]. 5.1.2 Parse Tree. A parse tree represents the hierarchy of tokens -that is, the program's terminal and non-terminal symbols. This data structure is generated by the language's parser [183]. Thus, ACM Comput. Surv., Vol. 57, No. 8, Article 217. Publication date: April 2025. the nodes represent the derivation of the grammar that yields the input strings. This representation has been used by Ceccato et al. [179] to represent SQL queries to train a model that detects SQL injection vulnerabilities. Although parse trees and ASTs both represent source code in a tree structure, their key di ff erence is that ASTs are much simpler than parse trees, as they abstract away grammar-related nodes while parse trees retain these tokens and their meanings with respect to their grammar. In Appendix A.1, we provide an example of a parse tree and AST for the same source code to demonstrate these di ff erences. 5.1.3 AST+. One paper [178] used a representation that is an enhanced version of an AST (which we denote in our article as AST+). That work uses a convention [184] that describes AST nodes in three types: placeholder , API , and syntax nodes . The ASTs are serialized and traversed using depth fi rst traversal, and each node and element is mapped to a vector. Xia et al. [51] do not specify the modi fi cations made to the AST; however, the paper states that additional edges are added to the AST to capture more semantic and stream information. This representation was used for vulnerability detection [51, 178].", "5.2 Graph-Based Representations": "Graph-based representations are those that transform source code into a graph form, with nodes and edges representing certain characteristics and relationships, respectively, between each code element. Graph-based representations can be embedded using G raph 2 vec [58], as it is an optimized method to transform the graphs into the low-dimensional numerical vectors that the models will learn from. As shown in Table 2, we found 24 di ff erent graph-based representations, whose descriptions are provided in the next sections. 5.2.1 Control Flow Graph. A CFG [185] was the most popular graph representation used in 14 papers [12, 13, 35-37, 78-86]. A CFG is a directed graph /u1D454 = ( /u1D449 , /u1D438 ) with nodes /u1D463 \u2208 /u1D449 and edges /u1D452 \u2208 /u1D438 , where /u1D438 \u2286 /u1D449 \u00d7 /u1D449 . The set of nodes /u1D449 represents the basic blocks of a program's procedure (i.e., a function/method), whereas the edge set /u1D438 represents the control fl ow between the basic blocks. A basic block is a group of instructions that are executed in order, one after the other. A CFG's edge /u1D452 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 denotes that the program's execution can fl ow from /u1D463 /u1D460 /u1D45F /u1D450 to /u1D463 /u1D451 /u1D460 /u1D461 . 5.2.2 Interprocedural Control Flow Graph. An Interprocedural Control Flow Graph (ICFG) is a variation of the CFG that describes not only intraprocedural fl ows among the basic blocks but also interprocedural ones [19]. An ICFG connects individual CFGs at the call sites to represent control fl ows across procedures. Thus, the ICFG allows the model to understand the control fl ow of the whole program , whereas the CFG allows the model to understand the control fl ow of a speci fi c procedure [186]. 5.2.3 Data Flow Graph. Seven papers used a Data Flow Graph (DFG) , which is a graph /u1D43A = ( /u1D449 , /u1D438 ) , where the nodes /u1D463 \u2208 /u1D449 are statements in the source code, and the edge set /u1D452 \u2208 /u1D438 represents the data dependencies between the nodes. In other words, an edge /u1D452 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that the node /u1D463 /u1D451 /u1D460 /u1D461 uses data that has been de fi ned by /u1D463 /u1D460 /u1D45F /u1D450 . 5.2.4 Program Dependence Graph. Program Dependence Graphs (PDGs) were the second most popular graph-based representation, being used by eight papers. A PDG [187] is a directed graph /u1D454 = ( /u1D449 , /u1D438 ) that shows the data and control dependencies for each statement in a program's procedure. The set of nodes /u1D449 in a PDG is partitioned into two types: statement nodes /u1D449 /u1D460 /u1D461 /u1D45A/u1D461 and predicate expression nodes /u1D449 /u1D45D /u1D45F /u1D452 /u1D451 . A statement node /u1D463 /u1D460 /u1D461 /u1D45A/u1D461 \u2208 /u1D449 /u1D460 /u1D461 /u1D45A/u1D461 represents simple statements in a program that are actions to be carried out by a program (e.g., x = 2; ). A predicate node /u1D463 /u1D45D /u1D45F /u1D452 /u1D451 \u2208 /u1D449 /u1D45D /u1D45F /u1D452 /u1D451 denotes statements that evaluate to true or false (e.g., x != 2 ). The edge set /u1D438 in a PDG has two partitions: control dependency edges /u1D438 /u1D450 and data dependency edges /u1D438 /u1D451 . A control dependency edge /u1D452 /u1D450 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 only executes if the predicate expression in /u1D463 /u1D460 /u1D45F /u1D450 evaluates to true. A data dependency edge /u1D452 /u1D451 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 denotes that /u1D463 /u1D451 /u1D460 /u1D461 uses data that has been de fi ned by /u1D463 /u1D460 /u1D45F /u1D450 . 5.2.5 Call Graph. A call graph is a directed graph /u1D454 = ( /u1D449 , /u1D438 ) in which the nodes are the functions/methods in a program, whereas the edges represents caller-callee relationships among program's procedures [188]. An edge /u1D452 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 denotes that /u1D463 /u1D460 /u1D45F /u1D450 invokes /u1D463 /u1D451 /u1D460 /u1D461 . These graphs can be of two types: static and dynamic call graphs. Dynamic call graphs give information regarding the procedure calls of a program while it is being executed. It shows the sequence of function/method calls, and the parameters that are passed to each procedure in the sequence. Static call graphs only give information about the potential execution paths a program can have based on information available at compile time. Thus, a static call graph is not as accurate in re fl ecting the actual calls in a program, particularly if the program is complex [188]. A total of six papers included in this survey used static call graphs [20, 22, 25, 35, 79, 96]. In Appendix A.2, we provide an example of a CFG, ICFG, DFG, PDG, and call graph to show the di ff erent type of information each representation provides for the same code snippet. 5.2.6 System Dependency Graph. Two papers represented source code using System Dependency Graphs (SDGs) [109, 110]. An SDG is a graph with multiple PDGs connected via the caller-callee relation given by a call graph. SDGs extend PDGs by describing the interprocedural relationships between the program's entrypoints 5 and the procedures they call [109]. To connect the PDGs, there are additional nodes and edges which dictate the actual input parameters and actual output values of a procedure. Every passed argument has an actual-in node /u1D44E /u1D456 and a formal-in node /u1D453 /u1D456 which are connected by the parameter-in edge /u1D44E /u1D456 - \u2192 /u1D453 /u1D456 . Every modi fi ed parameter and returned value has an actual-out node /u1D44E /u1D45C and a formal-out node /u1D453 /u1D45C , which are connected by the parameter-out edge /u1D453 /u1D45C - \u2192 /u1D44E /u1D45C . The formal-in and -out nodes are control dependent on the entry node /u1D452 and actual-in and -out nodes are control dependent on the call node /u1D450 . This parameter passing model ensures that interprocedural events of a procedure are propagated by the call sites. 5.2.7 Program Slices. A program slice [189] is a subgraph of a PDG or SDG that includes only the nodes that are relevant to a computation at a speci fi c point in the program. This subgraph is computed using a slicing criterion \u3008 /u1D463 , /u1D45D \u3009 which denotes a variable of interest /u1D463 at a program point /u1D45D . These slices can be computed in a backward or forward fashion. A backward slice includes all the nodes that may a ff ect the value of /u1D463 at the program point /u1D45D . A forward slice includes all nodes that are a ff ected by the variable /u1D463 at the program point /u1D45D . Program slices were used by two papers [14, 105] to detect vulnerabilities. The slicing criterion is determined by statements in the code that are considered as vulnerable. The statements could also be points where values are changed, which could then lead to an API call being vulnerable. Cheng et al. [105] use a PDG and perform forward and backward slicing from the node of interest. It is not speci fi ed in the work of Chen et al. [14] whether a PDG or SDG is used, but the same criterion for backward and forward slicing are used (i.e., forward slices include statements that are a ff ected by the node of interest, and backward slices include statements that a ff ect the node of interest). 5.2.8 Crucial Data Flow Graph. A Crucial Data Flow Graph (CDFG) , introduced by Wu et al. [101], is a subgraph of a DFG that contains only the crucial information from the DFG that could trigger a reentrancy vulnerability in smart contracts. The crucial nodes are variables containing sensitive or critical information, and that have a direct data fl ow to another crucial node. A CDFG is de fi ned as /u1D436 /u1D437 /u1D439 /u1D43A = ( /u1D449 , /u1D438 ) , where /u1D463 \u2208 /u1D449 are the crucial nodes and the edges /u1D452 \u2208 /u1D438 represent the data fl ow relationship. For example, /u1D452 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D460 /u1D45F /u1D450 and /u1D463 /u1D451 /u1D460 /u1D461 are both crucial nodes, and that there is a data fl ow between the two variables. In Appendix A.2, we provide an example of an SDG, a program slice, and a CDFG as a demonstration for what information can be expected from each representation. 5.2.9 Program Graph. Wang et al. [102] introduced the concept of the program graph , which is a directed graph /u1D454 = ( /u1D449 , /u1D438 ) in which the nodes /u1D463 \u2208 /u1D449 can be statements , identi fi ers (e.g., function declarations or variables), or values . This graph has eight types of edges: control fl ow edges, data fl ow edges, guarded by edges, jump edges, ComputedFrom edges, NextToken edges, LastUse edges, and LastLexicalUse edges. A control fl ow edge /u1D452 /u1D450 /u1D461 /u1D45F = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 can execute after /u1D463 /u1D460 /u1D45F /u1D450 . A data fl ow edge /u1D452 /u1D451 /u1D44E/u1D461 /u1D44E = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 uses a variable that has been de fi ned by /u1D463 /u1D460 /u1D45F /u1D450 . A guarded by edge /u1D452 /u1D454 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 only executes if the expression in /u1D463 /u1D460 /u1D45F /u1D450 evaluates to true (which is useful to identify operations that may be in the wrong order). A jump edge /u1D452 /u1D457 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 has a control dependency from /u1D463 /u1D460 /u1D45F /u1D450 . AComputedFrom edge /u1D452 /u1D450 /u1D45C/u1D45A/u1D45D /u1D439 /u1D45F /u1D45C/u1D45A = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D460 /u1D45F /u1D450 is or contains a variable used in an expression in /u1D463 /u1D451 /u1D460 /u1D461 . A NextToken edge /u1D452 /u1D45B/u1D452 /u1D465 /u1D461 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 is a successor of (i.e., follows) /u1D463 /u1D460 /u1D45F /u1D450 , where /u1D463 /u1D451 /u1D460 /u1D461 and /u1D463 /u1D460 /u1D45F /u1D450 are terminal nodes or tokens from the AST. A LastUse edge /u1D452 /u1D459 /u1D44E/u1D460 /u1D461 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 uses the same variable that is used in /u1D463 /u1D460 /u1D45F /u1D450 . A LastLexicalUse edge /u1D452 /u1D459 /u1D44E/u1D460 /u1D461 /u1D43F/u1D452 /u1D465 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 uses the same variable that is used in /u1D463 /u1D460 /u1D45F /u1D450 if /u1D463 /u1D460 /u1D45F /u1D450 is an if statement. 5.2.10 Code Property Graph. Used by fi ve papers [12, 97-100], a Code Property Graph (CPG) is a combination of ASTs, CFGs, and PDGs [52]. It was fi rst introduced by Yamaguchi et al. [52] speci fi cally as a way to detect vulnerabilities in C/C++ programs using static analysis. The way a CPG is generated is by taking the AST, CFG, and PDG of a program, modeling them as property graphs , and then these models are jointly combined by connecting statement and predicate nodes. A CPG is formally de fi ned as /u1D454 = ( /u1D449 , /u1D438 , /u1D706 , /u1D707 ) , which is a directed, labeled, attributed multigraph, with nodes /u1D463 \u2208 /u1D449 , edges /u1D452 \u2208 /u1D438 , edge labeling function /u1D706 , and a property mapping function /u1D707 . The set of nodes /u1D449 in a CPG is the nodes from an AST. The edge set /u1D438 in a CPG has three partitions: control fl ow edges /u1D438 /u1D450 /u1D453 \u2286 /u1D449 \u00d7 /u1D449 , program dependency edges /u1D438 /u1D45D/u1D451 \u2286 /u1D449 \u00d7 /u1D449 , and AST edges /u1D438 /u1D44E/u1D460 /u1D461 \u2286 /u1D449 \u00d7 /u1D449 . A control fl ow dependency /u1D452 /u1D450 /u1D453 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D460 /u1D45F /u1D450 can fl ow to /u1D463 /u1D451 /u1D460 /u1D461 in the next step of the program. A program dependency edge /u1D452 /u1D45D/u1D451 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 has a program dependence edge from /u1D463 /u1D460 /u1D45F /u1D450 . An AST edge /u1D452 /u1D44E/u1D460 /u1D461 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 is syntactically related to /u1D463 /u1D460 /u1D45F /u1D450 . The edge labeling function /u1D706 : /u1D438 - \u2192 \u03a3 assigns a label from the alphabet \u03a3 to each edge in /u1D438 . The function /u1D707 : ( /u1D449 \u222a /u1D438 ) \u00d7 /u1D43E - \u2192 /u1D446 applies properties to nodes and edges, where /u1D43E is the set of property keys and /u1D446 is the set of property values. Since a CPG is a combination of so many representations, it provides a very robust understanding of code. Other implementations of a CPG enhance it by adding information from a DFG [63]. 5.2.11 Simplified Code Property Graph. While CPGs are able to capture rich semantic and syntactic information, it is also very complex to create. Generating a PDG alone has a complexity of O ( n 2 ). The size of the graphs are also rather large, one example having 52 million nodes and 87 million edges [52]. To solve this issue, two papers implemented a Simpli fi ed Code Property Graph (SCPG) [106, 107]. An SCPG only uses edges from an AST and a CFG, as data dependence can be approximated from these two graphs. The nodes in the SCPG have two values: the code tokens and the node type . Removing the need to generate a PDG greatly reduces the cost of generating this representation, as one would only need to generate the AST and CFG. 5.2.12 Property Graph. A property graph [45] is variant of a CPG, de fi ned as /u1D454 = ( /u1D449 , /u1D438 , \u039b , \u03a3 , /u1D707 , /u1D706 , /u1D70E ) . Here, the edges and nodes are the same as the CPG. The adjacency function /u1D707 : /u1D438 \u2192 /u1D449 \u00d7 /u1D449 maps any edge to an ordered pair of its source and destination vertices. The function /u1D706 : /u1D449 \u2192 \u039b maps any given vertex to its respective attributes \u039b , and /u1D70E : /u1D438 \u2192 \u03a3 is the attribute function for edges, which, just as /u1D706 , maps any given edges to its respective attributes \u03a3 . 5.2.13 Code Aggregate Graph. A Code Aggregate Graph (CAG) is built from a combination of an AST, CFG, PDG, dominator tree, and post-dominator tree. A CAG is formally de fi ned as /u1D454 = ( /u1D449 , /u1D438 ) , which is a directed labeled, attributed multigraph, with nodes /u1D463 \u2208 /u1D449 and edges /u1D452 \u2208 /u1D438 where /u1D438 \u2286 /u1D449 \u00d7 /u1D449 . The set of nodes /u1D449 in a CAG is the nodes from an AST. The edge set /u1D438 in a CAG has fi ve partitions: control fl ow edges /u1D438 /u1D450 /u1D453 \u2286 /u1D449 \u00d7 /u1D449 , program dependency edges /u1D438 /u1D45D/u1D451 \u2286 /u1D449 \u00d7 /u1D449 , AST edges /u1D438 /u1D44E/u1D460 /u1D461 \u2286 /u1D449 \u00d7 /u1D449 , dominator tree edges /u1D438 /u1D451 /u1D461 \u2286 /u1D449 \u00d7 /u1D449 , and post-dominator tree edges /u1D438 /u1D45D/u1D451 /u1D461 \u2286 /u1D449 \u00d7 /u1D449 . A control fl ow dependency /u1D452 /u1D450 /u1D453 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D460 /u1D45F /u1D450 can fl ow to /u1D463 /u1D451 /u1D460 /u1D461 in the next step of the program. A program dependency edge /u1D452 /u1D45D/u1D451 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 has a program dependence edge from /u1D463 /u1D460 /u1D45F /u1D450 . An AST edge /u1D452 /u1D44E/u1D460 /u1D461 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 is syntactically related to /u1D463 /u1D460 /u1D45F /u1D450 . A dominator tree edge /u1D452 /u1D451 /u1D461 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that the operation /u1D463 /u1D451 /u1D460 /u1D461 is dominated by /u1D463 /u1D460 /u1D45F /u1D450 and all of /u1D463 /u1D460 /u1D45F /u1D450 dominators (i.e., all paths from the entry node to /u1D463 /u1D451 /u1D460 /u1D461 fi rst pass through /u1D463 /u1D460 /u1D45F /u1D450 ). A post-dominator tree edge /u1D452 /u1D45D/u1D451 /u1D461 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that the operation /u1D463 /u1D451 /u1D460 /u1D461 is post dominated by /u1D463 /u1D460 /u1D45F /u1D450 , meaning that all paths from /u1D463 /u1D451 /u1D460 /u1D461 to the end node must pass through /u1D463 /u1D460 /u1D45F /u1D450 . Using a dominator tree and post-dominator tree allows this representation to better capture semantic information in source code. This, in turn, allows models to perform better in the task of vulnerability detection. Nguyen et al. [114] point out certain information that a CFG and an AST in particular fail to capture, and how a dominator tree and a post-dominator tree can better describe these attributes. 5.2.14 Value Flow Graph. A Value Flow Graph (VFG) is similar to a PDG in that is shows the interprocedural program dependence. The edges, just like in a PDG, describe the control fl ow and data dependency of the program [190]. A VFG /u1D454 = ( /u1D449 , /u1D438 ) is a directed labeled graph, with nodes /u1D463 \u2208 /u1D449 and edges /u1D452 \u2208 /u1D438 . The set of nodes /u1D449 is a pair ( /u1D6FE 1 , /u1D6FE 2 ) in which /u1D6FE 1 is a node from the pre-directed acyclic graph and /u1D6FE 2 is a node from the post-directed acyclic graph. Both /u1D6FE 1 and /u1D6FE 2 represent the same value. The edge set /u1D438 in a VFG is a pair ( /u1D463 , /u1D463 \u2032 ) such that /u1D441 ( /u1D463 ) , the node fl ow graph of /u1D463 , is the predecessor of /u1D441 ( /u1D463 \u2032 ) , the node fl ow graph of /u1D463 \u2032 , and values are maintained along the connecting edge [191]. The paper [44] that used a VFG uses a special process that selects and preserves feasible valuefl ow paths to reduce the amount of data needed for training models for path-based vulnerability detection. This makes their method more lightweight than a typical VFG would be. In Appendix A.2, we provide an example of a CPG, a CAG, and a VFG for the same source code to highlight the di ff erences in the type of information provided by each representation. 5.2.15 Component Dependency Graph. A Component Dependency Graph (CDG) [27] represents the relationships between the di ff erent components in a graph and was created to capture Android app program logic. The CDG is formally de fi ned as /u1D454 = ( /u1D449 , /u1D438 ) , which is a directed labeled graph with nodes /u1D463 \u2208 /u1D449 and edges /u1D452 \u2208 /u1D438 . The set of nodes /u1D449 in a CDG represents the components of the Android app (i.e., Activity , Service , or Broadcast Receiver ). The edge set /u1D438 in a CDG represents the activation relationship between the components. An edge /u1D452 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that the component /u1D463 /u1D460 /u1D45F /u1D450 could activate the start of lifecycle of the component /u1D463 /u1D451 /u1D460 /u1D461 . 5.2.16 Component Behavior Graph. A Component Behavior Graph (CBG) [27] represents the lifetime or control fl ow logic of the permission-related API functions in a Java or Android program, as well as the functions performed on a particular resource for each component. This is the second half of the CDG, where both of these representations come together to fully describe the Android app. There are four types of nodes, each indicating the type of component at that portion of the graph. The edges connecting the CBG demonstrate the control fl ow logic between the API functions and sensitive resources. The CBG /u1D454 = ( /u1D449 , /u1D438 ) is a directed labeled graph with nodes /u1D463 \u2208 /u1D449 and edges /u1D452 \u2208 /u1D438 . The set of nodes /u1D449 in a CBG is partitioned into four types: root node /u1D449 /u1D45F /u1D45C /u1D45C /u1D461 , lifecycle function nodes /u1D449 /u1D459 /u1D456 /u1D453 /u1D452 , permission-related API function nodes /u1D449 /u1D45D /u1D45F /u1D44E/u1D45D /u1D456 , and sensitive resource nodes /u1D449 /u1D453 . A start node /u1D463 /u1D45F /u1D45C /u1D45C /u1D461 \u2208 /u1D449 /u1D45F /u1D45C /u1D45C /u1D461 represents the component itself. A lifecycle function node /u1D463 /u1D459 /u1D456 /u1D453 /u1D452 \u2208 /u1D449 /u1D459 /u1D456 /u1D453 /u1D452 represents the runtime programming logic. Each permission-related API functions node /u1D463 /u1D45D /u1D45F /u1D44E/u1D45D /u1D456 \u2208 /u1D449 /u1D45D /u1D45F /u1D44E/u1D45D /u1D456 denotes a permission-related API function-for example, Android's API sendTextMessage() . A sensitive resource node /u1D463 /u1D453 \u2208 /u1D449 /u1D453 indicates sensitive data that is accessed by a component. The edge set /u1D438 in a CBG represents the control fl ow logic of the framework API functions and sensitive resources. A CDG edge /u1D452 /u1D450 /u1D44F/u1D454 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates either that if /u1D463 /u1D460 /u1D45F /u1D450 and /u1D463 /u1D451 /u1D460 /u1D461 are in the same controlfl ow block, then /u1D463 /u1D451 /u1D460 /u1D461 is executed right after /u1D463 /u1D460 /u1D45F /u1D450 with no executions in between, or if /u1D463 /u1D460 /u1D45F /u1D450 and /u1D463 /u1D451 /u1D460 /u1D461 are in two continuous control fl ow blocks (named /u1D435 /u1D451 /u1D460 /u1D461 and /u1D435 /u1D451 /u1D460 /u1D461 , respectively), then /u1D463 /u1D460 /u1D45F /u1D450 is the last function node in /u1D435 /u1D460 /u1D45F /u1D450 and /u1D463 /u1D451 /u1D460 /u1D461 is the fi rst node in /u1D435 /u1D451 /u1D460 /u1D461 . In Appendix A.2, we provide an example of a CDG and a CBG to demonstrate how they work together. 5.2.17 Contextual Interprocedural Control Flow Graph. The Contextual Interprocedural Control Flow Graph (CICFG) is an extension of the ICFG, and it describes the complete control fl ow across all instructions, including context [19]. A context de fi nes the information needed for an operation to occur. The CICFG is formally de fi ned as /u1D43A = ( /u1D449 , /u1D438 , /u1D709 ) . The nodes /u1D463 \u2208 /u1D449 are basic blocks, and the edges /u1D452 \u2208 /u1D438 are either intraprocedural control fl ows or calling relationships from a node /u1D463 /u1D460 /u1D45F /u1D450 to /u1D463 /u1D451 /u1D460 /u1D461 . Last, /u1D709 is a set of contexts through which every node /u1D463 \u2208 /u1D449 could be reached [19]. The primary di ff erence between the CICFG and the ICFG is that the CICFG gives a more detailed analysis of a program because the context allows to di ff erentiate between di ff erent instances or paths that a function may be called. Two examples of a context are user aware and user unaware , which indicates whether the user is aware of what operations or resources an application or piece of code is using. For example, if an app is using the user's location, in a user-aware context, the user knows that the app is using their location, whereas in a user-unaware context, the user would not know about the app using the user's location [26]. 5.2.18 Contextual API Dependency Graph. The Contextual API Dependency Graph (CADG) is built from a CICFG. Not all of the nodes of the CICFG are security related or invoke a sensitive API. The CADG is an abstraction of the CICFG that only focuses on the security sensitive API invocations [19]. A CADG /u1D454 = ( /u1D449 , /u1D438 , /u1D6FC ) is a directed labeled graph, with nodes /u1D463 \u2208 /u1D449 , edges /u1D452 \u2208 /u1D438 , and labeling function /u1D6FC . The set of nodes /u1D449 in a CADG represents the basic blocks of the program. The edge set /u1D438 in a CADG represents the data fl ow between the basic blocks. A CADG edge /u1D452 /u1D450 /u1D44E/u1D451 /u1D454 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 uses data that has been de fi ned by the basic block /u1D463 /u1D460 /u1D45F /u1D450 . The labeling function /u1D6FC : /u1D449 - \u2192 \u03a3 associates nodes with the labels of corresponding contextual API operations. Each label consists of the API prototype, entry point, and constant parameter [192]. 5.2.19 Contract/Semantic Graph. A contract graph [103] (or a semantic graph [108]) is a representation created speci fi cally for vulnerability detection in smart contracts. The set of nodes /u1D449 in a contract/semantic graph is partitioned into three types: core node /u1D449 /u1D450 /u1D45C /u1D45F /u1D452 , normal nodes /u1D449 /u1D45B/u1D45C /u1D45F /u1D45A , and fallback nodes /u1D449 /u1D453 . A core node /u1D463 /u1D450 /u1D45C /u1D45F /u1D452 \u2208 /u1D449 /u1D450 /u1D45C /u1D45F /u1D452 represents the key invocations and variables that play a crucial role in detecting vulnerabilities. A normal node /u1D463 /u1D45B/u1D45C /u1D45F /u1D45A \u2208 /u1D449 /u1D45B/u1D45C /u1D45F /u1D45A represents invocations and variables that can assist in detecting vulnerabilities, although they do not have the same signi fi cance as core nodes. A fallback node /u1D463 /u1D453 \u2208 /u1D449 /u1D453 simulates the fallback function that is incurred on a contract attack. The edge set /u1D438 in a contract/semantic graph has three partitions: control fl ow edges /u1D438 /u1D450 /u1D453 \u2286 ( /u1D449 /u1D450 /u1D45C /u1D45F /u1D452 \u00d7 /u1D449 /u1D45B/u1D45C /u1D45F /u1D45A ) \u222a ( /u1D449 /u1D45B/u1D45C /u1D45F /u1D45A \u00d7 /u1D449 /u1D453 ) \u222a ( /u1D449 /u1D453 \u00d7 /u1D449 /u1D453 ) , data fl ow edges /u1D438 /u1D451 \u2286 ( /u1D449 /u1D450 /u1D45C /u1D45F /u1D452 \u00d7 /u1D449 /u1D45B/u1D45C /u1D45F /u1D45A ) \u222a ( /u1D449 /u1D45B/u1D45C /u1D45F /u1D45A \u00d7 /u1D449 /u1D453 ) \u222a ( /u1D449 /u1D453 \u00d7 /u1D449 /u1D453 ) , and fallback edges /u1D438 /u1D453 /u1D44E/u1D459 /u1D459 \u2286 /u1D449 /u1D453 \u00d7 /u1D449 /u1D453 . A control fl ow edge /u1D452 /u1D450 /u1D453 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D460 /u1D45F /u1D450 can fl ow to /u1D463 /u1D451 /u1D460 /u1D461 in the next step of the program. A data fl ow edge /u1D452 /u1D451 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 receives data from /u1D463 /u1D460 /u1D45F /u1D450 . A fallback edge /u1D452 /u1D453 /u1D44E/u1D459 /u1D459 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that /u1D463 /u1D451 /u1D460 /u1D461 is the fallback node and /u1D463 /u1D460 /u1D45F /u1D450 is the call.value invocation, which is the invocation in a smart contract that can cause a reentrancy vulnerability, if the code is vulnerable [108]. It can also mean that /u1D463 /u1D451 /u1D460 /u1D461 is the function under test, and /u1D463 /u1D460 /u1D45F /u1D450 is the fallback node. Generally, this edge indicates interactions with the fallback function [46]. In Appendix A.2, we provide an example of a CADG and a contract/semantic graph for a snippet of source code to demonstrate how the code is abstracted into these graph forms. 5.2.20 Contextual Permission Dependency Graph. The Contextual Permission Dependency Graph (CPDG) [26] is also built from a CICFG. The CPDG is an abstraction of the CICFG that only focuses on functionality related to Android permissions [26]. A CPDG /u1D454 = ( /u1D449 , /u1D438 , /u1D706 /u1D45D , /u1D709 ) is a directed labeled graph, with nodes /u1D463 \u2208 /u1D449 and edges /u1D452 \u2208 /u1D438 . Nodes in a CPDG represent the program's basic blocks whose functionality pertains to using Android permissions. Edges in a CPDG represent the data fl ow between the basic blocks. A CPDG edge /u1D452 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 indicates that there is a path from /u1D463 /u1D460 /u1D45F /u1D450 to /u1D463 /u1D451 /u1D460 /u1D461 in the CICFG, and that both nodes are in the same function. /u1D706 /u1D45D is the set of labels representing the concerned permissions. /u1D709 is a set of contexts through which every node is the CPDG could be reached [26]. 5.2.21 Contextual Source and Sink Dependency Graph. The Contextual Source and Sink Dependency Graph (CSSDG) [26] is also built from a CICFG. The CSSDG is an abstraction of the CICFG that considers only the nodes whose functionality is related to using sources and sinks . [26]. Sources are where sensitive data enters a program, and sinks are where they perform security critical operations. This sensitive data fl ow could be a point of a vulnerability if the data is not handled properly [96]. Thus, a CSSDG /u1D454 = ( /u1D449 , /u1D438 , /u1D706 /u1D460 , /u1D709 ) is a directed labeled graph, with nodes /u1D463 \u2208 /u1D449 and edges /u1D452 \u2208 /u1D438 . Nodes in a CSSDG represent the basic blocks of the program whose functionality is related to using sources and sinks, whereas the edges represent the data fl ow between the basic blocks. /u1D706 /u1D460 is the set of labels representing the concerned sources and sinks. /u1D709 is a set of contexts through which every node is the CSSDG could be reached [26]. 5.2.22 Slice Property Graph. Slice property graphs were proposed by Zheng et al. [111] and aim to preserve the semantics and structural information that is relevant to vulnerabilities. It also aims to eliminate irrelevant information to reduce the complexity of the graphs. The graph uses SyVCs (Syntax-based Vulnerability Candidates) as slicing criterion to extract the slice nodes that are relevant to vulnerabilities. Then, edges from the CPG are used as edges between the nodes in the SPG. 5.2.23 Token Graph. Token graphs [112] are built from tokens, connecting them via indexfocused construction. A token graph /u1D454 = ( /u1D449 , /u1D438 ) is a directed graph, with nodes /u1D463 \u2208 /u1D449 and edges /u1D452 \u2208 /u1D438 where /u1D438 \u2286 /u1D449 \u00d7 /u1D449 . The set of nodes /u1D449 in a token graph represents individual tokens from the source code. For example, a set of nodes can be /u1D456 /u1D453 , /u1D465 , == , /u1D466.alt . The edge set /u1D438 in a token graph de fi nes a co-occurrence relationship between tokens. The co-occurrences describe the relationships between tokens that occur within a fi xed-size sliding window [193]. 5.2.24 Propagation Chain. A propagation chain [104] exists when there is a code sequence among a number of speci fi ed code snippets. The sequence has direct or indirect data and control dependencies between adjacent code snippets. The propagation chain set /u1D443 /u1D436 ( /u1D44E , /u1D44F ) denotes the set of propagation chains between two code snippets a and b . Each program snippet will have propagation chains that a ff ect it and propagation chains that are a ff ected by it. In terms of vulnerability detection, a vulnerable, or defective, propagation chain denotes a code sequence from the vulnerable code to the program's vulnerable output. The set of defect propagation chain, called the defect propagation chain set , is denoted as /u1D438 /u1D443 /u1D436 ( /u1D451 , /u1D453 ) and is a subset of the propagation chain set /u1D443 /u1D436 ( /u1D451 , /u1D453 ) from a code snippet d to the program failure code f . Propagation chains can be constructed by data fl ow or control fl ow relationships. Zhang et al. [104] use data fl ow relationships to create the propagation chains for smart contracts. In this instance, the data fl ow graph is de fi ned as a set of nodes and edges /u1D454 = ( /u1D449 , /u1D438 ) , where the nodes /u1D463 \u2208 /u1D449 represent variables in a smart contract and the edge set /u1D438 denotes the dependency relationships between them. For example, /u1D452 = /u1D463 /u1D460 /u1D45F /u1D450 - \u2192 /u1D463 /u1D451 /u1D460 /u1D461 denotes that /u1D463 /u1D451 /u1D460 /u1D461 has a data relationship or dependence to /u1D463 /u1D460 /u1D45F /u1D450 .", "5.3 Lexical Representations": "Lexical representations describe representations that are focused on words and vocabularies. These representations do not show relationships between nodes, as done in graph representations. Lexical representations are also primarily based upon NLP work. 5.3.1 Tokenizer. A tokenizer , which can also be referred to as a lexed representation, takes source code and creates individual tokens for every word or symbol [63]. This is largely based o ff of existing NLP techniques. While there are a variety of di ff erent tokenization algorithms that can be used (e.g., SentencePiece), a majority of the studied papers did not specify what algorithm was used beyond simply stating 'the code was tokenized.' A few papers, instead, speci fi ed the library they used to tokenize the code-for example, Python's tokenizer [117], javalang tokenizer [40], ANTLR [15], js-tokens [120], Clang [137], and phply [86]. For the papers that explicitly stated their tokenization algorithm, we found papers using Byte Pair Encoding (BPE) subword tokenization [119, 122], SentencePiece [54], character-level tokenizers [39, 54], WordPiece [129, 138], white space tokenizers [133], and sentence-level tokenizers [87]. BPE subword tokenization is a method that breaks up whole words into smaller parts, in an e ff ort to compress the tokenized data. Frequent words are represented as individual tokens, but infrequent words are split into multiple subword tokens. For example, if the pair of tokens 'a' and 'b' happen frequently, then they will be combined and become the single token 'ab' [194]. SentencePiece is another subword tokenization method and employs lossless tokenization, where all the information needed to reproduce the normalized text is preserved in the output of the encoder (i.e., it treats the input text as a sequence of Unicode characters [195]). WordPiece tokenizes a word using MaxMatch, a process that involves iteratively picking the longest pre fi x of the remaining text that matches a vocabulary token until the entire word is segmented [196]. In Appendix A.3, we provide an example of BPE subword tokenizer, a standard tokenizer, SentencePiece, and WordPiece for the same source code, to demonstrate the di ff erences between the algorithms. Tokenizers that use strong embedding algorithms such as word2vec [57] are able to capture the semantic meaning of the code. When the vector embeddings are created from the tokenizer, these numbers are largely based o ff the semantic relationship with another word. In other words, if a word is semantically related to another, their vector representations will be similar [57]. These techniques can be particularly useful when the model needs to learn the semantics of a chunk of code to complete the task at hand. It is also quite simple to tokenize source code, with a complexity of /u1D442 ( /u1D45B ) . A built-in function for nearly any language will simply take in a line of text and break it up into tokens based on a provided delimiter. Models such as word2vec and doc2vec [57, 197] are very developed and are a great way to create word embeddings from a vocabulary. This is a reason this representation is also so popular. However, tokenizers do not capture the structural properties of source code, and this representation thus lacks the ability to understand the syntax of a program. 5.3.2 iSeVC and sSyVC. sSyVCs (source code and Syntax-based Vulnerability Candidates) are features of code that have some vulnerability syntax characteristics. An example would be for vulnerabilities that are associated with pointers. A sSyVC would be a line of code that contains an asterisk (*) since this symbol is what is used when dealing with pointers [158]. These characteristics are obtained through ASTs. [158]. iSeVCs (intermediate code and Semantics-based Vulnerability Candidates) are derived from sSyVC using program slicing. The sSyVCs are the nodes of interest, and the PDG of the program allows one to perform the forward and backward slicing, as described in Section 5.2.7. The resulting set of ordered statements, all containing data or control dependencies between them, are the iSeVCs [158]. iSeVCs contain information regarding data and control dependence, hence their name which relates them to semantics [48]. 5.3.3 Contract Snippet. A contract snippet [47] contains key program statements or lines from a smart contract which could induce a vulnerability. These contract snippets are aimed to be highly expressive such that more pertinent features can be extracted. The contract snippets are all semantically related by control fl ow dependence, and all highlight a key element ( call.value ) in reentrancy detection (which the paper this representation is proposed in focuses on). Contract snippets can be generated by control fl ow analysis. Once the contract snippets are created, they are then tokenized and transformed into feature vectors.", "5.4 Miscellaneous Representations": "Miscellaneous representations are those that do not fi t into any of the previously described categories. 5.4.1 Image. Prior works used the already very developed techniques in image analysis to analyze aspects of code to detect vulnerabilities [87, 92] and malware in Android applications [21]. The core idea behind this method is leveraging visual patterns in software to detect anomalies or similarities. This technique allows researchers to take advantage of the techniques developed for detection of elements in regular images. 5.4.2 Code Metrics. Code metrics are a quantitative measure that relates certain features to a numerical value, namely the number of times the feature occurs [198]. Code metrics can be de fi ned di ff erently for di ff erent tasks. Some common metrics include lines of code , code churn (i.e., how often code is changed), and more. Prior works also introduce new metrics for a particular purpose, such as SQL injection [156]. Rather than lines of code, or other classical metrics which would not be useful in SQL injection detection, metrics such as number of semicolons, presence of always true conditions, and the number of commands per statement provide more relevant information that would result in better predictions for SQL injection. These metrics can be related to a risk factor dictating how much of an impact the metric could have on code to create a security issue [198]. 5.4.3 Code Gadgets. Code gadgets are essentially a method to describe or represent a program slice. They have a number of ordered code statements or code lines that are semantically related to each other by data or control dependency [41]. Code gadgets were created for the exact purpose of vulnerability detection [41], which can explain the reason for its popularity in security-related tasks. 5.4.4 Opcode Sequences. An opcode , or operation code, speci fi es the operation to be completed for an instruction [199]. They, in particular, specify the lowest-level operation to be completed such as PUSH , MSTORE , and CALLVALUE [164]. These features can be used to understand on a low level what the code is doing. Opcodes are learned as vectors, and Liao et al. [164] use n-grams and word2vec [57] to learn them as embeddings. Since opcodes already dictate operations in computers, this representation is simple to generate. 5.4.5 Regular Expression. A regular expression is a sequence of characters that de fi nes a search pattern, often used for string matching or manipulating text within strings based on speci fi ed rules. One paper represented source code as regular expressions, which encode information about the API calls in the code. Speci fi cally, the work described by Liu et al. [180] fi rst takes an Android application and creates a CFG from the callbacks. The CFG is transformed to an ICFG, reduced to an API graph, and then an automata to regular expression algorithm is used to generate the regular expressions. This solution is used for multifamily malware classi fi cation and addresses the issues of recognizing malware family behavior patterns, code obfuscation, and polymorphic variants that are commonly used by attackers to evade detection. The regular expressions describe the behavior patterns of malware families. While this method can be computationally expensive, as three graphs have to be made before being transformed to a regular expression, it allows to capture the di ff erences between malware families. 5.4.6 Application Information. While this representation can be sorted under code metrics, the features extracted by Koli [23] more accurately fall under the name of application information . In this representation, an Android application is reverse engineered to extract the original Java fi les and Android XML. From these fi les, the API calls made and the permissions used are extracted. Other features such as is crypto code or is database that speci fi es certain features of the code that might be associated with malware [23] are also extracted. This representation is a method of feature extraction. Once these features are extracted, they are transformed into vectors of features, and given a label as being benign or malicious. Then, this data can be used in an ML classi fi er. 5.4.7 API Calls. Wang et al. [24] use API calls extracted from the source code of an Android application, along with permissions extracted from the Android Manifest fi le. This paper uses a tool called DroidAPIMiner to extract the top 20 API calls that are called by malicious applications. Using these API calls and permissions as features used to train a deep learning model allows [24] to fi nd malware in Android applications. Once again, this representation is a method of feature extraction, and the features are then converted into vectors which are then passed to a model.", "RQ1 Findings:": "-There are 39 representations o ff ering a variety of information about the source code, although a common goal is to capture the semantic and syntactic information in code. -There are 24 unique graph-based representations, the most popular source code representation category, as it shows the relationships between di ff erent nodes (e.g., lines or statements) and how they interact. -Althoughthere is a larger variety of graph-based representations, 47 papers used tokenizers and 32 papers used ASTs as their representations. -Seven papers [43-48, 101] propose a representation unique to their application (e.g., a contract graph [46] to fi nd smart contract vulnerabilities). Such task-/language-speci fi c representations are not generalizable to other languages and/or purposes.", "6 RQ2: Do Certain Tasks Only Use or Mostly Use One Type of Representation?": "Figure 2 depicts the relationships between representations and cybersecurity tasks . ASTs and tokenizers were the two representations most commonly used for vulnerability detection . Given how popular LLMs and NLP have become in recent years, it follows that a tokenizer would be a popular representation, as a tokenizer is what is used for NLP techniques. The vast availability of pre-trained Acronymns Binary Source Code Matching Tokenizer 1 Buffer Overrun Prediction Tokenizer 1 Classifying Android Sources & Sinks Code metrics 1 Call graph 1 Cryptography Misuse AST 1 Injection Attack Detection AST 1 Code metrics 1 Tokenizer 1 Malicious Behavior Detection CDG 1 CBG 1 Malicious Code Classi\u007fcation AST 1 Code metrics 1 Malicious Code Deobfuscation AST 1 Code metrics 1 Malicious Code Detection Tokenizer 1 Malicious Code Filtering Tokenizer 1 Malicious Code Localization ICFG 1 CADG 1 CPDG 1 CSSDG 1 CICFG 1 Malicious Package Detection AST 1 Malware Classi\u007fcation Regular Expression 1 Call graph 1 CFG 1 Malware Detection Call graph 3 ICFG 3 CADG 2 CPDG 1 Image 1 Application Information 1 API Calls 1 Tokenizer 1 CSSDG 1 CICFG 1 Malware Prediction Code metrics 1 Password Leaks Tokenizer 1 Reentrancy Detection Propagation Chain 1 Contract Snippet 1 Tokenizer 1 Security Analysis AST 1 Security Patch Identi\u007fcation Tokenizer 3 AST 1 Code metrics 1 Unprotected API Vulnerability Discovery AST 1 Vulnerability Analysis AST 1 CFG 1 Code metrics 1 CPG 1 Property Graph 1 PDG 1 Tokenizer 1 Vulnerability Classi\u007fcation AST 1 Tokenizer 1 Vulnerability Detection Tokenizer 20 AST 19 CFG 13 Code gadgets 7 DFG 7 PDG 7 Code metrics 4 CPG 4 iSeVC 3 AST+ 2 Image 2 Program slices 2 sSyVC 2 Contract Graph 2 Token Graph 2 SCPG 2 Call graph 1 Semantic Graph 1 CDFG 1 Program Graph 1 VFG 1 SDG 1 SPG 1 CAG 1 Vulnerability Extrapolation PDG 1 Vulnerability Localization CPG 1 Vulnerability Prediction Tokenizer 7 Code metrics 5 AST 2 SDG 1 Vulnerability Repair Tokenizer 3 AST 2 Vulnerability Testing Tokenizer 2 Opcode Sequences 1 Parse Tree 1 Vulnerable Code Clone Detection AST 1 Vulnerable Commits Detection Tokenizer 2 Code metrics 1 Legend graph-based tree-based miscellaneous lexical NLP models gives developers the power to easily fi ne-tune these models on whatever task they desire, without great cost [200]. ASTs are also a relatively cost-e ff ective representation, as compilers use ASTs to represent the structure of source code. This also allows developers to generate this representation with relative ease while also providing crucial structural details about source code that can expose vulnerabilities [175]. Although AST and tokenizers were the most used representations, we also found that vulnerability detection techniques mostly used graph-based representations . Graph-based representations were also popular for other cybersecurity tasks, namely malicious code localization, malware detection, vulnerability localization, vulnerability analysis, malware classi fi cation, and vulnerability extrapolation. Among the graph-based representations, CFG is the most popular one. This could be because it details the program's execution fl ow, which can be useful in fi nding whether a vulnerability would occur due to the structure of the program. A developer may choose a CFG over another representation, such as an AST, because it provides more detailed information about the source code. For example, compared to a call graph of a program from the dataset used in Mester and Bod\u00f3 [35], the CFG has 150,000 vertices/nodes, whereas the call graph has 10,000 nodes. While being more computationally expensive than some other methods (e.g., tokenizer or AST), the information provided by the graph allows for a more robust understanding of code. DFG is another popular representation, particularly for vulnerability detection. Similarly to CFGs, DFGs detail the fl ow of the program, although they detail the data fl ow . This can also be useful in vulnerability detection because if a harmful data input reaches a security sensitive program point, then a vulnerability will likely occur. Hence, one may choose a DFG over a CFG for detecting a speci fi c type of vulnerability related to data fl ows. Graph-based representations are useful for these types of tasks because they detail the overall structure and fl ow of code. To fi nd sinks , or points in code where a dangerous function call is invoked, it is helpful to understand the structure because one can pinpoint what function call starts or invokes the vulnerability. Additionally, depending on the type of information shared within the graph, one can better pinpoint areas of code which contains a vulnerability. Code gadgets , iSeVC , and sSyVC were representations that were speci fi cally made for vulnerability detection techniques. These representations are focused particularly on vulnerability candidates or potentially vulnerable snippets of code. This zoomed-in view allows for a more targeted approach toward vulnerability detection. One may choose this representation for a more lightweight approach to the problem compared to a more resource intensive method such as a CPG. ICFGs , call graphs , and CADGs are the preferred representations for malware detection. ICFGs describe the complete control fl ow across a program, and CADGs are derived from a version of ICFGs that include context. Both of these representations provide insights to potential security related invocations, which could allow malware to a ff ect the system. Understanding what calls are made and how instructions fl ow in a program can give insight to any irregular or unsafe operations done by the code. ICFGs are known to be robust against evasion and obfuscation methods that are used by malware [18]. This could be due to the fact that the ICFG gives the view of the whole program, and malware typically interacts with an entire system beyond just a singular procedure. Rather, malware may call functions outside of a procedure, and the ICFG would give insight to these calls, as well as any unusual or unexpected activity [26]. When choosing a representation for a particular task, it is important to consider the needs and resources of the developer for the application. For example, a CPG is a highly robust graph that is complex to generate. If the developer needs a highly robust graph for their task and has the resources to develop the CPG (for thousands of samples of code), then a CPG would be a good option as a representation. However, if the developer does not have the time or resources to have such a robust graph, but knows that the issue they are trying to detect pertains to the way data fl ows through a program (e.g., detecting injection attacks), then they might want to choose a DFG, as it would provide the information needed without being overly complex or resource intensive.", "RQ2 Findings:": "-Since vulnerability detection is the most popular task, it is the task that most representations are used for. -Certain representations (i.e., iSeVC, sSyVC, and code gadgets) were created for the speci fi c task of vulnerability detection and are therefore only used for that task. -Call graphs, ICFGs, and CADGs are the preferred representation for malware detection.", "7 RQ3: What Cybersecurity Tasks Are Covered by the ML-Based Techniques?": "To better understand the types of tasks that are covered by the techniques discussed in this paper, we sorted the di ff erent tasks to fi t into the nine disciplines of the Rational Uni fi ed Process (RUP) cycle [201]. The RUP cycle is a software development process framework that allows software developers to better organize and plan the development process. In this question, we sorted the unique cybersecurity tasks found from our search into the nine main work fl ows of the RUP cycle: business modeling, requirements, analysis and design, implementation, test, deployment, con fi guration and change management, project management, and environment. We observed that the cybersecurity tasks only fi t into fi ve out of the nine categories-those categories being analysis and design, con fi guration and change management, environment, implementation, and test. Figure 3 depicts how the di ff erent cybersecurity tasks fi t into these fi ve disciplines from the RUP cycle. Testing Vulnerability Detection 75 Vulnerability Prediction 14 Vulnerability Testing 4 Security Patch Detection/Identi\u007fcation 4 Vulnerability Analysis 3 Injection Attack Detection 3 Con\u007fguration and Change Management Vulnerability Fixing/Inducing Commits Detection 3 Reentrancy Detection 2 Vulnerability Localization 1 Vulnerability Extrapolation 1 Malicious Behavior Detection 1 Malicious Code Detection 1 Classifying Android Sources and Sinks 1 Malicious Code Localization 1 Cryptography Misuse 1 Password Leaks 1 Vulnerable Code Clone Detection 1 Unprotected API Vulnerability Discovery 1 Vulnerability Classi\u007fcation 2 Malicious Code Classi\u007fcation 1 Malicious Code Deobfuscation 1 Implementation Vulnerability Repair 4 Buffer Overrun Prediction 1 Malicious Code Filtering 1 Analysis and Design Malware Detection 10 Malware Classi\u007fcation 2 Malware Prediction 1 Security Analysis 1 Environment Malicious Package Detection 1 Binary Source Code Matching 1", "7.1 Analysis and Design": "Analysis and design involves translating requirements into a formal model of the software, resulting in a system description that guides implementation. We categorize these tasks under analysis and design, as these tasks are analyzing the source code without necessarily implementing a new design. The tasks in this category ensure that, once developers are able to start implementing the system, there are no security issues. Malware detection , prediction , and classi fi cation are important tasks, particularly for Android applications [17-26, 35, 150, 180], but also for any system vulnerable to malware. Malware allows attackers to take advantage of security fl aws in systems. Understanding types of malware and ransomware, as well as where they occur, allows one to take steps to avoid these issues before implementing a system. Security analysis is a task that was used particularly for smart contracts [175], but it can be generalized to any system that has the potential to be compromised.", "7.2 Implementation": "Implementation is the actual coding of the software model. This is when the design from the previous phase is brought to life. Vulnerability repair is a task that fi xes vulnerabilities in code. This fi ts into implementation because it is actually implementing the fi x to the code while the developer is working [30, 43, 115]. Moreover, there are a few tasks involved with inferring or predicting elements of code, such as bu ff er overrun prediction and vulnerability prediction . Bu ff er overrun is a type of vulnerability, and Choi et al. [128] focus their prediction approach on this one type of vulnerability rather than many others. These prediction techniques allow developers to know where these issues may occur in the code while they are implementing it. We consider these tasks as the implementation phase because vulnerability repair involves implementing a fi x to the problem. The prediction tasks, however, are also considered as implementation because it involves being proactive against these vulnerabilities or issues and fi nding them before they can be exploited.", "7.3 Testing": "Testing involves exercising the software for any fl aws or design inconsistencies, helping prevent costly security issues during production. Detection tasks indicate that the vulnerabilities already exist in the implemented system. Thus, the systems are being tested for these existing issues so they can be resolved. Many detection techniques fall into this category, such as cryptography misuse, malicious code detection, fi ltering, classi fi cation, deobfuscation, and localization; malicious behavior detection, password leaks, injection attack detection, reentrancy detection, vulnerability analysis, detection, classi fi cation, localization, extrapolation, and testing; vulnerable code clone detection; and unprotected API vulnerability discovery. Binary source code matching is also used for tasks like malware detection and vulnerability assessment [202].", "7.4 Configuration and Change Management": "Con fi guration and change management tracks and maintains a project as it is evolving through time. It ensures that the code created during implementation is still useable and can be reused throughout other portions of the project if needed [201]. Modern software development work fl ows often use remote repositories to track the code that has been created and its changes. Thus, commits are usually the source of a vulnerability or issue, and the fi x to a vulnerability or issue. Zhou et al. [131] and Nguyen-Truong et al. [130] created techniques to assist in the classi fi cation of security commits, as well as identifying vulnerability inducing, or vulnerability fi xing commits, including security patch detection. Due to the nature of these tasks (e.g., speci fi cally classifying, identifying, or detecting changes relating to security), we categorize these tasks under con fi guration and change management as they are directly related to how the code is changed and reused throughout a project.", "7.5 Environment": "Environment focuses on the software development environment required for the engineers to develop the system. This includes techniques and processes required by developers [201]. Packages are an essential part of the development process. They provide useful techniques that can greatly simplify the implementation of a system. However, some packages can contain some type of vulnerability or malware that can jeopardize the integrity of the system. Therefore, malicious package detection is an important task that can protect systems from such malicious software. We categorize this task under environment because packages are what developers use in their environment as part of their development process. While malicious packages might not necessarily impact their environment directly, it still involves the space in which developers work. As cryptocurrency becomes a more popular and prevalent topic, research is also starting to focus on creating ML-based techniques to assist in issues relating to cryptocurrencies and smart contracts [46, 47, 79, 101, 103, 108, 164, 166, 175, 176]. All of these papers are interested in vulnerability detection or testing, and security analysis of smart contracts. Two papers [47, 104] focus on a particular vulnerability called reentrancy attacks , which is a vulnerability speci fi c to smart contracts. This vulnerability results in an attacker being able to withdraw funds from a smart contract repeatedly and transfer them [47]. While most of the tasks are distinct, some tasks are very closely related to one another. For example, malicious behavior detection is looking for suspicious activities and behaviours that might indicate an attack, regardless of if the attack is using malware, whereas malware detection is typically looking for speci fi c features or signatures that are known to be associated with malware [17]. Detection tasks focus on generally identifying a certain feature (e.g., vulnerability detection focuses on broadly fi nding a segment of code that is vulnerable), whereas localization tasks are focused on pinpointing exactly where, in a larger code base, the feature occurs (e.g., vulnerability localization is focused on pinpointing the speci fi c line in which the vulnerability occurs). Similarly, prediction techniques are interested in fi nding issues before they are apparent in a system (e.g., vulnerability prediction focuses on fi nding vulnerabilities before they are launched o ffi cially into a system, to prevent an attacker having the opportunity to discover it when it is launched), whereas detection techniques are interested in identifying issues that already exist in a working system (e.g., vulnerability detection focuses on fi nding vulnerabilities that are already present in a launched system). Vulnerability testing , however, focuses on evaluating a system to determine whether it contains fl aws that could be exploited by malicious actors. Cryptography misuse describes a detection task, where improper uses of cryptography APIs are discovered. Cryptography APIs tend to be hard to use, so this task alerts developers to when they may have made a mistake in their implementation [33]. Vulnerability extrapolation describes a task that aims to fi nd potential vulnerabilities based on existing vulnerabilities. This allows developers to fi nd vulnerabilities that may not exist or be known yet based on past vulnerabilities and their structure. This task in particular focuses on how vulnerabilities can spread or appear in similar contexts based on the vulnerability characteristics [91]. Unprotected API vulnerability discovery refers to discovering instances in which a vulnerability can occur when an unprotected API is called or used in a system [174].", "RQ3 Findings:": "-Vulnerability detection by far is the most popular task, with 75 papers focusing on this task. -Certain papers focus solely on detecting one type of vulnerability, such as bu ff er overrun prediction, reentrancy detection, and injection attack detection. -Amajority of these tasks fi t under the testing category of the RUP cycle, meaning that these techniques are aimed for evaluating the security of already written code before it is deployed.", "8 RQ4: What Programming Languages Are Predominantly Targeted by the ML-Based Techniques for Cybersecurity Tasks?": "Table 3 shows the programming languages that are covered by existing techniques. Two works [35, 125] did not specify the language(s) used. Papers without language or dataset details are labeled as 'not speci fi ed.' We observed that C is the most popular language; 81 (57.4%) papers developed techniques for C programs. C++ is the second most common language, covered by 50 papers (35.5%), all of which also supported C . The popularity of the C and C++ languages could be attributed to two main factors: the availability of datasets for cybersecurity tasks [203-206], and the higher risk of memory-related vulnerabilities in these languages [207]. We also observed that a number of techniques focus on security tasks for Android applications [12, 12, 17-27, 35, 96, 150, 180]. Although Android applications can be written using Kotlin and Java , the papers studied in this survey only focused on apps written in Java . Additionally, with the increasing popularity of smart contracts, a number of papers developed techniques for Solidity , the language in which smart contracts are written. We also observed that there are only 6 techniques for Python and 12 for JavaScript , which is surprising given their increasing popularity with developers. 6 If they are used so much in practice, we could expect there to be an associated number of techniques that aim to cover them, particularly for security-related assistance. It is also possible that there are not enough datasets for these languages, and because of this, there are not many techniques for them because researchers are unable to have the necessary data to train and test the models. Nonetheless, this is a gap that should be addressed by future works. No techniques were language agnostic, meaning that all the systems created were made only for one or potentially a few languages. Making a tool language agnostic is di ffi cult due to the variety of programming paradigms that exist, and because all languages do not follow one particular paradigm. This does mean, however, that researchers should be diligent in developing techniques that support popular and commonly used languages.", "RQ4 Findings:": "-Cis the most common language that is targeted by ML-based cybersecurity techniques. -Despite their popularity, there are not many ML-based techniques for Python and Javascript. -A large portion of papers are aimed at solving security issues in Android applications. Thus, Java is also a popular language, with 36 techniques geared toward solving these issues in Java. -Given the increasing popularity of smart contracts, there are a number of techniques (12) that were created for Solidity-the language used to create smart contracts.", "9 RQ5: What Models Are Commonly Used with Di ff erent Representations?": "To sort the di ff erent types of models used throughout the papers, we took inspiration from Siow et al. [208] and classi fi ed them into fi ve categories: sequence-based models, feature-based models, treebased models, graph-based models, and neural networks . While there is overlap between our neural network categories and others, our classi fi cation is based on the type of inputs that the models accept. For example, a graph neural network may have a neural network architecture; however, it is designed to handle graph-based inputs. Table 4 demonstrates the models used by the surveyed papers and how they fall into each category. By far, a majority of these models are sequence based, particularly CNNs, Transformers, and LSTMs. This is most likely due to their general popularity, but also because these models are very powerful, are able to overcome the vanishing gradient problem, and are able to handle long-term dependencies [209]. However, Support Vector Machines (SVMs) overall were the most popular model. This might be because when determining if code has some sort of cybersecurity issue, such as a vulnerability, the most useful thing to learn or focus on are the features of the code. For example, if a model can API Calls Graph-based AST Sequence-based Feature-based Tree-Based Neural Networks Graph-based AST+ Sequence-based Application Information Tree-Based Feature-based CFG Sequence-based Feature-based Tree-Based Neural Networks Graph-based CPG Sequence-based Neural Networks Graph-based Call graph Tree-Based Graph-based Feature-based Neural Networks Code Aggregate Graph (CAG) Neural Networks Graph-based Code gadgets Sequence-based Tree-Based Neural Networks Feature-based Code metrics Sequence-based Tree-Based Neural Networks Feature-based Component Behavior Graph (CBG) Tree-Based Feature-based Component Dependency Graph (CDG) Tree-Based Feature-based Contextual API Dependency Graph (CADG) Sequence-based Feature-based Contextual Permission Dependency Graph (CPDG) Feature-based Contextual Source and Sink Dependency Graph (CSSDG) Feature-based Contract Graph Neural Networks Graph-based Contract Snippet Sequence-based Crucial Data Flow Graph (CDFG) Graph-based DFG Sequence-based Neural Networks Graph-based Feature-based ICFG Sequence-based Feature-based Image Sequence-based Opcode Sequences Tree-Based Feature-based PDG Sequence-based Feature-based Tree-Based Neural Networks Graph-based Parse Tree Feature-based Program Graph Graph-based Program slices Sequence-based Property Graph Graph-based Regular Expression Neural Networks SDG Sequence-based Tree-Based Feature-based Semantic Graph Graph-based Simplified CPG (SCPG) Neural Networks Graph-based Slice Property Graph (SPG) Graph-based Token Graph Graph-based Tokenizer Sequence-based Feature-based Tree-Based Neural Networks Graph-based Value Flow Graph (VFG) Program Slices Graph-based contextual ICFG (CICFG) Feature-based iSeVC Sequence-based sSyVC Sequence-based Neural Networks Neural Networks Tree-based Sequence-based Neural Networks Tree-based Neural Networks Graph-based Sequence-based Neural Networks Sequence-based Neural Networks Graph-based Neural Networks Sequence-based Graph-based Neural Networks Graph-based Sequence-based Graph-based Tree-based Neural Networks Sequence-based Neural Networks Sequence-based Graph-based Neural Networks Tree-based Sequence-based Graph-based Tree-based Tree-based Sequence-based Neural Networks Sequence-based Tree-based Tree-based Neural Networks Neural Networks Neural Networks Sequence-based Tree-based Neural Networks Sequence-based Sequence-based Sequence-based Neural Networks Graph-based Neural Networks Sequence-based Tree-based Sequence-based Tree-based Sequence-based Neural Networks Tree-based Tree-based Neural Networks Sequence-based Tree-based Neural Networks Sequence-based Tree-based Neural Networks Sequence-based Tree-based Graph-based Neural Networks Sequence-based Tree-based Neural Networks Sequence-based Tree-based Graph-based Neural Networks Neural Networks Propagation Chain Graph-based Neural Networks Sequence-based Tree-based learn what features make a piece of code vulnerable or not vulnerable, then the model will be able to successfully perform vulnerability detection. SVMs are powerful in learning the features that di ff erentiate classes, or in this case, code. Therefore, SVMs are useful for learning the features of code that would make it vulnerable or malicious versus benign. Figure 4 shows the types of models that were used for each type of representation. Additionally, the red boxes indicate model types that could potentially be used by these representations, although we did not observe it explicitly in our data. We consider a representation as potentially usable by a model if there are no further transformations needed to get the data into the form the model needs. In other words, this categorization is based on what representations are readily accepted by models. Many papers also used multiple di ff erent models to compare the performance of their method. Naturally, there is a constraint on the type of representation and the type of model used. For example, only graph representations can be used with a graph-based model.", "RQ5 Findings:": "-Sequence based is the most common and popular category of models. -SVMs overall are the most popular model used for di ff erent tasks due to their ability to discriminate features that would group code into one group or another. -The studied papers have a heavier focus on adjusting the models rather than investigating the representation of source code on the whole.", "10 Threats to Validity": "In this section, we will discuss the threats to validity of this survey around construct, internal, and external validity threats as outlined by Runeson and H\u00f6st [210]. Construct validity refers to how well the operational measures that are used represent the research questions that are being studied. In our study, these measures mainly involve counts of tasks and representations, as well as the relationship between the two, and the relationships between representations and models. Thus, our analysis relies on the accuracy of the reviewers while we were categorizing each of the papers. Additionally, when searching for the papers, we relied on the ability of the search engines we used to return to us all the papers that were related to our search query. To mitigate these issues, we had the reviewers separately analyze each paper, and later discuss and resolve any discrepancies in the analyses. We also created a thorough and broad enough query to ensure the results we received from our search encompassed all the papers related to this study. Internal validity describes how well a study mitigates bias and systematic error such that a causal conclusion can be drawn. Due to the potential threat of incorrectly categorizing a paper, we had two of the authors individually review the papers, and then meet to discuss any discrepancies between the categorizations. Disagreements were resolved through discussion. To assess the reliability of our evaluation, we used Cohen's kappa. Our calculated score is 0.97, meaning that we had a near perfect agreement in our analysis [211]. External validity assesses the generalizability of the study. The main threat to this work is that we only focus on the past 10 and a half years (2012-May 2023), so we may have missed papers outside of this range. We also did not include preprints and thus might have missed newer papers. Additionally, our keywords rely on ML, and any papers that do not include these keywords may have been missed. Finally, we only looked at three speci fi c sources: ACM, IEEE, and Springer Link. While there may have been papers outside of these three sources relevant to our work, they were outside of the scope of search for this work.", "11 Final Considerations": "In this section, we discuss our fi ndings, share recommendations for future works, and conclude the work.", "11.1 Discussion": "Aside from our fi ve RQs answered in this SLR, we also identi fi ed key fi ndings from our comprehensive analysis related to source code representation: -Graph complexity provides more information : Many papers found that using a graph representation allows to capture more information about the source code, resulting in better performance [37, 41, 44, 78, 81, 86, 89, 93, 98, 105, 106, 110, 113, 114, 135, 158, 161]. Thoroughly capturing the semantic and syntactic relationships and dependencies showed to be crucial for certain tasks, particularly vulnerability detection [41, 44, 78, 81, 86, 89, 93, 98, 105, 106, 110, 113, 114, 135, 158, 161]. Additionally, Sarbakysh and Wang [113] found that using a graph representation allows to reveal hidden connections within the source code, which was found to be useful in vulnerability detection and addressed limitations of traditional methods. -Capturing structure/syntactic information is important : Another common trend is that the structure and syntax of source code is an important aspect that impacts a model's ability to fully learn source code [19, 44, 78, 85, 86, 93, 98, 105, 106, 114, 136, 152, 158, 161, 164, 175]. One study found that in general, graph representations perform better, particularly for vulnerability detection, because the meaningful information relating to structure, syntax, and semantics is preserved through graph representation [98]. In general, one study found that vulnerabilities are related to code structure and patterns [175]. Additionally, other studies found that including some sort of information regarding the structure of the code on top of a representation which does not consider the structure helped improve the overall performance [85, 86]. -Extracted features impact performance : While seemingly self explanatory, the features one extracts about the source code will impact the performance of the model because it determines what the model is able to learn. In the case of vulnerability detection, the extracted features may not be associated with some vulnerabilities, thus rendering those features, for lack of a better term, useless to the model [15, 105, 132, 154, 164, 175]. Similarly, certain representations o ff er more information about the source code than others (i.e., a CPG versus an AST), which enhances the expressiveness of semantics, resulting in more informative extracted features, thus leading the model to perform better [31, 37, 41, 45, 110, 119, 158]. -Considering code as text does not capture behaviors well : Many studies agree that treating code as plain text does not provide enough information for a model to learn about the code [43, 44, 81, 89, 105, 119, 132, 135, 136, 158, 164]. Code has more semantic structures that di ff er from natural language [89], and representing code as plain text causes a loss in this semantic information, such as execution logic and relationships between the code, which is crucial for tasks such as vulnerability detection [44, 81, 105, 132]. One paper found that using BPE subword-level tokenization is more useful than word-level tokenizing [119], as a result of the tendency for code to contain uncommon keywords rather than natural language. Using word-level tokenization, as is done in NLP, results in vector representations that are not particularly meaningful, resulting in poor performance [43, 119]. -Capturing context improves performance : Including contextual information helps models better distinguish code features, leading to improved performance [19, 26, 100, 172]. In particular, this contextual information can decrease the number of false positives. In the example of vulnerability detection, added context can assist in precisely distinguishing malicious neighborhoods from benign ones [19]. -In certain instances, tokenizers can be useful : While a majority of papers state that tokenizers are not optimal for cybersecurity-related software engineering tasks, two papers point out that there are instances in which tokenizers might be a bene fi cial representation [15, 122]. Tokenization proves to be useful in making certain syntactic and semantic information easily available to simple neural architectures, which use it for fi ne tuning on a downstream task [122]. Additionally, one paper found that improving the dictionary by increasing its size and complexity when tokenizing also improved the performance of the method [15]. As previously mentioned, BPE subword-level tokenization is shown to improve performance [43, 119], thus suggesting that while a standard tokenizer (e.g., one used in an NLP model) may not be the most useful representations, there is room to improve tokenization methods such that more pertinent information is passed to the model.", "11.2 Recommendations": "From the 141 papers we have studied, we noticed that rather than attempting to fi nd a new or more comprehensive way to represent source code, prior works are focused on trying di ff erent or new models with more advanced architectures so that the model can learn more from the representation, without changing it. Given the improvements in power and capability of ML models in recent years, it is understandable why researchers would take this approach. However, it is important to remember that the way a model learns is impacted greatly by the feature representations, as it can allow the model to learn and isolate critical information that is important for it to successfully complete its task. Based on the results presented in Sections 5 through 9, we recommend that future works explore di ff erent representations for a particular task rather than just fi ne-tuning the model. Since the model learns features of the source code from the representation, there would be a greater improvement in performance if more attention is paid to the representations. It is also important for researchers to pay attention to the popularity of languages, as there should be an e ff ort to create techniques and tools that address popular and more frequently used languages to ensure that we can avoid as many security risks as possible. When choosing a representation for a particular task, one might consider the capabilities of di ff erent representations. Table 5 highlights these abilities based on key features. 'Lightweight'refers Structure Semantics Data Flow Statement Flow Lightweight Interprocedural CPG, PDG, Program Slices, SDG, SPG, CAG \u2713 \u2713 \u2713 \u2713 \u2717 \u2713 VFG, Contract/Semantic Graph Program Graph, Propagation Chain \u2713 \u2713 \u2713 \u2713 \u2717 \u2717 CADG, Property Graph, CPDG \u2713 \u2717 \u2713 \u2713 \u2717 \u2713 CICFG, Call Graph \u2713 \u2717 \u2717 \u2713 \u2717 \u2713 SCPG, CSSDG \u2713 \u2717 \u2713 \u2713 \u2717 \u2717 AST, Parse Tree, Image \u2713 \u2717 \u2717 \u2717 \u2713 \u2717 Tokenizer, Opcode Sequences \u2717 \u2713 \u2717 \u2717 \u2713 \u2717 iSeVC, Code Gadgets \u2713 \u2713 \u2713 \u2713 \u2713 \u2717 Contract Snippet \u2717 \u2713 \u2717 \u2713 \u2713 \u2717 App. Information, API Calls, Code Metrics \u2717 \u2717 \u2717 \u2717 \u2713 \u2717 CFG \u2713 \u2717 \u2717 \u2713 \u2717 \u2717 DFG \u2713 \u2713 \u2713 \u2717 \u2717 \u2717 ICFG \u2713 \u2717 \u2717 \u2713 \u2717 \u2713 CDG \u2713 \u2713 \u2717 \u2717 \u2717 \u2717 CBG \u2713 \u2713 \u2717 \u2713 \u2717 \u2717 CDFG \u2713 \u2717 \u2713 \u2717 \u2717 \u2717 Token Graph \u2717 \u2713 \u2717 \u2717 \u2717 \u2717 sSyVC \u2713 \u2713 \u2717 \u2717 \u2713 \u2717 Regular Expression \u2713 \u2717 \u2717 \u2713 \u2713 \u2717 Representations that have the same abilities are grouped together. BPE is BPE subword tokenization, Op. Seq. is opcode sequences, and App. Information is application information. to how complex the representation is to create. For example, as discussed earlier, ASTs are simple to generate. Because their computational complexity is relatively low, they can be considered lightweight. Program slices, however, have a lot of overhead and thus are not considered lightweight. Additionally, one may also want to consider the performance of these representations for particular tasks compared to one another. Figure 5 shows the comparison of the average precision, recall, and F1 scores for certain tasks, as reported by the studied papers. For space considerations, we only demonstrate in this paper the precision, F1, and recall scores, and only for tasks which had multiple representations. The rest of the metrics data in full is available on our GitHub repository for the project. We can see from Figure 5 that for vulnerability detection, the CPG has the best recall (99.0%), program slices has the best precision (94.8%), and the program graph has the best F1 score (94.5%). Interestingly, all of these representations are graph based, demonstrating the importance of structural information when detecting vulnerabilities. As a CPG is an incredibly robust graph, giving insights to many aspects of a program, it follows that this representation would perform incredibly well. One thing to consider is that because it is such a robust representation, it is complex to generate, which may not be ideal for someone who does not have the resources needed to generate such a graph. Broadly speaking, graph representations show strong results across a variety of tasks, thus speaking to their ability to convey the crucial information relating to the source code. However, in vulnerability prediction and analysis, a tokenized representation did have the best performance compared to other methods (80.1% recall and 96.8% recall, respectively). Code metrics also showed strong results for security patch detection/identi fi cation (91.4% F1 score), as well as vulnerability fi xing/inducing commits detection (92.0% precision) and vulnerability analysis (96.8% recall). Code metrics are a very lightweight representation, and its performance suggests that the features it presents (e.g., lines of code or code churn) provide enough information about the source code to perform well in tasks relating to security-related code changes and vulnerability analysis. Siow et al. [208] found similar results to us in their empirical study on code representations for code intelligence tasks such as code classi fi cation. The paper found that graph-based representations are the best at representing program semantics, thus resulting in the best performance compared to 24.7 56.5 11.2 11.2 0 20 40 60 80 100 AST Tokenizer Vulnerability Repair 81.9 80.7 86.3 92.4 85.2 67.3 74.8 79.5 89.2 84.8 69.5 92 82.3 84 72.1 79 67.3 75.5 94.8 21.3 84.8 84.8 93.5 68.3 89.9 99.0 76.2 72.8 78.8 80.5 89.1 82.9 65.8 94.5 85 83.1 79.2 59.5 70.7 82.9 49.5 58.2 74.2 88 87.1 82.5 57 76.7 75.9 89.2 67.8 80.4 94 83.6 79.9 64.2 63.5 78.8 77.7 72.1 29.4 80.9 78.5 0 20 40 60 80 100 AST+ AST CAG CPG Code gadgets Code metrics Contract Graph CFG CDFG DFG PDG Program Graph Semantic Graph SCPG SPG Token Graph Tokenizer VFG Program slices codeBERT iSeVC sSyVC Vulnerability Detection 52.3 73.4 65.8 83.6 44.8 57.3 71.8 80.1 46.5 56.6 85.9 0 20 40 60 80 100 AST Code metrics SDG Tokenizer Vulnerability Prediction 92 77 14.0 66.5 69.4 0 20 40 60 80 100 Code metrics Tokenizer Vulnerable Commits Detection 92.1 97.6 93.4 83.3 73.8 73.8 73.8 83.3 94.2 86.8 94.9 90.8 87.3 87.3 87.3 90.8 93 91.2 89.4 90.3 84.7 84.7 84.7 90.3 91.7 0 20 40 60 80 100 API Calls App. Info. Call graph CADG CICFG CPDG CSSDG ICFG Tokenizer Malware Detection 84.5 73.3 100 77.3 80.3 0 20 40 60 80 100 Opcode Sequences Parse Tree Tokenizer Vulnerability Testing 83.7 83.6 90 92 91.5 90 92 91.5 0 20 40 60 80 100 Contract Snippet Propagation Chain Tokenizer Reentrancy Detection 96.8 96.8 88.7 88.7 88.7 88.7 75.6 0 20 40 60 80 100 AST CPG Code metrics CFG PDG Property Graph Tokenizer Vulnerability Analysis 24.7 56.5 11.2 11.2 0 20 40 60 80 100 AST Tokenizer Vulnerability Repair 73.8 73.3 84.5 85.6 91.4 77.9 0 20 40 60 80 100 Code metrics Tokenizer Security Patch Detection 74.7 82.3 88.6 57.5 80.6 61.2 0 20 40 60 80 100 AST Tokenizer Vulnerability Classification Precision Recall F1 Score tree-based, feature-based, and sequence-based representations. Additionally, the paper found that di ff erent tasks require task-speci fi c semantics to achieve the best performance, but on the whole, a composite graph that represents program semantics comprehensively will produce strong results.", "11.3 Conclusion": "In this article, we studied 141 papers to examine the state of the art of source code representations in MLmodels used for cybersecurity-related tasks. We found that ASTs and a tokenized representation are the most common way to represent source code. We also found that vulnerability detection, malware detection, and vulnerability prediction are the most covered tasks by existing techniques. Additionally, we observed that C was the language covered by the most techniques, followed by C++.", "References": "[1] J. C. S. Santos, K. Tarrit, and M. Mirakhorli. 2017. A catalog of security architecture weaknesses. In Proceedings of the 2017 IEEE International Conference on Software Architecture Workshops (ICSAW'17) . [2] I. Alexander. 2003. Misuse cases: Use cases with hostile intent. IEEE Software 20, 1 (2003), 58-66. DOI: http://doi.org/ 10.1109/MS.2003.1159030 [3] J. McDermott and C. Fox. 1999. Using abuse case models for security requirements analysis. In Proceedings of the 15th Annual Computer Security Applications Conference (ACSAC'99) . DOI: http://doi.org/10.1109/CSAC.1999.816013 [4] A. Shostack. 2014. Threat Modeling Designing for Security . Wiley. [5] S. T. Halkidis, N. Tsantalis, A. Chatzigeorgiou, and G. Stephanides. 2008. Architectural risk analysis of software systems based on security patterns. IEEE Transactions on Dependable and Secure Computing 5, 3 (2008), 129-142. DOI: http://doi.org/10.1109/TDSC.2007.70240 [6] J. Ryoo, P. Laplante, and R. Kazman. 2010. A methodology for mining security tactics from security patterns. In Proceedings of the 2010 43rd Hawaii International Conference on System Sciences . DOI: http://doi.org/10.1109/HICSS. 2010.18 [7] L. Braz, E. Fregnan, G. \u00c7alikli, and A. Bacchelli. 2021. Why don't developers detect improper input validation?'; DROP TABLE papers;-. In Proceedings of the 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE'21) . ACM Comput. Surv., Vol. 57, No. 8, Article 217. Publication date: April 2025.", "A Survey of Source Code Representations": "[175] P. Momeni, Y. Wang, and R. Samavi. 2019. Machine learning model for smart contracts security analysis. In Proceedings of the 2019 17th International Conference on Privacy, Security, and Trust (PST'19) . DOI: http://doi.org/10.1109/PST47121. 2019.8949045 [176] X. Yan, S. Wang, and K. Gai. 2022. A semantic analysis-based method for smart contract vulnerability. In Proceedings of the 2022 IEEE 8th International Conference on Big Data Security on Cloud (BigDataSecurity'22), the IEEE International Conference on High Performance and Smart Computing (HPSC'22), and the IEEE International Conference on Intelligent Data and Security (IDS'22) . DOI: http://doi.org/10.1109/BigDataSecurityHPSCIDS54978.2022.00015 [177] H. Shi, R. Wang, Y. Fu, Y. Jiang, J. Dong, K. Tang, and J. Sun. 2019. Vulnerable code clone detection for operating system through correlation-induced learning. IEEE Transactions on Industrial Informatics 15, 12 (2019), 6551-6559. DOI: http://doi.org/10.1109/TII.2019.2929739 [178] W. Zheng, A. O. Abdallah Semasaba, X. Wu, S. A. Agyemang, T. Liu, and Y. Ge. 2021. Representation vs. model: What matters most for source code vulnerability detection. In Proceedings of the 2021 IEEE International Conference on Software Analysis, Evolution, and Reengineering (SANER'21) . DOI: http://doi.org/10.1109/SANER50967.2021.00082 [179] M. Ceccato, C. D. Nguyen, D. Appelt, and L. C. Briand. 2016. SOFIA: An automated security oracle for black-box testing of SQL-injection vulnerabilities. In Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering (ASE'16) . DOI: http://doi.org/10.1145/2970276.2970343 [180] X. Liu, X. Du, Q. Lei, and K. Liu. 2020. Multifamily classi fi cation of Android malware with a fuzzy strategy to resist polymorphic familial variants. IEEE Access 8 (2020), 156900-156914. DOI: http://doi.org/10.1109/ACCESS.2020.3019282 [181] E. Spirin, E. Bogomolov, V. Kovalenko, and T. Bryksin. 2021. PSIMiner: A tool for mining rich abstract syntax trees from code. In Proceedings of the 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR'21) . DOI: http://doi.org/10.1109/MSR52588.2021.00014 [182] U. Alon, M. Zilberstein, O. Levy, and E. Yahav. 2018. code2vec: Learning distributed representations of code. arXiv:cs.LG/1803.09473. [183] G. Buehrer, B. W. Weide, and P. A. G. Sivilotti. 2005. Using parse tree validation to prevent SQL injection attacks. In Proceedings of the 5th International Workshop on Software Engineering and Middleware (SEM'05) . DOI: http://doi.org/10. 1145/1108473.1108496 [184] G. Lin, J. Zhang, W. Luo, L. Pan, and Y. Xiang. 2017. POSTER: Vulnerability discovery with function representation learning from unlabeled projects. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security (CCS'17) . DOI: http://doi.org/10.1145/3133956.3138840 [185] D. G. Fritz and R. G. Sargent. 1995. An overview of hierarchical control fl ow graph models. In Proceedings of the 27th Conference on Winter Simulation (WSC'95) . DOI: http://doi.org/10.1145/224401.224819 [186] S. Sinha. 2002. Static and Dynamic Analysis of Programs That Contain Arbitrary Interprocedural Control Flow . Ph.D. Dissertation. Georgia Institute of Technology. http://proxy.library.nd.edu/login?url=https://www.proquest.com/ dissertations-theses/static-dynamic-analysis-progams-that-contain/docview/305602235/se-2 [187] J. Ferrante, K. J. Ottenstein, and J. D. Warren. 1987. The program dependence graph and its use in optimization. ACM Transactions on Programming Languages and Systems 9, 3 (1987), 319-349. DOI: http://doi.org/10.1145/24039.24041 [188] D. Grove and C. Chambers. 2001. A framework for call graph construction algorithms. ACM Transactions on Programming Languages and Systems 23, 6 (2001), 685-746. DOI: http://doi.org/10.1145/506315.506316 [189] M. Weiser. 1984. Program slicing. IEEE Transactions on Software Engineering 4 (1984), 352-357. [190] Y. Sui, X. Cheng, G. Zhang, and H. Wang. 2020. Flow2Vec: Valuefl ow-based precise code embedding. Proceedings of the ACM on Programming Languages 4, OOPSLA (2020), Article 233, 27 pages. DOI: http://doi.org/10.1145/3428301 [191] B. Ste ff en, J. Knoop, and O. R\u00fcthing. 1990. The value fl ow graph: A program representation for optimal program transformations. In ESOP'90 . Lecture Notes in Computer Science, Vol. 432. Springer, 389-405. https://link.springer. com/content/pdf/10.1007/3-540-52592-0_76.pdf [192] M. Zhang, Y. Duan, H. Yin, and Z. Zhao. 2014. Semantics-aware Android malware classi fi cation using weighted contextual API dependency graphs. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security. DOI: http://doi.org/10.1145/2660267.2660359 [193] Y. Zhang, X. Yu, Z. Cui, S. Wu, Z. Wen, and L. Wang. 2020. Every document owns its structure: Inductive text classi fi cation via graph neural networks. arXiv:cs.CL/2004.13826. [194] T. Xu and P. Zhou. 2022. Feature extraction for payload classi fi cation: A byte pair encoding algorithm. In Proceedings of the 2022 IEEE 8th International Conference on Computer and Communications (ICCC'22) . DOI: http://doi.org/10.1109/ ICCC56324.2022.10065977 [195] T. Kudo and J. Richardson. 2018. SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing. arXiv:cs.CL/1808.06226. https://arxiv.org/abs/1808.06226 [196] X. Song, A. Salcianu, Y. Song, D. Dopson, and D. Zhou. 2021. Fast WordPiece tokenization. arXiv:cs.CL/2012.15524. https://arxiv.org/abs/2012.15524 [197] Q. V. Le and T. Mikolov. 2014. Distributed representations of sentences and documents. arXiv:cs.CL/1405.4053. [198] Meiliana, S. Karim, H. L. H. S. Warnars, F. L. Gaol, E. Abdurachman, and B. Soewito. 2017. Software metrics for fault prediction using machine learning approaches: A literature review with PROMISE repository dataset. In Proceedings of the 2017 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom'17) . DOI: http://doi.org/10.1109/CYBERNETICSCOM.2017.8311708 [199] I. Santos, F. Brezo, X. Ugarte-Pedrero, and P. G. Bringas. 2013. Opcode sequences as representation of executables for data-mining-based unknown malware detection. Information Sciences 231 (2013), 64-82. DOI: http://doi.org/10.1016/j. ins.2011.08.020 [200] B. Min, H. Ross, E. Sulem, A. P. B. Veyseh, T. H. Nguyen, O. Sainz, E. Agirre, I. Heinz, and D. Roth. 2021. Recent advances in natural language processing via large pre-trained language models: A survey. arXiv:cs.CL/2111.01243. https://arxiv.org/abs/2111.01243 [201] P. Kruchten. 2009. The Rational Uni fi ed Process: An Introduction . Addison-Wesley. [202] Y. Gui, Y. Wan, H. Zhang, H. Huang, Y. Sui, G. Xu, Z. Shao, and H. Jin. 2022. Cross-language binary-source code matching with intermediate representations. arXiv:cs.SE/2201.07420. https://arxiv.org/abs/2201.07420 [203] Z. Chen, S. Kommrusch, and M. Monperrus. 2023. Neural transfer learning for repairing security vulnerabilities in C code. IEEE Transactions on Software Engineering 49, 1 (2023), 147-165. DOI: http://doi.org/10.1109/tse.2022.3147265 [204] Y. Chen, Z. Ding, L. Alowain, X. Chen, and D. Wagner. 2023. DiverseVul: A new vulnerable source code dataset for deep learning based vulnerability detection. arXiv:cs.CR/2304.00409. [205] R. L. Russell, L. Kim, L. H. Hamilton, T. Lazovich, J. A. Harer, O. Ozdemir, P. M. Ellingwood, and M. W. McConley. 2018. Automated vulnerability detection in source code using deep representation learning. arXiv:cs.LG/1807.04320. [206] T. Boland and P. E. Black. 2012. Juliet 1.1 C/C++ and Java test suite. Computer 45, 10 (2012), 88-90. DOI: http: //doi.org/10.1109/MC.2012.345 [207] L. Szekeres, M. Payer, T. Wei, and D. Song. 2013. SoK: Eternal war in memory. In Proceedings of the 2013 IEEE Symposium on Security and Privacy . DOI: http://doi.org/10.1109/SP.2013.13 [208] J. K. Siow, S. Liu, X. Xie, G. Meng, and Y. Liu. 2022. Learning program semantics with code representations: An empirical study. In Proceedings of the 2022 IEEE International Conference on Software Analysis, Evolution, and Reengineering (SANER'22) . DOI: http://doi.org/10.1109/SANER53432.2022.00073 [209] Y. Hu, A. Huber, J. Anumula, and S. Liu. 2019. Overcoming the vanishing gradient problem in plain recurrent networks. arXiv:cs.NE/1801.06105. [210] P. Runeson and M. H\u00f6st. 2009. Guidelines for conducting and reporting case study research in software engineering. Empirical Software Engineering 14 (2009), 131-164. DOI: http://doi.org/10.1007/s10664-008-9102-8 [211] J. Cohen. 1960. A coe ffi cient of agreement for nominal scales. Educational and Psychological Measurement 20, 1 (1960), 37-46. DOI: http://doi.org/10.1177/001316446002000104", "Appendix": "", "A Examples of Commonly Used Source Code Representations": "", "A.1 Examples of Tree-Based Source Code Representations": "Figure 6 demonstrates how ASTs and parse trees di ff er for the same Python code. Notice how the parse tree retained every symbol in the code (e.g., new lines and indentation) while the AST abstracted those away. Since parse trees are more verbose than ASTs, the work [179] that used it had a preprocessing step that removed from the tree nodes that were irrelevant to detect attacks (e.g., speci fi c user ids). def func (x, y): i = x + y j = x - y if (i == j): return i arguments y x = x y + i = x y - j == i j if return i Abstract Syntax Tree (AST) func Parse Tree ( \\t \\n ) , x y : NAME NAME def func \u007fle_input ... remaining nodes hidden due to space constraints COLON parameters LPAR typedargslist tfpdef NAME COMMA tfpdef NAME RPAR suite NEWLINE INDENT stmt stmt compound_stmt funcdef ENDMARKER Source Code", "A.2 Examples of Graph-Based Representations": "Figure 7 shows the CFG for the function func ( x , y ) . It has an entry and an exit basic block, to denote the start and end of the function execution, respectively. The entry block is connected to a basic block that has three instructions (i.e., i = x + y , j = x -y , and if i == j ). This basic block has two outgoing edges: one represents the fl ow when the if condition evaluates to true , and the other denotes the fl ow when it evaluates to false . After executing one of the branches, the execution fl ows into the exit block. Additionally, Figure 7 shows the ICFG for the entire program, including func ( x , y ) and main () . It has two entry blocks: one for main , where the program starts, and another for func . It also has two exit blocks which indicate the end of function execution for both main and func . The entry block for main is connected to the basic block that calls func , which, in turn, is connected to the callee's entry block. To capture the fl ow from the invoked function (i.e., func ( x , y ) ) back to its caller (i.e., main () ), this representation includes an edge from the callee's exit block to the caller's return call site block. In the same fi gure, it also shows the DFG for a Python function. There are two outgoing edges i = x + y to two statements that use the variable i . Similarly, there is an edge from j = x -y to if i == j because the expression is using the variable j . Figure 7 has an example of a PDG for a Python function ( func ( x , y ) ), where the dashed and straight lines represent control dependencies and data dependencies, respectively. The PDG starts with an entry node for this procedure. It has two param in nodes to represent the function's parameters ( x and y ). For the statements in lines 2 through 4 to execute, the function's entry must have executed. As such, there is a control dependency edge from the entry to the nodes representing these lines of code: i = x + y , j = x -y , and if i == j . Since the statements in lines 2 and 3 de fi ne variables that are used in the if condition, there is a data dependency edge from these variable assignments statements to the if condition. There is also a data dependency edge from the i = x + y to the return statement, since this return node uses the variable i . Given that the return statement only executes when the if condition evaluates to true, there is a control dependency between the if node and the return node. Finally, Figure 7 shows the call graph for the Python code snippet provided in it. In Figure 8, the SDG for the entire program is shown. The SDG starts with the entry node for main () , which is the entrypoint function in the call graph. The fi rst entry node from main has a control fl ow edge to func . Two actual in nodes have data fl ow edges, as the data is initialized from main and fl ows to func . There are also two actual in nodes, which de fi ne the parameters entering the procedure func ( x , y ) . The entry node in func has a control fl ow edge to the statement nodes which de fi ne the variables i and j , and the two param in nodes have a data fl ow edge to those same Call Graph func main def func (x, y): i = x + y j = x - y if (i == j): return i def main (): func( 2 , 3 ) main() Source Code PDG for func(x,y) ENTRY: func(x,y) i = x + y j = x - y if i == j: PARAM IN: x PARAM IN: y return i control dependency data dependency DFG for func(x,y) return i j = x - y i = x + y if (i == j) return i EXIT ENTRY i = x + y j = x - y if i == j: false true ENTRY EXIT call: func(2,3) return: func(2,3) CFG for func(x,y) ICFG return i EXIT ENTRY i = x + y j = x - y if i == j: false true func(x,y) main() 1. 2. 3. 4. 5. 6. 7. 8. 9. def func (x, y): i = x + y j = x - y if (i == j): return i def main (): z=func( 2 , 3 ) main() Source Code 1. 2. 3. 4. 5. 6. 7. 8. 9. (Backward) Program Slice ENTRY: main() ENTRY: func(x,y) j = x - y z=func(2,3) FORMAL IN: x FORMAL IN: y ACTUAL IN: 3 ACTUAL IN: 2 ACTUAL OUT: z CDFG for func(x,y) _am _am msg function CashOut (unit _am) public payable { if (_am<=balances[msg.sender]){ if msg.sender. call.value(_am)()){ balances[msg.sender]-=_am; TransferLog.AddMessage( msg.sender,_am,...); ... msg msg sender msg sender _am _am _am balances 5 12 46 54 38 40 42 32 52 50 17 24 ENTRY: func(x,y) i = x + y j = x - y if i == j: return i control dependency data dependency z=func(2,3) FORMAL IN: x FORMAL IN: y ACTUAL IN: 3 ACTUAL IN: 2 SDG ENTRY: main() PDG for main() PDG for func(x,y) FORMAL OUT: i ACTUAL OUT: z def func (x, y): i = x + y j = x - y if (i == j): return i def main (): func( 2 , 3 ) main() Source Code 1. 2. 3. 4. 5. 6. 7. 8. 9. a x b def multiply (x, y): z = x * y return z def foo (): a = 5 b = 10 c = multiply(a,b) two nodes; i = x + y and j = x -y . These statement nodes then both have a data fl ow to the predicate node if i == j . The entry node has a control dependency edge to this node and the formal in nodes. Finally, this predicate node has a control fl ow edge to the return i block, along with i = x + y node, except this node has a data dependency edge. The dashed line in this fi gure depicts control dependencies, and the solid line depicts data dependencies. Figure 8 also shows an example of a backward program slice over the SDG with the slice criterion \u3008 /u1D457 , /u1D459 /u1D456 /u1D45B/u1D452 3 \u3009 . The nodes that have control or data dependencies to the node of interest (i.e., j = x -y ) are part of the resulting program slice. In Figure 8, we also see our crucial nodes for a CDFG: any nodes that have to deal with msg , sender , balances , and _am . These nodes receive or compute data, and can be responsible for a reentrancy vulnerability. Figure 9 demonstrates the CPG for func() . We have the entry node at the start, demonstrating the entrance into the function. From the entry node, we have a control fl ow edge to the declaration node, which then branches to show the AST nodes and edges for the line i = x + y . We then have another control fl ow edge from the declaration node to another declaration node. This node branches down to show the AST nodes and edges for the line j = x -y . From this node, we have a control fl ow edge to a predicate node . We also have PDG edges from the fi rst and second declaration node to this predicate node, as the predicate node depends on the data from the two declaration nodes. The predicate node also has AST nodes and edges to show the line i == j . From here, we have a control fl ow edge to a return statement. We also have a PDG edge to this node from the predicate node, as the return statement depends on the result from the predicate edge. We fi nally have a control fl ow edge to the exit node from the return. The exit node also has a control fl ow edge from the predicate node because if the predicate evaluates to false, the program terminates. The same fi gure also demonstrates an example of a CAG for the function func() . We start with the entry node, which has a dominator tree edge to the DECL node. The DECL node then has AST nodes and edges representing the line i = x + y . From the DECL node, we have a dominator tree and post-dominator tree edge to another DECL node. Once again, the DECL node has AST nodes and edges representing the line j = x -y . Next, we have a dominator tree and post-dominator tree edge to the PRED node from the DECL node. Moreover, we have a data dependence edge from the DECL node de fi ning i and the DECL node de fi ning j nodes, as the if statement needs the data from both of these nodes to execute. The PRED node has a dominator tree and post-dominator tree edge to the RETURN node. The RETURN node has a data dependence edge from the DECL node that de fi nes i , since the return statement depends on that node's data. Finally, we have a dominator tree edge to the EXIT node. Figure 9 shows the VFG for the code snippet provided. We start with the nodes a and b . These two nodes have an edge into the multiply(x,y) node, as the values from a and b are passed into this function. We then have an edge to node z , which represents the multiplication operation on a and b . Finally, z has an edge connecting it to c , which stores the value from the multiplication operation. Figure 10 shows an example of the CDG which starts at the component node. We then have three edges: one for startActivity() which leads to a web page node, one for triggerTasks() which leads to the background tasks node, and fi nally a sendMessage() edge which leads to a message handler node. Below the CDG, there is an example of the CBG, as a continuation of the larger Web Application Behavior Graph. The web page node from the CDG leads to two di ff erent nodes in fallback edge core node normal node function withdraw (uint amount) public { if (Balance[msg.sender] < amount) { throw; } require(msg.sender.call .value(amount)()); Balance[msg.sender] -= amount; } data flow edge control flow edge def updateUserProfile(userID, profileData): if (checkUserPermission(userID)): if (validateProfileData(profileData)): updateProfileInDB(userID, profileData); the CBG: onLoad() and onRender() . Both of these nodes lead to API nodes, which can represent any of the aforementioned node types. This pattern continues: the background tasks node from the CDG leads to the beginTask() node and complexTask() node, which then lead to API nodes representing the further activities of the APIs in the program. Finally, the message handler node from the CDG leads to onMessageReceive() node in the CBG, which leads to other API nodes that represent their functionality within the program. Figure 10 also gives an example of the CADG for the code snippet shown. We start with the function updateUserProfile , and have a control fl ow edge to the security related node checkUserPermission with the context user aware . From here, we fl ow to another security related node, validateProfileData with the same context: user aware . Finally, we fl ow to updateProfileDB with the same user aware context. The same fi gure also shows a Contract/Semantic graph for the provided code snippet. The withdraw and balance are core nodes, and the call.value variable is a core node because they could be the cause for a vulnerability. The amount variable is a normal node, because it does not directly contribute to a security issue. The withdraw invocation has control fl ow edges to the balance invocation and the amount variable. The balance node as a data fl ow edge to itself since it is accessing data from itself, and receives or depends on data from the variable amount . The call.value also receives data from amount , and thus there is a data fl ow edge from amount to call.value . There are control fl ow edges from withdraw to balance and amount because it invokes these two nodes. After amount is called, then call.value is invoked, thus resulting in a control fl ow edge from amount to call.value . Finally, there is fallback edge from call.value to the fallback node, and from the fallback node back to withdraw .", "A.3 Lexical Representations": "Figure 11 provides an example of the resulting tokens from di ff erent tokenization techniques, including a standard tokenizer, BPE subword tokenization, SentencePiece, and WordPiece. def func (x, y): i = x + y j = x - y if (i == j): return i Source Code BPE Subword Tokenizer ['de',\u00a0'f',\u00a0'fu',\u00a0'n',\u00a0'c',\u00a0'(',\u00a0'x',\u00a0',',\u00a0'y',\u00a0')',\u00a0':',\u00a0'i',\u00a0'=',\u00a0'x',\u00a0'+',\u00a0'y',\u00a0'j',\u00a0'',\u00a0'i',\u00a0'f',\u00a0'(',\u00a0'i',\u00a0'=',\u00a0'=',\u00a0'j',\u00a0')',\u00a0':',\u00a0're',\u00a0'tu',\u00a0'r',\u00a0'n',\u00a0'i'] Tokenizer ['def',\u00a0'func',\u00a0'(',\u00a0'x',\u00a0'y',\u00a0')',\u00a0':',\u00a0'i',\u00a0'=',\u00a0'x',\u00a0'+',\u00a0'y',\u00a0'j',\u00a0'=',\u00a0'x',\u00a0'-',\u00a0'y',\u00a0'if',\u00a0'(',\u00a0'i',\u00a0'=',\u00a0'=',\u00a0'j',\u00a0')',\u00a0'return',\u00a0'i'] SetencePiece [' \u2581 def',\u00a0' \u2581 func',\u00a0'(',\u00a0'x',\u00a0',',\u00a0' \u2581 y',\u00a0')',\u00a0':',\u00a0' \u2581 ',\u00a0'i',\u00a0' \u2581 =',\u00a0' \u2581 x',\u00a0' \u2581 +',\u00a0' \u2581 y'\u00a0\u00a0\u00a0' \u2581 ',\u00a0'j',\u00a0' \u2581 =',\u00a0' \u2581 x',\u00a0' \u2581 -',\u00a0' \u2581 y',\u00a0' \u2581 if',\u00a0' \u2581 (',\u00a0'i',\u00a0' \u2581 ==',\u00a0' \u2581 j',\u00a0')',\u00a0':',\u00a0' \u2581 return',\u00a0' \u2581 i'] WordPiece ['def',\u00a0'fu',\u00a0'##nc',\u00a0'(',\u00a0'x',\u00a0',',\u00a0'y',\u00a0')',\u00a0':',\u00a0'i',\u00a0'=',\u00a0'x',\u00a0'+',\u00a0'y',\u00a0'j',\u00a0'=',\u00a0'x',\u00a0'-',\u00a0'y',\u00a0'if',\u00a0'(',\u00a0'i',\u00a0'==',\u00a0'j',\u00a0')',\u00a0':',\u00a0're',\u00a0'##turn',\u00a0'i'] Received 15 March 2024; revised 12 February 2025; accepted 24 February 2025"}
