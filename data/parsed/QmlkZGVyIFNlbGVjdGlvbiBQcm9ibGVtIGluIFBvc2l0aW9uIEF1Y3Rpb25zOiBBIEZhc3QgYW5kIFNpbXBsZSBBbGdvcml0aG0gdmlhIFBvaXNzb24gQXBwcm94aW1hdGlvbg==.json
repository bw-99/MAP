{"Bidder Selection Problem in Position Auctions: A Fast and Simple Algorithm via Poisson Approximation": "Nikolai Gravin \u2217 nikolai@mail.shufe.edu.cn Shanghai University of Finance and Economics Shanghai, China Yixuan Even Xu \u2217 xuyx20@mails.tsinghua.edu.cn Tsinghua University Beijing, China Renfei Zhou \u2217 zhourf20@mails.tsinghua.edu.cn Tsinghua University Beijing, China", "ABSTRACT": "In the Bidder Selection Problem (BSP) there is a large pool of \ud835\udc5b potential advertisers competing for ad slots on the user's web page. Due to strict computational restrictions, the advertising platform can run a proper auction only for a fraction \ud835\udc58 < \ud835\udc5b of advertisers. We consider the basic optimization problem underlying BSP: given \ud835\udc5b independent prior distributions, how to efficiently find a subset of \ud835\udc58 with the objective of either maximizing expected social welfare or revenue of the platform. We study BSP in the classic multi-winner model of position auctions for welfare and revenue objectives using the optimal (respectively, VCG mechanism, or Myerson's auction) format for the selected set of bidders. This is a natural generalization of the fundamental problem of selecting \ud835\udc58 out of \ud835\udc5b random variables in a way that the expected highest value is maximized. Previous PTAS results ([Chen, Hu, Li, Li, Liu, Lu, NIPS 2016], [Mehta, Nadav, Psomas, Rubinstein, NIPS 2020], [Segev and Singla, EC 2021]) for BSP optimization were only known for single-item auctions and in case of [Segev and Singla 2021] for \ud835\udc59 -unit auctions. More importantly, all of these PTASes were computational complexity results with impractically large running times, which defeats the purpose of using these algorithms under severe computational constraints. We propose a novel Poisson relaxation of BSP for position auctions that immediately implies that 1) BSP is polynomial-time solvable up to a vanishingly small error as the problem size \ud835\udc58 grows; 2) there is a PTAS for position auctions after combining our relaxation with the trivial brute force algorithm. Unlike all previous PTASes, we implemented our algorithm and did extensive numerical experiments on practically relevant input sizes. First, our experiments corroborate the previous experimental findings of Mehta et al. that a few simple heuristics used in practice (e.g., Greedy for general submodular maximization) perform surprisingly well in Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. https://doi.org/10.1145/3589334.3645418 terms of approximation factor. Furthermore, our algorithm outperforms Greedy both in running time and approximation on medium and large-sized instances, i.e., its running time scales better with the instance size.", "CCS CONCEPTS": "\u00b7 Theory of computation \u2192 Approximation algorithms analysis ; Algorithmic game theory and mechanism design ; \u00b7 Applied computing \u2192 Online auctions .", "KEYWORDS": "Bidder Selection, Submodular Maximization, Position Auctions", "ACMReference Format:": "Nikolai Gravin, Yixuan Even Xu, and Renfei Zhou. 2024. Bidder Selection Problem in Position Auctions: A Fast and Simple Algorithm via Poisson Approximation. In Proceedings of the ACM Web Conference 2024 (WWW '24), May 13-17, 2024, Singapore, Singapore. ACM, New York, NY, USA, 19 pages. https://doi.org/10.1145/3589334.3645418", "1 INTRODUCTION": "Online advertising is a big part of the modern e-commerce industry and a key to the monetization of many online businesses. The majority of ad slots on a user web page are sold in real time via an automated auction to a group of candidate advertisers. The whole process from the time when an auction is initiated based on the impression about advertising opportunity up to the time when ads are displayed on the user's page usually has to be completed in a few milliseconds. This makes it imperative for the platform (Ad exchange ADX, or Demand side DSP) to keep the auction processing and communication time under a strict limit. Meanwhile, a platform usually runs a complex ML model on each advertiser to get an accurate estimate of their auction score 1 . As some platforms already have or anticipate to have in the near future an excessive number of prospective advertisers, the comprehensive ML model can only be run on a fraction \ud835\udc58 of \ud835\udc5b advertisers due to strict time 2 limit. In practice, the platform handles this by a two-stage selection process: it filters out all but \ud835\udc58 advertisers by running a much faster and less accurate ML model, and then it runs a proper auction for the remaining \ud835\udc58 advertisers using the comprehensive and slow ML model. E.g., for the ADX platforms \ud835\udc5b may be in the range 20 -50 and \ud835\udc58 depends on the specific company, e.g., \ud835\udc58 = 10 or \ud835\udc58 = 20; in the case of DSPs, \ud835\udc5b may vary a lot and can reach thousands, while \ud835\udc58 cannot be too large, e.g., \ud835\udc58 = 100 or \ud835\udc58 = 200. This raises multiple practical challenges for the ADX and/or DSP platforms. A platform first needs to get \ud835\udc5b rough score estimates, which can be viewed as \ud835\udc5b distributions of the bidders' accurate auction scores. One problem is how to obtain these estimates online in a constantly changing environment. Another learning problem, recently considered by Goel et al. [10] is how to retrieve this information from strategic agents, who might affect the selection stage by adjusting their bids. Third, there is an underlying optimization question: for \ud835\udc5b prospective bidders with known independent prior distributions ( \ud835\udc37 \ud835\udc56 ) \ud835\udc56 \u2208[ \ud835\udc5b ] how to select \ud835\udc58 < \ud835\udc5b of them with the objective of either maximizing expected score (social welfare) or platform's revenue. We focus on this basic optimization problem termed the Bidder Selection Problem (BSP). The welfare maximization BSP for the VCG single-item (or more generally \u2113 -unit) auction is equivalent to the following fundamental algorithmic question: select \ud835\udc58 out of \ud835\udc5b independent random variables, with the objective of maximizing the expected maximum (expected sum of top \u2113 values). This question (for single-item) has received significant attention under different names: model-driven optimization [9], \ud835\udc58 -MAX [6], team selection with test scores [14], subset selection for expected maximum [17], non-adaptive ProbeMax [22], which extends to the top\u2113 -out-of\ud835\udc58 problem. It is also natural to consider the selection problem with a more general set of objectives given by linear combinations of the top\u2113 objectives. The latter problem generalizes \u2113 -unit auctions and corresponds to the widely used position auction [8, 24] environment as described, e.g., in [12]. In position auction, there are \ud835\udc5a sorted positions that appear alongside the search results and \ud835\udc5b advertisers competing for these \ud835\udc5a slots. Each slot \ud835\udc57 \u2208 [ \ud835\udc5a ] has a different click-through rate \ud835\udc64 \ud835\udc57 (additional multiplicative factor for the click probability on \ud835\udc57 -th position), which translates into the value \ud835\udc63 \ud835\udc56 \u00b7 \ud835\udc64 \ud835\udc57 for advertiser \ud835\udc56 if \ud835\udc56 's ad is displayed at \ud835\udc57 -th position. Prior Results for the BSP. The basic BSP of welfare maximization (second-price auction) was shown to be NP-hard by Goel et al. [9] and later by Mehta et al. [17]. On the positive side, there are a few known Polynomial Time Approximation Schemes (PTAS). First, Chen et al. [6] gave a dynamic programming-based polynomial time approximation scheme (PTAS). Later, Mehta et al. [17] and Segev and Singla [22] respectively proposed an Efficient PTAS (EPTAS) for the BSP. Both of their approaches are based on discretizing and enumerating all possible distributions for the maximum of a few random variables: [17] characterize all \ud835\udc5b distributions into one of \ud835\udc36 ( \ud835\udf00 ) bins (where \ud835\udc36 ( \ud835\udf00 ) = \ud835\udc42 ( 1 / \ud835\udf00 ) \ud835\udc42 ( 1 / \ud835\udf00 ) depends on the approximation guarantee 1 -\ud835\udf00 ) and then run a brute force search with the complexity of \ud835\udc42 GLYPH<16> \ud835\udc5b \u00b7 log ( \ud835\udc58 ) \ud835\udc42 ( \ud835\udc36 ( \ud835\udf00 ) ) GLYPH<17> ; [22] use a complex reduction to a multi-dimensional extension of Santa Claus problem of [2] with at least \ud835\udc42 ( 1 / \ud835\udf00 ) \ud835\udc42 ( 1 / \ud835\udf00 ) \ud835\udc42 ( 1 / \ud835\udf00 2 ) running time 3 . We would like to emphasize that the findings of Mehta et al. and Segev and Singla could only be considered as purely computational complexity results rather than real algorithms to be used in practice or even in testing/numerical experiments. Indeed, their approaches are rather involved and not very easy to implement, e.g., Segev and Singla only state an existential result without explicitly describing their algorithm. Furthermore, the running times of these EPTASes even for the basic \ud835\udc58 -MAX problem and small values of \ud835\udc5b and \ud835\udc58 are enormously large 4 . I.e., using any of the existing PTASes would completely defeat the purpose of a two-stage selection process. For the revenue objective, Mehta et al. [17] also considered BSP for the second-price auction, which is equivalent to maximizing the expectation of the second largest value among selected \ud835\udc58 random variables. They showed strong impossibility results: it is impossible to get any constant factor approximation in polynomial time under either of the exponential time, or the planted clique hypothesises. Auction Formats. One of the most commonly used formats in advertising industry is the Generalized Second Price (GSP) auction. It was shown in [8, 24] that GSP of any position auction with any set of bidders has a Nash equilibrium equivalent to the welfaremaximizing outcome of the VCG. In some cases (e.g., Google's auction for selling contextual ads [25]) the platform's auction format is based directly on the VCG. Thus, in the BSP context with the welfare-maximization objective, it is most natural to analyze the VCG mechanism. For the revenue objective, it is natural to study the optimal Myerson's auction, as it gives an upper bound on the revenue of any other auction format. Then one can reduce revenue maximization to welfare maximization of the VCG format. I.e., it is w.l.o.g. to only study welfare-maximization BSP for the VCG format, which we do in the rest of our paper. It is also natural to study revenue maximization BSP for the GSP format (or by the revenue equivalence of the VCG format). Unfortunately, it does not admit polynomial time \ud835\udc42 ( 1 ) -approximation even for the basic single-item auction due to strong impossibility results of [17].", "1.1 Our Results": "Wepropose a novel relaxation of the BSP for a more general position auction environment, which we call Poisson (or Poisson-Chernoff) relaxation. It has the following theoretical guarantees. (1) The relaxation is a continuous maximization problem with a concave objective that can be solved in time polynomial in \ud835\udc5b and \ud835\udc58 . In fact, the objective of this relaxation is a nicely structured algebraic function that lends itself to efficient convex minimization solvers. (2) With small adjustments (summarized in Algorithm 1), the relaxed objective converges at the rate 1 -\ud835\udc42 ( \ud835\udc58 -1 / 4 ) to the actual social welfare of fractional BSP as the problem size \ud835\udc58 grows (Theorem 4.4). The standard rounding of this fractional solution suffers only a small loss of \ud835\udc42 ( \ud835\udc58 -1 / 2 ) , yielding GLYPH<0> 1 -\ud835\udc42 ( \ud835\udc58 -1 / 4 ) GLYPH<1> -approximation (Theorem 4.5) for the integral BSP. (3) For the special case of the single-item auction, our algorithm achieves 1 -\ud835\udc42 GLYPH<0> \u221a\ufe01 ln \ud835\udc58 / \ud835\udc58 GLYPH<1> approximation (see Appendix C). These results have immediate theoretical implications and can be implemented in practice unlike all previous PTAS algorithms, as our approach has far superior running time to the point where it outperforms some of the existing heuristics used in practice, such as the Greedy algorithm for general submodular maximization. Furthermore, our results bring new theoretical insight for BSP: the BSP converges to a polynomial-time solvable optimization problem as the problem size \ud835\udc58 grows. Theoretical Implications. Our Algorithm 1 gives a ( 1 -\ud835\udf00 ) approximation to the BSP for any position auction with \ud835\udf00 = \u03a9 ( \ud835\udc58 -1 / 4 ) and works in polynomial time (independent of \ud835\udf00 ). On the other hand, for small values of \ud835\udf00 ( \ud835\udf00 = \ud835\udc42 ( \ud835\udc58 -1 / 4 ) ), a straightforward exhaustive search algorithm gives a perfect solution in \ud835\udc42 ( \ud835\udc5b \ud835\udc58 ) = \ud835\udc5b poly ( 1 / \ud835\udf00 ) time. I.e., the combination of our relaxation with the brute force algorithm yields a PTAS: Corollary 1.1. BSP for any position auction admits a ( 1 -\ud835\udf00 ) PTAS that runs in \ud835\udc5b poly ( 1 / \ud835\udf00 ) time. Moreover, the algorithm as in Corollary 1.1 is an EPTAS with a much better dependency on \ud835\udf00 than previous PTASes under a mild assumption that \ud835\udc58 \u2265 log \ud835\udc5b : Corollary 1.2. BSP for position auctions admits a ( 1 -\ud835\udf00 ) EPTAS for any \ud835\udc58 \u2265 log \ud835\udc5b that runs in \ud835\udc42 ( poly ( \ud835\udc5b, \ud835\udc58 )) + 2 \ud835\udc42 ( \ud835\udf00 -8 ) time. Proof. Algorithm 1 runs in \ud835\udc42 ( poly ( \ud835\udc5b, \ud835\udc58 )) . We run brute force only when \ud835\udf00 = \ud835\udc42 ( \ud835\udc58 -1 / 4 ) , i.e., when \ud835\udc58 2 = \ud835\udc42 ( \ud835\udf00 -8 ) . Then its running time is not more than \ud835\udc5b \ud835\udc58 \u2264 2 \ud835\udc58 2 = 2 \ud835\udc42 ( \ud835\udf00 -8 ) , since \ud835\udc58 \u2265 log \ud835\udc5b . \u25a1 Comparison with Previous Theoretical Results. Our novel Poisson approximation approach yields more general theoretical results than previous work. E.g., as Segev and Singla [22] briefly mention how their scheme can be extended from \ud835\udc58 -MAX (i.e., single-item auction) to \u2113 -unit auctions, one may wonder if a similar approach also extends to the more general position auction environment. To the best of our knowledge, it does not. Indeed, their main idea is to consider two regimes for \u2113 : small (a constant) \u2113 < 1 / \ud835\udf00 3 , and large \u2113 > 1 / \ud835\udf00 3 . They claim that the former case can be handled with a similar approach (maybe with a significantly worse dependency of the running time on \ud835\udf00 than the case \u2113 = 1), and in the later case, one can use concentration bounds similar to the (3) case described in Section 3.1. This argument cannot be used for the objective that is a linear combination of welfare in 1-unit and \ud835\udc58 / 2-unit auctions. Relevance in Practice. Our relaxation is a white-box approach that can be easily adapted to different scenarios. E.g., if some bidders have to be included in the final solution (which is often the case in industry because of contract obligations), then our approach gives the same approximation with these additional constraints 5 . Also, depending on the type of problem instances, a few steps of our algorithm can be removed or simplified to fit the specific domain, which results in simpler and more efficient solutions. Furthermore, unlike the case with all previous PTASes, we actually implemented our algorithm and did numerical experiments on several generated data sets of practically relevant sizes. Note that a company cares much more about the implementability and running time of their algorithms rather than its theoretical approximation guarantees 6 , which has been the main focus of previous PTAS results. In contrast, our algorithm is not very complex and is based on standard continuous convex maximization methods, which means that it is much easier to understand and adopt by a platform's product team. The experiments are summarized in Section 5. We slightly simplified our theoretical Algorithm 1 to avoid the hard-coded efficiency loss of \ud835\udc42 ( \ud835\udc58 -1 / 4 ) in the approximation. Weobserved that among all tested algorithms, our algorithm produced solutions that were always within 0.1% of the best-performing algorithm in terms of objective value. Furthermore, our algorithm's running time scales significantly slower than any other tested algorithm. For large instances where \ud835\udc5b = 1000 , \ud835\udc58 = 200, our algorithm took less than 1 minute to complete, while even Greedy (which is a subroutine in all previous PTASes) took more than 1 day and Local Search could not finish within 1 week. These findings demonstrate the practical relevance of our approach.", "1.2 Other Related Work": "Mehta et al. [17] mention a few other scenarios besides bidder selection with similar mathematical formulations. The applications range from a two-tier solution for scoring documents in a search result [5], to filtering initial proposals in procurement auctions [21, 23], to voting theory [20]. Bei at al. [3] studied BSP with the revenue objective under multiple auction formats including Myerson's auction and gave constant factor approximation for the second-price auction with anonymous reserve. They also introduced another optimization framework for the BSP under costs, which is more challenging than the BSP under capacity constraint. Poisson approximation is a well-developed technique from probability theory and statistics. A survey [19] mentions at least twenty different results on the basic question of approximating the sum of independent Bernoulli random variables by the Poisson distribution. In statistics, Poisson approximation is commonly used in Extreme Value Theory (EVT) with applications to structural and geological engineering, traffic prediction, and finance (see, e.g., a book [18]). It has also been used in theoretical computer science, e.g., [16] used Le Cam's Poisson approximation theorem for stochastic bin packing and knapsack problems and also for EUM introduced in [15]. In fact, the expected utility maximization (EUM) is closely related to our objective. EUM is formulated as choosing a feasible subset \ud835\udc46 out of \ud835\udc5b random variables \ud835\udc4b 1 , . . . , \ud835\udc4b \ud835\udc5b to maximize E [ \ud835\udc62 ( \u02dd \ud835\udc56 \u2208 \ud835\udc46 \ud835\udc4b \ud835\udc56 )] , where \ud835\udc62 is a given utility function. The problem has been studied under capacity [4] or other combinatorial constraints [15, 16, 26] with a non-linear (typically concave) utility function. The BSP for single-item auction, i.e., the \ud835\udc58 -MAXproblem, has a similar objective E [ max \ud835\udc56 \u2208 \ud835\udc46 { \ud835\udc4b \ud835\udc56 }] to EUM but with max operator instead of the sum. When the distributions of \ud835\udc4b \ud835\udc56 are unknown, EUM becomes an online learning problem. Chen et al. [6] gave the first PTAS for \ud835\udc58 -MAX, but their main focus is on Combinatorial Multi-Armed Bandits.", "2 PRELIMINARIES": "A set of \ud835\udc5b bidders wish to receive some service and each bidder \ud835\udc56 \u2208 [ \ud835\udc5b ] has a private non-negative value \ud835\udc63 \ud835\udc56 \u2208 R \u2265 0 indicating how much they are willing to pay for it. We denote the vector of bidder values as v = ( \ud835\udc63 \ud835\udc56 ) \ud835\udc56 \u2208[ \ud835\udc5b ] . By the revelation principle, we can restrict our attention to incentive compatible and individually rational singleround auctions A , where each bidder \ud835\udc56 submits a sealed bid \ud835\udc4f \ud835\udc56 to the auctioneer. The auctioneer then decides on a feasible allocation vector a ( b ) = ( \ud835\udc4e \ud835\udc56 ( b )) \ud835\udc56 \u2208[ \ud835\udc5b ] and payments p ( b ) = ( \ud835\udc5d \ud835\udc56 ( b )) \ud835\udc56 \u2208[ \ud835\udc5b ] . The incentive compatibility and individual rationality mean that by bidding truthfully \ud835\udc4f \ud835\udc56 = \ud835\udc63 \ud835\udc56 , each bidder \ud835\udc56 \u2208 [ \ud835\udc5b ] (a) maximizes her utility \ud835\udc62 \ud835\udc56 ( \ud835\udc4f \ud835\udc56 , b -\ud835\udc56 ) def == \ud835\udc63 \ud835\udc56 \u00b7 \ud835\udc4e \ud835\udc56 ( \ud835\udc4f \ud835\udc56 , b -\ud835\udc56 ) -\ud835\udc5d \ud835\udc56 ( \ud835\udc4f \ud835\udc56 , b -\ud835\udc56 ) and (b) receives non-negative utility \ud835\udc62 \ud835\udc56 ( \ud835\udc63 \ud835\udc56 , b -\ud835\udc56 ) \u2265 0. The seminal VCG mechanism (a second-price auction in the case of single-item auction) is an example of incentive compatible mechanism that also maximizes social welfare SW ( a , v ) = \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc4e \ud835\udc56 \u00b7 \ud835\udc63 \ud835\udc56 . Westudy auctions in the Bayesian setting, where we assume that bidder values are drawn independently from known prior distributions v \u223c D = \u02db \ud835\udc56 \u2208[ \ud835\udc5b ] \ud835\udc37 \ud835\udc56 . We also use \ud835\udc37 \ud835\udc56 ( \ud835\udf0f ) = Pr \ud835\udc63 \ud835\udc56 \u223c \ud835\udc37 \ud835\udc56 [ \ud835\udc63 \ud835\udc56 \u2264 \ud835\udf0f ] to denote the cumulative distribution function. The auction designer is usually concerned about two objectives: the expected social welfare SW = Ev \u223c D [ SW ( a ( v ) , v )] , and revenue Rev = Ev \u223c D [ \u02dd \ud835\udc56 \u2208[ \ud835\udc5b ] \ud835\udc5d \ud835\udc56 ( v )] . The VCG mechanism maximizes the welfare on every valuation profile v , and thus maximizes SW in expectation for any prior D . The well-known Myerson's auction maximizes Rev. This auction reduces the problem of revenue maximization to virtual welfare maximization by transforming values ( \ud835\udc63 \ud835\udc56 ) \ud835\udc56 \u2208[ \ud835\udc5b ] to virtual values \ud835\udf11 \ud835\udc56 ( \ud835\udc63 \ud835\udc56 ) for regular distribution \ud835\udc37 \ud835\udc56 and by doing ironing \ud835\udf11 \ud835\udc56 ( \ud835\udc63 \ud835\udc56 ) for irregular distribution \ud835\udc37 \ud835\udc56 . I.e., the expected revenue of Myerson's auction can be written as Rev = Ev [ SW ( a ( v ) , \ud835\udf11 ( v ))] for regular distributions and Rev = Ev [ SW ( a ( v ) , \ud835\udf11 ( v ))] for general distributions. Auction Environments. The single-item auction is an environment with the feasible allocations given by { a : \u02dd \ud835\udc56 \u2208[ \ud835\udc5b ] \ud835\udc4e \ud835\udc56 \u2264 1 } . A more general \u2113 -unit auction environment for \u2113 \u2208 N is given by the feasibility constraints: \u02dd \ud835\udc56 \u2208[ \ud835\udc5b ] \ud835\udc4e \ud835\udc56 \u2264 \u2113 and \ud835\udc4e \ud835\udc56 \u2208 [ 0 , 1 ] for all \ud835\udc56 \u2208 [ \ud835\udc5b ] . A position auction environment further generalizes \u2113 -unit auctions. It is specified by a sorted weight vector w = ( 1 \u2265 \ud835\udc64 1 \u2265 \ud835\udc64 2 \u2265 . . . \u2265 \ud835\udc64 \ud835\udc5b \u2265 0 ) , which represents the click-through rate probabilities for \ud835\udc5b advert positions 7 . Every bidder may get at most one position and each advert position can be assigned to at most one advertiser. Formally, the feasibility allocations can be specified with an assignment function \ud835\udf0b : [ \ud835\udc5b ] \u2192 [ \ud835\udc5b ] of \ud835\udc5b advertisers to \ud835\udc5b sorted slots as follows: { a : \u2203 \ud835\udf0b, \ud835\udc4e \ud835\udc56 \u2208 [ 0 , \ud835\udc64 \ud835\udf0b ( \ud835\udc56 ) ] for all \ud835\udc56 \u2208 [ \ud835\udc5b ]} . Bidder Selection. In the Bidder Selection Problem (BSP) the seller first decides \ud835\udc65 \ud835\udc56 \u2208 { 0 , 1 } which bidders \ud835\udc56 \u2208 [ \ud835\udc5b ] to invite to the auction. The selected set of bidders \ud835\udc46 may not exceed a certain capacity \ud835\udc58 \u2265 | \ud835\udc46 | , i.e., \u02dd \ud835\udc56 \u2208[ \ud835\udc5b ] \ud835\udc65 \ud835\udc56 \u2264 \ud835\udc58 . Then the auctioneer runs an optimal auction A for the set \ud835\udc46 of invited bidders: VCG mechanism for the welfare objective, and Myerson for the revenue objective. Since revenue of the Myerson's auction can be rewritten as the expected virtual welfare with independent (ironed) virtual values ( \ud835\udf11 \ud835\udc56 ( \ud835\udc63 \ud835\udc56 ) : \ud835\udc63 \ud835\udc56 \u223c \ud835\udc37 \ud835\udc56 ) \ud835\udc56 \u2208 \ud835\udc46 , the BSP for the revenue maximization is equivalent to the BSP for the welfare maximization. Thus it suffices to only consider the welfare maximization problem. Specifically, we denote by v \u223c x \u00b7 D the independent draws of \ud835\udc63 \ud835\udc56 \u223c \ud835\udc65 \ud835\udc56 \u00b7 \ud835\udc37 \ud835\udc56 (i.e., \ud835\udc63 \ud835\udc56 \u223c \ud835\udc37 \ud835\udc56 when \ud835\udc65 \ud835\udc56 = 1, and \ud835\udc63 \ud835\udc56 = 0 when \ud835\udc65 \ud835\udc56 = 0) for all \ud835\udc56 \u2208 [ \ud835\udc5b ] , then the BSP of the VCG mechanism for any \u2113 -unit/position auction with weights w can be written as follows: where \ud835\udc63 ( \ud835\udc56 ) is the \ud835\udc56 -th largest value among { \ud835\udc63 \ud835\udc56 } \ud835\udc56 \u2208[ \ud835\udc5b ] . We want to obtain good approximation algorithms for these BSPs. I.e., we would like to find in polynomial time x \u2208 { 0 , 1 } \ud835\udc5b with | x | 1 \u2264 \ud835\udc58 such that Ev \u223c x \u00b7 D [ \u02dd \u2113 \ud835\udc56 = 1 \ud835\udc63 ( \ud835\udc56 ) ] \u2265 ( 1 -\ud835\udf00 ) OPT ( \u2113 ) and Ev \u223c x \u00b7 D [ \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc64 \ud835\udc56 \u00b7 \ud835\udc63 ( \ud835\udc56 ) ] \u2265 ( 1 -\ud835\udf00 ) OPT ( w ) for a small \ud835\udf00 > 0. To simplify the presentation, we assume that all distributions ( \ud835\udc37 \ud835\udc56 ) \ud835\udc56 \u2208[ \ud835\udc5b ] have finite supports and are given explicitly as the algorithm's input. It has been observed before that the BSP's objective is a monotone submodular function of the set \ud835\udc46 = { \ud835\udc56 : \ud835\udc65 \ud835\udc56 = 1 } of invited bidders, i.e., SW ( \ud835\udc46 ) + SW ( \ud835\udc47 ) \u2265 SW ( \ud835\udc46 \u2229 \ud835\udc47 ) + SW ( \ud835\udc46 \u222a \ud835\udc47 ) for any \ud835\udc46,\ud835\udc47 \u2286 [ \ud835\udc5b ] . The same property holds for the \u2113 -unit and position auctions with an almost identical proof (see [6]). Wealso consider the standard (in submodular optimization literature) multi-linear extension of the BSP objective. I.e., for a fractional x \u2208 [ 0 , 1 ] \ud835\udc5b , we invite each bidder \ud835\udc56 to the auction independently with probability \ud835\udc65 \ud835\udc56 . We employ the same notation v \u223c x \u00b7 D as in the integral problem, where \ud835\udc63 \ud835\udc56 \u223c \ud835\udc65 \ud835\udc56 \u00b7 \ud835\udc37 \ud835\udc56 means that we first decide whether to invite \ud835\udf09 \ud835\udc56 \u2208 { 0 , 1 } bidder \ud835\udc56 according to a Bernoulli distribution \ud835\udf09 \ud835\udc56 \u223c Ber ( \ud835\udc65 \ud835\udc56 ) , then draw their value \ud835\udc63 \ud835\udc56 \u223c \ud835\udf09 \ud835\udc56 \u00b7 \ud835\udc37 \ud835\udc56 . The capacity constraint transforms into the bound on the expected number of invited bidders \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc65 \ud835\udc56 \u2264 \ud835\udc58 . We describe this new mathematical formulation in Section 3. In Section 4, we first consider this fractional relaxation of BSP and we discuss in Section 4.2 how to obtain a good solution to the integral BSP from the fractional problem.", "3 NEWMATHEMATICAL FORMULATION": "In this section, we give a fractional relaxation of BSP. As the welfare of any position auction can be written as a linear combination of \u2113 -unit auctions, we begin with a fractional relaxation of BSP for the \u2113 -unit auction. Specifically, the expected social welfare with a fractional set of bidders x is SW ( x , \u2113 ) = E v \u223c x \u00b7 D [ \u02dd \u2113 \ud835\udc56 = 1 \ud835\udc63 ( \ud835\udc56 ) ] , where \ud835\udc63 ( \ud835\udc56 ) denotes the \ud835\udc56 -th largest value among { \ud835\udc63 \ud835\udc56 } \ud835\udc56 \u2208{ 1 , 2 ,...,\ud835\udc5b } . Hence, the following mathematical program represents BSP for \u2113 -unit auction: As \u2113 is fixed, whenever it is clear from the context, we will simply write SW ( x ) . Bernoulli Representation. We now derive an explicit formula for the social welfare SW ( x ) . Fixing a threshold \ud835\udf0f , the expected number of bidders with values exceeding \ud835\udf0f among the highest \u2113 bidders is Ev \u223c x \u00b7 D [ min ( \u02dd \ud835\udc5b \ud835\udc56 = 1 I [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf0f ] , \u2113 )] . Therefore, by integrating 8 over \ud835\udf0f \u2208 [ 0 , +\u221e) , we get Note that I [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf0f ] for \ud835\udc63 \ud835\udc56 \u223c \ud835\udc65 \ud835\udc56 \u00b7 \ud835\udc37 \ud835\udc56 is a Bernoulli random variable, and Ev \u223c x \u00b7 D [ min ( \u02dd \ud835\udc5b \ud835\udc56 = 1 I [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf0f ] , \u2113 )] is the minimum of a sum of independent Bernoulli random variables and \u2113 . To simplify notations, we explicitly define the probabilities of Bernoulli random variables Definition 3.1 (Bernoulli Objective). For a vector q \u2208 [ 0 , 1 ] \ud835\udc5b and \u2113 , the Bernoulli objective term of q and \u2113 is a function H ber ( q , \u2113 ) : Position Auctions. A position auction is given by a vector of nonnegative weights 9 w : ( \ud835\udc64 1 \u2265 \ud835\udc64 2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 \ud835\udc64 \ud835\udc5b \u2265 0 ) . The highest social welfare we get from the set \ud835\udc46 of invited bidders is \u02dd | \ud835\udc46 | \ud835\udc56 = 1 \ud835\udc63 ( \ud835\udc56 ) \u00b7 \ud835\udc64 \ud835\udc56 , where \ud835\udc63 ( 1 ) \u2265 \u00b7 \u00b7 \u00b7 \u2265 \ud835\udc63 ( | \ud835\udc46 | ) are ordered values of bidders in \ud835\udc46 . Thus the expected social welfare for a fractional set x is where \ud835\udc64 \ud835\udc5b + 1 def == 0. Then the respective fractional BSP program for position auctions is as follows. We will often omit dependency on w in SW whenever it is clear from the context. We further consider the Bernoulli representation for position auctions: As in (2), q ( x , \ud835\udf0f ) represents the probabilities of each bidder's value exceeding \ud835\udf0f . Hber ( q , w ) is called the Bernoulli objective term for position auctions.", "3.1 Overview of Our Approach": "The fractional relaxation (4) is still neither convex nor concave and thus is too unwieldy. The central idea of our paper is to use instead Poisson approximation to the Bernoulli objective terms Hber ( q ( x , \ud835\udf0f ) , w ) . Specifically, we substitute each Bernoulli random variable \ud835\udc67 \u223c Ber ( \ud835\udc5d ) with \ud835\udc5d = \ud835\udc5e \ud835\udc56 ( \ud835\udc65 \ud835\udc56 , \ud835\udf0f ) by the Poisson random variable \ud835\udc66 \u223c Pois ( \ud835\udc5d ) with the same expectation as \ud835\udc67 . We use the following Poisson objective term H pois ( q , \u2113 ) to approximate H ber ( q , \u2113 ) . The advantage of the Poisson approximation H pois ( q , \u2113 ) is that the resulting functions H pois ( q , \u2113 ) and H pois ( q , w ) are concave in q . This in turn allows us to efficiently solve the optimization problem for the Poisson approximation analogous to (4). This Poisson approximation works well 10 in the following situations. (1) Whentheprobabilities \ud835\udc5d \ud835\udc56 = \ud835\udc5e \ud835\udc56 ( \ud835\udc65 \ud835\udc56 , \ud835\udf0f ) of \ud835\udc67 \ud835\udc56 \u223c Ber ( \ud835\udc5d \ud835\udc56 ) are small (i.e., \ud835\udc5d \ud835\udc56 \u2264 \ud835\udeff, \u2200 \ud835\udc56 \u2208 [ \ud835\udc5b ] ). This allows us to handle the crucial contribution to the welfare comprised of small probability tail events for large thresholds \ud835\udf0f . (2) When E [ \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc67 \ud835\udc56 ] is large (when thresholds \ud835\udf0f are small). Indeed, by Chernoff bounds the sums of independent random variables (both Bernoulli and Poisson) \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc67 \ud835\udc56 and \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc66 \ud835\udc56 are close to their expectations. In fact, we simply use Chernoff objective term H cher ( q , \u2113 ) def == min GLYPH<0>\u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc5e \ud835\udc56 , \u2113 GLYPH<1> instead of Poisson approximation in this case. (3) When \u2113 is large. In this case, either the concentration inequality gives a good approximation when E [ \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc67 \ud835\udc56 ] = E [ \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc66 \ud835\udc56 ] is large, or when this expectation is much smaller than \u2113 then the probability that either of \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc67 \ud835\udc56 or \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc66 \ud835\udc56 exceeds the threshold \u2113 is small. Then the algorithmic framework for the BSP is rather straightforward. We need to solve the following concave program of x : We define the approximate social welfare g SW ( x , w ) to be the objective of (6). Here, H pois ( q ( x , \ud835\udf0f ) , \u2113 ) = E \ud835\udc4c \u223c Pois ( \u02dd \ud835\udc5e \ud835\udc56 ) [ min ( \ud835\udc4c, \u2113 )] and all functions under the integral are piece-wise constant with the number of pieces bounded by the size of the union of the supports of \ud835\udc37 \ud835\udc56 . The optimal fractional solution x can be computed rather efficiently using continuous convex optimization. Finally, we use a rounding procedure (similar to the multi-linear extension of submodular function) to the fractional solution of (6) to obtain an integral solution with a small loss to the approximation guarantee.", "4 OUR ALGORITHM": "Poisson approximation is the central idea of this paper. We use the Poisson Objective to approximate Bernoulli objective terms. Definition 4.1 (Poisson Objective). For q \u2208 [ 0 , 1 ] \ud835\udc5b and \u2113 \u2208 N , the Poisson objective term is a function H pois ( q , \u2113 ) given by Note that the latter equality is an important property of Poisson distribution: the sum of independent Poisson random variables \ud835\udc66 \ud835\udc56 \u223c Pois ( \ud835\udc5e \ud835\udc56 ) follows the Poisson distribution Pois ( \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc5e \ud835\udc56 ) . Another crucial property is the concavity of Poisson approximation. Claim 4.2 (Concavity of Poisson). Hpois ( q , \u2113 ) is a concave function in q \u2208 [ 0 , 1 ] \ud835\udc5b for \u2200 \u2113 \u2208 N . Proof. Let \ud835\udf06 = \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc5e \ud835\udc56 . Notice that H pois ( q , \u2113 ) only depends on \ud835\udf06 , which is linear in q . We use H pois ( \ud835\udf06 ) to represent this function. Then, we only need to prove that H pois ( \ud835\udf06 ) is concave in \ud835\udf06 . Rewrite By a straightforward differentiation of the partial series we get Therefore, H pois ( q , \u2113 ) is concave in \ud835\udf06 , and thus concave in q . \u25a1 Chernoff Approximation. As we mentioned earlier Poisson approximation is useful for small probabilities \ud835\udc5e \ud835\udc56 \u2264 \ud835\udeff . For another extreme case where \ud835\udf06 = \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc5e \ud835\udc56 is large, due to concentration bounds, Poisson approximation also works well with \ud835\udc42 ( \ud835\udf06 -1 / 2 ) relative error, because both \u02dd \ud835\udc5b \ud835\udc56 = 1 Ber ( \ud835\udc5e \ud835\udc56 ) and Pois ( \ud835\udf06 ) concentrate around \ud835\udf06 . To optimize the presentation for an easier understanding, we will use Chernoff objective term Hcher ( q , \u2113 ) def == min GLYPH<0>\u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc5e \ud835\udc56 , \u2113 GLYPH<1> as an alternative of Poisson in this case. It is also concave in q . In a number of cases H pois ( q , \u2113 ) and H cher ( q , \u2113 ) are good approximations to H ber ( q , \u2113 ) . In Appendix A, we present these approximation guarantees along with a simple algorithm that illustrates our approach in an important special case.", "4.1 Algorithm for Position Auctions": "Below, we consider Bidder Section Problem for position auctions. We first analyze the fractional BSP, and then explain in Section 4.2 how to do integral rounding of the fractional solution with only a small loss to the approximation guarantee. For the fractional BSP, we give an efficient polynomial time ( 1 -\ud835\udc42 ( \ud835\udc58 -4 )) -approximation algorithm (see Theorem 4.4 for the exact statement). Recall that the Bernoulli objective term for position auctions Hber ( q , w ) is defined in Section 3. The expected welfare SW ( x ) = SW ( x , w ) is written as an integral of H ber . Below, we will also need the Chernoff objective term We sometimes slightly abuse notations and write H ber ( x , \ud835\udf0f ) and Hcher ( x , \ud835\udf0f ) instead of H ber ( q , w ) and H cher ( q , w ) . In order to effectively use the Poisson approximation we would like to have the small probability assumption \ud835\udc5e \ud835\udc56 \u2264 \ud835\udeff , which is achieved by fixing a small bidder set \ud835\udc46 fix properly (see Appendix A for formal approximation guarantees). Fixing Small Bidder Set. We will fix a small set of bidders \ud835\udc46 fix (set \ud835\udc65 \ud835\udc56 = 1 for \ud835\udc56 \u2208 \ud835\udc46 fix ) with | \ud835\udc46 fix | = \ud835\udf00 \u00b7 \ud835\udc58 and make sure that all other bidders \ud835\udc56 \u2209 \ud835\udc46 fix have only a small probability Pr [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf0f ] \u2264 \ud835\udeff to exceed any of the thresholds \ud835\udf0f > \ud835\udf02 for certain \ud835\udf02 > 0. This allows us to use Poisson approximation for the high range thresholds \ud835\udf0f > \ud835\udf02 and bidders \ud835\udc56 \u2208 \ud835\udc40 def == [ \ud835\udc5b ] \\ \ud835\udc46 fix . On the other hand, for the low range thresholds \ud835\udf0f \u2264 \ud835\udf02 , we would like to see a certain number \u2113 \u2217 of bidders \ud835\udc56 \u2208 \ud835\udc46 fix to exceed the threshold \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf0f . To this end, we choose \ud835\udc46 fix so that the expected number of bidders \ud835\udc56 \u2208 \ud835\udc46 fix with \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf0f is at least \u2113 \u2217 . We can achieve the following guarantees for \ud835\udf00, \ud835\udeff, and \u2113 \u2217 . Claim 4.3 (Small Bidder Set). Let \ud835\udf00 \u2208 [ \u2113 \u2217 \ud835\udeff \u00b7 \ud835\udc58 , 1 ) be a multiple of 1 / \ud835\udc58 for \u2113 \u2217 \u2208 R \u2265 0 : \u2113 \u2217 < \ud835\udc58 and \ud835\udeff \u2208 ( 0 , 1 ) . We can find in polynomial time a threshold \ud835\udf02 \u2265 0 and a set \ud835\udc46 fix \u2286 [ \ud835\udc5b ] of size | \ud835\udc46 fix | = \ud835\udf00 \u00b7 \ud835\udc58 : Proof. We search through all thresholds \ud835\udf0f in the supports of { \ud835\udc37 \ud835\udc56 } \ud835\udc56 \u2265 1 and find two consecutive threshold values \ud835\udf02 and \ud835\udf02 + > \ud835\udf02 such that |{ \ud835\udc56 : Pr [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf02 ] \u2265 \ud835\udeff }| \u2265 \ud835\udf00 \u00b7 \ud835\udc58 , but a similar number of bidders |{ \ud835\udc56 : Pr [ \ud835\udc63 \ud835\udc56 > \ud835\udf02 ] = Pr [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf02 +] \u2265 \ud835\udeff }| < \ud835\udf00 \u00b7 \ud835\udc58 for the next value \ud835\udf02 + . We place each bidder \ud835\udc56 with Pr [ \ud835\udc63 \ud835\udc56 > \ud835\udf02 ] \u2265 \ud835\udeff into \ud835\udc46 fix and fill the remaining positions in \ud835\udc46 fix up to \ud835\udf00 \u00b7 \ud835\udc58 with bidders from { \ud835\udc56 : Pr [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf02 ] \u2265 \ud835\udeff > Pr [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf02 +]} . Thus, every bidder \ud835\udc56 \u2209 \ud835\udc46 fix has Pr [ \ud835\udc63 \ud835\udc56 > \ud835\udf02 ] = Pr [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf02 +] < \ud835\udeff as required by condition (b). On the other hand, | \ud835\udc46 fix | = \ud835\udf00 \u00b7 \ud835\udc58 and Pr [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf02 ] \u2265 \ud835\udeff for every \ud835\udc56 \u2208 \ud835\udc46 fix , which implies (a), since \u2200 \ud835\udf0f \u2264 \ud835\udf02 , Thus we constructed in polynomial time the desired threshold \ud835\udf02 and set \ud835\udc46 fix . \u25a1 We need to balance three parameters \u2113 \u2217 , \ud835\udeff , and \ud835\udf00 , which must satisfy the conditions of Claim 4.3. Specifically, we choose \u2113 \u2217 = \ud835\udc58 1 / 2 , \ud835\udf00 = \ud835\udc58 -1 / 4 rounded up to a multiple of 1 / \ud835\udc58 , and \ud835\udeff = \ud835\udf00 \u2265 \ud835\udc58 -1 / 4 . Claim 4.3 leads to Algorithm 1 (which we will present shortly). For thresholds \ud835\udf0f > \ud835\udf02 , any bidder outside \ud835\udc46 fix has only \u2264 \ud835\udeff probability to exceed the threshold, which is ideal for applying the Poisson approximation. Therefore, to achieve the approximation guarantees when the probability of exceeding the threshold is low, we recalculate the adjusted Poisson objective term by applying Poisson approximation only on these bidders. Specifically, we let \ud835\udc40 def == [ \ud835\udc5b ] \\ \ud835\udc46 fix and define \ud835\udc4d fix ( \ud835\udf0f ) def == \u02dd \ud835\udc56 \u2208 \ud835\udc46 fix I [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf0f ] (as x \ud835\udc46 fix = 1 \ud835\udc46 fix , random variable \ud835\udc4d fix ( \ud835\udf0f ) has Poisson binomial distribution). Indeed, we may calculate all probabilities Pr [ \ud835\udc4d fix ( \ud835\udf0f ) = \ud835\udc57 ] for each \ud835\udc57 \u2208 [ 0 , \ud835\udf00 \u00b7 \ud835\udc58 ] in polynomial time, and define the adjusted Poisson objective term as a conditional expectation depending on \ud835\udc4d fix ( \ud835\udf0f ) : where H pois ( x \ud835\udc40 , \u2113 -\ud835\udc57, \ud835\udf0f ) = E \ud835\udc4c \u223c Pois ( \ud835\udf06 \ud835\udc40 ) [ min { \ud835\udc4c, \u2113 -\ud835\udc57 }] , and \ud835\udf06 \ud835\udc40 = \u02dd \ud835\udc56 \u2208 \ud835\udc40 \ud835\udc5e \ud835\udc56 ( \ud835\udc65 \ud835\udc56 , \ud835\udf0f ) . For the low-range thresholds \ud835\udf0f \u2264 \ud835\udf02 , we use the Chernoff objective H cher ( x , \ud835\udf0f ) = Hcher ( q ( x , \ud835\udf0f ) , w ) to approximate Hber ( x , \ud835\udf0f ) = Hber ( q ( x , \ud835\udf0f ) , w ) for x = ( x \ud835\udc40 , 1 \ud835\udc46 fix ) . Importantly, unlike the high-range thresholds, we do not recalculate H cher as a function of x \ud835\udc40 , but use Chernoff approximation for the entire \ud835\udc5b -dimensional vector x = ( x \ud835\udc40 , x \ud835\udc46 fix ) with x \ud835\udc46 fix = 1 \ud835\udc46 fix . Thus, as \u2113 \u2217 = \ud835\udc58 1 / 2 grows with \ud835\udc58 , Hcher ( x , \ud835\udf0f ) \u2192 Hber ( x , \ud835\udf0f ) .", "Algorithm 1: Fractional BSP for Position Auctions": "Let \u2113 \u2217 = \ud835\udc58 1 / 2 ; \ud835\udf00 be \ud835\udc58 -1 / 4 rounded up to a multiple of 1 / \ud835\udc58 GLYPH<0> \ud835\udf00 = \u2308 \ud835\udc58 \u00b7 \ud835\udc58 -1 / 4 \u2309 \ud835\udc58 GLYPH<1> ; \ud835\udeff = \ud835\udf00 . (1) Find \ud835\udf02 and \ud835\udc46 fix according to Claim 4.3. Set \ud835\udc65 \ud835\udc56 = 1 for \u2200 \ud835\udc56 \u2208 \ud835\udc46 fix . Let \ud835\udc40 def == [ \ud835\udc5b ] \\ \ud835\udc46 fix . (2) Define the approximate welfare using adjusted Poisson objective (7): (3) Return e x \u2217 = ( e x \u2217 \ud835\udc40 , 1 \ud835\udc46 fix ) , where e x \u2217 \ud835\udc40 is the solution to the concave program in x \ud835\udc40 : Algorithm. Our main algorithm is summarized as Algorithm 1. Theorem 4.4. Algorithm 1 works in polynomial time and is a ( 1 -\ud835\udc42 ( \ud835\udf00 )) -approximation, i.e., ( 1 -43 \ud835\udc58 -1 / 4 ) -approximation to the fractional BSP for any position auction. The proof of this theorem is deferred to Appendix B.1.", "4.2 Rounding": "Weconclude Section 4 by presenting the rounding algorithm, which takes our solution e x \u2217 to the fractional BSP produced by Algorithm 1 and returns a solution to the integral BSP. Our fractional relaxation works as the standard multi-linear extension of submodular functions, which corresponds to sampling a random set of bidders \ud835\udc46 \u223c \u02db \ud835\udc5b \ud835\udc56 = 1 Ber ( \ud835\udc65 \ud835\udc56 ) in the integral BSP. To align the notations for fractional and integral BSPs, we shall use vectors y , z \u2208 { 0 , 1 } \ud835\udc5b for the respective sets of selected bidders. Specifically, we use y \u223c Ber ( x ) to represent the random set \ud835\udc46 in the multi-linear extension. Our rounding procedure is in Algorithm 2.", "Algorithm 2: Rounding: algorithm for Integral BSP": "(1) Run Algorithm 1 to obtain a fractional solution x . (2) Sample an integral solution y \u223c Ber ( x ) , with y \u2208 { 0 , 1 } \ud835\udc5b . (3) \u00b7 If | y | 1 \u2264 \ud835\udc58 , return z = y , \u00b7 Else ( | y | 1 > \ud835\udc58 ), return \ud835\udc58 bidders z \u223c GLYPH<0> y \ud835\udc58 GLYPH<1> chosen uniformly at random from y . Theorem 4.5. Algorithm 2 works in polynomial time and in expectation is a GLYPH<0> 1 -43 \ud835\udc58 -1 / 4 -\ud835\udc42 ( \ud835\udc58 -1 / 2 ) GLYPH<1> -approximation to the integral BSP for any position auction. The proof of Theorem 4.5 is deferred to Appendix B.2. Since SW ( z ) \u2264 OPT , by running the rounding algorithm a few times and taking the best produced solution, we get a slightly worse approximation guarantee of ( 1 -\ud835\udc42 ( \ud835\udc58 -1 / 4 )) OPT with high probability.", "5 NUMERICAL EXPERIMENTS": "Wefocus on testing welfare maximization Bidder Selection Problem for position auctions. In our experiments, we used synthetically generated prior distributions, as (1) the BSP is a pure optimization problem, which ignores the issue of data retrieval (2) due to companies' strict nondisclosure rules, it is infeasible to experiment on real historical data. We generally followed the AuctionGym [13] setup, a popular online simulation environment for advertising auctions run by Amazon, in the design of our synthetic data. Implementation. We implemented Algorithms 1 and 2 as well as its modified version for BSP. In this simpler modification, we used a slightly different objective g SW ( x ) def == \u222b +\u221e 0 Hpois ( x , \ud835\udf0f ) d \ud835\udf0f than (8): we did not fix any small bidder set, only applied Poisson approximation, and used the same rounding step. The original Algorithm 1 was designed with the worst-case theoretical guarantees in mind, while the modified one is more practically oriented and retains only the most important Poisson approximation. The modification did not affect the run-time much, but allowed us to avoid hard-coded approximation loss of \ud835\udc42 ( \ud835\udc58 -1 / 4 ) due to the potentially suboptimal decision of fixing a small bidder set \ud835\udc46 fix . We implemented the practical variant in Python with the help of Gurobi [11], a well-known commercial convex optimization solver, and present its comparison 11 with benchmark algorithms in Table 1. Benchmarks. Ideally, we would like to compare our solutions to the optimum, which is usually not possible, as BSP is an NP-hard problem even for the case of single-item auction [9]. It is also infeasible to use any of the existing PTAS algorithms, as only [6] implemented their PTAS but could only run experiments on tiny input sizes of ( \ud835\udc5b = 9 , \ud835\udc58 = 3 ) , while EPTASes of [17, 22] are pure computational complexity results with unrealistically large estimates on running times for inputs of any size. Instead, we used two well-known heuristic algorithms as our benchmarks: Greedy for submodular maximization following numerical experiments in [6, 17], and Local Search mentioned in [3]. They are easy to implement and run in feasible times on most of our datasets. Note that if Local Search starts with the solution produced by Greedy, it can only improve upon it, i.e., it seems reasonable to use Local Search as a main reference point for approximation efficiency guarantees. We also tested Local Search against the exact optimum computed by Brute Force on small instances ( \ud835\udc5b = 50 , \ud835\udc58 = 5 ) and found that they always produced the same results. We implemented Greedy, Local Search, and Brute Force in Python to ensure a fair comparison with our algorithm. We also limited the number of threads used by our algorithm to 1, as the benchmark algorithms are not parallelizable. Datasets. We generated each of the \ud835\udc5b prior distributions as a log-normal distribution Lognormal ( \ud835\udf07, \ud835\udf0e 2 ) as in AuctionGym [13]. We selected parameters \ud835\udf07 and \ud835\udf0e of each individual distribution by Table 1: Experimental results of Local Search, Greedy, and our algorithm. The 'solution' column for each algorithm denotes the average relative quality of the produced solution to that of the best-performing algorithm that terminated in 1 week. Error bars denote the standard deviation. The 'time' column denotes the average running time of each algorithm. drawing them independently from continuous uniform distributions U[ 0 , 0 . 2 ] and U[ 0 , 0 . 5 ] , respectively. 12 We then discretized each distribution to a common, finite support { 0 } \u222a { 1 + \ud835\udc56 50 | \ud835\udc56 = 0 , 1 , . . . , 49 } by moving probability mass on each discretized interval inside [ 0 , 2 ] to its left point and by redistributing the mass on ( 2 , +\u221e) to the discrete points, proportional to their respective probabilities. The weights w of the position auction on each instance were set as: \ud835\udc64 \ud835\udc56 = 1 for \ud835\udc56 \u2208 [ 1 , 0 . 2 \ud835\udc58 ] , \ud835\udc64 \ud835\udc56 = 0 . 2 for \ud835\udc56 \u2208 ( 0 . 2 \ud835\udc58, 0 . 6 \ud835\udc58 ] , and \ud835\udc64 \ud835\udc56 = 0 for \ud835\udc56 \u2208 ( 0 . 6 \ud835\udc58, \ud835\udc58 ] . We constructed datasets with 3 different \ud835\udc5b \u2208 { 50 , 200 , 1000 } . For each \ud835\udc5b , we used 3 different values of \ud835\udc58 : for \ud835\udc5b = 50, we set \ud835\udc58 \u2208 { 5 , 10 , 20 } ; for \ud835\udc5b = 200, we set \ud835\udc58 \u2208 { 10 , 20 , 40 } ; and for \ud835\udc5b = 1000, we set \ud835\udc58 \u2208 { 50 , 100 , 200 } . The general idea was to capture practically relevant scenarios of different scales, and also have our benchmarks solve them in a reasonable time. Moreover, we picked \ud835\udc58 so that it is always significantly smaller than \ud835\udc5b . Note that this puts our algorithm at a disadvantage, as our Poisson relaxation gets more accurate as \ud835\udc58 grows. Results. The numerical experiments are given in Table 1. We ran Local Search, Greedy, and our algorithm on all 9 combinations of \ud835\udc5b and \ud835\udc58 . We recorded the approximate efficiency ('solution' column) and the running time of each algorithm (if an algorithm did not terminate in 1 week, we would stop it and write 'N/A' for the respective dataset). We measure efficiency as the relative quality of the produced solution with respect to the solution of the bestperforming algorithm that terminated in 1 week on that test case. (1) As shown in Table 1, Greedy performs surprisingly well: on each generated dataset, it produced solutions within 5% of the best-performing algorithm. It is much better than the ( 1 -1 / \ud835\udc52 ) -approximation guarantee for general submodular maximization. Similar observations have been made in [17]. (2) Our modified algorithm produced solutions that were always within 0.1% of the solution of the best-performing algorithm and also had very small variance. I.e., our algorithm is effective and consistently produces good results. Moreover, its effectiveness improves as the problem size \ud835\udc58 grows, which concurs with our theoretical analysis. (3) The running time is the most crucial parameter in the context of BSP, as the optimization algorithm must stop within strict time limits and approximate efficiency is only a secondary objective. According to Table 1, the running time of our algorithm scales much slower than that of Greedy and Local Search with \ud835\udc5b and \ud835\udc58 . The time complexities of Greedy and one iteration of Local Search are both \ud835\udc42 ( \ud835\udc5b\ud835\udc58 3 \u00b7 | Support |) . When \ud835\udc58 is constant ( \ud835\udc58 = 5), this time complexity is linear in \ud835\udc5b , but even then our algorithm has comparable running time and when \ud835\udc58 = \u0398 ( \ud835\udc5b ) , it is much faster than the benchmarks.", "6 CONCLUDING REMARKS": "In this paper, we studied a more general setting of position auction than all previous work on the Bidder Selection Problem. We proposed a new relaxation that can be solved in time polynomial in \ud835\udc5b and \ud835\udc58 , and the polynomial is rather small. The proposed Poisson approximation approach is much simpler than previous PTAS complexity results for \ud835\udc58 -MAX or non-adaptive probing, and it can be implemented in practice. We also did extensive numerical experiments on inputs with practically relevant sizes and observed that our algorithm outperforms some commonly used heuristics, such as Greedy for general submodular maximization. Furthermore, we showed that the Poisson approximation approach also yields good theoretical guarantees. Namely, that BSP becomes solvable in polynomial time for any fixed \ud835\udf00 , when the problem size \ud835\udc58 grows. Our algorithm is the first one with a nearly perfect efficiency guarantee of PTAS, that is relevant in the application domain of the BSP and can be used by a company. Indeed, all previous PTASes had enormous running times and high implementation complexities that made them completely irrelevant to the problem, which was motivated by getting a speedup of \ud835\udc5b / \ud835\udc58 magnitude. A natural next step would be to consider BSP of various auction environments under richer sets of feasibility constraints such as matroid, matching, and intersection of matroids. Another interesting direction is to identify conditions where it is possible to efficiently optimize the revenue of BSP for VCG/GSP auction formats.", "REFERENCES": "[1] MOSEK ApS. 2022. The MOSEK optimization toolbox for MATLAB manual. Version 10.0. MOSEK. http://docs.mosek.com/10.0/toolbox/index.html [2] Nikhil Bansal and Maxim Sviridenko. 2006. The Santa Claus Problem. In Proceedings of the 38th Annual ACM Symposium on Theory of Computing, Seattle, WA, USA, May 21-23, 2006 (Seattle, WA, USA) (STOC '06) . Association for Computing Machinery, New York, NY, USA, 31-40. https://doi.org/10.1145/1132516.1132522 [3] Xiaohui Bei, Nick Gravin, Pinyan Lu, and Zhihao Gavin Tang. 2023. Bidder Subset Selection Problem in Auction Design. In Proceedings of the 2023 ACMSIAM Symposium on Discrete Algorithms, SODA 2023, Florence, Italy, January 22-25, 2023 , Nikhil Bansal and Viswanath Nagarajan (Eds.). SIAM, 3788-3801. https://doi.org/10.1137/1.9781611977554.ch147 [4] Anand Bhalgat and Sanjeev Khanna. 2014. A Utility Equivalence Theorem for Concave Functions. In Integer Programming and Combinatorial Optimization , Jon Lee and Jens Vygen (Eds.). Springer International Publishing, Cham, 126-137. [5] Andrei Z. Broder, David Carmel, Michael Herscovici, Aya Soffer, and Jason Zien. 2003. Efficient Query Evaluation Using a Two-Level Retrieval Process. In Proceedings of the Twelfth International Conference on Information and Knowledge Management (New Orleans, LA, USA) (CIKM '03) . Association for Computing Machinery, New York, NY, USA, 426-434. https://doi.org/10.1145/956863.956944 [6] Wei Chen, Wei Hu, Fu Li, Jian Li, Yu Liu, and Pinyan Lu. 2016. Combinatorial Multi-Armed Bandit with General Reward Functions. In Advances in Neural Information Processing Systems , Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon, and Roman Garnett (Eds.), Vol. 29. Curran Associates Inc., Red Hook, NY, USA, 1651-1659. https://proceedings.neurips.cc/paper/2016/ hash/aa169b49b583a2b5af89203c2b78c67c-Abstract.html [7] D. J. Daley and D. Vere-Jones. 2008. An introduction to the theory of point processes. Vol. II: General Theory and Structure (second ed.). Springer, New York. https: //link.springer.com/book/10.1007/978-0-387-49835-5 [8] Benjamin Edelman, Michael Ostrovsky, and Michael Schwarz. 2007. Internet Advertising and the Generalized Second-Price Auction: Selling Billions of Dollars Worth of Keywords. American Economic Review 97, 1 (March 2007), 242-259. https://doi.org/10.1257/aer.97.1.242 [9] Ashish Goel, Sudipto Guha, and Kamesh Munagala. 2010. How to probe for an extreme value. ACM Trans. Algorithms 7, 1 (2010), 12:1-12:20. https://doi.org/10. 1145/1868237.1868250 [10] Gagan Goel, Renato Paes Leme, Jon Schneider, David Thompson, and Hanrui Zhang. 2023. Eligibility Mechanisms: Auctions Meet Information Retrieval. In Proceedings of the ACM Web Conference 2023 (Austin, TX, USA) (WWW '23) . Association for Computing Machinery, New York, NY, USA, 3541-3549. https: //doi.org/10.1145/3543507.3583478 [11] Gurobi Optimization, LLC. 2023. Gurobi Optimizer Reference Manual. [12] Jason Hartline. [n. d.]. Mechanism Design and Approximation. http:// jasonhartline.com/MDnA/. Accessed: 2022-01-10. [13] Olivier Jeunen, Sean Murphy, and Ben Allison. 2023. Off-Policy Learning-toBid with AuctionGym. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 4219-4228. [14] Jon Kleinberg and Maithra Raghu. 2018. Team Performance with Test Scores. ACM Trans. Econ. Comput. 6, 3-4, Article 17 (oct 2018), 26 pages. https://doi.org/ 10.1145/3274644 [15] Jian Li and Amol Deshpande. 2019. Maximizing Expected Utility for Stochastic Combinatorial Optimization Problems. Mathematics of Operations Research 44, 1 (February 2019), 354-375. https://doi.org/10.1287/moor.2017.0927 [16] Jian Li and Wen Yuan. 2013. Stochastic Combinatorial Optimization via Poisson Approximation. In Proceedings of the Forty-Fifth Annual ACM Symposium on Theory of Computing (Palo Alto, California, USA) (STOC '13) . Association for Computing Machinery, New York, NY, USA, 971-980. https://doi.org/10.1145/ 2488608.2488731 [17] Aranyak Mehta, Uri Nadav, Alexandros Psomas, and Aviad Rubinstein. 2020. Hitting the high notes: Subset selection for maximizing expected order statistics. Advances in Neural Information Processing Systems 33 (2020), 15800-15810. [18] S.Y. Novak. 2011. Extreme Value Methods with Applications to Finance . CRC Press, Boca Raton. [19] S. Y. Novak. 2019. Poisson approximation. Probability Surveys 16 (2019), 228 276. https://doi.org/10.1214/18-PS318 [20] Ariel D. Procaccia, Sashank Jakkam Reddi, and Nisarg Shah. 2012. A Maximum Likelihood Approach For Selecting Sets of Alternatives. In Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence, Catalina Island, CA, USA, August 14-18, 2012 , Nando de Freitas and Kevin P. Murphy (Eds.). AUAI Press, Corvallis, Oregon, 695-704. https://dslpitt.org/uai/displayArticleDetails. jsp?mmnu=1&smnu=2&article_id=2333&proceeding_id=28 [21] Zhou Rong and Zhixue Lu. 2007. Two-stage procurement auction with bidders of asymmetric capacity. Systems Engineering-Theory & Practice 27, 12 (2007), 36-41. [22] Danny Segev and Sahil Singla. 2021. Efficient Approximation Schemes for Stochastic Probing and Prophet Problems. In EC '21: The 22nd ACM Conference on Economics and Computation, Budapest, Hungary, July 18-23, 2021 , P\u00e9ter Bir\u00f3, Shuchi Chawla, and Federico Echenique (Eds.). ACM, New York, NY, USA, 793794. https://doi.org/10.1145/3465456.3467614 [23] Guofu Tan. 1992. Entry and R & D in procurement contracting. Journal of Economic Theory 58, 1 (1992), 41-60. [24] Hal Varian. 2007. Position auctions. International Journal of Industrial Organization 25, 6 (2007), 1163-1178. https://EconPapers.repec.org/RePEc:eee:indorg:v: 25:y:2007:i:6:p:1163-1178 [25] Hal R. Varian and Christopher Harris. 2014. The VCG Auction in Theory and Practice. American Economic Review 104, 5 (May 2014), 442-45. https://doi.org/ 10.1257/aer.104.5.442 [26] Jiajin Yu and Shabbir Ahmed. 2016. Maximizing expected utility over a knapsack constraint. Operations Research Letters 44, 2 (2016), 180-185.", "A POISSON AND CHERNOFF APPROXIMATION OF BERNOULLI OBJECTIVE": "In this section, we present approximation guarantees for Bernoulli objective term by the Poisson and Chernoff objectives. Poisson approximation is the central idea of this paper. It is defined in Section 4 as: We also will solve a special case of fractional Bidder Selection Problem for \u2113 -unit auction to demonstrate how Poisson approximation can be useful. In particular, we will assume that each bidder's value has only \u2264 \ud835\udeff probability to be nonzero. Our main goal here will be to illustrate our approach and analysis ideas rather than to derive independent results for this special case. Approximation Guarantees. There are many known Poisson approximation results (see, e.g., a survey [19]) for the sum of independent Bernoulli random variables, e.g., in total variation, earth mover's, uniform (a.k.a. Kolmogorov) distances. These are typically absolute approximation guarantees, while we need relative approximations similar to Chernoff approximations from Lemma A.3. As our goal is to handle small probability tail events, we assume that each bidder's value \ud835\udc63 \ud835\udc56 has only a small probability \ud835\udeff to be greater than zero, i.e., \u2200 \ud835\udc56 \u2208 [ \ud835\udc5b ] , Pr [ \ud835\udc63 \ud835\udc56 > 0 ] \u2264 \ud835\udeff . The following Poisson absolute approximation result will be useful to us: Lemma A.1 ([7, Lemma 11.3.V, p . 162]). Let ( \ud835\udc67 \ud835\udc56 \u223c Ber ( \ud835\udc5e \ud835\udc56 )) \ud835\udc5b \ud835\udc56 = 1 be \ud835\udc5b independent Bernoulli random variables with \ud835\udc5e \ud835\udc56 \u2264 \ud835\udeff for \u2200 \ud835\udc56 \u2208 [ \ud835\udc5b ] . Let \ud835\udc4d def == \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc67 \ud835\udc56 and \ud835\udc4c \u223c Pois ( \ud835\udf06 ) , where \ud835\udf06 def == \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc5e \ud835\udc56 . Then With Lemma A.1 we can derive relative approximations: Lemma A.2. Suppose q \u2208 [ 0 , \ud835\udeff ] \ud835\udc5b and \u2113 \u2208 N . Then Proof. (a). Let \ud835\udc67 \ud835\udc56 \u223c Ber ( \ud835\udc5e \ud835\udc56 ) be Bernoulli random variables and \ud835\udc4d = \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc67 \ud835\udc56 be their sum. Then we can rewrite H ber ( q , \u2113 ) = E [ min ( \ud835\udc4d, \u2113 )] = \u02dd \u2113 \ud835\udc57 = 1 Pr [ \ud835\udc4d \u2265 \ud835\udc57 ] . Also let \ud835\udc66 \ud835\udc56 \u223c Pois ( \ud835\udc5e \ud835\udc56 ) and define \ud835\udc4c = \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc66 \ud835\udc56 . Clearly, \ud835\udc4c \u223c Pois ( \ud835\udf06 ) for \ud835\udf06 = \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc5e \ud835\udc56 . Then H pois ( q , \u2113 ) = E [ min ( \ud835\udc4c, \u2113 )] = \u02dd \u2113 \ud835\udc57 = 1 Pr [ \ud835\udc4c \u2265 \ud835\udc57 ] . Hence, we have The RHS is similar to the earth mover's distance between the sum of Bernoulli and Poisson random variables (the difference is that the summation instead of +\u221e goes only up to \u2113 ). Next, we shall prove the following inequality: which together with Lemma A.3 (a) immediately implies the desired result: We consider two cases. First, when \ud835\udf06 \u2265 \u2113 . Then for any \ud835\udc57 \u2208 N + we have by (10) Second, when min ( \ud835\udf06, \u2113 ) = \ud835\udf06 < \u2113 , we use instead the earth mover's distance \ud835\udc51 G ( \ud835\udc4d,\ud835\udc4c ) = \u02dd +\u221e \ud835\udc57 = 0 | Pr [ \ud835\udc4d \u2265 \ud835\udc57 ] -Pr [ \ud835\udc4c \u2265 \ud835\udc57 ]| . We do not calculate the cumulative density functions of \ud835\udc4d = \u02dd \ud835\udc5b \ud835\udc56 \ud835\udc67 \ud835\udc56 and \ud835\udc4c = \u02dd \ud835\udc5b \ud835\udc56 \ud835\udc66 \ud835\udc56 , but get an upper bound by coupling individual \ud835\udc67 \ud835\udc56 and \ud835\udc66 \ud835\udc56 . Specifically, we couple \ud835\udc67 \ud835\udc56 and \ud835\udc66 \ud835\udc56 so that \ud835\udc67 \ud835\udc56 = 0 implies \ud835\udc66 \ud835\udc56 = 0 (note that Pr [ \ud835\udc67 \ud835\udc56 = 0 ] = 1 -\ud835\udc5e \ud835\udc56 \u2264 Pr [ \ud835\udc66 \ud835\udc56 = 0 ] = \ud835\udc52 -\ud835\udc5e \ud835\udc56 ). Conversely, if \ud835\udc67 \ud835\udc56 = 1 it is matched with all \ud835\udc66 \ud835\udc56 = 1 , 2 , . . . and the remaining probability for \ud835\udc66 \ud835\udc56 = 0. Then we have Since \ud835\udc67 \ud835\udc56 = 0 is matched to \ud835\udc66 \ud835\udc56 = 0, we get the following expression for the term E [| \ud835\udc67 \ud835\udc56 -\ud835\udc66 \ud835\udc56 |] , where the first inequality holds, since Pr [ \ud835\udc67 \ud835\udc56 = 1 \u2227 \ud835\udc66 \ud835\udc56 = 0 ] = ( Pr [ \ud835\udc66 \ud835\udc56 = 0 ] -Pr [ \ud835\udc67 \ud835\udc56 = 0 ]) = \ud835\udc52 -\ud835\udc5e \ud835\udc56 -1 + \ud835\udc5e \ud835\udc56 \u2264 \ud835\udc5e 2 \ud835\udc56 / 2 and Pr [ \ud835\udc66 \ud835\udc56 = \ud835\udc57 ] = \ud835\udc52 -\ud835\udc5e \ud835\udc56 \ud835\udc5e \ud835\udc57 \ud835\udc56 / \ud835\udc57 ! \u2264 \ud835\udc5e 2 \ud835\udc56 / 2 \ud835\udc57 -1 for \ud835\udc57 \u2265 2. Therefore, which concludes the proof. (b). As \u2113 = 1, H ber ( q , 1 ) = 1 -\u02db \ud835\udc5b \ud835\udc56 = 1 ( 1 -\ud835\udc5e \ud835\udc56 ) def == 1 -\ud835\udc52 -\ud835\udc60 , where \ud835\udc60 = -\u02dd \ud835\udc5b \ud835\udc56 = 1 ln ( 1 -\ud835\udc5e \ud835\udc56 ) . Let \ud835\udf06 = \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc5e \ud835\udc56 , then H pois ( q , 1 ) = 1 -\ud835\udc52 -\ud835\udf06 . Observe that \ud835\udc5e \ud835\udc56 \u2264 -ln ( 1 -\ud835\udc5e \ud835\udc56 ) \u2264 \ud835\udc5e \ud835\udc56 1 -\ud835\udc5e \ud835\udc56 \u2264 \ud835\udc5e \ud835\udc56 1 -\ud835\udeff . Thus \ud835\udf06 \u2264 \ud835\udc60 \u2264 \ud835\udf06 1 -\ud835\udeff . The former inequality implies the desired lower bound H ber ( q , 1 ) -Hpois ( q , 1 ) \u2265 0. To prove the required upper bound, observe that H ber ( q , 1 ) = \ud835\udc53 ( \ud835\udc60 ) , Hpois ( q , 1 ) = \ud835\udc53 ( \ud835\udf06 ) for \ud835\udc53 ( \ud835\udc61 ) = 1 -\ud835\udc52 -\ud835\udc61 . As \ud835\udc53 ( \ud835\udc61 ) is a concave function with \ud835\udc53 ( 0 ) = 0, we have \ud835\udc53 ( \ud835\udf06 ) \u2265 \ud835\udc53 ( \ud835\udc60 ) \u00b7 \ud835\udf06 \ud835\udc60 \u2265 \ud835\udc53 ( \ud835\udc60 ) \u00b7 ( 1 -\ud835\udeff ) . Thus H ber ( q , 1 ) -Hpois ( q , 1 ) = \ud835\udc53 ( \ud835\udc60 ) -\ud835\udc53 ( \ud835\udf06 ) \u2264 \ud835\udeff \u00b7 \ud835\udc53 ( \ud835\udc60 ) = \ud835\udeff \u00b7 Hber ( q , 1 ) , which concludes the proof. \u25a1 Algorithm for Small Tail Probabilities. Assume that each bidder's value \ud835\udc63 \ud835\udc56 has at most \ud835\udeff probability to be greater than zero. Then Lemma A.2 and Claim 4.2 (Concavity of Poisson) suggest Algorithm 3.", "Algorithm 3: Approximation to Fractional BSP for Tail Probabilities \u2113 -unit Auctions.": "Return the optimal solution e x \u2217 to the concave program: We can solve the above program efficiently via standard concave function maximization methods, as the objective g SW is concave in x . Indeed, from Claim 4.2 we know that H pois ( q , \u2113 ) is concave in q and, since q ( x , \ud835\udf0f ) is linear in x for every fixed \ud835\udf0f , Hpois is also concave in x . As g SW ( x , \u2113 ) is an integral (non-negative linear combination) of H pois ( q ( x , \ud835\udf0f ) , \u2113 ) , g SW is concave in x . From Lemma A.2, we obtain the following approximation guarantees of SW ( x , \u2113 ) by g SW ( x , \u2113 ) . Let x \u2217 be the best solution of the original problem (1). We have Hence, Algorithm 3 is ( 1 -35 \ud835\udeff ) -approximation. Chernoff Approximation Guarantees. We recall the following definitions Our main algorithm needs the following approximation guarantee of H cher : Lemma A.3. For all q \u2208 [ 0 , 1 ] \ud835\udc5b , \u2113 \u2208 N + , let \ud835\udf06 = \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc5e \ud835\udc56 , the following properties hold. In order to prove Lemma A.3, we first prove the following two auxiliary lemmas. Lemma A.4. For all q \u2208 [ 0 , 1 ] \ud835\udc5b , \u2113 \u2208 N + , let \ud835\udf06 = \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc5e \ud835\udc56 , the following properties hold. Proof of Lemma A.4. (a). Since \u2113 \u2265 1, We have the following lower bound on H ber ( q , \u2113 ) \u00ab \u2039 (b). If \ud835\udf06 \u2265 1, there exists q \u2032 \u2208 [ 0 , 1 ] \ud835\udc5b such that \ud835\udc5e \u2032 \ud835\udc56 \u2264 \ud835\udc5e \ud835\udc56 , \u2200 \ud835\udc56 \u2208 { 1 , 2 , . . . , \ud835\udc5b } and \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc5e \u2032 \ud835\udc56 = 1. Using Lemma A.4 (a), we can see that Hber ( q \u2032 , \u2113 ) \u2265 0 . 5. Then H ber ( q , \u2113 ) \u2265 Hber ( q \u2032 , \u2113 ) \u2265 0 . 5 . (c). As \u2113 \u2265 \ud835\udf06 , we have H cher ( q , \u2113 ) = \ud835\udf06 . Then We apply Chernoff bound to each tail probability \ud835\udc4d \u2265 \ud835\udc56 under the sum. Thus (d). By Lemma A.4 (c) Note that inside the last summation, \ud835\udeff ( \ud835\udc56 ) \u2265 \ud835\udefc and \ud835\udeff ( \ud835\udc56 ) 2 + \ud835\udeff ( \ud835\udc56 ) \u2265 \ud835\udefc 2 + \ud835\udefc \u2265 \ud835\udefc 3 . Therefore, As the summation in the right hand side becomes a geometric series, we get The last inequality holds as 1 -\ud835\udc52 -\ud835\udc65 \u2265 \ud835\udc65 / 2 for \ud835\udc65 \u2208 [ 0 , 1 ] . Hence, Lemma A.4 (d) holds. (e). If \u2113 \u2264 \ud835\udf06 , then H cher ( q , \u2113 ) = \u2113 . We have We again apply Chernoff bound for each tail event \ud835\udc4d \u2264 \ud835\udc56 under summation and get (f). By Lemma A.4 (e), we have The summation in the right hand side is again a geometric series, which allows us to get Hence Lemma A.4 (f) holds. Proof. When \ud835\udefc, \ud835\udc65 > 0, the function -\ud835\udc65 2 2 \ud835\udefc + \ud835\udc65 is decreasing in \ud835\udc65 . Therefore, Now we are ready to prove Lemma A.3. Lemma A.3. For all q \u2208 [ 0 , 1 ] \ud835\udc5b , \u2113 \u2208 N + , let \ud835\udf06 = \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc5e \ud835\udc56 , the following properties hold. Proof of Lemma A.3. (a). As min { \ud835\udc61, \u2113 } is a concave function in \ud835\udc61 , the Jensen inequality gives us which gives the first inequality. To prove the second inequality we consider the following 4 cases: \u00b7 If \ud835\udf06 \u2264 1, we use Lemma A.4 (a) to get H ber ( q , \u2113 ) \u2265 \ud835\udf06 GLYPH<16> 1 -1 2 \ud835\udf06 GLYPH<17> \u2265 1 2 \ud835\udf06 \u2265 1 2 \u00b7 Hcher ( q , \u2113 ) . \u00b7 If \ud835\udf06 > 1 and min ( \ud835\udf06, \u2113 ) \u2264 3 . 5, then Lemma A.4 (b) gives us H ber ( q , \u2113 ) \u2265 1 2 \u2265 1 7 \u00b7 min ( \ud835\udf06, \u2113 ) = 1 7 \u00b7 Hcher ( q , \u2113 ) . \u00b7 If min ( \ud835\udf06, \u2113 ) > 3 . 5 and \u2113 \u2265 \ud835\udf06 , then Lemma A.4 (c) gives us We apply Claim A.5 for \ud835\udefc = \ud835\udf06 and get H cher ( q , \u2113 ) -Hber ( q , \u2113 ) \u2264 0 . 85 \ud835\udf06, which implies that H ber ( q , \u2113 ) \u2265 0 . 15 \u00b7 Hcher ( q , \u2113 ) for Hcher ( q , \u2113 ) = \ud835\udf06 \u2264 \u2113 . \u00b7 If min ( \ud835\udf06, \u2113 ) > 3 . 5 and \ud835\udf06 \u2265 \u2113 , then Lemma A.4 (e) gives us H cher ( q , \u2113 ) -Hber ( q , \u2113 ) \u2264 \u2113 -1 \u02dd \ud835\udc56 = 0 \ud835\udc52 -1 2 \ud835\udf06 ( \ud835\udf06 -\ud835\udc56 ) 2 . Note that 1 2 \ud835\udf06 ( \ud835\udf06 -\ud835\udc56 ) 2 \u2265 1 2 \u2113 ( \u2113 -\ud835\udc56 ) 2 , when \ud835\udf06 \u2265 \u2113 \u2265 \ud835\udc56 . Thus By applying Claim A.5 with \ud835\udefc = \u2113 , we get H cher ( q , \u2113 ) -Hber ( q , \u2113 ) \u2264 0 . 85 \u2113, which implies that H ber ( q , \u2113 ) \u2265 0 . 15 \u00b7 Hcher ( q , \u2113 ) , as Hcher ( q , \u2113 ) = \u2113 \u2264 \ud835\udf06 . In all 4 cases, 7H ber ( q , \u2113 ) \u2265 Hcher ( q , \u2113 ) . (b). Let \ud835\udf00 def == 1 \u221a \ud835\udf06 . We consider three cases to show that H cher ( q , \u2113 ) -Hber ( q , \u2113 ) \u2264 3 \ud835\udf00 \u00b7 Hcher ( q , \u2113 ) , then combine it with the inequality 7H ber ( q , \u2113 ) \u2265 Hcher ( q , \u2113 ) from Lemma A.3 (a) to conclude the proof. Without loss of generality, we may assume that \ud835\udf00 < 1 / 3. \u00b7 If \u2113 \u2265 \ud835\udf06 , then Lemma A.4 (d) for \ud835\udefc = 1 . 8 \ud835\udf00 , gives us H cher ( q , \u2113 ) -Hber ( q , \u2113 ) \u2264 2 . 94 \ud835\udf00\ud835\udf06 = 2 . 94 \ud835\udf00 \u00b7 Hcher ( q , \u2113 ) . \u25a1 \u00b7 If \u2113 \u2264 3 4 \ud835\udf06 , then by Lemma A.4 (e) we have where the first inequality holds because \ud835\udf06 -\ud835\udc56 \u2265 \ud835\udf06 / 4; the second inequality holds, as H cher ( q , \u2113 ) = \u2113 and \ud835\udc52 -\ud835\udc65 / \ud835\udc50 \u221a \ud835\udc65 \u2264 \ud835\udc52 -1 / 2 \u221a\ufe01 \ud835\udc50 / 2 for all \ud835\udc65, \ud835\udc50 > 0. \u00b7 If \u2113 \u2208 GLYPH<16> 3 4 \ud835\udf06, \ud835\udf06 GLYPH<17> , by Lemma A.4 (f) for \ud835\udefc = 1 . 8 \ud835\udf00 we have (c). Let \ud835\udf00 def == 1 \u221a \u2113 . We first prove H cher ( q , \u2113 ) -Hber ( q , \u2113 ) \u2264 5 \ud835\udf00 \u00b7 Hcher ( q , \u2113 ) by considering the following four cases. It implies the second bound when combined with inequality 7H ber ( q , \u2113 ) \u2265 Hcher ( q , \u2113 ) from Lemma A.3 (a). We may assume without loss of generality that \ud835\udf00 < 1 / 5. \u00b7 If \ud835\udf06 < 1 \u221a \u2113 , then H cher ( q , \u2113 ) = \ud835\udf06 and Lemma A.4 (a) gives us \u00b7 If \ud835\udf06 \u2208 [ 1 \u221a \u2113 , \u2113 3 ) , then H cher ( q , \u2113 ) = \ud835\udf06 and by Lemma A.4 (c) we have where the second inequality holds, as \ud835\udeff ( \ud835\udc56 ) = \ud835\udc56 -\ud835\udf06 \ud835\udf06 \u2265 2 for all \ud835\udc56 \u2265 \u2113 + 1 and \ud835\udf06 < \u2113 / 3. Furthermore, where to get the first inequality we simply use the formula for the sum of geometric progression and estimate \ud835\udc52 -\u2113 + 1 -\ud835\udf06 2 \u2264 \ud835\udc52 -\u2113 / 3 ; the second inequality holds, because \ud835\udc52 -\ud835\udc65 / \ud835\udc50 \u2264 \ud835\udc50 \u00b7 \ud835\udc52 -1 / \ud835\udc65 for any \ud835\udc65, \ud835\udc50 > 0; the last inequality holds, because H cher ( q , \u2113 ) = \ud835\udf06 \u2265 \ud835\udf00 = 1 / \u221a \u2113 . \u00b7 If \ud835\udf06 \u2208 [ \u2113 3 , \u2113 ] , then H cher ( q , \u2113 ) = \ud835\udf06 and by Lemma A.4 (d) for \ud835\udefc = 4 \ud835\udf00 ( \ud835\udefc < 1, since \ud835\udf00 \u2264 1 / 5) we get H cher ( q , \u2113 ) -Hber ( q , \u2113 ) \u2264 4 \ud835\udf00\ud835\udf06 + 6 4 \ud835\udf00 \ud835\udc52 -16 \ud835\udf00 2 \u00b7 \ud835\udf06 3 \u2264 4 . 77 \ud835\udf00\ud835\udf06 = 4 . 77 \ud835\udf00 \u00b7 Hcher ( q , \u2113 ) , where the second inequality holds, since \u2113 \u2264 3 \ud835\udf06 and 6 4 \ud835\udf00 \ud835\udc52 -16 \ud835\udf00 2 \u00b7 \ud835\udf06 3 = 3 \ud835\udf00\u2113 2 \ud835\udc52 -16 \u00b7 \ud835\udf06 3 \u2113 \u2264 9 \ud835\udf00\ud835\udf06 2 \ud835\udc52 -16 \u2113 9 \u2113 \u2264 0 . 77 \u00b7 \ud835\udf00\ud835\udf06 . \u00b7 If \ud835\udf06 > \u2113 , then by considering q \u2032 with \ud835\udc5e \u2032 \ud835\udc56 \u2264 \ud835\udc5e \ud835\udc56 and \u02dd \ud835\udc5b \ud835\udc56 = 1 \ud835\udc5e \u2032 \ud835\udc56 = \u2113 , we get H ber ( q ) \u2265 Hber ( q \u2032 ) and H cher ( q ) = Hcher ( q \u2032 ) = \u2113 . Then according to the previous case, H cher ( q , \u2113 ) -Hber ( q , \u2113 ) \u2264 Hcher ( q \u2032 , \u2113 ) -Hber ( q \u2032 , \u2113 ) \u2264 4 . 77 \ud835\udf00 \u00b7 Hcher ( q \u2032 , \u2113 ) = 4 . 77 \ud835\udf00 \u00b7 Hcher ( q , \u2113 ) . These bounds combined with inequality 7H ber ( q , \u2113 ) \u2265 Hcher ( q , \u2113 ) conclude the proof of (c). \u25a1", "B MISSING PROOFS": "", "B.1 Proof of Theorem 4.4": "Theorem 4.4. Algorithm 1 works in polynomial time and is a ( 1 -\ud835\udc42 ( \ud835\udf00 )) -approximation, i.e., ( 1 -43 \ud835\udc58 -1 / 4 ) -approximation to the fractional BSP for any position auction. Proof of Theorem 4.4. We first show that Algorithm 1 is polynomial. Indeed, step (1) works in polynomial time by Claim 4.3. For each \ud835\udf0f in the support of { \ud835\udc37 \ud835\udc56 } \ud835\udc56 \u2208[ \ud835\udc5b ] and x \ud835\udc40 we can efficiently calculate H cher (( x \ud835\udc40 , 1 \ud835\udc46 fix ) , \ud835\udf0f ) and G pois ( x \ud835\udc40 , \ud835\udf0f ) , which allows us to compute g SW ( x \ud835\udc40 ) in polynomial time. It is easy to see that g SW ( x \ud835\udc40 ) is a concave function in x \ud835\udc40 , as G pois is a non-negative linear combination of constant terms and concave functions H pois ( x \ud835\udc40 , \u2113 -\ud835\udc57, \ud835\udf0f ) , and H cher is a non-negative linear combination of concave functions H cher ( q ( x , \ud835\udf0f ) , \u2113 ) in x . Furthermore, given the representation of g SW ( x \ud835\udc40 ) as an integral of nice algebraic functions H cher and G pois , we can also compute all first and second order derivatives of g SW ( x \ud835\udc40 ) in polynomial time. This allows us to find the optimal solution e x \u2217 \ud835\udc40 to (9) in polynomial time using standard concave (first or second order) maximization methods. To get the stated approximation guarantee we first compare the original objective SW ( x \ud835\udc40 , 1 \ud835\udc46 fix ) in (4) with g SW ( x \ud835\udc40 ) and get the following Lemma. Lemma B.1. For any x = ( x \ud835\udc40 , 1 \ud835\udc46 fix ) with x \ud835\udc40 \u2208 [ 0 , 1 ] | \ud835\udc40 | and any weights vector w , Proof. We rewrite SW ( x , w ) for x = ( x \ud835\udc40 , 1 \ud835\udc46 fix ) in the same form as (8). We first compare the corresponding adjusted Bernoulli and Poisson terms. Observe that \ud835\udc5e \ud835\udc56 ( x , \ud835\udf0f ) \u2264 \ud835\udeff = \ud835\udf00 for each bidder \ud835\udc56 \u2208 \ud835\udc40 and threshold \ud835\udf0f > \ud835\udf02 according to condition (b) in Claim 4.3. Thus by Lemma A.2 (a), Next, we compare Chernoff and Bernoulli objectives (H cher and H ber ) for low range thresholds \ud835\udf0f \u2264 \ud835\udf02 . As both H cher ( q , w ) and H ber ( q , w ) are non-negative linear combinations of respective terms for \u2113 -unit auctions with \u02dd \ud835\udc56 \u2208[ \ud835\udc5b ] \ud835\udc5e \ud835\udc56 ( \ud835\udc65 \ud835\udc56 , \ud835\udf0f ) \u2265 \u2113 \u2217 for \ud835\udf0f \u2264 \ud835\udf02 , we get by Lemma A.3 (b) that Thus after combining the two bounds for high and low ranges of thresholds \ud835\udf0f we get which concludes the proof of Lemma B.1. \u25a1 We proceed the proof of Theorem 4.4 by letting x \u2217 be the optimal solution to fractional BSP in (4). Then, we consider x \u2217 + \u2208 R \ud835\udc5b \u2265 0 defined as x \u2217 + def == ( x \u2217 \ud835\udc40 , 1 \ud835\udc46 fix ) , so that x \u2217 + \u2ab0 x \u2217 . By Lemma B.1, for x = x \u2217 + , we have On the other hand, by Lemma B.1 for x = e x \u2217 we have where the second inequality holds, as e x \u2217 \ud835\udc40 is the optimal solution to (9) and \ud835\udc58 -\ud835\udf00 \u00b7 \ud835\udc58 \ud835\udc58 \u00b7 x \u2217 \ud835\udc40 is a feasible solution; the third inequality holds, as g SW ( x ) is a concave function in x ; the last inequality holds by the last lower bound on g SW ( x \u2217 \ud835\udc40 ) . Finally, as ( 1 -\ud835\udf00 ) ( 1 -21 \ud835\udf00 ) 1 + 21 \ud835\udf00 \u2265 1 - ( 1 + 2 \u00b7 21 ) \u00b7 \ud835\udf00 , which concludes the proof of the theorem. \u25a1", "B.2 Proof of Theorem 4.5": "Theorem 4.5. Algorithm 2 works in polynomial time and in expectation is a GLYPH<0> 1 -43 \ud835\udc58 -1 / 4 -\ud835\udc42 ( \ud835\udc58 -1 / 2 ) GLYPH<1> -approximation to the integral BSP for any position auction. Proof of Theorem 4.5. Recall that the social welfare SW ( \ud835\udc46 ) of a \u2113 -unit or position auction is submodular as a function of the invited set of bidders \ud835\udc46 . Claim B.2. The expected social welfare SW ( \ud835\udc46 ) for a set of bidders \ud835\udc46 \u2286 [ \ud835\udc5b ] in any \u2113 -unit or position auction is a submodular function of \ud835\udc46 . Analysis of Algorithm 2. Clearly, z is a feasible solution to the integral BSP. We will prove below that Algorithm 2 has almost the same approximation guarantee as Algorithm 1. Let us denote the optimal social welfare for integral BSP as OPT . Then the best solution x \u2217 to the fractional BSP (4) may have only higher welfare SW ( x \u2217 , w ) \u2265 OPT . Furthermore, since (4) is a multi-linear extension of the integral BSP, we have Our solution z suffers an additional loss when the sample vector y has more than \ud835\udc58 elements | y | 1 > \ud835\udc58 . On the other hand, for each given y with | y | 1 > \ud835\udc58 we have E z \u223c( y \ud835\udc58 ) [ SW ( z , w )] \u2265 \ud835\udc58 | y | 1 SW ( y , w ) , due to submodularity of SW ( y , w ) (here we use a standard fact about monotone non-negative submodular function \ud835\udc53 : a uniformly sampled subset \ud835\udc47 \u2282 \ud835\udc46 of given size | \ud835\udc47 | = \ud835\udc58 has E \ud835\udc47 [ \ud835\udc53 ( \ud835\udc47 )] \u2265 \ud835\udc58 | \ud835\udc46 | \ud835\udc53 ( \ud835\udc46 ) ). Thus Furthermore, as OPT = max \ud835\udc46 \u2286[ \ud835\udc5b ] : | \ud835\udc46 | = \ud835\udc58 SW ( \ud835\udc46, w ) we have OPT \u2265 E z \u223c( y \ud835\udc58 ) [ SW ( z , w )] \u2265 \ud835\udc58 | y | 1 SW ( y , w ) for each y with | y | 1 > \ud835\udc58 . Therefore, Claim B.3. Let x \u2208 [ 0 , 1 ] \ud835\udc5b with | x | 1 = \ud835\udc58 . Then \u02dd \ud835\udc56 \u2265 1 Pr y \u223c Ber ( x ) [| y | \u2265 \ud835\udc58 + \ud835\udc56 ] = \ud835\udc42 GLYPH<0> \u221a \ud835\udc58 GLYPH<1> . Proof of Claim B.3. By Chernoff bound, we have We further estimate this integral as This concludes the proof of Claim B.3. \u25a1 Claim B.3 allows us to conclude that Ey \u223c Ber ( x ) [ SW ( y , w ) -SW ( z , w )] = \ud835\udc42 GLYPH<0> 1 \u221a \ud835\udc58 GLYPH<1> \u00b7 OPT , i.e.,", "C BETTER ALGORITHM FOR SINGLE-ITEM AUCTION": "In Section 4, we studied the Bidder Selection Problem (BSP) for position auctions and obtained a GLYPH<0> 1 -\ud835\udc42 ( \ud835\udc58 -1 / 4 ) GLYPH<1> -approximate algorithm. In this section, we study the special case of single-item auction (i.e., \u2113 -unit auction with \u2113 = 1) as it was extensively studied in previous work, and give a better approximation ratio GLYPH<0> 1 -\ud835\udc42 ( \u221a\ufe01 ln \ud835\udc58 / \ud835\udc58 ) GLYPH<1> . Similar to Section 4.1, we fix a small set \ud835\udc46 fix of \ud835\udf00 \u00b7 \ud835\udc58 bidders, which affects the final approximation by at most ( 1 -\ud835\udf00 ) factor due to the submodularity of BSP as a set function of the invited bidders. Formally, recall that for the single-item auction We find the set of \ud835\udf00 \u00b7 \ud835\udc58 bidders \ud835\udc46 fix such that Prv \u223c D [\u2203 \ud835\udc56 \u2208 \ud835\udc46 fix : \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf02 ] \u2265 1 -\ud835\udf00 for the largest possible threshold \ud835\udf02 . This allows us to take care of thresholds \ud835\udf0f in a low range \ud835\udf0f \u2208 [ 0 , \ud835\udf02 ] by including \ud835\udc46 fix in the solution (i.e., make \ud835\udc65 \ud835\udc56 = 1 for all \ud835\udc56 \u2208 \ud835\udc46 fix ). Naturally, we want to pick bidders with higher probabilities Pr [ \ud835\udc63 \ud835\udc56 > \ud835\udf02 ] into \ud835\udc46 fix , which means that for the high range thresholds \ud835\udf0f > \ud835\udf02 we get the small probability property for each bidder \ud835\udc56 \u2209 \ud835\udc46 fix . This allows us to reduce BSP to the case of small probabilities tail events (Appendix A) for \ud835\udf0f > \ud835\udf02 and bidders \ud835\udc56 \u2208 [ \ud835\udc5b ] \\ \ud835\udc46 fix , which can be effectively solved by the Poisson approximation. Formally, we can get the following guarantees for \ud835\udc46 fix . Claim C.1 (Small Bidder Set). Let \ud835\udf00 \u2265 \u221a\ufe03 ln \ud835\udc58 \ud835\udc58 be a multiple of 1 / \ud835\udc58 . We can find in polynomial time a threshold \ud835\udf02 \u2265 0 and a set \ud835\udc46 fix \u2282 [ \ud835\udc5b ] of size | \ud835\udc46 fix | = \ud835\udf00 \u00b7 \ud835\udc58 , such that Proof. Recall that all distributions { \ud835\udc37 \ud835\udc56 } \ud835\udc56 \u2208[ \ud835\udc5b ] have finite support. Thus we can search through all thresholds \ud835\udf0f in polynomial time. There must be two consecutive threshold values \ud835\udf02 and \ud835\udf02 + > \ud835\udf02 such that the number of bidders |{ \ud835\udc56 : Pr [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf02 ] \u2265 \ud835\udf00 }| \u2265 \ud835\udf00 \u00b7 \ud835\udc58 with large tail probabilities Pr [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf02 ] \u2265 \ud835\udf00 is at least \ud835\udf00 \u00b7 \ud835\udc58 , but a similar number of bidders |{ \ud835\udc56 : Pr [ \ud835\udc63 \ud835\udc56 > \ud835\udf02 ] = Pr [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf02 +] \u2265 \ud835\udf00 }| < \ud835\udf00 \u00b7 \ud835\udc58 for the next threshold value \ud835\udf02 + is strictly less than \ud835\udf00 \u00b7 \ud835\udc58 . Let us place each bidder \ud835\udc56 with Pr [ \ud835\udc63 \ud835\udc56 > \ud835\udf02 ] \u2265 \ud835\udf00 into \ud835\udc46 fix and fill the remaining positions in \ud835\udc46 fix up to size \ud835\udf00 \u00b7 \ud835\udc58 (so that | \ud835\udc46 fix | = \ud835\udf00 \u00b7 \ud835\udc58 ) with bidders from { \ud835\udc56 : Pr [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf02 ] \u2265 \ud835\udf00 > Pr [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf02 +]} . Then, every bidder \ud835\udc56 \u2209 \ud835\udc46 fix has Pr [ \ud835\udc63 \ud835\udc56 > \ud835\udf02 ] = Pr [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf02 +] < \ud835\udf00 as required by condition (b). On the other hand, | \ud835\udc46 fix | = \ud835\udf00 \u00b7 \ud835\udc58 and Pr [ \ud835\udc63 \ud835\udc56 \u2265 \ud835\udf02 ] \u2265 \ud835\udf00 for every \ud835\udc56 \u2208 \ud835\udc46 fix , i.e., condition (a) is satisfied since where to get the second inequality, we used the fact that ( 1 -1 \ud835\udc65 ) \ud835\udc65 < \ud835\udc52 -1 for any \ud835\udc65 \u2265 1. After selecting such set \ud835\udc46 fix and threshold \ud835\udf02 , we are ready to give the complete description of Algorithm 4.", "Algorithm 4: Fractional BSP for Single-Item Auction.": "(1) Find ( \ud835\udf02, \ud835\udc46 fix ) as in Claim C.1. Set \ud835\udc65 \ud835\udc56 = 1 for \u2200 \ud835\udc56 \u2208 \ud835\udc46 fix . (2) For the remaining bidders \ud835\udc40 def == [ \ud835\udc5b ] \\ \ud835\udc46 fix let the Poisson approximation g SW ( x \ud835\udc40 ) be x \u2217 e x = ( 1 \ud835\udc46 fix \u2217 \u2217 \ud835\udc40 e ) e x \ud835\udc40 x \ud835\udc40 In the algorithm, we ignore thresholds \ud835\udf0f \u2208 [ 0 , \ud835\udf02 ] , as by taking \ud835\udc46 fix we have already achieved high success probability of at least 1 -1 \ud835\udc58 by Claim C.1. For the high range thresholds \ud835\udf0f > \ud835\udf02 , we first observe that as the result of fixing set \ud835\udc46 fix , the probability that there is a bidder with value greater than the threshold \ud835\udf0f becomes where \ud835\udc5f \ud835\udf0f is a constant that we can easily compute. Hence, we respectively adjust the Poisson approximation term e Hpois ( q \ud835\udc40 ) in the algorithm according to (13) (we slightly abuse notations by writing H pois ( q \ud835\udc40 ) instead of H pois ( q ) : for the coordinates \ud835\udc56 \u2209 \ud835\udc40 we let \ud835\udc5e \ud835\udc56 = 0). Theorem C.2. Algorithm 4 for single-item auction works in polynomial time and is a ( 1 -2 \ud835\udf00 ) -approximation, i.e., a GLYPH<0> 1 -\ud835\udc42 GLYPH<0>\u221a\ufe01 ln \ud835\udc58 / \ud835\udc58 GLYPH<1> GLYPH<1> -approximation to the fractional BSP. Proof. We first verify that Algorithm 4 is polynomial. Note that the step (1) works in polynomial time by Claim C.1. For each \ud835\udf0f in the support of \ud835\udc37 \ud835\udc56 we calculate in polynomial time the constants \ud835\udc5f \ud835\udf0f \u2208 [ 0 , 1 ] . Both e Hpois ( q \ud835\udc40 ) for each x \ud835\udc40 and \ud835\udf0f in the support and g SW ( x \ud835\udc40 ) for each x \ud835\udc40 can be computed in polynomial time. Moreover, all first and second order partial derivatives of g SW ( x \ud835\udc40 ) can be computed in the same way as the integral of respective derivatives of e Hpois ( x \ud835\udc40 ) . Furthermore, it is easy to see that g SW ( x \ud835\udc40 ) is a concave function in x \ud835\udc40 , since it is a positive linear combination of constant terms (such as ( 1 -1 / \ud835\udc58 ) \ud835\udf02 and \ud835\udc5f \ud835\udf0f ) and concave functions H pois ( x \ud835\udc40 ) according to Claim 4.2. Hence, we can find the optimal solution e x \u2217 \ud835\udc40 in polynomial time using standard concave (first or second order) maximization methods. To prove an approximation guarantee of 1 -2 \ud835\udf00 for Algorithm 4, we first derive the following approximations of SW ( x \ud835\udc40 , 1 \ud835\udc46 fix ) by g SW ( x \ud835\udc40 ) similar to (11) (but in a special case of \u2113 = 1). Proof. Recall that by (3) the Social Welfare SW ( x ) for x = ( x \ud835\udc40 , 1 \ud835\udc46 fix ) and \u2113 = 1 is For the low range \ud835\udf0f \u2208 [ 0 , \ud835\udf02 ] we have H ber ( q ( x , \ud835\udf0f )) \u2208 [ 1 -1 \ud835\udc58 , 1 ] due to the choice of \ud835\udc46 fix in Claim C.1. It is well approximated by the respective term GLYPH<16> 1 -1 \ud835\udc58 GLYPH<17> \ud835\udf02 in (12). , where is the solution to the concave program in : \u25a1 (3) Return , For the high range \ud835\udf0f > \ud835\udf02 , we apply Lemma A.2 (b) with \ud835\udeff = \ud835\udf00 and get the following bound: On the other hand, H ber ( q ) -e Hpois ( q ) \u2265 0, as H ber ( q \ud835\udc40 ) \u2265 Hpois ( q \ud835\udc40 ) by Lemma A.2 (b). Thus where the last equality holds since \ud835\udf00 \u2265 \u221a\ufe03 ln \ud835\udc58 \ud835\udc58 . \u25a1 Now we are ready to complete the proof of Theorem C.2. Let x \u2217 be the optimal solution to fractional BSP. We consider x \u2217 + \u2208 R \ud835\udc5b \u2265 0 defined as x \u2217 + def == ( x \u2217 \ud835\udc40 , 1 \ud835\udc46 fix ) , so that x \u2217 + \u2ab0 x \u2217 . Then, by Lemma C.3 for x = x \u2217 + we have On the other hand, by Lemma C.3 for x = e x \u2217 we have where the second inequality holds, as e x \u2217 \ud835\udc40 is the optimal solution to (14) and \ud835\udc58 -\ud835\udf00 \u00b7 \ud835\udc58 \ud835\udc58 \u00b7 x \u2217 \ud835\udc40 is a feasible solution; the third inequality holds, as g SW ( x ) is a concave function in x by Claim 4.2; the last inequality holds, as g SW ( x \u2217 \ud835\udc40 ) \u2265 ( 1 -\ud835\udf00 ) \u00b7 SW ( x \u2217 ) and ( 1 -\ud835\udf00 ) 2 \u2265 1 -2 \ud835\udf00 . This concludes the proof. \u25a1", "D ADDITIONAL ASPECTS OF THE NUMERICAL EXPERIMENTS": "", "D.1 Comparison between Our Theoretical and Modified Algorithms": "We compare the performance of the theoretical version and the modified version of our algorithm. Due to certain limitations on the convex objectives in Gurobi, we implemented the theoretical version of our algorithm in MATLAB with the help of another convex optimization library, Mosek [1], and ran it on the same set of test inputs as in Section 5. As the implementations are in different programming languages, we do not compare their running time and only compare their approximation efficiency. As shown in Table 2, we can see that the theoretical version of our algorithm performs slightly worse than the modified version. This is due to the potentially suboptimal decision of fixing a small bidder set \ud835\udc46 fix . This step is helpful when we analyze our algorithm theoretically, but it may not be optimal in practice. Therefore, we choose to use the modified version of our algorithm in Section 5.", "D.2 Notes on the Discretization": "Recall that in Section 5, we discretized each generated distribution to a common, finite support { 0 } \u222a { 1 + \ud835\udc56 50 | \ud835\udc56 = 0 , 1 , . . . , 49 } by moving probability mass on each discretized interval inside [ 0 , 2 ] to its left point and by redistributing the mass on ( 2 , +\u221e) to the discrete points, proportional to their respective probabilities. We picked this unusual discretization to make instances more challenging for Greedy, as without it Greedy and other heuristics like our algorithm produce solutions with nearly optimal approximation efficiency (over 99% for both algorithms). Indeed, two distributions in Table 2: Experimental results of Local Search, Greedy, and both the modified version and the theoretical version of our algorithm. For each algorithm, we show the average relative quality of the produced solution to that of the best-performing algorithm that terminated in 1 week. Error bars denote the standard deviation. a well-structured family of log-normal distributions are likely to have strong dominance relation: a distribution \ud835\udc37 1 = Lognormal ( \ud835\udf07 1 , \ud835\udf0e 2 1 ) is always preferable to \ud835\udc37 2 = Lognormal ( \ud835\udf07 2 , \ud835\udf0e 2 2 ) , whenever \ud835\udf07 1 \u2265 \ud835\udf07 2 and \ud835\udf0e 1 \u2265 \ud835\udf0e 2 . Our choice of discretization was solely based on the comparison between Greedy and Local Search, i.e., after a few empirical trials of different discretizations we simply stopped once the average efficiency of Greedy was less than 99% that of the Local Search."}
