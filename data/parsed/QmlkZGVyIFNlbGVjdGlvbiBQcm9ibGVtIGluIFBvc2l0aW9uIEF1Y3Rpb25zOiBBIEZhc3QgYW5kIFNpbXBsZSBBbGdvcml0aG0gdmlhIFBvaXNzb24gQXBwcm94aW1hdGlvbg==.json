{
  "Bidder Selection Problem in Position Auctions: A Fast and Simple Algorithm via Poisson Approximation": "Nikolai Gravin âˆ— nikolai@mail.shufe.edu.cn Shanghai University of Finance and Economics Shanghai, China Yixuan Even Xu âˆ— xuyx20@mails.tsinghua.edu.cn Tsinghua University Beijing, China Renfei Zhou âˆ— zhourf20@mails.tsinghua.edu.cn Tsinghua University Beijing, China",
  "ABSTRACT": "In the Bidder Selection Problem (BSP) there is a large pool of ğ‘› potential advertisers competing for ad slots on the user's web page. Due to strict computational restrictions, the advertising platform can run a proper auction only for a fraction ğ‘˜ < ğ‘› of advertisers. We consider the basic optimization problem underlying BSP: given ğ‘› independent prior distributions, how to efficiently find a subset of ğ‘˜ with the objective of either maximizing expected social welfare or revenue of the platform. We study BSP in the classic multi-winner model of position auctions for welfare and revenue objectives using the optimal (respectively, VCG mechanism, or Myerson's auction) format for the selected set of bidders. This is a natural generalization of the fundamental problem of selecting ğ‘˜ out of ğ‘› random variables in a way that the expected highest value is maximized. Previous PTAS results ([Chen, Hu, Li, Li, Liu, Lu, NIPS 2016], [Mehta, Nadav, Psomas, Rubinstein, NIPS 2020], [Segev and Singla, EC 2021]) for BSP optimization were only known for single-item auctions and in case of [Segev and Singla 2021] for ğ‘™ -unit auctions. More importantly, all of these PTASes were computational complexity results with impractically large running times, which defeats the purpose of using these algorithms under severe computational constraints. We propose a novel Poisson relaxation of BSP for position auctions that immediately implies that 1) BSP is polynomial-time solvable up to a vanishingly small error as the problem size ğ‘˜ grows; 2) there is a PTAS for position auctions after combining our relaxation with the trivial brute force algorithm. Unlike all previous PTASes, we implemented our algorithm and did extensive numerical experiments on practically relevant input sizes. First, our experiments corroborate the previous experimental findings of Mehta et al. that a few simple heuristics used in practice (e.g., Greedy for general submodular maximization) perform surprisingly well in âˆ— The authors contributed equally to this research. The full version of this paper is available at https://arxiv.org/abs/2306.10648. Nikolai Gravin is supported by Science and Technology Innovation 2030 'New Generation of Artificial Intelligence' Major Project No.(2018AAA0100903), National Key R&D Program of China (2023YFA1009500), NSFC grants 62150610500, 61922052, and 61932002, Innovation Program of Shanghai Municipal Education Commission, and Fundamental Research Funds for Central Universities. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WWW'24, May 13-17, 2024, Singapore, Singapore Â© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0171-9/24/05...$15.00 https://doi.org/10.1145/3589334.3645418 terms of approximation factor. Furthermore, our algorithm outperforms Greedy both in running time and approximation on medium and large-sized instances, i.e., its running time scales better with the instance size.",
  "CCS CONCEPTS": "Â· Theory of computation â†’ Approximation algorithms analysis ; Algorithmic game theory and mechanism design ; Â· Applied computing â†’ Online auctions .",
  "KEYWORDS": "Bidder Selection, Submodular Maximization, Position Auctions",
  "ACMReference Format:": "Nikolai Gravin, Yixuan Even Xu, and Renfei Zhou. 2024. Bidder Selection Problem in Position Auctions: A Fast and Simple Algorithm via Poisson Approximation. In Proceedings of the ACM Web Conference 2024 (WWW '24), May 13-17, 2024, Singapore, Singapore. ACM, New York, NY, USA, 19 pages. https://doi.org/10.1145/3589334.3645418",
  "1 INTRODUCTION": "Online advertising is a big part of the modern e-commerce industry and a key to the monetization of many online businesses. The majority of ad slots on a user web page are sold in real time via an automated auction to a group of candidate advertisers. The whole process from the time when an auction is initiated based on the impression about advertising opportunity up to the time when ads are displayed on the user's page usually has to be completed in a few milliseconds. This makes it imperative for the platform (Ad exchange ADX, or Demand side DSP) to keep the auction processing and communication time under a strict limit. Meanwhile, a platform usually runs a complex ML model on each advertiser to get an accurate estimate of their auction score 1 . As some platforms already have or anticipate to have in the near future an excessive number of prospective advertisers, the comprehensive ML model can only be run on a fraction ğ‘˜ of ğ‘› advertisers due to strict time 2 limit. In practice, the platform handles this by a two-stage selection process: it filters out all but ğ‘˜ advertisers by running a much faster and less accurate ML model, and then it runs a proper auction for the remaining ğ‘˜ advertisers using the comprehensive and slow ML model. E.g., for the ADX platforms ğ‘› may be in the range 20 -50 and ğ‘˜ depends on the specific company, e.g., ğ‘˜ = 10 or ğ‘˜ = 20; in the case of DSPs, ğ‘› may vary a lot and can reach thousands, while ğ‘˜ cannot be too large, e.g., ğ‘˜ = 100 or ğ‘˜ = 200. 1 An auction score is comprised of estimates for click-through-rate (CTR), ad relevance, and value-per-click bid. 2 In some case, the platform may also estimate the bids to avoid communication lag. WWW'24, May 13-17, 2024, Singapore, Singapore Nikolai Gravin, Yixuan Even Xu, and Renfei Zhou This raises multiple practical challenges for the ADX and/or DSP platforms. A platform first needs to get ğ‘› rough score estimates, which can be viewed as ğ‘› distributions of the bidders' accurate auction scores. One problem is how to obtain these estimates online in a constantly changing environment. Another learning problem, recently considered by Goel et al. [10] is how to retrieve this information from strategic agents, who might affect the selection stage by adjusting their bids. Third, there is an underlying optimization question: for ğ‘› prospective bidders with known independent prior distributions ( ğ· ğ‘– ) ğ‘– âˆˆ[ ğ‘› ] how to select ğ‘˜ < ğ‘› of them with the objective of either maximizing expected score (social welfare) or platform's revenue. We focus on this basic optimization problem termed the Bidder Selection Problem (BSP). The welfare maximization BSP for the VCG single-item (or more generally â„“ -unit) auction is equivalent to the following fundamental algorithmic question: select ğ‘˜ out of ğ‘› independent random variables, with the objective of maximizing the expected maximum (expected sum of top â„“ values). This question (for single-item) has received significant attention under different names: model-driven optimization [9], ğ‘˜ -MAX [6], team selection with test scores [14], subset selection for expected maximum [17], non-adaptive ProbeMax [22], which extends to the topâ„“ -out-ofğ‘˜ problem. It is also natural to consider the selection problem with a more general set of objectives given by linear combinations of the topâ„“ objectives. The latter problem generalizes â„“ -unit auctions and corresponds to the widely used position auction [8, 24] environment as described, e.g., in [12]. In position auction, there are ğ‘š sorted positions that appear alongside the search results and ğ‘› advertisers competing for these ğ‘š slots. Each slot ğ‘— âˆˆ [ ğ‘š ] has a different click-through rate ğ‘¤ ğ‘— (additional multiplicative factor for the click probability on ğ‘— -th position), which translates into the value ğ‘£ ğ‘– Â· ğ‘¤ ğ‘— for advertiser ğ‘– if ğ‘– 's ad is displayed at ğ‘— -th position. Prior Results for the BSP. The basic BSP of welfare maximization (second-price auction) was shown to be NP-hard by Goel et al. [9] and later by Mehta et al. [17]. On the positive side, there are a few known Polynomial Time Approximation Schemes (PTAS). First, Chen et al. [6] gave a dynamic programming-based polynomial time approximation scheme (PTAS). Later, Mehta et al. [17] and Segev and Singla [22] respectively proposed an Efficient PTAS (EPTAS) for the BSP. Both of their approaches are based on discretizing and enumerating all possible distributions for the maximum of a few random variables: [17] characterize all ğ‘› distributions into one of ğ¶ ( ğœ€ ) bins (where ğ¶ ( ğœ€ ) = ğ‘‚ ( 1 / ğœ€ ) ğ‘‚ ( 1 / ğœ€ ) depends on the approximation guarantee 1 -ğœ€ ) and then run a brute force search with the complexity of ğ‘‚ GLYPH<16> ğ‘› Â· log ( ğ‘˜ ) ğ‘‚ ( ğ¶ ( ğœ€ ) ) GLYPH<17> ; [22] use a complex reduction to a multi-dimensional extension of Santa Claus problem of [2] with at least ğ‘‚ ( 1 / ğœ€ ) ğ‘‚ ( 1 / ğœ€ ) ğ‘‚ ( 1 / ğœ€ 2 ) running time 3 . We would like to emphasize that the findings of Mehta et al. and Segev and Singla could only be considered as purely computational complexity results rather than real algorithms to be used in practice or even in testing/numerical experiments. Indeed, their approaches are rather involved and not very easy to implement, e.g., Segev and 3 We give a lower bound on the running time, as it is hard to say what is the exact time complexity of their approach, as they did not specify it explicitly and their result proceeds by a sequence of reductions with non-trivial running time dependencies. Singla only state an existential result without explicitly describing their algorithm. Furthermore, the running times of these EPTASes even for the basic ğ‘˜ -MAX problem and small values of ğ‘› and ğ‘˜ are enormously large 4 . I.e., using any of the existing PTASes would completely defeat the purpose of a two-stage selection process. For the revenue objective, Mehta et al. [17] also considered BSP for the second-price auction, which is equivalent to maximizing the expectation of the second largest value among selected ğ‘˜ random variables. They showed strong impossibility results: it is impossible to get any constant factor approximation in polynomial time under either of the exponential time, or the planted clique hypothesises. Auction Formats. One of the most commonly used formats in advertising industry is the Generalized Second Price (GSP) auction. It was shown in [8, 24] that GSP of any position auction with any set of bidders has a Nash equilibrium equivalent to the welfaremaximizing outcome of the VCG. In some cases (e.g., Google's auction for selling contextual ads [25]) the platform's auction format is based directly on the VCG. Thus, in the BSP context with the welfare-maximization objective, it is most natural to analyze the VCG mechanism. For the revenue objective, it is natural to study the optimal Myerson's auction, as it gives an upper bound on the revenue of any other auction format. Then one can reduce revenue maximization to welfare maximization of the VCG format. I.e., it is w.l.o.g. to only study welfare-maximization BSP for the VCG format, which we do in the rest of our paper. It is also natural to study revenue maximization BSP for the GSP format (or by the revenue equivalence of the VCG format). Unfortunately, it does not admit polynomial time ğ‘‚ ( 1 ) -approximation even for the basic single-item auction due to strong impossibility results of [17].",
  "1.1 Our Results": "Wepropose a novel relaxation of the BSP for a more general position auction environment, which we call Poisson (or Poisson-Chernoff) relaxation. It has the following theoretical guarantees. (1) The relaxation is a continuous maximization problem with a concave objective that can be solved in time polynomial in ğ‘› and ğ‘˜ . In fact, the objective of this relaxation is a nicely structured algebraic function that lends itself to efficient convex minimization solvers. (2) With small adjustments (summarized in Algorithm 1), the relaxed objective converges at the rate 1 -ğ‘‚ ( ğ‘˜ -1 / 4 ) to the actual social welfare of fractional BSP as the problem size ğ‘˜ grows (Theorem 4.4). The standard rounding of this fractional solution suffers only a small loss of ğ‘‚ ( ğ‘˜ -1 / 2 ) , yielding GLYPH<0> 1 -ğ‘‚ ( ğ‘˜ -1 / 4 ) GLYPH<1> -approximation (Theorem 4.5) for the integral BSP. (3) For the special case of the single-item auction, our algorithm achieves 1 -ğ‘‚ GLYPH<0> âˆšï¸ ln ğ‘˜ / ğ‘˜ GLYPH<1> approximation (see Appendix C). These results have immediate theoretical implications and can be implemented in practice unlike all previous PTAS algorithms, as our approach has far superior running time to the point where it outperforms some of the existing heuristics used in practice, such as the Greedy algorithm for general submodular maximization. 4 Note that ğ‘˜ -MAX is a special case of general submodular optimization which already admits efficient 1 -1 / ğ‘’ approximation. Hence, ğœ€ < 1 / ğ‘’ and the time complexity of 2 Î˜ ( 1 / ğœ€ ) Î˜ ( 1 / ğœ€ ) > 2 9000 with conservative estimates of Î˜ ( 1 / ğœ€ ) = 2 / ğœ€ . Bidder Selection Problem in Position Auctions WWW'24, May 13-17, 2024, Singapore, Singapore Furthermore, our results bring new theoretical insight for BSP: the BSP converges to a polynomial-time solvable optimization problem as the problem size ğ‘˜ grows. Theoretical Implications. Our Algorithm 1 gives a ( 1 -ğœ€ ) approximation to the BSP for any position auction with ğœ€ = Î© ( ğ‘˜ -1 / 4 ) and works in polynomial time (independent of ğœ€ ). On the other hand, for small values of ğœ€ ( ğœ€ = ğ‘‚ ( ğ‘˜ -1 / 4 ) ), a straightforward exhaustive search algorithm gives a perfect solution in ğ‘‚ ( ğ‘› ğ‘˜ ) = ğ‘› poly ( 1 / ğœ€ ) time. I.e., the combination of our relaxation with the brute force algorithm yields a PTAS: Corollary 1.1. BSP for any position auction admits a ( 1 -ğœ€ ) PTAS that runs in ğ‘› poly ( 1 / ğœ€ ) time. Moreover, the algorithm as in Corollary 1.1 is an EPTAS with a much better dependency on ğœ€ than previous PTASes under a mild assumption that ğ‘˜ â‰¥ log ğ‘› : Corollary 1.2. BSP for position auctions admits a ( 1 -ğœ€ ) EPTAS for any ğ‘˜ â‰¥ log ğ‘› that runs in ğ‘‚ ( poly ( ğ‘›, ğ‘˜ )) + 2 ğ‘‚ ( ğœ€ -8 ) time. Proof. Algorithm 1 runs in ğ‘‚ ( poly ( ğ‘›, ğ‘˜ )) . We run brute force only when ğœ€ = ğ‘‚ ( ğ‘˜ -1 / 4 ) , i.e., when ğ‘˜ 2 = ğ‘‚ ( ğœ€ -8 ) . Then its running time is not more than ğ‘› ğ‘˜ â‰¤ 2 ğ‘˜ 2 = 2 ğ‘‚ ( ğœ€ -8 ) , since ğ‘˜ â‰¥ log ğ‘› . â–¡ Comparison with Previous Theoretical Results. Our novel Poisson approximation approach yields more general theoretical results than previous work. E.g., as Segev and Singla [22] briefly mention how their scheme can be extended from ğ‘˜ -MAX (i.e., single-item auction) to â„“ -unit auctions, one may wonder if a similar approach also extends to the more general position auction environment. To the best of our knowledge, it does not. Indeed, their main idea is to consider two regimes for â„“ : small (a constant) â„“ < 1 / ğœ€ 3 , and large â„“ > 1 / ğœ€ 3 . They claim that the former case can be handled with a similar approach (maybe with a significantly worse dependency of the running time on ğœ€ than the case â„“ = 1), and in the later case, one can use concentration bounds similar to the (3) case described in Section 3.1. This argument cannot be used for the objective that is a linear combination of welfare in 1-unit and ğ‘˜ / 2-unit auctions. Relevance in Practice. Our relaxation is a white-box approach that can be easily adapted to different scenarios. E.g., if some bidders have to be included in the final solution (which is often the case in industry because of contract obligations), then our approach gives the same approximation with these additional constraints 5 . Also, depending on the type of problem instances, a few steps of our algorithm can be removed or simplified to fit the specific domain, which results in simpler and more efficient solutions. Furthermore, unlike the case with all previous PTASes, we actually implemented our algorithm and did numerical experiments on several generated data sets of practically relevant sizes. Note that a company cares much more about the implementability and running time of their algorithms rather than its theoretical approximation guarantees 6 , which has been the main focus of previous PTAS results. In contrast, our algorithm is not very complex and 5 In fact, the approximation guarantee holds not only for the global objective, but also for the surplus objective, i.e., the additional gain to welfare from the non-fixed bidders. 6 In the context of BSP any reasonable heuristic is preferable to a complex and slow algorithm with good approximation efficiency guarantees. is based on standard continuous convex maximization methods, which means that it is much easier to understand and adopt by a platform's product team. The experiments are summarized in Section 5. We slightly simplified our theoretical Algorithm 1 to avoid the hard-coded efficiency loss of ğ‘‚ ( ğ‘˜ -1 / 4 ) in the approximation. Weobserved that among all tested algorithms, our algorithm produced solutions that were always within 0.1% of the best-performing algorithm in terms of objective value. Furthermore, our algorithm's running time scales significantly slower than any other tested algorithm. For large instances where ğ‘› = 1000 , ğ‘˜ = 200, our algorithm took less than 1 minute to complete, while even Greedy (which is a subroutine in all previous PTASes) took more than 1 day and Local Search could not finish within 1 week. These findings demonstrate the practical relevance of our approach.",
  "1.2 Other Related Work": "Mehta et al. [17] mention a few other scenarios besides bidder selection with similar mathematical formulations. The applications range from a two-tier solution for scoring documents in a search result [5], to filtering initial proposals in procurement auctions [21, 23], to voting theory [20]. Bei at al. [3] studied BSP with the revenue objective under multiple auction formats including Myerson's auction and gave constant factor approximation for the second-price auction with anonymous reserve. They also introduced another optimization framework for the BSP under costs, which is more challenging than the BSP under capacity constraint. Poisson approximation is a well-developed technique from probability theory and statistics. A survey [19] mentions at least twenty different results on the basic question of approximating the sum of independent Bernoulli random variables by the Poisson distribution. In statistics, Poisson approximation is commonly used in Extreme Value Theory (EVT) with applications to structural and geological engineering, traffic prediction, and finance (see, e.g., a book [18]). It has also been used in theoretical computer science, e.g., [16] used Le Cam's Poisson approximation theorem for stochastic bin packing and knapsack problems and also for EUM introduced in [15]. In fact, the expected utility maximization (EUM) is closely related to our objective. EUM is formulated as choosing a feasible subset ğ‘† out of ğ‘› random variables ğ‘‹ 1 , . . . , ğ‘‹ ğ‘› to maximize E [ ğ‘¢ ( Ë ğ‘– âˆˆ ğ‘† ğ‘‹ ğ‘– )] , where ğ‘¢ is a given utility function. The problem has been studied under capacity [4] or other combinatorial constraints [15, 16, 26] with a non-linear (typically concave) utility function. The BSP for single-item auction, i.e., the ğ‘˜ -MAXproblem, has a similar objective E [ max ğ‘– âˆˆ ğ‘† { ğ‘‹ ğ‘– }] to EUM but with max operator instead of the sum. When the distributions of ğ‘‹ ğ‘– are unknown, EUM becomes an online learning problem. Chen et al. [6] gave the first PTAS for ğ‘˜ -MAX, but their main focus is on Combinatorial Multi-Armed Bandits.",
  "2 PRELIMINARIES": "A set of ğ‘› bidders wish to receive some service and each bidder ğ‘– âˆˆ [ ğ‘› ] has a private non-negative value ğ‘£ ğ‘– âˆˆ R â‰¥ 0 indicating how much they are willing to pay for it. We denote the vector of bidder values as v = ( ğ‘£ ğ‘– ) ğ‘– âˆˆ[ ğ‘› ] . By the revelation principle, we can restrict our attention to incentive compatible and individually rational singleround auctions A , where each bidder ğ‘– submits a sealed bid ğ‘ ğ‘– to the auctioneer. The auctioneer then decides on a feasible allocation WWW'24, May 13-17, 2024, Singapore, Singapore Nikolai Gravin, Yixuan Even Xu, and Renfei Zhou vector a ( b ) = ( ğ‘ ğ‘– ( b )) ğ‘– âˆˆ[ ğ‘› ] and payments p ( b ) = ( ğ‘ ğ‘– ( b )) ğ‘– âˆˆ[ ğ‘› ] . The incentive compatibility and individual rationality mean that by bidding truthfully ğ‘ ğ‘– = ğ‘£ ğ‘– , each bidder ğ‘– âˆˆ [ ğ‘› ] (a) maximizes her utility ğ‘¢ ğ‘– ( ğ‘ ğ‘– , b -ğ‘– ) def == ğ‘£ ğ‘– Â· ğ‘ ğ‘– ( ğ‘ ğ‘– , b -ğ‘– ) -ğ‘ ğ‘– ( ğ‘ ğ‘– , b -ğ‘– ) and (b) receives non-negative utility ğ‘¢ ğ‘– ( ğ‘£ ğ‘– , b -ğ‘– ) â‰¥ 0. The seminal VCG mechanism (a second-price auction in the case of single-item auction) is an example of incentive compatible mechanism that also maximizes social welfare SW ( a , v ) = Ë ğ‘› ğ‘– = 1 ğ‘ ğ‘– Â· ğ‘£ ğ‘– . Westudy auctions in the Bayesian setting, where we assume that bidder values are drawn independently from known prior distributions v âˆ¼ D = Ë› ğ‘– âˆˆ[ ğ‘› ] ğ· ğ‘– . We also use ğ· ğ‘– ( ğœ ) = Pr ğ‘£ ğ‘– âˆ¼ ğ· ğ‘– [ ğ‘£ ğ‘– â‰¤ ğœ ] to denote the cumulative distribution function. The auction designer is usually concerned about two objectives: the expected social welfare SW = Ev âˆ¼ D [ SW ( a ( v ) , v )] , and revenue Rev = Ev âˆ¼ D [ Ë ğ‘– âˆˆ[ ğ‘› ] ğ‘ ğ‘– ( v )] . The VCG mechanism maximizes the welfare on every valuation profile v , and thus maximizes SW in expectation for any prior D . The well-known Myerson's auction maximizes Rev. This auction reduces the problem of revenue maximization to virtual welfare maximization by transforming values ( ğ‘£ ğ‘– ) ğ‘– âˆˆ[ ğ‘› ] to virtual values ğœ‘ ğ‘– ( ğ‘£ ğ‘– ) for regular distribution ğ· ğ‘– and by doing ironing ğœ‘ ğ‘– ( ğ‘£ ğ‘– ) for irregular distribution ğ· ğ‘– . I.e., the expected revenue of Myerson's auction can be written as Rev = Ev [ SW ( a ( v ) , ğœ‘ ( v ))] for regular distributions and Rev = Ev [ SW ( a ( v ) , ğœ‘ ( v ))] for general distributions. Auction Environments. The single-item auction is an environment with the feasible allocations given by { a : Ë ğ‘– âˆˆ[ ğ‘› ] ğ‘ ğ‘– â‰¤ 1 } . A more general â„“ -unit auction environment for â„“ âˆˆ N is given by the feasibility constraints: Ë ğ‘– âˆˆ[ ğ‘› ] ğ‘ ğ‘– â‰¤ â„“ and ğ‘ ğ‘– âˆˆ [ 0 , 1 ] for all ğ‘– âˆˆ [ ğ‘› ] . A position auction environment further generalizes â„“ -unit auctions. It is specified by a sorted weight vector w = ( 1 â‰¥ ğ‘¤ 1 â‰¥ ğ‘¤ 2 â‰¥ . . . â‰¥ ğ‘¤ ğ‘› â‰¥ 0 ) , which represents the click-through rate probabilities for ğ‘› advert positions 7 . Every bidder may get at most one position and each advert position can be assigned to at most one advertiser. Formally, the feasibility allocations can be specified with an assignment function ğœ‹ : [ ğ‘› ] â†’ [ ğ‘› ] of ğ‘› advertisers to ğ‘› sorted slots as follows: { a : âˆƒ ğœ‹, ğ‘ ğ‘– âˆˆ [ 0 , ğ‘¤ ğœ‹ ( ğ‘– ) ] for all ğ‘– âˆˆ [ ğ‘› ]} . Bidder Selection. In the Bidder Selection Problem (BSP) the seller first decides ğ‘¥ ğ‘– âˆˆ { 0 , 1 } which bidders ğ‘– âˆˆ [ ğ‘› ] to invite to the auction. The selected set of bidders ğ‘† may not exceed a certain capacity ğ‘˜ â‰¥ | ğ‘† | , i.e., Ë ğ‘– âˆˆ[ ğ‘› ] ğ‘¥ ğ‘– â‰¤ ğ‘˜ . Then the auctioneer runs an optimal auction A for the set ğ‘† of invited bidders: VCG mechanism for the welfare objective, and Myerson for the revenue objective. Since revenue of the Myerson's auction can be rewritten as the expected virtual welfare with independent (ironed) virtual values ( ğœ‘ ğ‘– ( ğ‘£ ğ‘– ) : ğ‘£ ğ‘– âˆ¼ ğ· ğ‘– ) ğ‘– âˆˆ ğ‘† , the BSP for the revenue maximization is equivalent to the BSP for the welfare maximization. Thus it suffices to only consider the welfare maximization problem. Specifically, we denote by v âˆ¼ x Â· D the independent draws of ğ‘£ ğ‘– âˆ¼ ğ‘¥ ğ‘– Â· ğ· ğ‘– (i.e., ğ‘£ ğ‘– âˆ¼ ğ· ğ‘– when ğ‘¥ ğ‘– = 1, and ğ‘£ ğ‘– = 0 when ğ‘¥ ğ‘– = 0) for all ğ‘– âˆˆ [ ğ‘› ] , then the BSP of the VCG mechanism for any â„“ -unit/position auction 7 The number of available positions ğ‘š is usually smaller than the number of bidders ğ‘› , in which case we simply let ğ‘¤ ğ‘š + 1 = Â· Â· Â· = ğ‘¤ ğ‘› = 0. with weights w can be written as follows:   where ğ‘£ ( ğ‘– ) is the ğ‘– -th largest value among { ğ‘£ ğ‘– } ğ‘– âˆˆ[ ğ‘› ] . We want to obtain good approximation algorithms for these BSPs. I.e., we would like to find in polynomial time x âˆˆ { 0 , 1 } ğ‘› with | x | 1 â‰¤ ğ‘˜ such that Ev âˆ¼ x Â· D [ Ë â„“ ğ‘– = 1 ğ‘£ ( ğ‘– ) ] â‰¥ ( 1 -ğœ€ ) OPT ( â„“ ) and Ev âˆ¼ x Â· D [ Ë ğ‘› ğ‘– = 1 ğ‘¤ ğ‘– Â· ğ‘£ ( ğ‘– ) ] â‰¥ ( 1 -ğœ€ ) OPT ( w ) for a small ğœ€ > 0. To simplify the presentation, we assume that all distributions ( ğ· ğ‘– ) ğ‘– âˆˆ[ ğ‘› ] have finite supports and are given explicitly as the algorithm's input. It has been observed before that the BSP's objective is a monotone submodular function of the set ğ‘† = { ğ‘– : ğ‘¥ ğ‘– = 1 } of invited bidders, i.e., SW ( ğ‘† ) + SW ( ğ‘‡ ) â‰¥ SW ( ğ‘† âˆ© ğ‘‡ ) + SW ( ğ‘† âˆª ğ‘‡ ) for any ğ‘†,ğ‘‡ âŠ† [ ğ‘› ] . The same property holds for the â„“ -unit and position auctions with an almost identical proof (see [6]). Wealso consider the standard (in submodular optimization literature) multi-linear extension of the BSP objective. I.e., for a fractional x âˆˆ [ 0 , 1 ] ğ‘› , we invite each bidder ğ‘– to the auction independently with probability ğ‘¥ ğ‘– . We employ the same notation v âˆ¼ x Â· D as in the integral problem, where ğ‘£ ğ‘– âˆ¼ ğ‘¥ ğ‘– Â· ğ· ğ‘– means that we first decide whether to invite ğœ‰ ğ‘– âˆˆ { 0 , 1 } bidder ğ‘– according to a Bernoulli distribution ğœ‰ ğ‘– âˆ¼ Ber ( ğ‘¥ ğ‘– ) , then draw their value ğ‘£ ğ‘– âˆ¼ ğœ‰ ğ‘– Â· ğ· ğ‘– . The capacity constraint transforms into the bound on the expected number of invited bidders Ë ğ‘› ğ‘– = 1 ğ‘¥ ğ‘– â‰¤ ğ‘˜ . We describe this new mathematical formulation in Section 3. In Section 4, we first consider this fractional relaxation of BSP and we discuss in Section 4.2 how to obtain a good solution to the integral BSP from the fractional problem.",
  "3 NEWMATHEMATICAL FORMULATION": "In this section, we give a fractional relaxation of BSP. As the welfare of any position auction can be written as a linear combination of â„“ -unit auctions, we begin with a fractional relaxation of BSP for the â„“ -unit auction. Specifically, the expected social welfare with a fractional set of bidders x is SW ( x , â„“ ) = E v âˆ¼ x Â· D [ Ë â„“ ğ‘– = 1 ğ‘£ ( ğ‘– ) ] , where ğ‘£ ( ğ‘– ) denotes the ğ‘– -th largest value among { ğ‘£ ğ‘– } ğ‘– âˆˆ{ 1 , 2 ,...,ğ‘› } . Hence, the following mathematical program represents BSP for â„“ -unit auction:  As â„“ is fixed, whenever it is clear from the context, we will simply write SW ( x ) . Bernoulli Representation. We now derive an explicit formula for the social welfare SW ( x ) . Fixing a threshold ğœ , the expected number of bidders with values exceeding ğœ among the highest â„“ bidders is Ev âˆ¼ x Â· D [ min ( Ë ğ‘› ğ‘– = 1 I [ ğ‘£ ğ‘– â‰¥ ğœ ] , â„“ )] . Therefore, by integrating 8 over ğœ âˆˆ [ 0 , +âˆ) , we get  8 The function inside the integral is piece-wise constant, i.e., it is constant between consecutive values of the threshold ğœ in the supports of { ğ· ğ‘– } ğ‘– âˆˆ[ ğ‘› ] . Bidder Selection Problem in Position Auctions WWW'24, May 13-17, 2024, Singapore, Singapore Note that I [ ğ‘£ ğ‘– â‰¥ ğœ ] for ğ‘£ ğ‘– âˆ¼ ğ‘¥ ğ‘– Â· ğ· ğ‘– is a Bernoulli random variable, and Ev âˆ¼ x Â· D [ min ( Ë ğ‘› ğ‘– = 1 I [ ğ‘£ ğ‘– â‰¥ ğœ ] , â„“ )] is the minimum of a sum of independent Bernoulli random variables and â„“ . To simplify notations, we explicitly define the probabilities of Bernoulli random variables   Definition 3.1 (Bernoulli Objective). For a vector q âˆˆ [ 0 , 1 ] ğ‘› and â„“ , the Bernoulli objective term of q and â„“ is a function H ber ( q , â„“ ) :  Position Auctions. A position auction is given by a vector of nonnegative weights 9 w : ( ğ‘¤ 1 â‰¥ ğ‘¤ 2 â‰¥ Â· Â· Â· â‰¥ ğ‘¤ ğ‘› â‰¥ 0 ) . The highest social welfare we get from the set ğ‘† of invited bidders is Ë | ğ‘† | ğ‘– = 1 ğ‘£ ( ğ‘– ) Â· ğ‘¤ ğ‘– , where ğ‘£ ( 1 ) â‰¥ Â· Â· Â· â‰¥ ğ‘£ ( | ğ‘† | ) are ordered values of bidders in ğ‘† . Thus the expected social welfare for a fractional set x is  where ğ‘¤ ğ‘› + 1 def == 0. Then the respective fractional BSP program for position auctions is as follows.  We will often omit dependency on w in SW whenever it is clear from the context. We further consider the Bernoulli representation for position auctions:  As in (2), q ( x , ğœ ) represents the probabilities of each bidder's value exceeding ğœ . Hber ( q , w ) is called the Bernoulli objective term for position auctions.",
  "3.1 Overview of Our Approach": "The fractional relaxation (4) is still neither convex nor concave and thus is too unwieldy. The central idea of our paper is to use instead Poisson approximation to the Bernoulli objective terms Hber ( q ( x , ğœ ) , w ) . Specifically, we substitute each Bernoulli random variable ğ‘§ âˆ¼ Ber ( ğ‘ ) with ğ‘ = ğ‘ ğ‘– ( ğ‘¥ ğ‘– , ğœ ) by the Poisson random variable ğ‘¦ âˆ¼ Pois ( ğ‘ ) with the same expectation as ğ‘§ . We use the following Poisson objective term H pois ( q , â„“ ) to approximate H ber ( q , â„“ ) .  9 Usually weights are only for the first ğ‘˜ slots, as we only select a set of ğ‘˜ bidders. In this case, we simply assume that ğ‘¤ ğ‘˜ + 1 = . . . = ğ‘¤ ğ‘› = 0. The advantage of the Poisson approximation H pois ( q , â„“ ) is that the resulting functions H pois ( q , â„“ ) and H pois ( q , w ) are concave in q . This in turn allows us to efficiently solve the optimization problem for the Poisson approximation analogous to (4). This Poisson approximation works well 10 in the following situations. (1) Whentheprobabilities ğ‘ ğ‘– = ğ‘ ğ‘– ( ğ‘¥ ğ‘– , ğœ ) of ğ‘§ ğ‘– âˆ¼ Ber ( ğ‘ ğ‘– ) are small (i.e., ğ‘ ğ‘– â‰¤ ğ›¿, âˆ€ ğ‘– âˆˆ [ ğ‘› ] ). This allows us to handle the crucial contribution to the welfare comprised of small probability tail events for large thresholds ğœ . (2) When E [ Ë ğ‘› ğ‘– = 1 ğ‘§ ğ‘– ] is large (when thresholds ğœ are small). Indeed, by Chernoff bounds the sums of independent random variables (both Bernoulli and Poisson) Ë ğ‘› ğ‘– = 1 ğ‘§ ğ‘– and Ë ğ‘› ğ‘– = 1 ğ‘¦ ğ‘– are close to their expectations. In fact, we simply use Chernoff objective term H cher ( q , â„“ ) def == min GLYPH<0>Ë ğ‘› ğ‘– = 1 ğ‘ ğ‘– , â„“ GLYPH<1> instead of Poisson approximation in this case. (3) When â„“ is large. In this case, either the concentration inequality gives a good approximation when E [ Ë ğ‘› ğ‘– = 1 ğ‘§ ğ‘– ] = E [ Ë ğ‘› ğ‘– = 1 ğ‘¦ ğ‘– ] is large, or when this expectation is much smaller than â„“ then the probability that either of Ë ğ‘› ğ‘– = 1 ğ‘§ ğ‘– or Ë ğ‘› ğ‘– = 1 ğ‘¦ ğ‘– exceeds the threshold â„“ is small. Then the algorithmic framework for the BSP is rather straightforward. We need to solve the following concave program of x :  We define the approximate social welfare g SW ( x , w ) to be the objective of (6). Here, H pois ( q ( x , ğœ ) , â„“ ) = E ğ‘Œ âˆ¼ Pois ( Ë ğ‘ ğ‘– ) [ min ( ğ‘Œ, â„“ )] and all functions under the integral are piece-wise constant with the number of pieces bounded by the size of the union of the supports of ğ· ğ‘– . The optimal fractional solution x can be computed rather efficiently using continuous convex optimization. Finally, we use a rounding procedure (similar to the multi-linear extension of submodular function) to the fractional solution of (6) to obtain an integral solution with a small loss to the approximation guarantee.",
  "4 OUR ALGORITHM": "Poisson approximation is the central idea of this paper. We use the Poisson Objective to approximate Bernoulli objective terms. Definition 4.1 (Poisson Objective). For q âˆˆ [ 0 , 1 ] ğ‘› and â„“ âˆˆ N , the Poisson objective term is a function H pois ( q , â„“ ) given by  Note that the latter equality is an important property of Poisson distribution: the sum of independent Poisson random variables ğ‘¦ ğ‘– âˆ¼ Pois ( ğ‘ ğ‘– ) follows the Poisson distribution Pois ( Ë ğ‘› ğ‘– = 1 ğ‘ ğ‘– ) . Another crucial property is the concavity of Poisson approximation. Claim 4.2 (Concavity of Poisson). Hpois ( q , â„“ ) is a concave function in q âˆˆ [ 0 , 1 ] ğ‘› for âˆ€ â„“ âˆˆ N . 10 The sum of Poisson random variables approaches the sum of Bernoulli random variables in TV and other statistical distances. WWW'24, May 13-17, 2024, Singapore, Singapore Nikolai Gravin, Yixuan Even Xu, and Renfei Zhou Proof. Let ğœ† = Ë ğ‘› ğ‘– = 1 ğ‘ ğ‘– . Notice that H pois ( q , â„“ ) only depends on ğœ† , which is linear in q . We use H pois ( ğœ† ) to represent this function. Then, we only need to prove that H pois ( ğœ† ) is concave in ğœ† . Rewrite  By a straightforward differentiation of the partial series we get  Therefore, H pois ( q , â„“ ) is concave in ğœ† , and thus concave in q . â–¡ Chernoff Approximation. As we mentioned earlier Poisson approximation is useful for small probabilities ğ‘ ğ‘– â‰¤ ğ›¿ . For another extreme case where ğœ† = Ë ğ‘› ğ‘– = 1 ğ‘ ğ‘– is large, due to concentration bounds, Poisson approximation also works well with ğ‘‚ ( ğœ† -1 / 2 ) relative error, because both Ë ğ‘› ğ‘– = 1 Ber ( ğ‘ ğ‘– ) and Pois ( ğœ† ) concentrate around ğœ† . To optimize the presentation for an easier understanding, we will use Chernoff objective term Hcher ( q , â„“ ) def == min GLYPH<0>Ë ğ‘› ğ‘– = 1 ğ‘ ğ‘– , â„“ GLYPH<1> as an alternative of Poisson in this case. It is also concave in q . In a number of cases H pois ( q , â„“ ) and H cher ( q , â„“ ) are good approximations to H ber ( q , â„“ ) . In Appendix A, we present these approximation guarantees along with a simple algorithm that illustrates our approach in an important special case.",
  "4.1 Algorithm for Position Auctions": "Below, we consider Bidder Section Problem for position auctions. We first analyze the fractional BSP, and then explain in Section 4.2 how to do integral rounding of the fractional solution with only a small loss to the approximation guarantee. For the fractional BSP, we give an efficient polynomial time ( 1 -ğ‘‚ ( ğ‘˜ -4 )) -approximation algorithm (see Theorem 4.4 for the exact statement). Recall that the Bernoulli objective term for position auctions Hber ( q , w ) is defined in Section 3. The expected welfare SW ( x ) = SW ( x , w ) is written as an integral of H ber . Below, we will also need the Chernoff objective term  We sometimes slightly abuse notations and write H ber ( x , ğœ ) and Hcher ( x , ğœ ) instead of H ber ( q , w ) and H cher ( q , w ) . In order to effectively use the Poisson approximation we would like to have the small probability assumption ğ‘ ğ‘– â‰¤ ğ›¿ , which is achieved by fixing a small bidder set ğ‘† fix properly (see Appendix A for formal approximation guarantees). Fixing Small Bidder Set. We will fix a small set of bidders ğ‘† fix (set ğ‘¥ ğ‘– = 1 for ğ‘– âˆˆ ğ‘† fix ) with | ğ‘† fix | = ğœ€ Â· ğ‘˜ and make sure that all other bidders ğ‘– âˆ‰ ğ‘† fix have only a small probability Pr [ ğ‘£ ğ‘– â‰¥ ğœ ] â‰¤ ğ›¿ to exceed any of the thresholds ğœ > ğœ‚ for certain ğœ‚ > 0. This allows us to use Poisson approximation for the high range thresholds ğœ > ğœ‚ and bidders ğ‘– âˆˆ ğ‘€ def == [ ğ‘› ] \\ ğ‘† fix . On the other hand, for the low range thresholds ğœ â‰¤ ğœ‚ , we would like to see a certain number â„“ âˆ— of bidders ğ‘– âˆˆ ğ‘† fix to exceed the threshold ğ‘£ ğ‘– â‰¥ ğœ . To this end, we choose ğ‘† fix so that the expected number of bidders ğ‘– âˆˆ ğ‘† fix with ğ‘£ ğ‘– â‰¥ ğœ is at least â„“ âˆ— . We can achieve the following guarantees for ğœ€, ğ›¿, and â„“ âˆ— . Claim 4.3 (Small Bidder Set). Let ğœ€ âˆˆ [ â„“ âˆ— ğ›¿ Â· ğ‘˜ , 1 ) be a multiple of 1 / ğ‘˜ for â„“ âˆ— âˆˆ R â‰¥ 0 : â„“ âˆ— < ğ‘˜ and ğ›¿ âˆˆ ( 0 , 1 ) . We can find in polynomial time a threshold ğœ‚ â‰¥ 0 and a set ğ‘† fix âŠ† [ ğ‘› ] of size | ğ‘† fix | = ğœ€ Â· ğ‘˜ :  Proof. We search through all thresholds ğœ in the supports of { ğ· ğ‘– } ğ‘– â‰¥ 1 and find two consecutive threshold values ğœ‚ and ğœ‚ + > ğœ‚ such that |{ ğ‘– : Pr [ ğ‘£ ğ‘– â‰¥ ğœ‚ ] â‰¥ ğ›¿ }| â‰¥ ğœ€ Â· ğ‘˜ , but a similar number of bidders |{ ğ‘– : Pr [ ğ‘£ ğ‘– > ğœ‚ ] = Pr [ ğ‘£ ğ‘– â‰¥ ğœ‚ +] â‰¥ ğ›¿ }| < ğœ€ Â· ğ‘˜ for the next value ğœ‚ + . We place each bidder ğ‘– with Pr [ ğ‘£ ğ‘– > ğœ‚ ] â‰¥ ğ›¿ into ğ‘† fix and fill the remaining positions in ğ‘† fix up to ğœ€ Â· ğ‘˜ with bidders from { ğ‘– : Pr [ ğ‘£ ğ‘– â‰¥ ğœ‚ ] â‰¥ ğ›¿ > Pr [ ğ‘£ ğ‘– â‰¥ ğœ‚ +]} . Thus, every bidder ğ‘– âˆ‰ ğ‘† fix has Pr [ ğ‘£ ğ‘– > ğœ‚ ] = Pr [ ğ‘£ ğ‘– â‰¥ ğœ‚ +] < ğ›¿ as required by condition (b). On the other hand, | ğ‘† fix | = ğœ€ Â· ğ‘˜ and Pr [ ğ‘£ ğ‘– â‰¥ ğœ‚ ] â‰¥ ğ›¿ for every ğ‘– âˆˆ ğ‘† fix , which implies (a), since âˆ€ ğœ â‰¤ ğœ‚ ,  Thus we constructed in polynomial time the desired threshold ğœ‚ and set ğ‘† fix . â–¡ We need to balance three parameters â„“ âˆ— , ğ›¿ , and ğœ€ , which must satisfy the conditions of Claim 4.3. Specifically, we choose â„“ âˆ— = ğ‘˜ 1 / 2 , ğœ€ = ğ‘˜ -1 / 4 rounded up to a multiple of 1 / ğ‘˜ , and ğ›¿ = ğœ€ â‰¥ ğ‘˜ -1 / 4 . Claim 4.3 leads to Algorithm 1 (which we will present shortly). For thresholds ğœ > ğœ‚ , any bidder outside ğ‘† fix has only â‰¤ ğ›¿ probability to exceed the threshold, which is ideal for applying the Poisson approximation. Therefore, to achieve the approximation guarantees when the probability of exceeding the threshold is low, we recalculate the adjusted Poisson objective term by applying Poisson approximation only on these bidders. Specifically, we let ğ‘€ def == [ ğ‘› ] \\ ğ‘† fix and define ğ‘ fix ( ğœ ) def == Ë ğ‘– âˆˆ ğ‘† fix I [ ğ‘£ ğ‘– â‰¥ ğœ ] (as x ğ‘† fix = 1 ğ‘† fix , random variable ğ‘ fix ( ğœ ) has Poisson binomial distribution). Indeed, we may calculate all probabilities Pr [ ğ‘ fix ( ğœ ) = ğ‘— ] for each ğ‘— âˆˆ [ 0 , ğœ€ Â· ğ‘˜ ] in polynomial time, and define the adjusted Poisson objective term as a conditional expectation depending on ğ‘ fix ( ğœ ) :  where H pois ( x ğ‘€ , â„“ -ğ‘—, ğœ ) = E ğ‘Œ âˆ¼ Pois ( ğœ† ğ‘€ ) [ min { ğ‘Œ, â„“ -ğ‘— }] , and ğœ† ğ‘€ = Ë ğ‘– âˆˆ ğ‘€ ğ‘ ğ‘– ( ğ‘¥ ğ‘– , ğœ ) . For the low-range thresholds ğœ â‰¤ ğœ‚ , we use the Chernoff objective H cher ( x , ğœ ) = Hcher ( q ( x , ğœ ) , w ) to approximate Hber ( x , ğœ ) = Hber ( q ( x , ğœ ) , w ) for x = ( x ğ‘€ , 1 ğ‘† fix ) . Importantly, unlike the high-range thresholds, we do not recalculate H cher as a function of x ğ‘€ , but use Chernoff approximation for the entire ğ‘› -dimensional vector x = ( x ğ‘€ , x ğ‘† fix ) with x ğ‘† fix = 1 ğ‘† fix . Thus, as â„“ âˆ— = ğ‘˜ 1 / 2 grows with ğ‘˜ , Hcher ( x , ğœ ) â†’ Hber ( x , ğœ ) . Bidder Selection Problem in Position Auctions WWW'24, May 13-17, 2024, Singapore, Singapore",
  "Algorithm 1: Fractional BSP for Position Auctions": "Let â„“ âˆ— = ğ‘˜ 1 / 2 ; ğœ€ be ğ‘˜ -1 / 4 rounded up to a multiple of 1 / ğ‘˜ GLYPH<0> ğœ€ = âŒˆ ğ‘˜ Â· ğ‘˜ -1 / 4 âŒ‰ ğ‘˜ GLYPH<1> ; ğ›¿ = ğœ€ . (1) Find ğœ‚ and ğ‘† fix according to Claim 4.3. Set ğ‘¥ ğ‘– = 1 for âˆ€ ğ‘– âˆˆ ğ‘† fix . Let ğ‘€ def == [ ğ‘› ] \\ ğ‘† fix . (2) Define the approximate welfare using adjusted Poisson objective (7):  (3) Return e x âˆ— = ( e x âˆ— ğ‘€ , 1 ğ‘† fix ) , where e x âˆ— ğ‘€ is the solution to the concave program in x ğ‘€ :  Algorithm. Our main algorithm is summarized as Algorithm 1. Theorem 4.4. Algorithm 1 works in polynomial time and is a ( 1 -ğ‘‚ ( ğœ€ )) -approximation, i.e., ( 1 -43 ğ‘˜ -1 / 4 ) -approximation to the fractional BSP for any position auction. The proof of this theorem is deferred to Appendix B.1.",
  "4.2 Rounding": "Weconclude Section 4 by presenting the rounding algorithm, which takes our solution e x âˆ— to the fractional BSP produced by Algorithm 1 and returns a solution to the integral BSP. Our fractional relaxation works as the standard multi-linear extension of submodular functions, which corresponds to sampling a random set of bidders ğ‘† âˆ¼ Ë› ğ‘› ğ‘– = 1 Ber ( ğ‘¥ ğ‘– ) in the integral BSP. To align the notations for fractional and integral BSPs, we shall use vectors y , z âˆˆ { 0 , 1 } ğ‘› for the respective sets of selected bidders. Specifically, we use y âˆ¼ Ber ( x ) to represent the random set ğ‘† in the multi-linear extension. Our rounding procedure is in Algorithm 2.",
  "Algorithm 2: Rounding: algorithm for Integral BSP": "(1) Run Algorithm 1 to obtain a fractional solution x . (2) Sample an integral solution y âˆ¼ Ber ( x ) , with y âˆˆ { 0 , 1 } ğ‘› . (3) Â· If | y | 1 â‰¤ ğ‘˜ , return z = y , Â· Else ( | y | 1 > ğ‘˜ ), return ğ‘˜ bidders z âˆ¼ GLYPH<0> y ğ‘˜ GLYPH<1> chosen uniformly at random from y . Theorem 4.5. Algorithm 2 works in polynomial time and in expectation is a GLYPH<0> 1 -43 ğ‘˜ -1 / 4 -ğ‘‚ ( ğ‘˜ -1 / 2 ) GLYPH<1> -approximation to the integral BSP for any position auction. The proof of Theorem 4.5 is deferred to Appendix B.2. Since SW ( z ) â‰¤ OPT , by running the rounding algorithm a few times and taking the best produced solution, we get a slightly worse approximation guarantee of ( 1 -ğ‘‚ ( ğ‘˜ -1 / 4 )) OPT with high probability.",
  "5 NUMERICAL EXPERIMENTS": "Wefocus on testing welfare maximization Bidder Selection Problem for position auctions. In our experiments, we used synthetically generated prior distributions, as (1) the BSP is a pure optimization problem, which ignores the issue of data retrieval (2) due to companies' strict nondisclosure rules, it is infeasible to experiment on real historical data. We generally followed the AuctionGym [13] setup, a popular online simulation environment for advertising auctions run by Amazon, in the design of our synthetic data. Implementation. We implemented Algorithms 1 and 2 as well as its modified version for BSP. In this simpler modification, we used a slightly different objective g SW ( x ) def == âˆ« +âˆ 0 Hpois ( x , ğœ ) d ğœ than (8): we did not fix any small bidder set, only applied Poisson approximation, and used the same rounding step. The original Algorithm 1 was designed with the worst-case theoretical guarantees in mind, while the modified one is more practically oriented and retains only the most important Poisson approximation. The modification did not affect the run-time much, but allowed us to avoid hard-coded approximation loss of ğ‘‚ ( ğ‘˜ -1 / 4 ) due to the potentially suboptimal decision of fixing a small bidder set ğ‘† fix . We implemented the practical variant in Python with the help of Gurobi [11], a well-known commercial convex optimization solver, and present its comparison 11 with benchmark algorithms in Table 1. Benchmarks. Ideally, we would like to compare our solutions to the optimum, which is usually not possible, as BSP is an NP-hard problem even for the case of single-item auction [9]. It is also infeasible to use any of the existing PTAS algorithms, as only [6] implemented their PTAS but could only run experiments on tiny input sizes of ( ğ‘› = 9 , ğ‘˜ = 3 ) , while EPTASes of [17, 22] are pure computational complexity results with unrealistically large estimates on running times for inputs of any size. Instead, we used two well-known heuristic algorithms as our benchmarks: Greedy for submodular maximization following numerical experiments in [6, 17], and Local Search mentioned in [3]. They are easy to implement and run in feasible times on most of our datasets. Note that if Local Search starts with the solution produced by Greedy, it can only improve upon it, i.e., it seems reasonable to use Local Search as a main reference point for approximation efficiency guarantees. We also tested Local Search against the exact optimum computed by Brute Force on small instances ( ğ‘› = 50 , ğ‘˜ = 5 ) and found that they always produced the same results. We implemented Greedy, Local Search, and Brute Force in Python to ensure a fair comparison with our algorithm. We also limited the number of threads used by our algorithm to 1, as the benchmark algorithms are not parallelizable. Datasets. We generated each of the ğ‘› prior distributions as a log-normal distribution Lognormal ( ğœ‡, ğœ 2 ) as in AuctionGym [13]. We selected parameters ğœ‡ and ğœ of each individual distribution by 11 We also compared the performances of the modified version and the theoretical version of our algorithm in Appendix D.1. The approximation efficiency of the theoretical version was worse than the modified version as expected. WWW'24, May 13-17, 2024, Singapore, Singapore Nikolai Gravin, Yixuan Even Xu, and Renfei Zhou Table 1: Experimental results of Local Search, Greedy, and our algorithm. The 'solution' column for each algorithm denotes the average relative quality of the produced solution to that of the best-performing algorithm that terminated in 1 week. Error bars denote the standard deviation. The 'time' column denotes the average running time of each algorithm. drawing them independently from continuous uniform distributions U[ 0 , 0 . 2 ] and U[ 0 , 0 . 5 ] , respectively. 12 We then discretized each distribution to a common, finite support { 0 } âˆª { 1 + ğ‘– 50 | ğ‘– = 0 , 1 , . . . , 49 } by moving probability mass on each discretized interval inside [ 0 , 2 ] to its left point and by redistributing the mass on ( 2 , +âˆ) to the discrete points, proportional to their respective probabilities. The weights w of the position auction on each instance were set as: ğ‘¤ ğ‘– = 1 for ğ‘– âˆˆ [ 1 , 0 . 2 ğ‘˜ ] , ğ‘¤ ğ‘– = 0 . 2 for ğ‘– âˆˆ ( 0 . 2 ğ‘˜, 0 . 6 ğ‘˜ ] , and ğ‘¤ ğ‘– = 0 for ğ‘– âˆˆ ( 0 . 6 ğ‘˜, ğ‘˜ ] . We constructed datasets with 3 different ğ‘› âˆˆ { 50 , 200 , 1000 } . For each ğ‘› , we used 3 different values of ğ‘˜ : for ğ‘› = 50, we set ğ‘˜ âˆˆ { 5 , 10 , 20 } ; for ğ‘› = 200, we set ğ‘˜ âˆˆ { 10 , 20 , 40 } ; and for ğ‘› = 1000, we set ğ‘˜ âˆˆ { 50 , 100 , 200 } . The general idea was to capture practically relevant scenarios of different scales, and also have our benchmarks solve them in a reasonable time. Moreover, we picked ğ‘˜ so that it is always significantly smaller than ğ‘› . Note that this puts our algorithm at a disadvantage, as our Poisson relaxation gets more accurate as ğ‘˜ grows. Results. The numerical experiments are given in Table 1. We ran Local Search, Greedy, and our algorithm on all 9 combinations of ğ‘› and ğ‘˜ . We recorded the approximate efficiency ('solution' column) and the running time of each algorithm (if an algorithm did not terminate in 1 week, we would stop it and write 'N/A' for the respective dataset). We measure efficiency as the relative quality of the produced solution with respect to the solution of the bestperforming algorithm that terminated in 1 week on that test case. (1) As shown in Table 1, Greedy performs surprisingly well: on each generated dataset, it produced solutions within 5% of the best-performing algorithm. It is much better than the ( 1 -1 / ğ‘’ ) -approximation guarantee for general submodular maximization. Similar observations have been made in [17]. (2) Our modified algorithm produced solutions that were always within 0.1% of the solution of the best-performing algorithm and also had very small variance. I.e., our algorithm is effective and consistently produces good results. Moreover, its effectiveness improves as the problem size ğ‘˜ grows, which concurs with our theoretical analysis. 12 AuctionGym uses comparable ğœ‡ = 0 . 1 and ğœ = 0 . 2. (3) The running time is the most crucial parameter in the context of BSP, as the optimization algorithm must stop within strict time limits and approximate efficiency is only a secondary objective. According to Table 1, the running time of our algorithm scales much slower than that of Greedy and Local Search with ğ‘› and ğ‘˜ . The time complexities of Greedy and one iteration of Local Search are both ğ‘‚ ( ğ‘›ğ‘˜ 3 Â· | Support |) . When ğ‘˜ is constant ( ğ‘˜ = 5), this time complexity is linear in ğ‘› , but even then our algorithm has comparable running time and when ğ‘˜ = Î˜ ( ğ‘› ) , it is much faster than the benchmarks.",
  "6 CONCLUDING REMARKS": "In this paper, we studied a more general setting of position auction than all previous work on the Bidder Selection Problem. We proposed a new relaxation that can be solved in time polynomial in ğ‘› and ğ‘˜ , and the polynomial is rather small. The proposed Poisson approximation approach is much simpler than previous PTAS complexity results for ğ‘˜ -MAX or non-adaptive probing, and it can be implemented in practice. We also did extensive numerical experiments on inputs with practically relevant sizes and observed that our algorithm outperforms some commonly used heuristics, such as Greedy for general submodular maximization. Furthermore, we showed that the Poisson approximation approach also yields good theoretical guarantees. Namely, that BSP becomes solvable in polynomial time for any fixed ğœ€ , when the problem size ğ‘˜ grows. Our algorithm is the first one with a nearly perfect efficiency guarantee of PTAS, that is relevant in the application domain of the BSP and can be used by a company. Indeed, all previous PTASes had enormous running times and high implementation complexities that made them completely irrelevant to the problem, which was motivated by getting a speedup of ğ‘› / ğ‘˜ magnitude. A natural next step would be to consider BSP of various auction environments under richer sets of feasibility constraints such as matroid, matching, and intersection of matroids. Another interesting direction is to identify conditions where it is possible to efficiently optimize the revenue of BSP for VCG/GSP auction formats. Bidder Selection Problem in Position Auctions WWW'24, May 13-17, 2024, Singapore, Singapore",
  "REFERENCES": "[1] MOSEK ApS. 2022. The MOSEK optimization toolbox for MATLAB manual. Version 10.0. MOSEK. http://docs.mosek.com/10.0/toolbox/index.html [2] Nikhil Bansal and Maxim Sviridenko. 2006. The Santa Claus Problem. In Proceedings of the 38th Annual ACM Symposium on Theory of Computing, Seattle, WA, USA, May 21-23, 2006 (Seattle, WA, USA) (STOC '06) . Association for Computing Machinery, New York, NY, USA, 31-40. https://doi.org/10.1145/1132516.1132522 [3] Xiaohui Bei, Nick Gravin, Pinyan Lu, and Zhihao Gavin Tang. 2023. Bidder Subset Selection Problem in Auction Design. In Proceedings of the 2023 ACMSIAM Symposium on Discrete Algorithms, SODA 2023, Florence, Italy, January 22-25, 2023 , Nikhil Bansal and Viswanath Nagarajan (Eds.). SIAM, 3788-3801. https://doi.org/10.1137/1.9781611977554.ch147 [4] Anand Bhalgat and Sanjeev Khanna. 2014. A Utility Equivalence Theorem for Concave Functions. In Integer Programming and Combinatorial Optimization , Jon Lee and Jens Vygen (Eds.). Springer International Publishing, Cham, 126-137. [5] Andrei Z. Broder, David Carmel, Michael Herscovici, Aya Soffer, and Jason Zien. 2003. Efficient Query Evaluation Using a Two-Level Retrieval Process. In Proceedings of the Twelfth International Conference on Information and Knowledge Management (New Orleans, LA, USA) (CIKM '03) . Association for Computing Machinery, New York, NY, USA, 426-434. https://doi.org/10.1145/956863.956944 [6] Wei Chen, Wei Hu, Fu Li, Jian Li, Yu Liu, and Pinyan Lu. 2016. Combinatorial Multi-Armed Bandit with General Reward Functions. In Advances in Neural Information Processing Systems , Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon, and Roman Garnett (Eds.), Vol. 29. Curran Associates Inc., Red Hook, NY, USA, 1651-1659. https://proceedings.neurips.cc/paper/2016/ hash/aa169b49b583a2b5af89203c2b78c67c-Abstract.html [7] D. J. Daley and D. Vere-Jones. 2008. An introduction to the theory of point processes. Vol. II: General Theory and Structure (second ed.). Springer, New York. https: //link.springer.com/book/10.1007/978-0-387-49835-5 [8] Benjamin Edelman, Michael Ostrovsky, and Michael Schwarz. 2007. Internet Advertising and the Generalized Second-Price Auction: Selling Billions of Dollars Worth of Keywords. American Economic Review 97, 1 (March 2007), 242-259. https://doi.org/10.1257/aer.97.1.242 [9] Ashish Goel, Sudipto Guha, and Kamesh Munagala. 2010. How to probe for an extreme value. ACM Trans. Algorithms 7, 1 (2010), 12:1-12:20. https://doi.org/10. 1145/1868237.1868250 [10] Gagan Goel, Renato Paes Leme, Jon Schneider, David Thompson, and Hanrui Zhang. 2023. Eligibility Mechanisms: Auctions Meet Information Retrieval. In Proceedings of the ACM Web Conference 2023 (Austin, TX, USA) (WWW '23) . Association for Computing Machinery, New York, NY, USA, 3541-3549. https: //doi.org/10.1145/3543507.3583478 [11] Gurobi Optimization, LLC. 2023. Gurobi Optimizer Reference Manual. [12] Jason Hartline. [n. d.]. Mechanism Design and Approximation. http:// jasonhartline.com/MDnA/. Accessed: 2022-01-10. [13] Olivier Jeunen, Sean Murphy, and Ben Allison. 2023. Off-Policy Learning-toBid with AuctionGym. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 4219-4228. [14] Jon Kleinberg and Maithra Raghu. 2018. Team Performance with Test Scores. ACM Trans. Econ. Comput. 6, 3-4, Article 17 (oct 2018), 26 pages. https://doi.org/ 10.1145/3274644 [15] Jian Li and Amol Deshpande. 2019. Maximizing Expected Utility for Stochastic Combinatorial Optimization Problems. Mathematics of Operations Research 44, 1 (February 2019), 354-375. https://doi.org/10.1287/moor.2017.0927 [16] Jian Li and Wen Yuan. 2013. Stochastic Combinatorial Optimization via Poisson Approximation. In Proceedings of the Forty-Fifth Annual ACM Symposium on Theory of Computing (Palo Alto, California, USA) (STOC '13) . Association for Computing Machinery, New York, NY, USA, 971-980. https://doi.org/10.1145/ 2488608.2488731 [17] Aranyak Mehta, Uri Nadav, Alexandros Psomas, and Aviad Rubinstein. 2020. Hitting the high notes: Subset selection for maximizing expected order statistics. Advances in Neural Information Processing Systems 33 (2020), 15800-15810. [18] S.Y. Novak. 2011. Extreme Value Methods with Applications to Finance . CRC Press, Boca Raton. [19] S. Y. Novak. 2019. Poisson approximation. Probability Surveys 16 (2019), 228 276. https://doi.org/10.1214/18-PS318 [20] Ariel D. Procaccia, Sashank Jakkam Reddi, and Nisarg Shah. 2012. A Maximum Likelihood Approach For Selecting Sets of Alternatives. In Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence, Catalina Island, CA, USA, August 14-18, 2012 , Nando de Freitas and Kevin P. Murphy (Eds.). AUAI Press, Corvallis, Oregon, 695-704. https://dslpitt.org/uai/displayArticleDetails. jsp?mmnu=1&smnu=2&article_id=2333&proceeding_id=28 [21] Zhou Rong and Zhixue Lu. 2007. Two-stage procurement auction with bidders of asymmetric capacity. Systems Engineering-Theory & Practice 27, 12 (2007), 36-41. [22] Danny Segev and Sahil Singla. 2021. Efficient Approximation Schemes for Stochastic Probing and Prophet Problems. In EC '21: The 22nd ACM Conference on Economics and Computation, Budapest, Hungary, July 18-23, 2021 , PÃ©ter BirÃ³, Shuchi Chawla, and Federico Echenique (Eds.). ACM, New York, NY, USA, 793794. https://doi.org/10.1145/3465456.3467614 [23] Guofu Tan. 1992. Entry and R & D in procurement contracting. Journal of Economic Theory 58, 1 (1992), 41-60. [24] Hal Varian. 2007. Position auctions. International Journal of Industrial Organization 25, 6 (2007), 1163-1178. https://EconPapers.repec.org/RePEc:eee:indorg:v: 25:y:2007:i:6:p:1163-1178 [25] Hal R. Varian and Christopher Harris. 2014. The VCG Auction in Theory and Practice. American Economic Review 104, 5 (May 2014), 442-45. https://doi.org/ 10.1257/aer.104.5.442 [26] Jiajin Yu and Shabbir Ahmed. 2016. Maximizing expected utility over a knapsack constraint. Operations Research Letters 44, 2 (2016), 180-185. WWW'24, May 13-17, 2024, Singapore, Singapore Nikolai Gravin, Yixuan Even Xu, and Renfei Zhou",
  "A POISSON AND CHERNOFF APPROXIMATION OF BERNOULLI OBJECTIVE": "In this section, we present approximation guarantees for Bernoulli objective term by the Poisson and Chernoff objectives. Poisson approximation is the central idea of this paper. It is defined in Section 4 as:  We also will solve a special case of fractional Bidder Selection Problem for â„“ -unit auction to demonstrate how Poisson approximation can be useful. In particular, we will assume that each bidder's value has only â‰¤ ğ›¿ probability to be nonzero. Our main goal here will be to illustrate our approach and analysis ideas rather than to derive independent results for this special case. Approximation Guarantees. There are many known Poisson approximation results (see, e.g., a survey [19]) for the sum of independent Bernoulli random variables, e.g., in total variation, earth mover's, uniform (a.k.a. Kolmogorov) distances. These are typically absolute approximation guarantees, while we need relative approximations similar to Chernoff approximations from Lemma A.3. As our goal is to handle small probability tail events, we assume that each bidder's value ğ‘£ ğ‘– has only a small probability ğ›¿ to be greater than zero, i.e., âˆ€ ğ‘– âˆˆ [ ğ‘› ] , Pr [ ğ‘£ ğ‘– > 0 ] â‰¤ ğ›¿ . The following Poisson absolute approximation result will be useful to us: Lemma A.1 ([7, Lemma 11.3.V, p . 162]). Let ( ğ‘§ ğ‘– âˆ¼ Ber ( ğ‘ ğ‘– )) ğ‘› ğ‘– = 1 be ğ‘› independent Bernoulli random variables with ğ‘ ğ‘– â‰¤ ğ›¿ for âˆ€ ğ‘– âˆˆ [ ğ‘› ] . Let ğ‘ def == Ë ğ‘› ğ‘– = 1 ğ‘§ ğ‘– and ğ‘Œ âˆ¼ Pois ( ğœ† ) , where ğœ† def == Ë ğ‘› ğ‘– = 1 ğ‘ ğ‘– . Then  With Lemma A.1 we can derive relative approximations: Lemma A.2. Suppose q âˆˆ [ 0 , ğ›¿ ] ğ‘› and â„“ âˆˆ N . Then  Proof. (a). Let ğ‘§ ğ‘– âˆ¼ Ber ( ğ‘ ğ‘– ) be Bernoulli random variables and ğ‘ = Ë ğ‘› ğ‘– = 1 ğ‘§ ğ‘– be their sum. Then we can rewrite H ber ( q , â„“ ) = E [ min ( ğ‘, â„“ )] = Ë â„“ ğ‘— = 1 Pr [ ğ‘ â‰¥ ğ‘— ] . Also let ğ‘¦ ğ‘– âˆ¼ Pois ( ğ‘ ğ‘– ) and define ğ‘Œ = Ë ğ‘› ğ‘– = 1 ğ‘¦ ğ‘– . Clearly, ğ‘Œ âˆ¼ Pois ( ğœ† ) for ğœ† = Ë ğ‘› ğ‘– = 1 ğ‘ ğ‘– . Then H pois ( q , â„“ ) = E [ min ( ğ‘Œ, â„“ )] = Ë â„“ ğ‘— = 1 Pr [ ğ‘Œ â‰¥ ğ‘— ] . Hence, we have  The RHS is similar to the earth mover's distance between the sum of Bernoulli and Poisson random variables (the difference is that the summation instead of +âˆ goes only up to â„“ ). Next, we shall prove the following inequality:  which together with Lemma A.3 (a) immediately implies the desired result:  We consider two cases. First, when ğœ† â‰¥ â„“ . Then for any ğ‘— âˆˆ N + we have by (10)  Second, when min ( ğœ†, â„“ ) = ğœ† < â„“ , we use instead the earth mover's distance ğ‘‘ G ( ğ‘,ğ‘Œ ) = Ë +âˆ ğ‘— = 0 | Pr [ ğ‘ â‰¥ ğ‘— ] -Pr [ ğ‘Œ â‰¥ ğ‘— ]| . We do not calculate the cumulative density functions of ğ‘ = Ë ğ‘› ğ‘– ğ‘§ ğ‘– and ğ‘Œ = Ë ğ‘› ğ‘– ğ‘¦ ğ‘– , but get an upper bound by coupling individual ğ‘§ ğ‘– and ğ‘¦ ğ‘– . Specifically, we couple ğ‘§ ğ‘– and ğ‘¦ ğ‘– so that ğ‘§ ğ‘– = 0 implies ğ‘¦ ğ‘– = 0 (note that Pr [ ğ‘§ ğ‘– = 0 ] = 1 -ğ‘ ğ‘– â‰¤ Pr [ ğ‘¦ ğ‘– = 0 ] = ğ‘’ -ğ‘ ğ‘– ). Conversely, if ğ‘§ ğ‘– = 1 it is matched with all ğ‘¦ ğ‘– = 1 , 2 , . . . and the remaining probability for ğ‘¦ ğ‘– = 0. Then we have  Bidder Selection Problem in Position Auctions WWW'24, May 13-17, 2024, Singapore, Singapore Since ğ‘§ ğ‘– = 0 is matched to ğ‘¦ ğ‘– = 0, we get the following expression for the term E [| ğ‘§ ğ‘– -ğ‘¦ ğ‘– |] ,  where the first inequality holds, since Pr [ ğ‘§ ğ‘– = 1 âˆ§ ğ‘¦ ğ‘– = 0 ] = ( Pr [ ğ‘¦ ğ‘– = 0 ] -Pr [ ğ‘§ ğ‘– = 0 ]) = ğ‘’ -ğ‘ ğ‘– -1 + ğ‘ ğ‘– â‰¤ ğ‘ 2 ğ‘– / 2 and Pr [ ğ‘¦ ğ‘– = ğ‘— ] = ğ‘’ -ğ‘ ğ‘– ğ‘ ğ‘— ğ‘– / ğ‘— ! â‰¤ ğ‘ 2 ğ‘– / 2 ğ‘— -1 for ğ‘— â‰¥ 2. Therefore,  which concludes the proof. (b). As â„“ = 1, H ber ( q , 1 ) = 1 -Ë› ğ‘› ğ‘– = 1 ( 1 -ğ‘ ğ‘– ) def == 1 -ğ‘’ -ğ‘  , where ğ‘  = -Ë ğ‘› ğ‘– = 1 ln ( 1 -ğ‘ ğ‘– ) . Let ğœ† = Ë ğ‘› ğ‘– = 1 ğ‘ ğ‘– , then H pois ( q , 1 ) = 1 -ğ‘’ -ğœ† . Observe that ğ‘ ğ‘– â‰¤ -ln ( 1 -ğ‘ ğ‘– ) â‰¤ ğ‘ ğ‘– 1 -ğ‘ ğ‘– â‰¤ ğ‘ ğ‘– 1 -ğ›¿ . Thus ğœ† â‰¤ ğ‘  â‰¤ ğœ† 1 -ğ›¿ . The former inequality implies the desired lower bound H ber ( q , 1 ) -Hpois ( q , 1 ) â‰¥ 0. To prove the required upper bound, observe that H ber ( q , 1 ) = ğ‘“ ( ğ‘  ) , Hpois ( q , 1 ) = ğ‘“ ( ğœ† ) for ğ‘“ ( ğ‘¡ ) = 1 -ğ‘’ -ğ‘¡ . As ğ‘“ ( ğ‘¡ ) is a concave function with ğ‘“ ( 0 ) = 0, we have ğ‘“ ( ğœ† ) â‰¥ ğ‘“ ( ğ‘  ) Â· ğœ† ğ‘  â‰¥ ğ‘“ ( ğ‘  ) Â· ( 1 -ğ›¿ ) . Thus H ber ( q , 1 ) -Hpois ( q , 1 ) = ğ‘“ ( ğ‘  ) -ğ‘“ ( ğœ† ) â‰¤ ğ›¿ Â· ğ‘“ ( ğ‘  ) = ğ›¿ Â· Hber ( q , 1 ) , which concludes the proof. â–¡ Algorithm for Small Tail Probabilities. Assume that each bidder's value ğ‘£ ğ‘– has at most ğ›¿ probability to be greater than zero. Then Lemma A.2 and Claim 4.2 (Concavity of Poisson) suggest Algorithm 3.",
  "Algorithm 3: Approximation to Fractional BSP for Tail Probabilities â„“ -unit Auctions.": "Return the optimal solution e x âˆ— to the concave program:  We can solve the above program efficiently via standard concave function maximization methods, as the objective g SW is concave in x . Indeed, from Claim 4.2 we know that H pois ( q , â„“ ) is concave in q and, since q ( x , ğœ ) is linear in x for every fixed ğœ , Hpois is also concave in x . As g SW ( x , â„“ ) is an integral (non-negative linear combination) of H pois ( q ( x , ğœ ) , â„“ ) , g SW is concave in x . From Lemma A.2, we obtain the following approximation guarantees of SW ( x , â„“ ) by g SW ( x , â„“ ) .  Let x âˆ— be the best solution of the original problem (1). We have  Hence, Algorithm 3 is ( 1 -35 ğ›¿ ) -approximation. Chernoff Approximation Guarantees. We recall the following definitions  Our main algorithm needs the following approximation guarantee of H cher : WWW'24, May 13-17, 2024, Singapore, Singapore Nikolai Gravin, Yixuan Even Xu, and Renfei Zhou Lemma A.3. For all q âˆˆ [ 0 , 1 ] ğ‘› , â„“ âˆˆ N + , let ğœ† = Ë ğ‘› ğ‘– = 1 ğ‘ ğ‘– , the following properties hold.    In order to prove Lemma A.3, we first prove the following two auxiliary lemmas. Lemma A.4. For all q âˆˆ [ 0 , 1 ] ğ‘› , â„“ âˆˆ N + , let ğœ† = Ë ğ‘› ğ‘– = 1 ğ‘ ğ‘– , the following properties hold.       Proof of Lemma A.4. (a). Since â„“ â‰¥ 1, We have the following lower bound on H ber ( q , â„“ )   Â« â€¹ (b). If ğœ† â‰¥ 1, there exists q â€² âˆˆ [ 0 , 1 ] ğ‘› such that ğ‘ â€² ğ‘– â‰¤ ğ‘ ğ‘– , âˆ€ ğ‘– âˆˆ { 1 , 2 , . . . , ğ‘› } and Ë ğ‘› ğ‘– = 1 ğ‘ â€² ğ‘– = 1. Using Lemma A.4 (a), we can see that Hber ( q â€² , â„“ ) â‰¥ 0 . 5. Then H ber ( q , â„“ ) â‰¥ Hber ( q â€² , â„“ ) â‰¥ 0 . 5 . (c). As â„“ â‰¥ ğœ† , we have H cher ( q , â„“ ) = ğœ† . Then  We apply Chernoff bound to each tail probability ğ‘ â‰¥ ğ‘– under the sum. Thus  (d). By Lemma A.4 (c)  Note that inside the last summation, ğ›¿ ( ğ‘– ) â‰¥ ğ›¼ and ğ›¿ ( ğ‘– ) 2 + ğ›¿ ( ğ‘– ) â‰¥ ğ›¼ 2 + ğ›¼ â‰¥ ğ›¼ 3 . Therefore,  As the summation in the right hand side becomes a geometric series, we get  The last inequality holds as 1 -ğ‘’ -ğ‘¥ â‰¥ ğ‘¥ / 2 for ğ‘¥ âˆˆ [ 0 , 1 ] . Hence, Lemma A.4 (d) holds. (e). If â„“ â‰¤ ğœ† , then H cher ( q , â„“ ) = â„“ . We have  Bidder Selection Problem in Position Auctions WWW'24, May 13-17, 2024, Singapore, Singapore We again apply Chernoff bound for each tail event ğ‘ â‰¤ ğ‘– under summation and get  (f). By Lemma A.4 (e), we have  The summation in the right hand side is again a geometric series, which allows us to get  Hence Lemma A.4 (f) holds.  Proof. When ğ›¼, ğ‘¥ > 0, the function -ğ‘¥ 2 2 ğ›¼ + ğ‘¥ is decreasing in ğ‘¥ . Therefore,  Now we are ready to prove Lemma A.3. Lemma A.3. For all q âˆˆ [ 0 , 1 ] ğ‘› , â„“ âˆˆ N + , let ğœ† = Ë ğ‘› ğ‘– = 1 ğ‘ ğ‘– , the following properties hold.    Proof of Lemma A.3. (a). As min { ğ‘¡, â„“ } is a concave function in ğ‘¡ , the Jensen inequality gives us  which gives the first inequality. To prove the second inequality we consider the following 4 cases: Â· If ğœ† â‰¤ 1, we use Lemma A.4 (a) to get H ber ( q , â„“ ) â‰¥ ğœ† GLYPH<16> 1 -1 2 ğœ† GLYPH<17> â‰¥ 1 2 ğœ† â‰¥ 1 2 Â· Hcher ( q , â„“ ) . Â· If ğœ† > 1 and min ( ğœ†, â„“ ) â‰¤ 3 . 5, then Lemma A.4 (b) gives us H ber ( q , â„“ ) â‰¥ 1 2 â‰¥ 1 7 Â· min ( ğœ†, â„“ ) = 1 7 Â· Hcher ( q , â„“ ) . Â· If min ( ğœ†, â„“ ) > 3 . 5 and â„“ â‰¥ ğœ† , then Lemma A.4 (c) gives us  We apply Claim A.5 for ğ›¼ = ğœ† and get H cher ( q , â„“ ) -Hber ( q , â„“ ) â‰¤ 0 . 85 ğœ†, which implies that H ber ( q , â„“ ) â‰¥ 0 . 15 Â· Hcher ( q , â„“ ) for Hcher ( q , â„“ ) = ğœ† â‰¤ â„“ . Â· If min ( ğœ†, â„“ ) > 3 . 5 and ğœ† â‰¥ â„“ , then Lemma A.4 (e) gives us H cher ( q , â„“ ) -Hber ( q , â„“ ) â‰¤ â„“ -1 Ë ğ‘– = 0 ğ‘’ -1 2 ğœ† ( ğœ† -ğ‘– ) 2 . Note that 1 2 ğœ† ( ğœ† -ğ‘– ) 2 â‰¥ 1 2 â„“ ( â„“ -ğ‘– ) 2 , when ğœ† â‰¥ â„“ â‰¥ ğ‘– . Thus  By applying Claim A.5 with ğ›¼ = â„“ , we get H cher ( q , â„“ ) -Hber ( q , â„“ ) â‰¤ 0 . 85 â„“, which implies that H ber ( q , â„“ ) â‰¥ 0 . 15 Â· Hcher ( q , â„“ ) , as Hcher ( q , â„“ ) = â„“ â‰¤ ğœ† . In all 4 cases, 7H ber ( q , â„“ ) â‰¥ Hcher ( q , â„“ ) . (b). Let ğœ€ def == 1 âˆš ğœ† . We consider three cases to show that H cher ( q , â„“ ) -Hber ( q , â„“ ) â‰¤ 3 ğœ€ Â· Hcher ( q , â„“ ) , then combine it with the inequality 7H ber ( q , â„“ ) â‰¥ Hcher ( q , â„“ ) from Lemma A.3 (a) to conclude the proof. Without loss of generality, we may assume that ğœ€ < 1 / 3. Â· If â„“ â‰¥ ğœ† , then Lemma A.4 (d) for ğ›¼ = 1 . 8 ğœ€ , gives us H cher ( q , â„“ ) -Hber ( q , â„“ ) â‰¤ 2 . 94 ğœ€ğœ† = 2 . 94 ğœ€ Â· Hcher ( q , â„“ ) . â–¡ WWW'24, May 13-17, 2024, Singapore, Singapore Nikolai Gravin, Yixuan Even Xu, and Renfei Zhou Â· If â„“ â‰¤ 3 4 ğœ† , then by Lemma A.4 (e) we have  where the first inequality holds because ğœ† -ğ‘– â‰¥ ğœ† / 4; the second inequality holds, as H cher ( q , â„“ ) = â„“ and ğ‘’ -ğ‘¥ / ğ‘ âˆš ğ‘¥ â‰¤ ğ‘’ -1 / 2 âˆšï¸ ğ‘ / 2 for all ğ‘¥, ğ‘ > 0. Â· If â„“ âˆˆ GLYPH<16> 3 4 ğœ†, ğœ† GLYPH<17> , by Lemma A.4 (f) for ğ›¼ = 1 . 8 ğœ€ we have  (c). Let ğœ€ def == 1 âˆš â„“ . We first prove H cher ( q , â„“ ) -Hber ( q , â„“ ) â‰¤ 5 ğœ€ Â· Hcher ( q , â„“ ) by considering the following four cases. It implies the second bound when combined with inequality 7H ber ( q , â„“ ) â‰¥ Hcher ( q , â„“ ) from Lemma A.3 (a). We may assume without loss of generality that ğœ€ < 1 / 5. Â· If ğœ† < 1 âˆš â„“ , then H cher ( q , â„“ ) = ğœ† and Lemma A.4 (a) gives us  Â· If ğœ† âˆˆ [ 1 âˆš â„“ , â„“ 3 ) , then H cher ( q , â„“ ) = ğœ† and by Lemma A.4 (c) we have  where the second inequality holds, as ğ›¿ ( ğ‘– ) = ğ‘– -ğœ† ğœ† â‰¥ 2 for all ğ‘– â‰¥ â„“ + 1 and ğœ† < â„“ / 3. Furthermore,  where to get the first inequality we simply use the formula for the sum of geometric progression and estimate ğ‘’ -â„“ + 1 -ğœ† 2 â‰¤ ğ‘’ -â„“ / 3 ; the second inequality holds, because ğ‘’ -ğ‘¥ / ğ‘ â‰¤ ğ‘ Â· ğ‘’ -1 / ğ‘¥ for any ğ‘¥, ğ‘ > 0; the last inequality holds, because H cher ( q , â„“ ) = ğœ† â‰¥ ğœ€ = 1 / âˆš â„“ . Â· If ğœ† âˆˆ [ â„“ 3 , â„“ ] , then H cher ( q , â„“ ) = ğœ† and by Lemma A.4 (d) for ğ›¼ = 4 ğœ€ ( ğ›¼ < 1, since ğœ€ â‰¤ 1 / 5) we get H cher ( q , â„“ ) -Hber ( q , â„“ ) â‰¤ 4 ğœ€ğœ† + 6 4 ğœ€ ğ‘’ -16 ğœ€ 2 Â· ğœ† 3 â‰¤ 4 . 77 ğœ€ğœ† = 4 . 77 ğœ€ Â· Hcher ( q , â„“ ) , where the second inequality holds, since â„“ â‰¤ 3 ğœ† and 6 4 ğœ€ ğ‘’ -16 ğœ€ 2 Â· ğœ† 3 = 3 ğœ€â„“ 2 ğ‘’ -16 Â· ğœ† 3 â„“ â‰¤ 9 ğœ€ğœ† 2 ğ‘’ -16 â„“ 9 â„“ â‰¤ 0 . 77 Â· ğœ€ğœ† . Â· If ğœ† > â„“ , then by considering q â€² with ğ‘ â€² ğ‘– â‰¤ ğ‘ ğ‘– and Ë ğ‘› ğ‘– = 1 ğ‘ â€² ğ‘– = â„“ , we get H ber ( q ) â‰¥ Hber ( q â€² ) and H cher ( q ) = Hcher ( q â€² ) = â„“ . Then according to the previous case, H cher ( q , â„“ ) -Hber ( q , â„“ ) â‰¤ Hcher ( q â€² , â„“ ) -Hber ( q â€² , â„“ ) â‰¤ 4 . 77 ğœ€ Â· Hcher ( q â€² , â„“ ) = 4 . 77 ğœ€ Â· Hcher ( q , â„“ ) . These bounds combined with inequality 7H ber ( q , â„“ ) â‰¥ Hcher ( q , â„“ ) conclude the proof of (c). â–¡",
  "B MISSING PROOFS": "",
  "B.1 Proof of Theorem 4.4": "Theorem 4.4. Algorithm 1 works in polynomial time and is a ( 1 -ğ‘‚ ( ğœ€ )) -approximation, i.e., ( 1 -43 ğ‘˜ -1 / 4 ) -approximation to the fractional BSP for any position auction. Proof of Theorem 4.4. We first show that Algorithm 1 is polynomial. Indeed, step (1) works in polynomial time by Claim 4.3. For each ğœ in the support of { ğ· ğ‘– } ğ‘– âˆˆ[ ğ‘› ] and x ğ‘€ we can efficiently calculate H cher (( x ğ‘€ , 1 ğ‘† fix ) , ğœ ) and G pois ( x ğ‘€ , ğœ ) , which allows us to compute g SW ( x ğ‘€ ) in polynomial time. It is easy to see that g SW ( x ğ‘€ ) is a concave function in x ğ‘€ , as G pois is a non-negative linear combination of constant terms and concave functions H pois ( x ğ‘€ , â„“ -ğ‘—, ğœ ) , and H cher is a non-negative linear combination of concave functions H cher ( q ( x , ğœ ) , â„“ ) in x . Furthermore, given the representation of g SW ( x ğ‘€ ) as an integral of nice algebraic functions H cher and G pois , we can also compute all first and second order derivatives of g SW ( x ğ‘€ ) in polynomial time. This allows us to find the optimal solution e x âˆ— ğ‘€ to (9) in polynomial time using standard concave (first or second order) maximization methods. To get the stated approximation guarantee we first compare the original objective SW ( x ğ‘€ , 1 ğ‘† fix ) in (4) with g SW ( x ğ‘€ ) and get the following Lemma. Lemma B.1. For any x = ( x ğ‘€ , 1 ğ‘† fix ) with x ğ‘€ âˆˆ [ 0 , 1 ] | ğ‘€ | and any weights vector w ,  Bidder Selection Problem in Position Auctions WWW'24, May 13-17, 2024, Singapore, Singapore Proof. We rewrite SW ( x , w ) for x = ( x ğ‘€ , 1 ğ‘† fix ) in the same form as (8).   We first compare the corresponding adjusted Bernoulli and Poisson terms. Observe that ğ‘ ğ‘– ( x , ğœ ) â‰¤ ğ›¿ = ğœ€ for each bidder ğ‘– âˆˆ ğ‘€ and threshold ğœ > ğœ‚ according to condition (b) in Claim 4.3. Thus by Lemma A.2 (a),  Next, we compare Chernoff and Bernoulli objectives (H cher and H ber ) for low range thresholds ğœ â‰¤ ğœ‚ . As both H cher ( q , w ) and H ber ( q , w ) are non-negative linear combinations of respective terms for â„“ -unit auctions with Ë ğ‘– âˆˆ[ ğ‘› ] ğ‘ ğ‘– ( ğ‘¥ ğ‘– , ğœ ) â‰¥ â„“ âˆ— for ğœ â‰¤ ğœ‚ , we get by Lemma A.3 (b) that  Thus after combining the two bounds for high and low ranges of thresholds ğœ we get  which concludes the proof of Lemma B.1. â–¡ We proceed the proof of Theorem 4.4 by letting x âˆ— be the optimal solution to fractional BSP in (4). Then, we consider x âˆ— + âˆˆ R ğ‘› â‰¥ 0 defined as x âˆ— + def == ( x âˆ— ğ‘€ , 1 ğ‘† fix ) , so that x âˆ— + âª° x âˆ— . By Lemma B.1, for x = x âˆ— + , we have  On the other hand, by Lemma B.1 for x = e x âˆ— we have  where the second inequality holds, as e x âˆ— ğ‘€ is the optimal solution to (9) and ğ‘˜ -ğœ€ Â· ğ‘˜ ğ‘˜ Â· x âˆ— ğ‘€ is a feasible solution; the third inequality holds, as g SW ( x ) is a concave function in x ; the last inequality holds by the last lower bound on g SW ( x âˆ— ğ‘€ ) . Finally, as ( 1 -ğœ€ ) ( 1 -21 ğœ€ ) 1 + 21 ğœ€ â‰¥ 1 - ( 1 + 2 Â· 21 ) Â· ğœ€ ,  which concludes the proof of the theorem. â–¡",
  "B.2 Proof of Theorem 4.5": "Theorem 4.5. Algorithm 2 works in polynomial time and in expectation is a GLYPH<0> 1 -43 ğ‘˜ -1 / 4 -ğ‘‚ ( ğ‘˜ -1 / 2 ) GLYPH<1> -approximation to the integral BSP for any position auction. Proof of Theorem 4.5. Recall that the social welfare SW ( ğ‘† ) of a â„“ -unit or position auction is submodular as a function of the invited set of bidders ğ‘† . Claim B.2. The expected social welfare SW ( ğ‘† ) for a set of bidders ğ‘† âŠ† [ ğ‘› ] in any â„“ -unit or position auction is a submodular function of ğ‘† . WWW'24, May 13-17, 2024, Singapore, Singapore Nikolai Gravin, Yixuan Even Xu, and Renfei Zhou Analysis of Algorithm 2. Clearly, z is a feasible solution to the integral BSP. We will prove below that Algorithm 2 has almost the same approximation guarantee as Algorithm 1. Let us denote the optimal social welfare for integral BSP as OPT . Then the best solution x âˆ— to the fractional BSP (4) may have only higher welfare SW ( x âˆ— , w ) â‰¥ OPT . Furthermore, since (4) is a multi-linear extension of the integral BSP, we have  Our solution z suffers an additional loss when the sample vector y has more than ğ‘˜ elements | y | 1 > ğ‘˜ . On the other hand, for each given y with | y | 1 > ğ‘˜ we have E z âˆ¼( y ğ‘˜ ) [ SW ( z , w )] â‰¥ ğ‘˜ | y | 1 SW ( y , w ) , due to submodularity of SW ( y , w ) (here we use a standard fact about monotone non-negative submodular function ğ‘“ : a uniformly sampled subset ğ‘‡ âŠ‚ ğ‘† of given size | ğ‘‡ | = ğ‘˜ has E ğ‘‡ [ ğ‘“ ( ğ‘‡ )] â‰¥ ğ‘˜ | ğ‘† | ğ‘“ ( ğ‘† ) ). Thus  Furthermore, as OPT = max ğ‘† âŠ†[ ğ‘› ] : | ğ‘† | = ğ‘˜ SW ( ğ‘†, w ) we have OPT â‰¥ E z âˆ¼( y ğ‘˜ ) [ SW ( z , w )] â‰¥ ğ‘˜ | y | 1 SW ( y , w ) for each y with | y | 1 > ğ‘˜ . Therefore,   Claim B.3. Let x âˆˆ [ 0 , 1 ] ğ‘› with | x | 1 = ğ‘˜ . Then Ë ğ‘– â‰¥ 1 Pr y âˆ¼ Ber ( x ) [| y | â‰¥ ğ‘˜ + ğ‘– ] = ğ‘‚ GLYPH<0> âˆš ğ‘˜ GLYPH<1> . Proof of Claim B.3. By Chernoff bound, we have  We further estimate this integral as  This concludes the proof of Claim B.3. â–¡ Claim B.3 allows us to conclude that Ey âˆ¼ Ber ( x ) [ SW ( y , w ) -SW ( z , w )] = ğ‘‚ GLYPH<0> 1 âˆš ğ‘˜ GLYPH<1> Â· OPT , i.e.,",
  "C BETTER ALGORITHM FOR SINGLE-ITEM AUCTION": "In Section 4, we studied the Bidder Selection Problem (BSP) for position auctions and obtained a GLYPH<0> 1 -ğ‘‚ ( ğ‘˜ -1 / 4 ) GLYPH<1> -approximate algorithm. In this section, we study the special case of single-item auction (i.e., â„“ -unit auction with â„“ = 1) as it was extensively studied in previous work, and give a better approximation ratio GLYPH<0> 1 -ğ‘‚ ( âˆšï¸ ln ğ‘˜ / ğ‘˜ ) GLYPH<1> . Similar to Section 4.1, we fix a small set ğ‘† fix of ğœ€ Â· ğ‘˜ bidders, which affects the final approximation by at most ( 1 -ğœ€ ) factor due to the submodularity of BSP as a set function of the invited bidders. Formally, recall that for the single-item auction  We find the set of ğœ€ Â· ğ‘˜ bidders ğ‘† fix such that Prv âˆ¼ D [âˆƒ ğ‘– âˆˆ ğ‘† fix : ğ‘£ ğ‘– â‰¥ ğœ‚ ] â‰¥ 1 -ğœ€ for the largest possible threshold ğœ‚ . This allows us to take care of thresholds ğœ in a low range ğœ âˆˆ [ 0 , ğœ‚ ] by including ğ‘† fix in the solution (i.e., make ğ‘¥ ğ‘– = 1 for all ğ‘– âˆˆ ğ‘† fix ). Naturally, we want to pick bidders with higher probabilities Pr [ ğ‘£ ğ‘– > ğœ‚ ] into ğ‘† fix , which means that for the high range thresholds ğœ > ğœ‚ we get the small probability property for each bidder ğ‘– âˆ‰ ğ‘† fix . This allows us to reduce BSP to the case of small probabilities tail events (Appendix A) for ğœ > ğœ‚ and bidders ğ‘– âˆˆ [ ğ‘› ] \\ ğ‘† fix , which can be effectively solved by the Poisson approximation. Formally, we can get the following guarantees for ğ‘† fix . Claim C.1 (Small Bidder Set). Let ğœ€ â‰¥ âˆšï¸ƒ ln ğ‘˜ ğ‘˜ be a multiple of 1 / ğ‘˜ . We can find in polynomial time a threshold ğœ‚ â‰¥ 0 and a set ğ‘† fix âŠ‚ [ ğ‘› ] of size | ğ‘† fix | = ğœ€ Â· ğ‘˜ , such that  Bidder Selection Problem in Position Auctions WWW'24, May 13-17, 2024, Singapore, Singapore Proof. Recall that all distributions { ğ· ğ‘– } ğ‘– âˆˆ[ ğ‘› ] have finite support. Thus we can search through all thresholds ğœ in polynomial time. There must be two consecutive threshold values ğœ‚ and ğœ‚ + > ğœ‚ such that the number of bidders |{ ğ‘– : Pr [ ğ‘£ ğ‘– â‰¥ ğœ‚ ] â‰¥ ğœ€ }| â‰¥ ğœ€ Â· ğ‘˜ with large tail probabilities Pr [ ğ‘£ ğ‘– â‰¥ ğœ‚ ] â‰¥ ğœ€ is at least ğœ€ Â· ğ‘˜ , but a similar number of bidders |{ ğ‘– : Pr [ ğ‘£ ğ‘– > ğœ‚ ] = Pr [ ğ‘£ ğ‘– â‰¥ ğœ‚ +] â‰¥ ğœ€ }| < ğœ€ Â· ğ‘˜ for the next threshold value ğœ‚ + is strictly less than ğœ€ Â· ğ‘˜ . Let us place each bidder ğ‘– with Pr [ ğ‘£ ğ‘– > ğœ‚ ] â‰¥ ğœ€ into ğ‘† fix and fill the remaining positions in ğ‘† fix up to size ğœ€ Â· ğ‘˜ (so that | ğ‘† fix | = ğœ€ Â· ğ‘˜ ) with bidders from { ğ‘– : Pr [ ğ‘£ ğ‘– â‰¥ ğœ‚ ] â‰¥ ğœ€ > Pr [ ğ‘£ ğ‘– â‰¥ ğœ‚ +]} . Then, every bidder ğ‘– âˆ‰ ğ‘† fix has Pr [ ğ‘£ ğ‘– > ğœ‚ ] = Pr [ ğ‘£ ğ‘– â‰¥ ğœ‚ +] < ğœ€ as required by condition (b). On the other hand, | ğ‘† fix | = ğœ€ Â· ğ‘˜ and Pr [ ğ‘£ ğ‘– â‰¥ ğœ‚ ] â‰¥ ğœ€ for every ğ‘– âˆˆ ğ‘† fix , i.e., condition (a) is satisfied since  where to get the second inequality, we used the fact that ( 1 -1 ğ‘¥ ) ğ‘¥ < ğ‘’ -1 for any ğ‘¥ â‰¥ 1. After selecting such set ğ‘† fix and threshold ğœ‚ , we are ready to give the complete description of Algorithm 4.",
  "Algorithm 4: Fractional BSP for Single-Item Auction.": "(1) Find ( ğœ‚, ğ‘† fix ) as in Claim C.1. Set ğ‘¥ ğ‘– = 1 for âˆ€ ğ‘– âˆˆ ğ‘† fix . (2) For the remaining bidders ğ‘€ def == [ ğ‘› ] \\ ğ‘† fix let the Poisson approximation g SW ( x ğ‘€ ) be   x âˆ— e x = ( 1 ğ‘† fix âˆ— âˆ— ğ‘€ e ) e x ğ‘€ x ğ‘€  In the algorithm, we ignore thresholds ğœ âˆˆ [ 0 , ğœ‚ ] , as by taking ğ‘† fix we have already achieved high success probability of at least 1 -1 ğ‘˜ by Claim C.1. For the high range thresholds ğœ > ğœ‚ , we first observe that as the result of fixing set ğ‘† fix , the probability that there is a bidder with value greater than the threshold ğœ becomes  where ğ‘Ÿ ğœ is a constant that we can easily compute. Hence, we respectively adjust the Poisson approximation term e Hpois ( q ğ‘€ ) in the algorithm according to (13) (we slightly abuse notations by writing H pois ( q ğ‘€ ) instead of H pois ( q ) : for the coordinates ğ‘– âˆ‰ ğ‘€ we let ğ‘ ğ‘– = 0). Theorem C.2. Algorithm 4 for single-item auction works in polynomial time and is a ( 1 -2 ğœ€ ) -approximation, i.e., a GLYPH<0> 1 -ğ‘‚ GLYPH<0>âˆšï¸ ln ğ‘˜ / ğ‘˜ GLYPH<1> GLYPH<1> -approximation to the fractional BSP. Proof. We first verify that Algorithm 4 is polynomial. Note that the step (1) works in polynomial time by Claim C.1. For each ğœ in the support of ğ· ğ‘– we calculate in polynomial time the constants ğ‘Ÿ ğœ âˆˆ [ 0 , 1 ] . Both e Hpois ( q ğ‘€ ) for each x ğ‘€ and ğœ in the support and g SW ( x ğ‘€ ) for each x ğ‘€ can be computed in polynomial time. Moreover, all first and second order partial derivatives of g SW ( x ğ‘€ ) can be computed in the same way as the integral of respective derivatives of e Hpois ( x ğ‘€ ) . Furthermore, it is easy to see that g SW ( x ğ‘€ ) is a concave function in x ğ‘€ , since it is a positive linear combination of constant terms (such as ( 1 -1 / ğ‘˜ ) ğœ‚ and ğ‘Ÿ ğœ ) and concave functions H pois ( x ğ‘€ ) according to Claim 4.2. Hence, we can find the optimal solution e x âˆ— ğ‘€ in polynomial time using standard concave (first or second order) maximization methods. To prove an approximation guarantee of 1 -2 ğœ€ for Algorithm 4, we first derive the following approximations of SW ( x ğ‘€ , 1 ğ‘† fix ) by g SW ( x ğ‘€ ) similar to (11) (but in a special case of â„“ = 1).  Proof. Recall that by (3) the Social Welfare SW ( x ) for x = ( x ğ‘€ , 1 ğ‘† fix ) and â„“ = 1 is  For the low range ğœ âˆˆ [ 0 , ğœ‚ ] we have H ber ( q ( x , ğœ )) âˆˆ [ 1 -1 ğ‘˜ , 1 ] due to the choice of ğ‘† fix in Claim C.1. It is well approximated by the respective term GLYPH<16> 1 -1 ğ‘˜ GLYPH<17> ğœ‚ in (12). , where is the solution to the concave program in : â–¡ (3) Return , WWW'24, May 13-17, 2024, Singapore, Singapore Nikolai Gravin, Yixuan Even Xu, and Renfei Zhou For the high range ğœ > ğœ‚ , we apply Lemma A.2 (b) with ğ›¿ = ğœ€ and get the following bound:  On the other hand, H ber ( q ) -e Hpois ( q ) â‰¥ 0, as H ber ( q ğ‘€ ) â‰¥ Hpois ( q ğ‘€ ) by Lemma A.2 (b). Thus  where the last equality holds since ğœ€ â‰¥ âˆšï¸ƒ ln ğ‘˜ ğ‘˜ . â–¡ Now we are ready to complete the proof of Theorem C.2. Let x âˆ— be the optimal solution to fractional BSP. We consider x âˆ— + âˆˆ R ğ‘› â‰¥ 0 defined as x âˆ— + def == ( x âˆ— ğ‘€ , 1 ğ‘† fix ) , so that x âˆ— + âª° x âˆ— . Then, by Lemma C.3 for x = x âˆ— + we have  On the other hand, by Lemma C.3 for x = e x âˆ— we have  where the second inequality holds, as e x âˆ— ğ‘€ is the optimal solution to (14) and ğ‘˜ -ğœ€ Â· ğ‘˜ ğ‘˜ Â· x âˆ— ğ‘€ is a feasible solution; the third inequality holds, as g SW ( x ) is a concave function in x by Claim 4.2; the last inequality holds, as g SW ( x âˆ— ğ‘€ ) â‰¥ ( 1 -ğœ€ ) Â· SW ( x âˆ— ) and ( 1 -ğœ€ ) 2 â‰¥ 1 -2 ğœ€ . This concludes the proof. â–¡",
  "D ADDITIONAL ASPECTS OF THE NUMERICAL EXPERIMENTS": "",
  "D.1 Comparison between Our Theoretical and Modified Algorithms": "We compare the performance of the theoretical version and the modified version of our algorithm. Due to certain limitations on the convex objectives in Gurobi, we implemented the theoretical version of our algorithm in MATLAB with the help of another convex optimization library, Mosek [1], and ran it on the same set of test inputs as in Section 5. As the implementations are in different programming languages, we do not compare their running time and only compare their approximation efficiency. As shown in Table 2, we can see that the theoretical version of our algorithm performs slightly worse than the modified version. This is due to the potentially suboptimal decision of fixing a small bidder set ğ‘† fix . This step is helpful when we analyze our algorithm theoretically, but it may not be optimal in practice. Therefore, we choose to use the modified version of our algorithm in Section 5.",
  "D.2 Notes on the Discretization": "Recall that in Section 5, we discretized each generated distribution to a common, finite support { 0 } âˆª { 1 + ğ‘– 50 | ğ‘– = 0 , 1 , . . . , 49 } by moving probability mass on each discretized interval inside [ 0 , 2 ] to its left point and by redistributing the mass on ( 2 , +âˆ) to the discrete points, proportional to their respective probabilities. We picked this unusual discretization to make instances more challenging for Greedy, as without it Greedy and other heuristics like our algorithm produce solutions with nearly optimal approximation efficiency (over 99% for both algorithms). Indeed, two distributions in Table 2: Experimental results of Local Search, Greedy, and both the modified version and the theoretical version of our algorithm. For each algorithm, we show the average relative quality of the produced solution to that of the best-performing algorithm that terminated in 1 week. Error bars denote the standard deviation. Bidder Selection Problem in Position Auctions WWW'24, May 13-17, 2024, Singapore, Singapore a well-structured family of log-normal distributions are likely to have strong dominance relation: a distribution ğ· 1 = Lognormal ( ğœ‡ 1 , ğœ 2 1 ) is always preferable to ğ· 2 = Lognormal ( ğœ‡ 2 , ğœ 2 2 ) , whenever ğœ‡ 1 â‰¥ ğœ‡ 2 and ğœ 1 â‰¥ ğœ 2 . Our choice of discretization was solely based on the comparison between Greedy and Local Search, i.e., after a few empirical trials of different discretizations we simply stopped once the average efficiency of Greedy was less than 99% that of the Local Search.",
  "keywords_parsed": [
    "Bidder Selection",
    " Submodular Maximization",
    " Position Auctions"
  ]
}