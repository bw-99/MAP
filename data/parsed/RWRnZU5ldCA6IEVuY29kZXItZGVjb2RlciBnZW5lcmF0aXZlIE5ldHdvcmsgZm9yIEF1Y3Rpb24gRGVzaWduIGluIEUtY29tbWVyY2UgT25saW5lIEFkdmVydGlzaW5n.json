{"EdgeNet : Encoder-decoder generative Network for Auction Design in E-commerce Online Advertising": "Guangyuan Shen \u2217 Shenjie Sun \u2217 {shenguangyuan.sgy,shengjie.ssj}@alibaba- inc.com Alibaba Group Hangzhou, Zhejiang, China", "Dehong Gao \u2020 Libin Yang": "{dehong.gdh,libiny}@nwpu.edu.cn NWPU Xian, Shaanxi, China", "ABSTRACT": "We present a new encoder-decoder generative network dubbed EdgeNet, which introduces a novel encoder-decoder framework for data-driven auction design in online e-commerce advertising. We break the neural auction paradigm of Generalized-Second-Price (GSP) and improve the utilization efficiency of data while ensuring the economic characteristics of the auction mechanism. Specifically, EdgeNet introduces a transformer-based encoder to better capture the mutual influence among different candidate advertisements. In contrast to GSP based neural auction model, we design an autoregressive decoder to better utilize the rich context information in online advertising auctions. EdgeNet is conceptually simple and easy to extend to the existing end-to-end neural auction framework. We validate the efficiency of EdgeNet on a wide range of e-commercial advertising auctions, demonstrating its potential in improving user experience and platform revenue. Yongping Shi Wei Ning {yongping.syp,wei.ningw}@alibaba- inc.com Alibaba Group Hangzhou, Zhejiang, China \u2026 \u2026 \u2026 Transformer Encoder RankScore \ud835\udc5e\ud835\udc62\ud835\udc4e\ud835\udc59\ud835\udc56\ud835\udc61\ud835\udc66\ud835\udc46\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52\t\u00d7\t\ud835\udc4f\ud835\udc56\ud835\udc51 Top K Sort &\t\ud835\udc54\ud835\udc5f\ud835\udc52\ud835\udc52\ud835\udc51\ud835\udc66 \u2026 \u2026 \u2026 Auto Regressive Decoder Pricing Payment Net (a) Traditional data-driven Auction (b) Encoder-decoder generative Auction", "CCS CONCEPTS": "\u00b7 Informationsystems \u2192 Onlineadvertising ; Computational advertising ; \u00b7 Applied computing \u2192 E-commerce infrastructure ; \u00b7 Computing methodologies \u2192 Learning paradigms.", "KEYWORDS": "Online Advertising, Auction Design, Data-driven Auction", "1 INTRODUCTION": "Online e-commerce advertising has grown into a massive industry, both in terms of advertisement(ad) volume as well as the complexity of the mechanism design behind [7]. Traditional auction mechanisms, such as Vickrey-Clarke-Groves (VCG) auction [13], Myerson auction [11] and generalized second-price auction [6], have been used to enable efficient ad allocation in various e-commerce advertising scenarios. However, none of these methods can make good use of the rich user history data of online advertising to optimize allocation and payment rules. It remains open to both academia and industry on how to make full use of powerful deep learning in designing data-driven auction mechanisms for industrial e-commerce advertising. Recently, pioneered by Liu et al. [10], there is rapid progress in designing data-driven auctions through deep learning [5, 9, 10]. Typically, we can formulate a data-driven auction design as a constrained optimization problem and find near-optimal solutions [2, 3]. The data-driven auctions enable us to exploit rich information, such as the context of the auction environment and the performance feedback from auction outcomes, to guide the design of a flexible mechanism. Though effective, most existing data-driven auction frameworks [9, 10] are still 'restricted' to the standard paradigm of Top-K ranking: Map the contextual auction features to onedimension rank score space, and then perform top-k sorting to generate new allocation and second price payment results. Such a paradigm may not be optimal in e-commerce online advertising for two main reasons. First, top-k ranking allocation has limited power to utilize auction contextual information. According to the greedy sorting method, such auction models can not know the final allocation result of each candidate ad when they output the rank score. As illustrated in Fig.1, the contextual information of these candidate ads when they are auctioned is different from the contextual information when they are displayed. However, all the existing e-commerce neural auction models [9, 10] still assign a rank score to each ad only based on the original context ignoring the change in the contextual information. At this time, the estimated display revenue (rank score) of the top-ranked ads may not be the highest since there exists mutual influence among the exposed ads. In practice, if an ad item is surrounded by others with similar quality but much higher prices, then its probability of being clicked would be high. On the contrary, if the same item is surrounded by items of much lower prices, then its probability of being purchased would be lower. Therefore, in e-commerce advertising auctions, mutual influences between items are even stronger than those in traditional auctions. Second, second price payment cannot leverage the full power of data-driven auctions. Almost all the data-driven auctions for e-commerce still use the GSP payment rule [9, 10], that is, paying the second-highest bid with a rank score fraction discount. Such a second-price payment paradigm can guarantee the economic characteristics of the mechanism design, like, Incentive Compatible (IC), and Individual Rational (IR). However, it is impossible to quantify the correct \"distance\" between two ads in the final impression context since the rank score itself is obtained based on the original auction context. How to break the GSP paradigm in e-commerce advertising auction design while making the auction conform to economic characteristics is still an open problem for researchers from industrial and academic institutes. To handle such practical problems, we need a new architecture to better model the auction context while maintaining economic characteristics. To overcome the aforementioned limitations of the previous works, we propose EdgeNet : an Encoder-decoder generative neural Network architecture as the auction model to be optimized. The context encoder is built upon the transformer architecture [12], which can capture the complex mutual influence among different ads and user page view information in an auction. In the autoregressive context decoder, we generate auction results one by one, i.e., once we have selected a candidate ad we will update the context information immediately and then select the next ad, thus it can perceive the dynamically changing auction context. Moreover, instead of following the GSP auction paradigm, we design lightweight ex-post regret loss to approximate the Dominant-Strategy Incentive Compatibility (DSIC). We have deployed the EdgeNet mechanism in the real advertising system for the e-commerce platform. Experimental results on large-scale industrial data sets showed that EdgeNet mechanism significantly outperformed other widely used industrial auction mechanisms in optimizing multiple performance metrics. Our main contributions can be summarized as follows: \u00b7 We are the first to realize that the GSP auction paradigm may not be optimal in e-commerce advertising since it can not model the change of the auction context and ignore the mutual influence among different candidate ads. \u00b7 We provide the first insight to model the context change and candidate mutual influence in auction design. The proposed EdgeNet casts auction as a sequence generative task and outputs the allocation results one by one, which can fully perceive the context change. \u00b7 We break the limit of the second-price payment, and output the payment fraction based on the payment network. We present the first ex-post regret loss training task in ecommerce advertising to approach DSIC.", "2 PRELIMINARIES": "", "2.1 Data-driven auction design": "Similar to prior work [10, 16], we describe a typical ad platform for online e-commerce. \ud835\udc41 advertisers compete for showing their ads in \ud835\udc3e \u2264 \ud835\udc41 ad slots, which are incurred by a page view request from the user. Each advertiser \ud835\udc56 submits bid \ud835\udc4f \ud835\udc56 based on his private information including the predicted click-through rate ( \ud835\udc5d\ud835\udc36\ud835\udc47\ud835\udc45 ), predicted conversion rate ( \ud835\udc5d\ud835\udc36\ud835\udc49\ud835\udc45 ), cost per conversion ( \ud835\udc36\ud835\udc43\ud835\udc36 ), etc, over the ad. We use vector b = ( \ud835\udc4f \ud835\udc56 , b -\ud835\udc56 ) to represent the bids of all advertisers, where b -\ud835\udc56 are the bids from all advertisers except \ud835\udc56 . We represent the ad auction mechanism by M\u27e8R , P\u27e9 , where R is the allocation rule and P is the payment rule. A data-driven auction mechanism M\u27e8R , P\u27e9 consists of an allocation rule R and a payment rule P : The allocation rule R = (R \ud835\udc56 \ud835\udc57 ) \ud835\udc56 \u2208 \ud835\udc41,\ud835\udc57 \u2208 \ud835\udc3e computes the probability that ad slot \ud835\udc57 is allocated to candidate ad \ud835\udc56 , given the bidding profile \ud835\udc4f , candidate ad information \ud835\udc65 and user information \ud835\udc66 . For all \ud835\udc4f, \ud835\udc65, \ud835\udc66 , and \ud835\udc57 \u2208 \ud835\udc3e , we have \u02dd \ud835\udc41 \ud835\udc56 = 1 R \ud835\udc56 \ud835\udc57 ( \ud835\udc4f, \ud835\udc65, \ud835\udc66 ) \u2264 1 to guarantee no slot is allocated more than once. The payment rule \ud835\udc5d = ( \ud835\udc5d 1 , \ud835\udc5d 2 , . . . , \ud835\udc5d \ud835\udc5b ) computes the price advertiser \ud835\udc56 need to pay. Definition 2.1 (Utility). In a data-driven auction setting, the utility of advertiser \ud835\udc56 under mechanism M\u27e8R , P\u27e9 is defined by where \ud835\udc63 \ud835\udc56 \ud835\udc57 = \ud835\udc5d\ud835\udc36\ud835\udc47\ud835\udc45 \u00d7 \ud835\udc5d\ud835\udc36\ud835\udc49\ud835\udc45 \u00d7 \ud835\udc36\ud835\udc43\ud835\udc36 denote the valuation of advertiser \ud835\udc56 wins the ad slot \ud835\udc57 in the auction. The ad allocation rule would jointly consider the bids and the quality ( \ud835\udc5d\ud835\udc36\ud835\udc47\ud835\udc45 and \ud835\udc5d\ud835\udc36\ud835\udc49\ud835\udc45 ) of the ads. We use R \ud835\udc56 \ud835\udc57 ( \ud835\udc4f \ud835\udc56 , b -\ud835\udc56 ) = 1 to denote the advertiser \ud835\udc56 wins the \ud835\udc57 \ud835\udc61\u210e ad slot, while R \ud835\udc56 \ud835\udc57 ( \ud835\udc4f \ud835\udc56 , b -\ud835\udc56 ) = 0 , \u2200 \ud835\udc57 \u2208 \ud835\udc3e represents the advertiser loses the auction. The \ud835\udc3e winning ads would be displayed to the user. The auction mechanism module further calculates the payments for the winning ads with a rule P , which would be carefully designed to guarantee the economic properties and the revenue of the auction mechanism. Definition 2.2 (DSIC). An auction is dominant strategy incentive compatible (DSIC) if for each advertiser, the optimal strategy is to report her true valuation no matter how others report. Definition 2.3 (IR). An auction is individually rational (IR) if for each advertiser, truthful bidding will receive a non-negative utility. Definition 2.4 ((Ex-post) Regret). The ex-post regret for an advertiser \ud835\udc56 under auction is the maximum utility gain he can achieve by misreporting when the bids of others are fixed, i.e., All the expectation terms are computed empirically by \ud835\udc3f samples, sampling from our train data sets. The empirical ex-post regret for advertiser \ud835\udc56 is defined as", "2.2 Problem Formulation": "Following the work [10, 15], we formulate the problem as multiple performance metrics optimization in the competitive advertising environments . Given bid vector b from all the advertisers and \ud835\udc3f ad performance metric functions { \ud835\udc53 1 ( b ; M) , .., \ud835\udc53 \ud835\udc3f ( b ; M)} (such as Revenue, CTR, CVR, etc), we aim to design an auction mechanism M\u27e8R , P\u27e9 , such that where D is the advertisers' bid distribution based on which bidding vectors b are drawn. We define \ud835\udc39 ( b ; M) = \ud835\udf06 1 \u00d7 \ud835\udc53 1 ( b ; M) + \u00b7 \u00b7 \u00b7 + \ud835\udf06 \ud835\udc3f \u00d7 \ud835\udc53 \ud835\udc3f ( b ; M) , where the objective is to maximize a linear combination of the multiple performance metrics \ud835\udc53 \ud835\udc59 's with preference parameters \ud835\udf06 \ud835\udc59 's. The parameters \ud835\udf06 \ud835\udc59 's are the inputs of our problem. The constraints of DSIC guarantee that advertisers would truthfully report the bid.", "3 MODEL ARCHITECTURE": "", "3.1 Overview of EdgeNet": "As illustrated in Fig. 2, EdgeNet consists of two main parts: a permutation-equivariant context encoder and an auto-regressive auction decoder. The transformer-based context encoder learns an auction context embedding from the features of page view user and candidate ads. The structural properties of the transformer not only allow for a better representation of the competition among different candidate ads but also guarantee that the context feature is permutation-equivariant. Afterward, we employ an auto-regressive decoder to generate context-aware exposure ads sequence. This neural network is partially monotonic with respect to bids, which is critical to the guarantee of IC property. Finally, we compute the allocation and payment result through the final output layer.", "3.2 Auction Context Encoding": "Given the features of each candidate ads \ud835\udc65 \ud835\udc56 \u2208 R \ud835\udc51 \ud835\udc65 and user \ud835\udc66 \u2208 R \ud835\udc51 \ud835\udc66 , each instance x \ud835\udc56 and \ud835\udc66 is firstly mapped to a dense and continuous space through an embedding layer, resulting in a set of intermediate states e = { \ud835\udc52 \ud835\udc56 } \ud835\udc41 + 1 \ud835\udc56 = 1 : Then, this intermediate states set e = { \ud835\udc52 \ud835\udc56 } \ud835\udc41 + 1 \ud835\udc56 = 1 is processed with Transformer [12] to build the context-aware embedding \u210e \ud835\udc56 for each candidate ad \ud835\udc56 and user embedding \u210e \ud835\udc66 , where \ud835\udc52 -\ud835\udc56 denote the intermediate state set e = { \ud835\udc52 1 , ..., \ud835\udc52 \ud835\udc56 -1 , \ud835\udc52 \ud835\udc56 + 1 , ..., \ud835\udc52 \ud835\udc41 } except \ud835\udc52 \ud835\udc56 . The final context embedding c can be obtained through an extra fully connected layer \ud835\udf19 : It should be noted that the context encoder does not include the bids from all candidate ads. This design is specified mainly for the guarantee of IC property, keeping the property that the advertiser would win the same or a better ad slot if she reports a higher bid.", "3.3 Auto-regressive Decoding": "To break through the limitation of the GSP auction paradigm and better utilize the rich contextual features of online advertising auctions, we propose a novel auto-regressive decoder. This decoder can generate auction results one by one thus it can perceive the real and dynamically changing auction context. Once the decoder selects an ad from all the candidate ads set, it immediately updates the context information and then selects the next exposure ad. The selection is based on the attention mechanism enhanced by context embedding. As shown in Fig. 2, at the beginning of the decoding, the context embedding will be used as the initial hidden state of the GRU cell [4], and then a special token \"start\" will be fed into the GRU cell as the initial input. After that, at each step, the output embedding of the GRU cell will be used as the state embedding, which should contain all the information needed to select the next ad. The model will consider the pre-order context information when selecting an ad at each step, and then update this context information to affect subsequent selection. Formally, we have the logits as follows, where \ud835\udc63 \ud835\udc47 , \ud835\udc4a 1 , \ud835\udc4a 2 , \ud835\udc4a 3 are the model parameter to be optimized, \u210e \ud835\udc56 denote the feature embedding of ad \ud835\udc56 and \ud835\udc50 \ud835\udc57 denote the state embedding of slot \ud835\udc57 . In the last decoder layer, we employ an MLP layer to get the global feature maps, which will be used to compute the final allocation and payment in the output layer. The first feature map \ud835\udc39 R \u2208 R \ud835\udc41 \u00d7 \ud835\udc3e is used to compute the original allocation probability R( \ud835\udc4f, \ud835\udc65, \ud835\udc66 ) \u2208 [ 0 , 1 ] \ud835\udc41 \u00d7 \ud835\udc3e by softmax activation function on each column of \ud835\udc39 R , i.e., Here R \ud835\udc56,\ud835\udc57 is the probability that slot \ud835\udc57 is allocated to ad \ud835\udc56 . For payment, we compute payment fraction \u02dc \ud835\udc5d ( \ud835\udc4f, \ud835\udc65, \ud835\udc66 ) \u2208 ( 0 , 1 ) \ud835\udc5b via the second feature map \ud835\udc39 \ud835\udc5d :", "3.4 Optimization and Training": "Similar to [5], EdgeNet is optimized through the augmented Lagrangian method. The Lagrangian with a quadratic penalty is: where \ud835\udc39 \ud835\udc4e\ud835\udc59\ud835\udc59 = [ \u02dd \ud835\udc3f \ud835\udc59 = 1 \ud835\udf06 \ud835\udc59 \u00d7 \ud835\udc53 1 \ud835\udc59 , \u00b7 \u00b7 \u00b7 , \u02dd \ud835\udc3f \ud835\udc59 = 1 \ud835\udf06 \ud835\udc59 \u00d7 \ud835\udc53 \ud835\udc41 \ud835\udc59 ] \ud835\udc47 .", "4 EXPERIMENTAL EVALUATION": "", "4.1 Experiment Setup": "4.1.1 Datasets. The data sets we used for experiments come from an e-commerce advertising system. We randomly select 1 million records logged data under GSP auctions from Sept. 1-4, 2022 as training data, and 1200k records logged data from Sept. 5, 2022 as test data. Unless stated otherwise, all experiments are conducted under the setting of top-3 ads displayed in each page view 1 . \u2026 \u2026 Embedding Layer \u2026 \u2026 Trans Trans Trans \u2026 \u2026 MLP Context Embedding Candidate Ad feature x 1 \u2026 Attention Layer \u2026 Masking Sampling \u2026 \u2026 Attention Layer \u2026 Attention Distribution Masking Sampling \u2026 GRU GRU Item 1 Item 4 GRU State Embedding State Embedding Candidate Ad feature x 2 Candidate Ad feature x N User feature y Trans feature e 1 feature e 2 feature e N feature e y feature h 1 feature h 2 feature h N feature h y feature h 1 feature h 2 feature h 4 feature h 3 feature h N feature h N feature h 4 feature h 3 feature h 2 feature h 1 First selection Second selection u 1 1 u 2 1 u 3 1 u 4 1 u N 1 u 1 2 u 2 2 u 3 2 u 4 2 u N 2 bid 1 bid 2 bid 4 bid N bid N bid 4 bid 3 bid 2 bid 1 bid 3 4.1.2 Evaluation Metrics. We consider the following metrics in our offline experiments, which reflect the platform revenue, user experience in e-commerce advertising. For all experiments in this paper, metrics are normalized to a same scale. i.e., \ud835\udc4f\ud835\udc56\ud835\udc51 \u00d7 \ud835\udc5d\ud835\udc36\ud835\udc47\ud835\udc45 \ud835\udf0e could improve the performance, where \ud835\udf0e can be adjusted to weight the performance of revenue and CTR. We refer to this exponential form extension as GSP in the experiments. \u00b7 Revenue Per Mille (RPM). \ud835\udc45\ud835\udc43\ud835\udc40 = \u02dd \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58 \u00d7 \ud835\udc43\ud835\udc43\ud835\udc36 \u02dd \ud835\udc56\ud835\udc5a\ud835\udc5d\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5b \u00d7 1000. \u00b7 Click-Through Rate (CTR). \ud835\udc36\ud835\udc47\ud835\udc45 = \u02dd \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc58 \u02dd \ud835\udc56\ud835\udc5a\ud835\udc5d\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5b . \u00b7 Conversion Rate (CVR). \ud835\udc36\ud835\udc49\ud835\udc45 = \u02dd \ud835\udc5c\ud835\udc5f\ud835\udc51\ud835\udc52\ud835\udc5f \u02dd \ud835\udc56\ud835\udc5a\ud835\udc5d\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5b . \u00b7 Incentive Compatiable-Regret (IC-R) [14], which represents the exposed regret of utility maximizers, to quantify IC of EdgeNet . A larger value of IC-R indicates that an advertiser could get larger utility by manipulating the bidding. For instance, 2.09% in Table 1 means advertisers can increase their utilities by about 2.09% through modifying bid in EdgeNet auctions. 4.1.3 Baselines Methods. We compare EdgeNet with the widely used mechanisms in the industrial ad platform. 1) Generalized Second Price auction (GSP). The rank score of traditional GSP is simply the bids times \ud835\udc5d\ud835\udc36\ud835\udc47\ud835\udc45 , that is, effective Cost Per Milles (eCPM). The payment rule is the value of the minimum bid required to retain the same slot. The work [8] suggested incorporating a squashing exponent \ud835\udf0e into the rank score function, 2) Utility-based Generalized Second Price auction (uGSP). uGSP [1] extends the conventional GSP by taking the rank score as a linear combination of multiple performance metrics using estimated values: \ud835\udc5f \ud835\udc56 ( \ud835\udc4f \ud835\udc56 ) = \ud835\udf06 1 \u00d7 \ud835\udc4f \ud835\udc56 \u00d7 \ud835\udc5d\ud835\udc36\ud835\udc47\ud835\udc45 \ud835\udc56 + \ud835\udc5c \ud835\udc56 , where \ud835\udc5c \ud835\udc56 represents other utilities, such as pCTR and pCVR: \ud835\udc5c \ud835\udc56 = \ud835\udf06 2 \u00d7 \ud835\udc5d\ud835\udc36\ud835\udc47\ud835\udc45 \ud835\udc56 + \ud835\udf06 3 \u00d7 \ud835\udc5d\ud835\udc36\ud835\udc49\ud835\udc45 \ud835\udc56 ( where \ud835\udf06 \ud835\udc59 \u2265 0 ) . The payment of uGSP follows the principle from GSP: \ud835\udc5d \ud835\udc56 = \ud835\udf06 1 \u00d7 \ud835\udc4f \ud835\udc56 + 1 \u00d7 \ud835\udc5d\ud835\udc36\ud835\udc47\ud835\udc45 \ud835\udc56 + 1 + \ud835\udc5c \ud835\udc56 + 1 -\ud835\udc5c \ud835\udc56 \ud835\udf06 1 \u00d7 \ud835\udc5d\ud835\udc36\ud835\udc47\ud835\udc45 \ud835\udc56 . 3) DNA [15] DNA uses a deep neural network to map ad's related features to a new rank score within the GSP auction.", "4.2 Results": "We construct an offline advertising simulation system. This simulation system can ensure that the offline and online performance trends are consistent. Each experiment is repeated 10 times with different random seeds and each result is presented in the form of mean \u00b1 standard. We summarize the detailed experimental results on our industrial datasets in Table 1. Compared with representative auction mechanisms, we have the following observations from the experimental results: 1) EdgeNet makes improvements over DNA, uGSP, GSP in CTR, RPM, CVR. One reasonable explanation is that EdgeNet have better capability to model the mutual influence among different candidate ad. 2) Compared with traditional GSP-based auction design (e.g., uGSP, DNA), EdgeNet also has a relatively low IC-R, i.e., maintain the economic properties without the help of GSP auction. The regret loss combined with the payment neural network plays an important role in keeping IC.", "5 CONCLUSION": "We present a novel encoder-decoder generative network (EdgeNet), which introduces a novel encoder-decoder framework for datadriven auction design in online e-commerce advertising. EdgeNet have broken the restriction of GSP auction and realized a real dataefficient auction structure design. EdgeNet mechanism significantly outperformed other widely used industrial auction mechanisms in optimizing multiple performance metrics. For future work, we are interested in how to construct budget-aware data-driven auctions for online e-commerce advertising.", "REFERENCES": "[1] Yoram Bachrach, Sofia Ceppi, Ian A Kash, Peter Key, and David Kurokawa. 2014. Optimising trade-offs among stakeholders in ad auctions. In EC . 75-92. [2] Vincent Conitzer and Tuomas Sandholm. 2002. Complexity of mechanism design. In UAI . 103-110. [3] Vincent Conitzer and Tuomas Sandholm. 2004. Self-interested automated mechanism design and implications for optimal combinatorial auctions. In Proceedings of the 5th ACM Conference on Electronic Commerce . 132-141. [4] Rahul Dey and Fathi M Salem. 2017. Gate-variants of gated recurrent unit (GRU) neural networks. In 2017 IEEE 60th international midwest symposium on circuits and systems (MWSCAS) . IEEE, 1597-1600. [5] Paul D\u00fctting, Zhe Feng, Harikrishna Narasimhan, David Parkes, and Sai Srivatsa Ravindranath. 2019. Optimal Auctions through Deep Learning. In ICML . 17061715. [6] Benjamin Edelman, Michael Ostrovsky, and Michael Schwarz. 2007. Internet advertising and the generalized second-price auction: Selling billions of dollars worth of keywords. American economic review 97, 1 (2007), 242-259. [7] Zhe Feng, Okke Schrijvers, and Eric Sodomka. 2019. Online learning for measuring incentive compatibility in ad auctions. In WWW . 2729-2735. [8] S\u00e9bastien Lahaie and David M Pennock. 2007. Revenue analysis of a family of ranking rules for keyword auctions. In EC . 50-56. [9] Guogang Liao, Xuejian Li, Ze Wang, Fan Yang, Muzhi Guan, Bingqi Zhu, Yongkang Wang, Xingxing Wang, and Dong Wang. 2022. NMA: Neural Multi-slot Auctions with Externalities for Online Advertising. arXiv preprint arXiv:2205.10018 (2022). [10] Xiangyu Liu, Chuan Yu, Zhilin Zhang, Zhenzhe Zheng, Yu Rong, Hongtao Lv, Da Huo, Yiqing Wang, Dagui Chen, Jian Xu, et al. 2021. Neural auction: End-toend learning of auction mechanisms for e-commerce advertising. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining . 3354-3364. [11] Roger B Myerson. 1981. Optimal auction design. Mathematics of operations research 6, 1 (1981), 58-73. [12] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems 30 (2017). [13] William Vickrey. 1961. Counterspeculation, auctions, and competitive sealed tenders. The Journal of finance 16, 1 (1961), 8-37. [14] Yiqing Wang, Xiangyu Liu, Zhenzhe Zheng, Zhilin Zhang, Miao Xu, Chuan Yu, and Fan Wu. 2022. On Designing a Two-stage Auction for Online Advertising. In Proceedings of the ACM Web Conference 2022 . 90-99. [15] Zhilin Zhang, Xiangyu Liu, Zhenzhe Zheng, Chenrui Zhang, Miao Xu, Junwei Pan, Chuan Yu, Fan Wu, Jian Xu, and Kun Gai. 2021. Optimizing Multiple Performance Metrics with Deep GSP Auctions for E-commerce Advertising. In WSDM . 993-1001. [16] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In KDD . 1059-1068. Received 20 February 2007; revised 12 March 2009; accepted 5 June 2009"}
