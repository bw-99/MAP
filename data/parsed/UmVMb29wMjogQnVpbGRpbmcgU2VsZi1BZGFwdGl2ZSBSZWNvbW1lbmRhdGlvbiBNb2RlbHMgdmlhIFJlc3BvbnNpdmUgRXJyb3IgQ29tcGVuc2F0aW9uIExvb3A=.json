{"ReLoop2: Building Self-Adaptive Recommendation Models via Responsive Error Compensation Loop": "Jieming Zhu \u2217 Huawei Noah's Ark Lab Shenzhen, China jiemingzhu@ieee.org Guohao Cai \u2217 Huawei Noah's Ark Lab Shenzhen, China caiguohao1@huawei.com Junjie Huang \u2020 Shanghai Jiao Tong University Shanghai, China legend0018@sjtu.edu.cn Zhenhua Dong Huawei Noah's Ark Lab Shenzhen, China dongzhenhua@huawei.com Ruiming Tang Huawei Noah's Ark Lab Shenzhen, China tangruiming@huawei.com", "ABSTRACT": "Weinan Zhang Shanghai Jiao Tong University Shanghai, China wnzhang@sjtu.edu.cn", "KEYWORDS": "Industrial recommender systems face the challenge of operating in non-stationary environments, where data distribution shifts arise from evolving user behaviors over time. To tackle this challenge, a common approach is to periodically re-train or incrementally update deployed deep models with newly observed data, resulting in a continual learning process. However, the conventional learning paradigm of neural networks relies on iterative gradient-based updates with a small learning rate, making it slow for large recommendation models to adapt. In this paper, we introduce ReLoop2, a self-correcting learning loop that facilitates fast model adaptation in online recommender systems through responsive error compensation. Inspired by the slow-fast complementary learning system observed in human brains, we propose an error memory module that directly stores error samples from incoming data streams. These stored samples are subsequently leveraged to compensate for model prediction errors during testing, particularly under distribution shifts. The error memory module is designed with fast access capabilities and undergoes continual refreshing with newly observed data samples during the model serving phase to support fast model adaptation. We evaluate the effectiveness of ReLoop2 on three open benchmark datasets as well as a real-world production dataset. The results demonstrate the potential of ReLoop2 in enhancing the responsiveness and adaptiveness of recommender systems operating in non-stationary environments.", "CCS CONCEPTS": "", "\u00b7 Information systems \u2192 Recommender systems .": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. KDD '23, August 6-10, 2023, Long Beach, CA, USA \u00a9 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0103-0/23/08...$15.00 https://doi.org/10.1145/3580305.3599785 Recommender systems, continual learning, distribution shift, model adaptation, retrieval augmentation", "ACMReference Format:": "Jieming Zhu, Guohao Cai, Junjie Huang, Zhenhua Dong, Ruiming Tang, and Weinan Zhang. 2023. ReLoop2: Building Self-Adaptive Recommendation Models via Responsive Error Compensation Loop. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '23), August 6-10, 2023, Long Beach, CA, USA. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3580305.3599785", "1 INTRODUCTION": "Nowadays, personalized recommendation has emerged as a prominent channel across a range of online applications, including ecommerce, news feeds, and music apps. It enables the delivery of tailored items to users based on their individual interests. The provision of high-quality recommendations not only enhances user engagement but also fuels revenue growth for platforms. To achieve accurate recommendations, deep learning-based models have gained widespread adoption in industry owing to their flexibility and ability to capture intricate user-item relationships. However, industrial recommender systems often operates in non-stationary environments, where data distribution shifts [36] occur as a result of evolving user behaviors over time. This can lead to the deterioration of well-trained recommendation models during online serving, and thus poses a challenge for models to quickly adapt under distribution shifts. To address this challenge, previous research efforts have been made from two aspects: behavior sequence modeling and incremental model training. The first line of research aims to capture dynamic patterns at the feature level by modeling sequential user behavior sequences. Notable progress has been made in this area, particularly in click-through rate (CTR) prediction tasks [68], with models incorporating attention, GRU, and transformer architectures, such as DIN [67], DIEN [66], and BST [5]. These models formulate CTR prediction as a few-shot learning task [62], where given k historical behaviors from a user (i.e., k-shot samples), the goal is to predict whether the user will click on the next item. Fewshot learning enables rapid adaptation to new users with only a few observed samples [32]. However, these studies do not explicitly address the test-time distribution shift problem. In parallel, another line of research focuses on incremental model training. While regular re-training of models (e.g., daily) is straightforward, it becomes time-consuming due to the large volume of training data in practice (e.g., up to billions of samples in Google Play's app recommendation [7]). As a result, incremental model training [26, 47, 61] has gained popularity in industrial recommender systems. This approach retains previous model parameters for initialization [26] or knowledge transfer [47] while continually updating the model using newly observed data samples, often at a minute-level granularity. Incremental training brings training efficiency and enhances model freshness. However, learning the parameters of neural networks relies on iterative gradient-based updates to gradually incorporate supervision information into model weights with a small learning rate. This makes it challenging for large parametric recommendation models to achieve fast adaptation to distribution shifts. This challenge, often referred to as the stability-plasticity dilemma [37] in incremental learning, stems from the need to balance the stability of existing knowledge with the plasticity required to incorporate new information efficiently. In comparison, humans possess an extraordinary capability for fast incremental learning in dynamic environments [1]. This remarkable learning ability can be attributed to the presence of two complementary learning systems (CLS) in the human brain: the hippocampus and the neocortex [30, 44]. The hippocampus is responsible for rapid learning of recent specific experiences and exhibits short-term adaptation. On the other hand, the neocortex functions as a slow learning system, gradually acquiring structured knowledge about the environment over time. The combination of these slow and fast CLS learning mechanisms empowers humans to learn quickly and remember information in the long term. This inspires us to design an adaptive recommendation framework that incorporates both fast and slow learning modules to build self-adaptive recommendation models and make accurate recommendations in dynamic environments. Our approach consists of two key components: a base model serving as a slow learning module that updates through gradient back-propagation, and a fast learning module equipped with a non-parametric error memory. Unlike traditional gradient-based training, the fast learning module is training-free and thus enables rapid adaptation to new data distributions. To be specific, consider the learning process of students, who often organize and review their past incorrect questions to reflect on their errors and improve their performance in subsequent exams. Inspired by this, we propose to store recent error samples from the incoming data stream in the error memory. These error samples reflect situations where the model's performance degrades, particularly during distribution shifts. In response, we estimate the errors between the base model's predictions and the ground-truth labels using the error memory. These error estimations are then utilized to compensate for the model's degradation caused by distribution shifts. During the model serving phase, newly observed data is continuously written to the error memory, creating a self-correcting learning loop that facilitates fast model adaptation. We refer to this approach as ReLoop2, which extends the original ReLoop learning framework [3] to test-time adaptation. In building a self-correcting learning loop for online recommendation, we encounter two primary challenges. The first challenge pertains to estimating the errors for output compensation without relying on back-propagation. To address this, we propose a nonparametric method that leverages the error memory to retrieve similar samples, enabling us to approximate the errors effectively. The second challenge lies in the time- and space-efficient design of the error memory. Given the substantial volume and high velocity of data streams, we introduce a locality-sensitive hashing (LSH)-based sketching approach. This approach ensures efficient O(1)-time memory reading and writing operations while maintaining a constant memory footprint. The ReLoop2 framework establishes a continual model adaptation process by continuously refreshing the error memory with newly observed error samples after model deployment. It has the potential to significantly enhance model performance when faced with data distribution shifts. Importantly, the framework is orthogonal to existing incremental learning techniques and compatible with diverse models used in recommendation systems. We empirically validate the effectiveness of ReLoop2 on three open benchmark datasets and a proprietary production dataset, showcasing substantial performance improvements over existing models and incremental training techniques. We hope that our work could inspire further research attention to address the challenge of traintest distribution shift in online recommender systems. In summary, this paper makes three main contributions: \u00b7 Weidentify the challenging problem of fast model adaptation for online recommendation, and propose a slow-fast learning paradigm inspired by the complementary learning systems observed in human brains. \u00b7 We introduce a time- and space-efficient non-parametric error memory and leverage it to build a responsive error compensation loop for fast model adaptation. \u00b7 Weconduct extensive experimental evaluations on both open benchmark datasets and real-world production datasets to demonstrate the effectiveness of our ReLoop2 framework.", "2 BACKGROUND": "In this section, we provide an overview of the CTR prediction task. We then describe our motivation for fast model adaptation in real-world scenarios. Additionally, we review the locality-sensitive hashing (LSH) technique used in our work.", "2.1 CTR Prediction": "Typically, input samples consist of two main types of features: categorical features, and numerical features. In our approach, we utilize embedding techniques to map these features into a lowerdimensional embedding space. Specifically, for numerical features, we first discretize them into categorical bucket features. Then, same with categorical features, we apply one-hot/multi-hot encoding and embedding table lookups to obtain embedding vectors. Let \ud835\udc65 = { \ud835\udc65 1 , \ud835\udc65 2 , ..., \ud835\udc65 \ud835\udc5b } denotes a data instance with \ud835\udc5b feature fields. Then we could get its feature embeddings as \ud835\udc52 = { \ud835\udc52 1 , \ud835\udc52 2 , ..., \ud835\udc52 \ud835\udc5b } , which serve as the input to a deep neural network. Given the set of feature embeddings, various CTR prediction models have been proposed to model feature interactions (e.g., DeepFM [12], DCN [58], DCN-V2 [59]) and sequential user interests (e.g., DIN [67], DIEN [66], and BST [5]). At last, the CTR model outputs the predicted click probability \u02c6 \ud835\udc66 \u2208 [ 0 , 1 ] using the sigmoid activation \ud835\udf0e (\u00b7) on the logit value. Formally, we denote a CTR prediction model as follows: where \ud835\udf19 (\u00b7) is a multi-layer deep neural network. For example, \ud835\udf19 \ud835\udc37\ud835\udc52\ud835\udc52\ud835\udc5d\ud835\udc39\ud835\udc40 , \ud835\udf19 \ud835\udc37\ud835\udc36\ud835\udc41 , and \ud835\udf19 \ud835\udc37\ud835\udc3c\ud835\udc41 are commonly used model architectures [12, 58, 67]. We denote \ud835\udc66 \u2208 { 0 , 1 } as a true label to indicate whether a user has clicked a recommended item. The binary cross-entropy loss function is usually used for CTR prediction: where \ud835\udc41 is the number of training instances. Readers may refer to our BARS benchmark [68] for more training details.", "2.2 Fast Model Adaptation": "In this section, we analyze the motivation behind the need for fast model adaptation to address the problem of distribution shift. In Figure 1, we present our observations regarding the dynamic data distribution from various perspectives, including data variance, feature dynamics, overall CTR, and category-specific CTR over time. To illustrate this, we split the test dataset of MicroVideo (detailed in Section 4) into ten chronological time slots, simulating an online advertising scenario. Specifically, Figure 1(a) depicts the data variance (from embedding \ud835\udc52 ) for each time slot, revealing the spread of data instances relative to their average. A higher value indicates a greater deviation from the average. Figure 1(b) demonstrates the changes in the number of users and items over time. Both (a) and (b) highlight the covariate shift in feature \ud835\udc65 . 1 2 3 4 5 6 7 8 9 10 Time Slot 0.090 0.095 0.100 0.105 0.110 0.115 Data Variance (a) 1 2 3 4 5 6 7 8 9 10 Time Slot 4.0K 4.5K 5.0K 5.5K 6.0K 6.5K Number of Users (b) 1 2 3 4 5 6 7 8 9 10 Time Slot 0.15 0.16 0.17 0.18 0.19 CTR (c) 1 2 3 4 5 6 7 8 9 10 Time Slot 0.04 0.06 0.08 0.10 0.12 CTR of Categories (d) CTR of Category 1 CTR of Category 2 70K 80K 90K 100K 110K 120K Number of Items Number of Users Number of Items Furthermore, Figure 1(c) showcases the dynamic nature of CTR over time, while (d) exhibits the dynamic CTR based on different categories. These figures reveal the label shift in \ud835\udc66 and the concept drift between \ud835\udc65 and \ud835\udc66 , respectively. Collectively, these visualizations demonstrate a significant level of data change occurring over time. As a result, there is a pressing demand for fast model adaptation to swiftly adjust to the dynamic patterns present in the data.", "2.3 Locality Sensitive Hashing": "This section provides a brief review of the classical Locality Sensitive Hashing (LSH) algorithm [9, 21], which is a widely adopted sublinear-time algorithm for approximate nearest neighbor search. In LSH, a hash function \u210e ( \ud835\udc65 ) \u21a6\u2192 Z a mapping that assigns an input \ud835\udc65 to an integer in the range [ 0 , \ud835\udc45 -1 ] . LSH encompasses a family of such hash functions with a key property: similar points have a high probability of being mapped to the same hash value [9]. More formally, a LSH family is defined as follows [9]. Definition 1. LSHFamily . A family H is called ( \ud835\udc46 0 , \ud835\udc50\ud835\udc46 0 , \ud835\udc5d 1 , \ud835\udc5d 2 ) -sensitive with respect to a similarity measure \ud835\udc60\ud835\udc56\ud835\udc5a (\u00b7 , \u00b7) if for any two points \ud835\udc65,\ud835\udc66 \u2208 R \ud835\udc51 and \u210e chosen uniformly from H the following properties hold: \u00b7 if \ud835\udc60\ud835\udc56\ud835\udc5a ( \ud835\udc65,\ud835\udc66 ) \u2265 \ud835\udc46 0 then \ud835\udc5d ( \ud835\udc65,\ud835\udc66 ) \u2265 \ud835\udc5d 1 \u00b7 if \ud835\udc60\ud835\udc56\ud835\udc5a ( \ud835\udc65,\ud835\udc66 ) \u2264 \ud835\udc50\ud835\udc46 0 then \ud835\udc5d ( \ud835\udc65,\ud835\udc66 ) \u2264 \ud835\udc5d 2 Typically, \ud835\udc5d 1 > \ud835\udc5d 2 and \ud835\udc50 < 1 is required for approximate nearest neighbor search. We use the notation \ud835\udc5d ( \ud835\udc65,\ud835\udc66 ) to denote the collision probability \ud835\udc43\ud835\udc5f GLYPH<0> \u210e ( \ud835\udc65 ) = \u210e ( \ud835\udc66 ) GLYPH<1> between \ud835\udc65 and \ud835\udc66 , where their hash values are equal. One sufficient condition for being a LSH family is that the collision probability \ud835\udc5d ( \ud835\udc65,\ud835\udc66 ) is a monotonically increasing function of similarity between the two data points, i.e., where \ud835\udc53 (\u00b7) is required to be a monotonically increasing function. In other words, similar data points are more likely to collide with each other under LSH mapping. Among the widely known LSH families, SimHash [18] is a popular LSH that applies the technique of Signed Random Projections (SRP) [4, 10, 18] for the cosine similarity measure. Given a vector \ud835\udc65 , SRP utilizes a random \ud835\udc64 vector with each component generated from i.i.d. normal, i.e., \ud835\udc64 \ud835\udc56 \u223c \ud835\udc41 ( 0 , 1 ) , and only stores the sign of the projection. Hence, SimHash is given by Particularly, we could take [ \u210e \ud835\udc64 ( \ud835\udc65 )] + = \ud835\udc5a\ud835\udc4e\ud835\udc65 GLYPH<0> 0 , \u210e \ud835\udc64 ( \ud835\udc65 ) GLYPH<1> using the ReLU function to re-map it to { 0 , 1 } . It has been shown in the seminal work [10] that the collision probability under SRP satisfies the following equation: where \ud835\udc5d ( \ud835\udc65,\ud835\udc66 ) is monotonic to the cosine similarity \ud835\udc65 \ud835\udc47 \ud835\udc66 \u2225 \ud835\udc65 \u2225 2 \u2225 \ud835\udc66 \u2225 2 . It is important to note that each hash function \u210e \ud835\udc64 ( \ud835\udc65 ) generates a single bit using SRP, resulting in two possible hash values { 0 , 1 } . By independently sampling \ud835\udc3f hash functions with different \ud835\udc64 vectors, we can generate new hash values in the range [ 0 , 2 \ud835\udc3f -1 ] by combining the outcomes of the \ud835\udc3f independent SRP bits. The collision probability is equal to \ud835\udc5d ( \ud835\udc65,\ud835\udc66 ) \ud835\udc3f , the power of \ud835\udc3f of Equation 5. ptation Error Loop Error compensation BaseModel slow learning ErrorMemory fast learning Input Output (a) Memory write + (b) Estimation Query Input Nearest neighbors Fast-Access Error Memory Memory write if +", "3 APPROACH": "In this section, we present our ReLoop2 apporach that enables fast model adaptation through a self-correcting learning loop with responsive error compensation.", "3.1 Overview": "non-parametric manner and subsequently correct the model output through error compensation. This establishes a continual fast adaptation process for the model within the evolving dynamics of the non-stationary data distribution. New error samples observed during model deployment are continuously written back to the error memory, enabling the tracking of changing dynamics in the online data. Deep learning-based recommendation models, such as CTR prediction models discussed in Section 2.1, are typically optimized using back-propagation algorithms within the empirical risk minimization (ERM) framework. These models assume a stationary data distribution (i.e., the training and testing data are drawn from the same distribution) and require a small learning rate to gradually incorporate information into model weights. However, in real-world online recommendation scenarios, the rapid emergence of new users and items, along with potential changes in user behavior over time, result in the distribution shift challenge. Consequently, a well-trained model may gradually degrade after deployment. To address this challenge, we propose the ReLoop2 framework for fast model adaptation, as depicted in Figure 2. Our framework employs a slow-fast learning paradigm, where the base model undergoes slow gradient updates, while an episodic memory module, free from back-propagation, is introduced to facilitate rapid acquisition of new knowledge. The base model is a standard parametric neural network that learns common knowledge through gradual gradient updates. In contrast, the memory module is a non-parametric component that stores recently observed samples and enables fast learning and adaptation from these samples. This slow-fast learning paradigm aligns with the theory of complementary learning systems (CLS) in human brains [30, 44]. Specifically, we refer to the memory module as the error memory, which stores the recent error samples produced by the base model on the incoming data stream. These error samples provide insights into cases where the model makes incorrect predictions, particularly in the presence of distribution shifts. By directly capturing and remembering these error samples, we can estimate errors in a", "3.2 Error Compensation Loop": "Figure 2(b) depicts our error compensation loop for fast model adaptation, comprising three key components: the base model \ud835\udf19 , the fast-access error memory \ud835\udc40 , and the error estimation module E . Our learning framework is generic and compatible with various base models used for CTR prediction. We formulate the base model as follows: where \ud835\udc52 represents the feature embeddings of a data instance. \ud835\udc66 \ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52 \u2208 [ 0 , 1 ] denotes the predicted click probability from the base model. We provide a brief overview of feature embedding and CTR modeling approaches in Section 2.1. It is worth noting that the model function \ud835\udf19 can be implemented using any existing CTR prediction model, such as DeepFM [12], DCN [58], and DIN [67]. The base model approximates the ground truth label \ud835\udc66 by minimizing the error between \ud835\udc66 and \ud835\udc66 \ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52 within an empirical risk minimization framework: Ideally, under the assumption of independent and identically distributed (i.i.d.) data, the error \ud835\udf16 should be a small random variable close to zero after model training. However, the base model degrades when confronted with distribution shifts, resulting in an enlarged error \ud835\udf16 during model serving. To address this issue, we propose a proactive approach to estimate the model prediction error and correct the model output accordingly. However, directly obtaining \ud835\udf16 from Equation 7 is not feasible due to the unknown label \ud835\udc66 during prediction. Therefore, we propose to estimate it using recently observed samples stored in the error memory module \ud835\udc40 . Formally, we perform error estimation with the following formula: where \u210e \ud835\udc5e denotes the hidden representation of input sample \ud835\udc5e , which can be chosen from any hidden layer (e.g., the last hidden layer) of the base model \ud835\udf19 . With the estimated error \ud835\udc66 \ud835\udc52\ud835\udc5f\ud835\udc5f , we can make compensation for the model output to correct its prediction: where \ud835\udc66 \ud835\udc5d\ud835\udc5f\ud835\udc52\ud835\udc51 denotes the final output with model adaptation. The compensation weight \ud835\udf06 adjusts the proportion of error compensation. It is important to note that the value of \ud835\udc66 \ud835\udc5d\ud835\udc5f\ud835\udc52\ud835\udc51 may exceed the range [ 0 , 1 ] after error compensation. In such cases, we clamp the value within the range. In the following sections, we will describe our designs for the error estimation module E and the error memory module \ud835\udc40 . 3.2.1 Error Estimation Module. Given the error memory that retains recently observed data samples, our goal is to estimate the prediction error based on similar samples to a new input \ud835\udc5e . Formally, we aim to retrieve a set of top-k similar samples from the memory, as described below: where \ud835\udc60 \ud835\udc56 = \ud835\udc60\ud835\udc56\ud835\udc5a ( \u210e \ud835\udc5e , \u210e \ud835\udc56 ) denotes the similarity between the hidden vectors of the query sample \ud835\udc65 and memory instance \ud835\udc56 . Additionally, \ud835\udc66 \ud835\udc56 and \ud835\udc66 \ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52 _ \ud835\udc56 represent the ground-truth label and the prediction value of the base model, respectively. The derivation of similar samples K is provided in Section 3.2.2. Inspired by the attention mechanism employed in content-addressing memory networks [63], we can estimate the attention-weighted ground truth \u00af \ud835\udc66 and prediction value \u00af \ud835\udc66 \ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52 as follows. The attention weight \ud835\udc4e \ud835\udc56 is computed using the following equation: Here, \ud835\udf0f is a temperature parameter that adjusts the smoothness of the softmax. The value of \ud835\udf0f can be learned jointly with the base model or manually tuned as a hyper-parameter (e.g., 0 . 1). Next, we estimate the prediction error as a weighted combination of two error measures: where \ud835\udefe is a weight that balances the two error measures. Notably, when \ud835\udefe = 0, the error is estimated from the model predictions on similar samples. When \ud835\udefe = 1, the error is computed from the ground truth labels of similar samples. In the latter case, we substitute \ud835\udc66 \ud835\udc52\ud835\udc5f\ud835\udc5f into Equation 9 and can obtain the corrected model prediction with error compensation as follows: This can be seen as a weighted ensemble of the base model's output \ud835\udc66 \ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52 and the estimation \u00af \ud835\udc66 from k-nearest neighbors (KNN). For simplicity, we use \ud835\udefe = 1 in our experiments. 3.2.2 Fast-Access Error Memory. In this section, we focus on the key component of our framework, the error memory \ud835\udc40 . In online recommendation systems, data is acquired sequentially over time, and the model generates click predictions based on the received samples. The true labels are received when users interact with the recommended items. During this process, we can easily obtain the hidden representation \u210e \ud835\udc56 from a specific hidden layer of the base model (same with \u210e \ud835\udc5e ), the base model output \ud835\udc66 \ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52 _ \ud835\udc56 , and the true label \ud835\udc66 \ud835\udc56 . To enable fast adaptation to distribution shifts, we utilize the memory to store these recently observed samples. Ideally, our memory consists of a set of key-value pairs formulated as follows: where \u210e \ud835\udc56 \u2208 R \ud835\udc51 represents the d-dimensional key vector of memory slot \ud835\udc56 , while \ud835\udc66 \ud835\udc56 and \ud835\udc66 \ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52 _ \ud835\udc56 serve as the memory values. We define a memory reader function \ud835\udc45 that retrieves a set of similar samples K from the memory given \u210e \ud835\udc5e as a query: However, designing the memory poses two main challenges in real-world recommender systems due to the large volume of click data: \u00b7 Fast Access . For real-time online CTR prediction, model inference must meet stringent latency requirements. Therefore, it is crucial to enable fast access to the error memory. However, retaining a large number of recently observed data samples for adaptation makes the memory size too large to utilize traditional attention-based content addressing mechanisms in memory networks [63], which needs to read all memory slots for each query. \u00b7 Memory Size . The memory module requires a substantial memory size to store an adequate number of data samples. In our production system, the number of samples can easily reach millions within a 10-minute timeframe. Storing such a large number of data samples consumes significant computing resources (e.g., RAM) for model serving. Therefore, minimizing memory resource consumption for the error memory is highly desirable. To address these challenges, we explore two potential solutions: approximate nearest neighbor (ANN) search and LSH-based sketching. ANN search techniques are widely used in industry to efficiently retrieve top-k nearest vectors in sub-linear time. These techniques have been successful in various retrieval-augmented machine learning tasks (e.g., language modeling [29], machine translation [27]). Additionally, they are supported by mature tools and libraries, including Faiss [23], ScaNN [13] and Milvus [56]. However, constructing popular ANN indices like HNSW [42] and IVFPQ in Faiss [23] involves time-consuming steps (e.g., k-means) and requires substantial memory (gigabytes of RAM). To reduce memory consumption, we propose filtering the data samples based on the model's errors. Specifically, we only store samples with relatively large errors (greater than a threshold \ud835\udf0e ) since they indicate significant degradation in the base model. Despite applying error filtering and random down-sampling, storing these raw data samples still imposes a considerable burden on memory. Therefore, for online recommendation tasks with limited computing resources, ANN search may not be the optimal choice. Ideally, we aim to design a lightweight and fast-access memory that avoids directly storing massive data points in RAM, eliminates the need for iterative and non-streaming processes like kmeans, and avoids constructing complex index structures such as graphs, which are either time-consuming or difficult to parallelize. To achieve these objectives, we propose an alternative design of the error memory by employing the LSH-based data sketching algorithm on the streaming data [8]. LSH, as introduced in Section 2.3, enables efficient bucketing of each data point in constant time using fixed hash functions. Data sketching supports the construction of a compact sketch that summarizes the streaming data. The sketching algorithm compresses a set of high-dimensional vectors into a small array of integer counters, which is sufficient for estimating the similarity \ud835\udc60 \ud835\udc56 of similar samples in Equation 16. Formally, we define the memory as a sketch consisting of \ud835\udc3e repeated arrays, denoted as \ud835\udc40 \ud835\udc58 for \ud835\udc58 \u2208 [ 0 , \ud835\udc3e -1 ] . Each array \ud835\udc40 \ud835\udc58 is indexed by \ud835\udc3f independent hash functions \ud835\udc3b \ud835\udc3f ( \ud835\udc65 ) = { \u210e \ud835\udc64 ( \ud835\udc65 ) | \ud835\udc64 } , where \u210e \ud835\udc64 ( \ud835\udc65 ) \u21a6\u2192 [ 0 , 1 ] is a singed random projection described in Equation 4. Consequently, an input \ud835\udc65 can be hashed into an index in 2 \ud835\udc3f buckets: \ud835\udc3b \ud835\udc3f ( \ud835\udc65 ) \u21a6\u2192 [ 0 , 2 \ud835\udc3f -1 ] . For example, setting \ud835\udc3f = 16 can result in approximately 65,536 buckets. While the sketch is originally designed for kernel density estimation with integer counters [8], in our design, we store a tuple of summation values at bucket \ud835\udc4f in the array \ud835\udc40 \ud835\udc58 , denoted as \ud835\udc40 \ud835\udc58 [ \ud835\udc4f ] = ( \ud835\udc60\ud835\udc62\ud835\udc5a _ \ud835\udc65 [ \ud835\udc4f ] , \ud835\udc60\ud835\udc62\ud835\udc5a _ \ud835\udc66 [ \ud835\udc4f ] , \ud835\udc60\ud835\udc62\ud835\udc5a _ \ud835\udc66 \ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52 [ \ud835\udc4f ]) To ensure more stable estimations, the same process is repeated \ud835\udc3e times using \ud835\udc3e different sets of hash functions { \ud835\udc3b \ud835\udc58 \ud835\udc3f ( \ud835\udc65 ) | \ud835\udc58 \u2208 [ 0 , \ud835\udc3e -1 ]} . In summary, the memory can be viewed as a concatenated array of size 2 \ud835\udc3f \u00d7 \ud835\udc3e \u00d7 3. More specifically, we formulate the memory writing and reading processes as follows: Memory Writing . For each observed sample \ud835\udc56 from the data stream, we obtain ( \u210e \ud835\udc56 , \ud835\udc66 \ud835\udc56 , \ud835\udc66 \ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52 _ \ud835\udc56 ) . Instead of directly storing the raw samples in the memory following Equation 15, we apply each set of hash functions \ud835\udc3b \ud835\udc58 \ud835\udc3f to map the key vector \u210e \ud835\udc56 to the corresponding bucket \ud835\udc4f and update the sketch array \ud835\udc40 \ud835\udc58 [ \ud835\udc4f ] as follows. Note that the values in \ud835\udc40 \ud835\udc58 [ \ud835\udc4f ] are initially set to zero and can be reset regularly or when the base model has been updated to refresh the memory. The updates on all \ud835\udc3e memory arrays can be performed in parallel. Memory Reading . Given a query sample vector \u210e \ud835\udc5e , we can apply the same set of hash functions to map the query to bucket \ud835\udc4f . We then obtain the summation values from each sketch array \ud835\udc40 \ud835\udc58 [ \ud835\udc4f ] and compute the readout values via averaging them over all buckets as follows: . After parallel reading from \ud835\udc3e sketch arrays, we obtain the \ud835\udc3e readout results of similar samples K = GLYPH<8> ( \ud835\udc60 \ud835\udc56 , \ud835\udc66 \ud835\udc56 , \ud835\udc66 \ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc52 _ \ud835\udc56 ) | \ud835\udc56 \u2208 [ 0 , \ud835\udc3e -1 ] GLYPH<9> , which can then be used in Equation 10 for error estimation. Compared to traditional memory that stores raw samples, our LSH-based sketch memory offers several advantages. It enables fast construction time (O(1) writing time per sample), has a low memory requirement (constant memory size of 2 \ud835\udc3f \u00d7 \ud835\udc3e \u00d7 3), and eliminates the need for query-time distance computations (O(1) reading time per query). It is worth noting that our sketch memory is not only practical to implement but also enjoys strong theoretical guarantees [8]. In this way, the error memory module helps estimate the potential error of the base model based on observed similar data samples, contributing to an error compensation loop that continuously and adaptively corrects the model output. This results in a slow-fast joint learning framework for fast model adaptation.", "4 EXPERIMENTS": "In this section, we present extensive experimental results conducted on three open benchmark datasets and one real-world production dataset to validate the effectiveness of ReLoop2. Our experiments aim to answer the following three research questions: \u00b7 RQ1 : How does the integration of ReLoop2 with state-of-the-art models contribute to the improvement of model performance? \u00b7 RQ2 : How does ReLoop2 compare to incremental training in terms of performance? \u00b7 RQ3 : How do different hyperparameters affect model performance?", "4.1 Experimental Setup": "Datasets. Weconductexperiments on three open benchmark datasets, and a large-scale production dataset. \u00b7 AmazonElectronics is a subset of the Amazon dataset [16], a widely used benchmark dataset for recommendation. We follow the DIN work [67] to preprocess the dataset. Specifically, the AmazonElectronics contains 1,689,188 samples, 192,403 users, 63,001 goods and 801 categories. Features include goods_id, category_id, and their corresponding user-reviewed sequences: goods_id_list, category_id_list. \u00b7 MicroVideo is an open dataset for short video recommendation, which has been released by [6]. We follow the same preprocessing steps. It contains 12,737,617 interactions that 10,986 users have made on 1,704,880 micro-videos. The labels include click or nonclick, while the features include user_id, item_id, category, and the extracted image embedding vectors of cover images of microvideos. \u00b7 KuaiVideo is another open dataset for short video recommendation. We follow the work [33] to obtain the preprocessed dataset. Specifically, we randomly selected 10,000 users and their 3,239,534 interacted micro-videos. It contains several interaction data between users and videos, such as user_id, photo_id, duration_time, click, like, and so on. In addition, 2048-dimensional video embeddings are provided as content features. \u00b7 Production is a production dataset from Huawei's news feed recommendation. It has a total of 500 million records sampled from 7 days user logs and each record has more than 100 fields of features, such as doc_id, category_id, short-term interest topic_id, and anonymous data masking user_id. We use the latest 2-hour samples as testing data, and split it into 12 consective parts in chronological order. Base models. We compare our model with the following mainstream base models for CTR prediction. in Table 1. Through the analysis of experiment results, we get some conclusions as follows: deep-learning-based methods get higher accuracy than the low-rank-based methods, thus revealing the powerful feature interaction ability of neural networks. In addition, xDeepFM obtains the second-best results on the MicroVideo dataset, indicating that a well-designed structure could fully use the advantages of the factorization machine component. What's more, DIEN method obtains the second-best results on AmazonElectronics and KuaiVideo datasets, which benefits from the evolution of user interests and exploitation of the sequential features. In addition, we can see that our BASE+ReLoop2 outperforms all the other baseline methods since the error memory module is applied to the baseline method to augment the base encoder, and the error compensation helps to adapt to data distribution shift rapidly. Specifically, we choose DIEN as the base model for AmazonElectronics and KuaiVideo, and DCNv2 for MicroVideo because of their relatively better performance. It is worth noting that our ReLoop2 framework is model agnostic to all the existing models, which is shown in Table 2. After applying ReLoop2 to the five state-of-theart models respectively, we can obtain the new SOTA. \u00b7 Shallow models: FM [53], FmFM [55]. \u00b7 Feature interaction models: DeepFM [12], xDeepFM [35], DCN [58], AutoInt+ [54], DCNv2 [59], AOANet [54]. \u00b7 Behavior sequence models: DIN [67], DIEN [66], BST [5]. Metrics. We adopt the most popular ranking metrics, AUC [7] and gAUC [67] (i.e., user-grouped AUC), to evaluate the model performance. In addition, we report the relative improvements (RelImp) over the classic factorization machine (FM) model. We note that the preprocessed datasets and evaluation settings for all the baseline models we studied are available on the BARS benchmark website: https://openbenchmark.github.io/BARS.", "4.2 Performance Evaluation with SOTA Models": "We evaluate the ReLoop2 module on existing models, including manystate-of-the-art (SOTA) methods. The performances are shown Evaluation on production dataset. The comparison of our model with the baseline on the product dataset is shown in Figure 3. The baseline is an incremental learning method, which serves as the base encoder, so the results of the first part of the test set are exactly the same. From the second part, we utilize the previous parts as fast access error memory to learn the error compensation rapidly, and the performance demonstrates the efficiency of our ReLoop2 apporach.", "4.3 Evaluation between ReLoop2 and Incremental Training": "As mentioned earlier, incremental model training has been a common choice in real-world production systems, so in Figure 4, we compare our fast model adaptation with incremental training based on DCNv2 backbone on MicroVideo. The horizontal axis of Figure 4 19:10 19:20 19:30 19:40 19:50 20:00 20:10 20:20 20:30 20:40 20:50 21:00 72.5 73.0 73.5 74.0 74.5 75.0 AUC (%) Baseline Baseline+ReLoop2 is time slot, as we split the test dataset of MicroVideo into ten time slots in chronological order evenly to simulate online advertising task. Four methods are compared in Figure 4. \u00b7 DCNv2 is the baseline model in this experiment. \u00b7 DCNv2+IncCTR applies the incremental training method, IncCTR [61], on top of DCNv2. Specifically, after model training on the training data and model evaluation on the first part of the test data, we continually train the model using the first part of the test data and then evaluate it on the second part. The process goes on like this on ten test parts. Note that we only pass the test data once for IncCTR as suggested in the paper. \u00b7 DCNv2+ReLoop2 applies fast model adaptation (FMA) to DCNv2. \u00b7 DCNv2+IncCTR+ReLoop2 applies both incremental training and fast model adaptation (FMA) to DCNv2. Note that our ReLoop2 framework is orthogonal to the incremental training technique since ReLoop2 do not need extra training. In Figure 4, ReLoop2 outperforms IncCTR most of the time on both gAUC and AUC, except for the last two time slots, where AUC of IncCTR exceeds that of ReLoop2. It is understandable since, with the passage of time, new data distribution changes dramatically from the initial data distribution, and as a result, the accuracy of the original base model's prediction for new data decreases. As ReLoop2 relies on base model prediction and error memory with no training process, it is likely that the AUC of IncCTR exceeds that of ReLoop2 when the time slot increases. From another point of view, additional training, like incremental learning, is necessary since it can make the model have better control over new data by updating the model parameters. By combining IncCTR and ReLoop2, DCNv2 achieves the best performance in Figure 4, demonstrating the efficiency of our fast model adaptation module.", "4.4 Ablation Studies": "4.4.1 Effect of \ud835\udc3e for Memory Reading. We investigate the effect of K in Figure 5. When K is small, error compensation is mainly determined by a small number of neighbors, which can not stand for the average error in the error memory, leading to a higher but not the best gAUC. When K is too large, the final output will be influenced by those neighbor samples that are not so similar to itself, resulting in a slight decrease in gAUC, but it is generally stable. 1 2 3 4 5 6 7 8 9 10 Time Slot 68.0 68.5 69.0 69.5 70.0 70.5 71.0 71.5 gAUC (%) (a) gAUC on MicroVideo DCNv2 DCNv2 + IncCTR DCNv2 + FMA DCNv2 + IncCTR + FMA 1 2 3 4 5 6 7 8 9 10 Time Slot 72.5 73.0 73.5 74.0 74.5 75.0 75.5 76.0 (b) AUC on MicroVideo AUC (%) 30 60 90 120 150 180 210 240 K 88.55 88.60 88.65 88.70 88.75 88.80 gAUC (%) (a) Effect of Top-K on AmazonElectronics 30 40 50 60 70 80 90 100 K 69.60 69.62 69.64 69.66 69.68 69.70 69.72 gAUC (%) (b) Effect of Top-K on MicroVideo 0.0 0.3 0.5 0.7 0.9 1.1 1.3 1.5 Compensation Weight 87.9 88.0 88.1 88.2 88.3 88.4 88.5 88.6 88.7 gAUC (%) (a) Effect of on AmazonElectronics 0.0 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Compensation Weight 68.6 68.8 69.0 69.2 69.4 69.6 gAUC (%) (b) Effect of on MicroVideo The best results are obtained when we choose an appropriate K. Through our experiment, we find that K=180 and K=70 achieve the best performance of DCNv2 on AmazonElectronics and MicroVideo, respectively. 4.4.2 Effect of Compensation Weight \ud835\udf06 . We investigate the effect of compensation weights \ud835\udf06 in Figure 6. When \ud835\udf06 is small, the final output is mainly determined by the base model output, thus a bit higher but relatively close to the baseline. Specifically, when \ud835\udf06 = 0, the final output is the same as that of the base model, serving as the baseline. When \ud835\udf06 is too large, error compensation contributes more to the final output. gAUC of the final output decreases because of the lower percentage of base model, whose accuracy is supported by a large amount of training data. We empirically find \ud835\udf06 = 0 . 9 and \ud835\udf06 = 0 . 4 achieve the best performance of DCNv2 on AmazonElectronics and MicroVideo, respectively.", "5 RELATED WORK": "CTR Prediction . CTR prediction plays a key role in online advertising, recommender system, and information retrieval. Even a small improvement in CTR prediction can have a significant impact, benefiting both users and platforms. As a result, extensive research efforts have been dedicated to this field, both in academia and industry. In general, the goal of CTR prediction is to generate probability scores that represent user preferences for item candidates in specific contexts. Recently, a plethora of CTR prediction approaches have been proposed, ranging from traditional logistic regression (LR) models [45], factorization machines (FM) models [24, 53], to various deep neural network (DNN) models. Many of these models focus on designing feature interaction operators to capture complex relationships among features, such as product operators [17, 51, 55], bilinear interaction and aggregation [20, 43], factorized interaction layers [70], convolutional operators [34, 38, 40], and attention operators [5, 54]. Additionally, user behavior sequences play a crucial role in modeling user interests. Different models have been employed for behavior sequence modeling, including attention-based models [66, 67], memory network-based models [48, 52], and retrievalbased models [49, 50]. Notably, the BARS benchmark [68, 69] provides a comprehensive review and benchmarking results of existing CTR prediction models. However, all of these models focus on modeling sequential patterns during training and assume fixed parameters during testing, making them incapable of handling distribution shifts. Incremental Learning . Incremental learning is a general framework that aims to continuously update model parameters to acquire new knowledge from new data while preserving the model's ability to generalize on old data [15]. In the context of recommender systems, incremental training has been widely adopted to cope with the data distribution shift and minimize the generalization gap between training and testing. Typically, model parameters from the previous version are reused as an initialization for the next round of training [26]. To alleviate the catastrophic forgetting problem, Wang et al. [61] proposed the IncCTR method, which uses knowledge distillation to strike a balance between retaining the previous pattern and learning from the new data distribution. In our earlier work, we introduced the ReLoop framework[3], which establishes a self-correcting learning loop during the model training phase. However, ReLoop2 focuses on test-time adaptation instead. Integrating both techniques is an interesting direction and we leave it for future research. Other studies [11, 47, 65] apply meta-learning techniques to incremental training of recommendation models, aiming to facilitate knowledge transfer from old parameters to new parameters. A recent study [39] proposes an adaptive incremental learning algorithm for mixture-of-experts (MoE) models to adapt to concept drift. Instead, our work is orthogonal to incremental training and focuses on enabling fast model adaptation through error compensation using a non-parametric memory approach. Furthermore, in contrast to the majority of continual learning studies [57], ReLoop2 employs a refreshed error memory for model adaptation, deviating from the conventional practice of utilizing a memory buffer for experience replay to prevent catastrophic forgetting. Retrieval Augmentation . Our work also draws some inspiration from recent research on retrieval augmented machine learning techniques [64]. Retrieval augmentation focuses on retrieving similar key-value pairs from the external memory to enhance model generalizability, particularly for rare events or long-tail classes [25]. This approach has been successfully applied in various domains, including neural machine translation [28, 46, 60], visual recognition [22, 41], question answering [31], retrieval-augmented pretraining [14, 19] and text-to-image generation [2]. However, unlike these studies that retrieve data for model training, our work leverages refreshed online data for retrieval-augmented model adaptation. Additionally, we present a time- and memory-efficient design for top-k retrieval in large-scale online recommendation scenarios.", "6 CONCLUSION": "In this paper, we make a pioneering effort towards fast adaptation of CTR prediction models for online recommendation. To address the challenge of distribution shifts in streaming data, we introduce a slow-fast learning paradigm inspired by the complementary learning systems observed in human brains. In line with this paradigm, we propose ReLoop2, a self-correcting learning loop that facilitates fast model adaptation in online recommender systems through responsive error compensation. Central to ReLoop2 is a non-parametric error memory module that is designed to be timeand space-efficient and undergoes continual refreshing with newly observed data samples during model serving. Through comprehensive experiments conducted on open benchmark datasets and our production dataset, we demonstrate the effectiveness of ReLoop2 in enhancing model adaptiveness under distribution shifts.", "ACKNOWLEDGMENTS": "We gratefully acknowledge the support of MindSpore 1 , which is a new deep learning computing framework used for this research.", "REFERENCES": "[1] Elahe Arani, Fahad Sarfraz, and Bahram Zonooz. 2022. Learning Fast, Learning Slow: A General Continual Learning Method based on Complementary Learning System. In The Tenth International Conference on Learning Representations (ICLR) . [2] Andreas Blattmann, Robin Rombach, Kaan Oktay, Jonas M\u00fcller, and Bj\u00f6rn Ommer. 2022. Retrieval-Augmented Diffusion Models. In Annual Conference on Neural Information Processing Systems (NeurIPS) . [3] Guohao Cai, Jieming Zhu, Quanyu Dai, Zhenhua Dong, Xiuqiang He, Ruiming Tang, and Rui Zhang. 2022. ReLoop: A Self-Correction Continual Learning Loop for Recommender Systems. In The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR) . 2692-2697. [4] Moses Charikar. 2002. Similarity estimation techniques from rounding algorithms. In Annual ACM Symposium on Theory of Computing (STOC) . 380-388. [5] Qiwei Chen, Huan Zhao, Wei Li, Pipei Huang, and Wenwu Ou. 2019. Behavior Sequence Transformer for E-commerce Recommendation in Alibaba. CoRR abs/1905.06874. [6] Xusong Chen, Dong Liu, Zheng-Jun Zha, Wengang Zhou, Zhiwei Xiong, and Yan Li. 2018. Temporal Hierarchical Attention at Category- and Item-Level for Micro-Video Click-Through Prediction. In 2018 ACM Multimedia Conference on Multimedia Conference (MM) . 1146-1153. [7] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, et al. 2016. Wide & Deep Learning for Recommender Systems. In Proceedings of the 1st Workshop on Deep Learning for Recommender Systems (DLRS@RecSys) . 7-10. [8] Benjamin Coleman and Anshumali Shrivastava. 2020. Sub-linear RACE Sketches for Approximate Kernel Density Estimation on Streaming Data. In The Web Conference 2020 (WWW) . 1739-1749. [9] Aristides Gionis, Piotr Indyk, and Rajeev Motwani. 1999. Similarity Search in High Dimensions via Hashing. In Proceedings of 25th International Conference on Very Large Data Bases (VLDB) . 518-529. [33] Yongqi Li, Meng Liu, Jianhua Yin, Chaoran Cui, Xin-Shun Xu, and Liqiang Nie. 2019. Routing Micro-videos via A Temporal Graph-guided Recommendation [54] Weiping Song, Chence Shi, Zhiping Xiao, Zhijian Duan, Yewen Xu, Ming Zhang, and Jian Tang. 2019. AutoInt: Automatic Feature Interaction Learning via SelfAttentive Neural Networks. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM) . 1161-1170. [55] Yang Sun, Junwei Pan, Alex Zhang, and Aaron Flores. 2021. FM2: Field-matrixed Factorization Machines for Recommender Systems. In Proceedings of the Web Conference (WWW) . 2828-2837. [56] Jianguo Wang, Xiaomeng Yi, Rentong Guo, Hai Jin, Peng Xu, Shengjun Li, Xiangyu Wang, Xiangzhou Guo, Chengming Li, Xiaohai Xu, Kun Yu, Yuxing Yuan, Yinghao Zou, Jiquan Long, Yudong Cai, Zhenxiang Li, Zhifeng Zhang, Yihua Mo, Jun Gu, Ruiyi Jiang, Yi Wei, and Charles Xie. 2021. Milvus: A Purpose-Built Vector Data Management System. In International Conference on Management of Data (SIGMOD) . 2614-2627. [57] Liyuan Wang, Xingxing Zhang, Hang Su, and Jun Zhu. 2023. A Comprehensive Survey of Continual Learning: Theory, Method and Application. CoRR abs/2302.00487 (2023). [58] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep & Cross Network for Ad Click Predictions. In Proceedings of the 11th International Workshop on Data Mining for Online Advertising (ADKDD) . 12:1-12:7. [59] Ruoxi Wang, Rakesh Shivanna, Derek Cheng, Sagar Jain, Dong Lin, Lichan Hong, and Ed Chi. 2021. DCN V2: Improved Deep & Cross Network and Practical Lessons for Web-scale Learning to Rank Systems. In Proceedings of the Web Conference (WWW) . 1785-1797. [60] Shuhe Wang, Jiwei Li, Yuxian Meng, Rongbin Ouyang, Guoyin Wang, Xiaoya Li, Tianwei Zhang, and Shi Zong. 2021. Faster Nearest Neighbor Machine Translation. CoRR abs/2112.08152 (2021). [61] Yichao Wang, Huifeng Guo, Ruiming Tang, Zhirong Liu, and Xiuqiang He. 2020. APractical Incremental Method to Train Deep CTR Models. CoRR abs/2009.02147 (2020). [62] Yaqing Wang, Quanming Yao, James T. Kwok, and Lionel M. Ni. 2021. Generalizing from a Few Examples: A Survey on Few-shot Learning. ACM Comput. Surv. 53, 3 (2021), 63:1-63:34."}
