{"Model-based Unbiased Learning to Rank": "Dan Luo dal417@lehigh.edu Lehigh University Bethlehem, PA, USA Lixin Zou zoulixin15@gmail.com Baidu Inc. Beijing, China Qingyao Ai aiqy@tsinghua.edu.cn Tsinghua University Beijing, China Zhiyu Chen", "\u2217": "zhiyuche@amazon.com Amazon.com, Inc. Seattle, WA, USA Dawei Yin yindawei@acm.org Baidu Inc. Beijing, China", "ABSTRACT": "", "\u2020": "Brian D. Davison davison@cse.lehigh.edu Lehigh University Bethlehem, PA, USA", "ACMReference Format:": "Unbiased Learning to Rank (ULTR), i.e., learning to rank documents with biased user feedback data, is a well-known challenge in information retrieval. Existing methods in unbiased learning to rank typically rely on click modeling or inverse propensity weighting (IPW). Unfortunately, search engines face the issue of a severe long-tail query distribution, which neither click modeling nor IPW handles well. Click modeling usually requires that the same query-document pair appears multiple times for reliable inference, which makes it fall short for tail queries; IPW suffers from high variance since it is highly sensitive to small propensity score values. Therefore, a general debiasing framework that works well under tail queries is sorely needed. To address this problem, we propose a modelbased unbiased learning-to-rank framework. Specifically, we develop a general context-aware user simulator to generate pseudo clicks for unobserved ranked lists to train rankers, which addresses the data sparsity problem. In addition, considering the discrepancy between pseudo clicks and actual clicks, we take the observation of a ranked list as the treatment variable and further incorporate inverse propensity weighting with pseudo labels in a doubly robust way. The derived bias and variance indicate that the proposed model-based method is more robust than existing methods. Extensive experiments on benchmark datasets, including simulated datasets and real click logs, demonstrate that the proposed modelbased method consistently outperforms state-of-the-art methods in various scenarios. The code is available at https://github.com/ rowedenny/MULTR.", "CCS CONCEPTS": "\u00b7 Information systems \u2192 Learning to rank .", "KEYWORDS": "Unbiased Learning to Rank; Doubly Robust; User Simulator \u2020 Corresponding author. \u2217 The work was done prior to joining Amazon. This work is licensed under a Creative Commons Attribution International 4.0 License. WSDM '23, February 27-March 3, 2023, Singapore, Singapore \u00a9 2023 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-9407-9/23/02. https://doi.org/10.1145/3539597.3570395 Dan Luo, Lixin Zou, Qingyao Ai, Zhiyu Chen \u2217 , Dawei Yin \u2020 , and Brian D. Davison. 2023. Model-based Unbiased Learning to Rank. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (WSDM '23), February 27-March 3, 2023, Singapore, Singapore. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3539597.3570395", "1 INTRODUCTION": "Search engines serve as one of the most important tools for accessing information online. In modern search engines, learning to rank (LTR) algorithms play a critical role by creating models to accurately order a list of candidate documents based on their relevance to the query. As deep supervised models have been widely applied and been state-of-the-art in many ranking tasks [8, 13, 48, 51, 56, 58], obtaining large-scale and high-quality training data has become a bottleneck for the development of large scale learningto-rank systems [5, 57]. In practice, implicit feedback that reflects users' information needs [37] provides natural, abundant sustainable training data for ranking optimization without costly time consumption and human annotation. Therefore, LTR with implicit feedback such as clicks has received considerable attention in the IR community. However, click data is biased since relevance is not the only factor influencing users' clicks. For example, position bias occurs because users are more likely to examine documents at higher ranks [11, 24]. Consequently, the highly ranked document may receive more clicks, and the relevant document may be perceived as a negative sample simply by not being examined by users. Furthermore, ranking positions [23], display differences [38, 50], users' first impression [32], etc ., also influence the implicit feedback. These biases make the data deviate from reflecting true relevance, and jeopardize the learned ranking model's performance. Tobeunaffected by biases [25], there are two groups of methods: (1) Click modeling methods explicitly introduce an additional factor as bias, make hypotheses about users' browsing behaviors, and estimate true relevance by optimizing the likelihood of observed user clicks [7, 11, 15, 45]. Click models are straightforward yet effective, and they have made promising progress for various applications, such as CTR prediction in live recommendation [16] and grid view web applications [54]. However, search engines are faced with severe long-tail query distribution, where click models can fall short since multiple observations for the same query may not be available [2]. (2) Propensity-basedmethods treat the click bias as the counterfactual factor [34], and re-weight the click data WSDM '23, February 27-March 3, 2023, Singapore, Singapore Dan Luo et al. Figure 1: The framework of model-based unbiased learning to rank. User Search Engine Interact Click Logs \u2026 Observed Ranked List with Real Clicks \u2026 Unobserved Ranked List with Pseudo Labels Train Infer Context-aware User Simulator Offline Shuffle Simulate Doubly Robust Learning Ranker Model Inverse Propensity Weighting Imputation Based Estimation User Simulator for a relevance-equivalent training loss through inverse propensity weighting (IPW) [25, 46]. To this end, many approaches [2, 20, 44] are proposed to jointly learn user bias models (i.e., propensity models) with unbiased rankers. However, propensity-based methods generally suffer from high variance [35], which can lead to suboptimal estimation [41]. Therefore, a general debiasing framework with low variance is needed. To address these challenges, we propose a novel model-based unbiased learning to rank (MULTR) framework, as shown in Figure 1. MULTR consists of a context-aware user simulator for addressing the data sparsity problem and a doubly-robust learning algorithm for reducing the variance and achieving unbiased estimation. Specifically, we first develop a user simulator that directly learns from click data, which generates pseudo clicks for unobserved ranked lists as data imputation and alleviates the sparse training data problem. Remarkably, the user simulator is unbiased since the factor, i.e., the position, influencing the click is being considered as its input, which ensures the consistency between the training of user simulator and data augmentation. However, as the user simulator cannot be as accurate as real users, the discrepancy between pseudo and actual clicks may mislead the ranking models, and unbiasedness cannot be guaranteed. To reduce the variance and ensure the unbiasedness, we resort to doubly robust approaches. In particular, we propose to take the observation of ranked lists as the treatment, generate pseudo-click data via offline result randomization , and incorporate the inverse propensity weighting with pseudo-click labels in a doubly robust way, where the user simulator essentially functions as the imputation model. The derived bias and variance indicate that the proposed modelbased method has low bias and low variance. Thus, it is more robust than existing methods. To demonstrate the effectiveness of the proposed method, we conduct extensive experiments on simulated and real datasets, and demonstrate that the proposed model-based method consistently outperforms state-of-the-art methods. The contributions of the proposed model-based unbiased learning to rank framework can be summarized as follows: \u00b7 We propose model-based unbiased learning to rank (MULTR) a general debiasing framework with low variance. \u00b7 We devise a user simulator, which addresses data sparsity by generating pseudo-click labels for unobserved ranked lists. \u00b7 We propose the observation of rank lists as treatment, which addresses the treatment unobservability in unbiased learning to rank, and incorporate inverse propensity weighting with pseudo labels in a doubly robust way. \u00b7 We conduct extensive experiments on simulated datasets and real user click logs to demonstrate the superiority of MULTR.", "2 RELATED WORK": "Unbiased Learning to Rank. To extract unbiased and reliable relevance signals from biased click signals, there are two streams of unbiased learning to rank methodologies. One school depends on click modeling, which makes assumptions about user browsing behaviors. Such methods maximize the likelihood of the observed data, model the examination probability and infer accurate relevance feedback from user clicks [6, 9, 11, 30]. For example, Guo et al. [16] propose a position-bias aware learning framework for CTR prediction that models position-bias in offline training and conducts online inference without biased information. Wang et al. [47] unify the training of the ranker model and the estimation of examination propensity with a graphical model and an EM algorithm. Despite their success, one major drawback of click models is that they usually require that the same query-document pair appears multiple times for reliable inference [29]; thus they may fall short for tail queries. The other school derives from counterfactual learning, which treats bias as a counterfactual factor and debiases user clicks via inverse propensity weighting [25, 46]. Recent efforts jointly model the propensity estimation and unbiased learning to rank. For instance, Ai et al. [2] and Hu et al. [20] present dual learning frameworks for estimating bias and training a ranking model. Vardasbi et al. [43] propose cascade model-based inverse propensity scoring for propensity estimation in the cascade scenario. However, these methods ignore the severe high variance problem in IPW-based methods, particularly for long-tail data. Our paper falls in the same propensity-based framework; however, we address the high variance problem by optimizing the ranking model in a doubly robust way, which has low bias and low variance. Model-based Methods. Model-based methods aim to construct a predictive user model and ask the question of the counterfactual form 'what will the user click if the search result page is presented differently?', which naturally fits debiasing. Recent work has proposed some methods that improve ranking performance based on user simulators. For example, Dai et al. [12] propose a utility estimator to generate counterfactual data to train the ranking model. Zhang et al. [53] develop a reinforcement learning algorithm to learn ranking policies in the simulation environments. While both methods show promising improvements, the theoretical guarantees with respect to unbiasedness are unclear. Different from such work, we leverage the user simulator as the imputation model in a doubly-robust way, which addresses the high bias issue caused by the discrepancy between user simulator and real clicks. More importantly, our derivation demonstrates the unbiasedness of the proposal. Our ablation study verifies that the doubly robust approach can effectively leverage both real and pseudo clicks, and improve the ranking performance. Model-based Unbiased Learning to Rank WSDM'23, February 27-March 3, 2023, Singapore, Singapore Doubly-Robust Methods. Doubly-Robust(DR)methods have been widely applied to position-biased clicks. Saito [36] proposes a DR method for post-click conversions. Guo et al. [17] further develop a more doubly robust estimator to reduce the variance. Kiyohara et al. [26] develop a cascade doubly robust estimator for off-policy evaluation, Yuan et al. [49] introduce a DR estimator for click-throughrate prediction. Zou et al. [55] propose a doubly robust estimator for relevance estimation. A significant difference between current DR estimators and those in ULTR is that existing solutions use corrections based on action propensities, which is similar to generic counterfactual estimation; while ULTR needs examination propensities [31], which unfortunately is unobservable in click logs. In this paper, we address this challenge by taking the observation of rank lists as treatment, and incorporate the inverse propensity weighting with pseudo-click labels in a doubly-robust way.", "3 PRELIMINARIES": "This section presents the task of unbiased learning to rank and reviews the preliminary methods of click modeling and propensitybased methods with their strengths and weaknesses.", "3.1 Task Formulation": "Let D be the universal set of documents, and Q be the universal set of queries. For a user-issued query /u1D45E \u2208 Q , we use /u1D45F /u1D451 to denote the relevance annotation over the query /u1D45E and document /u1D451 \u2208 D . The goal of learning to rank is to find a mapping function from a query document pair ( /u1D45E, /u1D451 ) to its relevance /u1D45F /u1D451 as /u1D453 : Q\u00d7D \u2192 R . A corresponding local loss function is usually proposed to learn the best /u1D453 , given its retrieved ranked list /u1D70B /u1D45E as,  where \u0394 is a function that computes the individual loss on each document. \u2113 /u1D456 /u1D451 /u1D452 /u1D44E /u1D459 ( /u1D453 , /u1D45E ) is the ideal local ranking loss for optimizing the ranking function /u1D453 with all the documents annotated. Without loss of generality, we simplify the individual loss function \u0394 ( /u1D453 ( /u1D45E, /u1D451 ) , /u1D45F /u1D451 | /u1D70B /u1D45E ) as \u0394 ( /u1D45F /u1D451 | /u1D70B /u1D45E ) . Typically, the relevance annotation /u1D45F /u1D451 is elicited through expert judgment; thus /u1D45F /u1D451 is considered to be unbiased, but expensive. An alternative approach is to use click data as relevance feedback from users. Suppose there is a click dataset in which the clicks on documents with respect to queries by an initial ranking model are logged. If we conduct learning to rank by replacing the relevance label /u1D45F /u1D451 with click label /u1D450 /u1D451 in Equation 1, then the empirical local ranking loss is derived as follows,  where /u1D70B /u1D45C is the observed ranked list, which is the ranked list presented to users, and /u1D450 /u1D451 is a binary variable indicating whether the document /u1D451 in the ranked list /u1D70B /u1D45C is clicked. However, this naive loss function is biased. For instance, position bias occurs because users are more likely to examine the documents at higher ranks [25]. Consequently, highly ranked documents may receive more clicks, and relevant (but unclicked) documents may be perceived as negative samples because they are unexamined by users. To address this issue, unbiased learning-to-rank aims to eliminate bias in click data and then train a ranking model with the resulting user clicks.", "3.2 Click Modeling": "To eliminate biases in click data, one intuitive method is to model bias and relevance as independent factors, and represent the joint effects of bias and relevance with bias-aware click modeling [16, 27]. Here we refer to the general approach as click modeling. Let b be the bias features, and x /u1D451 be the vector representation of document /u1D451 , then the bias-aware click predictor is modeled as follows:  where \u02c6 /u1D443 ( /u1D450 /u1D451 = 1 , /u1D45E ) is the estimated click probability of document /u1D451 of query /u1D45E . \u210e is the bias model parameterized by /u1D719 that generates a score based on the inputs of bias features. /u1D453 is the relevance prediction model parameterized by /u1D703 that generates a relevance score based on the relevance representations. \u2295 is an operation that combines the bias-based score and the relevance score, which could be addition [54], multiplication [16], etc . The general local ranking loss of a bias-aware click predictor is defined as:  where /u1D450 /u1D451 is a binary variable indicating whether document /u1D451 is clicked, and CE (\u00b7 , \u00b7) the cross-entropy function. When conducting the relevance inference, one can easily eliminate the influence of bias by dropping the scores from \u210e ( b ; /u1D719 ) , i.e., directly ranking with /u1D453 ( x /u1D451 , /u1D703 ) . Though click models work well with head queries, they could fall short when multiple observations of the same query may not be available [2].", "3.3 Propensity-based Methods": "Inverse propensity weighting (IPW) is the first unbiased learning to rank algorithm proposed under the propensity-based framework [25, 46]. Let /u1D452 /u1D451 , /u1D450 /u1D451 be the binary variables that represent whether document /u1D451 is examined and clicked by a user, based on the Examination Hypothesis [33] that a user would only click a document when it is observed by the user and considered relevant to the user's need, we have  Then, IPW instantiates the local ranking loss as  where \u02c6 /u1D443 ( /u1D452 /u1D451 = 1 ) is the estimated probability that document /u1D451 is examined in the query session. A nice property is that only clicked documents /u1D450 /u1D451 = 1 contribute to the estimation in Eq. 6. Bias and Variance Analysis. We analyze the bias and variance of the inverse propensity weighting approach. WSDM '23, February 27-March 3, 2023, Singapore, Singapore Dan Luo et al. Theorem 3.1. The bias of the IPW estimators is  Proof. Joachims et al. [25] proved that a ranking model trained with clicks and IPW loss will converge to the same model trained with true relevance labels; see Ai et al. [2] for more detail. /square AsshowninTheorem3.1,whentheestimatedexamination probability is accurate, i.e., /u1D443 ( /u1D452 /u1D451 /u1D456 = 1 ) = \u02c6 /u1D443 ( /u1D452 /u1D451 /u1D456 = 1 ) , then /u1D435/u1D456 /u1D44E/u1D460 [ \u2113 /u1D43C /u1D443/u1D44A ] = 0, indicating accurate estimation can be achieved with rich observation data. Then, we derive the variance of the IPW estimators. Theorem 3.2. The variance of the IPW estimator is  Proof. For the IPW estimator, its variance on the observed ranking documents is:  Theorem 3.2 illustrates that the variance of IPW estimators depends on the estimated propensity. When \u02c6 /u1D443 ( /u1D452 /u1D451 = 1 ) is small, it may lead to high variance. Especially for long-tail queries with rare observation data, the high variance of IPW becomes a problem that directly influences the effectiveness of the ranker.", "4 MODEL-BASED UNBIASED LEARNING TO RANK": "In this section, we first introduce the context-aware user simulator, which generates pseudo-click labels for unobserved ranked lists as data imputation and addresses the data sparsity. Afterwards, we propose a doubly robust estimator, which takes the observation of ranked lists as the treatment, and further incorporates inverse propensity weighting with pseudo labels from the user simulator above in a doubly robust way. Lastly, we derive the bias and variance of the proposed method, and demonstrate that our proposed method is more robust than existing methods. Figure 2: Framework of the Context-aware User Simulator. Bi-LSTM Bi-LSTM Bi-LSTM \u2026 Query Context + + + Local Context Encoder LSTM LSTM LSTM Click Probability Context-aware Click Decoder Query Ranked List Gumble-Softmax Layer Previous Action Click Probability Click Probability Unknown Previous Action", "4.1 Context-aware User Simulator": "The user simulator consists of two important components: a local context encoder, which captures different feature distributions from different queries, and a context-aware click decoder, which produces the click probability of each document sequentially. The framework of our user simulator is shown in Fig. 2. Local Context Encoder. To capture the characteristics of queries, i.e., different queries may have different distributions in the feature space [1], we first design a local context encoder for each query and use it to refine the query-specific features, as shown at the bottom block in Figure 2. Formally, given the top /u1D441 documents { /u1D451 /u1D456 } /u1D441 /u1D456 = 1 in a ranked list /u1D70B /u1D45E from top to bottom, and their corresponding feature vectors { x /u1D456 } /u1D441 /u1D456 = 1 , we use a bi-directional long short-term memory [19] network to obtain a contextual representation of each document with respect to the entire ranked list:  where [\u00b7 ; \u00b7] is concatenation, and - - - - \u2192 LSTM ( x /u1D456 , /u1D456 ) processes the document /u1D465 from top to bottom and returns the LSTM hidden state at position /u1D456 (and vice versa for the backward direction \u2190- - - -LSTM). We then produce the local context representation h /u1D70B /u1D45E by a linear transformation of the last hidden state h /u1D441 . Context-aware Click Decoder. Tocharacterize different influences from the previous actions, we encode actions with an embedding matrix A . In our settings, there are three types of actions, i.e., click , skip , and unknown , where unknown is designed for the initial step. We use h /u1D44E /u1D461 to denote the action embedding corresponding to action /u1D44E /u1D461 at step /u1D461 . The context-aware click decoder is formulated as:  where W 1 , W 2 , W 3 , b 1 , b 2 , b 3 are the trainable parameters used to transform the query context vector, the document vector and the previous action embedding, respectively. Model-based Unbiased Learning to Rank WSDM'23, February 27-March 3, 2023, Singapore, Singapore At each step /u1D461 , the hidden state h /u1D461 is projected into a conditional click probability score through the sigmoid function:  where W 4 , b 4 are trainable parameters, and /u1D45D /u1D461 \u2208 [ 0 , 1 ] represents the probability that a user clicks document /u1D451 /u1D461 . User Simulator Optimization. After obtaining the click probability score /u1D45D /u1D461 for each document, we train the user simulator by applying the binary cross-entropy:  where /u1D454 is the whole context-aware user simulator, /u1D450 /u1D461 denotes the click label of document /u1D451 /u1D461 in observed ranked list /u1D70B /u1D45C , /u1D719 denotes all the parameters of the user simulator /u1D454 , and /u1D706 denotes the /u1D43F 2 regularization coefficient. Discussion . It is worth noting that the goal of this paper is not to propose a high-performance user simulator. More sophisticated models, such as utility estimator [12] and UBS4RL [52], can be applied here. We leverage the user simulator as the imputation model to generate pseudo-click labels for an arbitrary ranked list. In the next section, we will leverage the user simulator in a doubly robust way to obtain unbiased ranking models.", "4.2 Doubly Robust Learning": "User simulators have the benefit of data imputation [18]. However, directly optimizing the ranking model through the user simulator could be highly biased due to the discrepancy between pseudo labels and actual clicks, i.e., the pseudo clicks cannot be as accurate as real clicks. To address this problem, we resort to the doubly robust approach. Unfortunately, the treatment, i.e., document examination, is not directly observable in click data. It is because when a document is not clicked, we cannot determine whether the user chose not to click or the user did not examine it [31]. To overcome this bottleneck, we propose to take the observation of ranked lists as the treatment. After that, we incorporate inverse propensity weighting with pseudo-clicked labels in a doubly robust way, where the user simulator essentially functions as the imputation model. Before we describe our doubly robust estimator for unbiased learning to rank, we introduce two concepts: prediction error and imputation error. We refer to the local ranking loss \u2113 /u1D45B/u1D44E/u1D456 /u1D463/u1D452 in Eq 2 with actual clicks as prediction error . Then the imputed error \u2113 /u1D43C /u1D440 /u1D443 , i.e., the estimated value of the prediction error, is defined as:  where \u02c6 /u1D450 /u1D451 is the imputed click generated from the user simulator for each document /u1D451 in the observed ranked list /u1D70B /u1D45C under query /u1D45E . Let \u03a0 /u1D45E be the set of document permutations, i.e., all possible ranked lists. We simplify \u03a0 /u1D45E as \u03a0 when there is no ambiguity for the issued query /u1D45E . We propose our doubly robust (DR) estimator by combining the imputed errors for all ranked lists, and the IPWbased prediction error for observed ranked lists. The loss function of the DR estimator given query /u1D45E is defined as:  where \u02c6 \u2113 /u1D43C /u1D443/u1D44A ( /u1D453 , /u1D45E | /u1D70B ) = \u2211 /u1D451 \u2208 /u1D70B , \u02c6 /u1D450 /u1D451 = 1 \u0394 ( \u02c6 /u1D450 /u1D451 | /u1D70B ) \u02c6 /u1D443 ( /u1D452 /u1D451 = 1 ) is the propensity score weighted imputed error, and /u1D45C /u1D70B = /BD { /u1D70B = /u1D70B /u1D45C } indicates whether /u1D70B is an observed ranked list. A nice property of the DR estimator is: if either the imputed error of any unobserved ranked list or the estimated propensities of any observed ranked list is accurate, the DR estimator is then unbiased [17, 55], which is recognized as double robustness . Discussion . Careful readers may notice that our method is similar in spirit to result randomization. Ideally, if the pseudo-click labels generated from the user simulator are accurate for any unobserved ranked lists, learning from user simulators would be equivalent to learning from online result randomization, which is unbiased in principle [25, 46]. However, online result randomization is often impractical since it can negatively affect the user experience. Our method overcomes the aforementioned limitations by leveraging the user simulator in a doubly robust way, and simultaneously obtains unbiased ranking models.", "4.3 Bias and Variance of DR Estimator": "In this section, we derive the bias and variance of MULTR, and prove its double robustness. Theorem 4.1. Let /u1D6FF /u1D70B , /u1D451 = /u1D450 /u1D451 \u0394 ( /u1D450 /u1D451 | /u1D70B ) -\u02c6 /u1D450 /u1D451 \u0394 ( \u02c6 /u1D450 /u1D451 | /u1D70B ) be the error deviation, and /u1D70C /u1D45E, /u1D451 = /u1D443 ( /u1D452 /u1D451 = 1 )-\u02c6 /u1D443 ( /u1D452 /u1D451 = 1 ) \u02c6 /u1D443 ( /u1D452 /u1D451 = 1 ) be the propensity deviation. The bias of the doubly robust (DR) estimator is  /u1D435/u1D456 /u1D44E/u1D460 [ \u2113 /u1D437 /u1D445 ( /u1D453 , /u1D45E | /u1D70B /u1D45C ) ]   WSDM '23, February 27-March 3, 2023, Singapore, Singapore Dan Luo et al. In the third line, we expand \u2113 /u1D456 /u1D451 /u1D452 /u1D44E /u1D459 with online result randomization. Based on the examination hypothesis in Eq 5, the terms in the first row can be derived as,   Finally, combing the two parts above, we derive the bias of the proposed DR estimator  As shown in Theorem 4.1, when the imputed error is accurate ( /u1D6FF /u1D45E, /u1D451 = 0 ) or the propensity estimation is accurate ( /u1D70C /u1D45E, /u1D451 = 0 ) , the bias of DR estimator /u1D435/u1D456 /u1D44E/u1D460 [ \u2113 /u1D437 /u1D445 ( /u1D453 , /u1D45E | /u1D70B /u1D45C )] = 0. Next, we derive the variance of the DR estimator. Theorem 4.2. The variance of the DR estimator is  Proof. The variance of \u2113 /u1D437 /u1D445 ( /u1D453 , /u1D45E | /u1D70B /u1D45C ) with respect to the observation indicator O is V O [ \u2113 /u1D437 /u1D445 ( /u1D453 , /u1D45E | /u1D70B /u1D45C ) ]  where the third step utilizes the similar derivation in Eq 9. /square In Theorem 4.2, we demonstrate that the variance of the DR estimator depends on the estimated propensity, i.e., \u02c6 /u1D443 ( /u1D452 /u1D451 = 1 ) , which may lead to a high variance problem. Recall the variance of the IPW estimator in Theorem 3.2; it is worth noting that our DR estimator can still reduce the variance of the IPW estimator, if any given observed ranked list satisfies [ /u1D450 /u1D451 \u0394 ( /u1D450 /u1D451 | /u1D70B ) -\u02c6 /u1D450 /u1D451 \u0394 ( \u02c6 /u1D450 /u1D451 | /u1D70B )] 2 \u2264 [ /u1D450 /u1D451 \u0394 ( /u1D450 /u1D451 | /u1D70B )] 2 . Then, the variance of the DR estimator is smaller than that of the IPW-based estimator.", "4.4 Learning Framework": "We summarize the learning framework in Algorithm 1. It is worth noting that the proposed MULTR is a plug-in model, which can be seamlessly integrated into any IPW-based unbiased learning to rank framework without result randomization, such as DLA [2] and REM [47].", "Algorithm 1: Model-based Unbiased Learning to Rank": "Input : query set Q , an IPW-based framework /u1D439 Output: ranking model /u1D453 ( /u1D703 ) and user simulator /u1D454 ( /u1D719 ) 1 Initialize the parameters /u1D703 , /u1D719 ; 2 for number of steps for training the user simulator do 3 Sample a batch of queries /u1D444 from Q , with observed ranked lists \u03a0 /u1D45C ; 4 Update /u1D719 , according to Eq. 13 ; 5 end 6 for number of steps for training the unbiased ranking model do 7 Sample a batch of queries /u1D444 from Q , with observed ranked lists \u03a0 /u1D45C ; 8 Obtain unobserved ranked lists \u03a0 /u1D462 by result randomization over \u03a0 /u1D45C ; 9 Generate pseudo-click labels \u02c6 /u1D450 /u1D451 for all ranked list \u03a0 = \u03a0 /u1D45C \u222a \u03a0 /u1D462 by sampling on the click probabilities, according to Eq. 12 1 ; 10 Update /u1D703 , according to Eq. 15 11 end", "5 EXPERIMENTAL SETUP": "To analyze the effectiveness of MULTR, we conduct two types of experiments. The first is simulation experiments based on two of the largest public learning-to-rank datasets. The second is an experiment based on the actual rank lists and user clicks collected from a commercial web search engine.", "5.1 Simulation Experiment Setup": "To fully investigate the spectrum of propensity estimation and performance of MULTR, we conduct experiments on two of the largest publicly available datasets: \u00b7 Yahoo! LETOR 2 comes from the Learn to Rank Challenge version 2.0 (Set 1), and it is one of the largest benchmark datasets widely used in unbiased learning to rank [2, 20]. It consists of 29,921 queries and 710K documents. Each query-document pair 1 Due to the large sample space of all possible ranked lists ( i.e., /u1D441 documents have /u1D441 ! permutations), we decrease the sample size in practice. 2 https://webscope.sandbox.yahoo.com/ Model-based Unbiased Learning to Rank WSDM'23, February 27-March 3, 2023, Singapore, Singapore is represented by a 700-D feature vector, and annotated with 5level relevance labels [4]. \u00b7 Istella-S 3 contains 33K queries and 3,408K documents (roughly 103 documents per query) sampled from a commercial Italian search engine. Each query-document pair is represented by 220 features and annotated with 5-level relevance judgments [28]. We follow the predefined data split of training, validation and testing of all datasets. The Yahoo! set splits the queries arbitrarily and uses 19,944 for training, 2,994 for validation and 6,983 for testing. The Istella-S dataset has been divided into train, validation and test sets according to a 60% -20% -20% scheme. Click Simulation. We generate click data on both datasets with a two-step process as in Joachims et al. [25] and Ai et al. [2]. First, we train a Rank SVM model [22] using 1% of the training data with real relevance labels to generate the initial ranked list /u1D70B /u1D45E for each query /u1D45E . Then, we simulate the user browsing process and sample clicks from the initial ranked list by utilizing the simulation model. The simulation model generates clicks based on the examination hypothesis in Equation 5. Following the methodology proposed by Chapelle et al. [6], the relevance probability is set to be  where /u1D466.alt \u2208 [ 0 , /u1D466.alt max ] is the relevance label of the document /u1D451 /u1D456 , and /u1D466.alt max is the maximum value of /u1D466.alt , which is 4 on both datasets. /u1D716 is the noise level, which models click noise such that irrelevant documents ( i.e., /u1D466.alt = 0) have a non-zero probability to be perceived as relevant and clicked. We fix /u1D716 = 0 . 1 as the default setting. Weusethecascade model[11] to generate the examination probability. It is a context-aware click model, and a user is modeled as searching and clicking documents from top to bottom, and deciding whether to click each result before moving to the next; users stop examining a search result page after the first click. The cascade model is defined as,  where /u1D452 and /u1D450 are binary variables that indicate whether the document /u1D451 is examined and clicked. Baselines. Todemonstratethe effectiveness of our proposed method, we compare with baseline methods, including IPW-based methods and bias modeling methods, which are widely used in ULTR problems. \u00b7 DLA : The Dual Learning Algorithm [2] treats the problem of unbiased learning to rank and unbiased propensity estimation as a dual problem, such that they can be optimized simultaneously. \u00b7 REM : The Regression EM model [47] uses an EM framework to estimate the propensity scores and ranking scores. \u00b7 PairD : The Pairwise Debiasing (PairD) Model [20] uses inverse propensity weighting for pairwise learning to rank. \u00b7 PAL : The Position-bias Aware Learning framework [16] is a bias modeling method. It introduces a position model to explicitly represent position bias, and jointly model the bias and relevance. 3 http://quickrank.isti.cnr.it/istella-dataset/ \u00b7 Oracle : This model utilizes human experts' annotated labels to train the ranking model and test its performance. Its performance can be considered as an upper bound for the ranking model. \u00b7 Naive : This model just uses the raw click data to train the ranking model, without any correction. Its performance can be considered as a lower bound for the ranking model. In addition, we also consider two variants of MULTR as follows, \u00b7 Rand-MULTR : We replace the well-trained user simulator with the model with random initialization, i.e., we skip lines 2-5 in the Algorithm 1. We refer to this variant as Rand-MULTR. \u00b7 EIB-MULTR : We alternate the doubly robust loss in Equation 15 with the error imputation based loss [18], defined as \u2113 /u1D438 /u1D43C /u1D435 = 1 | \u03a0 | \u2211 /u1D70B \u2208 \u03a0 \u2113 /u1D45B/u1D44E/u1D456 /u1D463/u1D452 ( /u1D453 , /u1D45E | /u1D70B ) . It is called EIB since it uses the user simulator to compute an imputed error, i.e., the estimated values of the ranking loss, for each unobserved ranked list, and then used it to estimate the true ranking loss for all the ranked lists. We refer this variant as EIB-MULTR. Experimental Protocols. Weimplement MULTRand usethe baselines in ULTRA 4 [42] to conduct our experiments. In particular, MULTR is integrated with DLA, as we consider it to be the best method to estimate propensity. For each query, only the top /u1D441 = 10 documents are assumed to be displayed to the users. For both datasets, all models are trained with synthetic clicks. Following the setting in Ai et al. [2], the click sessions for training are generated on the fly. We fix the batch size to 256 and train each model for 10K steps. The user simulator is also trained with batch size of 256 and 10K steps; afterwards, we fix it to generate pseudo-click labels. We use the AdaGrad optimizer [14] and tune learning rates from 0.01 to 0.05 for each unbiased learning-to-rank algorithm. In our experiments, we train neural networks for our ranking functions. All reported results are produced using a model with three hidden layers with size [ 512 , 256 , 128 ] respectively, with the ELU [10] activation function and 0.1 dropout [40]. In terms of imputation model, the dimension of the hidden states is 64. We tune the /u1D43F 2 regularization coefficient /u1D706, /u1D707 in range of { 1 /u1D452 -5 , 1 /u1D452 -4 , \u00b7 \u00b7 \u00b7 , 1 } , and the number of pseudo samples in { 2 , 4 , 8 , 16 , 24 , 32 } based on results in the validation set. To evaluate all methods, we use the normalized Discounted Cumulative Gain (nDCG) [21] and the ExpectedReciprocal Rank (ERR) [6]. For both metrics, we report the results at rank 1, 3, 5, and 10 to show the performance of models at different positions. Following Ai et al. [2], statistical differences are computed based on the Fisher randomization test [39] with /u1D45D \u2264 0 . 05.", "5.2 Real Click Experiment Setup": "In order to show the effectiveness of MULTR in practice, we also conduct experiments on click data Tiangong-ULTR 5 collected froma commercial web search engine [2, 3]. It contains 3,449 queries written by real search engine users and the corresponding top 10 results are sampled from a two-week search log collected on Sogou 6 . The raw HTML documents are downloaded, and then the rank lists that cannot be crawled are removed. After cleaning, there 4 https://github.com/ULTR-Community/ULTRA_pytorch/ 5 http://www.thuir.cn/data-tiangong-ultr/ 6 https://www.sogou.com/ WSDM '23, February 27-March 3, 2023, Singapore, Singapore Dan Luo et al. are 333,813 documents, 71,106 ranked lists and 3,268,177 anonymous click sessions. Feature Extraction. Totrain the learning-to-rank models, features are extracted based on the text of queries and documents. The ranking features are constructed based on the URL, title, content and whole text of the documents and queries [2]. In total, each querydocument pair has 33 features. Evaluation. Tiangong-ULTR provides a test set with 100 queries written by real users. Each query has 100 candidate documents (retrieved by BM25) and each query-document pair has 5-level relevance annotation. We train the ranking model in MULTR and baselines on the training set with clicks following the same protocols in the simulation experiments, and we evaluate their performance on the test set with human annotations. Similar to the simulation experiments, we report nDCG and ERR for all models.", "6 RESULTS AND ANALYSIS": "In this section, we discuss the results of our proposed model-based unbiased learning to rank method with existing approaches using both simulated and real-world experiments. In general, we expect the experimental results to answer the following research questions: \u00b7 RQ1 : Can MULTR outperform state-of-the-art unbiased learning to rank methods? \u00b7 RQ2 : What influence do variant designs have on MULTR? \u00b7 RQ3 : How does the sample number of unobserved ranked lists influence the performance of MULTR? \u00b7 RQ4 : How does MULTR perform on real click logs?", "6.1 Performance Comparison (RQ1)": "To answer RQ1, we compare MULTR with other unbiased learningto-rank algorithms in the simulation experiments. Table 1 summarizes the performance of different unbiased learning to rank algorithms under various click situations. We find that: \u00b7 Our model-based unbiased learning to rank achieves the best performance among all the state-of-the-art methods in terms of nDCG and ERR, which indicates our model is robust when propensity cannot be accurately estimated. \u00b7 Reducing variance can enhance performance on unbiased learning to rank. As MULTR shares the same method with DLA in estimating propensity, the improvements over DLA demonstrate the necessity of handling variance in IPW-based methods. \u00b7 The naive method may achieve better performance than some unbiased learning to rank methods when clicks are generated by a cascade model. One explanation is that documents displayed at a lower rank have a higher opportunity to be examined; thus they receive more clicks, which alleviates the bias in click data. This observation confirms that a mismatch between propensity estimation and real bias could lead to performance even worse than raw click data. \u00b7 The oracle model with human annotation consistently achieves the best performance. It implies that there is still room to improve in unbiased learning to rank methods.", "6.2 Ablation Study (RQ2)": "MULTR has specific design features, including a context-aware user simulator and a doubly robust loss function to train rankers. To demonstrate their effectiveness, we analyze their respective impacts on the model's performance via ablation study. The experimental results of its two variants on two datasets are summarized in Table 1. We analyze their respective effects as follows. (1) Rand-MULTR: When we replace the well-trained user simulator with one from random initialization, the performance of Rand-MULTR significantly degrades. This observation verifies the necessity of an accurate user simulator for the doubly robust estimator learning process: when the user simulator has a high bias due to inaccurate click imputations, it will mislead the rankers. (2) EIB-MULTR: When we use the same treatments for real clicks from observations and pseudo clicks from user simulators, the performance of EIB-MULTR suffers a significant decrease. This suggests, naturally, that there is a discrepancy between real clicks and pseudo clicks. The doubly robust approach effectively leverages pseudo clicks and improves the performance of rankers.", "6.3 Parameter Sensitivity Study (RQ3)": "As we have explained previously, when /u1D441 is the maximum number of documents that can be shown to users, there will be /u1D441 ! candidate ranked lists, which could be large. Therefore, we decrease the number of samples for unobserved ranked lists in practice. To investigate its impact in MULTR, we vary the sample size for unobserved ranked lists in the range of { 0 , 2 , 4 , 8 , 16 , 24 , 32 } . Figure 3 shows the NDCG@K and ERR@K for MULTR with respect to different sample sizes on both datasets. First, MULTR with sample number 0, i.e., we merely sample from unobserved candidate rank lists, derives the worst performance. This observation shows that the well-trained user simulator enables the unobserved rank lists to provide rankers with useful information. Second, when the sampling number increases from 0 to 8, the performance at all levels increases. This shows that sampling more unobserved rank lists can bring more beneficial information to rankers. Third, overly large sampling does not show a significant improvement, even though we should sample all unobserved rank lists in theory. We even observe that NDCG starts to decrease when the sample number increases from 8 to 32. One possible reason could be that the observed rank lists are typically sparse in practice, meaning that we cannot ensure that the rankers obtain sufficient information. For both datasets, the optimal sampling size is 8. In conclusion, setting the sampling size too conservatively or too aggressively may adversely affect the ranking performance, and too aggressively also brings in unnecessary computational cost.", "6.4 Real Data Study (RQ4)": "As we have demonstrated that the proposed MULTR works well in the simulation study, we would further investigate how it performs on real click logs recorded by the search engine. We compare MULTRwith existing unbiased learning to rank algorithms on real data. The experimental results are summarized in Table 2. From the Model-based Unbiased Learning to Rank WSDM'23, February 27-March 3, 2023, Singapore, Singapore Table 1: A comparison of the overall performance MULTR and competing methods on Yahoo! and Istella-S datasets. ' \u2217 ' indicates a statistically significant improvement over the best baseline. Figure 3: Study of effect of sample size for unobserved ranked lists on Yahoo! LETOR and Istella-S. 0 2 4 8 16 24 32 sample size 0.68 0.70 0.72 0.74 NDCG@K Yahoo! LETOR 0 2 4 8 16 24 32 sample size 0.36 0.38 0.40 0.42 0.44 0.46 ERR@K Yahoo! LETOR 0.62 0.64 0.66 0.68 0.70 NDCG@K 0 2 4 8 16 24 32 sample size Istella-S 0 2 4 8 16 24 32 sample size 0.58 0.60 0.62 0.64 0.66 0.68 0.70 0.72 ERR@K Istella-S K=1 K=3 K=5 K=10 results, we can see that MULTR outperforms state-of-the-art unbiased learning to rank algorithms. This shows that the user simulator in MULTR provides reliable pseudo-clicks for the ranker,which enhances the ranking performance. In addition, propensity models in both MULTR and baseline methods are developed upon positionbased examination assumption, which makes accurate propensity estimation infeasible on real data. Therefore, they are more likely to suffer from the high variance problem. The superior performance of MULTR over baseline methods verifies the necessity of reducing the variance via doubly-robust learning. Table 2: Comparison of MULTR and competing methods on Tiangong-ULTR. the natural discrepancy between pseudo and actual clicks could mislead the ranking models, as pseudo data cannot be as accurate as real users. Therefore, we resort to DR approaches. In particular, we take the observation of the ranked lists as the treatment, which addresses the treatment unobservation when naively applying existing DR methods. Afterward, we take the pseudo-click data as data imputation, and propose a doubly-robust learning algorithm to obtain unbiased ranking models. Theoretical analysis reveals that our method is more robust than existing methods. Extensive experiments on benchmark datasets, including simulated datasets and real click logs, demonstrate that the proposed modelbased method consistently outperforms state-of-the-art methods.", "7 CONCLUSION": "In this work, we propose MULTR, a model-based unbiased learning to rank framework. We first design a context-aware user simulator to produce labels for unobserved ranked lists as supervision signals, which addressed data sparsity for long-tail queries. However,", "REFERENCES": "[1] Qingyao Ai, Keping Bi, Jiafeng Guo, and W. Bruce Croft. 2018. Learning a Deep Listwise Context Model for Ranking Refinement. In SIGIR 2018 . [2] Qingyao Ai, Keping Bi, Cheng Luo, Jiafeng Guo, and W. Bruce Croft. 2018. Unbiased Learning to Rank with Unbiased Propensity Estimation. In SIGIR 2018 . [3] Qingyao Ai, Jiaxin Mao, Yiqun Liu, and W. Bruce Croft. [n. d.]. Unbiased Learning to Rank: Theory and Practice. In CIKM 2018 . [4] Olivier Chapelle and Yi Chang. 2011. Yahoo! Learning to Rank Challenge Overview. In Proceedings of the Yahoo! Learning to Rank Challenge, held at ICML 2010, Haifa, Israel, June 25, 2010 (JMLR Proceedings) . [5] Olivier Chapelle, Yi Chang, and Tie-Yan Liu (Eds.). 2011. Proceedings of the Yahoo! Learning to Rank Challenge, held at ICML 2010, Haifa, Israel, June 25, 2010 . JMLR Proceedings, Vol. 14. JMLR.org. [6] Olivier Chapelle, Donald Metlzer, Ya Zhang, and Pierre Grinspan. 2009. Expected reciprocal rank for graded relevance. In CIKM 2009 . [7] Olivier Chapelle and Ya Zhang. 2009. A dynamic bayesian network click model for web search ranking. In WWW2009 . [8] Xiaokai Chu, Jiashu Zhao, Lixin Zou, and Dawei Yin. 2022. H-ERNIE: A MultiGranularity Pre-Trained Language Model for Web Search. In CIKM'22 . WSDM '23, February 27-March 3, 2023, Singapore, Singapore Dan Luo et al. [9] Aleksandr Chuklin, Ilya Markov, and Maarten de Rijke. 2016. Click Models for Web Search and their Applications to IR: WSDM 2016 Tutorial. In WSDM 2016 . [10] Djork-Arn\u00e9 Clevert, Thomas Unterthiner, and Sepp Hochreiter. 2016. Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs). In ICLR 2016 . [11] Nick Craswell, Onno Zoeter, Michael J. Taylor, and Bill Ramsey. 2008. An experimental comparison of click position-bias models. In WSDM 2008 . [12] Xinyi Dai, Jiawei Hou, Qing Liu, Yunjia Xi, Ruiming Tang, Weinan Zhang, Xiuqiang He, Jun Wang, and Yong Yu. 2020. U-rank: Utility-oriented Learning to Rank with Implicit Feedback. In CIKM '20 . [13] Mostafa Dehghani, Hamed Zamani, Aliaksei Severyn, Jaap Kamps, and W. Bruce Croft. 2017. Neural Ranking Models with Weak Supervision. In SIGIR 2017 . [14] John C. Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. J. Mach. Learn. Res. 12 (2011), 2121-2159. [15] Georges Dupret and Benjamin Piwowarski. 2008. A user browsing model to predict search engine click data from past observations. In SIGIR 2008 . [16] Huifeng Guo, Jinkai Yu, Qing Liu, Ruiming Tang, and Yuzhou Zhang. 2019. PAL: a position-bias aware learning framework for CTR prediction in live recommender systems. In RecSys 2019 . [17] Siyuan Guo, Lixin Zou, Yiding Liu, Wenwen Ye, Suqi Cheng, Shuaiqiang Wang, Hechang Chen, Dawei Yin, and Yi Chang. 2021. Enhanced Doubly Robust Learning for Debiasing Post-Click Conversion Rate Estimation. In SIGIR 2021 . [18] Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, Neil Houlsby, and Zoubin Ghahramani. 2014. Probabilistic Matrix Factorization with Non-random Missing Data. In ICML 2014 (JMLR Workshop and Conference Proceedings) . [19] Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long Short-Term Memory. Neural Comput. 9, 8 (1997), 1735-1780. [20] Ziniu Hu, Yang Wang, Qu Peng, and Hang Li. 2019. Unbiased LambdaMART: An Unbiased Pairwise Learning-to-Rank Algorithm. In WWW2019 . [21] Kalervo J\u00e4rvelin and Jaana Kek\u00e4l\u00e4inen. 2002. Cumulated gain-based evaluation of IR techniques. ACM Trans. Inf. Syst. 20, 4 (2002), 422-446. [22] Thorsten Joachims. 2006. Training linear SVMs in linear time. In SIGKDD 2006 . [23] Thorsten Joachims, Laura A. Granka, Bing Pan, Helene Hembrooke, and Geri Gay. 2005. Accurately interpreting clickthrough data as implicit feedback. In SIGIR 2005 . [24] Thorsten Joachims, Laura A. Granka, Bing Pan, Helene Hembrooke, Filip Radlinski, and Geri Gay. 2007. Evaluating the accuracy of implicit feedback from clicks and query reformulations in Web search. ACM Trans. Inf. Syst. 25, 2 (2007), 7. [25] Thorsten Joachims, Adith Swaminathan, and Tobias Schnabel. 2017. Unbiased Learning-to-Rank with Biased Feedback. In WSDM 2017 . [26] Haruka Kiyohara, Yuta Saito, Tatsuya Matsuhiro, Yusuke Narita, Nobuyuki Shimizu, and Yasuo Yamamoto. 2022. Doubly Robust Off-Policy Evaluation for Ranking Policies under the Cascade Behavior Model. In WSDM '22 . [27] Dugang Liu, Pengxiang Cheng, Zhenhua Dong, Xiuqiang He, Weike Pan, and Zhong Ming. 2020. A General Knowledge Distillation Framework for Counterfactual Recommendation via Uniform Data. In SIGIR 2020 . [28] Claudio Lucchese, Franco Maria Nardini, Salvatore Orlando, Raffaele Perego, Fabrizio Silvestri, and Salvatore Trani. 2016. Post-Learning Optimization of Tree Ensembles for Efficient Ranking. In SIGIR 2016 . [29] Jiaxin Mao, Zhumin Chu, Yiqun Liu, Min Zhang, and Shaoping Ma. 2019. Investigating the Reliability of Click Models. In ICTIR 2019 . [30] Jiaxin Mao, Cheng Luo, Min Zhang, and Shaoping Ma. 2018. Constructing Click Models for Mobile Search. In SIGIR 2018 . [31] Harrie Oosterhuis. 2022. Doubly-Robust Estimation for Unbiased Learningto-Rank from Position-Biased Click Feedback. arXiv preprint arXiv:2203.17118 (2022). [32] Zohreh Ovaisi, Ragib Ahsan, Yifan Zhang, Kathryn Vasilaky, and Elena Zheleva. 2020. Correcting for Selection Bias in Learning-to-rank Systems. In WWW2020 . [33] Matthew Richardson, Ewa Dominowska, and Robert Ragno. 2007. Predicting clicks: estimating the click-through rate for new ads. In WWW2007 . [34] Paul R Rosenbaum and Donald B Rubin. 1983. The central role of the propensity score in observational studies for causal effects. Biometrika 70, 1 (1983). [35] Yuta Saito. 2020. Asymmetric Tri-training for Debiasing Missing-Not-AtRandom Explicit Feedback. In SIGIR 2020 . [36] Yuta Saito. 2020. Doubly Robust Estimator for Ranking Metrics with Post-Click Conversions. In RecSys 2020 . [37] Mark Sanderson. 2010. Test Collection Based Evaluation of Information Retrieval Systems. Found. Trends Inf. Retr. 4, 4 (2010), 247-375. [38] Chengyao Shen and Qi Zhao. 2014. Webpage Saliency. In ECCV 2014 . [39] Mark D. Smucker, James Allan, and Ben Carterette. 2007. A comparison of statistical significance tests for information retrieval evaluation. In CIKM 2007 . [40] Nitish Srivastava, Geoffrey E. Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: a simple way to prevent neural networks from overfitting. J. Mach. Learn. Res. 15, 1 (2014), 1929-1958. [41] Adith Swaminathan and Thorsten Joachims. 2015. The Self-Normalized Estimator for Counterfactual Learning. In NeurIPS 2015 . [42] Anh Tran, Tao Yang, and Qingyao Ai. 2021. ULTRA: An Unbiased Learning To Rank Algorithm Toolbox. In CIKM 2021 . [43] Ali Vardasbi, Maarten de Rijke, and Ilya Markov. 2020. Cascade Model-based Propensity Estimation for Counterfactual Learning to Rank. In SIGIR 2020 . [44] Ali Vardasbi, Harrie Oosterhuis, and Maarten de Rijke. 2020. When Inverse Propensity Scoring does not Work: Affine Corrections for Unbiased Learning to Rank. In CIKM '20 . [45] Hongning Wang, ChengXiang Zhai, Anlei Dong, and Yi Chang. 2013. Contentaware click modeling. In WWW2013 . [46] Xuanhui Wang, Michael Bendersky, Donald Metzler, and Marc Najork. 2016. Learning to Rank with Selection Bias in Personal Search. In SIGIR 2016 . [47] Xuanhui Wang, Nadav Golbandi, Michael Bendersky, Donald Metzler, and Marc Najork. 2018. Position Bias Estimation for Unbiased Learning to Rank in Personal Search. In WSDM 2018 . [48] Wenwen Ye, Yiding Liu, Lixin Zou, Hengyi Cai, Suqi Cheng, Shuaiqiang Wang, and Dawei Yin. 2022. Fast semantic matching via flexible contextualized interaction. In WSDM'22 . [49] Bo-Wen Yuan, Jui-Yang Hsia, Meng-Yuan Yang, Hong Zhu, Chih-Yao Chang, Zhenhua Dong, and Chih-Jen Lin. 2019. Improving Ad Click Prediction by Considering Non-displayed Events. In CIKM 2019 . [50] Yisong Yue, Rajan Patel, and Hein Roehrig. 2010. Beyond position bias: examining result attractiveness as a source of presentation bias in clickthrough data. In WWW2010 . [51] Hamed Zamani, Bhaskar Mitra, Xia Song, Nick Craswell, and Saurabh Tiwary. 2018. Neural Ranking Models with Multiple Document Fields. In WSDM 2018 . [52] Junqi Zhang, Yiqun Liu, Jiaxin Mao, Weizhi Ma, Jiazheng Xu, Shaoping Ma, and Qi Tian. 2022. User Behavior Simulation for Search Result Re-Ranking. ACM Transactions on Information Systems (2022). [53] Junqi Zhang, Jiaxin Mao, Yiqun Liu, Ruizhe Zhang, Min Zhang, Shaoping Ma, Jun Xu, and Qi Tian. 2019. Context-Aware Ranking by Constructing a Virtual Environment for Reinforcement Learning. In CIKM 2019 . [54] Honglei Zhuang, Zhen Qin, Xuanhui Wang, Michael Bendersky, Xinyu Qian, Po Hu, and Dan Chary Chen. 2021. Cross-Positional Attention for Debiasing Clicks. In WWW2021 . [55] Lixin Zou, Changying Hao, Hengyi Cai, Shuaiqiang Wang, Suqi Cheng, Zhicong Cheng, Wenwen Ye, Simiu Gu, and Dawei Yin. 2022. Approximated Doubly Robust Search Relevance Estimation. In CIKM '22 . [56] Lixin Zou, Weixue Lu, Yiding Liu, Hengyi Cai, Xiaokai Chu, Dehong Ma, Daiting Shi, Yu Sun, Zhicong Cheng, Simiu Gu, et al. 2022. Pre-trained Language Model based Retrieval and Ranking for Web Search. ACM Transactions on the Web (2022). [57] Lixin Zou, Haitao Mao, Xiaokai Chu, Jiliang Tang, Wenwen Ye, Shuaiqiang Wang, and Dawei Yin. 2022. A Large Scale Search Dataset for Unbiased Learning to Rank. arXiv preprint arXiv:2207.03051 (2022). [58] Lixin Zou, Shengqiang Zhang, Hengyi Cai, Dehong Ma, Suqi Cheng, Shuaiqiang Wang, Daiting Shi, Zhicong Cheng, and Dawei Yin. 2021. Pre-trained language model based ranking in Baidu search. In KDD '21 ."}
