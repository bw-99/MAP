{"Efficient Multi-task Prompt Tuning for Recommendation": "", "Ting Bai": "", "Le Huang": "Beijing University of Posts and Telecommunications Beijing, China baiting@bupt.edu.cn Yue Yu Beijing University of Posts and Telecommunications Beijing, China loadingyy@bupt.edu.cn Cheng Yang Beijing University of Posts and Telecommunications Beijing, China yangcheng@bupt.edu.cn Beijing University of Posts and Telecommunications Beijing, China lehuang@bupt.edu.cn Cheng Hou Tencent AI Lab Beijing, China chenghou@tencent.com", "Chuan Shi": "Beijing University of Posts and Telecommunications Beijing, China shichuan@bupt.edu.cn", "ABSTRACT": "With the expansion of business scenarios, real recommender systems are facing challenges in dealing with the constantly emerging new tasks in multi-task learning frameworks. In this paper, we attempt to improve the generalization ability of multi-task recommendations when dealing with new tasks. We find that joint training will enhance the performance of the new task but always negatively impact existing tasks in most multi-task learning methods. Besides, such a re-training mechanism with new tasks increases the training costs, limiting the generalization ability of multi-task recommendation models. Based on this consideration, we aim to design a suitable sharing mechanism among different tasks while maintaining joint optimization efficiency in new task learning. A novel two-stage prompt-tuning MTL framework (MPT-Rec) is proposed to address task irrelevance and training efficiency problems in multi-task recommender systems. Specifically, we disentangle the task-specific and task-sharing information in the multi-task pretraining stage, then use task-aware prompts to transfer knowledge from other tasks to the new task effectively. By freezing parameters in the pre-training tasks, MPT-Rec solves the negative impacts that may be brought by the new task and greatly reduces the training costs. Extensive experiments on three real-world datasets show the effectiveness of our proposed multi-task learning framework. MPT-Rec achieves the best performance compared to the SOTA multi-task learning method. Besides, it maintains comparable model performance but vastly improves the training efficiency (i.e., with up to 10% parameters in the full training way) in the new task learning.", "KEYWORDS": "Multi-Task Learning, Prompt Learning, Recommender Systems", "1 INTRODUCTION": "Multi-task learning (MTL) refers to optimizing different tasks together to make full utilization of the information contained in 0.99 0.81 AUC AUC 0.97 0.8 0.95 0.79 T1, T2 T3 0.93 0.78 T1 T2 T3 T1   T2 T1   T2 T3 Single Task Two Tasks Three Tasks Figure 1: The experimental results of multi-task learning method MMOE on Census-income dataset. Task T1, T2 and T3 are the predictions of the \"income\", \"marital status\", and \"sex\" labels. We can see that compared with the AUC performance on the single task, MTL on two tasks promotes each other. Learning with the new task T3, MTL improves the performance on new task T3, but damages T1 and T2 which had been optimized in the two-tasks stage. other tasks. Due to its broad application in recommender systems, for example, the Click Through Rate (CTR) and Click Conversion Rate (CVR) are usually jointly optimized, multi-task learning has become an active research topic in recent recommendation studies [6, 7, 17, 19, 31, 40, 44]. Different from transfer learning [23, 38, 46], which uses the associated tasks to provide extra information to the main task, multi-task learning aims to optimize all tasks at the same time. To achieve better performance on all different tasks, existing studies on multi-task learning [3, 20, 27, 30] mainly focus on designing effective knowledge-sharing mechanisms to avoid the negative transfer problem, i.e., transferring unrelated information from other tasks. Most of them ignore their generalization ability in multi-task learning to deal with new tasks. Zhe Zhao Tencent AI Lab Beijing, China nlpzhezhao@tencent.com 1 Ting Bai, Le Huang, Yue Yu, Cheng Yang, Cheng Hou, Zhe Zhao, and Chuan Shi We find that not all new tasks will promote the overall performance in existing multi-task learning frameworks. As shown in Fig. 1, compared with the joint training of existing tasks T1 and T2 in the typical multi-task learning method MMOE [20], the joint optimization with new task T3 promotes the performance on single task T3, but it harms the efforts on the previous joint training stage (i.e., two tasks) of T1 and T2. To avoid such degradations of model performance and expand the utility of multi-tasking learning when dealing with new tasks, two issues need to be urgently addressed: (1) The generalization of new tasks, especially for the irrelevant ones. If the data distribution in the new task is not consistent with existing tasks, the joint optimization strategy in MTL will give rise to the negative transfer problem, which damages model performance on existing tasks; (2) the high costs of the full training process, that is to say, all tasks ( i.e., the new task and existing tasks) will be fully re-trained with all parameters updated in MTL methods. Such a full training process will result in low training efficiency, especially when frequent requests for new task optimization are made due to changes in business scenarios. Inspired by the efficiency approaches in the NLP area that use prompt tuning to deal with downstream tasks based on the pretrained language models [5, 8, 12], we design a Multi-task Prompttuning framework, termed as MPT-Rec to address the generalization problem in dealing the new task in recommender systems. We aim to extract useful information from existing pre-trained tasks to promote new task learning, which enables us to avoid the negative transfer from the new task and to speed up the training process. To achieve these goals, as shown in Fig. 2, a two-stage learning framework is designed in MPT-Rec: multi-task pre-training stage and multi-task prompt-tuning stage. In the multi-task pre-training stage, we design a task-aware generative adversarial network to separate the task-sharing and task-specific information, so as to ensure the high-quality transfer of task-sharing information in the prompt learning process for new tasks. In the prompt-tuning stage, MPT-Rec freezes the parameters in the pre-training model and only updates the parameters of the new task with the useful knowledge transferred from the pre-trained tasks by a prompt mechanism. By splitting multi-task learning into pre-training and prompt-tuning processes, our proposed framework MPT-Rec addresses the negative transfer and high-cost training problems in multi-task learning of new tasks. Our contributions are as follows: \u00b7 Wedesign a novel MTL framework MPT-Rec, in which a taskaware generative adversarial network is used to separate the task-sharing and task-specific information, making it flexible to fully utilize the information from other tasks to improve the model performance in multi-task learning. \u00b7 We also study the generalization ability of multi-task recommendations to deal with new tasks. A novel two-stage pretraining and prompt-tuning MTL framework is proposed to solve the negative transfer and high-training cost problems in the optimization process of new tasks in recommender systems. \u00b7 Extensive experiments on three real-world datasets show the effectiveness of our proposed multi-task learning framework MPT-Rec. It achieves the best model performance compared to the SOTA multi-task learning method, i.e., CSRec. Besides, it vastly improves the efficiency of training in dealing with new tasks. Compared with training our method in the full training scheme, our fine-tuning method MPT-Rec only needs up to 10% of the parameters.", "2 RELATED WORK": "", "2.1 Multi-Task Learning": "In the field of recommendation systems, multi-task learning has been a popular research topic in recent years [7, 17, 19, 31, 33, 40, 41, 44]. It optimizes multiple tasks simultaneously to reduce training time and use the knowledge between related tasks to improve the model's performance. Generally, the multi-task learning methods in recommender systems can be classified into four types [3]: hard sharing, soft sharing, expert sharing, and sparse sharing according to the sharing mechanism of learning parameters. The hard parameter sharing methods [4, 6, 15, 25] ensure the unimpeded flow of knowledge between tasks through the sharing network at the bottom, but when dealing with weakly related or unrelated tasks, it faces the negative transfer problem. Different from hard parameter sharing, soft parameter sharing methods [10, 22] train a separate model for each task. They achieve a sharing mechanism by adding the distance between parameters of different tasks to the joint optimization function. Although soft sharing methods perform better in dealing with weakly related tasks since they use separate parameters to realize knowledge transfer without considering task correlations, they suffer the costs of larger parameter store space and lower inference efficiency in recommender systems. The expert sharing methods [20, 30] are further proposed to solve the negative transfer problem and the seesaw phenomenon by combining the outputs of different experts with gated networks. Recently, some methods also consider the efficiency problem in multi-task learning. Sparse parameter sharing [3, 28, 32] methods learn different subnets for each task, and knowledge transfer is realized through the overlapping part of subnets, so as to achieve the purpose of parameter efficiency. In recommender systems, CSRec [3] uses contrastive learning to evaluate the influence of parameters on specific tasks and solves the problem of parameter conflict. In our work, we propose a novel MTL framework MPT-Rec, in which a task-aware generative adversarial network is designed to separate task-sharing and task-specific information. In MPT-Rec, the information from other tasks can be fully utilized, alleviating the negative transfer problem and improving the model performance in multi-task learning.", "2.2 Multi-Task Generalization": "As recommendation scenarios become increasingly complicated, increasing attention has been paid to the generalization ability of multi-task learning in recent years. Different from transfer learning or domain adaptation [23, 38, 39, 46], which uses the associated tasks to provide extra information to the main task, multi-task learning aims to optimize all tasks at the same time. To achieve better performance on the new task, some model-agnostic methods are proposed in new task adoption [11, 18, 24, 37]. For example, meta-learning approaches like MAML [11] are proposed to train the model's initial parameters such that the model has maximal 2 Efficient Multi-task Prompt Tuning for Recommendation performance on a new task after the parameters have been updated with a small amount of data from that new task. However, in addition to learning the initializations, the key to improving the model performance in MTL is learning the effective transfer of knowledge from other tasks to the new task, which has not been well addressed in the meta-learning approaches. Besides, how to update all tasks efficiently in the new task learning process has been rarely studied in the literature on multi-task recommendations. As for improving the generalization ability of multi-task learning methods, it is essential to distinguish the task-specific and task-sharing information among different tasks and then transfer the helpful knowledge to the new task. From the perspective of task-specific information learning, existing MTL models can be generally classified into tower-level, gate-level and expert-level respectively [27]. For example, the Shared Bottom is a tower-level multi-task learning model, in which the parameters in the independent tower of each task are updated by the supervised task loss. MMOE is the gate-level model that learns task-specific information from the gate networks. PLE learns task-specific information also at the expertlevel by the task-specific and task-sharing experts. Recently, an embedding-level method [27] is proposed to learn task-specific and task-sharing information. Specifically, each task has its own embeddings by simple separate embedding networks to solve the negative transfer problem. Our multi-task framework MPT-Rec learns taskspecific information at the expert level, but more effectively by using generative advertisement neural networks.", "2.3 Multi-Task Fine-tuning": "In the field of recommender systems, multi-task fine-tuning is a promising technique to make the training process more efficient [8, 9, 13, 14, 34, 42, 45]. Its core objective is to enhance the model's generalization ability at a relatively low training cost. The fine-tuning operations can be implemented by transfer learning and prompt learning. Different from multi-task learning, which leverages knowledge among tasks to improve the overall performance of all tasks, transfer learning places greater emphasis on utilizing the similarities between source and target domains to enhance performance, specifically in the target task [23, 31, 38, 43, 46]. Prompt learning is a method that is widely used in natural language processing (NLP) models. Its goal is to get the desired output or result by providing clear guidance or prompts. This approach is useful for many NLP tasks, including text generation, question answering, machine translation, and information retrieval [16, 29]. For example, MPT [36] learns a single transferable prompt by distilling knowledge from multiple task-specific source prompts, then learns multiplicative low-rank updates to this shared prompt to efficiently adapt it to each downstream target task. In addition to the textual prompts, recent studies [1, 16] also utilize embedding vectors as soft prompts. ATTEMPT [1] combines knowledge transferred across different tasks via a mixture of soft prompts while keeping the original LM unchanged. However, in the field of recommendation, most of the work related to prompt learning requires a language model as an intermediary, and the prompt exists in the form of text [5, 8, 12]. Different from them, our work uses task embeddings as prompt vectors, which guide the generation of task-specific representations in the new task generalization phase. Our proposed prompt-tuning multi-task learning method has a unique advantage in terms of training efficiency.", "3 METHODOLOGY": "In this section, we briefly introduce the architecture of MPT-Rec and then explain each component in detail.", "3.1 The General Framework": "MPT-Rec consists of two components: the multi-task pre-training component and the multi-task prompt-tuning component, corresponding to the two training stages in MPT-Rec (as shown in Fig 2). \u00b7 Multi-Task Pre-training Component. Following the invariant learning [35], which uses an environment classifier to identify the environment-variant and invariant information in an unsupervised way. In our pre-training component, we design a generative adversarial network with a task classifier to separate task-sharing and task-specific information, so as to ensure the high-quality transfer of task-sharing information in the prompt learning process of new tasks. \u00b7 Multi-Task Prompt-tuning Component. In the prompttuning component, to avoid the negative transfer from the new task to existing tasks, MPT-Rec freezes the parameters in the pre-trained model and only updates the parameters of the new task with useful knowledge transferred from the pre-trained tasks by task-aware prompt mechanism. In summary, we employ multi-task pre-training to acquire highly expressive task-sharing knowledge, ensuring MPT-Rec's predictive performance on existing tasks. With the high-quality transferred knowledge, we can further improve the learning performance on new tasks and gain an additional advantage in terms of training efficiency by freezing the parameters in pre-trained tasks.", "3.2 Multi-Task Pre-training": "The multi-task pre-training phase aims to enhance the performance of existing tasks while extracting transferable knowledge to facilitate the generalization of new tasks, which consists of two main operations: information disentangling and information fusion. 3.2.1 Learning Disentangled Information. To avoid the negative transfer problem among tasks, we use generative adversarial networks together with different experts to learn task-sharing and task-specific information respectively. The task-sharing information is expected to be well adapted to the new task, while the task-specific information needs to be further learned to provide useful information. Follow the method in invariant learning [35], which uses an environment classifier to identify the environmentvariant and invariant information in an unsupervised way. In our pre-training component, we design a generative adversarial network with a task classifier to separate task-sharing and task-specific information. This ensures the high-quality transfer of task-sharing information in the prompt learning process. Specifically, the generative adversarial network consists of the task-sharing expert (as a generator) and the task classifier (as a discriminator). The goal of the generator is to confuse the task classifier by generating representations devoid of task-specific information. Meanwhile, the discriminator aims to determine the task label associated with the 3 Ting Bai, Le Huang, Yue Yu, Cheng Yang, Cheng Hou, Zhe Zhao, and Chuan Shi Figure 2: The overall architecture of our proposed MTL framework MPT-Rec. It consists of two components: the multi-task pre-training component and the multi-task prompt-tuning component. In the pre-training component, a generative adversarial network is designed to disentangle the task-specific and task-sharing information by using the task-sharing expert as a generator and the task classifier as the discriminator. In the prompt-tuning component, the parameters in the pre-training model are frozen, and useful knowledge is transferred to the new task by a prompt mechanism. Whether parameters need to be trained is indicated by labeling them as \"ice\" or \"fire\". Multi-Task Pre- -training Multi-Task Prompt-Turning Output T1 Output T2 Output T3 Tower T1 Tower T2 Tower T3 shared Xs Generative Adversarial Disentangling task er1 Task Classifier task erz task er3 specific XT1 specific specific XT2 a2 task er1 projected ho Task-specific Task-shared Task-specific task erz Gate T1 Expert T1 Expert Expert T2 Gate T2 Gate T3 Projection Attention Module Network Input Xo Input Xo XT3 task-shared representations. After training, the task-sharing expert will learn the shared information that can not be identified by the task classifier. Given the input raw features x , the input vector x \ud835\udc5c \u2208 R \ud835\udc37 is learned from a sparse embedding network I , where \ud835\udc37 is the dimension of the input vector. We assume that the function in the expert network is denoted as F , the task-shared representation x \ud835\udc60 \u2208 R \ud835\udc3b and task-specific representations x \ud835\udc58 \u2208 R \ud835\udc3b are denoted as x \ud835\udc60 = F( x \ud835\udc5c , \ud835\udf03 \ud835\udc60 ) and x \ud835\udc58 = F( x \ud835\udc5c , \ud835\udf03 \ud835\udc58 ) , where \ud835\udf03 \ud835\udc60 and \ud835\udf03 \ud835\udc58 are the learning parameters in the expert networks, and F is a two-layer MLP (Multi-Layer Perceptron) with ReLU activation function. Then we calculate the training loss of the generative adversarial network. The first loss is the prediction loss \ud835\udc3f\ud835\udc5c\ud835\udc60\ud835\udc60 \ud835\udc60 to ensure the predictive ability of task-sharing information, denoted by:   where G represents a tower network composed of fully connected layers, \u02c6 \ud835\udc66 \ud835\udc60 is the predicted value based on the task-sharing representations, and \ud835\udc66 \ud835\udc58 is the ground truth in the training dataset. For classification problems, \ud835\udc59 \ud835\udc5f\ud835\udc52\ud835\udc50 can be set to the widely used binary cross-entropy loss function. The second loss in the generative adversarial network is the task label prediction loss \ud835\udc3f\ud835\udc5c\ud835\udc60\ud835\udc60 \ud835\udc52 , defined as:   where K is the softmax learning function and \ud835\udf19 is the learning parameters in the task classifier. \u02c6 \ud835\udc66 \ud835\udc52 and \ud835\udc66 \ud835\udc52 represent the predicted value and ground truth of the task label respectively. As our datasets lack task labels, following [35], we adopt the EM-based clustering algorithm to assign task labels and use the negative log-likelihood (NLL) loss function as \ud835\udc59 \ud835\udc50 to ensure the task label is correct. The final optimization loss for the generative adversarial network consists of the prediction loss \ud835\udc3f\ud835\udc5c\ud835\udc60\ud835\udc60 \ud835\udc60 and the \ud835\udc3f\ud835\udc5c\ud835\udc60\ud835\udc60 \ud835\udc52 , defined as:  where \ud835\udefc is a weight coefficient used to balance the two loss functions, and \ud835\udc41 is the number of tasks. 3.2.2 Learning Fusion Information. After separating the task-sharing and task-specific information through the generative adversarial network, we design a fusion network to combine them together for the final prediction of each task. Specifically, we assign a task embedding to each task to guide the fusion process. The task-specific representation is combined with the task embedding to create a task-aware representation. Given a task \ud835\udc58 , the task-aware representation x \ud835\udc52 \u2208 R \ud835\udc3b is denoted as:  where x \ud835\udc58 \u2208 R \ud835\udc3b is the task-specific representation, E \ud835\udc58 \u2208 R \ud835\udc3b represents the task embedding, and \u2299 is the element-wise product operation. 4 Efficient Multi-task Prompt Tuning for Recommendation Subsequently, a gated network is employed to combine the tasksharing and task-aware representations in a weighted sum manner. For a task \ud835\udc58 , the weight coefficients \ud835\udefd \ud835\udc60 and \ud835\udefd \ud835\udc52 for the task-sharing and task-aware representations are automatically computed by the gated network H( x \ud835\udc5c ) , where x \ud835\udc5c \u2208 R \ud835\udc37 is the input vector from the embedding network, and H is one-layer MLP with softmax activation function. The fusion representation x \ud835\udc53 \u2208 R \ud835\udc3b can be formulated as:  Then the fused representation is forwarded to the upper tower network with a sigmoid function for task prediction. For task \ud835\udc58 , assuming that the prediction result of the fused representation is \u02c6 \ud835\udc66 \ud835\udc53 , the prediction loss \ud835\udc3f\ud835\udc5c\ud835\udc60\ud835\udc60 \ud835\udc53 for all tasks is computed as:  Finally, the overall loss of the multi-task pre-training phase is obtained by summing the training loss for the generative adversarial networks and the prediction loss of the fused representations, defined as:  The multi-task pre-training component realizes the initial separation and subsequent fusion of knowledge through the tower network of each task, substantially mitigating the issue of negative transfer. Simultaneously, task-sharing and task-specific representations, which are flexible in knowledge transfer, greatly enhance the generalization of new tasks.", "3.3 Multi-Task Prompt-tuning": "The multi-task prompt-tuning phase is designed to leverage existing knowledge, speeding up the training process for new tasks. This objective fits well in the recommendation situation where frequent requests are made for new task optimization due to the changes in business scenarios. We propose a task-aware prompt-tuning method to extract useful information from other tasks. Task embeddings are used as prompts to combine the well-trained task-specific representations in the multi-task pre-training phase. 3.3.1 Task-Specific Information Transfer. Given an existing task \ud835\udc58 , the weight \ud835\udefe \ud835\udc58 to combine its specific information in the new task learning is computed as:   where P represents the projection function, which is a two-layer MLP. h \ud835\udc5c \u2208 R 1 \u00d7 \ud835\udc3b and E \ud835\udc58 \u2208 R 1 \u00d7 \ud835\udc3b are the vectors with same dimensions, and \ud835\udc47 denotes a softmax temperature, that is used to scale the logits to prevent overconfidence. By combining the useful information from existing tasks, the transferred representation x \ud835\udc61 \u2208 R \ud835\udc3b for the new task learning can be defined as:  where \ud835\udc41 is the number of tasks. 3.3.2 Task-Aware Prompt Tuning . We fuse the transferred taskspecific representation x \ud835\udc61 with the new task embedding E \ud835\udc5b \u2208 R \ud835\udc3b to obtain the task-aware representation x \ud835\udc5b\ud835\udc52\ud835\udc64 \u2208 R \ud835\udc3b of the new task, then combine it with the task-sharing representation x \ud835\udc60 for the new task prediction. The representations x \u2032 \ud835\udc5b\ud835\udc52\ud835\udc64 \u2208 R \ud835\udc3b for the new task prediction is defined as as:   The optimization of the new task is formulated as:  where \u02c6 \ud835\udc66 \ud835\udc5b\ud835\udc52\ud835\udc64 is the prediction result from a sigmoid function with input vector x \u2032 \ud835\udc5b\ud835\udc52\ud835\udc64 . 3.3.3 Efficiency Analysis. Due to the comprehensive utilization of knowledge obtained during the multi-task pre-training phase. Our framework eliminates the necessity to re-train the sparse embedding network I of the high-dimensional input raw features, as well as the task-specific experts, which essentially reduces the training parameters and meanwhile improves the model efficiency. Only a small-scale projection network, tower network, and the new task embedding need to be learned in the prompt-tuning process. This efficient approach allows MPT-Rec to adapt to new tasks quickly. Moreover, we use task embeddings as prompts to guide weight learning, making it possible to transfer useful knowledge from the existing tasks to the new task. The multi-task prompttuning method ensures MPT-Rec's predictive capability on new tasks with minimal resource costs. These unique advantages make MPT-Rec an effective solution for addressing the challenge of new task generalization in recommender systems. Table 1: The statistics of datasets.", "4 EXPERIMENTS": "", "4.1 Experimental Settings": "4.1.1 Datasets. We conduct extensive experiments on three largescale datasets, including two public datasets, Census-income and Ali-CCP, and a competition dataset ByteRec to validate the effectiveness of our proposed method in multi-task learning and its ability to generalize to new tasks. The statistics of the three datasets are summarized in Table 1. \u00b7 Census-income [2]. This dataset comprises census data extracted from the 1994 and 1995 population surveys. Following prior work on multi-task learning, we designate T1 : the prediction of whether an individual's income exceeds $50,000, and T2 : the prediction of their marital status. 5 Ting Bai, Le Huang, Yue Yu, Cheng Yang, Cheng Hou, Zhe Zhao, and Chuan Shi \u00b7 Ali-CCP [21]. This dataset comprises 84 million samples collected from real-world traffic logs of the recommender system on Taobao. Following the settings in previous studies, we use T1 : the prediction of the click-through rate (CTR) of items, and T2 : the prediction of the conversion rate to evaluate the performance of MTL models. \u00b7 Byte-Rec [26]. This dataset comes from a competition focused on short video recommendations. It comprises tens of millions of interactions from tens of thousands of users. The dataset includes multi-modal short video content features and provides user interaction behavior data after desensitization. We evaluate the multi-task learning capability on two tasks. T1 : predicting whether the user completed watching a video, and T2 : whether the user liked the video. 4.1.2 Baseline Methods. We compare our proposed method MPTRec with several representative models in multi-task learning, including: \u00b7 Single Task. It optimizes each task individually without intertask knowledge transfer. \u00b7 Shared Bottom [25]. Multiple tasks share the same bottom network, followed by task-specific tower networks. \u00b7 MMOE [20]. It replaces the bottom network in Shared Bottom with multiple expert networks to learn different aspects of knowledge. Additionally, a gated network is employed to learn the attention of different expert outputs. \u00b7 PLE [30]. Following MMOE, PLE further divides the expert networks into task-sharing experts and task-specific experts. \u00b7 STEM [27]. It is the latest work in the multi-task recommendation, in which simple separate embedding networks are used to learn the shared and task-specific embeddings. \u00b7 Sparse sharing [28]. It utilizes pruning operations to learn a subnet separately for each task and then trains them in parallel. Knowledge is able to flow through overlapping parts between subnets. \u00b7 CSRec [3]. It is the SOTA baseline in multi-task learning. CSRec learns each task from separate subnets and constructs contrastive subnets to evaluate the contribution of parameters to a specific task, which alleviates the parameter conflict problem and enhances the optimization process. Except for the Single Task model, the above methods cover different kinds of multi-task learning approaches in recommendation. Shared Bottom enables knowledge flow between tasks through the sharing bottom at the bottom. MMOE and PLE utilize expert information through gated networks. Sparse Sharing and CSRec design the models from the perspective of parameter efficiency. The most similar models to our methods are STEM and PLE, both of them can learn task-sharing and task-specific knowledge at the embedding-level and expert-level respectively. Different from them, our proposed framework MPT-Rec is a two-stage multi-task prompt-tunning framework to deal with the negative transfer and high training costs problems in new task optimization in MTL recommendation. MPT-Rec uses generative adversarial networks to separate the task-specific and task-sharing representations at the expert level, which enables our framework to achieve high training efficiency and good generalization ability in dealing with new tasks in recommender systems. 4.1.3 Parameter Settings. All methods are implemented in PyTorch with NVIDIA GeForce RTX 3090. For each baseline method, a grid search is applied to find the optimal settings. These include learning rate from { 0 . 1 , 0 . 01 , 0 . 001 , 0 . 0001 , 0 . 00001 } , hidden layer size of the expert network from {( 256 , 192 , 128 ) , ( 256 , 128 ) , ( 128 . 64 )} . We report the result of each method with its optimal hyperparameter settings on the validation data. In our model, the dimension \ud835\udc37 of input feature vectors after the embedding network is 127, 90, and 32 in Census-income, Ali-CCP, and Byte-Rec datasets respectively. The hidden layer size of the expert networks is set to (256, 128)in Census-income, and (128,64) in Ali-CCP and Byte-Rec datasets. The hidden layer sizes of the projection network are (64,128), (32,64), (32,64) in three datasets. The feature embedding dimension \ud835\udc3b is 128, 64, 64, and the learning rate is 1e-3, 1e-4, 1e-4 in three datasets respectively. The balance weight \ud835\udefc for the two loss terms in the generative adversarial network training to 0.1. The code will be publicly available after the review process.", "4.2 Results of Multi-Task Learning": "The results on three datasets are shown in Table 2. All tasks on three datasets are binary classification tasks, we use AUC as the evaluation metric. We have the following observations: (1) Compared with the Single Task model, all the multi-task models achieve a certain performance gain except for the T2 in Byte-Rec dataset, which indicates that the joint training of multiple tasks can promote the transfer of related knowledge among tasks, which can promote the model performance of each task. (2) For the multi-task learning models, the Shared Bottom model performs the worst, because the task-irrelevant knowledge from other tasks may also be learned in the shared bottom network. MMOE and PLE perform better than the Shared Bottom model, they use the gated network to filter the useful information with different experts. (3) The performances of the STEM model on different datasets are not consistent: it performs relatively better than other baselines in task T2 on the Byte-Rec dataset but loses advantages compared with PLE in the Census-income dataset. It indicates that distinguishing the task-specific and sharing information by simple embedding networks can not well address the negative transfer problem. (4) Sparse Sharing and CSRec learn different subnets for each task, and only the overlapping subnets allow knowledge transfer. Thus, they achieve better experimental performance with fewer parameters. In addition, CSRec uses contrastive learning to solve the problem of parameter conflict and further improves the model performance. (5) Our proposed method MPT-Rec achieves the best performance on all datasets. Different from PLE, which uses task-sharing and task-specific experts to distinguish the task-sharing and taskspecific information, MPT-Rec uses a generative adversarial network to make more explicit restrictions in the learning process, making it more capable of avoiding the transfer of task-irrelevant information. 6 Efficient Multi-task Prompt Tuning for Recommendation Table 2: Experimental results of multi-task learning on three datasets. It is acknowledged by previous studies that a slight increase in AUC at 0.001 level is known to be a significant improvement in the MTL task. Besides, a t-test (with \ud835\udc5d < 0 . 05 , marked as \" \u2217 \") on the experiments shows the statistically significant improvements of our method over the best baseline (marked by underline). The compared methods used to compute the gain of model performance are identified in italics. Table 3: Experimental results of new task generalization on Census-income and Ali-CCP datasets. #Params denotes the number of trainable parameters and #FLOPs denotes the number of floating-point operations per batch. We report the performance of MTL methods in the prompt-tuning scheme, e.g., Shared \u2217 ,MMOE \u2217 , PLE \u2217 . Besides, comparing training them in the full-training scheme (e.g., Shared, MMOE, PLE), we report the percentage of #Params and #FLOPs in parentheses. The fine-tuning scheme inevitably suffers from performance degradation because only a fraction of the parameters are learned. Compared with MPT-Rec in a full-training scheme, our prompt-tuning model remains 99.7% and 95.5% model performance on two datasets.", "4.3 Results of New Task Generalization": "To evaluate the generalization ability of MTL methods, we construct a new task T3 by excluding the predictive feature. Due to the space limitation, we present the experimental results using the feature \"education\" in the Census-income dataset and the \"business scenario\" in the Ali-CCP dataset as T3. 4.3.1 Negative Transfer on Full-training Scheme. We first verify the negative impacts on existing tasks by incorporating the new task into MTL models. Existing MTL models, e.g., MMOE, PLE, adopt full-training scheme to learn with the new task: all three tasks are trained simultaneously, and all parameters are updated in the entire model. Considering that the new task's impacts on existing tasks may be influenced by their correlations, we compute the Pearson's correlation coefficient to measure the similarity of distributions between them and test on two features (i.e., \"Sex\" and \"Education\") with different correlation coefficient in the Census-income dataset. As shown in Table 4, we can see that for the new task T3 \"Education\" ( correlation coefficient T3-T1: 0.186, T3-T2: 0.142 ) with a relatively small gap in average correlation coefficient to the existing tasks (i.e., the correlation coefficient of T1-T2 is 0.178 ), only MMOE will gain benefits from the joint training on existing tasks, most of MTL models suffer the negative impacts on existing tasks. For the new task T3 \"Sex\" ( correlation coefficient T3-T1: 0.158, T3-T2: 0.063 ), which has a lower correlation coefficient, the incorporation of new tasks will negatively impact existing tasks in all models. We can see that for the new tasks with different data distribution, it is necessary to design a mechanism to separate the task-sharing and task-specific information, so as to alleviate the negative transfer of irrelevant information from other tasks and boost the model's performance. As the generalization ability of each MTL model may be different, for fair comparisons, we report the new task (T3: \"Education\") with a similar correlation coefficient as the previous two tasks T1 and T2 in our following experiments. 4.3.2 Efficiency Improvements in Fine-tuning Scheme. We further evaluate the generalization ability of our model in dealing with the new task in the fine-tuning scheme. To make a fair comparison, we freeze the feature embedding networks in baseline methods and optimize their upper tower networks for the new task. The fine-tuning operations for the typical MTL methods are shown in Fig. 3. The compared methods for new task learning in MTL recommendation are as follows: \u00b7 Shared Bottom*. It freezes the shared network at the bottom. 7 Ting Bai, Le Huang, Yue Yu, Cheng Yang, Cheng Hou, Zhe Zhao, and Chuan Shi Table 4: The positive or negative impacts on the existing task T1 and T2 after making full training with T3 in multi-task learning methods. \"-\" means the negative impact and \"+\" means the positive impact. Avg.Coef is the average correlation coefficient between new task T3 and tasks T1, T2. Figure 3: Fine-tuning operations on Shared Bottom, MMOE and PLE methods. \"fire\" means the parameters need to be trained, and \"ice\" indicates the freeze status. (a) Shared* (b) MMOE* (c) PLE* Tower Ca Shared Shared Shared Shared Specific Input Input Input \u00b7 MMOE*. It freezes all expert networks, while the gated network that learns attention can still be trained. \u00b7 PLE*. It freezes all shared expert networks, while task-specific experts and gating networks can still be trained. \u00b7 MAML [11]. It is a typical model-agnostic method by metelearning to address the new task adoption problem. The experimental results of different methods are shown in Table 3. We have the following observations: (1) The model-agnostic method MAML performs the worst in experiments because the information can not be fully shared by the mete-learning mechanism. PLE* performs better than Shared Bottom* and MMOE*. Because Shared Bottom and MMOE do not model the general information explicitly, the transferred knowledge is not well adapted to the new task. (2) Our MPT-Rec further improves performance over PLE*, because the sharing information learned in PLE is mixed with more noise that is useless for the new task, while MPT-Rec learns highquality task-sharing information by using generative adversarial networks. Compared to the SOTA method PLE*, it shows a particular advantage in terms of parameters and FLOPs. (3) Compared with the full training scheme, the fine-tuning scheme greatly improves the training efficiency although at the cost of a certain performance degradation. In particular, our proposed MPT-Rec achieves more than a 90% reduction in the number of parameters and FLOPs on both datasets. As for the model performance, compared to MPT-Rec in a full-training scheme, our prompt-tuning model remains 99.7% in the Census-income dataset and 95.5% in the AliCCP dataset respectively. (4) The reduction of parameters in the Ali-CCP dataset is much smaller than that of the Census-Income dataset, which indicates that the larger the dataset is, the more obvious the advantage of our proposed fine-tuning scheme in multi-task learning. This is because as the increasing of dimension in the input feature, the parameters in the feature embedding network of the corresponding model will expand rapidly, showing the necessity to learn the new task in a fine-tuning scheme. In summary, our proposed multi-task prompt-tuning approach provides a better trade-off between model performance and resource costs. It is able to make full use of the knowledge obtained in the multi-task pre-training phase, which can greatly accelerate the learning of new tasks and avoid the negative impacts on existing tasks. It can be well fit for large-scale real-world recommender systems, especially in situations where frequent requests are made for new task optimization due to the changes in business scenarios. (a) Census-income (b) Ali-CCP 0.87 0.70 0.86 0.65 0.85 0.84 0.60 0.83 0.82 0.55 Share Specific GAN MPT-Rec Share Specific -GAN MPT-Rec Figure 4: Performance comparison of variant models on new task prediction on Census-income and Ali-CCP datasets. \"Share\" and \"Specific\" denote only task-shared and taskspecific information is used. \"-GAN\" refers that does not disentangle the task-specific and task-sharing information by removing the GAN part. Figure 5: Performance comparison of different methods to combine the specific information from other tasks. \"FW\" uses fixed weights to fuse the task-specific knowledge in the pre-training phase. \"TES\" calculates the fusion weights according to task embedding similarity. (a) Census-income (b) Ali-CCP 0.87 0.70 0.86 0.69 0.85 0.68 FW TES MPT-Rec FW TES MPT-Rec 8 Efficient Multi-task Prompt Tuning for Recommendation (a) Census-income Initial PLE STEM MPT-Rec 100 Initial PLE STEM MPT-Rec (b) Ali-CCP Figure 6: The Visualization of disentangled information. The green color marks the task-sharing information, the different task-specific information is marked by the blue and pink colors respectively.", "4.4 Experimental Analysis": "In this section, we conduct ablation studies to show the effectiveness of the multi-task prompt-tuning component. Then we further make visualization of the task-sharing and task-specific information for better explainability. 4.4.1 The Effectiveness of the Disentangled Pre-training. To verify the effectiveness of the task-aware generative adversarial network in learning the task-sharing and task-specific information in the pre-training component of MPT-Rec, we conduct the ablation experiment with two variants, i.e., MPT-Rec (Share) and MPT-Rec (Specific), which only utilize the task-sharing information and the task-specific information respectively. We also remove the generative adversarial component, termed MPT-Rec (-GAN), in which both the task-shared and task-specific information are mixed together. We test the AUC scores of the three variant models on the Census-income and Ali-CCP datasets. The results are shown in Fig 4. We can see that the performance of both MPT-Rec (Share) and MPT-Rec (Specific) decrease compared with MPT-Rec, indicating that both information is useful in the new task prediction. The decrement of model performance is much larger in the MPT-Rec (Share) variant, which may be caused by the task conflict problem, where only a little information is shared among them. In this case, the task-specific information is more beneficial to the new task learning and it is necessary to extract the useful information from it. Without the separation process by GAN, the variant MPT-Rec(GAN) performs worse than the specific model with only part of the information, showing the effectiveness of using the generative adverisal networks in our framework. 4.4.2 The Effectiveness of the Prompt-tuning Mechanism. In MPTRec, we use a task-aware prompt mechanism to extract the information from other tasks. To verify the effectiveness of our prompt operation, we compare MPT-Rec with two variants, i.e. MPT-Rec (FW) and MPT-Rec (TES). MPT-Rec (FW) uses fixed weights (e.g., equal weights) as hyperparameters to fuse the task-specific information and task-sharing information obtained in the multi-task pre-training phase. MPT-Rec (TES) calculates the fusion weights according to Task Embedding Similarity, which is calculated by the dot product of the embeddings between the new task and the existing task. The difference between MPT-Rec and MPT-Rec (TES) is that MPT-Rec can extract the task-specific knowledge at an instance level, while in MPT-Rec (TES), the knowledge is extracted at a task level (i.e., the weights of all instances in a task are the same). The experimental results are shown in Fig 5. Our task-aware prompt-tuning scheme achieves the best performance since the other two reconstruction operations are conducted at the task level. Our prompt learning operation is more flexible and capable of learning fine-grained fusion weights, i.e., it learns fusion weights for each input instance. 4.4.3 The Visualization of Disentangled Information. We further visualize the task-sharing and task-specific representations learned in MPT-Rec. All the representations are randomly initialed and trained in the multi-task learning models. We utilize t-SNE to map the high-dimensional representation vectors to a two-dimensional space and report our visualization results in Fig 6. The green color marks the task-sharing information; the different task-specific information is marked by the blue and pink colors respectively. We can see that after training, our MPT-Rec shows clear boundaries between the three types of information. Compared with PLE, the 9 Ting Bai, Le Huang, Yue Yu, Cheng Yang, Cheng Hou, Zhe Zhao, and Chuan Shi boundary between two task-specific representations is more evident in the Census-income dataset. For the Ali-CCP dataset, STEM loses the advantage of distinguishing the task-sharing information, which is confused with the task-specific information. Both PLE and our method distinguish the three types of information well. For the task-sharing representation, the distance is more closer to the taskspecific information in our model, which helps to make a fusion of the information and further improve the model performance.", "5 CONCLUSION": "In this paper, we propose an effective multi-task learning framework and also investigate the generalization problem of multi-task learning in dealing with new tasks. We point out the negative transfer and high resource cost problems in the new task learning in recommender systems. We propose a novel two-stage (i.e., pretraining and prompt-tuning stages) multi-task learning framework, MPT-Rec. It separates task-sharing and task-specific information in the pre-training stage and allows it to be fully utilized in the prompt-tuning stage. Our proposed method MPT-Rec effectively solves the negative transfer in multi-task optimization and highcost problems in new task learning, which provides a solution to make trade-offs between model performance and resource overhead in large-scale real-world recommender systems.", "REFERENCES": "[1] Akari Asai, Mohammadreza Salehi, Matthew E Peters, and Hannaneh Hajishirzi. 2022. Attempt: Parameter-efficient multi-task tuning via attentional mixtures of soft prompts. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing . 6655-6672. [2] Arthur Asuncion and David Newman. 2007. UCI machine learning repository. [3] Ting Bai, Yudong Xiao, Bin Wu, Guojun Yang, Hongyong Yu, and Jian-Yun Nie. 2022. A Contrastive Sharing Model for Multi-Task Recommendation. In Proceedings of the ACM Web Conference 2022 . 3239-3247. [4] Rich Caruana. 1997. Multitask learning. Machine learning 28 (1997), 41-75. [5] Zhixuan Chu, Hongyan Hao, Xin Ouyang, Simeng Wang, Yan Wang, Yue Shen, Jinjie Gu, Qing Cui, Longfei Li, Siqiao Xue, et al. 2023. Leveraging large language models for pre-trained recommender systems. arXiv preprint arXiv:2308.10837 (2023). [6] Ronan Collobert and Jason Weston. 2008. A unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of the 25th international conference on Machine learning . 160-167. [7] Michael Crawshaw. 2020. Multi-task learning with deep neural networks: A survey. arXiv preprint arXiv:2009.09796 (2020). [8] Yang Deng, Wenxuan Zhang, Weiwen Xu, Wenqiang Lei, Tat-Seng Chua, and Wai Lam. 2023. A unified multi-task learning framework for multi-goal conversational recommender systems. ACM Transactions on Information Systems 41, 3 (2023), 1-25. [9] Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et al. 2023. Parameterefficient fine-tuning of large-scale pre-trained language models. Nature Machine Intelligence 5, 3 (2023), 220-235. [10] Long Duong, Trevor Cohn, Steven Bird, and Paul Cook. 2015. Low resource dependency parsing: Cross-lingual parameter sharing in a neural network parser. In Proceedings of the 53rd annual meeting of the Association for Computational Linguistics and the 7th international joint conference on natural language processing (volume 2: short papers) . 845-850. [11] Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-agnostic metalearning for fast adaptation of deep networks. In International conference on machine learning . PMLR, 1126-1135. [12] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022. Recommendation as language processing (rlp): A unified pretrain, personalized prompt & predict paradigm (p5). In Proceedings of the 16th ACM Conference on Recommender Systems . 299-315. [13] Bowen Hao, Chaoqun Yang, Lei Guo, Junliang Yu, and Hongzhi Yin. 2024. Motifbased prompt learning for universal cross-domain recommendation. In Proceedings of the 17th ACM International Conference on Web Search and Data Mining . 257-265. [14] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019. Parameter-efficient transfer learning for NLP. In International Conference on Machine Learning . PMLR, 2790-2799. [15] Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. 2019. Multi-task deep neural networks for natural language understanding. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics . 4487-4496. [16] Yajing Liu, Yuning Lu, Hao Liu, Yaozu An, Zhuoran Xu, Zhuokun Yao, Baofeng Zhang, Zhiwei Xiong, and Chenguang Gui. 2023. Hierarchical Prompt Learning for Multi-Task Learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 10888-10898. [17] Yichao Lu, Ruihai Dong, and Barry Smyth. 2018. Why I like it: multi-task learning for recommendation and explanation. In Proceedings of the 12th ACM Conference on Recommender Systems . 4-12. [18] Linhao Luo, Yumeng Li, Buyu Gao, Shuai Tang, Sinan Wang, Jiancheng Li, Tanchao Zhu, Jiancai Liu, Zhao Li, and Shirui Pan. 2023. MAMDR: A model agnostic learning framework for multi-domain recommendation. In 2023 IEEE 39th International Conference on Data Engineering (ICDE) . IEEE, 3079-3092. [19] Minh-Thang Luong, Quoc V Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. 2016. Multi-task sequence to sequence learning. (2016). [20] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed H Chi. 2018. Modeling task relationships in multi-task learning with multi-gate mixture-ofexperts. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1930-1939. [21] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun Gai. 2018. Entire space multi-task model: An effective approach for estimating post-click conversion rate. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval . 1137-1140. [22] Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, and Martial Hebert. 2016. Cross-stitch networks for multi-task learning. In Proceedings of the IEEE conference on computer vision and pattern recognition . 3994-4003. [23] Sinno Jialin Pan and Qiang Yang. 2009. A survey on transfer learning. IEEE Transactions on knowledge and data engineering 22, 10 (2009), 1345-1359. [24] Danni Peng, Sinno Jialin Pan, Jie Zhang, and Anxiang Zeng. 2021. Learning an adaptive meta model-generator for incrementally updating recommender systems. In Proceedings of the 15th ACM Conference on Recommender Systems . 411-421. [25] Sebastian Ruder. 2017. An overview of multi-task learning in deep neural networks. arXiv preprint arXiv:1706.05098 (2017). [26] W Shen. 2021. Deepctr: easy-to-use, modular and extendible package of deep-learning based CTR models (2017). GitHub Repository, https://github. com/shenweichen/deepctr, accessed November (2021). [27] Liangcai Su, Junwei Pan, Ximei Wang, Xi Xiao, Shijie Quan, Xihua Chen, and Jie Jiang. 2023. STEM: Unleashing the Power of Embeddings for Multi-task Recommendation. arXiv preprint arXiv:2308.13537 (2023). [28] Tianxiang Sun, Yunfan Shao, Xiaonan Li, Pengfei Liu, Hang Yan, Xipeng Qiu, and Xuanjing Huang. 2020. Learning sparse sharing architectures for multiple tasks. In Proceedings of the AAAI conference on artificial intelligence , Vol. 34. 8936-8943. [29] Xiangguo Sun, Hong Cheng, Jia Li, Bo Liu, and Jihong Guan. 2023. All in one: Multi-task prompting for graph neural networks. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 2120-2131. [30] Hongyan Tang, Junning Liu, Ming Zhao, and Xudong Gong. 2020. Progressive layered extraction (ple): A novel multi-task learning (mtl) model for personalized recommendations. In Proceedings of the 14th ACM Conference on Recommender Systems . 269-278. [31] Kim-Han Thung and Chong-Yaw Wee. 2018. A brief review on multi-task learning. Multimedia Tools and Applications 77 (2018), 29705-29725. [32] Richa Upadhyay, Ronald Phlypo, Rajkumar Saini, and Marcus Liwicki. 2023. Less is More-Towards parsimonious multi-task models using structured sparsity. arXiv preprint arXiv:2308.12114 (2023). [33] Yuhao Wang, Ha Tsz Lam, Yi Wong, Ziru Liu, Xiangyu Zhao, Yichao Wang, Bo Chen, Huifeng Guo, and Ruiming Tang. 2023. Multi-Task Deep Recommender Systems: A Survey. arXiv preprint arXiv:2302.03525 (2023). [34] Yuhao Wang, Xiangyu Zhao, Bo Chen, Qidong Liu, Huifeng Guo, Huanshuo Liu, Yichao Wang, Rui Zhang, and Ruiming Tang. 2023. PLATE: A PromptEnhanced Paradigm for Multi-Scenario Recommendations. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1498-1507. [35] Zimu Wang, Yue He, Jiashuo Liu, Wenchao Zou, Philip S Yu, and Peng Cui. 2022. Invariant preference learning for general debiasing in recommendation. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 1969-1978. [36] Zhen Wang, Rameswar Panda, Leonid Karlinsky, Rogerio Feris, Huan Sun, and Yoon Kim. 2023. Multitask prompt tuning enables parameter-efficient transfer learning. (2023). [37] Tianxin Wei, Ziwei Wu, Ruirui Li, Ziniu Hu, Fuli Feng, Xiangnan He, Yizhou Sun, and Wei Wang. 2020. Fast adaptation for cold-start collaborative filtering with meta-learning. In 2020 IEEE International Conference on Data Mining (ICDM) . 10 Efficient Multi-task Prompt Tuning for Recommendation IEEE, 661-670. [38] Karl Weiss, Taghi M Khoshgoftaar, and DingDing Wang. 2016. A survey of transfer learning. Journal of Big data 3, 1 (2016), 1-40. [39] Sen Wu, Hongyang R Zhang, and Christopher R\u00e9. 2019. Understanding and Improving Information Transfer in Multi-Task Learning. In International Conference on Learning Representations . [40] Amir R Zamir, Alexander Sax, William Shen, Leonidas J Guibas, Jitendra Malik, and Silvio Savarese. 2018. Taskonomy: Disentangling task transfer learning. In Proceedings of the IEEE conference on computer vision and pattern recognition . 3712-3722. [41] Mingzhu Zhang, Ruiping Yin, Zhen Yang, Yipeng Wang, and Kan Li. 2023. Advances and Challenges of Multi-task Learning Method in Recommender System: A Survey. arXiv preprint arXiv:2305.13843 (2023). [42] Zijian Zhang, Shuchang Liu, Jiaao Yu, Qingpeng Cai, Xiangyu Zhao, Chunxu Zhang, Ziru Liu, Qidong Liu, Hongwei Zhao, Lantao Hu, et al. 2024. M3oE: MultiDomain Multi-Task Mixture-of Experts Recommendation Framework. arXiv preprint arXiv:2404.18465 (2024). [43] Cheng Zhao, Chenliang Li, Rong Xiao, Hongbo Deng, and Aixin Sun. 2020. CATN: Cross-domain recommendation for cold-start users via aspect transfer network. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval . 229-238. [44] Zhe Zhao, Lichan Hong, Li Wei, Jilin Chen, Aniruddh Nath, Shawn Andrews, Aditee Kumthekar, Maheswaran Sathiamoorthy, Xinyang Yi, and Ed Chi. 2019. Recommending what video to watch next: a multitask ranking system. In Proceedings of the 13th ACM Conference on Recommender Systems . 43-51. [45] Qihuang Zhong, Liang Ding, Juhua Liu, Bo Du, and Dacheng Tao. 2024. Panda: Prompt transfer meets knowledge distillation for efficient model adaptation. IEEE Transactions on Knowledge and Data Engineering (2024). [46] Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong, and Qing He. 2020. A comprehensive survey on transfer learning. Proc. IEEE 109, 1 (2020), 43-76. 11"}
