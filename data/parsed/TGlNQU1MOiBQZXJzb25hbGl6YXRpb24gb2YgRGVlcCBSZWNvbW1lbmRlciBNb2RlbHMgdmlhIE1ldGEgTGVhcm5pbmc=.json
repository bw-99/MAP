{"LiMAML: Personalization of Deep Recommender Models via Meta Learning": "Ruofan Wang, Prakruthi Prabhakar, Gaurav Srivastava, Tianqi Wang, Zeinab S. Jalali, Varun Bharill, Yunbo Ouyang, Aastha Nigam, Divya Venugopalan, Aman Gupta, Fedor Borisyuk, Sathiya Keerthi, Ajith Muralidharan \u2217 LinkedIn Inc USA", "ABSTRACT": "In the realm of recommender systems, the ubiquitous adoption of deep neural networks has emerged as a dominant paradigm for modeling diverse business objectives. As user bases continue to expand, the necessity of personalization and frequent model updates have assumed paramount significance to ensure the delivery of relevant and refreshed experiences to a diverse array of members. In this work, we introduce an innovative meta-learning solution tailored to the personalization of models for individual members and other entities, coupled with the frequent updates based on the latest user interaction signals. Specifically, we leverage the Model-Agnostic Meta Learning (MAML) algorithm to adapt per-task sub-networks using recent user interaction data. Given the near infeasibility of productionizing original MAML-based models in online recommendation systems, we propose an efficient strategy to operationalize meta-learned sub-networks in production, which involves transforming them into fixed-sized vectors, termed meta embeddings, thereby enabling the seamless deployment of models with hundreds of billions of parameters for online serving. Through extensive experimentation on production data drawn from various applications at LinkedIn, we demonstrate that the proposed solution consistently outperforms the baseline models of those applications, including strong baselines such as using wide-and-deep ID based personalization approach. Our approach has enabled the deployment of a range of highly personalized AI models across diverse LinkedIn applications, leading to substantial improvements in business metrics as well as refreshed experience for our members.", "CCS CONCEPTS": "\u00b7 Information systems \u2192 Collaborative filtering ; Personalization ; Recommender systems .", "KEYWORDS": "Recommendation systems, Meta learning, Hyper-personalization, Deployment, Few-shot learning Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. KDD'24, August 25-29, 2024, Barcelona, Spain \u00a9 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-XXXX-X/18/06 https://doi.org/XXXXXXX.XXXXXXX", "ACMReference Format:": "Ruofan Wang, Prakruthi Prabhakar, Gaurav Srivastava, Tianqi Wang, Zeinab S. Jalali, Varun Bharill, Yunbo Ouyang, Aastha Nigam, Divya Venugopalan, Aman Gupta, Fedor Borisyuk, Sathiya Keerthi, Ajith Muralidharan \u2217 . 2024. LiMAML: Personalization of Deep Recommender Models via Meta Learning. In Proceedings of (KDD'24). ACM, New York, NY, USA, 10 pages. https: //doi.org/XXXXXXX.XXXXXXX", "1 INTRODUCTION": "With the advent of deep learning, neural-network based recommendation models have become very popular for modeling a variety of objectives at large internet companies, including click-through rate (CTR) prediction, invite prediction, and visit prediction. It is important for these models to understand the diverse and evolving individual needs of millions of members and provide refreshed item recommendations everyday. An array of approaches have been proposed to improve the performance of such networks for better personalization. The first set of approaches propose architectural improvements to learn sophisticated feature interactions [2, 6, 29]. Deeper models with intricate architectures based on factorization machines have achieved state of the art performance on several recommender system prediction tasks. However, they are still global models served across all members, entities and items with limited personalization. The second set of approaches leverage the power of embeddings to handle sparse categorical feature inputs per user or per entity (e.g. per advertiser, per job, per industry segment, etc.) [14, 21, 32]. Embedding based approaches provide some degree of personalization for each user or entity. But such approaches can only learn reliable embeddings when there is a significant amount of data per user, limiting their personalization scope to frequent members on the platform. In other words, such models are data inefficient during learning. In general, the definition of personalization varies across different objectives and applications. As an example, for an ad - Click Through Rate (CTR) prediction task, we may want to build personalized models for each advertiser ID. For a general user-item CTR prediction task, we may want to build personalized models per user. For a model that predicts whether or not a user would apply for a job, a per-user and job-to-industry segment level personalization might make more sense. In the meta learning framework 1 , this would entail designing different task definitions for different use cases. With meta learning, the goal is to quickly and effectively learn a new task from a small number of data samples using a model that is learnt on a large number of different tasks. [4] proposes a model-agnostic meta-learning algorithm (MAML) that modifies the optimization approach so that it can be directly applied to any deep learning model that is trained with a gradient descent procedure. Only recently, MAML based approaches have started gaining popularity in recommendation systems for handling cold start scenarios of CTR prediction models [12, 17, 26]. These approaches try to learn personalized user preferences by meta learning ID embedding vectors for cold start items or meta learning final few layers of the Multi-Layer Perceptron (MLP) based on few user interaction samples. In this paper, we extend all of these ideas to provide a general architecture for personalizing deep recommender models via meta learning. In our approach, we leverage MAML [4] to meta learn a part of the network at a per-task level, where tasks could be members or entities or a combination of both. The rest of the network is shared across all tasks and is kept identical to the architecture for that application. As opposed to the original MAML which is nearly infeasible to be productionized online in large scale recommendation systems, this approach provides an easy way to deploy personalized models with hundreds of billions of parameters in production by converting the output of the meta-learnt sub-network into meta embeddings, and providing these embeddings as regular features while serving the deployed neural network. By doing meta-finetuning frequently, we present a way to keep the models refreshed and personalized to the most recent user interactions on the platform. We demonstrate across several real-world use cases at LinkedIn that the proposed approach (termed LiMAML) beats the baseline models across all use cases. Along with business impact, we dive deep into how this approach truly uplifts model performance even for infrequent members with limited data, thereby presenting a compelling case for adopting a meta learnt personalization strategy for all recommender system models. We go over related work in Section 2 and provide preliminaries on meta learning in Section 3. In Section 4, we introduce our proposed methodology and in Section 5, we share some insights around LiMAML productionization. Offline experiments and online A/B testing results are presented in Sections 6 and 7 respectively.", "2 RELATED WORK": "Deep recommender models usually rely on deep feature interactions and large ID embedding tables to enable personalization. Feature interaction modules such as Wide-and-Deep Network [2], DeepFM [6] and DCN v2 [29] effectively fuse user features and entity features to improve the representation power. Another stream of approaches attempt to learn a personalized embedding per user or entity by introducing large cardinality embedding tables [14, 19, 21, 32]. Although the aforementioned recommendation approaches can provide user-level or entity-level personalization, in industrial-scale recommender applications with billions of members and entities, these approaches require large models to incorporate personalized information and large data to train such models, making it less feasible in some large scale online recommendation systems due to limited data availability. Meta learning, on the contrary, focuses on training models to adapt to every user or entity quickly when only a few samples are provided. Most literature on meta learning focuses on vision [4, 23] and language domain [8], whereas applications of recommender systems domain have unique challenges since the number of tasks are much larger than vision and language domain. Meta learning can be roughly classified into 3 categories: model-based [24], metric-based [25] and optimization-based [4]. Multiple works have applied metric-based and model-based meta learning for recommender systems [13], applied meta learning for scenario specific task definition [3] and applied meta learning in the online setting [10, 19]. These recommendation approaches focus on smallscale, non-industrial benchmark datasets, such as movie recommendation [7], book recommendation [33], ads prediction [1]. Model Agnostic Meta Learning (MAML) [4] enables large-scale task adaptation through bi-level optimization setup. MAML based optimization has already been applied for recommender systems [9, 11, 12, 15, 26, 28]. For example, MAML-based recommender systems have been utilized for ads CTR prediction problems [17, 18]. MetaLearned User Preference Estimator (MeLU) [12] performs MAML based task adaptation on the MLP layers of the model. However, productionizing MeLU type architectures is challenging because the task adaptation layers are the last layers in the model architecture, which necessitates the storing of the personalization weights of all the members. Instead, we perform task adaptation on a sub-network, which includes only the first few layers of the network. This subnetwork outputs a fixed size meta learned embedding vector during the inference for each user, which significantly facilitates model serving. A few works have applied Meta learning based solutions for recommender systems on production scale datasets [16, 31]. However, these papers do not provide meta learning specific productionization strategies for industrial scale recommender systems. G-Meta [30] discussed speeding up MAML-based recommender systems by using GPU parallelism strategies, but other optimization strategies can be utilized together with parallelism to further accelerate meta learning model training.", "3 PRELIMINARIES": "The central idea of meta learning, also referred to as \"learning-tolearn\", is to learn a model \ud835\udf03 across a variety of learning tasks, such that it is capable of adapting to any new task quickly with only a small number of data points. There are broadly three types of meta learning: metric based, model based and optimization based. In this paper, we adopt optimization based meta learning from the reference paper [4]. In this approach called Model-Agnostic Meta Learning (MAML), we learn the model parameters \ud835\udf03 such that the model has maximal generalization performance on a new task after the parameters have been updated through one or more gradient steps to a personalized \ud835\udf03 \ud835\udc56 starting from \ud835\udf03 . Formally, let us consider a prediction function \ud835\udc53 \ud835\udf03 : \ud835\udc65 \u2192 \ud835\udc66 which maps observations denoted by \ud835\udc65 to outputs denoted by \ud835\udc66 . \ud835\udc53 can be any neural network based function approximator with parameters \ud835\udf03 . Then we define each task as \ud835\udc47 \ud835\udc56 = {( \ud835\udc65 1 , \ud835\udc66 1 ) , ( \ud835\udc65 2 , \ud835\udc66 2 ) , . . . )} where \ud835\udc65 \ud835\udc57 , \ud835\udc66 \ud835\udc57 are i.i.d. samples from a specific task \ud835\udc47 \ud835\udc56 . The loss L \ud835\udc47 \ud835\udc56 ( \ud835\udc53 \ud835\udf03 \ud835\udc56 ) provides task-specific feedback based on the problem type using the task-specific model weights \ud835\udf03 \ud835\udc56 . For a binary classification problem, it can be cross entropy loss, and for a regression problem, it can be mean-squared error (MSE) loss. We want the meta learnt model to be performing well on a distribution of learning tasks \ud835\udc5d (T) . The entire dataset is therefore constructed as a set of tasks { \ud835\udc47 1 , \ud835\udc47 2 , . . . , \ud835\udc47 \ud835\udc41 } where \ud835\udc41 is the number of tasks in total and each \ud835\udc47 \ud835\udc56 \u223c \ud835\udc5d (T) refers to a single task with all data points under task \ud835\udc56 . Each task level data \ud835\udc47 \ud835\udc56 is further split into two parts: support set and query set. The support set is utilized for task-level personalization and query set is utilized for maximizing generalization performance across tasks. This will become clearer as we describe the steps of MAML given in Algorithm 1[4]. The MAML algorithm mainly involves two stages: task adaptation phase (Lines 4 - 10 of Algorithm 1), henceforth called the inner loop and meta-optimization phase (Line 11 of Algorithm 1), henceforth called the outer loop. The goal of the inner loop is to learn task-level personalization. It does so by minimizing the loss on each task's support set data by performing gradient updates \ud835\udc5b times to obtain a set of personalized (fine-tuned) model weights \ud835\udf03 \ud835\udc56 per task. Note that at a task-level, the learning process presents an over-parameterized problem, with multiple solutions for \ud835\udf03 \ud835\udc56 that can minimize the loss on the support set. However, this algorithm restricts the solution space by bootstrapping from \ud835\udf03 as the starting point to learn \ud835\udf03 \ud835\udc56 , creating a strong dependence of \ud835\udf03 \ud835\udc56 on \ud835\udf03 . The step size \ud835\udefc is the task learning rate. \u2207 \ud835\udf03 refers to the gradient w.r.t. \ud835\udf03 . The inner loop is also sometimes referred to as task-level fine-tuning as we fine tune \ud835\udf03 to learn personalized model parameters \ud835\udf03 \ud835\udc56 for each task using a few samples from it. The goal of the outer loop is to update the model parameters \ud835\udf03 such that it can maximize the generalization performance on a wide variety of tasks. This is achieved by doing gradient update [4] of \ud835\udf03 using the losses computed on the query sets of each task from the per-task model parameters \ud835\udf03 \ud835\udc56 . Note that this gradient update is done using all tasks since \ud835\udf03 is shared across all tasks. \ud835\udefd is the learning rate used in the meta optimization step, also known as global learning rate, and is usually different from the task learning rate \ud835\udefc . The minimization of the losses of different \ud835\udf03 \ud835\udc56 s computed on the query sets represents the maximization of generalization performance across tasks. The outer loop update involves a gradient through a gradient computation, which requires Hessian-vector products computation. In essence, we learn the model parameters \ud835\udf03 such that the model has maximal generalization performance on any new task after the parameters for that task are bootstrapped from \ud835\udf03 and updated through one or more task-level gradient steps to a personalized \ud835\udf03 \ud835\udc56 .", "4 METHODOLOGY": "In this section, we start with discussing how MAML can be designed for applications in recommender systems, specifically choosing the right task definitions and loss functions. We will then present the difficulties of deploying MAML based solutions as is in production. After that, we introduce our proposed method: LiMAML , which preserves the benefits from meta learning while also ensuring a scalable and production-friendly approach to personalization.", "4.1 Task definition in MAML": "Defining the task is one of the critical first steps in formulating the problem via meta learning. The goal of personalizing a model", "Algorithm 1 Original MAML Algorithm [4]": "Require: \ud835\udc5d ( T) : distribution over tasks Require: \ud835\udefc, \ud835\udefd : step size/learning rate hyperparameters of inner and outer loop Require: \ud835\udc5b : number of times to repeat the inner loop gradient updates 1: randomly initialize \ud835\udf03 2: while not done do 3: Sample batch of tasks \ud835\udc47 \ud835\udc56 \u223c \ud835\udc5d ( T) 4: for all \ud835\udc47 \ud835\udc56 do 5: \ud835\udf03 \ud835\udc56 \u2190 \ud835\udf03 6: repeat \ud835\udc5b times 7: Evaluate \u2207 \ud835\udf03 \ud835\udc56 L \ud835\udc47\ud835\udc56 ( \ud835\udc53 \ud835\udf03 \ud835\udc56 ) with support set 8: \ud835\udf03 \ud835\udc56 \u2190 \ud835\udf03 \ud835\udc56 - \ud835\udefc \u2207 \ud835\udf03 \ud835\udc56 L \ud835\udc47\ud835\udc56 ( \ud835\udc53 \ud835\udf03 \ud835\udc56 ) 9: end 10: end for 11: Update \ud835\udf03 \u2190 \ud835\udf03 - \ud835\udefd \u2207 \ud835\udf03 \u02dd \ud835\udc47\ud835\udc56 \u223c \ud835\udc5d (T) L \ud835\udc47\ud835\udc56 ( \ud835\udc53 \ud835\udf03 \ud835\udc56 ) with query set 12: end while via meta learning is to effectively and quickly learn to produce the fine-tuned network weights for each new task. If the learning objective is to predict CTR on an item from a user, each user or user segment could be a natural choice of task definition for this problem. In general, the input to the neural network in recommender systems usually consists of a set of one or more entities and their corresponding features. Examples of entities include job ID, advertiser ID, viewer ID, etc. One or more combination of entities or their segmentation would be a good choice in designing the task for meta learning. If we treat each viewer ID as a task, then \ud835\udc47 \ud835\udc56 includes all data points for a particular viewer and the outcome of meta learning would be to produce per-viewer personalized networks based on most recent viewer interaction data.", "4.2 Loss functions for a task": "The next step would be to define the loss function for the learning problem. In recommender systems, the prediction function \ud835\udc53 \ud835\udf03 : \ud835\udc65 \u2192 \ud835\udc66 is usually a binary classifier probability predicting a user response given a set of features. \ud835\udc65 is a collective feature set including several dimensions such as user, item, context, etc. \ud835\udc66 represents the user response, for example, whether a user clicked on a recommended item. \ud835\udc53 can be of any form. In this paper, we assume \ud835\udc53 to be a neural network based function approximator. Given \ud835\udc66 is a binary signal in general, L can be cross-entropy loss as defined below. Please note that in MAML, the losses are defined at a task level.", "4.3 LiMAML": "With the MAML algorithm, by treating each entity as a task, we can build a personalized model where each entity has its own set of values for the fine-tuned model parameters. In order to deploy such a model in practice, we would either have to store the personalized per-entity network weights and serve them during inference or would have to do the fine-tuning during inference in real time. Both of these solutions are infeasible to be deployed into production in online recommendation systems mainly from two aspects. Storage : If we treat each user or each entity as a task, the number of tasks can be extremely large, running in the order of millions or more. For example, there are over 1 billion members of LinkedIn and it is extremely expensive to store 1 billion \ud835\udf03 \ud835\udc56 per user. Hence, storing the full \ud835\udf03 \ud835\udc56 \u2200 \ud835\udc56 would be infeasible from a storage perspective. Latency : Recommendations are made online in near real time. Performing task-level fine-tuning during an inference call could cause significant inference latency with high computation cost. Hence, doing real time fine-tuning would be infeasible from a compute perspective. These two considerations inspired us to come up with an effective variant of the original MAML for LinkedIn recommender applications, called LiMAML . It still possesses the capability of personalization, offering well-tailored and frequently refreshed models per entity, but more importantly, provides a much easier framework to productionize and serve at a larger scale. Algorithms 2a and 2b provide an overview of the algorithm. Figure 1 provides the network structure of LiMAML.", "Algorithm 2a LiMAML: Training": "Require: \ud835\udc5d ( T) : distribution over tasks Require: \ud835\udefc, \ud835\udefd : step size/learning rate hyperparameters of inner and outer loop Require: \ud835\udc5b : number of times to repeat the inner loop gradient updates 1: randomly initialize \ud835\udf03 meta, \ud835\udf03 global 2: while not done do 3: Sample batch of tasks \ud835\udc47 \ud835\udc56 \u223c \ud835\udc5d ( \ud835\udc47 ) 4: for all \ud835\udc47 \ud835\udc56 do 5: \ud835\udf03 meta \ud835\udc56 \u2190 6: 7: 8: \ud835\udf03 meta repeat \ud835\udc5b times 9: end 10: end for 11: Update \ud835\udf03 meta and \ud835\udf03 global with query set: 12: \ud835\udf03 \ud835\udc41 meta \u2190 \ud835\udf03 - \ud835\udefd \u2207 L ( \ud835\udc53 13: \ud835\udf03 global \u2190 meta \ud835\udf03 global - \ud835\udf03 \ud835\udefd meta \u2207 \ud835\udf03 \u02dd \ud835\udc56 global = 1 \u02dd \ud835\udc41 \ud835\udc56 = \ud835\udc47\ud835\udc56 1 \ud835\udf03 L \ud835\udc47\ud835\udc56 meta ( ) \ud835\udc56 \ud835\udc53 \ud835\udf03 global ) 14: end while", "Algorithm 2b LiMAML: Meta Embedding Generation": "Require: \ud835\udc58 : number of times to repeat the fine-tuning gradient updates 1: for each \ud835\udc47 \ud835\udc56 \u2208 T do 2: \ud835\udf03 meta \ud835\udc56 \u2190 \ud835\udf03 meta 3: repeat \ud835\udc58 times 4: Evaluate \u2207 \ud835\udf03 meta \ud835\udc56 L \ud835\udc47\ud835\udc56 ( \ud835\udc53 \ud835\udf03 meta \ud835\udc56 ) with recent samples of \ud835\udc47 \ud835\udc56 5: \ud835\udf03 meta \ud835\udc56 \u2190 \ud835\udf03 meta \ud835\udc56 - \ud835\udefc \u2207 \ud835\udf03 meta \ud835\udc56 L \ud835\udc47\ud835\udc56 ( \ud835\udc53 \ud835\udf03 meta \ud835\udc56 ) 6: end 7: Score the most recent sample \ud835\udc65 \ud835\udc56 using \ud835\udf03 meta \ud835\udc56 to obtain the output of the meta block (meta embedding) \ud835\udc38 \ud835\udc56 8: end for 4.3.1 Network Structure. In this approach, we divide the network into two blocks Meta Block and Global Block . Meta block, whose parameters are denoted by \ud835\udf03 meta, is the sub-network that we will meta learn using MAML approach. Hence, for every task, we will start with \ud835\udf03 meta, and fine-tune it to produce personalized sub-networks \ud835\udf03 meta1 , \ud835\udf03 meta2 , . . . , \ud835\udf03 meta \ud835\udc41 for \ud835\udc41 tasks. Global block, y_pred Block @global Meta embedding Other features Meta Block Meta features whose parameters are denoted by \ud835\udf03 global , is the sub-network that is shared across all tasks and is usually equivalent in architecture to the network structure currently deployed for an application. We will split the input features for each task into two categories. Meta Features are the input to the meta block, which usually contains features specific to the entity which forms the task definition. For example, if we are meta learning the sub-network per user, meta features are the user features for each item in the task. Other Features refer to all other features input to the global model. In our applications of LiMAML, meta features can also be fed directly into the global block as well. Global block additionally takes in the output of the meta block, referred to as Meta Embedding , as additional inputs along with other features. In our experiments, we simply concatenated meta embeddings with other features and provided that as input to the Global block. In essence, the meta block provides the personalized embeddings per task as additional input signals to the global block. 4.3.2 Training. Algorithm 2a provides the steps to train LiMAML. In the inner loop (Lines 4 - 10), we only update the meta block parameters \ud835\udf03 meta \ud835\udc56 for each task \ud835\udc47 \ud835\udc56 using the support set data from each task. In the outer loop (Lines 11 - 13), both meta block parameters \ud835\udf03 meta and global block parameters \ud835\udf03 global are updated with the query set of training data. For the meta block parameter update, the loss for the gradient is computed using each task's fine-tuned model parameters \ud835\udf03 meta \ud835\udc56 . For the global block parameter update, the loss for the gradient is computed using the model parameters \ud835\udf03 global . By the end of training, we have learned a set of model parameters \u27e8 \ud835\udf03 meta , \ud835\udf03 global \u27e9 for both blocks. \ud835\udf03 meta is obtained by training against a variety of tasks and therefore capable of adapting quickly to any new or old task given just a few data points. 4.3.3 Meta Embedding Generation. The central idea of LiMAML is to decouple serving of meta block and global block in production. Meta block is served offline, whereas Global block is served online during inference. In order to do this, we create a separate flow called Meta Embedding Generation , which is run on a regular cadence (say, once per day) to do fine-tuning of the meta block to output meta embeddings . Algorithm 2b provides the set of steps for updating \ud835\udf03 meta frequently via meta fine-tuning and producing embeddings for online serving of the global block. In lines 3-6, we use recent samples of each task to update \ud835\udf03 meta and obtain \ud835\udf03 meta \ud835\udc56 for that task by taking \ud835\udc58 gradient descent steps. Note that the number of gradient steps \ud835\udc58 can be different from the number of inner loop gradient steps \ud835\udc5b taken during training. Every time we run the meta embedding generation flow, we bootstrap the meta block parameters with \ud835\udf03 meta as indicated in line 2 of the algorithm. After getting \ud835\udf03 meta \ud835\udc56 for each task, we then immediately score the meta block with \ud835\udf03 meta \ud835\udc56 as the model parameters using the most recent sample \ud835\udc65 \ud835\udc56 for that task as shown in line 7. We then store the output of the meta block as meta embedding \ud835\udc38 \ud835\udc56 for that task. Note that the input to the meta block only contains entity-specific features and do not contain any other item specific features for a task. Hence, scoring the personalized meta block with the most recent sample \ud835\udc65 \ud835\udc56 would correspond to scoring with the latest entity specific features and obtaining an embedding for that entity. In our experiments, we also tried variants of this approach such as mean pooling of meta embeddings across multiple samples of a task and found little to no difference in the performance of our model. Instead of persisting all the updated task-level model parameters, we only store the output of meta block, which is a fix-sized vector, so called meta embedding . These embedding vectors will be persisted and stored in a feature store for retrieval during online inference. This is an extremely important change as it reduces the required storage from a set of model weights per task (quadrillions of parameters) to an embedding vector per task (tens of billions of parameters). Global Block is served online as per the usual deployment and inference process. When a new scoring request comes in, we retrieve all features as well as the latest version of meta embeddings from the feature store, and score them with the global block \ud835\udf03 global . We highlight the differences between the original MAML and our approach LiMAML in Table 1. In summary, the network is decoupled into two blocks: Meta Block and Global Block. With LiMAML, some of the key advantages include \u00b7 We are able to preserve the personalization capability, while enabling easier deployment of large scale models. \u00b7 Given that meta block is served offline using a sequence of samples per task, we can use any simple to complex architecture for personalization such as ID embedding layer, dense MLP or a transformer for the meta block. \u00b7 Wecan easily refresh a part of the model at a regular cadence and adapt it to the recent user interactions occurring on the platform.", "5 PRODUCTION INSIGHTS": "Serving refreshed meta embeddings via frequent fine-tuning brings in additional complexities to the data and model pipelines in production, especially when the number of tasks runs to the order of hundreds of millions. In this section, we present some insights on how we designed our pipelines and some lessons we learnt while deploying LiMAML to production. Every day, there are two pipelines running in production: a data pipeline and an inference pipeline. As members are interacting with the platform, we first needed a daily data processing pipeline that collects these interactions and creates labeled data by joining with feature datasets. We follow this with an inference pipeline that collects the most recent \ud835\udc4b days of data, groups it on a task level, and performs meta fine-tuning to produce meta embeddings for all tasks. \ud835\udc4b could range from 2 weeks to 2 months depending on the application and the scale of its dataset. These embeddings are then pushed to a feature store for online inference usage. Global block is the model deployed online for inference, which fetches all features from the feature store as well as the pre-populated meta embeddings to make the final prediction. In terms of the cadence of refreshing both blocks, the model parameters \ud835\udf03 meta and \ud835\udf03 global are usually updated as per the regular retraining schedules of different applications. For most use cases, we do not frequently update them because we don't observe significant performance downgrade over time. However, we run the embedding generation flow daily, bootstrapping from \ud835\udf03 meta to produce a fine tuned meta block \ud835\udf03 meta \ud835\udc56 using the latest user interaction data. The primary purpose of the meta block is to capture the fast evolution of user interest and provide personalization of the model. We expect the meta embeddings populated on a daily basis to provide a refreshed representation of each entity or user adapted from their latest engagement history. In our experiments on Push Notifications CTR prediction problem (pTap), updating the embeddings weekly instead of daily caused a drop in offline AUC by 0.5%, indicating that refreshed embeddings are critical to maintaining meta learned model performance online.", "6 OFFLINE EXPERIMENTS": "In this section, we present offline results of LiMAML on various applications at LinkedIn. We begin by providing an overview of all applications and datasets in Section 6.1. Then we use one of the applications as an example for a deep dive in Section 6.2. We then summarize results of other applications in Section 6.3. Some techniques to speed up LiMAML training is presented in Section 6.4 and an ablation study is provided in Section 6.5.", "6.1 Applications and datasets": "We evaluate LiMAML across the following applications at LinkedIn. \u00b7 CTR Prediction of Push Notifications ( pTap ): This model predicts the probability of members tapping on a push notification card sent to their mobile devices from LinkedIn. We define the tasks at a user level, i.e. each recipient of the push notification becomes a new task. \u00b7 CTR Prediction of InApp Notifications ( pClick ): This model predicts the probability of members clicking on a notification shown to the members on the in-app notifications tab within the LinkedIn app. For this model, we experiment with two different task definitions - a per-user task definition as well as a per-(user, notification type) task definition. \u00b7 CTR Prediction of People You May Know Recommendations ( pInvite ): This model predicts the probability of a user sending a connection invite to the recommended person on My Network tab within the LinkedIn App. This model takes in two different entities and their features as input. The first entity is the user, also called as the inviter, who sends the connection invite and second entity is the invitee, who receives the connection invite. We experiment with both entities as the task definitions for this problem. Table 2: Application, Task Definition and Dataset Size across all applications. We describe the scale of these datasets in Table 2. For all applications, the date range used to derive the training data is prior to the date range used for validation data. Similarly, the validation data is temporally before the test data. As each task has a varying number of samples, we also limit the number of samples per task to an upper bound by keeping only the most recent samples. When splitting the training dataset into support and query sets, we sort the samples for each task chronologically over time and assign the first 75% of the samples to the support set, and the last 25% to the query set. This is done to prevent any form of information leakage. Validation data is used for task-level fine-tuning and test data is used for final evaluation and metrics reporting. They can be regarded as the support and query set during inference time.", "6.2 LiMAML on pTap": "6.2.1 Experiment Setup. The baseline model for pTap uses an MLP network. We compare three different algorithms (described below) on this dataset. For each algorithm, we also wish to demonstrate the value of fine-tuning tasks on recent validation data. \u00b7 Vanilla Training: In this approach, we train the neural network with regular gradient descent procedure using optimizers such as Adam. Usually, the samples in the training data are randomly shuffled and a mini-batch of samples are provided at a given time for training. However, in our experiments, we group the training data at a task-level first and then provide a mini-batch of tasks for training. This is done to provide a fairer and stronger baseline to compare with MAML. In the no-fine-tune scenario, we evaluate the same trained model on all tasks on the test data. In the fine-tune scenario, we use the trained model as bootstrap to take a few gradient descent steps on the validation data for each task, and evaluate this per-task model on the test data. \u00b7 Entire Network MAML: In this approach, we use the MAML algorithm from [4] on the entire MLP network. In the no-fine-tune scenario, we evaluate the trained model output from the MAML algorithm on all tasks on the test data. In the fine-tune scenario, we use the trained model as bootstrap to do task adaptation on the validation data for each task, and evaluate this per-task model on the test data. \u00b7 LiMAML: In this approach, we use the LiMAML algorithm described in 2a to meta learn part of the network. The meta block is set to a smaller MLP architecture in comparison to the global block. Referring to Figure 1, meta features include all user-specific features, and, we use both meta features as well as the rest of the features as other features. The setting up of fine-tune and no-fine-tune are similar to Entire Network MAML, except that the task-adaptation (Line 4-8 of Algorithm 2a) is done only for the meta block on the validation data for each task. For all experiments, we report AUC (Area under the ROC Curve) gain (or loss) in comparison to the contextual baseline on the test dataset. Across all our experiments, we usually observe the relative standard deviation of AUC gain over multiple runs to be less than 0.02%. For the outer loop of both variants of MAML, we use the same optimizer as Vanilla Training baseline. In addition to the results on all tasks in the test data, we also slice the results into tasks with less than 25 samples and tasks with greater than 25 samples (in test data). This is done to highlight the efficacy of our approach even on tasks with smaller number of samples. 6.2.2 Experiment Results. We present the results of our experiments in Table 3. As we can see, MAML with Fine Tuning gives significant gains in AUC in comparison to Vanilla Training without and with fine-tuning. This indicates that the model parameters output from the MAML algorithm provides a good bootstrap starting point to quickly and effectively adapt to any task. Additionally, the model parameters output from MAML are not expected to be at any optimal point, and hence we see that MAML without finetuning performs the worst among all approaches. Even though MAML gives the highest gains on tasks with larger number of samples, tasks with smaller number of samples do see significant gains as well. We also observe that LiMAML achieves comparable gains with Entire Network MAML, while additionally providing a production-friendly approach to personalization of large-scale online recommender models. 6.2.3 Comparison with Wide-and-Deep ID embedding models. Here, we want to compare a MAML based personalization strategy with another popular personalization strategy in recommender models using ID embeddings. For this experiment, we construct a baseline pTap model with a wide-and-deep architecture [2] with ID embeddings for every user ID. These embeddings are learnt via an embedding-lookup layer and are then concatenated with other dense features and passed through an MLP network. We compare two variants of LiMAML-based models - one with a learnable embedding-lookup layer as the meta block and the other with a small MLP as the meta block. The global block is kept identical to the baseline network without the ID embedding layer. In Table 4, we present the AUC results of the baseline network as well as the two LiMAML variants on test data. For the baseline network, we report results without fine-tuning since ID embeddings provide the personalization component. For the LiMAML variants, we report results on the test data after task adaption on validation data at a user-level. As we can observe from this experiment, LiMAML proves to be an effective strategy for personalizing a recommender model, with different meta block architectures - MLP layers and ID embeddings layers. In our future work, we plan to explore using more complex architectures, such as transformers [27], as the meta block, to understand the performance across different architectures.", "6.3 LiMAML on other applications": "In Table 5, we list the performance of LiMAML with different task definitions across several other applications. Baseline model for all experiments use the deep neural network architecture for that application. We train the baseline model using Vanilla Training by providing a mini-batch of tasks (samples grouped at a task level). We observe consistent AUC gains from LiMAML (with task adaption) for most applications in comparison to the baseline (without fine-tune). This indicates that the proposed approach provides a robust personalization paradigm for all recommender system models. Additionally, we also learn the significance of choosing the right task definition in meta learning. As seen in pClick, a broader task definition at a user level provides little to no gains, whereas a fine-grained task definition at a (user, notification type) level has a higher gain. We have observed such patterns across many applications.", "6.4 Training speed-up": "LiMAML training is computationally more expensive compared to Vanilla Training due to the additional inner loop task adaptation step resulting in Hessian-vector product computation [4]. On pTap, training with 5 inner loop iterations resulted in 221% increase in training time over Vanilla Training (see Table 9 in Section A.1). We present some techniques which helped us significantly reduce the training time. Firstly, we increased the number of tasks per batch per GPU from 32 to 128. As evidenced in [5], simply increasing the batch size can potentially introduce training instability. Therefore, we employed following techniques to mitigate the challenges with large batch training: \u00b7 We linearly scaled the global learning rate as we scaled the number of tasks per batch [5]. We experimented with different values around the scaled learning rate to choose the optimal setting. \u00b7 We clipped the gradient norm to 1 . 0 during the outer loop. \u00b7 We utilized global learning rate scheduling with warm-up and decay. With these changes, LiMAML could achieve the same offline metrics with 46.85% reduction in training time. We observed that learning rate scheduling and gradient clipping play a pivotal role in achieving faster convergence speed. Secondly, we utilized multi-GPU training in a data parallel paradigm with gradient synchronization between different GPUs. The gradient synchronization is done only during the outer loop but not during the inner loop updates. Multi-GPU training along with the large batch size optimization gave us a 64.28% reduction in training time. Thirdly, we realized that the number of inner loop gradient updates, \ud835\udc5b , significantly affects the training time. We didn't observe a significant difference in AUC gain as we vary \ud835\udc5b . Hence, we change \ud835\udc5b to 1 to achieve further speed-up in training (refer to Appendix A.1 for details). Overall we achieve 77% training speedup by applying all the above techniques. We summarize these results in table 6.", "6.5 Ablation study": "In this section, we provide some insights on the sensitivity of different hyper-parameters and some observations from our experiments with LiMAML. \u00b7 Among the hyper-parameter choices, we observed a relatively higher sensitivity to global learning rate, which requires some tuning to see gains. In Appendix A.3, we present some experiments on pTap and pClick to illustrate this. \u00b7 We experimented with applying dropout after each MLP layer. However, even a dropout rate as low as 0.1 resulted in a drop in test AUC. We postulate that this is the result of using large training dataset with tens or hundreds of millions of tasks which prevents the meta learn model from overfitting. More details about this experiment is presented in Appendix A.2. \u00b7 In Algorithm 2b, we score the latest sample for each task with the fine-tuned meta block to produce meta embeddings. We also investigated the impact of different aggregation methods such as max, mean pooling to produce these embeddings and they all performed poorer than using the latest sample. More details are presented in A.4.", "7 ONLINE EXPERIMENTS": "", "7.1 Online A/B test results": "We have deployed LiMAML based pClick and pTap models for evaluating the propensity of clicking and tapping on notifications. These predicted CTRs are important components in the offline reinforcement learning based decision making system [20] to make notification send/drop decisions. Both pClick and pTap models were experimented separately online with their respective deep neural network as the baselines. We evaluated the performance of these models on the following metrics. \u00b7 Weekly Active Users (WAU) : The number of unique members who have visited the LinkedIn site within a seven-day period. This is one of the most important metrics to drive long term value on our platform. \u00b7 Notifications Click-Through Rate (CTR) : The average clickthrough rate of notifications sent to the members on a daily basis. This is an important metric to measure the relevance of notifications sent to the members. All A/B tests have been conducted online with production traffic, lasting a week. The results are reported in table 7. All numbers are statistically significant ( \ud835\udc5d -value < 0 . 05 ) . As shown in the table, LiMAML based models have not only improved the relevance of notifications sent to the user, but also driven long term value to members on LinkedIn.", "7.2 Analysis of online results": "Frequent members of the platform are usually over-represented in the training datasets across most applications. Hence, we have seen modeling efforts seldom showing improved performance on members with little to no data in the training set. However, with a meta learning based approach, we expect to see personalization of models even on tasks with very few (>=1) samples. We evaluate online model performance on three select user cohorts who are infrequent members of LinkedIn, whom we have seen in our data to have very few samples. \u00b7 Cohort 1 : Members who have visited at least once a week in one of the past four weeks. These users can be roughly regarded as Monthly Active Users. \u00b7 Cohort 2 : Members who have not visited in the past 28 days but have visited in the last 3 months. \u00b7 Cohort3 : Members who have signed up newly on our platform in the last four weeks. These members' data have not been included in training the LiMAML model. In Table 8, we present online A/B test results for these three selected user cohorts. From the table, we can observe that LiMAML models have shown huge online CTR gains as well as long term engagement (WAU) on these cohorts. These gains are large in comparison to what we usually observe for these cohorts in our modeling experiments. Additionally, in one case, we see significant gains in Cohort 3, whose tasks are not present during training LiMAML. This is stemming from the fact that meta learning significantly uplifts the model performance even for members with little to no data, thereby enhancing user segments which were previously underoptimized by the global models. These results also indicate that unlike ID embedding based approaches which usually require a decent amount of data per entity, meta learning can adapt very well to any new or existing task given a few data points, making it a more generalized and effective personalization strategy.", "8 CONCLUSION": "In this paper, we introduced a meta learning method called LiMAML, which provides a generalized framework for personalization of recommender models. We have done extensive experiments to demonstrate significant offline and online metric lifts against state-of-the-art recommendation models when the framework is deployed to different LinkedIn applications. We have also shown the efficacy of our approach on tasks with very little data. For future work, we want to explore different extensions of this approach, along with new applications. Firstly, we want to integrate LiMAML with our in-house foundation models, such as Large Language Models, Reinforcement Learning Agents and Graph Neural Networks. Secondly, many applications contain a flavor of multiple entities for which we need to achieve personalization simultaneously. For example, an ad CTR prediction problem might want a model personalized per user as well as per advertiser, but a task definition of user-advertiser pair may not make sense. Similarly, for a notifications CTR prediction problem, we might want a user task as well as a user-notification type task simultaneously. We are exploring ways to extend LiMAML for multiple simultaneous task definitions, either via multiple meta-blocks or via intelligently combining different task distributions. Thirdly, we are exploring different architectures such as a transformer for the meta block. Given that the meta block is trained on a chronological sequence of user interaction data, a sequential architecture might give higher gains while personalizing on such a data.", "9 ACKNOWLEDGMENTS": "The authors would like to thank Mohsen Jamali, Shipeng Yu, Angus Qiu, Viral Gupta, Akashnil Dutta, Parag Agrawal, Xiaobing Xue and others who collaborated with us, and Kenneth Tay, Ruoying Wang, Ankan Saha for reviewing the paper and providing insightful suggestions.", "REFERENCES": "[1] Yi Wang Aden. 2012. KDD Cup 2012, Track 2. https://kaggle.com/competitions/ kddcup2012-track2 [2] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al. 2016. Wide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems . 7-10. [3] Zhengxiao Du, Xiaowei Wang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Sequential scenario-specific meta learner for online recommendation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 2895-2904. [4] Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-Agnostic MetaLearning for Fast Adaptation of Deep Networks. In Proceedings of the 34th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 70) , Doina Precup and Yee Whye Teh (Eds.). PMLR, 1126-1135. https://proceedings.mlr.press/v70/finn17a.html [5] Priya Goyal, Piotr Doll\u00e1r, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. 2017. Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv preprint arXiv:1706.02677 (2017). [6] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247 (2017). [7] F Maxwell Harper and Joseph A Konstan. 2015. The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis) 5, 4 (2015), 1-19. [8] Nathan Hu, Eric Mitchell, Christopher D Manning, and Chelsea Finn. 2023. MetaLearning Online Adaptation of Language Models. arXiv preprint arXiv:2305.15076 (2023). [9] TIANZE HU. 2021. Hybrid Meta-Learning for Cold-Start Recommendation. (2021). [10] Minseok Kim, Hwanjun Song, Yooju Shin, Dongmin Park, Kijung Shin, and JaeGil Lee. 2022. Meta-learning for online update of recommender systems. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 36. 4065-4074. [11] Minchang Kim, Yongjin Yang, Jung Hyun Ryu, and Taesup Kim. 2023. MetaLearning with Adaptive Weighted Loss for Imbalanced Cold-Start Recommendation. arXiv preprint arXiv:2302.14640 (2023). [12] Hoyeop Lee, Jinbae Im, Seongwon Jang, Hyunsouk Cho, and Sehee Chung. 2019. Melu: Meta-learned user preference estimator for cold-start recommendation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 1073-1082. [13] Mi Luo, Fei Chen, Pengxiang Cheng, Zhenhua Dong, Xiuqiang He, Jiashi Feng, and Zhenguo Li. 2020. Metaselector: Meta-learning for recommendation with user-level adaptive model selection. In Proceedings of The Web Conference 2020 . 2507-2513. [14] Maxim Naumov, Dheevatsa Mudigere, Hao-Jun Michael Shi, Jianyu Huang, Narayanan Sundaraman, Jongsoo Park, Xiaodong Wang, Udit Gupta, CaroleJean Wu, Alisson G Azzolini, et al. 2019. Deep learning recommendation model for personalization and recommendation systems. arXiv preprint arXiv:1906.00091 (2019). [15] Krishna Prasad Neupane, Ervine Zheng, Yu Kong, and Qi Yu. 2022. A dynamic meta-learning model for time-sensitive cold-start recommendations. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 36. 7868-7876. [16] Wentao Ouyang, Xiuwu Zhang, Shukui Ren, Li Li, Kun Zhang, Jinmei Luo, Zhaojie Liu, and Yanlong Du. 2021. Learning graph meta embeddings for cold-start ads in click-through rate prediction. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1157-1166. [17] Feiyang Pan, Shuokai Li, Xiang Ao, Pingzhong Tang, and Qing He. 2019. Warm up cold-start advertisements: Improving ctr predictions via learning to learn id embeddings. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval . 695-704. [18] Haoyu Pang, Fausto Giunchiglia, Ximing Li, Renchu Guan, and Xiaoyue Feng. 2022. PNMTA: A pretrained network modulation and task adaptation approach for user cold-start recommendation. In Proceedings of the ACM Web Conference 2022 . 348-359. [19] Danni Peng, Sinno Jialin Pan, Jie Zhang, and Anxiang Zeng. 2021. Learning an adaptive meta model-generator for incrementally updating recommender systems. In Proceedings of the 15th ACM Conference on Recommender Systems . 411-421. [20] Prakruthi Prabhakar, Yiping Yuan, Guangyu Yang, Wensheng Sun, and Ajith Muralidharan. 2022. Multi-objective Optimization of Notifications Using Offline Reinforcement Learning. arXiv:2207.03029 [cs.LG] [21] Yanru Qu, Han Cai, Kan Ren, Weinan Zhang, Yong Yu, Ying Wen, and Jun Wang. 2016. Product-based neural networks for user response prediction. In 2016 IEEE 16th international conference on data mining (ICDM) . IEEE, 1149-1154. [22] Aniruddh Raghu, Maithra Raghu, Samy Bengio, and Oriol Vinyals. 2019. Rapid learning or feature reuse? towards understanding the effectiveness of maml. arXiv preprint arXiv:1909.09157 (2019). [23] Aravind Rajeswaran, Chelsea Finn, Sham M Kakade, and Sergey Levine. 2019. Meta-learning with implicit gradients. Advances in neural information processing systems 32 (2019). [24] AdamSantoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. 2016. Meta-learning with memory-augmented neural networks. In International conference on machine learning . PMLR, 1842-1850. [25] Jake Snell, Kevin Swersky, and Richard Zemel. 2017. Prototypical networks for few-shot learning. Advances in neural information processing systems 30 (2017). [26] Manasi Vartak, Arvind Thiagarajan, Conrado Miranda, Jeshua Bratman, and Hugo Larochelle. 2017. A meta-learning perspective on cold-start recommendations for items. Advances in neural information processing systems 30 (2017). [27] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems 30 (2017). [28] Chunyang Wang, Yanmin Zhu, Haobing Liu, Tianzi Zang, Jiadi Yu, and Feilong Tang. 2022. Deep Meta-learning in Recommendation Systems: A Survey. arXiv:2206.04415 [cs.IR] [29] Ruoxi Wang, Rakesh Shivanna, Derek Cheng, Sagar Jain, Dong Lin, Lichan Hong, and Ed Chi. 2021. Dcn v2: Improved deep & cross network and practical lessons for web-scale learning to rank systems. In Proceedings of the web conference 2021 . 1785-1797. [30] Youshao Xiao, Shangchun Zhao, Zhenglei Zhou, Zhaoxin Huan, Lin Ju, Xiaolu Zhang, Lin Wang, and Jun Zhou. 2023. G-Meta: Distributed Meta Learning in GPU Clusters for Large-Scale Recommender Systems. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management . 4365-4369. [31] Runsheng Yu, Yu Gong, Xu He, Yu Zhu, Qingwen Liu, Wenwu Ou, and Bo An. 2021. Personalized adaptive meta learning for cold-start user preference prediction. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 35. 10772-10780. [32] Kui Zhao, Yuechuan Li, Zhaoqian Shuai, and Cheng Yang. 2018. Learning and transferring ids representation in e-commerce. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 10311039. [33] Cai-Nicolas Ziegler, Sean M McNee, Joseph A Konstan, and Georg Lausen. 2005. Improving recommendation lists through topic diversification. In Proceedings of the 14th international conference on World Wide Web . 22-32.", "A INFORMATION FOR REPRODUCIBILITY": "", "A.1 Results for different inner loop iterations": "Table 9 illustrates the increase in training time for pTap application when we introduce meta learning over vanilla training. When increasing the inner loop iterations \ud835\udc5b , the training time increases roughly linearly while AUC gains remain the same. We have similar observation on pClick applications.", "A.2 Results with different dropout rates": "In this experiment on pTap, we apply dropout to every layer of the neural network. With dropout, we observe a drop in Test AUC gains. As presented in Table 10, test AUC gains drop from +1.47% to +1.44% with a minimal dropout rate of 0.1. As the dropout rate is increased, we observed the drop in AUC consistently increasing. Table 10: pTap LiMAML Test AUC gains for different dropout rates with respect to vanilla training baseline.", "A.3 Hyperparameter tuning experiments": "On the pTap LiMAML model, we fix the hyperparameter configuration and experiment with different task learning rate values. As evident from Table 12, tweaking task learning rate (0.005 to 10) around the best model configuration has insignificant drop on the test AUC gains. We have similar observation for pClick LiMAML (user, notification type) model as shown in Table 11. We perform similar experiment over global learning rate values to observe the effects on test AUC gains. The resulting test AUC gains are shown in Table 13. We observe that in comparison, the task learning rate requires less tuning and is usually set to 100x or 1000x orders of magnitude higher than global learning rate. This observation is consistent with high task learning rates values used in other MAML works [4, 22].", "A.4 Aggregation strategies": "In our experiments, we score the latest sample for each task with the fine-tuned meta block to produce meta embeddings. Alternatively, we also tried the following strategies (Max, Mean, Cos) to produce these embeddings. : \u00b7 Max: Max pooling across all samples for each task. \u00b7 Mean: Mean pooling across all samples for each task. \u00b7 Cos: Cosine similarity weighted mean pooling, where we take a weighted mean across all the samples for each task with the weights set to the cosine similarity between that sample and the latest sample for the task. As we can see from Table 14, all these aggregation strategies performed poorer in comparison to deriving the meta embeddings from the latest sample for each task."}
