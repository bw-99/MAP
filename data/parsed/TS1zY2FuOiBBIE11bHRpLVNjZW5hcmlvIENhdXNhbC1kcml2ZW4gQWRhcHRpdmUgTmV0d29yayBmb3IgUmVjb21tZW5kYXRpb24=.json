{
  "M-scan: A Multi-Scenario Causal-driven Adaptive Network for Recommendation": "Jiachen Zhu Shanghai Jiao Tong University Shanghai, China gebro13@sjtu.edu.cn Yichao Wang Huawei Noah's Ark Lab Shenzhen, China wangyichao5@huawei.com Jianghao Lin Jiarui Qin chiangel@sjtu.edu.cn qinjr@icloud.com Shanghai Jiao Tong University Shanghai, China Ruiming Tang Huawei Noah's Ark Lab Shenzhen, China tangruiming@huawei.com Weinan Zhang Shanghai Jiao Tong University Shanghai, China wnzhang@sjtu.edu.cn",
  "ABSTRACT": "",
  "Yong Yu ∗": "Shanghai Jiao Tong University Shanghai, China yyu@apex.sjtu.edu.cn",
  "KEYWORDS": "We primarily focus on the field of multi-scenario recommendation, which poses a significant challenge in effectively leveraging data from different scenarios to enhance predictions in scenarios with limited data. Current mainstream efforts mainly center around innovative model network architectures, with the aim of enabling the network to implicitly acquire knowledge from diverse scenarios. However, the uncertainty of implicit learning in networks arises from the absence of explicit modeling, leading to not only difficulty in training but also incomplete user representation and suboptimal performance. Furthermore, through causal graph analysis, we have discovered that the scenario itself directly influences click behavior, yet existing approaches directly incorporate data from other scenarios during the training of the current scenario, leading to prediction biases when they directly utilize click behaviors from other scenarios to train models. To address these problems, we propose the M ultiS cenario C ausal-driven A daptive N etwork M-scan ). This model incorporates a Scenario-Aware Co-Attention mechanism that explicitly extracts user interests from other scenarios that align with the current scenario. Additionally, it employs a Scenario Bias Eliminator module utilizing causal counterfactual inference to mitigate biases introduced by data from other scenarios. Extensive experiments on two public datasets demonstrate the efficacy of our M-scan compared to the existing baseline models.",
  "CCS CONCEPTS": "",
  "· Information systems → Recommender systems .": "∗ Yong Yu is the corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WWW'24, May 13-17, 2024, Singapore, Singapore © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0171-9/24/05...$15.00 https://doi.org/10.1145/3589334.3645635 Multi-scenario Recommendation, Causal Inference, Counterfactual",
  "ACMReference Format:": "Jiachen Zhu, Yichao Wang, Jianghao Lin, Jiarui Qin, Ruiming Tang, Weinan Zhang, and Yong Yu. 2024. M-scan: A Multi-Scenario Causal-driven Adaptive Network for Recommendation. In Proceedings of the ACM Web Conference 2024 (WWW '24), May 13-17, 2024, Singapore, Singapore. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3589334.3645635",
  "1 INTRODUCTION": "With the rapid development of e-commerce platforms, social networks, and other online services, recommendation systems [29] have emerged as crucial tools for personalized content recommendations, enhancing user experience, and increasing business revenue. Traditional recommendation algorithms, such as collaborative filtering [10, 30, 31, 36] and content-based filtering [1, 23, 38, 39], have been extensively employed and implemented. These recommendation algorithms rely on users' historical behavior data to train recommendation models that predict whether users will click on or like specific products. However, traditional recommendation systems have limitations in dealing with complex scenarios and achieving precise predictions. In these systems, recommendation models are designed based on a single scenario, utilizing only the data available within that particular scenario for model training. While single-scenario models can capture variations in user behavior within the given scenario and make accurate predictions, they still encounter three main challenges: (1) Some scenarios suffer from data sparsity [32], especially in the case of cold-start scenarios [13]. (2) The absence of user information from other scenarios may lead to suboptimal performance and incomplete user representations. (3) Single-scenario models may result in resource waste, as large-scale commercial platforms often contain numerous scenarios such as multiple rankings. To address the limitations of single-scenario models, the concept of multi-scenario modeling has been introduced. As is shown in Figure 1, Figure 1a shows a single-scenario situation, while Figure 1b and 1c depict two multi-scenario situations. Multi-scenario recommendation systems [2] integrate information from multiple scenarios through collaborative modeling, thereby enhancing the Jiachen Zhu, et al.",
  "WWW'24, May 13-17, 2024, Singapore, Singapore": "14-33 14-43 phone Recommended For You Trending SPIDERHEAD Just Released pluto (a) Amazon (b) Netflix (c) Google Play Figure 1: Illustration of single and multi scenario situations. Left: the whole page as a single-scenario in Amazon. Medium: horizontal lists as multi-scenarios in Netflix. Right: vertical and horizontal lists as multi-scenarios in Google Play. accuracy and robustness of recommendation algorithms. These systems leverage data from various scenarios to capture diverse user behaviors and train a unified model. This model simultaneously serves multiple scenarios and effectively mitigates resource waste. In the current landscape of multi-scenario recommendation systems, previous works mostly focus on the model framework, such as MMOE [21] and STAR [35]. These approaches train models by incorporating data from various scenarios and designing specific network architectures tailored for multi-scenario settings. For instance, MMOE employs multiple expert networks to implicitly capture features from different scenarios, while STAR adopts a star-shaped topology network with separate sub-networks for each scenario. However, these existing approaches in multi-scenario modeling for recommendations have certain limitations. Firstly, they predominantly concentrate on designing the overall framework at the model architecture level, involving multiple networks or experts, while not explicitly modeling user interests at the individual user level, resulting in not only difficulty to train but also incomplete user representation and suboptimal performance. Secondly, they overlook the data biases introduced by the scenarios themselves, such as the impact of a scenario's location and size on user attention, which directly influences their likelihood to click on it. Therefore, to gain a more intuitive and in-depth understanding of multi-scenario recommendation, we employ a causal graph [24] to depict the qualitative relationships among the variables involved. As is shown in Figure 2, each node represents a causal variable, and a directed edge 𝐴 → 𝐵 indicates that 𝐴 directly influences 𝐵 . · The causal graph consists of five nodes: 𝑈 , 𝐼 , 𝑀 , 𝑆 , and 𝑌 . 𝑈 represents the user, 𝐼 represents the item, 𝑀 represents the matching degree between the user and the item, indicating the user's interest. 𝑆 represents the scenario, and 𝑌 represents the click behavior. Both 𝑈 and 𝐼 naturally have an influence on the user's interest, denoted as 𝑀 . Hence, there are edges 𝑈 → 𝑀 and 𝐼 → 𝑀 in the graph. Furthermore, the user's interest 𝑀 directly affects whether the user clicks on the item, resulting in the edge 𝑀 → 𝑌 . · Next, we consider the impact of the scenario. The edge 𝑆 → 𝑀 indicates that different scenarios lead to distinct user interests. Figure 2: Causal analysis of multi-scenario recommendation. M Y U I S M Y U I S Need Eliminating Need Retaining Potential Impact Click or Not Y Matching or Not M Scenario Identifier S I te m I de ntifie r I U User Identifier Causal Graph Analys is For example, the users' interests in the \"gaming\" scenario would differ from their interests in the \"lifestyle\" scenario. · Finally, we have the edge 𝑆 → 𝑌 , suggesting that the scenario can directly influence the click outcome without affecting the user's interest. This is because factors like the location and size of the scenario can affect the user's field of view, subsequently influencing their click behavior. For instance, if Ranking A is large and positioned centrally, while Ranking B is small and located at the edge, Ranking A is more likely to be clicked because Ranking B may go unnoticed. Based on the causal graph, we can observe that the influence of the scenario on the final click behavior can be categorized into two parts: 𝑆 → 𝑌 and 𝑆 → 𝑀 → 𝑌 . When constructing multi-scenario recommendation systems, it is crucial to take both these influences into account. We not only need to gather insights into user interests and enhance user representations by utilizing data from various scenarios, but also need to address the biases introduced by different scenarios. For instance, if an item 𝐼 appears in scenario B, and B is less noticeable than other scenarios, then when incorporating data where the item 𝐼 is not clicked in scenario B, the model could mistakenly assume that the user genuinely dislikes 𝐼 , disregarding the fact that the user simply didn't notice scenario B. Presently, mainstream approaches to multi-scenario modeling encounter two primary issues: (1) They solely focus on the relationship 𝑆 → 𝑀 → 𝑌 and overlook the direct influence of 𝑆 → 𝑌 . (2) When considering 𝑆 → 𝑀 → 𝑌 , they focus on implicit model design, expecting the model to learn user interests in different scenarios, rather than explicitly modeling user interests. In practice, implicit modeling often requires a large number of parameters which poses difficulties in model training and parameter tuning. Moreover, the absence of explicit user interest modeling may cause incomplete user representations and suboptimal performances. To address the aforementioned issues, we propose the M ultiS cenario C ausal-driven A daptive N etwork ( M-scan ). M-scan incorporates two modules called Scenario Bias Eliminator and Scenario-Aware Co-Attention to address the two problems above respectively. (1) Scenario Bias Eliminator module models the direct influence of the scenario on click behavior and utilizes counterfactual causality to remove its effects. This ensures that our inference within the current scenario is not biased by other scenarios. (2) We want to use a widely successful attention mechanism [41] in M-scan: A Multi-Scenario Causal-driven Adaptive Network for Recommendation WWW'24, May 13-17, 2024, Singapore, Singapore order to extract explicit user interests from other scenarios. But unlike typical attention module [14, 15, 26, 50, 51] as target attention with candidate item as query or self-attention, M-scan introduces a specially designed co-attention [12, 20, 28] with current scenario's behavior also in the query. The Scenario-Aware Co-Attention module explicitly captures the impact of the scenario on user interests. It utilizes two user behavior sequences: the current scenario behavior sequence and the behavior sequences from all scenarios. By explicitly extracting user interests from other scenarios that align with the current scenario, it helps the model make better inferences. The main contributions of our paper are summarized as follows: · To the best of our knowledge, this is the first paper that analyzes the impact of scenarios not only on user interests but also directly on click behavior using causal graphs. · We propose a novel model, M-scan, inspired by causal graphs. We design two modules to address two issues of multi-scenario modeling. The Scenario Bias Eliminator module eliminates the direct biases of other scenarios on click behavior. The ScenarioAware Co-Attention mechanism explicitly models the impact of scenarios on user interests, extracting user interests from other scenarios that align with the patterns of the current scenario. · Weconductoffline experiments on two publicly available datasets and achieve promising results, demonstrating the effectiveness of our proposed model.",
  "2 PRELIMINARIES": "In this section, we will formulate the problem and then give a causal analysis of the multi-scenario recommendation problem.",
  "2.1 Preliminaries": "Weprovide a clear definition and formulation for the multi-scenario recommendation system, as well as define the current scenario user sequence and mixed scenario user sequence that we will use. In the task of multi-scenario recommendation system, we have Musers U = { 𝑢 1 , 𝑢 2 , . . . , 𝑢 𝑀 } , N items I = { 𝑖 1 , 𝑖 2 , . . . , 𝑖 𝑁 } , and P scenario numbers S = { 𝑠 1 , 𝑠 2 , . . . , 𝑠 𝑃 } . We define a user interaction as a triplet that includes the user, item, and scenario, denoted by 𝑦 to represent the click or nonclick. Therefore, the interaction records can be represented as a set Y = { 𝑦 𝑢𝑖𝑠 | 𝑢 ∈ U , 𝑖 ∈ I , 𝑠 ∈ S} .  The multi-scenario recommendation model aims to provide an accurate prediction for 𝑦 𝑢𝑖𝑠 and obtain a recommendation list by ranking the scores of the candidate set. The predicted score 𝑦 𝑢𝑖𝑠 is derived from a model with parameters Θ .  where H 𝑢 = { ℎ 𝑏 1 , ℎ 𝑏 2 , . . . , ℎ 𝑏 𝑁 𝑢ℎ } represents 𝑁 𝑢ℎ sequential behaviors of user u across all scenarios. It includes the common interests of the user in multiple scenarios. We can further obtain the scenario IDs for each behavior ℎ 𝑏 𝑗 , and S 𝑢 = { 𝑠 𝑏 1 , 𝑠 𝑏 2 , . . . , 𝑠 𝑏 𝑁𝑢𝑠 } indicates there are 𝑁 𝑢𝑠 history behaviors in scenario 𝑠 . There is a notable challenge in this situation: during the final inference, it is incorrect to consider the user's interests across all scenarios; rather, we only need to focus on their interests in a specific scenario. Therefore, to achieve more precise predictions, we should adopt the following approach:  Where M 𝑢𝑠 represents the user u's interest in scenario s. It is included in H 𝑢 , and our goal is to extract it.",
  "2.2 Causal-driven Analysis": "Causal graphs are directed acyclic graphs [24] in which a node represents a variable and an edge represents the causal relationship between two variables. They are highly useful from a modeling perspective. In this section, we have built a causal-driven analysis for multi-scenario recommendation and gained inspiration for designing M-scan. In the previous Figure 2, we presented the causal graph for the multi-scenario recommendation system. The following list defines the nodes and edges in the graph: · Node 𝑈 : A user identifier. · Node 𝐼 : An item identifier. · Node 𝑆 : A scenario identifier. · Node 𝑀 : The degree of matching between the user and the candidate item, indicating the user's interest and preference for the item. · Node 𝑌 : The user's final click behavior on the item. · Edge 𝑈 → 𝑀 : The user's features influence the degree of matching between the user and the item. · Edge 𝐼 → 𝑀 : The item's features influence the degree of matching between the user and the item. · Edge 𝑆 → 𝑀 : The scenario in which the user and item are situated influences the degree of matching between them. · Edge 𝑀 → 𝑌 : The degree of matching between the user and the item influences the likelihood of the user clicking on it. · Edge 𝑆 → 𝑌 : The scenario features directly influence the likelihood of the user clicking. In order to explore and model the impact of multiple scenarios, the most important edges that require significant attention are 𝑆 → 𝑀 → 𝑌 and 𝑆 → 𝑌 . These edges represent the influence of scenarios on click behavior through user interests and the direct impact of scenarios on click behavior, respectively. For instance, a user may exhibit different interests in the \"Lifestyle\" and \"Gaming\" scenarios, indicating the influence of 𝑆 → 𝑀 → 𝑌 . Moreover, if the \"Gaming\" category is in a small and remote slot, while the \"Lifestyle\" category is in a larger and more prominent slot, the \"Lifestyle\" category is more likely to be viewed and clicked, demonstrating the influence of 𝑆 → 𝑌 . The presence of these two edges suggests that the click behavior Y in the multi-scenario recommendation system is influenced by both user interests and the scenarios themselves. However, during the inference process, we typically utilize intra-scenario inference, such as recommending 10 candidate items for a specific scenario. During inference, we should only consider user interests and exclude the influence of scenarios because the impact of 𝑆 → 𝑌 remains the same for a particular scenario. Since the real data labels reflect the combined influence of all variables, directly supervising the model output with multi-scenario user interaction labels during WWW'24, May 13-17, 2024, Singapore, Singapore Jiachen Zhu, et al. Figure 3: Overall illustration of M-scan. Scenario Encoder Scenario-Aware Co-Attention Feed-Forward Network(FFN) Scenario Bias Eliminator yb ydb Hu Attn(i, s k , h j ) Luis Ls S Training ys I nference yb FFN ydb = yuis*ys-c*ys yuis yuis Fusion Embedding Layer Scenario Representation Similar Scenario Interest Extraction User Embedding Scenario Embedding Scenario Bias Eliminator Su Scenario-Aware Co-Attention M-scan Framework Scenario FFN ••• ••• History in Current Scenario User Profile u I te m Candidate i s Scenario features ••• ••• History in Other Scenarios Su Hu I te m Embedding S ys yb FFN Fusion Scenario FFN training would introduce the bias of 𝑆 → 𝑌 , leading to biased or suboptimal predictions. Consequently, the model might mistakenly assume that the user's lack of clicks on items from other scenarios indicates disinterest, while in reality, it is simply due to the user's ignoring those items. Hence, during training, it is crucial to model the influences of both 𝑆 → 𝑀 → 𝑌 and 𝑆 → 𝑌 in a specialized manner. During inference, the 𝑆 → 𝑌 bias should be eliminated, with only the influence of 𝑆 → 𝑀 → 𝑌 retained (as depicted in Figure 2). In the following sections, we will provide a comprehensive explanation of the M-scan model, which we have designed to capture the two aspects of scenario influence.",
  "3 METHODOLOGY": "In this section, we will give detailed descriptions of M-scan with its overview and the two primary designs, i.e., Scenario-Aware Co-Attention and Scenario Bias Eliminator.",
  "3.1 M-scan Overview": "When designing our model, we focus on two crucial aspects: eliminating biases from other scenarios and extracting user behaviors specifically for the current scenario from different scenarios. To address the bias issue, we employ a counterfactual causality approach and develop the Scenario Bias Eliminator module. To extract user behaviors for the current scenario explicitly, we introduce the Scenario-Aware Co-Attention mechanism. In this section, we will provide a comprehensive explanation of our M-scan framework on network architecture as well as its training and inference processes. Figure 3 illustrates the overall framework of the M-scan model we designed. As is shown in the figure, M-scan takes five input components: user profile 𝑢 , candidate item 𝑖 , user behaviors in the current scenario 𝑆 𝑢 , historical behaviors across all scenarios 𝐻 𝑢 , and scenario features 𝑠 . We start by feeding all inputs into the embedding layer to transform the sparse raw features 𝑢 , 𝑖 , 𝑠 , S 𝑢 , H 𝑢 into low-dimensional dense embedding vectors 𝒖 , 𝒊 , 𝒔 , 𝑺 𝑢 , 𝑯 𝑢 . In M-scan, our objective is to first model the user interest specifically for the current scenario and then leverage it to extract more similar interests from other scenarios. Therefore, the user behaviors for the current scenario, 𝑺 𝑢 , play a crucial role in the user representation, as the historical behaviors in the current scenario inherently contain the user interest representation in that scenario. So we feed 𝑺 𝑢 into a scenario encoder, which can be implemented using Attention [51], GRU [7], transformer [40], or other encoders to model the representation of the current scenario behavior. We choose GRU here since scenario behaviors are in a sequential order. For the scenario encoder, the input consists of item embedding vectors [ 𝒔 𝑏 1 , 𝒔 𝑏 2 , . . . , 𝒔 𝑏 𝑁𝑢𝑠 ] . The hidden states [ ℎ 1 , ℎ 2 , . . . , ℎ 𝑁 𝑢𝑠 ] can be calculated using the following formula:    where ⊙ is the element-wise product operator, 𝑾 , 𝑼 , 𝒃 are weight parameter matrices. . With this, the historical behavior for the current scenario has been effectively modeled. Our next objective is to extract user interests that are similar to the current scenario from the behaviors observed in other scenarios. For this purpose, we utilize the historical behaviors across all scenarios 𝑯 𝑢 . To capture the interest of historical behaviors more accurately, we employ the widely adopted attention mechanism in sequential recommendation. Ideally, we would like to leverage only those historical behaviors that align with the interests of the current scenario. However, since we lack explicit knowledge about which behaviors from other scenarios are aligned with the current scenario's interests, we adopt an indirect measure to identify relevant historical behaviors. Specifically, we quantify the alignment of interests by measuring the similarity between the behaviors of the current scenario and those of other scenarios. This is where our specially designed Scenario-Aware Co-Attention mechanism comes into play, and its detailed explanation will be provided in Section 3.2. Once we have computed the interest alignment 𝛽 𝑗 for each historical behavior 𝒉 𝑏 𝑗 , we employ a weighted aggregation approach using the attention mechanism to obtain the final representation of the user's history.  Next, the prediction ˆ 𝑦 𝑚 of user interest can be obtained by feeding all the features into a feed-forward neural network.  Note that in ˆ 𝑦 𝑚 , the subscript 𝑚 represents matching, which refers to the degree of matching between the user and the item, i.e., user M-scan: A Multi-Scenario Causal-driven Adaptive Network for Recommendation WWW'24, May 13-17, 2024, Singapore, Singapore interest. As discussed in Section 3.2, ˆ 𝑦 𝑚 represents the impact of user interest on the click behavior ( 𝑀 → 𝑌 ). Additionally, there is another aspect of the scenario itself influencing the click behavior ( 𝑆 → 𝑌 ). The prediction ˆ 𝑦 𝑠 for this can be obtained simply by feeding the scenario feature 𝑠 into a feed-forward neural network.  3.1.1 Training and inference process. In Section 2.2, we conduct causal graph analysis and determine that the true sample labels 𝑦 are influenced by both 𝑀 → 𝑌 and 𝑆 → 𝑌 . Hence, directly using a model trained with 𝑦 for inference would be inappropriate, requiring specific bias removal techniques. Consequently, we model these two influences separately, resulting in ˆ 𝑦 𝑚 and ˆ 𝑦 𝑠 . In this section, we provide a summary of the model's training and inference processes. Detailed theoretical derivations and formulas will be presented in Section 3.3. In the training process, since 𝑦 𝑚 represents the influence of 𝑀 → 𝑌 and 𝑦 𝑠 represents the influence of 𝑆 → 𝑌 , we combine them in the Fusion layer using the following formula:  where 𝜎 denotes the sigmoid function. Subsequently, we supervise the prediction ˆ 𝑦 𝑢𝑖𝑠 using the true labels with the cross-entropy loss function:  (9) Similarly, we supervise the prediction ˆ 𝑦 𝑠 , which solely focuses on the prediction of the scenario's impact on the click behavior:  The final overall loss function is the weighted sum of the above two loss functions:  Here, 𝛼 represents the balancing coefficient. During the inference phase, we adopt the approach of scenariospecific prediction, where each scenario is predicted individually. Since the scenarios are the same, there is no variation in the influence of 𝑆 → 𝑌 . Therefore, we need to remove the previously modeled impact of 𝑆 → 𝑌 to obtain an unbiased prediction that truly represents the user interest. The formula for this is as follows:  Here, 𝑐 is a hyper-parameter that represents the counterfactual reference state of 𝑦 𝑚 . The theoretical analysis of this formula will be discussed in subsequent sections. Intuitively, this inference formula can be understood as an adjustment based on 𝑦 𝑢𝑖𝑠 . For example, consider two scenarios 𝑠 1 and 𝑠 2, where 𝑠 1 is more prominent and likely to be clicked compared to 𝑠 2. In this case, if 𝑦 𝑠 1 >> 𝑦 𝑠 2 , subtracting the second term 𝑐 ∗ 𝑦 𝑠 will make 𝑦 𝑚 2 , which was originally smaller than 𝑦 𝑚 1 , larger than 𝑦 𝑚 1 . This signifies that although the user is influenced by the scenario, they still clicked, which represents their genuine love for this item. To provide a clear explanation of the training and inference processes, we have prepared pseudocode shown in Algorithm 1.",
  "Algorithm 1 M-scan": "",
  "3.2 Scenario-Aware Co-Attention": "In this section, we will introduce a module called the ScenarioAware Co-Attention module, which is designed to extract user interests from other scenarios that are similar to the current scenario. The attention mechanism widely used in sequence behavior modeling is the target attention [26, 50, 51]. The key point of the target attention mechanism is to compute the relevance between items and each user behavior. The general formula is as follows:  where softmax 𝑗 represents the 𝑗 𝑡ℎ score in the softmax function, and 𝒉 𝑏 𝑗 represents the 𝑗 𝑡ℎ behavior in the historical sequence 𝑯 𝑢 . In traditional target attention mechanisms, it is assumed that all behaviors belong to the user's interest in the current scenario. However, in multi-scenario situations, such attention mechanisms are insufficient. We need to explicitly distinguish which behaviors can help represent interests in the current scenario and utilize them. The indicator of the current scenario's interests is the user's historical behaviors of the current scenario. Therefore, we need to incorporate the historical behaviors of the current scenario into the attention mechanism to compute the relevance scores between behaviors from other scenarios and the current scenario's interest. As is shown in the \"Scenario-Aware Co-Attention\" section of Figure 3, we calculate the Co-Attention matrix C :  where 𝑠 𝑏 𝑘 represents the 𝑘 𝑡ℎ behavior in the historical sequence of the current scenario. \"Attn\" refers to a feed-forward neural network:  where ⊕ represents the concatenation operator. 𝐶 𝑗𝑘 denotes the relevance between the historical behavior 𝒉 𝑏 𝑗 , the current scenario behavior 𝒔 𝑏 𝑘 , and candidate item 𝒊 . Next, we utilize a max-pooling layer to capture the most important correlations of 𝒉 𝑏 𝑗 among { 𝐶 𝑗𝑘 } 𝑁 𝑢𝑠 𝑘 = 1 . This signifies that as long as 𝒉 𝑏 𝑗 is highly correlated with any item in the current scenario, it aligns with the interest distribution of the current scenario.  WWW'24, May 13-17, 2024, Singapore, Singapore Jiachen Zhu, et al. Figure 4: Counterfactual causal graph of multi-scenario recommendation. Scenario Identifier Counterfactual Value Click or Not Potential Impact M* Y U* I* S* S Counterfactual Caus al Graph S Y Thus, 𝑐 𝑗 represents the relevance of behavior 𝒉 𝑏 𝑗 with the entire current scenario sequence 𝑺 𝑢 . Next, the attention score for 𝒉 𝑏 𝑗 is computed using the softmax function.  And this will be used in Eq. (5). By doing so, we can extract historical behaviors from other scenarios that align with the interest of the current scenario and then utilize them.",
  "3.3 Scenario Bias Eliminator": "In Section 3.1, we have listed all the formulas and computations for this module, but we have not provided theoretical derivations and detailed explanations yet. In this section, we will provide a detailed theoretical derivation and explain its rationale. 3.3.1 Causal Counterfactual. In the causal graph depicted in Figure 2, the variables in the graph influence each other, for example, both 𝑀 and 𝑆 have an impact on 𝑌 . Therefore, the variable 𝑌 can be computed based on its ancestor nodes. Mathematically, this can be expressed as follows:  where 𝑌 (·) represents the value function of 𝑌 . It can be observed that the causal graph provides explicit causal relationships, which aids us in constructing the architecture based on the directed edges. Within the causal graph, a variable may have multiple influences on the next variable. These influences can be direct, such as 𝑆 → 𝑌 , or indirect, such as 𝑆 → 𝑀 → 𝑌 . We need to quantify these influences using mathematical formulas, and this is where counterfactual methods come into play. Counterfactual means considering S as s*, representing its removal from reality, for example, by setting S to be empty or an unknown constant value. Since s* is fixed or nonexistent, we can treat it as a reference status, having the same influence on other variables. Consequently, we can compute the total effect of all influences on 𝑌 using counterfactual methods:  Here, M is also replaced by 𝑚 ∗ because 𝑚 ∗ also has an influence on Y. 𝑚 ∗ represents the counterfactual value of M. 3.3.2 Scenario Bias Eliminator. Furthermore, based on the causal graph structure, we can decompose the overall influence into two components: the impact of the scenario on the click behavior 𝑆 → 𝑌 , and the impact of user interest on the click behavior 𝑀 → 𝑌 . The influence of 𝑆 → 𝑌 can be expressed as follows:  where 𝑌 𝑆,𝑚 ∗ represents the scenario 𝑆 obtained and only M is couterfactually removed. We counterfactually remove M because we are only interested in calculating the influence of 𝑆 → 𝑌 while disregarding 𝑀 → 𝑌 . The process of calculating the direct impact of 𝑆 on 𝑌 is a causal counterfactual process since we cannot directly compute it using real data and can only rely on causal reasoning. Once TE and 𝐸 𝑆 → 𝑌 are calculated, 𝐸 𝑀 → 𝑌 can be obtained by subtracting the former from the latter.  At this point, we have obtained the calculated value for 𝐸 𝑀 → 𝑌 , which represents the influence of 𝑀 → 𝑌 . Both terms, 𝑌 ( 𝑆 = 𝑠, 𝑀 = 𝑚 ∗ ) and 𝑌 ( 𝑆 = 𝑠, 𝑀 = 𝑚 ) , can be fitted using neural networks. As mentioned in Section 3.1, we compute two prediction scores, ˆ 𝑦 𝑚 for 𝑀 → 𝑌 and ˆ 𝑦 𝑠 for 𝑆 → 𝑌 . However, the ultimate target label should be 𝑌 ( 𝑆 = 𝑠, 𝑀 = 𝑚 ) , representing the actual click behavior. Therefore, during training, to reconstruct the true click behavior, we combine these two branches together, which is shown in Eq. (8) During inference, since the evaluation criterion is based on individual scenarios, the impact of scenarios on click behavior remains consistent. Therefore, we perform inference solely based on user interest, which is represented by the previously calculated 𝐸 𝑀 → 𝑌 in Eq. (12), as it has already removed the influence of 𝑆 → 𝑌 .",
  "4 EXPERIMENTS": "In this section, we show the experimental settings and results. Three research questions lead the following discussions, and our implementation code of M-scan is publicly available with torch version 1 and mindspore version 2 · RQ1: Does M-scan outperform existing multi-scenario recommendation models? · RQ2: Are both innovative modules of M-scan effective? · RQ3: What is the impact of the balance coefficient 𝛼 and the hyperparameter 𝑐 on the results?",
  "4.1 Experimental Settings": "Weconductexperiments using two publicly available multi-scenario datasets. The descriptions and statistics of the two datasets are detailed in appendix A.1. 4.1.1 Baselines and Hyper-parameters. To demonstrate the effectiveness of our proposed model, we compare it with different stateof-the-art models: Single, Mixing, Finetune, Shared Bottom, MMOE, PLE, AESM2, and M2M. The details of these models and the hyperparameters are introduced in appendix A.2. 4.1.2 Evaluation Metric. We both evaluate the performance of the models in a single scenario and in all the scenarios. The evaluation metric used are the commonly used AUC (Area Under the Curve) [6, 9] and RelaImpr [34, 46] to the Single model. Since model Single 1 https://github.com/Gebro13/M-scan 2 https://gitee.com/mindspore/models/ tree/master/research/recommend/M-scan M-scan: A Multi-Scenario Causal-driven Adaptive Network for Recommendation WWW'24, May 13-17, 2024, Singapore, Singapore cannot be tested in all the scenarios, RelaImpr is calculated by Mix in row \"#All\" in Table 1,",
  "4.2 Overall Performance": "The performance of the proposed M-scan and other baselines are presented in Table 1. #All means the whole dataset with all the scenarios. #1,#2,#3 represent three scenarios respectively. In Cloud Theme, we randomly choose 3 scenarios in 355 scenarios to demonstrate in the table. Model Single and Finetune don't have results in row #All because they can only be tested in one scenario. We have the following observations: · M-scan outperforms the state-of-the-art baselines in two datasets significantly with p-value < 0.05 against the best baseline. This demonstrates that our M-scan model effectively captures the distribution within each scenario and accurately predicts user interests. Additionally, there are significant improvements in AUC in each scenario, which shows the robustness of our Mscan within different scenarios. The reason why the significance level does not drop below 0.05 in certain scenarios is probably attributed to the limited data within these scenarios. · In the whole Aliccp dataset, the PLE model achieves the best performance among the baselines. On the other hand, the MMOE model, which also uses a multi-expert framework, performs significantly worse than PLE. This suggests that the approach of dividing the expert networks into shared and scenario-specific parts in PLE is effective, highlighting the specific characteristics of multi-scenario data distributions. · While AESM2's overall performance is even worse than MMOE, it performs on par with PLE in certain scenarios. This is because AESM2 automatically selects experts as shared or scenariospecific experts. Despite this clever approach, it requires accurate representations of all scenarios. If a scenario representation is inaccurate, selecting unreliable experts can lead to poor results. Therefore, AESM2 only performs well in certain scenarios. · In the Cloud Theme, M2M achieves the best overall performance over the baselines. However, it doesn't perform so well in Aliccp. This could be due to its unique meta-learning mechanism. Compared to datasets with only three scenarios, the dataset with 355 scenarios is better suited for adjusting network weights based on different scenarios. Because it's almost impossible to use 355 experts in the network when using MMOE-based models. So when it comes to a large number of scenarios, it is more feasible to model them in one network together rather than individually(using experts). This is also one of the advantages of M-scan. · Most importantly, we observe that Finetune outperforms other baselines in certain scenarios. It's probably because Finetune uses behaviors in the current scenario to train a model in the 2 𝑛𝑑 stage, reminding the model of its original intention. It inspires us that in the field of multi-scenario recommendation, further improving model architecture has become increasingly complex and hard to train but has only marginal or even negative improvements due to excessive parameters or high requirements for representation. Therefore, rather than implicitly learn unique representations of multiple scenarios through model architecture, we believe it more effective to explicitly model the unique interest representations of multiple scenarios at feature or data Figure 5: Performance of M-scan using different 𝑐 values of Eq. (12) on two datasets. 0 20 40 60 80 100 c (when = 0.001) 0.6595 0.6615 0.6635 0.6655 0.6675 0.6695 0.6715 AUC Aliccp 0 1 2 3 4 5 6 7 8 910 c (when = 0.1) 0.7596 0.7598 0.7600 0.7602 0.7604 0.7606 0.7608 0.7610 AUC Cloud level, reminding the model of its original intention, a.k.a current scenario, which is also one of the main contributions of M-scan.",
  "4.3 Ablation Study (RQ2)": "In this section, we conduct ablation experiments to analyze the effectiveness of two components in M-scan. The main modules of M-scan are the Scenario-Aware Co-Attention (SACA) and the Scenario Bias Eliminator (SBE). Next, we examine the performance of two sub-models: · w/ SACA, w/ SBE: This is the complete version of M-scan, as depicted in Figure 3 · w/ SACA, w/o SBE: This is a sub-model of M-scan without the Scenario Bias Eliminator module. It neither involves causal reasoning nor includes ˆ 𝑦 𝑠 . Instead, it directly trains ˆ 𝑦 𝑚 calculated by the network using the real data labels and uses ˆ 𝑦 𝑚 for inference. · w/o SACA, w/ SBE: This is a sub-model of M-scan without the Scenario-Aware Co-Attention module. It removes the component that extracts the current scenario user interests from historical behaviors of other scenarios. · w/o SACA, w/o SBE: This is a sub-model of M-scan without both the Scenario Bias Eliminator and the Scenario-Aware CoAttention modules. Similar to other mainstream state-of-the-art models, it only utilizes the historical behaviors from the current scenario as features. The results are shown in Table 2. we can observe that the performance of M-scan significantly decreases when the 𝑆𝐵𝐸 module is removed. This finding confirms the existence of scenario bias in the field of multi-scenario recommendation. The Scenario Bias Eliminator we design effectively mitigates the scenario bias and leads to improved performance. Additionally, we can observe that the performance of M-scan also significantly decreases when the SACA module is removed. This finding confirms the importance of incorporating the interests from other scenarios as features into the neural network. The ScenarioAware Co-Attention module effectively extracts user interests from other scenarios that align with the current scenario. Finally, when both the SBE and SACA modules are removed, the performance further deteriorates. This indicates that our SACA module and SBE module are both crucial. WWW'24, May 13-17, 2024, Singapore, Singapore Jiachen Zhu, et al. Table 1: Performance comparison against baselines. The best result for all the models is given in bold, while the second-best is underlined. ∗ represents the significance level p-value < 0.05 against the best baseline. Table 2: The AUC of M-scan and sub-models in ablation study 0.0001 0.001 0.01 0.1 (when c = 18) 0.650 0.655 0.660 0.665 0.670 0.675 AUC Aliccp 0.01 0.1 1 10 (when c = 1) 0.755 0.757 0.759 0.761 0.763 0.765 AUC Cloud",
  "4.4 Hyperparameter Study (RQ3)": "In this section, we conducted hyperparameter experiments on the balance coefficient 𝛼 and the counterfactual hyperparameter 𝑐 . The results are shown in Figure 5 and Figure 6. In Figure 5, we can observe that the evaluation metric AUC initially increases and then decreases with the increase of the counterfactual hyperparameter 𝑐 , reaching a maximum value. The experiment demonstrates that moderation is the key when determining the amount of counterfactual bias removal represented by 𝑐 . If 𝑐 is too large, the bias is excessively removed, and if 𝑐 is too small, the bias is not adequately removed, leading to suboptimal performance. In Figure 6, we can also see that the evaluation metric AUC initially increases and then decreases with the increase of the balance coefficient 𝛼 , reaching a maximum value. The experiment verifies the existence of a balance between the primary cross-entropy function 𝐿 𝑢𝑖𝑠 and the secondary cross-entropy function 𝐿 𝑠 . When 𝛼 approaches 0, 𝐿 𝑠 does not exist, resulting in biased outcomes. Conversely, when 𝛼 approaches infinity, 𝐿 𝑢𝑖𝑠 ceases to exist, impeding the proper training of the recommendation model. From the Figure 5 and 6, we can observe some patterns in hyperparameters adjusting. Since Aliccp has only 3 scenarios while Cloud Theme has 355, it has two impacts: (1) scenario bias in Aliccp is smaller than in Cloud Theme. So 𝛼 , which represents the amount of scenario loss, will be smaller in Aliccp than in Cloud Theme. (2) There are more data in one scenario in Aliccp, so the interests are more concentrated in Aliccp. In this way, user interests have more influence on click behavior. As 𝑐 represents the counterfactual reference state of 𝑀 → 𝑌 in Eq. (12), it is reasonable to be larger in Aliccp than in Cloud Theme.",
  "5 RELATED WORKS": "",
  "5.1 Single-scenario Recommendation": "Most of the existing deep CTR models primarily concentrate on modeling a single scenario and follow the embedding and MLP paradigm. Wide&Deep [6] and DeepFM [9] combine the low-order (explicit interaction) and deep (implicit interaction) components to Figure 6: Performance of M-scan using different 𝛼 values of Eq. (11) on two datasets. enhance performance. EDCN [4] further improves information sharing between different interaction networks in deep models through a parallel structure. DIEN [50] integrates the attention mechanism with GRU [7] to model the dynamic evolution of user interests over time. SIM [25] extracts user interests using two cascaded search units, enabling better modeling of lifelong behavior.",
  "5.2 Multi-scenario Recommendation": "As mentioned previously, the mainstream approach for addressing multi-scenario problem is to create a unified framework that simultaneously models all scenarios. Consequently, our survey primarily focuses on works related to this paradigm. Specifically, Sharedbottom [3] constructs a shared bottom network to encode data from all scenarios, and different sub-networks to serve different scenarios. MMoE [21] adopts a multi-gate mixture-of-experts technique to implicitly capture commonalities and distinctions among multiple scenarios. STAR [35] designs a star topology framework with a central network to capture overarching scenario commonalities and a set of scenario-specific networks to distinguish scenario-specific differences. The combination strategy of the element-wise product of layer weights serves as the information transfer mechanism from the overall scenarios to individual scenarios. PLE [37] divides experts in MMOE into scenario-shared experts and scenario-specific experts. AESM2 [52] adaptively selects suitable experts to obtain knowledge for the current scenario by calculating the distance between experts and scenarios. M2M [47] focuses on advertiser modeling in multiple scenarios and introduces a dynamic weights meta unit to model inter-scenario correlations. LLM-based models[1719] use large language models to integrate overall scenarios. However, the aforementioned methods employ implicit approaches for scenario information transfer, making it challenging to explicitly represent the impacts of multiple scenarios. Furthermore, these models directly use click labels from other scenarios for training, ignoring the impact of scenario bias. M-scan: A Multi-Scenario Causal-driven Adaptive Network for Recommendation WWW'24, May 13-17, 2024, Singapore, Singapore",
  "5.3 Causal Inference": "Causal inference [24] is used in recommendation for debiasing [5], data missing, fairness, etc [16]. For example, IPS [33] adopted an inverse propensity weighting objective to learn unbiased matrix factorization models to address exposure bias. PD [49]introduced backdoor adjustment to remove the confounding popularity bias during model training and incorporated an inference strategy to leverage popularity bias. CR [42] and MACR [45] employ counterfactual inference to remove the effect of clickbait issues and popularity bias respectively. DCR-MOE [11] uses backdoor adjustment and designs an MOE structure network to address confounding features. CBDF [48] tackles the problem of data noise caused by delayed feedback with importance sampling to re-weight the original reward and obtain the modified reward in the counterfactual world. Though causal inference is widely employed to address various problems, scenario bias has not yet been addressed. We highlight the significance of this bias and propose the utilization of counterfactual inference as a means to mitigate its effects.",
  "6 CONCLUSION": "In this paper, we present M-scan, a model for multi-scenario recommendation systems. M-scan incorporates a Scenario-Aware CoAttention mechanism to explicitly extract user interests from other scenarios that can match the current scenario at the feature level.. Additionally, M-scan includes a Scenario Bias Eliminator that employs causal counterfactual reasoning to mitigate biases introduced when we are using data from other scenarios to train models. Mscan demonstrates promising performance in offline experiments conducted on two public datasets, validating its effectiveness. The ablation experiments and hyperparameter analysis further confirm the utility of both modules. In future work, we plan to explore more advanced and comprehensive approaches to address scenario bias removal, continue designing more effective methods to leverage interests from other scenarios, delve into deeper causal reasoning techniques, and conduct online experiments. Finally, we may scale up multi-scenario models to large recommendation models.",
  "ACKNOWLEDGMENTS": "The Shanghai Jiao Tong University team is partially supported by National Key R&D Program of China (2022ZD0114804), Shanghai Municipal Science and Technology Major Project (2021SHZDZX0102) and National Natural Science Foundation of China (62177033, 62322603).",
  "REFERENCES": "[1] Justin Basilico and Thomas Hofmann. 2004. Unifying collaborative and contentbased filtering. In Proceedings of the twenty-first international conference on Machine learning . 9. [2] Iván Cantador, Ignacio Fernández-Tobías, Shlomo Berkovsky, and Paolo Cremonesi. 2015. Cross-domain recommender systems. Recommender systems handbook (2015), 919-959. [3] R Caruana. 1993. Multitask learning: A knowledge-based source of inductive bias1. In Proceedings of the Tenth International Conference on Machine Learning . Citeseer, 41-48. [4] Bo Chen, Yichao Wang, Zhirong Liu, Ruiming Tang, Wei Guo, Hongkun Zheng, Weiwei Yao, Muyu Zhang, and Xiuqiang He. 2021. Enhancing Explicit and Implicit Feature Interactions via Information Sharing for Parallel Deep CTR Models. [5] Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan He. 2023. Bias and debias in recommender system: A survey and future directions. ACM Transactions on Information Systems 41, 3 (2023), 1-39. [6] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al. 2016. Wide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems . 7-10. [7] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling. arXiv:1412.3555 [cs.NE] [8] Zhengxiao Du, Xiaowei Wang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Sequential scenario-specific meta learner for online recommendation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 2895-2904. [9] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247 (2017). [10] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web . 173-182. [11] Xiangnan He, Yang Zhang, Fuli Feng, Chonggang Song, Lingling Yi, Guohui Ling, and Yongdong Zhang. 2023. Addressing confounding feature issue for causal recommendation. ACM Transactions on Information Systems 41, 3 (2023), 1-23. [12] Binbin Hu, Chuan Shi, Wayne Xin Zhao, and Tianchi Yang. 2018. Local and global information fusion for top-n recommendation in heterogeneous information network. In Proceedings of the 27th ACM international conference on information and knowledge management . 1683-1686. [13] Yan Hu, Qimin Peng, and Xiaohui Hu. 2014. A time-aware and data sparsity tolerant approach for web service recommendation. In 2014 IEEE international conference on web services . IEEE, 33-40. [14] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In 2018 IEEE international conference on data mining (ICDM) . IEEE, 197-206. [15] Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017. Neural attentive session-based recommendation. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management . 1419-1428. [16] Dawen Liang, Laurent Charlin, and David M Blei. 2016. Causal inference for recommendation. In Causation: Foundation to Application, Workshop at UAI. AUAI . [17] Jianghao Lin, Bo Chen, Hangyu Wang, Yunjia Xi, Yanru Qu, Xinyi Dai, Kangning Zhang, Ruiming Tang, Yong Yu, and Weinan Zhang. 2023. ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction. arXiv preprint arXiv:2310.09234 (2023). [18] Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Xiangyang Li, Chenxu Zhu, Huifeng Guo, Yong Yu, Ruiming Tang, et al. 2023. How Can Recommender Systems Benefit from Large Language Models: A Survey. arXiv preprint arXiv:2306.05817 (2023). [19] Jianghao Lin, Yanru Qu, Wei Guo, Xinyi Dai, Ruiming Tang, Yong Yu, and Weinan Zhang. 2023. MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 1384-1395. [20] Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh. 2016. Hierarchical question-image co-attention for visual question answering. Advances in neural information processing systems 29 (2016). [21] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed H Chi. 2018. Modeling task relationships in multi-task learning with multi-gate mixture-ofexperts. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1930-1939. [22] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun Gai. 2018. Entire space multi-task model: An effective approach for estimating post-click conversion rate. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval . 1137-1140. [23] Michael J Pazzani. 1999. A framework for collaborative, content-based and demographic filtering. Artificial intelligence review 13 (1999), 393-408. [24] Judea Pearl. 2009. Causality . Cambridge university press. [25] Qi Pi, Guorui Zhou, Yujing Zhang, Zhe Wang, Lejian Ren, Ying Fan, Xiaoqiang Zhu, and Kun Gai. 2020. Search-based user interest modeling with lifelong sequential behavior data for click-through rate prediction. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management . 2685-2692. [26] Jiarui Qin, Weinan Zhang, Xin Wu, Jiarui Jin, Yuchen Fang, and Yong Yu. 2020. User behavior retrieval for click-through rate prediction. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval . 2347-2356. [27] Jiarui Qin, Jiachen Zhu, Bo Chen, Zhirong Liu, Weiwen Liu, Ruiming Tang, Rui Zhang, Yong Yu, and Weinan Zhang. 2022. RankFlow: Joint Optimization of MultiStage Cascade Ranking Systems as Flows. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval . 814-824. [28] Jiarui Qin, Jiachen Zhu, Yankai Liu, Junchao Gao, Jianjie Ying, Chaoxiong Liu, Ding Wang, Junlan Feng, Chao Deng, Xiaozheng Wang, et al. 2023. Learning to Distinguish Multi-User Coupling Behaviors for TV Recommendation. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining . 204-212. WWW'24, May 13-17, 2024, Singapore, Singapore Jiachen Zhu, et al. [29] Paul Resnick and Hal R Varian. 1997. Recommender systems. Commun. ACM 40, 3 (1997), 56-58. [30] Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-based collaborative filtering recommendation algorithms. In Proceedings of the 10th international conference on World Wide Web . 285-295. [31] J Ben Schafer, Dan Frankowski, Jon Herlocker, and Shilad Sen. 2007. Collaborative filtering recommender systems. The adaptive web: methods and strategies of web personalization (2007), 291-324. [32] Andrew I Schein, Alexandrin Popescul, Lyle H Ungar, and David M Pennock. 2002. Methods and metrics for cold-start recommendations. In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval . 253-260. [33] Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and Thorsten Joachims. 2016. Recommendations as treatments: Debiasing learning and evaluation. In international conference on machine learning . PMLR, 16701679. [34] Qijie Shen, Wanjie Tao, Jing Zhang, Hong Wen, Zulong Chen, and Quan Lu. 2021. SAR-Net: A scenario-aware ranking network for personalized fair recommendation in hundreds of travel scenarios. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management . 4094-4103. [35] Xiang-Rong Sheng, Liqin Zhao, Guorui Zhou, Xinyao Ding, Binding Dai, Qiang Luo, Siran Yang, Jingshan Lv, Chi Zhang, Hongbo Deng, et al. 2021. One model to serve all: Star topology adaptive recommender for multi-domain ctr prediction. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management . 4104-4113. [36] Xiaoyuan Su and Taghi M Khoshgoftaar. 2009. A survey of collaborative filtering techniques. Advances in artificial intelligence 2009 (2009). [37] Hongyan Tang, Junning Liu, Ming Zhao, and Xudong Gong. 2020. Progressive layered extraction (ple): A novel multi-task learning (mtl) model for personalized recommendations. In Proceedings of the 14th ACM Conference on Recommender Systems . 269-278. [38] Poonam B Thorat, Rajeshwari M Goudar, and Sunita Barve. 2015. Survey on collaborative filtering, content-based filtering and hybrid recommendation system. International Journal of Computer Applications 110, 4 (2015), 31-36. [39] Robin Van Meteren and Maarten Van Someren. 2000. Using content-based filtering for recommendation. In Proceedings of the machine learning in the new information age: MLnet/ECML2000 workshop , Vol. 30. Barcelona, 47-56. [40] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems 30 (2017). [41] Shoujin Wang, Liang Hu, Yan Wang, Longbing Cao, Quan Z Sheng, and Mehmet Orgun. 2019. Sequential recommender systems: challenges, progress and prospects. arXiv preprint arXiv:2001.04830 (2019). [42] Wenjie Wang, Fuli Feng, Xiangnan He, Hanwang Zhang, and Tat-Seng Chua. 2021. Clicks can be cheating: Counterfactual recommendation for mitigating clickbait issue. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1288-1297. [43] Yichao Wang, Huifeng Guo, Bo Chen, Weiwen Liu, Zhirong Liu, Qi Zhang, Zhicheng He, Hongkun Zheng, Weiwei Yao, Muyu Zhang, et al. 2022. CausalInt: Causal Inspired Intervention for Multi-Scenario Recommendation. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 4090-4099. [44] Yichao Wang, Huifeng Guo, Ruiming Tang, Zhirong Liu, and Xiuqiang He. 2020. APractical Incremental Method to Train Deep CTR Models. CoRR abs/2009.02147 (2020). arXiv:2009.02147 https://arxiv.org/abs/2009.02147 [45] Tianxin Wei, Fuli Feng, Jiawei Chen, Ziwei Wu, Jinfeng Yi, and Xiangnan He. 2021. Model-agnostic counterfactual reasoning for eliminating popularity bias in recommender system. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining . 1791-1800. [46] Dongbo Xi, Zhen Chen, Peng Yan, Yinger Zhang, Yongchun Zhu, Fuzhen Zhuang, and Yu Chen. 2021. Modeling the sequential dependence among audience multistep conversions with multi-task learning in targeted display advertising. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining . 3745-3755. [47] Qianqian Zhang, Xinru Liao, Quan Liu, Jian Xu, and Bo Zheng. 2022. Leaving no one behind: A multi-scenario multi-task meta learning approach for advertiser modeling. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining . 1368-1376. [48] Xiao Zhang, Haonan Jia, Hanjing Su, Wenhan Wang, Jun Xu, and Ji-Rong Wen. 2021. Counterfactual reward modification for streaming recommendation with delayed feedback. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval . 41-50. [49] Yang Zhang, Fuli Feng, Xiangnan He, Tianxin Wei, Chonggang Song, Guohui Ling, and Yongdong Zhang. 2021. Causal intervention for leveraging popularity bias in recommendation. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval . 11-20. [50] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Deep interest evolution network for click-through rate prediction. In Proceedings of the AAAI conference on artificial intelligence , Vol. 33. 5941-5948. [51] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1059-1068. [52] Xinyu Zou, Zhi Hu, Yiming Zhao, Xuchu Ding, Zhongyi Liu, Chenliang Li, and Aixin Sun. 2022. Automatic Expert Selection for Multi-Scenario and Multi-Task Search. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1535-1544.",
  "A EXPERIMENTAL SETTINGS": "",
  "A.1 Datasets": "We conducted experiments using two publicly available multiscenario datasets, which are listed in Table 3:",
  "Table 3: The data statistics.": "· Aliccp [22]: This dataset is provided by AliMama. It is collected from the recommendation system logs of the mobile Taobao application, including click data and associated conversion data. The dataset has 3 themes, which can be considered as a multiscenario recommendation dataset. · Cloud Theme [8]: This dataset contains user click logs from the cloud theme scenario in the Taobao app. It is used to optimize recommendations for users in multiple different scenarios. It consists of 355 scenarios and 1.4 million records. Train & test splitting . We first filter out the users who own behaviors across multiple scenarios and then sort all the logged samples in chronological order. Finally, we split the most recent 40% samples as the test set while the other samples are put into the training set because we always use the old data to train and infer on the new data. It is a widely used splitting strategy in recommendation tasks. [26, 27]",
  "A.2 Baseline Model": "The baseline models compared in the experiments are listed as follows: · Single . The model is trained only with samples from the target scenario. Specifically, three-layer fully connected networks are applied for the experiments. · Mix . We refer to the Mix as the model trained with a mixture of samples from all scenarios. The model structure is the same as the Single. · Finetune . Finetune is a commonly-used and effective domain adaption (DA) training manner in industrial recommendation system [43, 44]. It first trains a unified model with the mixture of samples from all scenarios (namely the Mix), then adjusts the unified model with the data of the target scenario. · Shared bottom [3]: Shared bottom is a widely used multiscenario multi-task model that shares the parameters of the bottom network. Specifically, we use the embedding layer as the shared part and design 3 fully connected layers for each scenario on top of the shared part. WWW'24, May 13-17, 2024, Singapore, Singapore M-scan: A Multi-Scenario Causal-driven Adaptive Network for Recommendation · MMOE [21]: MMOE is a multi-scenario multi-task model that is based on the shared bottom and uses multiple expert networks to learn knowledge for multiple scenarios and tasks, which are then integrated for prediction. · PLE [37]: PLE is currently a state-of-the-art multi-scenario model. Compared to MMOE, it divides the experts into scenario-shared and scenario-specific ones and uses a progressive path mechanism to extract deep knowledge from experts. · AESM2 [52]: AESM2 is a state-of-the-art multi-scenario model that adaptively selects suitable experts to obtain knowledge for the current scenario by calculating the distance between experts and scenarios. · M2M [47]: M2M is a state-of-the-art multi-scenario model that uses meta-learning techniques to design meta-attention and meta-network mechanisms for the multi-scenario framework, helping each scenario obtain its unique network.",
  "keywords_parsed": [
    "Multi-scenario Recommendation",
    "Causal Inference",
    "Counterfactual"
  ]
}