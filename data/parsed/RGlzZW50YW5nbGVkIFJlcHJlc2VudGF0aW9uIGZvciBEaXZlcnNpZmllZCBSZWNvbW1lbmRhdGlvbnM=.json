{"Disentangled Representation for Diversified Recommendations": "", "Xiaoying Zhang": "zhangxiaoying.xy@bytedance.com AI Lab, Bytedance Inc.", "Hongning Wang": "hw5x@virginia.edu Department of Computer Science University of Virginia, USA Hang Li lihang.lh@bytedance.com AI Lab, Bytedance Inc.", "Abstract": "Accuracy and diversity have long been considered to be two conflicting goals for recommendations. We point out, however, that as the diversity is typically measured by certain pre-selected item attributes, e.g., category as the most popularly employed one, improved diversity can be achieved without sacrificing recommendation accuracy, as long as the diversification respects the user's preference about the pre-selected attributes. This calls for a fine-grained understanding of a user's preferences over items, where one needs to recognize the user's choice is driven by the quality of the item itself, or the pre-selected attributes of the item. In this work, we focus on diversity defined on item categories. We propose a general diversification framework agnostic to the choice of recommendation algorithms. Our solution disentangles the learnt user representation in the recommendation module into categoryindependent and category-dependent components to differentiate a user's preference over items from two orthogonal perspectives. Experimental results on three benchmark datasets and online A/B test demonstrate the effectiveness of our solution in improving both recommendation accuracy and diversity. In-depth analysis suggests that the improvement is due to our improved modeling of users' categorical preferences and refined ranking within item categories. Keywords: Recommender system, recommendation diversity, disentangled user representation", "1. Introduction": "Recommender systems learn users' interests from historical observations (e.g., their clicks, bookmarked or purchased items, etc.) so as to identify the items that best suit users' preferences. The success of recommender system in enhancing user experience and boosting platform utility has been witnessed in a number of scenarios including e-commerce (Zhou et al., 2018; He and Chua, 2017), online news recommendation (Wu et al., 2019a) and streaming services (Covington et al., 2016). Recommendation accuracy, which measures whether a recommendation model can recommend items that users will like, serves as the dominant target or even the only target in most previous work (Zhou et al., 2018; Wang et al., 2021; He and Chua, 2017; Guo et al., 2017; Covington et al., 2016). Various complicated models (Zhou et al., 2018; Guo et al., 2017; Covington et al., 2016) have been proposed for higher accuracy. While recommendation accuracy has been shown to be closely related to user satisfaction, it is never 1 Figure 1: Illustration of recommendation accuracy and diversity optimization in different recommendation models. Action movie Romance movie Children's movie Documentary User browsing history Diversifying across Diversifying within the all item categories user'$ preferred categories 1 0.2 0.1 Feedback loop Accuracy-targeted recommendation models (KIDS) 1 0.1 User feedback the only rule of thumb. Recent work found the recommendation diversity, which measures the dissimilarity among recommended items regarding certain pre-selected item attributes (e.g., item category) also plays an important role in the overall user experience (Wilhelm et al., 2018; Kapoor et al., 2015; Zhou et al., 2010). For example, even if a user is a fan of basketball, he/she can still get bored with recommendations only about basketball videos or news, which increases the risk of user attrition. Following previous work (Steck, 2018; Wang et al., 2021; Zheng et al., 2021a), we focus on diversity defined on item categories in this paper and aim to address the so-called accuracy-diversity dilemma (Zheng et al., 2021a). On one hand, recommendation models with accuracy as their primary target often lose diversity to some extent, due to overly emphasizing items in the dominant categories in a user's interaction history (Steck, 2018; Wang et al., 2021). Figure 1(a) illustrates this issue with an example in movie recommendation, where 70% of the movies watched by a user are action movies, which leads 90% of the system's recommendations to fall in the action movie category. Worse still, because of the feedback loop (Chaney et al., 2018), the emphasis on the dominant categories in the system's recommendations will be further intensified when the user follows the recommendations, causing further decreased recommendation diversity and issues like filter bubbles (Nguyen et al., 2014) and echo chambers (Ge et al., 2020). On the other hand, simply diversifying recommendations over all item categories without considering the user's categorical preference hurts the accuracy of generated recommendations (Wilhelm et al., 2018; Ziegler et al., 2005; Qin and Zhu, 2013; Zheng et al., 2021a). As shown in Figure 1(b), although the recommendation list is diverse by covering all four categories, negative feedback is more 2 likely on the categories where the user interacted less often or negative feedback already prevailed, e.g., children's movies and documentary movies respectively in this example. Clearly one should not recklessly increase diversity. For categories the user is less likely to be interested in, the risk of making a bad recommendation overweights the benefit of increased diversity. Thus, this paper focuses on conducting diversification only among item categories that the user prefers, suggesting the possibility to improve recommendation diversity without sacrificing recommendation accuracy. Figure 1(c) gives an example recommendation list following such a strategy, where the recommended items mainly fall in action and romance movies, the two preferred categories inferred from the user's interaction history. This strategy requires the recommendation model to clearly distinguish whether the user's positive/negative feedback is due to the item's category or other category-independent features of the item (e.g., the item's own quality), which was ignored by previous recommendation models. In this paper, we propose a general and model-agnostic framework to disentangle a user's category-dependent and category-independent preferences for an accurate and diversified recommender system (DCRS). Specifically, DCRS takes a user's preference over an item as a product of: (1) the user's preference over the item's category; and (2) the user's preference over category-independent features of the item, e.g., the item's quality. Such disentanglement suggests a hierarchical decision making process by the user: If a user has a strong preference over a particular category of items, he/she may still enjoy items of this category, even though their qualities are not perfect. However, if the probability that a user likes a category is low, only items of high quality in this category could have a chance to be considered. The disentanglement ensures items of the same quality, but in different categories that a user prefers similarly, have equal probabilities to be recommended. It naturally avoids overly recommending items from the dominant categories in the user's interaction history. The main challenge therefore lies in how to disentangle a user's preference regarding the aforementioned two orthogonal perspectives, given his/her preference over the item categories is not observable. This makes naive solutions like using different supervision signals to separately train users' representations (Zheng et al., 2021b), or separating items' feature vectors into category dependent and independent segments, ineffective. DCRS is agnostic to the choice of recommendation module, which is supposed to learn informative representations of users and items. In particular, DCRS adopts a discriminator to disentangle the learnt representation into category-independent and category-dependent segments respectively. The recommendation module and discriminator are learnt simultaneously to ensure the effectiveness of disentangled representation learning for accurate and diverse recommendations. To evaluate the proposed DCRS solution, we conduct both offline experiments on three benchmark datasets and online A/B test on Toutiao app, one of the largest news recommendation platforms in China. Experiment results demonstrate that DCRS can successfully recommend diverse items that users prefer, and thus improve both recommendation accuracy and diversity. In-depth analysis and case studies suggest strong evidence showing: (1) the disentangled category-independent representation from DCRS can distinguish the user's preference within category more accurately; and (2) DCRS can capture a user's diverse preferences in historical interactions more thoroughly. All codes and data can be found in https://github.com/Xiaoyinggit/DCRS.git . Overall, our contribution of this work is as follows: 3 \u00b7 We demonstrate that accuracy and diversity are not conflicting goals for recommendation, as long as the diversification respects the user's categorical preference. \u00b7 To capture a user's latent preferences on item categories more accurately, our proposed DCRS disentangles the user's preference into category-dependent and categoryindependent components. \u00b7 Experiments on three benchmark datasets and online A/B test demonstrate the effectiveness of DCRS in improving both recommendation accuracy and diversity. In-depth analysis further demonstrates the improvement comes from more accurate modeling of the user's preference both over and within categories.", "2. Framework": "In this section, we describe how the proposed DCRS solution disentangles a user's category dependent and independent preferences to simultaneously improve recommendation accuracy and diversity. For the ease of illustration, we first briefly describe a general architecture which covers almost all popularly used recommendation models. We then depict how to smoothly integrate DCRS into such a general architecture to diversify its recommendations.", "2.1 Preliminary: A General Recommendation Architecture": "In a recommendation task, we are given a user behavior dataset X that contains interactions between N users and M items. The interaction between user u and item i is represented as a tuple ( u, i, y u,i ) \u2208 X . Here y u,i \u2208 { 0 , 1 } denotes user u 's feedback to item i , where y u,i = 1 denotes positive feedback (e,g., a click or a positive rating), and y u,i = 0 denotes negative feedback. Generally speaking, a recommendation model will first learn a user-item representation to capture the user's preference over the item:  where \u03b8 denotes a set of trainable parameters in the recommendation model. Various architectures (Zhou et al., 2018; Wang et al., 2021; He and Chua, 2017; Guo et al., 2017) have been proposed to implement f ( u, i, \u03b8 ), ranging from the simple matrix factorization algorithm (Mnih and Salakhutdinov, 2007) that directly takes the element-wise product of user and item embeddings to form the representation, to complex architectures such as the bi-interaction layer in NFM (He and Chua, 2017). Let \u02c6 p u,i denote the probability that user u gives positive feedback to item i . The goal of the recommendation model is to use the learnt user-item representation to estimate \u02c6 p u,i , either by directly summing up elements in h u,i as in matrix factorization, or through a learnable projection layer as follows:  where Y u,i is a random variable representing the feedback from user u on item i ; W \u2208 R d \u00d7 1 is the learnable weight vector of the projection layer, and \u03c3 ( \u00b7 ) is the sigmoid function. The parameters of the recommendation model are then optimized by minimizing the following 4 loss:  where L rec ( \u00b7 , \u00b7 ) represents the chosen loss function. Various loss functions have been explored in literature, inlcuding cross entropy loss, Mean Squared Error (MSE) and BPR loss (Rendle et al., 2012). In this work, we will use the cross entropy loss by default.", "2.2 Disentangle Category Dependent and Independent Representations": "We consider a user's feedback on an item as a mixture reflecting his/her preference over the item's category and category-independent properties, e.g., the item's intrinsic quality. As shown in Figure 2, the first action movie that receives positive feedback can very likely be caused by the user's strong preference over the category of action movies, while his/her positive feedback on the second romance movie is more likely to be caused by its high quality that makes up the low probability that the user likes romance movies. In order to diversify the recommendations with respect to a user's preferred categories, the recommendation model needs to clearly distinguish the effect of item category and other category-independent properties on a user's decision making. To make our method description general enough to cover situations where an item can associate with multiple categories, we take item i 's category as the set that contains all categories that the item relates to, and denote it as t i . For example, assume there are three categories { c 1 , c 2 , c 3 } in a dataset. If item i is related to the first category, then t i = { c 1 } . And if item i is associated with the first two categories, then t i = { c 1 , c 2 } . We propose to disentangle a user's preference over an item into two parts : \u00b7 Category-dependent preference : it captures the user's preference over the item's category; \u00b7 Category-independent preference : it depicts how category-independent features affect the user's preference about the item. Such a disentanglement can be explained through a probabilistic view about the generation of user u 's feedback on item i . Let Y C u,i denote the binary random variable indicating user u 's feedback on item i 's category. We have the following,    In particular, Eq.(4a) is due to the assumption that user u gives positive feedback to item i only if user u likes item i 's category, i.e., P ( Y u,i = 1 , Y C u,i = 1 | u, i ) = 1 and P ( Y u,i = 1 , Y C u,i = 0 | u, i ) = 0. Eq.(4b) follows the chain rule. And Eq.(4c) is because Y C u,i only depends on the item's category, instead of specific items. The first term in Eq.(4c) depicts how likely user u will give positive feedback to item i when he/she is interested in item i 's category; and the second term models how likely user u is interested in item i 's category. Given that user u likes the category of item i , the 5 Action movie Romance movie The user's preference Figure 2: Hierarchical decision making process of DCRS framework. Each feedback is determined by: (1) the user's preference over the item's category; and (2) the user's preference over category-independent features of the item. Probability that the user recommendation list like each category within category 0.9 1 0.3 Items Item category 1 Items probability in the first term only depends on the category-independent features of item i , such as item i 's quality, price, etc. Thus, under the disentangled user-item representations, we can compute the first term by the probability P ( Y \u22a5 C u,i = 1 | u, i ), which depicts user u 's preference over item i driven by the category-independent features . Thus, Eq.(4c) can be rewritten as:  Eq.(5) depicts a hierarchical decision making process illustrated in Figure 2. If user u likes item i 's category with a higher probability P ( Y C u,i = 1 | u, t i ), he/she may still enjoy item i even though item i 's quality is not perfect, indicated by a lower P ( Y \u22a5 C u,i = 1 | u, i ). For example, the positive feedback of the first action movie in Figure 2 is generated under such a scenario. Meanwhile, if there is only a small probability that user u would be interested in item i 's category (i.e., low P ( Y C u,i = 1 | u, t i )), item i must be of high quality to get positive feedback, i.e., high P ( Y \u22a5 C u,i = 1 | u, i ). The positive feedback on the second romance movie in Figure 2 is a good example of this case. Eq.(5) also suggests why disentanglement makes recommendations diversified within a user's preferred categories. Assume there are two categories c 1 and c 2 on which the user has similar preference. Instead of recommending more items from the dominant category (either c 1 or c 2 ), via the disentanglement in Eq.(5), items of the same quality within c 1 and c 2 will have an equal chance to be recommended, thus diversifying the recommendations. 6 Unfortunately, both terms in Eq.(5) cannot be learnt via direct supervision signals, since neither user u 's feedback on item i 's category nor feedback driven by category-independent features of item i can be observed. Classical solutions would appeal to Expectation Maximization type algorithms (Dempster et al., 1977) to estimate the two terms in an iterative manner. However, given modern recommendation algorithms are usually realized via complex deep neural networks, posterior inference becomes cumbersome and also leads to slow convergence. Instead, DCRS implements Eq.(5) by simultaneously learning two disentangled representations for estimating the two terms separately. Specifically, DCRS learns two disentangled representations by:  where h \u22a5 C u,i \u2208 R d aims to capture user u 's preference over category-independent features to estimate P ( Y \u22a5 C u,i = 1 | u, i ), and h C u,i \u2208 R d depicts user u 's preference over item i 's category t i , aiming to estimate P ( Y C u,i = 1 | u, t i ). Simply splitting item i 's feature vector into two parts, even with separate networks, cannot ensure complete disentanglement. Instead, in addition to requiring the learnt the representations to best capture the user's preference, we employ an adversarial discriminator that enforces the learnt h \u22a5 C u,i and h C u,i to be category-independent and category-dependent respectively. Discriminator Module. The discriminator D ( \u00b7 ) acts as a category classifier, which takes one segment of disentangled representation, such as h C u,i or h \u22a5 C u,i , as input, and aims to predict the category of item i (i.e., t i ). However, it is hard for the discriminator to directly predict t i , since t i can take 2 K -1 values, where K is the number of unique categories available in the dataset. For ease of learning, we represent t i by a vector over K unique categories, denoted as \u02dc t i . Again, assume there are three categories { c 1 , c 2 , c 3 } , if t 1 = { c 1 } , then \u02dc t i = [1 , 0 , 0] glyph[latticetop] . And if t 1 = { c 1 , c 2 } , then \u02dc t i = [0 . 5 , 0 . 5 , 0] glyph[latticetop] . Specifically, when relevance between item i and each associated category can be measured (Pu et al., 2020), a more accurate \u02dc t i can be achieved by making the j -th element of \u02dc t i proportional to the relevance between item i and the j -th category. Otherwise, \u02dc t i can be simply assumed to be evenly distributed among related categories, which is also the default setting in our experiments. The discriminator then takes h C u,i or h \u22a5 C u,i as input to predict \u02dc t i . In our experiments, the discriminator D ( \u00b7 ) is implemented via a fully connected layer, and it should enforce the following: \u00b7 Given h C u,i is closely related to item i 's category, the discriminator should predict \u02dc t i accurately based on h C u,i , i.e., the following loss should be minimized:  where L CE is the cross entropy loss. \u00b7 Given h \u22a5 C u,i is independent from item category, h \u22a5 C u,i should fool the discriminator by maximizing the classification loss:  7 Figure 3: The architecture of DCRS, which disentangles the user u 's preference on item i into category-dependent segment h C u,i and category-independent segment h \u22a5 C u,i for diverse and accurate recommendations. Encoder LS(u,i) G R L Discriminator Loss dLrec Lrec dLrec We leverage a Gradient Reverse Layer (GRL) (Ganin and Lempitsky, 2015) to implement above requirements due to its simplicity. More specifically, we insert a Gradient Reverse Layer between h \u22a5 C u,i and the discriminator, as shown in Figure 3. During back propagation, the gradients for minimizing the discriminator loss \u2202 L \u22a5 C D ( u,i ) \u2202 h \u22a5 C u,i flow backward through the dis- criminator. After the GRL, the gradients will be reversed, i.e., becoming -\u2202 L \u22a5 C D ( u,i ) \u2202 h \u22a5 C u,i . Thus, we perform gradient descent on parameters of the discriminator for accurately predicting item i 's category, while performing gradient ascent on h \u22a5 C u,i , so that h \u22a5 C u,i cannot predict item i 's category. Learning category-independent representation. h \u22a5 C u,i should be optimized under two objectives: (1) it can accurately estimate the first term P ( Y \u22a5 C u,i = 1 | u, i ) in Eq.(5) by:  and (2) it needs to be independent from item categories. Thus we minimize the following loss for its learning:  where the two terms optimize two distinct objectives respectively, and \u03bb is a hyper-parameter that controls the strength of category-independent constraint on h \u22a5 C u,i . Learning category-dependent representation. While user u 's preference on item i 's category is unobservable, P ( Y C u,i = 1 | u, t i ) can be estimated by fixing the learnt categoryindependent representation h \u22a5 C u,i and estimating the overall probability that user u gives 8 positive feedback to item i :  where stop gradient ( h \u22a5 C u,i ) implies that h \u22a5 C u,i will not be updated by this prediction. In other words, given the learnt user u 's preference over category-independent features of item i , only user u 's preference over item i 's category is optimized to accurately predict the overall feedback of user u to item i , by minimizing the loss:  where the second loss forces h C u,i to predict item i 's category accurately with \u03bb representing the strength of the constraint. Overall, combining Eq.(8) and Eq.(10), given a user behavior dataset X , DCRS learns a disentangled recommendation model as in Eq.(5) by minimizing the following loss:  Inference. At the inference stage, we leverage \u02c6 p u,i in Eq.(9) as the predicted preference of user u over item i to rank items. We adopt \u02c6 p u,i in Eq.(9) since it considers both the category dependent and independent preference of the user, while \u02c6 p \u22a5 C u,i in Eq.(7) only captures the user's preference over category-independent features.", "3. Offline Experiments": "In this section, we conduct experiments on several public offline datasets to demonstrate the effectiveness of DCRS. We mainly investigate from two perspectives: \u00b7 How does the proposed DCRS perform in terms of recommendation accuracy and diversity? \u00b7 Can the disentangled category-independent representation accurately distinguish a user's preference within item categories? A case study is also conducted to illustrate the effectiveness of the proposed DCRS more explicitly.", "3.1 Experimental Settings": "Dataset. We use three widely-used datasets under different recommendation scenarios for evaluation. \u00b7 ML-1M 1 : This dataset contains 1 million ratings from 6040 users on 3883 movies from the online movie recommendation service MovieLens. It also contains rich user 1. https://grouplens.org/datasets/movielens/1m/ 9 Table 1: Statistics of Three Datasets features (e.g., age, gender, etc.) and movie features (e.g., titles). We encode user and movie features following previous work (Zhou et al., 2018; Wang et al., 2021). We take y u,i = 1, if user u gives item i a rating greater than 3, otherwise y u,i = 0. \u00b7 ML-10M 2 : This dataset is also from MovieLens. It contains 10 million ratings from 69878 users on 10680 movies. Similarly, we take y u,i = 1, if user u gives item i a rating greater than 3, otherwise y u,i = 0. \u00b7 Amazon-Books 3 : This dataset contains reviews and metadata of books from Amazon. To ensure data quality, we only keep categories that link to more than 20 books with 141 categories, and adopt the 20-core settings (Wang et al., 2021), i.e., discarding users and books with less than 20 interactions. To make the number of positive and negative samples balanced, we take y u,i = 1, if user u gives item i a rating greater than 4, otherwise y u,i = 0. The statistics of the three datasets are summarized in Table 1. On each dataset, we also randomly sampled items that the user did not interact with as negative instances. We then sorted the user-item interactions by timestamps, and split them into training, validation, and testing datasets with the ratio of 80%, 10%, and 10%. Baselines. The proposed DCRS is a general and model-agnostic framework to disentangle category dependent and independent representations for accurate and diverse recommendations. In this paper, we instantiated it with Neural Factorization Machine (NFM) (He and Chua, 2017), one representative recommendation model that has been widely used. NFM was also taken as the backbone model in several closely related work for diversified recommendations (Grgic-Hlaca et al., 2016; Wang et al., 2021). We compared DCRS with the following algorithms that have different focuses on recommendation diversity and accuracy. \u00b7 NFM (He and Chua, 2017) : The state-of-the-art recommendation model serving as the backbone model of DCRS. \u00b7 Unawareness (Grgic-Hlaca et al., 2016) : It also takes NFM as the backbone model and tries to improve diversity by directly removing categorical features of items from model input. \u00b7 IPS (Saito et al., 2020) : It is a state-of-the-art technique of improving diversity by boosting item categories that a user interacted with less often, while suppressing the dominant categories in the user's interaction history. Specifically, it takes the category distribution in a user's historical interactions as propensity scores to reweigh items of 2. https://grouplens.org/datasets/movielens/10m/ 3. https://jmcauley.ucsd.edu/data/amazon/ 10 this category during training. Propensity clipping (Saito et al., 2020) is also employed to reduce the variance with clipping threshold searched in { 0.001, 0.005, 0.01, 0.05, 0.1 } . \u00b7 MMR (Carbonell and Goldstein, 1998) : One of the state-of-art post-processing methods for diversified recommendations. It re-ranks the recommended items generated by NFM by a greedy strategy to reduce redundancy. \u00b7 DPP (Chen et al., 2018) : An effective post-processing method for diversified recommendations. It selects a diverse set of items from the recommended items generated by NFM by balancing the relevance of items and their similarities. \u00b7 PD GAN (Wu et al., 2019c) : A recent work that leverages the generative adversarial networks (GAN) framework to generate diverse and relevant recommendations. Its discriminator aims to distinguish the generated diverse set of items by its generator from the ground-truth sets randomly sampled from the observed data of the user. \u00b7 DGCN (Zheng et al., 2021a) : A recent work that leverages rebalanced neighbor discovering, category-boosted negative sampling and adversarial learning on top of Graph Convolutional Networks (GCN) for diversified recommendations. \u00b7 DecRS (Wang et al., 2021) : A recent work for alleviating the bias that previous recommendation models over-recommend items of the dominant categories in a user's interaction history from a causal view. It aims at improving both recommendation accuracy and diversity. \u00b7 DCRS CI : A variant of DCRS that leverages \u02c6 p \u22a5 C u,i in Eq.(7) for item ranking without considering the user's preference over categories. Its comparison with DCRS CI can reveal the importance of modeling users' categorical preference. Implementation Details. Following previous work (Wang et al., 2021; He and Chua, 2017), we set the embedding size of user/item features to 64 (i.e., d = 64), and used AdaGrad (Duchi et al., 2011) for optimization. We used grid search to select the hyperparameters based on the model's performance on validation dataset: the learning rate was searched in { 0.005, 0.01, 0.05 } ; the normalization coefficient was searched in { 0, 0.1, 0.2 } ; the dropout ratio was searched in { 0.2, 0.3, ..., 0.5 } ; \u03bb for controlling strength of category independent and dependent constraints was searched in { 0.01, 0.05, 0.1, 0.5, 1 } . For baseline algorithms, when evaluating on the dataset the algorithms were also evaluated in their original papers, we adopted the recommended hyperparameters from the original paper; otherwise we performed a similar grid search as above with the search range following the original paper.", "3.2 Performance on Recommendation Accuracy & Diversity": "We first evaluate all algorithms in terms of recommendation accuracy and diversity. Evaluation Metrics. We evaluate the accuracy of a recommendation model from two perspectives: (1) Whether the model can rank positively interacted items of a user before those negatively interacted ones accurately in the testing dataset; (2) Whether the model 11 Table 2: Experimental results regarding to recommendation accuracy and diversity. Improved (or dropped) performance over the base NFM model under the same setting is marked as + (or -). Table 3: Recommendation accuracy of disentangled category-independent representation on category-specifc testing data. can accurately retrieve those positively interacted items in the testing dataset from the item pool, which includes all items that the user did not interact with in the training dataset. For MMR and DPP, because they only re-rank the recommended items generated by NFM, a specifically created item pool that contains top-200 items of NFM is used. We adopted AUC (Fawcett, 2006) and UAUC (Zhou et al., 2018) as metrics to evaluate the first perspective. Basically, UAUC is a micro-average version of AUC, measuring the goodness of intra-user recommendation by averaging AUC over users. Besides, we followed previous work (Yan et al., 2014; Zhou et al., 2018) to use the RelaImpr metric to measure the relative improvement over the base NFM model on UAUC. For a random guesser, the value of AUC is 0.5, and thus RelaImpr is defined as:  12 To evaluate the second perspective of recommendation accuracy, we adopted Recall@K and NDCG@K for the purpose. Regarding recommendation diversity, we used two widelyadopted metrics: (1) Category coverage (CC@K), which is the ratio between number of categories covered by top-K recommendations and the total number of categories in dataset; (2) Category entropy (CE@K), which is the entropy of category distribution in top-K recommendations. Higher CC@K and CE@K suggest more diverse top-K recommendations. Table 2 shows the experiment results of all algorithms. We cannot report AUC, UAUC and RelaImpr for PD GAN, since it directly recommends a set of items. For MMR and DPP, we can only report UAUC and RelaImpr since it is hard to find an appropriate way to merge the re-ranked list of different users to calculate AUC. Based on the results, we can observe that: \u00b7 Although Unawareness, MMR, DPP, PD GAN and DGCN promoted more diverse recommendations with higher CE@K and CC@K, their recommendation accuracy dropped a lot, indicating their failure to handle accuracy-diversity dilemma. \u00b7 IPS did not consistently outperform the base NFM model in recommendation diversity or accuracy, due to the inaccurate estimation and high variance of propensity scores. \u00b7 At most time, especially on ML 1M and ML 10M100K dataset, DecRS improved both recommendation accuracy and diversity, since it could avoid many less-relevant or low-quality items from the dominant categories being recommended. However, its improvement was not larger than our proposed DCRS. \u00b7 Our proposed DCRS effectively improved both recommendation accuracy and diversity on all three datasets compared to the base NFM model. One can observe on all datasets, DCRS achieved the highest recommendation accuracy in all metrics, and generated more diverse recommendations than the base NFM model with higher CC@K and CE@K. This implies that DCRS tends to generate diverse recommendations the users will prefer, rather than solely pursuing diversity regardless of recommendation accuracy. Moreover, compared to DCRS, the recommendation accuracy of DCRS CI dropped on all three datasets, confirming the importance of modeling users' categorical preference.", "3.3 Predicting Users' In-Category Preferences": "We dive deeper to investigate why DCRS can make accurate and diversified recommendations. Based on our design, the disentanglement shields the users' preference on item categories from their preference on items within the category when learning the user-item representations. As a result, the user-item representations learnt by DCRS should better predict a user's interest within item category, compared to those did not consider this aspect. Thus we inspect whether the disentangled category-independent representation (i.e., { h \u22a5 C u,i } ) can distinguish less relevant (or low-quality) items from relevant (or high-quality) items more accurately within a given category of items. We split the testing dataset according to item categories, and evaluated all algorithms on each category-specific testing dataset separately. On all three of our evaluation datasets, an item may relate to multiple categories. For example, the movie 'Toy Story (1995)' in 13 ML-1M dataset is related to three categories: 'Animation', 'Children's', and 'Comedy'. Here, we split the testing dataset according to each unique combination of related categories. Then given one unique combination of categories, we traversed the testing dataset and only kept user-item interactions where the interacted item is associated with the same category combination. To ensure the reliability of the evaluation results, on each dataset, we only evaluated the algorithms on the top-3 most popular categories. In this experimental setting, we only need to evaluate DCRS CI, as all items are from the same category. Table 3 demonstrates the experiment results. Due to space limit, we only report results on AUC, UAUC, Recall@20 and NDCG@20, and omit baselines that perform worse than the base NFM model. From Table 3, we can observe that both DecRS and DCRS CI performed better than the base NFM model, as aligned with the results in Section 3.2. Moreover, DCRS CI achieved the best performance most time, implying that disentangled representations contribute to more accurate preference modeling within categories.", "3.4 Case Study": "We also use a case study to qualitatively illustrate the behavior of the proposed DCRS model. Figure 4 shows the distribution of categories in the interacted items in training and testing data of a user from ML-1M dataset, as well as the top-10 recommended items generated by NFM, DecRS and DCRS. One can observe from Figure 4 that: the top-10 recommendations of NFM and DecRS model mainly fell in the 'Thriller' category, which is the most popular in the training data of this user. Our proposed DCRS could capture the user's preference over categories more thoroughly. As shown in Figure 4, the recommended items from DCRS did not simply concentrate to the dominant category 'Thriller' as in other recommendation algorithms, but they successfully covered six out of ten categories that have a non-zero support in the user's testing data. Moreover, DCRS could also identify the user's preference on categories that the user seldom interacted with before, for example, the category of 'Documentary'. This explains its improved recommendation diversity without losing recommendation accuracy.", "4. Online Deployment and A/B Test": "To further verify the effectiveness of DCRS, we deploy it on the recommendation channel of Toutiao app, one of the largest news recommendation platforms in China, for online A/B test. More specifically, we implemented DCRS based on the main candidate generator of Toutiao. Here, the main candidate generator is one of many candidate generators that produce recommendation candidates, which are later scored and ranked by a separate ranking model before presenting to users (Chen et al., 2019). But the recommendation candidates produced by the main candidate generator account for the largest proportion of the recommendations shown to users. We then replaced the main candidate generator by DCRS in the experimental group, and used the prior main candidate generator in the control group. We adopted two key metrics: (1) Click Through Rate (CTR) ; (2) StayTime , to measure users' satisfaction with the resulting recommendations. To accurately evaluate recommendation diversity, we only targeted items with more than 1000 impressions, because for those 14 Figure 4: Categorical distributions of training data, testing data and top-10 recommended items of a sampled user. Comedy Documentary Fantasy HorrorWar Mystery Western Adventure Musical Drama Children's Thriller Animation Action Crime Film-Noir Sci-Fi Romance 0 . 00 0 . 20 0 . 40 0 . 60 0 . 80 1 . 00 Probability Train Test DCRS NFM DecRS Table 4: Results of online A/B test on Toutiao app. that appear less frequently could be introduced by some special strategies rather than the compared methods. We then calculated four metrics: (1) E CN: number of distinct categories of targeted items shown to a user; (2) E CE: entropy of category distribution of targeted items shown to a user ; (3) R CN: number of distinct categories of targeted items read by a user ; (4) R CE: entropy of category distribution of targeted items read by a user. The A/B test was conducted for seventeen consecutive days and the average performance of the above metrics is reported. We report experimental results in Table 4. All reported results are significant with p-value < 0 . 05. We can observe that DCRS achieved higher CTR and StayTime , indicating improved users' satisfaction. Moreover, while the improvements in E CN and E CE were not that large, DCRS gained huge improvements in R CN and R CE, implying DCRS is able to generate diverse recommendations the user will prefer.", "5. Relate work": "DCRS is closely related to two lines of existing work: (1) addressing accuracy-diversity dilemma in recommendations; and (2) disentangled user representation learning for general user modeling. 15 Addressing accuracy-diversity dilemma in recommendations. Besides recommendation accuracy, more and more research suggests other factors of recommendation quality also contribute to the overall user satisfaction about the system. Of these factors, recommendation diversity has been shown as a critically important one (Anderson et al., 2020; Wilhelm et al., 2018), which however also leads to the so-called accuracy-diversity dilemma (Wang et al., 2021; Zheng et al., 2021a): higher accuracy often means losing diversity to some extent and vice verse. One main reason is that previous solutions with accuracy as the primary goal tend to focus on items in the dominant categories in users' interaction history. In order to guarantee user satisfaction, three different types of solutions are proposed, namely post-processing, learning to rank, and diversified recommendation models. For the first, and most popular, type of solutions, a re-ranking or post-processing module is appended to a chosen recommendation model. The post-processing module takes recommended items as input and re-orders them to balance recommendation accuracy and diversity. Various post-processing algorithms (Ziegler et al., 2005; Qin and Zhu, 2013; Ashkan et al., 2015; Chen et al., 2018; Kaya and Bridge, 2019) are proposed. For example, Ziegler et. al. (Ziegler et al., 2005) first applied the Maximal Marginal Relevance (MMR) algorithm, which was used for topic diversification in search engines, to minimize redundancy among recommended items. Determinantal Point Process (DPP) has been shown as the most effective one (Chen et al., 2018) of all post-processing algorithms, which scores an entire list of items rather than every item individually for better modeling of item correlations. However, all these post-processing algorithms are separately constructed from the recommendation models, though their learning highly depends on the performance of the recommendation model. When the recommendation model fails to provide a diverse item list to start with, or gives pretty-low scores to diverse items, the effectiveness of the aforementioned post-processing algorithms will largely deteriorate. Moreover, as shown in our experiment results in Section 3, the aforementioned post-processing algorithms usually seriously sacrifice recommendation accuracy. Learning To Rank type solutions (Cheng et al., 2017; Wu et al., 2018a; Liu et al., 2022) aim to directly recommend a list of items to users, rather than selecting items one by one according to their prediction scores. However, this line of work often suffers from high time complexity, which limits its application in real world recommendation scenarios. Recently, several solutions are proposed to directly improve the diversity of recommendation models. Zheng et. al (Zheng et al., 2021a) proposed a diversified recommendation model based on Graph Convolutional Networks (GCN), with improving recommendation diversity as its only target. Wu et. al (Wu et al., 2019c) leveraged the GAN framework for diverse recommendations, where a generator tries to recommend diverse sets of items, and a discriminator aims to distinguish the generated recommendations from a set of items randomly sampled from the observed data of the target user. The most related work to ours is (Wang et al., 2021), where the authors studied the problem of lack of diversity in recommendations from a casual perspective, and proposed DecRS to alleviate the problem. Experiments demonstrate the advantage of our proposed DCRS over these solutions in improving recommendation accuracy and diversity. A recent work (Lin et al., 2022) also tried to diversify recommendations in relevant recommendation scenario, where the diversification is conducted regarding multiple item aspects such that relevance and diversity are 16 adaptively balanced among different item aspects. However, when only one item aspect is considered, e.g., the item category in this paper, their algorithm degenerates to the MMR algorithm. Disentangled user representations. Learning disentangled user representations has drawn increasing attention in recent years. A family of solutions are based on Variational Auto-Encoder (VAE) to force each dimension of learnt representations to focus on different latent factors (Ma et al., 2019; Xie et al., 2021; Nema et al., 2021). However, such a disentanglement is implicit and therefore one cannot associate the disentangled representation with the specific attributes of interest. Zheng et. al (Zheng et al., 2021b) proposed DICE to learn representations where user interest and conformity are structurally disentangled via direct supervision from cause-specific data. However, in our problem, we cannot access users' preferences over item categories explicitly, thus are not able to get any direct supervision about it. Chen et. al. (Chen et al., 2022) proposed to disentangle item representations to address popularity bias, by requiring the two disentangled item representations to be orthogonal. In our solution, we disentangle a user's preference over an item into category dependent and independent segments. Both segments relate to the user and thus they do not need to be orthogonal to each other.", "6. Conclusion": "In this paper, we propose a new principle that the diversification of recommendations should be performed within a user's preferred categories, such that improved recommendation diversity can be achieved without sacrificing recommendation accuracy. We realize this principle via a general framework, named DCRS, to disentangle a user's category dependent and independent preference in the learnt representations. We evaluate DCRS through both offline experiments on three widely-used benchmark datasets for recommendation and online A/B test on Toutiao, one of the largest news recommendation platforms in China. We demonstrate DCRS can provide more accurate and diversified recommendations. Via indepth analysis and case studies, we find that the benefit of DCRS is introduced by: (1) it can capture a user's diverse preference in historical interactions more thoroughly; and (2) it can rank items in the same category more accurately. In this work, we took a static view of users' preferences over items and item categories. But numerous studies have demonstrated that users' preferences evolve over time Wu et al. (2018b, 2019b). It is interesting to study the problem of recommendation diversification in an interactive manner over time. Moreover, currently we only recommend one item a time to a user. It is interesting to study how to generate a list of diverse recommendations, where diversity should be optimized within and across recommendation lists.", "References": "Ashton Anderson, Lucas Maystre, Ian Anderson, Rishabh Mehrotra, and Mounia Lalmas. Algorithmic effects on the diversity of consumption on spotify. In Proceedings of The Web Conference 2020 , pages 2155-2165, 2020. Azin Ashkan, Branislav Kveton, Shlomo Berkovsky, and Zheng Wen. Optimal greedy diversity for recommendation. In Twenty-Fourth International Joint Conference on Artificial Intelligence , 2015. 17 18 19 20 Yu Zheng, Chen Gao, Liang Chen, Depeng Jin, and Yong Li. Dgcn: Diversified recommendation with graph convolutional networks. In Proceedings of the Web Conference 2021 , pages 401-412, 2021a. Yu Zheng, Chen Gao, Xiang Li, Xiangnan He, Yong Li, and Depeng Jin. Disentangling user interest and conformity for recommendation with causal embedding. In Proceedings of the Web Conference 2021 , pages 2980-2991, 2021b. Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. Deep interest network for click-through rate prediction. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining , pages 1059-1068, 2018. Tao Zhou, Zolt\u00b4 an Kuscsik, Jian-Guo Liu, Mat\u00b4 u\u02c7 s Medo, Joseph Rushton Wakeling, and YiCheng Zhang. Solving the apparent diversity-accuracy dilemma of recommender systems. Proceedings of the National Academy of Sciences , 107(10):4511-4515, 2010. Cai-Nicolas Ziegler, Sean M McNee, Joseph A Konstan, and Georg Lausen. Improving recommendation lists through topic diversification. In Proceedings of the 14th international conference on World Wide Web , pages 22-32, 2005. 21"}
