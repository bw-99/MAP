{"Scaling User Modeling: Large-scale Online User Representations for Ads Personalization in Meta": "", "ABSTRACT": "", "CCS CONCEPTS": "Effective user representations are pivotal in personalized advertising. However, stringent constraints on training throughput, serving latency, and memory, often limit the complexity and input feature set of online ads ranking models. This challenge is magnified in extensive systems like Meta's, which encompass hundreds of models with diverse specifications, rendering the tailoring of user representation learning for each model impractical. To address these challenges, we present Scaling User Modeling (SUM), a framework widely deployed in Meta's ads ranking system, designed to facilitate efficient and scalable sharing of online user representation across hundreds of ads models. SUM leverages a few designated upstream user models to synthesize user embeddings from massive amounts of user features with advanced modeling techniques. These embeddings then serve as inputs to downstream online ads ranking models, promoting efficient representation sharing. To adapt to the dynamic nature of user features and ensure embedding freshness, we designed SUM Online Asynchronous Platform (SOAP), a latency-free online serving system complemented with model freshness and embedding stabilization, which enables frequent user model updates and online inference of user embeddings upon each user request. We share our hands-on deployment experiences for the SUM framework and validate its superiority through comprehensive experiments. To date, SUM has been launched to hundreds of ads ranking models in Meta, processing hundreds of billions of user requests daily, yielding significant online metric gains and improved infrastructure efficiency. \u2217 Both authors contributed equally to this paper. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WWW'24 Companion, May 13-17, 2024, Singapore, Singapore \u00a9 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0172-6/24/05...$15.00 https://doi.org/10.1145/3589335.3648301 \u00b7 Information systems \u2192 Personalization .", "KEYWORDS": "user representation, personalization, online advertising", "ACMReference Format:": "Wei Zhang, Dai Li, Chen Liang, Fang Zhou, Zhongke Zhang, Xuewei Wang, Ru Li, Yi Zhou, Yaning Huang, Dong Liang, Kai Wang, Zhangyuan Wang, Zhengxing Chen, Fenggang Wu, Minghai Chen, Huayu Li, Yunnan Wu, Zhan Shu, Mindi Yuan, and Sri Reddy. 2024. Scaling User Modeling: Large-scale Online User Representations for Ads Personalization in Meta. In Companion Proceedings of the ACM Web Conference 2024 (WWW '24 Companion), May 13-17, 2024, Singapore, Singapore. ACM, New York, NY, USA, 9 pages. https: //doi.org/10.1145/3589335.3648301", "1 INTRODUCTION": "Personalization [5, 13, 18-20, 25] is the cornerstone of modern online advertising, enhancing both advertiser returns and user experiences. At the heart of personalization is user understanding, which traditionally relied on manually engineered features and simplistic architectures. The advent of deep learning-based recommender systems has shifted this paradigm, leveraging sophisticated neural network models to learn intricate user representations [6, 911, 13, 18, 19, 21, 22, 28-33, 37]. However, practical constraints such as training throughput, serving latency, and host memory limit their capacity to fully utilize the plethora of user data. In expansive systems like Meta's, which encompass lots of diverse models processing hundreds of billions of user requests daily, these limitations become even more pronounced, leading to several interrelated challenges in effective user representation learning: \u00b7 Sub-optimal Representations : Models independently learning user representations often yield inferior results. \u00b7 Feature Redundancy : Overlapping user features across models necessitate unnecessary duplication in training pipelines, leading to high storage overhead. \u00b7 Data Scarcity for Specialized Models : Models serving niche segments lack the large training data volumn needed for robust user understanding. WWW'24 Companion, May 13-17, 2024, Singapore, Singapore Wei Zhang et al. Upstream Online Inference Downstream upon User Request Mobile Feed CTR Supervision IG Feed CTR User (e.9 , click) Representations Web Offsite Conversion App Download Conversion SUM User Model Messenger Post Impresslon Converslon Marketplace CTR Online Conversion Vast Amount of IG Story CTR User Features Train upstream user Get user embeddings SUM user embeddings as input models offline with latest snapshot features to massive downstream Shop models Figure 1: An overview of the proposed SUM framework. SUM envisions the following state: We have a few dedicated user models that can consume a vast amount of user-side features with advanced user modeling techniques and produce embedding representation for each user. User models can be trained with multiple supervisions (click, conversion, etc.) and support recurring snapshot updates. Multiple downstream models are able to safely consume user model output (i.e., SUM user embeddings) as input features. As a result, the gain from the user model will add up across all the downstream models. \u00b7 Intensive Tailoring : Customizing architecture and feature selection for specific performance needs of each model is not scalable. Addressing these challenges is crucial for supporting user modeling with the growing complexity and efficiently scaling representation learning advances across numerous models. To address these challenges, we introduce Scaling User Modeling (SUM) , an online framework revolutionizing user modeling within Meta Ads. SUM is designed to capitalize on advanced modeling techniques while adhering to practical constraints and promoting efficient, scalable representation sharing across models. SUM employs an upstream-downstream paradigm (Figure 1), drawing inspiration from recent works in user history modeling [18, 19, 37]. Our approach involves training a small number of largescale upstream user models with sophisticated architectures under diverse supervisions, like clicks and conversions. The user models process a vast amount of user-side signal (features) to synthesize compact user embeddings (representations). These embeddings are then seamlessly integrated into various downstream production models, propagating advanced user modeling and representation sharing. A key design in SUM is its adaptability to the dynamic nature of user features. Our serving system, SUM Online Asynchronous Platform (SOAP), is a pivotal component, enabling latency-free, asynchronous serving that achieves embedding freshness while overcoming the latency limit regardless of model complexity, substantially surpassing traditional offline-based solutions. Complementing SOAP, we've devised a recurrent training regimen, enhanced by average pooling techniques, to maintain model freshness and stabilize user embeddings. Since its initial deployment, SUM has been launched into hundreds of production ads ranking models in Meta, leading to notable improvements in both offline and online business metrics. Its efficacy and adaptability have also prompted its extension into Meta's feed and quality models. The primary contributions of this paper are: \u00b7 We propose SUM, an online user modeling framework that focuses on optimal usage of all existing user features and complex models within production constraints, and scaling representation learning across hundreds of models. \u00b7 We detail a large-scale user model architecture, essential for learning meaningful user representations from a vast array of input user features, which serves as the backbone of SUM models. \u00b7 We present SOAP, a design of latency-free online serving system that balances feature freshness against serving constraints, surpassing offline solutions and enhancing scalability. \u00b7 We provide extensive experimental studies and practical insights from deploying SUM, including strategies like average pooling to mitigate embedding distribution shifts from frequent model updates.", "2 RELATED WORK": "Personalization has been at the forefront of ads ranking and recommender system research. A plethora of modeling techniques have been proposed to deliver customized ads for users. Factorization Machines [21, 22] transform the high-dimensional and sparse features into low-dimensional vectors using matrix factorization. Collaborative Filtering [4, 16, 23] leverages the patterns of similar users and items to predict personalized recommendations for users. The proliferation of deep learning has empowered modern ads ranking models and recommender systems to learn high-order and non-linear interactions from large-scale datasets [6, 11, 14, 28, 29]. Cutting-edge models like Recurrent Neural Networks (RNNs) [8], Transformers [18, 30] and Graph Neural Networks (GNNs) [9, 26] have further advanced the depth and breadth of personalization. Nevertheless, stringent infrastructural constraints often limit the sophistication of model architectures and the spectrum of user features in online models, inhibiting optimal user representation. As a result, the industry has embraced embedding-based approaches that utilize an upstream-downstream paradigm [2, 9, 10, 18, 19, 26, 3033, 37]. The upstream model is usually trained and updated offline to produce condensed embeddings, which will be used as input features for downstream online production models to consume. In this way, the latency constraints are relaxed, allowing for larger model complexity. The embeddings mainly contain item embeddings [2, 9, 10, 26, 31] and user embeddings [18, 19, 30, 37]. For item embeddings, TwHin from Twitter [9] derives embeddings from a heterogeneous knowledge graph, capturing nuances of users, tweets, and ads. PinSage from PinInterest [31] combines Scaling User Modeling: Large-scale Online User Representations for Ads Personalization in Meta WWW'24 Companion, May 13-17, 2024, Singapore, Singapore Figure 2: An illustration of SUM upstream model architecture. The SUM user tower consumes the massive amount of user features and outputs a few user embeddings which will then be fed to mix tower. The user tower is the core of the upstream model and has a pyramid architecture with residual connections to learn user representations gradually. Its basic building block, Interaction Module, consists of various feature extractors in parallel to capture different feature interactions. SUM User Tower SUM User Nk X D Embeddings Supervision click) Concat Interaction Residual Module K Module K xD Mix Tower Concat SUM User Other Other Embeddings Interaction Module 2 Residual Module 2 Embedding Layer Embedding Layer oo000 Ad Features Concat Interaction Module Residua Module Output 0,* D Output R xD Interaction Output Embeddings Module Dense Embeddings Sparse Embeddings Fusion Extractor Extractor Extractor Embedding Layer Embedding Layer User Dense Features User Sparse Features Dense Input Embeddings Embeddings (e.9 random walks with graph convolutions to learn graph node embeddings. Airbnb [10] extracts listing embeddings to improve search ranking which are pre-computed offline and stored daily to make them real-time available during online serving. ItemSage [2] leverages a transformer-based architecture to learn product embeddings from multi-modalities, which is computationally expensive. It adopts an offline serving solution that performs daily batch inference. Given the inherent stability of item features, embedding staleness from such offline serving solutions remains acceptable. But for the user features used by SUM, it hurts the user embedding performance significantly as discussed in later sections, which makes ensuring embedding freshness crucial for SUM productionization. For user embeddings, PinnerFormer from Pinterest [18] models user sequences, leaning on a daily offline batch setting to reduce infra pressure. Tencent [37] learns user app usage embeddings and updates them daily for the active users, while the upstream model updates are much less frequent to avoid embedding distribution shift and corresponding downstream model updates. Ali [19] mines long-term user behavior through e2e learning, which decouples the user modeling part from entire model and stores the latest user embeddings for easy access online. The user embedding updates are triggered by user behavior events instead of traffic request. Previous studies mainly concentrated on learning user history behavior, along with additional efforts to build and maintain data pipelines for user-centric behaviors. While this work focuses on exploring a feasible solution for supporting user modeling with the growing complexity impractical to be directly added in production ads models, and efficiently scaling user representation sharing in large-scale ads ranking systems.", "3 MODEL ARCHITECTURE": "In this section, we present the design of the upstream SUM user model.", "3.1 Preliminary": "As depicted in Figure 2, the SUM user model utilizes the acclaimed DLRM architecture [17]. It is divided into two main components: the user tower and the mixed tower. The user tower processes an extensive range of user-side input features, converting them into a refined set of SUM user embeddings. These embeddings are then relayed to the mixed tower, where they engage in further WWW'24 Companion, May 13-17, 2024, Singapore, Singapore Wei Zhang et al. interactions with other types of features, such as those related to advertisements. We classify input user features into two major categories: dense and sparse. Dense features are numerical or continuous variables, for example, the frequency of clicks on a particular page. Sparse features are typically categorical or binary variables with high cardinality, including user ID and page ID. These sparse features are storage and computation-intensive, necessitating embedding lookup tables with an exceedingly large parameter count to map raw values to dense embeddings [6, 7, 15, 34, 38]. Standard models often handle fewer than 300 user sparse features, while more compact models are limited to under 100. In contrast, SUM user models are significantly more expansive, accommodating much more user features, far exceeding those managed by downstream models.", "3.2 User Tower": "The user tower employs a pyramid-like structure with successive Interaction Modules to compress these input features methodically. Residual connections [12] are applied to facilitate the training as well as retain the original information. After dense features and sparse features pass the initial embedding layers, assuming we have \ud835\udc41 0 sparse embeddings and \ud835\udc41 \ud835\udc51\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc52 dense embeddings of dimension \ud835\udc37 , the user tower coalesces them into \ud835\udc41 \ud835\udc3e output user embeddings of the same dimension, where \ud835\udc41 0 >> \ud835\udc41 \ud835\udc3e . For the n-th Interaction Module,  Interaction, Residual denote Interaction Module and Residual Module in Figure 2 respectively. \ud835\udc4b \ud835\udc5b -1 is the input of the n-th Interaction Module. \ud835\udc4b \ud835\udc51\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc52 \u2208 \ud835\udc45 \ud835\udc41 \ud835\udc51\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc52 \u00d7 \ud835\udc37 is the raw dense embeddings after the initial embedding layer. Residual Module is usually MLPs. The Interaction Module integrates multiple parallel feature extractors, designed to capture a spectrum of complementary interactions. The feature extractor has different options, some are listed below. MLP. It's used to learn general nonlinear low-level implicit representations. Dot Compression with Attention. Compressing the pairwise dot product matrix is an effective way to increase both model capacity and efficiency. We incorporate an advanced dot compression with attention and residual connections to learn high-level explicit representations, formulated as    where \ud835\udc39\ud835\udc36 (\u2217) means a fully connected layer without non-linear function, \ud835\udc3f\ud835\udc36 (\u2217) means linear compression. \ud835\udc3f\ud835\udc36 ( \ud835\udc4b \ud835\udc51\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc52 ) = \ud835\udc39\ud835\udc36 ( \ud835\udc4b \ud835\udc51\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc52 ) for dense features. \ud835\udc3f\ud835\udc36 ( \ud835\udc4b ) are a set of weighted sum's of the sparse embeddings in \ud835\udc4b . The reason we use \ud835\udc3f\ud835\udc36 (\u2217) before \ud835\udc36\ud835\udc5c\ud835\udc5b\ud835\udc50\ud835\udc4e\ud835\udc61 (\u2217) is to reduce the input size for \ud835\udc40\ud835\udc3f\ud835\udc43 (\u2217) to improve model efficiency. \ud835\udc4c is the attention weights. \ud835\udc4d is the residual branch. Deep Cross Net. DCN [28, 29] learns expressive representations through effective explicit and implicit feature crosses. Its basic component is the cross layer which can be illustrated by the following eqation.  Here \ud835\udc4a \ud835\udc5b and \ud835\udc4f \ud835\udc5b are learnable weight and bias. By stacking multiple cross layers, the model can capture high-order verctor-level and bit-level interactions. MLP-Mixer. MLP-Mixer [24] is an all-MLP architecture that was originally designed for Computer Vision. This architecture can be viewed as a unique CNN, which uses 1x1 convolutions for channel mixing, and single-channel depth-wise convolutions for token mixing as shown in Equation 7 and Equation 6, respectively.   \ud835\udc4a 1, \ud835\udc4a 2, \ud835\udc4a 3, \ud835\udc4a 4 are learnable weights.", "3.3 Mix Tower": "The mix tower adopts a DHEN-style architecture [36]. It does not contain any user-side features as input apart from the SUM user embeddings from user tower. This strategic design choice aims to bolster upstream training throughput and encourage the model to refine user representations primarily through the user tower. Our experience indicates that a more intricate mix tower architecture, though shows stronger predictive performance of the upstream model, does not bring notable improvements to the quality of user embeddings or yield downstream benefits. We utilize a multi-task cross-entropy loss:  where \ud835\udc64 \ud835\udc61 is the weight for task \ud835\udc61, \ud835\udc61 = 1 , 2 , ...\ud835\udc47 , representing its importance in the final loss. \ud835\udc66 \ud835\udc61\ud835\udc56 \u2208 { 0 , 1 } is the label for sample \ud835\udc56 in task \ud835\udc61 . \u02c6 \ud835\udc66 \ud835\udc61\ud835\udc56 is the predicted value of the model for sample \ud835\udc56 in task \ud835\udc61 . \ud835\udc41 is the number of samples.", "4 ONLINE SERVING SYSTEM: SOAP": "In contrast to the relatively stable item features used by [2, 9, 31], the user features within the SUM user tower often changes drastically. A considerable portion of these features are categorical variables, which face challenges from both the introduction of new ids and shifting semantic meanings of existing ids. In this case, the embedding staleness from offline-based serving solutions, either batch inference [2, 18] or event-triggered inference [19] can detrimentally impact downstream performance as discussed in Section 6.4. Thus we decide to implement online inference of the user embeddings upon each user request. However, the latency budget is usually tight for online inference. Typically, once a user request is received, there is a mere 30ms window to conduct the inference and relay user embeddings to downstream ranking models, thereby limiting the complexity of the user model and, by extension, the representative power of SUM user embeddings. To tackle the aforementioned challenges, we designed SUM Online Asynchronous Platform (SOAP) which harnesses a novel Async Scaling User Modeling: Large-scale Online User Representations for Ads Personalization in Meta WWW'24 Companion, May 13-17, 2024, Singapore, Singapore Asynchronous Serving R2. Avgerage pooling of previous embeddings RI. Get previous 0. User Request embeddings Downstream Feature Client Model Store R3. Send the average W2. Write back the pooled embedding to current embedding to models Feature Store W1 Compute the current embedding Compute Service Figure 3: An illustration of SOAP, the online serving system for SUM, which leverages our proposed Async Serving paradigm. Serving paradigm tailored for SUM online inference. As depicted in Figure 3, upon the downstream model receiving a user request, the SOAP Compute Center computes the current embedding using the latest snapshot, subsequently writing it to the Feature Store. In parallel, the Client immediately reads the previous embeddings for this user from Feature Store and forwards the average pooled embedding to the downstream model, without waiting for the Compute Center's inference to conclude. In this way, SOAP decouples the feature write path from the read path. The calculation and updating of the current embedding is invoked as an asynchronous call. By separating the expensive and latency-intensive write path from the read path, Async Serving effectively removes the latency limit and can in theory support complex user models with arbitrarily long inference latency (in practice, the inference latency will still proportionally affect the serving power use, but it is no longer a hard blocker). It significantly outperforms offline-based methods, while trades off a slight amount of realtime-ness to boost scaling potential yeilding improved ROI, as elaborated in Section 6.4. To further reduce inference time, only the user tower of the SUM user model is served in SOAP to generate user embeddings, instead of the entire model.", "5 PRODUCTIONIZATION": "", "5.1 Model Training": "The SUM user model is trained offline in a recurring manner which allows the model to retain historical patterns while incrementally adapting to envolving user preferences. This frequent snapshot publishing, combined with online inference, empowers SUM to consistently deliver up-to-date user embeddings to downstream models.", "5.2 Embedding Distribution Shift": "However, with recurring training, the user model keeps publishing new snapshots. This implies that even for the same inference input, the computed user embeddings are changing over time. We call this phenomenon \"embedding distribution shift\". As shown in Section 6.5, it significantly hurts the effectiveness of the user embeddings. There are two options to mitigate embedding distribution shift. Option 1 One is to make sure a new version of embedding features has been seen by downstream models during training, before it is used in inference. This option requires changes in model training, serving and feature logging, which brings additional complexity to our system. Option 2 The other option is to reduce distribution shift by enforcing a new version to be similar to its previous version. This can be done through various ways such as regularization [9], distillation and post processing with average pooling. We propose to mitigate this by average pooling over the 2 most recent cached embeddings and the current computed embedding as the final current embedding of that user. Average pooling has been a widely adopted practice in ads ranking and recommender systems, especially to cope with code-start problems [3, 10, 27]. We choose this option because it is cheap, brings good performance, and increases feature coverage for free.", "5.3 Feature Storage Optimization": "In production, we usually configure K=2 and D=96, meaning a user model generates 2 SUM user embeddings, each of dimension 96. After investigating the value of K, we found K=2 has good ROI between performance enhancement and feature storage efficiency. To further reduce the online and offline storage use, the two user embeddings are quantized from fp32 to fp16; we evaluated that this quantization didn't lead to downstream performance difference.", "5.4 Distributed Inference": "To lift memory constraints of SUM user model for more performance gains, we've incorporated Distributed Inference (DI) for the user tower so that the online inference workload could be efficiently distributed among multiple hosts.", "6 EXPERIMENTS": "", "6.1 Experimental Setup": "6.1.1 Dataset. In this work, all the experiments were done on industrial datasets. We did not use public datasets as there are gaps applying them onto our serving system and the large discrepancy with internal models makes them unsuitable for downstream experiments.", "6.1.2 Evaluation Metric.": "Normalized Entropy. We use Normalized Entropy (NE) [15, 35] defined in (9) as the metric to evaluate model predictive performance offline. It measures how accurately a model is predicting when users will click on ads. It is equivalent to the average logarithmic loss per impression divided by what the average logarithmic loss per impression would be if a model predicted the background Click Through Rate (CTR, i.e., a constant model that always predicts the average CTR) for every impression. Lower is better.  Here \ud835\udc41 represents the total number of examples in the dataset. \ud835\udc66 \ud835\udc56 \u2208 { 0 , 1 } are the labels, \ud835\udc56 = 1 , 2 , ..., \ud835\udc41 . \ud835\udc5d \ud835\udc56 is the estimated probability of a click for each impression, while p is the average empirical WWW'24 Companion, May 13-17, 2024, Singapore, Singapore Table 1: The performance of FB CTR SUM embeddings on some production ads ranking models in Meta. Offsite, MAI (mobile app install), and inline are all particular ad conversion types. CVR means conversion rate. NE diff means the NE difference of the model with FB CTR SUM embeddings compared to the model without them. Lower is better. FI is the Feature Importance ranking of SUM embeddings in all available sparse and embedding features of that model. The total number of ranked features here is usually thousands. Note that the model in production can only use a small portion of them due to aforementioned practical constraints. CTR. Feature Importance Ranking. We use the Feature Importance Ranking (FI) [1] to evaluate how important one feature is to a model. SUM embeddings generated by the user model are fed to various production models as input. By analyzing the FI ranks of SUM embeddings compared to other available features of one model, we can understand the relative value and impact of SUM user embeddings. 6.1.3 FB CTR SUM User Model. In practice, we maintain a few SUM user models, each trained on different datasets and supervisions. As a representative example for our ensuing discussions, we will focus on the FB CTR SUM user model. FB CTR SUM user model utilizes the training dataset of Facebook mobile app feed, comprising roughly 6 billion daily examples, and targets the CTR prediction task. The user tower consists of four sequentially stacked Interaction Modules, employing MLP, Dot Compression with Attention, and the MLPMixer as feature extractors. It processes around 600 user-side sparse features and 1,000 user-side dense features. As a result, the user tower occupies a size of 160 GB and requires 390M inference FLOPs.", "6.2 Downstream Offline Results": "Table 1 lists the offline NE performance of FB CTR SUM on some downstream models. From Table 1, we can see that SUM embeddings bring statistically significant NE gains across diverse downstream tasks such as CTR prediction, inline conversion prediction, mobile app install conversion prediction, and offsite conversion prediction in various domains. Wei Zhang et al. Table 2: Comparison of SUM performances under different serving schemes. The staleness here is the number of days between the last training date of the user model and the first training date of the downstream ranking model. This underscores the strong representative power and generalizability of SUM. It is expected that they show higher gains in CTR tasks since they are trained on CTR data. One special case is the relatively smaller gains on Instagram models, highlighting the need for a Instagram SUM model to bridge the domain discrepancy between FB and Instagram. Additionally, on those small models like Messenger inbox with low model complexity and feature count, the benefits from large-scale user representation sharing are more salient. What is worth noticing is that, adding SUM embeddings brings minimal training throughput or other infra metrics change to the downstream models, given embedding features are dense representations that do not require computationally intensive embedding look-up tables necessary for sparse features.", "6.3 Online Performance": "SUM has been launched to hundreds of production ads models in Meta, achieving significant gains in both offline and online business metrics, benefiting diverse platforms such as IG, FAM, Shop Ads, Messenger Ads, to name a few. Online A/B tests show that SUM led to 2.67% online ads metric gains in total (0.2% gain can be considered as statistically significant internally). Notably, while accomplishing these gains, SUM successfully avoided 15.3% serving capacity increase, compared to directly introducing the same complexity into each downstream model.", "6.4 Async Serving": "We conduct experiments to compare 4 different serving solutions. Frozen User Model The user model is only trained once and we keep using the initial snapshot to evaluate the new data and generate user embeddings. One important prerequisite for this setting to work is to only consume stable content-based features as input rather than short-lived ID features, which restricts the input feature space considerably. Given that our current user model setup tries to utilize all existing user-side information without differentiating stable features from non-stable features, the frozen model setting might not reach the full potential of the user models. Offline Batch The user model is in daily recurring training after the initial training finished. We use the snapshot trained on (ds-1) to evaluate the data on (ds) to produce user embeddings. Typically there is usually 1 to 3 days staleness, contingent on the data pipeline design of the downstream models. Online Real-time Serving Upon receiving a user request, the Client gets the current embedding from the Compute Service and Scaling User Modeling: Large-scale Online User Representations for Ads Personalization in Meta WWW'24 Companion, May 13-17, 2024, Singapore, Singapore Table 3: Embedding distribution shift study. Embedding 0 and 1 are the two user embeddings output by a SUM upstream model. The number in Average pooling column means how many versions of the embedding are pooled to get final embedding. None means no average pooling applied. (Average) cosine similarity and (average) L2 norm change measure the similarity between two user embeddings produced by snapshots from consecutive dates, which can be regarded as the degree of embedding shift. the previous embeddings from Feature Store, then forwards the average pooled embedding as final current embedding to the downstream model. If the inference of Compute Service does not conclude within the stipulated latency window, it is considered a fallback. Online Async Serving Details are described in Section 4. For a fair comparison of real-time serving and Async serving, the user model we used for this set of experiments is a more compact version with only 20M inference FLOPs, as larger ones would have very high fallback rates. The results are presented in Table 2, showing that transitioning the model serving from real-time to Async incurs a mere 10% average loss, which is much smaller than the loss observed when shifting from real-time to the offline batch setting. Moreover, it paves the way for harnessing more intricate user models, underscoring the benefits of Async Serving.", "6.5 Embedding Distribution Shift": "We conduct offline experiments to understand the embedding distribution shift issue. Here the SUM user model is in Offline Batch mode for easier e2e experiments, i.e., we do daily recurring training for the user model and dump user embeddings using the daily updated moving snapshots. The two user embeddings are denoted as \ud835\udc38\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc51\ud835\udc51\ud835\udc56\ud835\udc5b\ud835\udc54 0 and \ud835\udc38\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc51\ud835\udc51\ud835\udc56\ud835\udc5b\ud835\udc54 1. For each user, we compare the cosine similarity and L2 norm change between the embeddings on consecutive dates, and report the average in Table 3. A side note is that, we also found that \ud835\udc38\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc51\ud835\udc51\ud835\udc56\ud835\udc5b\ud835\udc54 1 brings larger training NE gain to the downstream model than \ud835\udc38\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc51\ud835\udc51\ud835\udc56\ud835\udc5b\ud835\udc54 0, but \ud835\udc38\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc51\ud835\udc51\ud835\udc56\ud835\udc5b\ud835\udc54 0 can bring additional gains on top of \ud835\udc38\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc51\ud835\udc51\ud835\udc56\ud835\udc5b\ud835\udc54 1. Understanding why one embedding is much more stable than the other and why the more stable one brings larger training gains is not the focus of this work. It can be a potential area for future improvement. As shown in Table 4, without average pooling, good training NE gain is observed, which means during training the downstream model can adapt to embedding distribution shift. However, evaluation NE gain is much smaller, which is expected: For evaluation, the embedding features are generated by a new user model snapshot, and the new version of embeddings is not seen by the downstream model during training. The sudden change leads to worse eval NE. Table 4: Downstream model performance of average pooling. AP stands for average pooling. The NE numbers here are NE difference compared to the baseline. Average pooling over 3 embeddings can significantly reduce embedding shift and improve performance, especially in terms of eval NE.", "7 CONCLUSION": "In this paper, we present SUM, a large-scale online personalization framework which empowers Meta's ads ranking models with powerful user representations synthesized from a few SUM user models. Our innovative SOAP serving system facilitates online Async inference of SUM user embeddings, complemented with user model freshness and embedding stabilization. This not only enhances embedding freshness compared to offline serving methods but also unlocks the potential of employing more intricate user models. We delve into the challenges and our best practices in deploying SUM. The experimental results, coupled with its successful launches within Meta, attest to SUM's superiority. SUM has been launched to hundreds of production ads models in Meta, processing hundreds of billions of user requests daily. We believe that this work provides a practical, scalable and efficient path to improve ads personalization with effective user embedding sharing and address the inherent limitations of online ads models in terms of training throughput, memory and serving power. Looking ahead, we aspire to further improve the user modeling algorithm and the serving system to achieve even more nuanced user representations.", "REFERENCES": "[1] Javad Rahimipour Anaraki and Hamid Usefi. 2019. A feature selection based on perturbation theory. Expert Systems with Applications 127 (2019), 1-8. [2] Paul Baltescu, Haoyu Chen, Nikil Pancha, Andrew Zhai, Jure Leskovec, and Charles Rosenberg. 2022. ItemSage: Learning Product Embeddings for Shopping Recommendations at Pinterest. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Washington DC, USA) (KDD '22). Association for Computing Machinery, New York, NY, USA, 2703-2711. https://doi.org/10.1145/3534678.3539170 [3] Walid Bendada, Guillaume Salha-Galvan, Romain Hennequin, Thomas Bouab\u00e7a, and Tristan Cazenave. 2023. On the Consistency of Average Embeddings for Item Recommendation. arXiv:2308.12767 [cs.IR] [4] John S. Breese, David Heckerman, and Carl Kadie. 1998. Empirical Analysis of Predictive Algorithms for Collaborative Filtering. In Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (Madison, Wisconsin) (UAI'98). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 43-52. [5] Haibin Cheng and Erick Cant\u00fa-Paz. 2010. Personalized Click Prediction in Sponsored Search. In Proceedings of the Third ACM International Conference on Web Search and Data Mining (New York, New York, USA) (WSDM '10). Association for Computing Machinery, New York, NY, USA, 351-360. https: //doi.org/10.1145/1718487.1718531 [6] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, Rohan Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah. 2016. Wide & Deep Learning for Recommender Systems. In Proceedings of the 1st Workshop on Deep Learning for Recommender Systems (Boston, MA, USA) WWW'24 Companion, May 13-17, 2024, Singapore, Singapore Wei Zhang et al. (DLRS 2016). Association for Computing Machinery, New York, NY, USA, 7-10. https://doi.org/10.1145/2988450.2988454 [7] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations. In Proceedings of the 10th ACM Conference on Recommender Systems (Boston, Massachusetts, USA) (RecSys '16). Association for Computing Machinery, New York, NY, USA, 191-198. https://doi.org/10. 1145/2959100.2959190 [8] Tim Donkers, Benedikt Loepp, and J\u00fcrgen Ziegler. 2017. Sequential UserBased Recurrent Neural Network Recommendations. In Proceedings of the Eleventh ACM Conference on Recommender Systems (Como, Italy) (RecSys '17). Association for Computing Machinery, New York, NY, USA, 152-160. https: //doi.org/10.1145/3109859.3109877 [9] Ahmed El-Kishky, Thomas Markovich, Serim Park, Chetan Verma, Baekjin Kim, Ramy Eskander, Yury Malkov, Frank Portman, Sof\u00eda Samaniego, Ying Xiao, and Aria Haghighi. 2022. TwHIN: Embedding the Twitter Heterogeneous Information Network for Personalized Recommendation. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Washington DC, USA) (KDD '22). Association for Computing Machinery, New York, NY, USA, 2842-2850. https://doi.org/10.1145/3534678.3539080 [10] Mihajlo Grbovic and Haibin Cheng. 2018. Real-Time Personalization Using Embeddings for Search Ranking at Airbnb. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (London, United Kingdom) (KDD '18). Association for Computing Machinery, New York, NY, USA, 311-320. https://doi.org/10.1145/3219819.3219885 [11] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A Factorization-Machine Based Neural Network for CTR Prediction. In Proceedings of the 26th International Joint Conference on Artificial Intelligence (Melbourne, Australia) (IJCAI'17). AAAI Press, 1725-1731. [12] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual Learning for Image Recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). [13] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In Proceedings of the 26th International Conference on World Wide Web (Perth, Australia) (WWW '17). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE, 173-182. https://doi.org/10.1145/3038912.3052569 [14] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In Proceedings of the 26th International Conference on World Wide Web (Perth, Australia) (WWW '17). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE, 173-182. https://doi.org/10.1145/3038912.3052569 [15] Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, et al. 2014. Practical lessons from predicting clicks on ads at facebook. In Proceedings of the eighth international workshop on data mining for online advertising. 1-9. [16] Yehuda Koren. 2008. Factorization Meets the Neighborhood: A Multifaceted Collaborative Filtering Model. In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (Las Vegas, Nevada, USA) (KDD '08). Association for Computing Machinery, New York, NY, USA, 426-434. https://doi.org/10.1145/1401890.1401944 [17] Maxim Naumov, Dheevatsa Mudigere, Hao-Jun Michael Shi, Jianyu Huang, Narayanan Sundaraman, Jongsoo Park, Xiaodong Wang, Udit Gupta, Carole-Jean Wu, Alisson G. Azzolini, Dmytro Dzhulgakov, Andrey Mallevich, Ilia Cherniavskii, Yinghai Lu, Raghuraman Krishnamoorthi, Ansha Yu, Volodymyr Kondratenko, Stephanie Pereira, Xianjie Chen, Wenlin Chen, Vijay Rao, Bill Jia, Liang Xiong, and Misha Smelyanskiy. 2019. Deep Learning Recommendation Model for Personalization and Recommendation Systems. arXiv:1906.00091 [cs.IR] [18] Nikil Pancha, Andrew Zhai, Jure Leskovec, and Charles Rosenberg. 2022. PinnerFormer: Sequence Modeling for User Representation at Pinterest. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Washington DC, USA) (KDD '22). Association for Computing Machinery, New York, NY, USA, 3702-3712. https://doi.org/10.1145/3534678.3539156 [19] Qi Pi, Weijie Bian, Guorui Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Practice on Long Sequential User Behavior Modeling for Click-Through Rate Prediction. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (Anchorage, AK, USA) (KDD '19). Association for Computing Machinery, New York, NY, USA, 2671-2679. https://doi.org/10.1145/ 3292500.3330666 [20] Massimo Quadrana, Alexandros Karatzoglou, Bal\u00e1zs Hidasi, and Paolo Cremonesi. 2017. Personalizing Session-Based Recommendations with Hierarchical Recurrent Neural Networks. In Proceedings of the Eleventh ACM Conference on Recommender Systems (Como, Italy) (RecSys '17). Association for Computing Machinery, New York, NY, USA, 130-137. https://doi.org/10.1145/3109859. 3109896 [21] Steffen Rendle. 2010. Factorization Machines. In 2010 IEEE International Conference on Data Mining. 995-1000. https://doi.org/10.1109/ICDM.2010.127 [22] Steffen Rendle. 2012. Factorization Machines with LibFM. 3, 3, Article 57 (may 2012), 22 pages. https://doi.org/10.1145/2168752.2168771 Scaling User Modeling: Large-scale Online User Representations for Ads Personalization in Meta WWW'24 Companion, May 13-17, 2024, Singapore, Singapore Badr, Jongsoo Park, Jiyan Yang, Dheevatsa Mudigere, and Ellie Wen. 2022. DHEN: A Deep and Hierarchical Ensemble Network for Large-Scale Click-Through Rate Prediction. arXiv:2203.11014 [cs.IR] [37] Junqi Zhang, Bing Bai, Ye Lin, Jian Liang, Kun Bai, and Fei Wang. 2020. GeneralPurpose User Embeddings Based on Mobile App Usage. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (Virtual Event, CA, USA) (KDD '20). Association for Computing Machinery, New York, NY, USA, 2831-2840. https://doi.org/10.1145/3394486.3403334 [38] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Deep Interest Evolution Network for Click-through Rate Prediction. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence (Honolulu, Hawaii, USA) (AAAI'19/IAAI'19/EAAI'19). AAAI Press, Article 729, 8 pages. https://doi.org/10.1609/aaai.v33i01.33015941"}
