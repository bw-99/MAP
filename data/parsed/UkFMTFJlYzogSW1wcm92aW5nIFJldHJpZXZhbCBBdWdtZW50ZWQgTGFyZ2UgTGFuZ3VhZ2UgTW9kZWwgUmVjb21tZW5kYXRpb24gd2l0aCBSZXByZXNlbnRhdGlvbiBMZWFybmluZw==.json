{"RALLRec: Improving Retrieval Augmented Large Language Model Recommendation with Representation Learning": "Jian Xu \u2217 Tsinghua University Beijing, China xujian20@mails.tsinghua.edu.cn Sichun Luo City University of Hong Kong Hong Kong, China City University of Hong Kong Shenzhen Research Institute Shenzhen, China Dongguan University of Technology Dongguan, China sichun.luo@my.cityu.edu.hk", "\u2217": "Xiangyu Chen Tsinghua University Beijing, China xy-c21@mails.tsinghua.edu.cn Haoming Huang Alibaba Group Shenzhen, China huanghaoming.hhm@alibaba- inc.com", "ABSTRACT": "", "Hanxu Hou \u2020": "Dongguan University of Technology Dongguan, China houhanxu@163.com", "Linqi Song \u2020": "City University of Hong Kong Hong Kong, China City University of Hong Kong Shenzhen Research Institute Shenzhen, China linqi.song@cityu.edu.hk", "KEYWORDS": "Large Language Models (LLMs) have been integrated into recommendation systems to enhance user behavior comprehension. The Retrieval Augmented Generation (RAG) technique is further incorporated into these systems to retrieve more relevant items and improve system performance. However, existing RAG methods rely primarily on textual semantics and often fail to incorporate the most relevant items, limiting the effectiveness of the systems. In this paper, we propose R epresentation learning for retrievalA ugmented L arge L anguage model Rec ommendation ( RALLRec ). Specifically, we enhance textual semantics by prompting LLMs to generate more detailed item descriptions, followed by joint representation learning of textual and collaborative semantics, which are extracted by the LLM and recommendation models, respectively. Considering the potential time-varying characteristics of user interest, a simple yet effective reranking method is further introduced to capture the dynamics of user preference. We conducted extensive experiments on three real-world datasets, and the evaluation results validated the effectiveness of our method. Code is made public at https://github.com/JianXu95/RALLRec.", "CCS CONCEPTS": "", "\u00b7 Information systems \u2192 Recommender systems .": "* Equal Contribution \u2020 Corresponding Author This work is licensed under a Creative Commons Attribution 4.0 International License. WWWCompanion '25, April 28-May 2, 2025, Sydney, NSW, Australia \u00a9 2025 Copyright held by the owner/author(s). https://acm.org.10.1145/3701716.3715508 Retrieval-augmented generation, Large language model, Recommender system", "ACMReference Format:": "Jian Xu \u2217 , Sichun Luo \u2217 , Xiangyu Chen, Haoming Huang, Hanxu Hou \u2020 , and Linqi Song \u2020 . 2025. RALLRec: Improving Retrieval Augmented Large Language Model Recommendation with Representation Learning. In Companion Proceedings of the ACM Web Conference 2025 (WWW Companion '25), April 28-May 2, 2025, Sydney, NSW, Australia. ACM, New York, NY, USA, 5 pages. https://acm.org.10.1145/3701716.3715508", "1 INTRODUCTION": "Recently, large language models (LLMs) have demonstrated significant potential and have been integrated into recommendation tasks [8-10, 14]. One promising direction for LLM-based recommendations, referred to as LLMRec, involves directly prompting the LLM to perform recommendation tasks in a text-based format [1, 16]. However, simply using prompts with recent user history can be suboptimal, as they may contain irrelevant information that distracts the LLMs from the task at hand. To address this challenge, ReLLa [7] incorporates a retrieval augmentation technique, which retrieves the most relevant items and includes them in the prompt. This approach aims to improve the understanding of the user profile and improve the performance of recommendations. Furthermore, GPT-FedRec [15] proposes a hybrid Retrieval Augmented Generation mechanism to enhance privacy-preserving recommendations by using both an ID retriever and a text retriever. Despite the advancements, current methods have limitations. ReLLa relies primarily on text embeddings for retrieval, which is suboptimal as it overlooks collaborative semantic information from the item side in recommendations. The semantics learned from text are often inadequate as they typically only include titles and limited contextual information. GPT-FedRec does not incorporate user's . WWWCompanion '25, April 28-May 2, 2025, Sydney, NSW, Australia Jian Xu \u2217 , Sichun Luo \u2217 , Xiangyu Chen, Haoming Huang, Hanxu Hou \u2020 , and Linqi Song \u2020 Figure 1: RALLRec with embedding, retrieval and reranker. User Historical Most recent Retriever Behavior K Items Reranker ID Information Representation Most relevant Retriever Learning K Items Kltems Text Information Encoder Item Title Textual Semantic LLM Concat Encoder Item Item Description Lssl Joint Representation Encoder Collaborative Semantic User-Item Graph Iop recent interest, and the ID based retriever and text retrieval are in a separate manner, which may not yield the best results. The integration of text and collaborative information presents challenges as these modalities are not inherently aligned. In this work, we propose Representation Learning enhanced Retrieval-Augmented Large Language Models for Recommendation ( RALLRec ). Our objective is to enhance the performance of retrievalaugmented LLM recommendations through improved representation learning. Specifically, instead of solely relying on abbreviated item titles to extract item representations, we prompt the LLM to generate detailed descriptions for items utilizing its world knowledge. These generated descriptions are used to extract improved item representations. This representation is concatenated with the abbreviated item representation. Subsequently, we obtain collaborative semantics for items using a recommendation model. This collaborative semantic is aligned with textual semantics through self-supervised learning to produce the final representation. This enhanced representation is used to retrieve items, thereby improving Retrieval-Augmented Large Language Model recommendations. In a nutshell, our contribution is threefold. \u00b7 We propose RALLRec , which incorporates collaborative information and learns joint representations to retrieve more relevant items, thereby enhancing the retrieval-augmented large language model recommendation. \u00b7 We design a novel reranker that takes into account both the semantic similarity to the target item and the timestamps for boosting the validness of RAG. \u00b7 With extensive explorations of the training and prompting strategies, the experiments reveal several interesting findings and validate the effectiveness of our method.", "2 METHODOLOGY": "", "2.1 Framework Pipeline": "The pipeline of the developed framework is illustrated in Figure 1. The RALLRec encompasses both the retrieval and generation processes. In the retrieval process, we first learn a joint representation of users and items, allowing us to retrieve the most relevant items in semantic space. These items are then fused with the most recent items by a reranker and incorporated into the prompts. The constructed prompts can be used solely for inference or to train a more effective model through instruction tuning (IT). For the generation Here is movie. Its title is Pretty Woman. The movie's genre is comedy. Pretty Woman is a romantic comedy about a businessman and a spirited woman who unexpectedly fall in love Set in vibrant 990s Los Angeles; it explores themes of love; and self-discovery.  Directed by Garry Marshall, the film stars  Richard Gere and Julia Roberts, creating an iconic and culturally impactful story. class. Figure 2: Comparison of textual descriptions with fixed template (upper) and automatic generation (blow). phase, the base LLM responses to the prompt for inference. The base LLM could be standard or customized.", "2.2 Representation Learning": "To learn better item embeddings 1 for reliable retrieval, we propose to integrate both the text embedding from textual description and collaborative embedding from user-item interaction, as well as the joint representation through self-supervised training. 2.2.1 Textual Representation Learning. In previous work [7], only the fixed text template with basic information such as item title was utilized to extract textual information. However, we argue that relying solely on the fixed text format is inadequate, as it may not capture sufficient semantic depth, e.g., two distinct and irrelevant items may probably have similar names. To enhance this, we take advantage of the LLMs to generate a more comprehensive and detailed description containing the key attributes of the item (e.g., Figure 2), which can be denoted as  where \ud835\udc4f \ud835\udc56 is the basic information of the \ud835\udc56 -th item and the \ud835\udc5d is the template for prompting the LLMs. Subsequently, we derive textual embeddings by feeding the text into LLMs and taking the hidden representation as in [7], represented as  Since the plain embedding of item title \ud835\udc52 \ud835\udc56 title could also be useful, we aim to directly concatenate these two kinds of embeddings to obtain the final textual representations, denoted by  It is worth noting that those textual embeddings are reusable after being extracted and they already contain affinity information attributed to the rich knowledge of LLMs. 2.2.2 Collaborative Representation Learning. A notable shortcoming of previous LLM-based approaches is their failure to incorporate collaborative information, which is directed learned from the useritem interaction records and thus can be complementary to the text embeddings. To this end, we utilize conventional recommendation models to extract collaborative semantics, denoted as  where \ud835\udc5b is the total number of items and V is the interaction history. 1 We interchangeably use the representation and embedding to denote the extracted item feature considering the habits in deep learning and information retrieval domains. RALLRec WWWCompanion '25, April 28-May 2, 2025, Sydney, NSW, Australia Table 1: The performance of different models in default settings. The best results are highlighted in boldface. The symbol \u2217 indicates statistically significant improvement of RALLRec over the best baseline with \ud835\udc5d -value < 0.01. 2.2.3 Joint Representation Learning. A straightforward approach for integrating above two representations is to directly concatenate the textual and collaborative representations. However, since these representations may not be on the same dimension and scale, this might not be the best choice. Inspired by the success of contrastive learning in aligning different views in recommendations [18], we employ a self-supervised learning technique to effectively align the textual and collaborative representations. Specifically, we adopt a simple two-layer MLP as the projector for mapping the original text embedding space into a lower feature space and use the following self-supervised training objective  where \ud835\udc53 GLYPH<16> e \ud835\udc56 text , e \ud835\udc63 colla GLYPH<17> = \ud835\udc52\ud835\udc65\ud835\udc5d ( \ud835\udc60\ud835\udc56\ud835\udc5a ( MLP ( e \ud835\udc56 text ) , e \ud835\udc63 colla )) and \ud835\udc60\ud835\udc56\ud835\udc5a (\u00b7) is the cosine similarity function. After the joint representation learning, we can get the aligned embedding for each item \ud835\udc56 as  2.2.4 Embedding Mixture. Instead of retrieval using different embeddings separately, we find that integrating those embeddings before retrieval can present better performance, therefore we directly concat them after magnitude normalization  where \u00af e : = e /\u2225 e \u2225 . With the final item embeddings, we can retrieve the most relevant items to the target item by simply comparing the dot-production for downstream recommendation tasks.", "2.3 Prompt Construction": "To form a prompt message that LLMs can understand, we use a similar template as in [7] by filling the user profile, listing the relevant behavior history and instructing the model to give a prediction. We also observed that the pre-trained base LLMs may perform poorly in instruction following. Therefore, we collect a small amount of training data for instruction tuning, where the prompts are constructed with similarity-based retrieval and a data augmentation technique is also employed by re-arranging the retrieved sequence according to the timestamp to reduce the impact of item order. Table 2: The dataset statistics.", "2.4 Reranker": "Since we can retrieve the most recent \ud835\udc3e items as well as the most relevant \ud835\udc3e items, relying solely on one of them may not be the optimal choice. During the inference stage, we further innovatively design a reranker to merge these two different channels. The reranker can be either learning-based or rule-based; in this case, we utilize a heuristic rule-based reranker. For each item, we assign a channel score S \ud835\udc50 and a position score S \ud835\udc5d\ud835\udc5c\ud835\udc60 . We assign the channel score as \ud835\udefc and ( 1 -\ud835\udefc ) for embedding-based and time-based channel, respectively. The position score is inversely proportional to the position in the original sequence, i.e., { 1 , 1 2 \ud835\udefd , ..., 1 \ud835\udc3e \ud835\udefd } . The hyper-parameters \ud835\udefc and \ud835\udefd are tunable. The total score for each item is calculated as the production of these two scores  By taking the items with top\ud835\udc3e scores, we can obtain a refined retrieval result to maximize the prediction performance.", "3 EXPERIMENT": "", "3.1 Dataset": "In this paper, we focus on the click-through rate (CTR) prediction [7]. We utilize three widely used public datasets: BookCrossing [17], MovieLens [4], and Amazon [11]. For the MovieLens dataset, we select the MovieLens-1M subset, and for the Amazon dataset, we focus on the Movies & TV subset. We apply the 5-core strategy to filter out long-tailed users/items with less than 5 records. Some statistics are shown in Table 2. Similar to ReLLa [7], we collect the user history sequence before the latest item and the ratings to construct the prompting message and ground-truth.", "3.2 Baseline": "We compare our approach with baseline methods, which include both ID-based and LLM-based recommendation systems. For IDbased methods, we select DeepFM [3], xDeepFM [6], DCN [13], and WWWCompanion '25, April 28-May 2, 2025, Sydney, NSW, Australia Jian Xu \u2217 , Sichun Luo \u2217 , Xiangyu Chen, Haoming Huang, Hanxu Hou \u2020 , and Linqi Song \u2020 Table 3: The performance of different variants of RALLRec . We remove different components of RALLRec to evaluate the contribution of each part to the model. The best results are highlighted in boldface. Figure 3: The impact of history sequence length K on AUC. 0.70 0.72 0.74 0.76 0.78 AUC MovieLens 5 10 15 20 25 30 Length of User Behavior Sequence K 0.56 0.58 AUC 0.820 0.825 0.830 0.835 0.840 0.845 0.850 Amazon 5 10 15 20 25 30 Length of User Behavior Sequence K 0.700 0.725 RALLRec ReLLa Zero-shot AutoInt [12] as our baseline models. We utilize Llama3.1-8B-Instruct [2] as the base model and LightGCN [5] to learn collaborative embeddings in our comparisons. For LLM-based methods, we consider ReLLa [7] and a Hybrid-Score based retrieval as in [15]. By default, we apply the LoRA method and 8-bit quantization to conduct instruction-tuning as in [7] and the maximum length of history is \ud835\udc3e = 30. For the reranker in our method, we search the \ud835\udefc over { 1 2 , 2 3 , 4 5 } and fix \ud835\udefd = 1 in the experiments.", "3.3 Result Analysis": "Sequential Behavior Comprehension. From the numerical results presented in Table 1, several noteworthy observations emerge. Firstly, the vanilla ID-based methods generally underperform LLMbased methods, demonstrating that LLMs can better leverage textual and historical information for preference understanding. Secondly, among LLM-based baselines, ReLLa effectively incorporates a retrieval-augmented approach but relies predominantly on simple textual semantics for item retrieval. Hybrid-Score, which considers both ID-based and textual features, also improves over the zero-shot LLM setting (Llama3.1). However, both ReLLa and Hybrid-Score still fail to fully leverage the rich collaborative semantics and the alignment between textual and collaborative embeddings. In contrast, RALLRec consistently achieves the best results across all three datasets, outperforming both ID-based and LLM-based baselines. The improvements are statistically significant with \ud835\udc5d -values less than 0.01, emphasizing the robustness of our approach. Impact of sequence length K. We change the history length \ud835\udc3e during the inference stage and collect the final performance in Figure 3. It can be found that as \ud835\udc3e increases, both RALLRec and ReLLa benefit from longer historical sequences to gain richer insights into user preferences, while the zero-shot LLM baseline suffers from noise and thus does not improve. This phenomenon Figure 4: Comparison of fine-tuning and inference settings. Recent Retri.-then-Mix Mix-then-Retri. ReRank Inference-time Retrieval 0.74 0.75 0.76 0.77 0.78 0.79 AUC AUC Comparison Recent Behavior RAG-enhanced Recent Retri.-then-Mix Mix-then-Retri. ReRank Inference-time Retrieval 0.660 0.665 0.670 0.675 0.680 0.685 0.690 0.695 0.700 ACC ACC Comparison Recent Behavior RAG-enhanced underscores the importance of carefully selecting and structuring historical user behaviors to assist LLMs in recommendation.", "3.4 Ablation Studies": "3.4.1 Fine-tuning and Data Construction. Weexaminetheinfluence of instruction tuning (IT) and data augmentation in Table 3. Removing IT significantly degrades performance, reverting the model to near zero-shot levels, as it struggles to follow the given instructions and task format. Similarly, removing the data augmentation strategy leads to a non-negligible performance drop. This confirms the importance of carefully crafted training data and instruction tuning for aligning the LLM with recommendation objectives. 3.4.2 Reranking and Retrieval Methods. Figure 4 compares different retrieval and prompt construction approaches on the MovieLens. Our reranker, which balances semantic relevance and temporal recency, outperforms both plain recent-history-based prompts and simple hybrid retrieval strategies. These results emphasize the necessity of refining retrieved items through post-processing rather than relying solely on a single retrieval strategy. 3.4.3 Embedding Strategies. In Table 4, we contrast various embedding schemes for retrieval. Text-based embeddings provide a decent performance, but they are weaker than the mixture with IDbased embeddings. By aligning textual and collaborative semantics through SSL, we achieve further improvements. Overall, the ablation studies confirm that (i) instruction tuning and data augmentation are essential for aligning the LLM to recommendation tasks, (ii) embedding alignment of textual and collaborative semantics consistently improves retrieval quality, and (iii) a reranking strategy that considers both item relevance and temporal factors enhances the final recommendation performance. Combining these insights, RALLRec presents a robust and effective framework for retrieval-augmented LLM-based recommendation. RALLRec WWWCompanion '25, April 28-May 2, 2025, Sydney, NSW, Australia Table 4: The comparison of different embeddings used for historic behavior retrieval during inference. For fair comparisons, the model is instruction-tuned using the RAG-enhanced training data, while the inference prompt is constructed based on the embedding similarity without re-ranking. The best results are highlighted in boldface.", "4 CONCLUSION": "In this paper, we introduce a new representation learning frameworkofitem embeddings for LLM-based Recommendation ( RALLRec ), which improves item description generation and enables joint representation learning of textual and collaborative semantics. Experiments on three datasets demonstrate its capability to retrieve relevant items and improve overall performance.", "ACKNOWLEDGMENTS": "This work was supported in part by the National Natural Science Foundation of China under Grant 62371411, the Research Grants Council of the Hong Kong SAR under Grant GRF 11217823, the Collaborative Research Fund C1042-23GF, and InnoHK initiative, the Government of the HKSAR, Laboratory for AI-Powered Financial Technologies.", "REFERENCES": "[1] Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023. Tallrec: An effective and efficient tuning framework to align large language model with recommendation. In Proceedings of the 17th ACM Conference on Recommender Systems . 1007-1014. [2] Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783 (2024). [3] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. In Proceedings of the 26th International Joint Conference on Artificial Intelligence . 1725-1731. [4] F Maxwell Harper and Joseph A Konstan. 2015. The movielens datasets: History and context. Acm transactions on interactive intelligent systems 5, 4 (2015), 1-19. [5] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, YongDong Zhang, and Meng Wang. 2020. LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval . 639-648. [6] Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018. xdeepfm: Combining explicit and implicit feature interactions for recommender systems. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1754-1763. [7] Jianghao Lin, Rong Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, Shigang Quan, Ruiming Tang, Yong Yu, and Weinan Zhang. 2024. Rella: Retrieval-enhanced large language models for lifelong sequential behavior comprehension in recommendation. In Proceedings of the ACM on Web Conference 2024 . 3497-3508. [8] Sichun Luo, Bowei He, Haohan Zhao, Wei Shao, Yanlin Qi, Yinya Huang, Aojun Zhou, Yuxuan Yao, Zongpeng Li, Yuanzhang Xiao, et al. 2024. Recranker: Instruction tuning large language model as ranker for top-k recommendation. ACM Transactions on Information Systems (2024). [9] Sichun Luo, Jiansheng Wang, Aojun Zhou, Li Ma, and Linqi Song. 2024. Large Language Models Augmented Rating Prediction in Recommender System. In ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) . IEEE, 7960-7964. [10] Sichun Luo, Yuxuan Yao, Bowei He, Yinya Huang, Aojun Zhou, Xinyi Zhang, Yuanzhang Xiao, Mingjie Zhan, and Linqi Song. 2024. Integrating large language models into recommendation via mutual augmentation and adaptive aggregation. arXiv preprint arXiv:2401.13870 (2024). [11] Jianmo Ni, Jiacheng Li, and Julian McAuley. 2019. Justifying recommendations using distantly-labeled reviews and fine-grained aspects. In Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP) . 188-197. [12] Weiping Song, Chence Shi, Zhiping Xiao, Zhijian Duan, Yewen Xu, Ming Zhang, and Jian Tang. 2019. Autoint: Automatic feature interaction learning via selfattentive neural networks. In Proceedings of the 28th ACM international conference on information and knowledge management . 1161-1170. [13] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep & cross network for ad click predictions. In Proceedings of the ADKDD'17 . 1-7. [14] Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu, Tingjia Shen, Chuan Qin, Chen Zhu, Hengshu Zhu, Qi Liu, et al. 2024. A survey on large language models for recommendation. World Wide Web 27, 5 (2024), 60. [15] Huimin Zeng, Zhenrui Yue, Qian Jiang, and Dong Wang. 2024. Federated recommendation via hybrid retrieval augmented generation. arXiv preprint arXiv:2403.04256 (2024). [16] Jizhi Zhang, Keqin Bao, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023. Is chatgpt fair for recommendation? evaluating fairness in large language model recommendation. In Proceedings of the 17th ACM Conference on Recommender Systems . 993-999. [17] Cai-Nicolas Ziegler, Sean M McNee, Joseph A Konstan, and Georg Lausen. 2005. Improving recommendation lists through topic diversification. In Proceedings of the 14th international conference on World Wide Web . 22-32. [18] Ding Zou, Wei Wei, Xian-Ling Mao, Ziyang Wang, Minghui Qiu, Feida Zhu, and Xin Cao. 2022. Multi-level cross-view contrastive learning for knowledgeaware recommender system. In Proceedings of the 45th international ACM SIGIR conference on research and development in information retrieval . 1358-1368."}
