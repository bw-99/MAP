{"LLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation": "Yuhao Wang City University of Hong Kong Hong Kong, China yhwang25-c@my.cityu.edu.hk Yichao Wang Huawei Noah's Ark Lab Shenzhen, China wangyichao5@huawei.com Xiangyang Li Huawei Noah's Ark Lab Shenzhen, China lixiangyang34@huawei.com Xiangyu Zhao City University of Hong Kong Hong Kong, China xianzhao@cityu.edu.hk", "Zichuan Fu": "City University of Hong Kong Hong Kong, China zichuanfu2-c@my.cityu.edu.hk Huifeng Guo Huawei Noah's Ark Lab Shenzhen, China huifeng.guo@huawei.com Ruiming Tang Huawei Noah's Ark Lab Shenzhen, China tangruiming@huawei.com", "ABSTRACT": "As the demand for more personalized recommendation grows and a dramatic boom in commercial scenarios arises, the study on multiscenario recommendation (MSR) has attracted much attention, which uses the data from all scenarios to simultaneously improve their recommendation performance. However, existing methods tend to integrate insufficient scenario knowledge and neglect learning personalized cross-scenario preferences, thus leading to suboptimal performance and inadequate interpretability. Meanwhile, though large language model (LLM) has shown great capability of reasoning and capturing semantic information, the high inference latency and high computation cost of tuning hinder its implementation in industrial recommender systems. To fill these gaps, we propose an effective efficient interpretable LLM-enhanced paradigm LLM4MSR in this work. Specifically, we first leverage LLM to uncover multi-level knowledge including scenario correlations and users' cross-scenario interests from the designed scenario- and userlevel prompt without fine-tuning the LLM, then adopt hierarchical meta networks to generate multi-level meta layers to explicitly improves the scenario-aware and personalized recommendation capability. Our experiments on KuaiSAR-small, KuaiSAR, and Amazon datasets validate two significant advantages of LLM4MSR: (i) the effectiveness and compatibility with different multi-scenario backbone models (achieving 1.5%, 1%, and 40% AUC improvement Conference'17, July 2017, Washington, DC, USA on three datasets), (ii) high efficiency and deployability on industrial recommender systems, and (iii) improved interpretability. The implemented code and data is available to ease reproduction 1 .", "CCS CONCEPTS": "\u00b7 Information systems \u2192 Recommender systems .", "KEYWORDS": "Large Language Model, Multi-Domain, Multi-Scenario Recommendation, Click-Through Rate Prediction", "ACMReference Format:": "Yuhao Wang, Yichao Wang, Zichuan Fu, Xiangyang Li, Xiangyu Zhao, Huifeng Guo, and Ruiming Tang. 2024. LLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation. In Proceedings of ACM Conference (Conference'17). ACM, New York, NY, USA, 11 pages. https: //doi.org/XXXXXXX.XXXXXXX", "1 INTRODUCTION": "The research on recommender system (RS) has been a hot spot in the past few years which targets at mining users' interests from the vast amount of historical interaction data. In order to provide services in a more personalized manner and make profits, an explosive growth of business scenarios (also known as domains) are emerging in commercial RSs such as the search and recommendation services on mobile apps [13, 23] and different product categories on the e-commerce platform [20]. Therefore, as a group of efficient joint modeling approach, multi-scenario recommendation (MSR) has drawn attention increasingly, which exploits all data to improve the recommendation accuracy on all these scenarios, thus addressing the data sparsity issue [38] and reducing computation cost. Nevertheless, existing MSR methods usually suffer from the following two limitations: (i) Insufficient scenario knowledge is incorporated. Specifically, domain indicator is usually the only scenario knowledge leveraged to capture the domain distinction in practice [3, 21], while the abundant semantic information such as the description of scenario is neglected. Consequently, the correlations among scenarios are not adequately established. (ii) Users' personalized preferences across scenarios tend to be ignored, since most MSR models merely rely on different parameter sharing patterns in multi-task learning [21, 28] and the collaborative signal learned in conventional RSs to conduct recommendation. However, these deficiencies are still overlooked even if they would lead to the sub-optimal performance of multi-scenario recommender system. To tackle these drawbacks of conventional MSR models, we resort to large language model (LLM) which is known for its remarkable capability of language understanding and reasoning [10]. Although there have been some attempts to enhance RSs harnessing LLM [13, 16, 33], there are some key challenges. The first is high inference latency of LLM since the existing methods conduct training and inference with LLM through sample level alignment [16, 25]. Second, the information generated from LLM is usually in natural language format. In other words, it requires filling the gap between semantic and recommendation space like employing additional knowledge encoder [31] and instruction tuning on LLM [33] which brings high computation cost. Moreover, both conventional RS and LLM-based recommendation methods lack interpretability. To this end, we propose an LLM-based paradigm to enhance conventional multi-scenario recommendation, which leverages LLM and hierarchical meta networks to explicitly improve the performance of the backbone model on all scenarios. To be specific, on the one hand, LLM helps grasping the cross-scenario correlation and personalized preferences, while the meta networks act as a flexible and adaptive bridge connecting the semantic space in LLM and the recommendation space in the multi-scenario backbone model. On the other hand, to tackle the efficiency of LLM (see Section 3.4), a frozen LLM is used without tuning and high level of user- & scenario knowledge is reasoned about through prompt design. The main contributions of this paper are summarized as follows: \u00b7 Weproposeaneffective efficient interpretable paradigm LLM4MSR for multi-scenario recommendation enhancement by exploiting LLM. To the best of our knowledge, it is the first practical solution to reasoning about multi-scenario knowledge through LLM and bring information gain in recommender systems. \u00b7 The scenario commonality and heterogeneity, and users' crossscenario preferences are explicitly captured by LLM through the designed scenario- and user-level prompt. Furthermore, they are leveraged by the hierarchical meta networks which generate meta layers to explicitly enhance the scenario-aware and personalized recommendation capability of multi-scenario backbones. \u00b7 Extensive experiments on three real-world datasets show that LLM4MSR is an effective paradigm compared with state-of-theart multi-scenario enhancement methods and compatible with various MSR backbone models. Besides, it is efficient to deploy on industrial recommender systems and enables real-time recommendation without fine-tuning LLM .", "2 PRELIMINARY": "This section first introduces the problem formulation of multiscenario CTR prediction and the typical architecture of multi-scenario backbone models. Then, large language model is illustrated. Domain 1 Tower Domain 2 Tower Embedding Layer domain ID user profile item feature", "2.1 Multi-Scenario CTR Prediction": "The Click-Trough Rate (CTR) prediction task is essential in recommendation which is a binary classification problem. Specifically, in a multi-scenario recommender system, the historical interaction sample ( \ud835\udc51, \ud835\udc99 ) is taken as input to predict the ground truth label \ud835\udc66 where \ud835\udc66 = 1 and \ud835\udc66 = 0 denote click and unclick, respectively. \ud835\udc51 represents the domain indicator \ud835\udc51 \u2208 { 1 , 2 , . . . , \ud835\udc37 } indicating the origin of sample. \ud835\udc99 denotes the feature fields including user and item attributes. For simplicity, suppose there are \ud835\udc40 categorical features, then \ud835\udc99 = [ \ud835\udc99 1 , . . . , \ud835\udc99 \ud835\udc5a , . . . , \ud835\udc99 \ud835\udc40 ] where \ud835\udc99 \ud835\udc5a indicates the one-hot encoding of the \ud835\udc5a -th feature. Next, \ud835\udc99 is mapped into a dense vector \ud835\udc86 = [ \ud835\udc86 1 \u2225 . . . \u2225 \ud835\udc86 \ud835\udc5a \u2225 . . . \u2225 \ud835\udc86 \ud835\udc40 ] through an embedding layer where \u2225 denotes the concatenation operation. For the \ud835\udc5a -th feature, we calculate \ud835\udc86 \ud835\udc5a through a look-up operation \ud835\udc86 \ud835\udc5a = \ud835\udc6c \ud835\udc5a \u00b7 \ud835\udc99 \ud835\udc5a in which \ud835\udc6c \ud835\udc5a \u2208 R \ud835\udc62 \ud835\udc5a \u00d7 \ud835\udc37\ud835\udc56\ud835\udc5a denotes the embedding table, \ud835\udc62 \ud835\udc5a denotes the value counts of feature, and \ud835\udc37\ud835\udc56\ud835\udc5a is the embedding size. Finally, the prediction result \u02c6 \ud835\udc66 is obtained via \u02c6 \ud835\udc66 = \ud835\udc53 \ud835\udc51 ( \ud835\udc86 ) where \ud835\udc53 \ud835\udc51 represents the recommendation model applied to the \ud835\udc51 -th scenario. The loss function is binary cross entropy loss or the so-called Logloss [1]: where \u0398 is the set of parameters learned, \ud835\udc35 represents the number of batch samples, and \ud835\udc66 \ud835\udc56 and \u02c6 \ud835\udc66 \ud835\udc56 denote the true label and prediction of the \ud835\udc56 -th sample, respectively.", "2.2 Multi-Scenario Backbone Models": "In the recommendation community, multi-task learning (MTL) technique is first developed targeting at leveraging a unified framework to learn the inter-related tasks like click and conversion, which would lead to mutual enhancement among tasks and higher efficiency [28]. Specifically, a mainstream solution is to design various parameter sharing mechanisms with shared and specific parameters in multi-task modeling. Afterward, most multi-scenario recommendation models adopt a similar approach when modeling scenario correlations by simply regarding scenarios as tasks. They model the commonality and distinction among scenarios through explicitly maintaining domain-shared parameters \u0398 \ud835\udc60 and domain-specific parameters \u0398 \ud835\udc62 . As depicted in Figure 1, the feature embedding is first fed into the shared parameters like the experts in MMoE [19] and the centered network in STAR [21] to extract common knowledge. Then the scenario-specific parameters like gates [24] and towers are employed to generate the prediction result. Scenario Statistics & Description On the Kuaishou app, which is a short-video platform, suppose there is a search scenario with 3038362 interactions and a recommendation scenario with 7493101 interactions. In these two scenarios there are 25877 users and 4157218 items containing normal videos, advertisement, and unknown videos , where 97981 items are overlapped. From the relationship between search and recommendation and statistics given, explicitly summarize the scenario commonality and distinction of recommendation scenario. Scenario-level Prompt On a short-video platform, suppose there is a search scenario and a recommendation scenario. In the search scenario, user_{id} {behavior + item_type + category}. Besides, in the recommendation scenario, this user {behavior + item_type + category}. For this user, considering the interaction behavior frequency and item category information, if there is no interaction in search or recommendation scenario, only summarize the interest in the other scenario. Otherwise, explicitly summarize the common interest among the two scenarios first, then summarize the distinct interest across two scenarios. User-level Prompt Interaction Data Scenario Correlation form 1. hidden states form 2. text form 2. text form 1. hidden states Cross-Scenario Interest Embeddings (a) Multi-Scenario Knowledge Reasoning (b) Multi-Level Knowledge Fusion Features Frozen Updated Meta Network MSR Backbone Meta Network parallel bottom Scenario-level Meta Layers User-level Meta Layers LLM Reshape Reshape interpretable", "2.3 Large Language Model": "", "3 PROPOSED METHOD": "Unlike Pre-trained Language Models (PLMs) like BERT trained with masked language modeling task, most popular Large Language Models like GPT [2] and ChatGLM2 [9] adopt the decoder-only architecture and they are trained with next token prediction objective in a self-supervised manner, i.e., a sequence of text is taken as input to predict the next token for each token in the sequence: where \ud835\udc96 is the input text with \ud835\udc41 tokens and \ud835\udf03 is the parameters of LLM. The probability distribution of future tokens conditioned on the previous ones are maximized, which is equivalent to minimizing the negative log-likelihood above. Meanwhile, it adopts masked self-attention or the so-called causal self-attention preventing accessing future tokens, which enables to understand the text data and generate proper results. Specifically, a query (Q), a key (K), and a value (V) vector are obtained multiplying the input token vector \ud835\udc7f by weight matrices \ud835\udc7e \ud835\udc44 , \ud835\udc7e \ud835\udc3e , and \ud835\udc7e \ud835\udc49 . Then a score is calculated multiplying the current query vector and key vector, which is further multiplied by the value vector and summed up: \uf8f0 \uf8fb where \ud835\udc74 is the mask matrix. In practice, the raw text sequence is passed through the tokenizer to obtain tokens, which are embeded and passed into the decoder-only transformer with several feed-forward and masked self-attention blocks. Then the hidden vectors with the maximum probability are produced and decoded to generate the results in an auto-regressive fashion. We first illustrate the overall framework of the proposed LLM4MSR paradigm. Next, it is further detailed in the multi-scenario knowledge reasoning and multi-level knowledge fusion step. Finally, we discuss the idea and characteristics of LLM4MSR compared with the existing multi-scenario and LLM-based recommendation methods, and illustrate the necessity of LLMs versus PLMs.", "3.1 Overall Framework": "To tackle the limitations of the existing MSR methods, i.e., insufficient scenario knowledge incorporation and ignoring personalized cross-scenario interest, we propose a paradigm LLM4MSR for multi-scenario enhancement which is compatible with different multi-scenario backbone models. Specifically, it is equipped with an LLM with frozen parameters and two learnable meta networks. Meanwhile, the general procedure of LLM4MSR is summarized in Algorithm 1. It is comprised of two steps: (i) multi-scenario knowledge reasoning (from Line 1 to 10) including scenario correlation and cross-scenario interests inference, and (ii) multi-level knowledge fusion (from Line 11 to 15) to adaptively fuse with backbone. The illustration of LLM4MSR is depicted in Figure 2. Specifically, the scenario-level prompt is generated from the scenario statistics, semantic descriptions, and expert knowledge while the user-level prompt is constructed using historical interactions. Afterward, they are fed into LLM to generate scenario correlation and personalized cross-scenario interest respectively. Notably, only the last hidden state of LLM output (i.e., the hidden state of the last token generated) is chosen as representative and stored which is a high-dimensional dense vector, i.e., in 4096 dimensions taking ChatGLM2-6B [9] as an example. It is common because the generation of the last token is based on all previous ones and contains", "LLM4MSR paradigm taking multi-scenario": "Algorithm 1: CTR prediction as an example Input: Domain ID \ud835\udc51 \u2208 { 1 , 2 , . . . , \ud835\udc37 } ; set of user Output: \ud835\udc62 \u2208 { 1 , 2 , . . . , \ud835\udc48 } ; features \ud835\udc99 ; true label \ud835\udc66 ; a pre-trained large language model (LLM) A well trained model for all scenarios Step 1: Multi-scenario Knowledge Reasoning 1 for \ud835\udc51 \u2208 { 1 , 2 , . . . , \ud835\udc37 } do 2 Generate scenario-level prompt; 3 Feed into LLM; 4 Obtain the last hidden state of scenario-level output; 5 end 6 for \ud835\udc62 \u2208 { 1 , 2 , . . . , \ud835\udc48 } do 7 Generate user-level prompt; 8 Feed into LLM; 9 Obtain the last hidden state of user-level output;", "10 end": "Step 2: Multi-level Knowledge Fusion", "11 while not converge do": "12 Sample a mini-batch data from all scenarios; 13 Calculate the corresponding scenario- and user-level meta layers via Equation (5) and (6); 14 Calculate the prediction result via Equation (9); 15 Calculate the loss via Equation (1); 16 Take the gradient and update parameters; 17 end overall information. Finally, the hierarchical meta networks produce meta layers in scenario- and user-level, and they are trained with the MSR backbone model to enhance its all-scenario performance. Overall, the final enhanced model can be obtained in a simple yet efficient end-to-end training manner by optimizing Equation (1).", "3.2 Multi-Scenario Knowledge Reasoning": "On the one hand, it is difficult for the mainstream MSR models to grasp the complex scenarios correlations because in practice the domain indicator distinguishing data origin is usually the only scenario-related knowledge [3, 11, 21], thus their scenario representation is only learned from the implicit collaborative signals. Therefore, we design a scenario-level prompt to explicitly capture the commonality and distinction of scenarios from their statistics and semantic descriptions. For example, as shown in the purple box in Figure 2, the statistics like the number of interactions, users, items, and overlaps on KuaiSAR-small together with the background semantic information are given to uncover both similarity and heterogeneity of the recommendation and search scenario. On the other hand, existing MSR models tend to neglect modeling personalized interest and it is challenging to capture user's cross-scenario preferences in a disentangled manner. To this end, we design a user-level prompt to explicitly explore personalized common and distinct interests among all the scenarios from the abundant historical interaction. Intuitively, positive interaction behavior tend to better reflect user's interest than negative behavior. Meanwhile, the proportion of negative samples is usually large and they contain much noise information due to the biases and uncertainty in data collection and user interaction. Consequently, the positive interaction data (i.e., samples with positive interaction behavior such as click, forward, and like) are filtered and leveraged in the user-level prompt. As shown in the blue box in Figure 2(a), LLM helps explicitly capturing user's preferences in the search and recommendation scenario considering both the interaction frequency and the semantic relationships, e.g., in the category and title of item. The specific prompt template are provided in Appendix B. After obtaining the scenario- and user-level prompt, they are passed into LLM to reason about the multi-scenario knowledge. Moreover, we conduct a case study in Section 4.6 to investigate what multi-scenario knowledge can LLM obtain and how it contributes to enhancing the MSR backbone model.", "3.3 Multi-Level Knowledge Fusion": "Existing methods either choose to directly leverage the augmented information from LLM as additional input features in the RS [31], adopt a linear projection or a fully connected network to conduct dimension transformation and align instance representation [16], or fine-tune the LLM [37]. However, we argue that these are suboptimal solutions [22]. First, since the LLM-augmented information is treated as a common feature by recommender system, it is unable to play a significant role as expected because the number of feature fields is usually large [36]. Second, simply aligning the dimension would result in loss of information [34]. Third, tuning LLM brings high cost [4, 5] and it requires consistent update. Therefore, after obtaining the informative multi-scenario knowledge which is in the form of high-dimensional hidden vectors from LLM, our proposed LLM4MSR adopts a new and efficient approach leveraging hierarchical meta networks to bring information gain. To be specific, the meta networks dynamically generate meta layers to adaptively fuse the scenario- and user-level knowledge with the collaborative information in the MSR backbone model. Intuitively, on the one hand, the scenario-level knowledge usually plays a more general role like the domain distinction captured by auxiliary network in STAR [21]. On the other hand, the user-level information tends to be more personalized and significant [3] because it breaks the boundary of scenarios and contains a complete user profile across all scenarios. Consequently, we propose a hierarchical 'bottom + parallel' structure, in which the user-level meta layers are placed at the bottom while the scenario-level meta layers are implemented in parallel to the MSR backbone, as shown in Figure 2(b). Notably, They target at improving scenario-aware recommendation and cross-scenario personalization capability respectively, thus contributing to knowledge fusion and enhancement in different levels and granularity. We will empirically investigate this architecture of LLM4MSR through experiments in Section 4.3 where we also observe that user-level meta layers at bottom and scenario-level meta layers in parallel is the optimal combination. Specifically, denote the last hidden state of LLM output as \ud835\udc89 \ud835\udc3f\ud835\udc3f\ud835\udc40 , the meta work takes it as input and outputs \ud835\udc89 \ud835\udc5a\ud835\udc64 \u2208 R \ud835\udc37\ud835\udc56\ud835\udc5a \ud835\udc5a\ud835\udc64 and \ud835\udc89 \ud835\udc5a\ud835\udc4f \u2208 R \ud835\udc37\ud835\udc56\ud835\udc5a \ud835\udc5a\ud835\udc4f , then a reshape operation is employed to obtain \ud835\udc3e meta layers in total: LLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation where \ud835\udc7e ( \ud835\udc56 ) \ud835\udc59 and \ud835\udc83 ( \ud835\udc56 ) \ud835\udc59 indicate the weight and bias matrix of the \ud835\udc56 -th meta layer. Notably, \ud835\udc37\ud835\udc56\ud835\udc5a \ud835\udc5a\ud835\udc64 and \ud835\udc37\ud835\udc56\ud835\udc5a \ud835\udc5a\ud835\udc4f equals to the sum of dimensions of all \ud835\udc7e ( \ud835\udc56 ) \ud835\udc59 and \ud835\udc83 ( \ud835\udc56 ) \ud835\udc59 , respectively. For example, \ud835\udc89 \ud835\udc5a\ud835\udc64 with the dimension of 8256 can be reshaped into a weight matrix with dimension 128 \u00d7 64 plus a weight matrix with dimension 64 \u00d7 1 (bias matrix is similar). Then each meta layer is followed by an activation function \ud835\udf0e like ReLU: where \ud835\udc89 ( \ud835\udc56 ) is the output of the \ud835\udc56 -th meta layer. Afterward, the feature embedding \ud835\udc86 , which is exactly \ud835\udc89 ( 0 ) , is transferred into the obtained meta layers. Finally, the prediction result is calculated by combining the output of the parallel scenario-level meta layers and the result from MSR backbone in an adaptive manner: where \ud835\udc89 is the output hidden vector of the MSR backbone model, \ud835\udc89 ( \ud835\udc3e ) \ud835\udc62 is the output of the \ud835\udc3e -th user-level meta layer, \ud835\udc89 ( \ud835\udc3e ) \ud835\udc60 is the output of the \ud835\udc3e -th scenario-level meta layer, \ud835\udf0e \u2032 is the activation function for the final task (e.g., sigmoid function for CTR prediction task), and \ud835\udefc is a learnable parameter.", "3.4 Discussion": "In the following part, we first illustrate the idea of the proposed LLM4MSR paradigm, then compare it with the mainstream multiscenario RSs and the LLM-based recommendation methods, and finally demonstrate the necessity of LLM here compared with PLM. Basically, rather than designing a specific multi-scenario recommendation model architecture, our goal is to propose a general multi-scenario enhancement paradigm. Specifically, considering the model architecture and optimization, LLM4MSR does not impose any restrictions on the multi-scenario backbone models, thus being model-agnostic. Meanwhile, for LLM the most two significant questions are: (i) WHAT information can be obtained from LLM and (ii) HOW to use it to bring information gain, which correspond to the multi-scenario knowledge reasoning and multi-level knowledge fusion steps proposed in our LLM4MSR. LLM4MSRv.s.multi-scenarioRS. Conventional multi-scenario RSs treat the domain indicator either as a distinct feature [21] or as the only scenario knowledge to generate scenario-specific module [11], and adopt different parameter sharing patterns to model scenario correlations where only the collaborative signal is learned. By contrast, LLM4MSR generates LLM-enhanced scenario- and userlevel representation from the semantic space, then it dynamically generates meta layers to effectively and efficiently combine with the multi-scenario RS based on these representations. Consequently, the LLM-augmented information is flexibly fused with the collaborative signal in conventional RS, thus achieving enhancement. LLM4MSR v.s. LLM-based RS. Existing LLM-based recommender systems can be categorized into two groups, i.e., using LLM as the knowledge enhancer [13, 16, 17, 25] and directly as the recommender [8, 12, 18]. However, the former models possess low efficiency since they require aligning the information from LLM and RS in the instance level. Meanwhile, the latter methods lack scenario knowledge, thus achieving unsatisfying recommendation performance and suffering from high inference latency of LLM. By contrast, LLM4MSR can efficiently and effectively tackle these problems. First, thanks to the zero-shot capability [26], an LLM with fixed parameters is leveraged free from tuning in [16, 25, 33]. Meanwhile, the way of obtaining information from LLM is shifted from the low 'instance-level' (e.g., in [16, 25, 37]) to the high 'user& scenario-level' , thus improving efficiency. Besides, through hierarchical meta networks, the multi-level scenario knowledge is adaptively injected and lead to enhancement. Moreover, apart from distinct scenario-specific and user-specific features, it also enables to incorporate expert scenario knowledge through the prompt design, which is more universal and advanced than simply extracting invariant features and aligning the heterogeneous ones in [13]. Necessity of LLMs v.s. PLMs. As illustrated in Section 2.3, Different training objectives of Large Language Models (LLMs) and Pre-trained Language Models (PLMs) determine their roles. Specifically, rather than simply deriving a representation of existing (old) information by adopting PLMs as encoder (like BERT in CTRL [16]), the key of leveraging LLM as reasoner in LLM4MSR is to further infer useful (new) knowledge like analyzing user's crossscenario preference. This knowledge (in the form of hidden vectors) could potentially help enhancing conventional recommender systems. Besides, a case study is conducted in Section 4.6 and the knowledge (in the form of text) from ChatGLM2-6B is shown in Figure 5, which helps improving interpretability. By contrast, we also adopt GPT-2 (a typical PLM) to reason about user_1's interest given the same input prompt as in ChatGLM2-6B, and it generates the following nonsense text: \"The main strategy of this study was to combine two scenarios into a two-way analysis. The primary strategies are presented in Table I. If the main scenario is presented as a list of stories, then...\" In that case, such information could not bring information gain and improve the recommendation performance.", "4 EXPERIMENTS": "Extensive experiments are conducted on three public datasets to verify the effectiveness and efficiency of our proposed LLM4MSR paradigm, and the following five questions are answered: \u00b7 RQ1: Is LLM4MSR an effective paradigm and compatible with different multi-scenario backbone models? \u00b7 RQ2: What is the effect of the scenario-level and user-level prompt? What is their optimal architecture correspondingly? \u00b7 RQ3: What is the impact of interaction threshold and the number of neural network layers generated by the meta network? \u00b7 RQ4: What is the efficiency of LLM4MSR compared with the original multi-scenario backbone models? \u00b7 RQ5: How does LLM help improving the multi-scenario backbone models through our proposed LLM4MSR?", "4.1 Experimental Settings": "4.1.1 Datasets . Our experiments are conducted on three datasets: KuaiSAR-small, KuaiSAR [23], and Amazon [20]. To be specific, there is a search and a recommendation scenario on KuaiSAR-small and KuaiSAR while there are three correlated recommendation scenarios selected on Amazon. Furthermore, their statistics and detailed descriptions are summarized in Table 1. To be specific, we divide the original data into training, validation, and test set with the ratio of 8:1:1 by chronological order. Besides, the sparsity metric denotes the proportion of unclicked samples with label \ud835\udc66 = 0. \u00b7 KuaiSAR-small & KuaiSAR 2 datasets are both crawled from the short-video platform Kuaishou. The only difference is KuaiSARsmall is a smaller version of data in 9 days while KuaiSAR is in 19 days. Specifically, all users are overlapped in the recommendation and search scenario. Meanwhile, there are 97981 and 181849 items overlapped on KuaiSAR-small and KuaiSAR, respectively. \u00b7 Amazon 3 is collected from Amazon. Following [7], we select three connected scenarios: All Beauty, Clothing Shoes and Jewelry, and Luxury Beauty and we also filter the overlapped users among these scenarios without overlapped items. The goal is to predict whether a user would give a rating (from 1 to 5) higher than 3 to an item. 4.1.2 Evaluation Metrics . Area Under the ROC curve (AUC) is adopted to conduct evaluation on the test set, where a higher AUC value at 0.001 level usually denotes significant enhancement [6, 29]. 4.1.3 Backbone Models . We implement LLM4MSR on the following representative multi-scenario backbone models commonly deployed in industrial recommender system: \u00b7 STAR [21] proposes a star topology architecture with a shared centered network multiplied by many domain-specific networks. \u00b7 OMoE [14] leverages a group of expert networks and a gating network learned to ensemble the results from these experts. \u00b7 MMoE [19] explicitly learns a gating network for each task to assemble task-specific information compared with OMoE. \u00b7 PLE [24] proposes Customized Gate Control (CGC) which separates shared and specific expert networks and employs multi-level extraction network with a progressive routing mechanism. \u00b7 AITM [30] adaptively learns to transfer information for different tasks with sequential dependence. \u00b7 Shared Bottom is a multi-task model where the embedding layer is usually shared on which task-specific networks are built. 4.1.4 Baselines . There are few works aimed at explicitly enhancing multi-scenario recommendation. Besides, previous LLM-based models are not applicable in the same setting (refer to Section 5.2), e.g., LLM as recommender fails to meet real-time inference requirement. Consequently, we compare LLM4MSR with two typical paradigm as baseline methods: \u00b7 Dynamic Network . It targets at adaptively generating model parameters in a fine-grained manner [32]. In multi-scenario modeling [35], the scenario knowledge is employed to generate scenario-specific attention and tower module. \u00b7 EPNet . It is a gate structure proposed in PEPNet [3]. Specifically, it takes domain-side information as input and produce scenariospecific gates to transform embedding. 4.1.5 Implementation Details . The implementation details of the experiments conducted are summarized in Appendix A and the code is available to ease reproduction 1 . Specifically, for the open-source LLM we choose ChatGLM2-6B 4 [9] as an example.", "4.2 Overall Performance (RQ1)": "To answer RQ1 , we verify LLM4MSR's compatibility with various multi-scenario backbone models introduced in Section 4.1.3. Meanwhile, LLM4MSR is compared with two methods for multi-scenario recommendation enhancement as the baseline methods detailed in Section 4.1.4. The overall performance of AUC on KuaiSAR-small, KuaiSAR, and Amazon dataset is shown in Table 2. First, Dynamic Network and EPNet are able to simultaneously improve the recommendation accuracy on different scenarios in most cases, while there are exceptions like 'AITM_DN' on KuaiSAR and 'STAR_EP' on all datasets. By contrast, the proposed LLM4MSR significantly enhances the recommendation performance in all scenarios on the three datasets especially in Rec#1 and Rec#3 on Amazon. It also consistently outperforms the baseline methods except in the search scenario on KuaiSAR-small based on MMoE. The reason for its superiority is that, on the one hand, both the multi-scenario backbone models and baseline methods incorporate insufficient scenario knowledge, i.e., domain id only, and lack personalized modeling. On the other hand, LLM4MSR first utilizes LLM to explore domain correlation and infer personalized cross-scenario interest, then integrates meta network to explicitly enhance multi-scenario modeling capability. Besides, we observe that compared with the significant enhancement on scenario Rec#1 and Rec#3, LLM4MSR results in relatively subtle improvement (around 0.7%) on scenario Rec#2 on Amazon. The reason is that Rec#1 and Rec#3 are relatively sparse where each user has 1.4 and 2.3 interactions on average as shown in Table 1. Therefore, less information of user preference on these two scenarios could be captured by LLM to enhance Rec#2. Overall, LLM4MSR achieves an increase of 1.5%, 1%, and 40% in AUC on three datasets. To summarize, we can draw the conclusion that LLM4MSR serves as an effective and powerful enhancement paradigm, which possesses great compatibility and deployability on the mainstream multi-scenario recommendation backbone models.", "4.3 Ablation & Component Study (RQ2)": "To answer RQ2 , we conduct ablation study and component analysis based on STAR considering the following variants. \u00b7 user-bottom / user-parallel: It only adopts user-level meta layers at bottom / in parallel without scenario knowledge as input. \u00b7 domain-bottom / domain-parallel: It only adopts scenario-level meta layers at bottom / in parallel without user knowledge. \u00b7 LLM4MSR:Fullmodelwithbothuser-bottom and domain-parallel. \u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 0.5 0.0 0.5 1.0 1.5 \u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 0.5 0.0 0.5 1.0 \u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 0 10 20 30 40 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000 the domain-level prompt plays a more significant role on KuaiSARsmall and KuaiSAR dataset, while the user-level prompt is a more essential component on Amazon dataset. The results are depicted in Figure 3. On the one hand, the full model LLM4MSR achieves the best result on all scenarios on all the three datasets. The reason is that it makes full use of both the informative multi-scenario knowledge and the collaborative signal learned from the LLM and MSR backbone model, respectively. Meanwhile, from 'user - bottom' and 'domain - parallel' it is seen that both user- and domain-level prompt contribute to the performance enhancement on the backbone model. Nonetheless, Onthe other hand, comparing 'user - bottom' and 'user - parallel' we can observe that the former is better while the latter structure even has a negative impact in many cases. Similarly, placing the layers generated from the domain-level prompt in parallel to the scenario tower of the backbone model is the better choice contrasting 'domain - bottom' and 'domain - parallel'. Consequently, we can draw the conclusion that the combination of layers from user-level prompt at bottom and layers from domain-level prompt in parallel is the optimal architecture. A reasonable explanation is that the user-level multi-scenario information helps personalizing and modulating the general embedding better in a lower level. By contrast, the scenario-level information acts better in a higher level like the auxiliary network adopted in STAR [21]. Last but not least, it is intuitive to investigate the effect of LLM by replacing the obtained knowledge in the form of hidden states with randomly initialized vectors. However, such enhancement is not observed.", "4.4 Hyper-parameter Analysis (RQ3)": "We analyze the effect of two significant hyper-parameters, i.e., the threshold ( \ud835\udc47 ) of positive interactions in the user-level prompt and 10 25 40 55 0.7255 0.7260 0.7265 0.7270 0.7275 0.7280 Rec \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 T \u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000 0.6135 0.6145 0.6155 0.6165 0.6175 0.6185 Search 1 2 3 4 0.7255 0.7260 0.7265 0.7270 0.7275 0.7280 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 K \u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000 0.6145 0.6153 0.6161 0.6169 0.6177 0.6185 Search Rec the number of fully connected layers ( \ud835\udc3e ) generated by the meta network using STAR as the backbone model on KuaiSAR-small dataset. Specifically, as shown in Figure 4(a), the recommendation accuracy continuously increases as \ud835\udc47 rises until the token limit of LLM is reached, since more information about cross-scenario preference of users is introduced and captured by LLM. Besides, from Figure 4(b) we can see that the best performance is obtained where \ud835\udc3e = 2. Nevertheless, the results degrade as the network becomes deeper and a possible reason is overfitting.", "4.5 Efficiency Analysis (RQ4)": "To validate the efficiency of our proposed LLM4MSR paradigm, we take STAR as the backbone model and experiment on KuaiSARsmall dataset. As shown in Table 3, as an LLM-based method, LLM4MSR still enables real-time inference even if it requires more training and inference time than other baseline methods. Besides, the real-world industrial system has a maximum latency specification (let's say 0.1s), and the present inference time (0.05s in our method) will not undermine the effectiveness of system considering both latency and success rate, while significant improvement of performance is still achieved. Consequently, LLM4MSR possesses an excellent trade-off in effectiveness and efficiency. In practice, the last hidden states generated from the user-level prompt can be stored before training, since inferring user preference is the most time-consuming step in LLM4MSR and it takes about 2 to 4 seconds per user on one single GPU. Besides, the architecture with scenario-level parameters only (i.e., 'domain - parallel' in Section 4.3) can serve as an alternative approach because the scenario-level prompt does not require frequent updates or personalization, thus leading to higher efficiency.", "4.6 Case Study (RQ5)": "To answer RQ5 , we conduct a case study on KuaiSAR-small dataset taking user_1 as an example and the results generated from the corresponding designed scenario- and user-level prompt by ChatGLM26B are shown in Figure 5. Specifically, we can see that ChatGLM2-6B not only explicitly captures the commonality and distinction between the recommendation and search scenario, but it also clearly infers user_1's common and distinct interests among these two scenarios with an accurate user profile summary. Afterward, the generated information is integrated hierarchically by the meta network and meta layers. Consequently, the performance of the multiscenario backbone model is enhanced. Meanwhile, this knowledge in different levels from LLM also helps improving the interpretability of the original recommender system.", "5 RELATED WORK": "This section brief summarizes the recent work on multi-scenario recommendation and adopting language model for CTR prediction.", "5.1 Multi-Scenario Recommendation": "Multi-scenario recommendation [27, 29], also known as multidomain or multi-target cross-domain recommendation [38], uses the data from all scenarios to simultaneously improve their recommendation performance and tackle data sparsity problem. For example, STAR [21] adopts a star-like framework with a shared centered network and scenario-specific networks similar to the parameter sharing pattern design in multi-task modeling [28]. M2M [35] proposes a meta learning mechanism with hierarchically organized meta attention and meta tower module to grasp inter-scenario correlations and scenario-specific representation. In addition, to address the imperfectly double seesaw phenomenon, PEPNet [3] proposes embedding and parameter personalized network to dynamically scale the parameters based on the designed gate mechanism in a domain-specific and task-specific manner, respectively. Facing the drawbacks of the aforementioned methods introduced in Section 1, i.e., insufficient integration of scenario knowledge and neglecting personalized interest across different scenarios, our proposed framework leverages LLM to uncover domain commonality and distinction and infer users' cross-scenario preference, which are further utilized to enhance the multi-scenario backbone model.", "5.2 Language Model for CTR Prediction": "Several works try to incorporate Language Models (LMs) including Large Language Models (LLMs) and Pre-trained Language Models (PLMs) as illustrated in Section 2.3 with recommendation for Click-Through Rate (CTR) prediction [13, 16, 17, 25, 31] since they have the potential to bring information gain. Specifically, one of the solutions is to treat the semantic knowledge as cross-modal information and align with the collaborative signal in conventional recommender systems. For example, CTRL [16] employs contrastive learning for knowledge alignment and integration. KAR [31] first generates reasoning knowledge of user preferences and item factual information, then encodes and adapts them to the backbone recommendation models. Besides, S&R Multi-domain Foundation Model [13] simply adopts LLM to extract scenario-invariant text features and tackle item heterogeneity issue. However, on the one hand, these methods necessitate conducting both training and inference with LM in the sample level, leading to low efficiency of inference and poor deployability on industrial recommender systems. On the other hand, the connection between scenarios and personalized modeling are ignored. In this paper, we investigate a new LLM-enhanced paradigm, which not only improves the performance of multi-scenario modeling through", "Scenario Correlation:": "The commonality between the search scenario and the recommendation scenario on Kuaishou is that they both involve useritem interactions. However, the distinction is that in the search scenario, users actively input queries, while in the recommendation scenario, items are recommended to users based on their behaviors and characteristics. Additionally, the recommendation scenario has more interactions, users, and items than the search scenario, and there is a large overlap between the items in the two scenarios. Given the interaction behavior and item category information for user_1, there are interactions in both the search scenario and the recommendation scenario. Therefore, we will first summarize the common interests across both scenarios, and then summarize the distinct interests in each scenario.", "Common Interests:": "Based on the interaction behavior frequency, user_1 shows a common interest in the following categories across both the search and recommendation scenarios: 1. Education category : The user clicked on normal videos in this category multiple times in both scenarios, indicating a strong interest in educational content. \u2026", "Distinct Interests:": "Search Scenario Distinct Interests: 1. Talent category : The user clicked on normal videos in this category during the search scenario, suggesting an interest in content showcasing talent, skills, or creativity. \u2026 Recommendation Scenario Distinct Interests: 1. Music category : The user clicked on a normal video in this category during the recommendation scenario, indicating an interest in music-related content. \u2026", "Summary:": "User_1 has a strong interest in education, beauty makeup, and emotional content, which is evident in both the search and recommendation scenarios. Additionally, there is evidence of interest in talent, photography, music, parenting, health, unusual phenomena, style, and dynamic content, although these interests are more pronounced in one scenario or the other. Figure 5: Case study of user_1 on KuaiSAR-small dataset. The purple and blue box denote the result on the scenario correlation and the inferred cross-scenario preferences from scenario- and user-level prompt by ChatGLM2-6B. the inferred scenario-level correlation and user-level cross-scenario interest, but it also enables efficient training and real-time inference.", "6 CONCLUSION": "In this paper, we propose an effective efficient interpretable paradigm LLM4MSR which first leverages LLM to reason about multiscenario knowledge, including scenario commonality and distinction, and users' cross-scenario preferences through the designed scenario- and user-level prompt. Then it adopts hierarchical meta networks which generate meta layers to adaptively fuse the multilevel knowledge and improve the conventional multi-scenario recommender systems. Extensive experiments on three public datasets validate that LLM4MSR is not only an effective paradigm compatible with various multi-scenario backbone models, but it is also efficient without fine-tuning LLM and enables real-time recommendation on industrial recommender systems. Besides, the interpretability of conventional recommender system is improved.", "A EXPERIMENTAL SETTINGS": "The hyper-parameters are summarized in Table 4. Meanwhile, the designed template of scenario- and user-level prompt are shown in the purple and blue box in Figure 2, respectively. Specifically, the most recent 55, 55, and 35 positive interactions, i.e., with click, forward, and like behavior on each scenario are leveraged when constructing the user-level prompt on KuaiSAR-small, KuaiSAR, and Amazondataset because the maximum context length of ChatGLM26B is 8K. Besides, the Adam [15] optimizer is adopted. The meta network employed is simply a fully connected network. Overall, all the experimental results shown are averaged over 3 runs.", "B PROMPT TEMPLATE": "In this section, we provide the designed scenario-level and userlevel prompt template, where the information in square brackets needs to be filled. Specifically, to capture the commonality among scenarios and emphasize distinction for each scenario, the present scenario-level prompts only differ in the instruction: 'explicitly summarize the distinction of [scenario_i name]', where [scenario_i name] is the name of each scenario like recommendation or search scenario in KuaiSAR. Meanwhile, other distinctive information of scenario like prior expert knowledge can be provided. That's the reason why the prompts are constructed separately for each scenario in Algorithm 1. Prompts with the best performance are:", "\u00b7 Scenario-level Prompt:": "\"On platform [dataset name], [platform description], suppose there are [specific number] interactions in [scenario_1 name], [specific number] interactions in [scenario_2 name]... Besides, in these scenarios there are [specific number] users [user description] and [specific number] items [item description] where [specific number] users and [specific number] products are overlapped. From the relationship among these scenarios and statistics given, explicitly summarize the scenario commonality among the three scenarios and the distinction of [scenario name].\"", "\u00b7 User-level Prompt:": "\"On platform [dataset name], suppose there are [scenario_1 name], [scenario_2 name]... In [scenario_1 name], user_[id] [historical behavior + item_type + category]... Besides, in [scenario_2 name], this user [historical behavior + item_type + category]. For this user, considering the interaction frequency and item title plus description information, explicitly summarize the common interest among the three scenarios first, then summarize the distinct interest in each scenario.\"", "REFERENCES": "[1] Joseph Berkson. 1944. Application of the logistic function to bio-assay. Journal of the American statistical association 39, 227 (1944), 357-365. [2] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901. [3] Jianxin Chang, Chenbin Zhang, Yiqun Hui, Dewei Leng, Yanan Niu, Yang Song, and Kun Gai. 2023. Pepnet: Parameter and embedding personalized network for infusing with personalized prior information. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 3795-3804. [4] Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian. 2023. Extending context window of large language models via positional interpolation. arXiv preprint arXiv:2306.15595 (2023). [5] Yukang Chen, Shengju Qian, Haotian Tang, Xin Lai, Zhijian Liu, Song Han, and Jiaya Jia. 2023. Longlora: Efficient fine-tuning of long-context large language models. arXiv preprint arXiv:2309.12307 (2023). [6] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al. 2016. Wide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems . 7-10. [7] Qiang Cui, Tao Wei, Yafeng Zhang, and Qing Zhang. 2020. HeroGRAPH: A Heterogeneous Graph Framework for Multi-Target Cross-Domain Recommendation.. In ORSUM@ RecSys . [8] Zeyu Cui, Jianxin Ma, Chang Zhou, Jingren Zhou, and Hongxia Yang. 2022. M6-rec: Generative pretrained language models are open-ended recommender systems. arXiv preprint arXiv:2205.08084 (2022). [9] Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. GLM: General Language Model Pretraining with Autoregressive Blank Infilling. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) . 320-335. [10] Wenqi Fan, Zihuai Zhao, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Jiliang Tang, and Qing Li. 2023. Recommender systems in the era of large language models (llms). arXiv preprint arXiv:2307.02046 (2023). [11] Jingtong Gao, Bo Chen, Menghui Zhu, Xiangyu Zhao, Xiaopeng Li, Yuhao Wang, Yichao Wang, Huifeng Guo, and Ruiming Tang. 2023. Scenario-Aware Hierarchical Dynamic Network for Multi-Scenario Recommendation. arXiv preprint arXiv:2309.02061 (2023). [12] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022. Recommendation as language processing (rlp): A unified pretrain, personalized prompt & predict paradigm (p5). In Proceedings of the 16th ACM Conference on Recommender Systems . 299-315. [13] Yuqi Gong, Xichen Ding, Yehui Su, Kaiming Shen, Zhongyi Liu, and Guannan Zhang. 2023. An Unified Search and Recommendation Foundation Model for Cold-Start Scenario. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management . 4595-4601. [14] Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. 1991. Adaptive mixtures of local experts. Neural computation 3, 1 (1991), 79-87. [15] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv:1412.6980 (2014). [16] Xiangyang Li, Bo Chen, Lu Hou, and Ruiming Tang. 2023. CTRL: Connect Tabular and Language Model for CTR Prediction. arXiv preprint arXiv:2306.02841 (2023). [17] Jianghao Lin, Bo Chen, Hangyu Wang, Yunjia Xi, Yanru Qu, Xinyi Dai, Kangning Zhang, Ruiming Tang, Yong Yu, and Weinan Zhang. 2023. ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction. arXiv preprint arXiv:2310.09234 (2023). [18] Junling Liu, Chao Liu, Renjie Lv, Kang Zhou, and Yan Zhang. 2023. Is chatgpt a good recommender? a preliminary study. arXiv preprint arXiv:2304.10149 (2023). [19] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed H Chi. 2018. Modeling task relationships in multi-task learning with multi-gate mixture-ofexperts. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1930-1939. [20] Jianmo Ni, Jiacheng Li, and Julian McAuley. 2019. Justifying recommendations using distantly-labeled reviews and fine-grained aspects. In Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP) . 188-197. [21] Xiangrong Sheng, Liqin Zhao, Guorui Zhou, Xinyao Ding, Binding Dai, Qiang Luo, Siran Yang, Jingshan Lv, Chi Zhang, Hongbo Deng, et al. 2021. One model to serve all: Star topology adaptive recommender for multi-domain ctr prediction. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management . 4104-4113. [22] Liangcai Su, Junwei Pan, Ximei Wang, Xi Xiao, Shijie Quan, Xihua Chen, and Jie Jiang. 2023. STEM: Unleashing the Power of Embeddings for Multi-task Recommendation. arXiv preprint arXiv:2308.13537 (2023). [23] Zhongxiang Sun, Zihua Si, Xiaoxue Zang, Dewei Leng, Yanan Niu, Yang Song, Xiao Zhang, and Jun Xu. 2023. KuaiSAR: A Unified Search And Recommendation Dataset. (2023). https://doi.org/10.1145/3583780.3615123 [24] Hongyan Tang, Junning Liu, Ming Zhao, and Xudong Gong. 2020. Progressive layered extraction (ple): A novel multi-task learning (mtl) model for personalized recommendations. In Fourteenth ACM Conference on Recommender Systems . 269278. [25] Hangyu Wang, Jianghao Lin, Xiangyang Li, Bo Chen, Chenxu Zhu, Ruiming Tang, Weinan Zhang, and Yong Yu. 2023. ALT: Towards Fine-grained Alignment between Language and CTR Models for Click-Through Rate Prediction. arXiv preprint arXiv:2310.19453 (2023). [26] Thomas Wang, Adam Roberts, Daniel Hesslow, Teven Le Scao, Hyung Won Chung, Iz Beltagy, Julien Launay, and Colin Raffel. 2022. What language model architecture and pretraining objective works best for zero-shot generalization?. In International Conference on Machine Learning . PMLR, 22964-22984. [27] Yichao Wang, Huifeng Guo, Bo Chen, Weiwen Liu, Zhirong Liu, Qi Zhang, Zhicheng He, Hongkun Zheng, Weiwei Yao, Muyu Zhang, et al. 2022. Causalint: Causal inspired intervention for multi-scenario recommendation. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 4090-4099. [28] Yuhao Wang, Ha Tsz Lam, Yi Wong, Ziru Liu, Xiangyu Zhao, Yichao Wang, Bo Chen, Huifeng Guo, and Ruiming Tang. 2023. Multi-Task Deep Recommender Systems: A Survey. arXiv preprint arXiv:2302.03525 (2023). [29] Yuhao Wang, Xiangyu Zhao, Bo Chen, Qidong Liu, Huifeng Guo, Huanshuo Liu, Yichao Wang, Rui Zhang, and Ruiming Tang. 2023. PLATE: A PromptEnhanced Paradigm for Multi-Scenario Recommendations. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1498-1507. [30] Dongbo Xi, Zhen Chen, Peng Yan, Yinger Zhang, Yongchun Zhu, Fuzhen Zhuang, and Yu Chen. 2021. Modeling the sequential dependence among audience multistep conversions with multi-task learning in targeted display advertising. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining . 3745-3755. [31] Yunjia Xi, Weiwen Liu, Jianghao Lin, Jieming Zhu, Bo Chen, Ruiming Tang, Weinan Zhang, Rui Zhang, and Yong Yu. 2023. Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models. arXiv preprint arXiv:2306.10933 (2023). [32] Bencheng Yan, Pengjie Wang, Kai Zhang, Feng Li, Hongbo Deng, Jian Xu, and Bo Zheng. 2022. Apg: Adaptive parameter generation network for click-through rate prediction. Advances in Neural Information Processing Systems 35 (2022), 24740-24752. [33] Bin Yin, Junjie Xie, Yu Qin, Zixiang Ding, Zhichao Feng, Xiang Li, and Wei Lin. 2023. Heterogeneous knowledge fusion: A novel approach for personalized recommendation via llm. In Proceedings of the 17th ACM Conference on Recommender Systems . 599-601. [34] Rizgar Zebari, Adnan Abdulazeez, Diyar Zeebaree, Dilovan Zebari, and Jwan Saeed. 2020. A comprehensive review of dimensionality reduction techniques for feature selection and feature extraction. Journal of Applied Science and Technology Trends 1, 2 (2020), 56-70. [35] Qianqian Zhang, Xinru Liao, Quan Liu, Jian Xu, and Bo Zheng. 2022. Leaving No One Behind: A Multi-Scenario Multi-Task Meta Learning Approach for Advertiser Modeling. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining . 1368-1376. [36] Xiangyu Zhao, Haochen Liu, Hui Liu, Jiliang Tang, Weiwei Guo, Jun Shi, Sida Wang, Huiji Gao, and Bo Long. 2021. Autodim: Field-aware embedding dimension searchin recommender systems. In Proceedings of the Web Conference 2021 . 30153022. [37] Bowen Zheng, Yupeng Hou, Hongyu Lu, Yu Chen, Wayne Xin Zhao, and JiRong Wen. 2023. Adapting large language models by integrating collaborative semantics for recommendation. arXiv preprint arXiv:2311.09049 (2023). [38] Feng Zhu, Yan Wang, Chaochao Chen, Jun Zhou, Longfei Li, and Guanfeng Liu. 2021. Cross-domain recommendation: challenges, progress, and prospects. arXiv preprint arXiv:2103.01696 (2021)."}
