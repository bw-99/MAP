{"Calibration-compatible Listwise Distillation of Privileged Features for CTR Prediction": "Xiaoqiang Gui School of Software, Shandong University Jinan, China x.q.gui@mail.sdu.edu.cn Yueyao Cheng Xiang-Rong Sheng Alibaba Group Beijing, China chengyueyao.cyy@taobao.com xiangrong.sxr@taobao.com Yunfeng Zhao Guoxian Yu* School of Software, Shandong University Jinan, China yunfengzhao@mail.sdu.edu.cn gxyu@sdu.edu.cn Shuguang Han* Alibaba Group Hangzhou, China shuguang.sh@taobao.com Yuning Jiang Jian Xu Alibaba Group Beijing, China mengzhu.jyn@taobao.com xiyu.xj@taobao.com", "ABSTRACT": "In machine learning systems, privileged features refer to the features that are available during offline training but inaccessible for online serving. Previous studies have recognized the importance of privileged features and explored ways to tackle online-offline discrepancies. A typical practice is privileged features distillation (PFD): train a teacher model using all features (including privileged ones) and then distill the knowledge from the teacher model using a student model (excluding the privileged features), which is then employed for online serving. In practice, the pointwise cross-entropy loss is often adopted for PFD. However, this loss is insufficient to distill the ranking ability for CTR prediction. First, it does not consider the non-i.i.d. characteristic of the data distribution, i.e., other items on the same page significantly impact the click probability of the candidate item. Second, it fails to consider the relative item order ranked by the teacher model's predictions, which is essential to distill the ranking ability. To address these issues, we first extend the pointwise-based PFD to the listwise-based PFD. We then define the calibration-compatible property of distillation loss and show that commonly used listwise losses do not satisfy this property when employed as distillation loss, thus compromising the model's calibration ability, which is another important measure for CTR prediction. To tackle this dilemma, we propose Calibration-compatible LIstwise Distillation (CLID), which employs carefully-designed listwise distillation loss to achieve better ranking ability than the *Guoxian Yu and Shuguang Han are the corresponding authors. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WSDM '24, March 4-8, 2024, Merida, Mexico \u00a9 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0371-3/24/03...$15.00 https://doi.org/10.1145/3616855.3635810 Bo Zheng Alibaba Group Beijing, China bozheng@taobao.com pointwise-based PFD while preserving the model's calibration ability. We theoretically prove it is calibration-compatible. Extensive experiments on public datasets and a production dataset collected from the display advertising system of Alibaba further demonstrate the effectiveness of CLID.", "CCS CONCEPTS": "\u00b7 Information systems \u2192 Recommendation systems .", "KEYWORDS": "CTR Prediction, Privileged Features, Calibration-compatible Listwise Distillation", "ACMReference Format:": "Xiaoqiang Gui, Yueyao Cheng, Xiang-Rong Sheng, Yunfeng Zhao, Guoxian Yu*, Shuguang Han*, Yuning Jiang, Jian Xu, and Bo Zheng. 2024. Calibrationcompatible Listwise Distillation of Privileged Features for CTR Prediction. In Proceedings of the 17th ACM International Conference on Web Search and Data Mining (WSDM '24), March 4-8, 2024, Merida, Mexico. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3616855.3635810", "1 INTRODUCTION": "Click-through rate (CTR) prediction is an essential component in online recommendation systems [16, 53]. While receiving a user request, a recommendation system retrieves a set of candidate items, ranks them, and then displays them to users. In the ranking stage, a CTR prediction model typically takes the user's features and candidate items' features as input. The model then predicts the user's probability of clicking the candidate item. In most cases, the same set of features are adopted in offline training and online serving to guarantee model consistency. However, previous studies have also identified that despite being useful during offline training, some features are not readily available for online serving [43, 49, 51]. For example, when predicting the probability of purchase after a user clicks the item[10, 18, 56], the dwell time on the detailed item page is a useful post-event feature that only exists in the offline training data because the online WSDM'24, March 4-8, 2024, Merida, Mexico Xiaoqiang Gui et al. model cannot know this time before the user leaves the page. For ease of differentiation, we call the features that exist only during training privileged features and those that exist during both training and serving non-privileged features . There exist some informative privileged features in the CTR prediction task. Fig. 1 illustrates the formation process of the items a user sees when visiting the online recommendation system. In the ranking stage, the CTR model retrieves hundreds of candidate items and generates tens of items that will be refined in the re-ranking stage and then exposed to the user. Therefore, the ranking model (i.e., the CTR model in the ranking stage) cannot observe exposed items before generating recommendations. That is to say, the features regarding the items displayed together with the candidate item on the same page are privileged ones for the ranking model when predicting the user's probability of clicking the candidate item. In the following, we refer to these items and their features as contextual items and contextual features . Contextual items significantly affect the user click propensity of the candidate item. Therefore, properly utilizing privileged contextual features for the ranking model can significantly improve CTR prediction performance. Note that contextual features are non-privileged features for the model in the re-ranking stage where there is no issue of training-serving inconsistency, and many attempts [1, 3, 34, 59] have been made. To utilize privileged features, previous works [19, 54, 58] have examined adding them into the detached shallow tower of the prediction model and discarding them at serving. However, in this way, the input distributions at the training and inference (i.e., online serving) phases are inconsistent, i.e., the covariate shift issue still exists, which usually hurts the model generalizability [41]. To preserve the offline-online consistency while incorporating the privileged features, Xu et al. [49] proposed a privileged features distillation (PFD) framework. PFD introduces student and teacher models, in which the teacher model utilizes both privileged and non-privileged features for better training performance. In contrast, the student model only trains on top of non-privileged features and acts as the final model for serving. The knowledge learned from the teacher model (i.e., the teacher model's predictions) is employed as soft labels to instruct the student model. Knowledge distillation of existing PFD methods [30, 49, 51] is typically implemented with a pointwise loss. Despite being effective, the pointwise distillation loss separately treats each item based on the identical and independently distributed (i.i.d.) assumption, which is against reality since items in a recommendation system are often displayed in a list format, and the probability of clicking on an item is affected by other items on the same page [9, 48]. Consequently, the pointwise loss fails to consider the information of the relative item order ranked by the teacher model's predicted click probabilities (pCTR) for items within the same page, making it insufficient to distill the ranking ability from the teacher model. To address the above issue, a straightforward approach is to extend the PFD framework with the listwise loss as the distillation loss. The listwise loss treats each list as an optimization instance and naturally accounts for the non-i.i.d. nature of items' pCTR. Indeed, we empirically observe an improved ranking performance for the listwise-based PFD methods over the pointwise-based one. However, when employed as distillation loss, the commonly used listwise losses can destroy the probabilistic meaning of the student model's predictions as pCTR, degrading the student model's calibration ability. For the CTR prediction task, the calibration ability, i.e., whether or not the predicted click probability aligns with the actual click-through rate , is another important factor for measuring the model performance [5, 11, 30, 39, 47, 50, 57]. For example, considering the cost-per-click (CPC) system in online advertising, a candidate advertisement (ad) is ranked and charged by the strategy of effective cost per mile impressions (eCPM), which is computed as eCPM = 1000 \u00b7 \ud835\udc5d\ud835\udc36\ud835\udc47\ud835\udc45 \u00b7 BidCPC, where BidCPC is the bid price from the advertiser, and \ud835\udc5d\ud835\udc36\ud835\udc47\ud835\udc45 denotes the predicted click-through rate (predicted click probability) of the ad, which the predictive model produces. The computation of eCPM shows that mis-calibrated pCTR can damage the user experience, prevent advertisers from achieving their marketing goals, and eventually affect the revenue of advertising platforms. Thus, a well-calibrated prediction is the key to bidding, charging, and ranking the candidate ads. To improve the model's ranking ability while preserving its calibration ability with the listwise distillation loss, we propose a Calibration-compatible LIstwise Distillation (CLID) approach for CTR prediction. In particular, inspired by RCR [5], a calibrationcompatible listwise loss in the field of Learning-To-Rank (LTR), we first define the calibration-compatible property of the distillation loss within the PFD context: the distillation loss (using the soft label from the teacher model) can achieve the global minima simultaneously with the losses (using the click label) of the student and teacher model . We show that widely employed listwise losses (e.g., ListNet [9], and ListMLE [48]) are not calibration-compatible when applied as the distillation loss. Subsequently, to achieve the calibrationcompatible listwise distillation loss, we carefully design the listwise loss by exploiting the cross-entropy to measure the discrepancy between two relative item orders on the same page, encoded using normalized pCTR generated by the student and teacher models, respectively. Finally, we provide theoretical proof that the tailored listwise loss in CLID is indeed calibration-compatible . Extensive experiments over various baselines on two public datasets and a production dataset collected from the display advertising system of Alibaba verify that CLID achieves substantial ranking performance improvements while preserving the model's calibration performance. The main contributions of this research are as follows: (i) We observe that the popular pointwise-based PFD methods disregard the non-i.i.d. nature of data distribution for CTR prediction and suggest extending the distillation loss with listwise ones to improve the model's ranking ability better. Moreover, we further show the widely employed listwise losses can compromise the model's calibration ability, a crucial aspect in CTR prediction, rendering them unsuitable for direct application in PFD. (ii) We propose a Calibration-compatible LIstwise Distillation (CLID) approach that carefully designs the listwise distillation loss to distill the ranking ability from the teacher model without destroying the model's calibration ability. Besides, we theoretically prove the tailored listwise distillation loss satisfies the defined calibrationcompatible property, thus yielding well-calibrated predictions. (iii) We validate the effectiveness of CLID on both public and production datasets. Experimental results show that CLID significantly improves the student model's ranking ability while preserving its calibration ability. Calibration-compatible Listwise Distillation of Privileged Features for CTR Prediction WSDM'24, March 4-8, 2024, Merida, Mexico Figure 1: An illustration of the formation process of the items a user sees when visiting the online recommendation system. User Request Exposed Items Re-Ranking Ranking Pre-Ranking Matching tens of millions tens of  thousands hundreds tens", "2 RELATED WORK": "Privileged features [31] are available during training but inaccessible at the testing time due to the expensive real-time computation overhead or feature unavailability before online inference. Privileged features widely exist in various machine learning applications, including the emotion recognition [44], action detection [33], image super-resolution [26], etc. Several Unbiased Learning To Rank (ULTR) [4] methods have been made to utilize the privileged exposed position features of items for CTR prediction. One line of work [19, 20, 29, 54, 58] incorporates the position information as the feature of the detached shallow tower when training and adopts the default position or discards the external tower at inference. As a result, the input distributions of these methods during training and inference are inconsistent, which causes unstable improvements in the model's ranking ability and vast degradation of the model's calibration ability, as shown in our later experiments. Instead of regarding the position as a feature, another line of work attempts to directly model the position influence with result randomization [24, 42, 45] or Inverse Propensity Weighting (IPW) [2, 12, 46]. These approaches are often ad-hoc and cannot be simply extended to various privileged features, such as dwell time and contextual features. Note that the privileged contextual features here are different from the non-privileged \"contextual features\" mentioned in other works, which either focus on the \"contextual features\" in the reranking stage [1, 3, 35, 59] or the \"contextual features\" of each item within the user's historical behaviors [15, 25, 28]. Therefore these works can not be compared with CLID when conducting experiments. This paper employs the privileged knowledge distillation (PFD) framework to model various privileged features. Privileged features distillation is a popular and powerful technique to exploit privileged features while solving the trainingserving inconsistency. Xu et al. [49] proposes the Privileged Features Distillation (PFD) technique that feeds the teacher model with both non-privileged and privileged features and further demonstrates the superiority of PFD in the recommendation systems. Liu et al. [30] demonstrates that PFD achieves the state-of-the-art performance when utilizing the privileged position feature. Yang et al. [51] further analyzes the underlying mechanism of PFD in recommendation systems. However, these methods all employ the pointwise loss as the distillation loss that is insufficient to distill the teacher model's ranking ability for CTR prediction. Unlike them, our CLID designs the calibration-compatible listwise distillation loss to capture the inter-item dependency and distill the ranking ability while maintaining the model's calibration ability. Our research is also closely related to the field of Learning-ToRank (LTR) . In LTR, numerous attempts have been made to design effective loss functions, including pointwise, pairwise, and listwise losses [13, 21]. Generally, the pointwise loss takes a single item as the learning instance [14, 27], the pairwise loss views a pair of items as the learning instance [8, 17], and the listwise loss regards an individual list of items as a learning instance [9, 48]. Among these losses, the listwise loss naturally captures the non-i.i.d. data dependency and aims to learn a scoring function that minimizes the ranking loss and induces a perfect ranking list, thus producing better ranking performance than the pointwise and pairwise ones. In addition, a listwise loss with a list size of 2 degenerates into a pairwise loss. Therefore, this paper mainly focuses on employing the listwise loss as the distillation loss. However, the scores of commonly employed listwise losses (e.g., ListNet [9], ListMLE [48], ApproxNDCG [37]) are not well calibrated, limiting their usage in score-sensitive business applications, e.g., the online advertising platform. Recently, Bai et al. [5] proposed RCR which modified the mapping function in ListNet to align with various pointwise losses and proved that RCR and pointwise losses share the global minima in the context of LTR. Inspired by them, we carefully design the listwise distillation loss and prove that the loss satisfies the defined calibration-compatible property within the PFD context.", "3 METHODOLOGY": "In this section, we first give a brief overview of the system architecture and then introduce the proposed calibration-compatible listwise distillation (CLID) approach for CTR prediction.", "3.1 System Overview": "Figure 2 depicts the overall framework of CLID, which consists of three parts: a base module, a student model, and a teacher model. The base module first transforms discrete feature IDs into lowdimensional embeddings. Then those embeddings are aggregated to obtain a fixed-length vector. The teacher model utilizes the vector obtained from both non-privileged and privileged features as input, and outputs pCTR \u02c6 \ud835\udc5d \ud835\udc61 . The student model shares the same MLP structure as the teacher model, while it only employs the vector obtained from non-privileged features as input and outputs pCTR \u02c6 \ud835\udc5d \ud835\udc60 . In the meantime, the student model also adopts the calibrationcompatible listwise distillation loss to distill the knowledge from \u02c6 \ud835\udc5d \ud835\udc61 . The final output \u02c6 \ud835\udc5d \ud835\udc60 from the student model will be used for serving.", "3.2 Model Structure": "A typical CTR prediction task aims to predict the likelihood of a click for each user-item pair. In the most common case, a CTR prediction model often utilizes non-privileged features, including the user behavior sequence \ud835\udc65 \ud835\udc4f , user profile \ud835\udc65 \ud835\udc62 , candidate item \ud835\udc65 \ud835\udc61 , and other features \ud835\udc65 \ud835\udc5c , as input and outputs pCTR. 3.2.1 Base Module. As shown in Figure 2, the base module first utilizes the embedding layer to transform the high-dimensional features \ud835\udc65 into low-dimensional embeddings \ud835\udc52 ( \ud835\udc65 ) . These features include non-privileged features and privileged ones. \ud835\udc5a different privileged features are denoted as \ud835\udc65 \ud835\udc5d 1 , \ud835\udc65 \ud835\udc5d 2 , . . . , \ud835\udc65 \ud835\udc5d \ud835\udc5a . For user behavior features, the pooling layer is applied to transform the list of embedding vectors into a fixed-length vector. Before pooling, WSDM'24, March 4-8, 2024, Merida, Mexico Xiaoqiang Gui et al. Figure 2: The framework of our proposed CLID method. CLID consists of three parts: base module, student model, and teacher model. The base module takes non-privileged features (e.g., user profile and a set of features with regard to candidate item) and privileged features as input and maps them into the fixed-length vectors. Both non-privileged and privileged features are employed as the input of the teacher model for training, whereas only non-privileged features are employed as the input of the student model for training and serving. PReLU [22] represents the commonly used activation function in CTR prediction. The output pCTR of the student and teacher model is \u02c6 \ud835\udc5d \ud835\udc60,\ud835\udc56 and \u02c6 \ud835\udc5d \ud835\udc61,\ud835\udc56 , respectively. The calibration-compatible listwise distillation loss takes \u02c6 \ud835\udc5d \ud835\udc61,\ud835\udc56 as the soft label and instructs the learning of \u02c6 \ud835\udc5d \ud835\udc60,\ud835\udc56 . Only the output pCTR of the student model is used for serving. Other User Profile User Behaviors Privileged Features Candidate Item DIN ... ... ... ... Concat Embedding Layer Concat & Flatten Concat & Flatten PReLU PReLU Sigmoid PReLU PReLU Sigmoid pCTR pCTR Base Module Student Model Teacher Model Calibration-compatible Listwise Distillation Loss Pooling Training and Serving Only for Training ... ... DIN [60] is adopted for better modeling of feature interaction. With the concatenation layer, we can obtain the non-privileged representation vector V \ud835\udc5f as the input of the student model: Unlike the teacher model, the student model serves online and thus only takes the non-privileged vector V \ud835\udc5f,\ud835\udc56 as input. The output \u02c6 \ud835\udc5d \ud835\udc60,\ud835\udc56 of the student model is as follows:  We concatenate the low-dimensional embeddings of \ud835\udc5a privileged features to obtain the privileged representation vector:  Since the privileged features are available at training but inaccessible during serving, we add them to the teacher model to guide the learning of the student model. The input vector V \ud835\udc61 of the teacher model is composed of the non-privileged vector V \ud835\udc5f and the privileged vector V \ud835\udc5d as follows:  3.2.2 Teacher and Student Model. Given a sample \ud835\udc65 \ud835\udc56 with the click label \ud835\udc66 \ud835\udc56 \u2208 { 0 , 1 } , V \ud835\udc5f,\ud835\udc56 and V \ud835\udc61,\ud835\udc56 represent the input vectors of the student and teacher model, respectively. During training, V \ud835\udc61,\ud835\udc56 will be fed into the teacher model to obtain the logit \ud835\udc60 \ud835\udc61,\ud835\udc56 of sample \ud835\udc65 \ud835\udc56 , and then the sigmoid activation function \ud835\udf0e (\u00b7) is adopted to compute the pCTR \u02c6 \ud835\udc5d \ud835\udc61,\ud835\udc56 as follows:  The standard pointwise cross-entropy (PointCE) loss is adopted to obtain a well-calibrated predicted probability of sample \ud835\udc65 \ud835\udc56 :   where \ud835\udc60 \ud835\udc60,\ud835\udc56 is the logit of sample \ud835\udc65 \ud835\udc56 , obtained from the student model before the sigmoid activation function. We adopt two loss functions for training. The first loss is similar to the teacher model, in which the PointCE loss is adopted with the ground truth label  The second loss is a knowledge distillation loss \ud835\udc3f \ud835\udc51 ( \u02c6 \ud835\udc5d \ud835\udc61,\ud835\udc56 , \u02c6 \ud835\udc5d \ud835\udc60,\ud835\udc56 ) , aiming to distill the knowledge from the teacher model. The reason is that the teacher model incorporates the privileged features and thus performs better than the student model. The final loss of the student model can be written as follows:  where \ud835\udefc is the hyper-parameter that balances the importance of PointCE loss and distillation loss. The knowledge distillation loss will be discussed in detail in the following subsection.", "3.3 Listwise Privileged Features Distillation": "3.3.1 Challenges. We encounter two challenges when designing the distillation loss of the student model. For the distillation loss, the pointwise loss is widely used [30, 49, 51]:  Calibration-compatible Listwise Distillation of Privileged Features for CTR Prediction WSDM'24, March 4-8, 2024, Merida, Mexico where \ud835\udf0f > 0 denotes a temperature parameter. A larger \ud835\udf0f yields a softer distribution of predictions. With \ud835\udf0f \u2192 +\u221e and the zeromeaned assumption of logits, \ud835\udc3f \ud835\udc51 can be equivalent to MSE loss that matches the logits directly [23]. The first challenge is that the pointwise loss is sub-optimal when distilling the ranking ability from the teacher model. Concretely, the pointwise loss does not consider the relative item orders for items within the same list and treats each item independently based on the i.i.d. assumption. However, data in recommendation tasks are non-i.i.d. [9, 48], where the click probability of an item is affected by other items in the same list [25, 39]. Therefore, it is insufficient for the pointwise loss to learn from the teacher model in CTR prediction. Some listwise losses [9, 38, 48] have been proposed to optimize the model with each list as a learning instance, thus naturally accounting for the information of the relative item orders. However, although the direct utilization of typical listwise losses can improve the model's ranking ability over the pointwise one, it causes the student model's predictions to lose probabilistic meaning as pCTR, destroying the model's calibration ability. This issue is unacceptable for CTR prediction and thus poses the second challenge . 3.3.2 Calibration-compatible Listwise Distillation. To address the above two challenges, inspired by RCR [5], we first formally define the calibration-compatible property of the distillation loss and analyze the calibration-compatible property of the pointwise loss and the commonly used listwise losses. We then give our solutions to design the calibration-compatible listwise distillation loss. Definition 1. A distillation loss \ud835\udc3f \ud835\udc51 is calibration-compatible if it can achieve global minima when the PointCE losses of both student and teacher model achieve global minima for any candidate item \ud835\udc65 \ud835\udc56 . We can easily prove the pointwise distillation loss is calibrationcompatible. To be specific, for each list \ud835\udc5e , let \ud835\udc43 \ud835\udc56 = E [ \ud835\udc66 \ud835\udc56 | \ud835\udc5e, \ud835\udc65 \ud835\udc56 ] be the ground truth click probability conditioned on sample \ud835\udc65 \ud835\udc56 . Assume that we draw \ud835\udc5b \ud835\udc56 samples \ud835\udc65 \ud835\udc58 \ud835\udc56 of \ud835\udc65 \ud835\udc56 from its true label distribution \ud835\udc4c \ud835\udc56 , with \ud835\udc66 \ud835\udc58 \ud835\udc56 as the label of the \ud835\udc58 -th sample. We can see that the PointCE loss is minimized when \u02c6 \ud835\udc5d \ud835\udc60,\ud835\udc56 = \u02dd \ud835\udc5b \ud835\udc56 \ud835\udc58 \ud835\udc66 \ud835\udc58 \ud835\udc56 / \ud835\udc5b \ud835\udc56 , \u02c6 \ud835\udc5d \ud835\udc61,\ud835\udc56 = \u02dd \ud835\udc5b \ud835\udc56 \ud835\udc58 \ud835\udc66 \ud835\udc58 \ud835\udc56 / \ud835\udc5b \ud835\udc56 , where \u02dd \ud835\udc5b \ud835\udc56 \ud835\udc58 \ud835\udc66 \ud835\udc58 \ud835\udc56 / \ud835\udc5b \ud835\udc56 = E [ \ud835\udc66 \ud835\udc56 | \ud835\udc5e, \ud835\udc65 \ud835\udc56 ] with \ud835\udc5b \ud835\udc56 \u2192 +\u221e . Therefore, the PointCE losses of the student and teacher model are calibrated and can always achieve the global minima [50] simultaneously when  For the pointwise distillation loss in Eq. (9), it is minimized when \u02c6 \ud835\udc5d \ud835\udc60,\ud835\udc56 = \u02c6 \ud835\udc5d \ud835\udc61,\ud835\udc56 and thus obviously satisfies the calibration-compatible property. Take the commonly used listwise loss ListNet [9] as an example, we prove it is not calibration-compatible when employed as distillation loss:  where \ud835\udc5b is the number of items for the list containing \ud835\udc65 \ud835\udc56 . By the rules of differentiation, we can know that the ListNet distillation loss achieves global minima when  From Eq. (10) and Eq. (12), we can observe that \ud835\udc3f \ud835\udc3f\ud835\udc56\ud835\udc60\ud835\udc61\ud835\udc41\ud835\udc52\ud835\udc61 \ud835\udc51 is not minimized (i.e., exp ( \ud835\udc60 \ud835\udc60,\ud835\udc56 ) \u2260 \ud835\udc43 \ud835\udc56 , for \ud835\udc56 = 1 . . . \ud835\udc5b ) when both the PointCE losses of the student and teacher model achieve global minima, thus not satisfying the calibration-compatible property. In addition, if another popular listwise loss ListMLE [48] is employed as distillation loss:  where \ud835\udf0b \ud835\udc56 represents the sample \ud835\udc65 \ud835\udf0b \ud835\udc56 ranked at position \ud835\udc56 in the predictions generated by the teacher model, sorted in descending order. Wecan observe that \ud835\udc3f \ud835\udc3f\ud835\udc56\ud835\udc60\ud835\udc61\ud835\udc40\ud835\udc3f\ud835\udc38 \ud835\udc51 is formulated through likelihood loss that does not have a global minima during optimization, and thus it is also not calibration-compatible. Indeed, widely used listwise losses are designed to improve the model's ranking ability without additional consideration for the calibration-compatible property when employed as the distillation loss, thus pushing the logits to fit different objectives and corrupting the model's calibration ability. To enable the listwise distillation loss calibration-compatible, we propose a novel privileged features distillation framework, Calibrationcompatible LIstwise Distillation (CLID), which distills the ranking ability from the teacher model while preserving the student model's calibration ability. In detail, we project \u02c6 \ud835\udc5d \ud835\udc61,\ud835\udc56 and \u02c6 \ud835\udc5d \ud835\udc60,\ud835\udc56 onto the probability simplex to form the ground-truth distribution \ud835\udc43 \ud835\udc61 ( \ud835\udc65 \ud835\udc56 ) and the score distribution \ud835\udc43 \ud835\udc60 ( \ud835\udc65 \ud835\udc56 ) as follows:  These probabilities encode the likelihood of sample \ud835\udc65 \ud835\udc56 appearing at the top of the ranked list. Given these two distributions, we use the cross entropy loss to penalize the difference between them and obtain the calibration-compatible listwise distillation loss :  We can prove the distillation loss formulation in Eq. (15) is calibration-compatible. Specifically, by the rules of differentiation, the distillation loss can achieve the global minima when  From Eq. (10) and Eq. (16), we can observe that when the PointCE losses of the student and teacher model achieve global minima, the distillation loss \ud835\udc3f \ud835\udc36\ud835\udc3f\ud835\udc3c\ud835\udc37 \ud835\udc51 is also minimized. Therefore, this tailored distillation loss is calibration-compatible and can preserve the student model's calibration ability when distilling the teacher model's ranking ability.", "4 EXPERIMENT": "In this section, we conduct an extensive amount of experiments to understand the effectiveness of CLID over various baselines.", "4.1 Experiment Setup": "4.1.1 Datasets. To demonstrate the generalization of CLID, our experiments are conducted on two widely-adopted public datasets WSDM'24, March 4-8, 2024, Merida, Mexico Xiaoqiang Gui et al. and one production dataset. The public datasets are two popular LTR datasets, Web30K and Istella-S, with multi-graded labels ranging from 0 (irrelevant) to 4 (perfectly relevant). Following previous works [5, 7, 50], we binarize the labels (labels 1, 2, 3, 4 as 1, label 0 as 0) for the CTR prediction task. Since the public datasets lack the position feature, we utilize contextual features as privileged features. Specifically, in industrial recommendation systems, CTR models of the ranking and re-ranking stages are both trained with the exposed items to users. Therefore, we use the public datasets to simulate the training and serving process of the ranking stage, where the features regarding contextual documents of the candidate document in the same query are privileged features, which are inaccessible for the ranking model when testing. For convenience, we utilize the mean pooling operation on contextual features to obtain privileged representation vectors for all methods. Both public datasets contain training, validation, and test set. Final model evaluation is performed on the test set. The experiments on the public datasets are repeated for 5 trials, and the mean metrics and 95% confidence intervals are reported. For consistency, we also employ contextual features as privileged features to train the ranking model in the production dataset. Web30K 1 [36]. Web30K is a public LTR dataset, including 31,531 queries split into training, validation, and test partitions with 18,919, 6,306, and 6,306 queries, respectively. On average, about 119 candidate documents are associated with each query, where querydocument pairs are represented by 136 numerical features and graded with a 5-level relevance label. After binarized, the percentages for labels 0 and 1 are 51.4% and 48.6%, respectively. Istella-S 2 [32]. Istella-S is also a public LTR dataset composed of 33,018 queries and 220 features representing each query-document pair. It has, on average, about 103 candidate documents associated with each query. After binarized, the percentages for labels 0 and 1 are 82.1% and 17.9%. Production. The production dataset is sampled from the impression log of the Alibaba online advertising system. Specifically, the impression and click data from 2022/11/16 and 2022/11/17 are adopted for training and testing. We train the model by hours and test it in the next hour, similar to the system's online activity. The dataset consists of billions of samples with hundreds of features. 4.1.2 Baselines. We utilize six baseline methods for a comprehensive comparison. We first involve recent non-PFD (PAL and PriDropOut) methods to show the generalization of CLID. We then compare the state-of-the-art PFD methods involving the mainstream pointwise-based PFD method and our extended listwisebased PFD methods with the commonly used listwise losses (ListMLE and ListNet) as distillation losses to show the superiority of CLID in both ranking and calibration performance. The details of these baselines are listed as follows: (i) Base: It takes the non-privileged features as input and is optimized by the PointCE loss. The Base method is the one deployed in our production system. (ii) PriDropOut [54]: It constructs a shallow tower using privileged features as input. After applying a dropout layer, its logits 1 https://www.microsoft.com/en-us/research/project/mslr/ 2 http://quickrank.isti.cnr.it/istella-dataset/ are added to the main tower's logits to compute pCTR during training. During testing, the shallow tower is discarded, and pCTR is computed by the logits of the main tower. (iii) PAL [19]: It calculates the pCTR by multiplying the probability score of the shallow tower with privileged features and the main tower with non-privileged features when training. During testing, only the probability score of the main tower serves as pCTR. (iv) Base+Pointwise [30, 49, 51]: It employs the PFD framework to improve model performance, where the teacher model takes the non-privileged and privileged features as input. The distillation loss is the pointwise loss in Eq. (9). (v) Base+ListMLE: It employs the PFD framework to distill the privileged features from the teacher model, with Eq. (13) as the distillation loss. (vi) Base+ListNet: It employs the PFD framework to distill the privileged features from the teacher model with Eq. (11) as the distillation loss. Our proposed CLID adopts Eq. (15) as the distillation loss. 4.1.3 Evaluation Metrics. Following previous works [5, 7, 50], for ranking performance on the public datasets, we adopt the widely used NDCG@10 as the evaluation metric. The higher the NDCG@10 is, the better the ranking performance is. As to the production dataset, we compute the GAUC (Group Area Under Receiver Operating Characteristic Curve) metric to evaluate the ranking performance. GAUC has shown to be more consistent with the online performance [6, 39, 40, 60, 61] and is also the top-line metric in our production system. It can be calculated with Eq. (17), where \ud835\udc48 is the number of users, #impression( \ud835\udc62 ) and AUC \ud835\udc62 are the number of impressions and AUC of the \ud835\udc62 -th user, respectively.  To measure the calibration performance, we employ the widely used averaged LogLoss for public and production datasets, following [5, 10, 18, 50]. The LogLoss measures the sample-level calibration error, defined in Eq. (18), where \ud835\udc41 is the number of samples. The expected calibration error ( ECE ) is additionally compared on public datasets. Following [50], for the computation of ECE, we sort the documents by model predictions and divide them into \ud835\udc3e bins, each containing approximately the same number of documents. It is defined in Eq. (19), where \ud835\udc44 is the number of lists, \ud835\udc5b \ud835\udc5e and \ud835\udc5b \ud835\udc5e,\ud835\udc58 are the number of samples in list \ud835\udc5e and bin \ud835\udc58 of list \ud835\udc5e , \ud835\udc66 \ud835\udc5e,\ud835\udc58,\ud835\udc56 and \u02c6 \ud835\udc5d \ud835\udc5e,\ud835\udc58,\ud835\udc56 represent the true label and pCTR of the \ud835\udc56 -th sample in the \ud835\udc58 -th bin of the list \ud835\udc5e , respectively. Here we set \ud835\udc3e = 10. The lower the LogLoss and ECE are, the better the performance is.   4.1.4 Implementation Details. We conduct experiments on public datasets using the PT-Ranking library [52]. The codes of public datasets can be found in this link. 3 Specifically, we fixed the neural 3 https://www.sdu-idea.cn/codes.php?name=CLID Calibration-compatible Listwise Distillation of Privileged Features for CTR Prediction WSDM'24, March 4-8, 2024, Merida, Mexico Table 1: A comparison of model performance (95% confidence intervals) for different methods on two widely-used public datasets. The mean results are reported on the test set. The best results are highlighted in boldface. \u25e6/\u00b7 indicates that CLID is statistically worse/better than the compared method by student pairwise \ud835\udc61 -test at 95% confidence level. 0 20 40 60 80 100 Epoch 0.64 0.65 0.66 0.67 0.68 0.69 0.70 0.71 NDCG@10 Base Base+Pointwise SD (CLID) PFD (CLID)", "4.2 Performance on Public Datasets": "Figure 3: A comparison of the Base, Base+Pointwise, selfdistillation (SD), and privileged features distillation (PFD) methods on the Istella-S dataset. ranking model for all compared methods to be a three-layer Dense Neural Network (DNN) whose hidden layer dimensions are 1024, 512, and 256. For PriDropOut and PAL, the shallow tower contains one layer with 256 hidden units. We apply the input transformation log 1 \ud835\udc5d ( \ud835\udc65 ) = \ud835\udc60\ud835\udc56\ud835\udc54\ud835\udc5b ( \ud835\udc65 ) log ( 1 + | \ud835\udc65 |) , batch normalization, weight decay and dropout. The dropout rate in training is set to be 0 . 5 and the weight decay is set to be 0 . 001. The learning rate is tuned for each method at the validation set. For distillation baselines, the hyperparameters of the student model keep the same as the teacher model to ensure that the change in performance comes from the distillation. For the coefficient of distillation loss \ud835\udefc , we experiment with the weight ratio ( 1 -\ud835\udefc )/ \ud835\udefc rather than a direct tuning of \ud835\udefc . The weight ratio is searched in the range of { 0 . 001 , 0 . 01 , 0 . 1 , 1 , 10 , 100 , 1000 , 10000 } . The impact of the weight ratio is analyzed in later experiments. For the Base+Pointwise method, we also search \ud835\udf0f in the range of { 0 . 001 , 0 . 01 , 0 . 1 , 1 , 10 , 100 , 1000 , 10000 } . To balance ranking and calibration, the weight ratio of Base+ListMLE is set to be 0 . 01 on the Web30K dataset and 10 on the Istella-S dataset. The weight ratio of Base+ListNet is set to be 100 on the Web30K dataset and 10 on the Istella-S dataset. The weight ratio of CLID is set to be 1 on the Web30K dataset and 100 on the Istella-S dataset. The Base+Pointwise method's weight ratio and \ud835\udf0f are 10 and 1 on the Web30K dataset, and 1 and 1 on the Istella-S dataset. On the production dataset, we utilize DIN [60] as the neural network structure for all methods. For the distillation methods on the public datasets, we first train the teacher model before distillation and then fix the converged teacher model to instruct the student model. For production scenarios, due to the huge amount of data, the teacher and student models are updated simultaneously with distillation loss. 4.2.1 Overall Performance. We report results on the test set to demonstrate the superiority of CLID in both ranking and calibration performance. All methods are trained with 100 epochs following [5, 50, 51]. Table 1 provides the model performance for all the compared methods, and the following observations can be made: (i) Listwise-based PFD methods consistently outperform the pointwisebased PFD method in ranking performance. The fact demonstrates that the listwise distillation loss can account for the non-i.i.d. characteristic of data distribution, learning the teacher model's relative item order. Therefore they can distill more ranking ability from the teacher model than the pointwise one. However, the Base+ListMLE and Base+ListNet methods have compromised calibration performance. This is because the listwise distillation loss in them does not satisfy the calibration-compatible property, thus destroying the probabilistic meaning of the model's predictions as pCTR. (ii) CLID achieves the best ranking performance among all compared methods while ensuring that the model's calibration performance remains equal to or surpasses that of the Base method. The observation confirms that the carefully-designed listwise distillation loss in CLID behaves well on distilling the listwise information to improve the model's ranking ability while being calibrationcompatible, thereby preserving the meaning of the model's scores as pCTR. We further observe that the calibration of CLID is better than the Base in the Web30K dataset. We hypothesize that the improved ranking ability may further boost the calibration ability due to the calibration-compatible property. (iii) The PFD methods effectively maintain the model's generalization by preserving the offline-online consistency. This is supported by the unstable ranking performance and destroyed calibration performance of the non-PFD (PAL and PriDropOut) methods. These two non-PFD methods incorporate the shallow tower at training and discard it to compute pCTR at testing, resulting in the inconsistency of pCTR between training and serving. On the one hand, the inconsistency comprises the probabilistic meaning of the model's predictions, often causing huge calibration degradation; on the other hand, it improves the ranking performance without a theoretical guarantee, such that the methods are not always effective, e.g., the degradation of ranking performance for the PriDropOut method in the Web30K dataset. The above analyses demonstrate CLID can significantly improve the model's ranking ability while preserving its calibration ability. WSDM'24, March 4-8, 2024, Merida, Mexico Xiaoqiang Gui et al. Figure 4: The impact of weight ratio in CLID about the ranking and calibration ability on the Web30K and Istella-S datasets. 0.001 0.01 0.1 1 10 100 100010000 (1 ) / 0.436 0.440 0.444 0.448 0.452 NDCG@10 0.620 0.618 0.616 0.614 0.612 0.610 0.608 Web30K 0.001 0.01 0.1 1 10 100 100010000 (1 ) / 0.67 0.68 0.69 0.70 0.71 0.72 0.73 0.74 NDCG@10 0.180 0.168 0.156 0.144 0.132 0.120 0.108 -LogLoss Istella-S -LogLoss 4.2.2 Ablation Study. In this section, we aim to explore the source of CLID's effectiveness in improving ranking performance. We hypothesize that listwise distillation loss, privileged features distillation, and knowledge distillation are essential in CLID. To verify the effect of listwise distillation loss, we utilize the Base+Pointwise method as a comparison. We adopt self-distillation (SD) as a comparison to show the effect of privileged features distillation. The teacher model of SD only takes the non-privileged features as input and uses the same listwise distillation loss as CLID. We call this method SD (CLID). Finally, Base is employed to show the effect of knowledge distillation. We plot the NDCG@10 metric calculated on validation data for 100 epochs, and the results on the Istella-S dataset are shown in Figure. 3. From the figure, we can observe that all distillation methods perform better than Base, demonstrating the effectiveness of knowledge distillation. In addition, as the training epochs increase, Base has an over-fitting problem (the performance begins to decline after 60 epochs of training), which can be solved by knowledge distillation, as shown in the figure. Further, we observe that PFD (CLID) achieves better performance than the Base+Pointwise method and SD (CLID) method. These two facts demonstrate the effect of listwise distillation loss and privileged features distillation, respectively. Therefore, we can conclude that CLID's ranking improvements come from listwise distillation loss, privileged features distillation, and knowledge distillation. 4.2.3 Impact of Weight Ratio. In this section, we study the impact of the weight ratio ( 1 -\ud835\udefc )/ \ud835\udefc in CLID on the ranking and calibration ability. To this end, we examine the weight ratio in { 0 . 001 , 0 . 01 , 0 . 1 , 1 , 10 , 100 , 1000 , 10000 } . The higher the weight ratio is, the more dominative the listwise distillation loss is. We plot the NDCG@10 and -LogLoss metrics evaluated on test data for each weight ratio on the Web30K and Istella-S datasets, as shown in Figure. 4. The higher the metric value is, the better the performance is. We observe the ranking and calibration performance gradually rise and then decrease on both datasets. We hypothesize that a large weight ratio, on the one hand, weakens the effect of PointCE loss, which uses the click label as ground truth and thus contributes significantly to the calibration; on the other hand, it makes the student model learn some noise from the teacher model and therefore cannot achieve the optimal ranking performance. Generally, CLID can achieve a proper trade-off between the ranking and calibration performance with the weight ratio ranging from 1 to 100.", "4.3 Performance on Production Dataset": "4.3.1 Overall Performance. In the production dataset, we employ the methods mentioned above as baselines. All methods are trained with one epoch following [55]. Note that for proprietary reasons, Table 2: A comparison of model relative improvements to the Base method for different methods in the production. The best results are highlighted in bold. we only report relative numbers to our baseline (the Base method) with respect to the GAUC for ranking and LogLoss for calibration. The results are reported in Table 2, and we can observe that the conclusions on the production dataset are aligned well with those on the public datasets: (i) Listwise-based PFD methods consistently obtain significant ranking improvements over the pointwise-based PFD method, again validating the power of listwise distillation loss on learning from the teacher model. (ii) The listwise-based PFD methods cause significant calibration degradation except for CLID. This is because only the listwise distillation loss of CLID is calibration-compatible among them and thus preserving the calibration ability. The CLID's slight increase in LogLoss might be that the added listwise loss causes the model to require more training steps for convergence than Base. (iii) PriDropOut and PAL hurt the model's generalization. To be specific, PriDropOut and PAL have huge calibration degradation due to inconsistent data distribution during training and serving. PriDropOut performs well, but PAL has no effect since the ranking improvements lack a theoretical guarantee. These results again demonstrate CLID can significantly improve the model's ranking ability while preserving its calibration ability.", "5 CONCLUSION AND DISCUSSION": "This research studies the ways of incorporating privileged features for CTR prediction. Previous works mainly include the non-PFD and PFD methods. The former can cause training-serving inconsistency and hurt the model's generalization, while the latter adopts the pointwise distillation loss that is unsuitable for CTR prediction since it fails to consider the non-i.i.d. characteristic of the data distribution. To address these issues, we first extend the pointwisebased PFD to the listwise-based PFD and show the commonly used listwise losses can compromise the model's calibration ability. We then propose a Calibration-compatible LIstwise Distillation (CLID) method that employs a calibration-compatible listwise distillation loss to distill the teacher model's ranking ability without destroying the model's calibration ability. Both theory and experiment demonstrate the effectiveness of CLID.", "ACKNOWLEDGMENTS": "This work is supported by the National Key Research and Development Program of China under Grant 2022YFC3502101, National Natural Science Foundation of China (No. 62072380 and 62272276), Taishan Scholar Program of Shandong Province in China, and Alibaba Group through Alibaba Innovation Research Program. Calibration-compatible Listwise Distillation of Privileged Features for CTR Prediction WSDM'24, March 4-8, 2024, Merida, Mexico", "REFERENCES": "[1] Qingyao Ai, Keping Bi, Jiafeng Guo, and W Bruce Croft. 2018. Learning a deep listwise context model for ranking refinement. In SIGIR . 135-144. [2] Qingyao Ai, Keping Bi, Cheng Luo, Jiafeng Guo, and W Bruce Croft. 2018. Unbiased learning to rank with unbiased propensity estimation. In SIGIR . 385-394. [3] Qingyao Ai, Xuanhui Wang, Sebastian Bruch, Nadav Golbandi, Michael Bendersky, and Marc Najork. 2019. Learning groupwise multivariate scoring functions using deep neural networks. In SIGIR . 85-92. [4] Qingyao Ai, Tao Yang, Huazheng Wang, and Jiaxin Mao. [n. d.]. Unbiased learning to rank: online or offline? TOIS ([n. d.]). [5] Aijun Bai, Rolf Jagerman, Zhen Qin, Le Yan, Pratyush Kar, Bing-Rong Lin, Xuanhui Wang, Michael Bendersky, and Marc Najork. 2023. Regression Compatible Listwise Objectives for Calibrated Ranking with Binary Relevance. In CIKM . 4502-4508. [6] Weijie Bian, Kailun Wu, Lejian Ren, Qi Pi, Yujing Zhang, Can Xiao, Xiang-Rong Sheng, Yong-Nan Zhu, Zhangming Chan, Na Mou, et al. 2022. CAN: feature co-action network for click-through rate prediction. In WSDM . 57-65. [7] Sebastian Bruch, Shuguang Han, Michael Bendersky, and Marc Najork. 2020. A stochastic treatment of learning to rank scoring functions. In WSDM . 61-69. [8] Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Greg Hullender. 2005. Learning to rank using gradient descent. In ICML . 89-96. [9] Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. 2007. Learning to rank: from pairwise approach to listwise approach. In ICML . 129-136. [10] Zhangming Chan, Yu Zhang, Shuguang Han, Yong Bai, Xiang-Rong Sheng, Siyuan Lou, Jiacen Hu, Baolin Liu, Yuning Jiang, Jian Xu, et al. 2023. Capturing Conversion Rate Fluctuation during Sales Promotions: A Novel Historical Data Reuse Approach. In KDD . 1-11. [11] Sougata Chaudhuri, Abraham Bagherjeiran, and James Liu. 2017. Ranking and calibrating click-attributed purchases in performance display advertising. In KDD . 1-6. [12] Mouxiang Chen, Chenghao Liu, Jianling Sun, and Steven CH Hoi. 2021. Adapting interactional observation embedding for counterfactual learning to rank. In SIGIR . 285-294. [13] Wei Chen, Tie-Yan Liu, Yanyan Lan, Zhiming Ma, and Hang Li. 2009. Ranking measures and loss functions in learning to rank. In NeurIPS . 315-323. [14] David Cossock and Tong Zhang. 2008. Statistical analysis of Bayes optimal subset ranking. IEEE Transactions on Information Theory 54, 11 (2008), 5140-5154. [15] Zhifang Fan, Dan Ou, Yulong Gu, Bairan Fu, Xiang Li, Wentian Bao, Xin-Yu Dai, Xiaoyi Zeng, Tao Zhuang, and Qingwen Liu. 2022. Modeling users' contextualized page-wise feedback for click-through rate prediction in e-commerce search. In WSDM . 262-270. [16] Jingyue Gao, Shuguang Han, Han Zhu, Siran Yang, Yuning Jiang, Jian Xu, and Bo Zheng. 2023. Rec4Ad: A Free Lunch to Mitigate Sample Selection Bias for Ads CTR Prediction in Taobao. CIKM (2023). [17] Thore Graepel, Klaus Obermayer, et al. 2000. Large margin rank boundaries for ordinal regression. In Advances in large margin classifiers . 115-132. [18] Siyu Gu, Xiang-Rong Sheng, Ying Fan, Guorui Zhou, and Xiaoqiang Zhu. 2021. Real negatives matter: continuous training with real negatives for delayed feedback modeling. In KDD . 2890-2898. [19] Huifeng Guo, Jinkai Yu, Qing Liu, Ruiming Tang, and Yuzhou Zhang. 2019. PAL: a position-bias aware learning framework for CTR prediction in live recommender systems. In RecSys . 452-456. [20] Malay Haldar, Prashant Ramanathan, Tyler Sax, Mustafa Abdool, Lanbo Zhang, Aamir Mansawala, Shulin Yang, Bradley Turnbull, and Junshuo Liao. 2020. Improving deep learning for airbnb search. In KDD . 2822-2830. [21] Shuguang Han, Xuanhui Wang, Mike Bendersky, and Marc Najork. 2020. Learning-to-Rank with BERT in TF-Ranking. arXiv preprint arXiv:2004.08476 (2020). [22] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Delving deep into rectifiers: surpassing human-level performance on imagenet classification. In ICCV . 1026-1034. [23] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. 2015. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531 (2015). [24] Katja Hofmann, Anne Schuth, Shimon Whiteson, and Maarten De Rijke. 2013. Reusing historical interaction data for faster online learning to rank for IR. In WSDM . 183-192. [25] Jianqiang Huang, Xingyuan Tang, Zhe Wang, Shaolin Jia, Yin Bai, Zhiwei Liu, Jia Cheng, Jun Lei, and Yan Zhang. 2022. Deep presentation bias integrated framework for CTR prediction. In CIKM . 4049-4053. [26] Wonkyung Lee, Junghyup Lee, Dohyung Kim, and Bumsub Ham. 2020. Learning with privileged information for efficient image super-resolution. In ECCV . 465482. [27] Ping Li, Christopher J. C. Burges, and Qiang Wu. 2007. McRank: learning to rank using multiple classification and gradient boosting. In NeurIPS . 897-904. [28] Xiang Li, Shuwei Chen, Jian Dong, Jin Zhang, Yongkang Wang, Xingxing Wang, and Dong Wang. 2023. Decision-making context interaction network for clickthrough rate prediction. AAAI (2023). [29] Xiaoliang Ling, Weiwei Deng, Chen Gu, Hucheng Zhou, Cui Li, and Feng Sun. 2017. Model ensemble for click prediction in bing search ads. In Web Conf . 689-698. [30] Congcong Liu, Yuejiang Li, Jian Zhu, Fei Teng, Xiwei Zhao, Changping Peng, Zhangang Lin, and Jingping Shao. 2022. Position awareness modeling with knowledge distillation for CTR prediction. In RecSys . 562-566. [31] David Lopez-Paz, L\u00e9on Bottou, Bernhard Sch\u00f6lkopf, and Vladimir Vapnik. 2016. Unifying distillation and privileged information. In ICLR . 1-12. [32] Claudio Lucchese, Franco Maria Nardini, Salvatore Orlando, Raffaele Perego, Fabrizio Silvestri, and Salvatore Trani. 2016. Post-learning optimization of tree ensembles for efficient ranking. In SIGIR . 949-952. [33] Zelun Luo, Jun-Ting Hsieh, Lu Jiang, Juan Carlos Niebles, and Li Fei-Fei. 2018. Graph distillation for action detection with privileged modalities. In ECCV . 166183. [34] Rama Kumar Pasumarthi, Honglei Zhuang, Xuanhui Wang, Michael Bendersky, and Marc Najork. 2020. Permutation equivariant document interaction network for neural learning to rank. In ICTIR . 145-148. [35] Changhua Pei, Yi Zhang, Yongfeng Zhang, Fei Sun, Xiao Lin, Hanxiao Sun, Jian Wu, Peng Jiang, Junfeng Ge, Wenwu Ou, et al. 2019. Personalized re-ranking for recommendation. In RecSys . 3-11. [36] Tao Qin and Tie-Yan Liu. 2013. Introducing LETOR 4.0 datasets. arXiv preprint arXiv:1306.2597 (2013). [37] Tao Qin, Tie-Yan Liu, and Hang Li. 2010. A general approximation framework for direct optimization of information retrieval measures. Information Retrieval 13 (2010), 375-397. [38] Tao Qin, Xu-Dong Zhang, Ming-Feng Tsai, De-Sheng Wang, Tie-Yan Liu, and Hang Li. 2008. Query-level loss functions for information retrieval. Information Processing & Management 44, 2 (2008), 838-855. [39] Xiang-Rong Sheng, Jingyue Gao, Yueyao Cheng, Siran Yang, Shuguang Han, Hongbo Deng, Yuning Jiang, Jian Xu, and Bo Zheng. 2023. Joint optimization of ranking and calibration with contextualized hybrid model. In KDD . [40] Xiang-Rong Sheng, Liqin Zhao, Guorui Zhou, Xinyao Ding, Binding Dai, Qiang Luo, Siran Yang, Jingshan Lv, Chi Zhang, Hongbo Deng, et al. 2021. One model to serve all: Star topology adaptive recommender for multi-domain ctr prediction. In CIKM . 4104-4113. [41] Masashi Sugiyama, Matthias Krauledat, and Klaus-Robert M\u00fcller. 2007. Covariate shift adaptation by importance weighted cross validation. JMLR 8 (2007), 9851005. [42] Adith Swaminathan and Thorsten Joachims. 2015. Batch learning from logged bandit feedback through counterfactual risk minimization. JMLR 16, 1 (2015), 1731-1755. [43] Vladimir Vapnik, Rauf Izmailov, et al. 2015. Learning using privileged information: similarity control and knowledge transfer. JMLR 16, 1 (2015), 2023-2049. [44] Shangfei Wang, Yachen Zhu, Lihua Yue, and Qiang Ji. 2015. Emotion recognition with the help of privileged information. IEEE Transactions on Autonomous Mental Development 7, 3 (2015), 189-200. [45] Xuanhui Wang, Michael Bendersky, Donald Metzler, and Marc Najork. 2016. Learning to rank with selection bias in personal search. In SIGIR . 115-124. [46] Xuanhui Wang, Nadav Golbandi, Michael Bendersky, Donald Metzler, and Marc Najork. 2018. Position bias estimation for unbiased learning to rank in personal search. In WSDM . 610-618. [47] Kailun Wu, Weijie Bian, Zhangming Chan, Lejian Ren, Shiming Xiang, ShuGuang Han, Hongbo Deng, and Bo Zheng. 2022. Adversarial gradient driven exploration for deep click-through rate prediction. In KDD . 2050-2058. [48] Fen Xia, Tie-Yan Liu, Jue Wang, Wensheng Zhang, and Hang Li. 2008. Listwise approach to learning to rank: theory and algorithm. In ICML . 1192-1199. [49] Chen Xu, Quan Li, Junfeng Ge, Jinyang Gao, Xiaoyong Yang, Changhua Pei, Fei Sun, Jian Wu, Hanxiao Sun, and Wenwu Ou. 2020. Privileged features distillation at Taobao recommendations. In KDD . 2590-2598. [50] Le Yan, Zhen Qin, Xuanhui Wang, Michael Bendersky, and Marc Najork. 2022. Scale calibration of deep ranking models. In KDD . 4300-4309. [51] Shuo Yang, Sujay Sanghavi, Holakou Rahmanian, Jan Bakus, and SVN Vishwanathan. 2022. Toward understanding privileged features distillation in learningto-rank. In NeurIPS . 1-12. [52] Hai-Tao Yu. 2020. PT-ranking: A benchmarking platform for neural learning-torank. arXiv preprint arXiv:2008.13368 (2020). [53] Yujing Zhang, Zhangming Chan, Shuhao Xu, Weijie Bian, Shuguang Han, Hongbo Deng, and Bo Zheng. 2022. KEEP: An industrial pre-training framework for online recommendation via knowledge extraction and plugging. In CIKM . 3684-3693. [54] Yunan Zhang, Le Yan, Zhen Qin, Honglei Zhuang, Jiaming Shen, Xuanhui Wang, Michael Bendersky, and Marc Najork. 2023. Towards Disentangling Relevance and Bias in Unbiased Learning to Rank. In KDD . 5618-5627. [55] Zhao-Yu Zhang, Xiang-Rong Sheng, Yujing Zhang, Biye Jiang, Shuguang Han, Hongbo Deng, and Bo Zheng. 2022. Towards understanding the overfitting phenomenon of deep click-through rate models. In CIKM . 2671-2680. WSDM'24, March 4-8, 2024, Merida, Mexico Xiaoqiang Gui et al. [56] Yunfeng Zhao, Xu Yan, Xiaoqiang Gui, Shuguang Han, Xiang-Rong Sheng, Guoxian Yu, Jufeng Chen, Zhao Xu, and Bo Zheng. 2023. Entire Space Cascade Delayed Feedback Modeling for Effective Conversion Rate Prediction. In CIKM . 49814987. [57] Zhishan Zhao, Jingyue Gao, Yu Zhang, Shuguang Han, Siyuan Lou, Xiang-Rong Sheng, Zhe Wang, Han Zhu, Yuning Jiang, Jian Xu, et al. 2023. COPR: ConsistencyOriented Pre-Ranking for Online Advertising. CIKM (2023). [58] Zhe Zhao, Lichan Hong, Li Wei, Jilin Chen, Aniruddh Nath, Shawn Andrews, Aditee Kumthekar, Maheswaran Sathiamoorthy, Xinyang Yi, and Ed Chi. 2019. Recommending what video to watch next: a multitask ranking system. In RecSys . 43-51. [59] Zhi Zheng, Zhaopeng Qiu, Tong Xu, Xian Wu, Xiangyu Zhao, Enhong Chen, and Hui Xiong. 2022. CBR: context bias aware recommendation for debiasing user modeling and click prediction. In Web Conf . 2268-2276. [60] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In KDD . 1059-1068. [61] Han Zhu, Junqi Jin, Chang Tan, Fei Pan, Yifan Zeng, Han Li, and Kun Gai. 2017. Optimized cost per click in taobao display advertising. In KDD . 2191-2200."}
