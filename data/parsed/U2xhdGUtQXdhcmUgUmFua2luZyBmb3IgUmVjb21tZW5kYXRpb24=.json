{
  "Slate-Aware Ranking for Recommendation": "Yi Ren ∗† Tencent Beijing, China henrybjren@tencent.com Xiao Han ∗ Tencent Beijing, China alisahan@tencent.com Xu Zhao Tencent Beijing, China xuzzzhao@tencent.com Shenzheng Zhang Tencent Beijing, China qjzcyzhang@tencent.com Yan Zhang Tencent Beijing, China zyzn5288@126.com",
  "ABSTRACT": "We see widespread adoption of slate recommender systems, where an ordered item list is fed to the user based on the user interests and items' content. For each recommendation, the user can select one or several items from the list for further interaction. In this setting, the significant impact on user behaviors from the mutual influence among the items is well understood [1, 3, 4, 1012, 14, 19, 22, 26, 27, 33, 36, 42, 46]. The existing methods add another step of slate re-ranking after the ranking stage of recommender systems, which considers the mutual influence among recommended items to re-rank and generate the recommendation results so as to maximize the expected overall utility. However, to model the complex interaction of multiple recommended items, the re-ranking stage usually can just handle dozens of candidates because of the constraint of limited hardware resource and system latency. Therefore, the ranking stage is still essential for most applications to provide high-quality candidate set for the re-ranking stage. In this paper, we propose a solution named Slate-Aware ranking ( SAR ) for the ranking stage. By implicitly considering the relations among the slate items, it significantly enhances the quality of the re-ranking stage's candidate set and boosts the relevance and diversity of the overall recommender systems. Both experiments with the public datasets 1 and internal online A/B testing are conducted to verify its effectiveness.",
  "CCS CONCEPTS": "· Information systems → Recommender systems .",
  "KEYWORDS": "Slate Recommendation; Ranking; Re-Ranking; Recommender Systems; Multi-Task Learning; Privileged Information; Distillation ∗ Both authors contributed equally to this research. † Corresponding author. 1 Code link is: https://github.com/BestActionNow/Slate_Aware_Ranking Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WSDM '23, February 27-March 3, 2023, Singapore, Singapore © 2023 Association for Computing Machinery. ACM ISBN 978-1-4503-9407-9/23/02...$15.00 https://doi.org/10.1145/3539597.3570380",
  "ACMReference Format:": "Yi Ren, Xiao Han, Xu Zhao, Shenzheng Zhang, and Yan Zhang. 2023. SlateAware Ranking for Recommendation. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (WSDM '23), February 27-March 3, 2023, Singapore, Singapore. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3539597.3570380",
  "1 INTRODUCTION": "In this era of information explosion, recommender systems are useful tools to filter out valuable information for the users and already impact almost every facet of people's lives. Typically, for each user request, recommender systems select a slate of items for presentation from the large candidate set based on its understanding on the user's intention. There are two main reasons for returning a slate of items rather than a single item. First, in many recommendation scenarios, the user can observe multiple items in the screen at once. Moreover, the overload of the recommender systems is greatly alleviated by lowering the QPS (Query-Per-Second) of interactions between the users and system servers. After receiving the recommendation slate, the user can scroll the screen and consume the items relevant to his current interest. A new user request will be issued once the slate of items are all presented. Please refer to the \"watch next recommendation\" scenario on Youtube displayed at the right pane of Figure 1 for a representative slate recommendation scenario. Generally speaking, typical recommender systems take the multistage design and consist of at least two steps [8], namely matching and ranking. For some later systems [35], additional steps, including matching, pre-ranking, ranking and re-ranking, are introduced for better trade-off between recommendation performance and system latency. From matching to re-ranking, more and more powerful models and comprehensive features are utilized yet with a decreasing candidate size. The steps of matching and pre-ranking usually utilize highly efficient methods to filter out relevant items from a vast candidate pool and care coverage more than precision. What's more, with limited hardware resource and system latency, the re-ranking stage normally just handles dozens of candidates by design. Hence, the ranking stage, which selects top tens of items from a pool of hundreds to thousands with high precision, plays an essential role for the recommendation performance. Traditionally, the models in the ranking stage compute a univariate score for each given user-item pair and construct the slate based on the order of item scores [9]. As the top ranked items take more chance to be observed or preferred, the overall efficiency WSDM'23, February 27-March 3, 2023, Singapore, Singapore Yi Ren, Xiao Han, Xu Zhao, Shenzheng Zhang, & Yan Zhang Figure 1: Watch Next Recommendation on Youtube Hey; so the Sennheiser have arrived] h should be optimized in this way if we assume the user's preference for a item is stable. Nevertheless, it is well known that the user interaction and feedback depends on not only the corresponding item's quality and relevance but also the contextual items' impact [1, 3, 4, 10-12, 14, 19, 22, 26, 27, 33, 36, 42, 46]. As a result, the traditional models in the ranking stage, which just accept a given user-item pair's features to learn a uni-variate scoring function, is incapable of taking into account the complex influence exerted by the surrounding items. And the recommendation performance tends to be sub-optimal. To tackle this challenge, various algorithms have been devised and implemented in the re-ranking stage [1, 3, 4, 11, 12, 14, 26, 27, 33, 36, 42, 46]. Acting as the last step after the matching and ranking stage, the re-ranking stage obtains the top ranking items from the ranking stage as candidates and refines into the final recommendation results. Admittedly, these re-ranking methods achieved success in many industrial applications. Nevertheless, to account for the complex relations among the displayed items, these models are usually much more complex than the models in the ranking stage. Considering the limited system latency, the reranking models usually can only handle dozens of items ranked top by the ranking stage. Thus, it is essential for the ranking stage to provide highly relevant yet diverse top item set. Nonetheless, as the ranking stage is oblivious to the overall recommendation list and does not consider the cross item impact, the re-ranking stage are likely to receive unsatisfactory candidate set, thereby negatively affecting the overall performance of recommender systems. There are some challenges for addressing the issue of cross item impact in the ranking stage. In contrast to the re-ranking stage, the ranking stage just provides competitive candidates to the next stage and cannot determine the final recommendation results. Therefore, we cannot use the slate-wise features in the ranking stage for model training. Moreover, with much larger candidate set, it is also infeasible to deploy these sophisticated and time-consuming models used in the re-ranking stage, such as the sequential generation algorithms [4, 14, 46], to the ranking stage. To model the mutual influence among the items of a recommendation slate in the ranking stage, one viable solution is to borrow the ideas from the works of privileged features, which are defined as the features only available for training, and distillation [23, 41]. Besides the base ranking model, a teacher model utilizing both the base ranking features and the slate-wise features can be trained. With knowledge distillation, valuable information can be transferred from the teacher model to the base ranking model served online. But this approach need roughly double the training resources. In addition, without specialized attention to the privileged features, the distillation methods may generate sub-optimal performance, which is verified by our experiment. We propose the method of Slate-Aware Ranking ( SAR ), which utilizes the whole recommendation slate's information during training, for the ranking stage. Specifically, with an encoder network, we construct the slate-wise features based on the whole item sequence in a slate and encode them into the latent space, which is then processed by a decoder network and concatenated to the input of upper ranking modules so as to help to minimize the training loss. Meanwhile, with another encoder network, we also encode the user features to an embedding vector that matches the slate's embedding well. The rationality is that the recommender systems are inclined to recommend results with homogeneous patterns based on the user's previous behaviors, which can be memorized by the user encoder network. As we cannot figure out the actual recommendation slate during prediction, we use the embedding vector from user features instead. The most similar works come from [19, 22], which also encode the information of the whole slate to the latent space. But as a generation model, they can just use the vector-product based DNN model with limited expressive capacity. Previous works [35, 41, 45] have shown the obviously superior performance of incorporating complex deep models over vectorproduct form networks. Moreover, the generative methods show stochastic behavior because of the Reconstruction-Concentration dilemma [22]. Finally, they need input the best reward, which is hard to define for multi-task applications, as a generation condition during inference. We summarize our main contributions below. · We design an effective solution to implicitly model the mutual influence on user behaviors among the slate items in the ranking stage, which generates significantly better recommendation relevance and diversity by boosting the quality of the re-ranking stage's candidate set. · Compared with the distillation and privileged feature methods [23, 41], we achieve significant performance gains with around half training resources. · We conduct extensive offline and online experiments to evaluate and understand the effectiveness of our method. Online A/B testing in one of the world's largest content recommendation platforms shows significant improvement of the business metrics.",
  "2 RELATED WORK": "",
  "2.1 Re-ranking Models for Slate Recommendation": "To model the mutual influence among slate items, various algorithms have been devised and implemented in the re-ranking stage. Acting as the last step after the matching and ranking stage, the reranking stage obtains the top ranking items from the ranking stage as candidates and refines into the final recommendation results. These re-ranking methods can be roughly classified into three categories. The first category comprises the methods of one-step generator , which extract both item-wise features and slate-wise features for each item, predict its relevance score and perform greedy ranking. Though DLCM [1], PRM [27], GSF [3] and SetRank Slate-Aware Ranking for Recommendation WSDM'23, February 27-March 3, 2023, Singapore, Singapore Loss Task Loss Task M Output Task Output Task Backbone Network Embedding Item User eatures veatures (a) Base Model Loss Task Loss Task M Similarity Loss Output Task Output Task Backbone Netwvork Decoder Network Embedding User Encoder Slate Encoder Network Network Embedding Embedding Item User Items of Yeatures veatures Slate (b) SAR Training Figure 2: Model Architecture of SAR [26] leverage different modelling methods, they all belong to this type. Admittedly, for some methods [1], the scoring function may vary based on the permutation of the initial ranking list, all of them [1, 3, 26, 27] are not sensitive to the order of the final recommendation slate. Second, for the methods of sequential generator [4, 14, 46], besides the slate-wise feature extraction and encoding, these methods explicitly model the sequential impact on the current item from the previously chosen ones with uni-directional sequential models, such as LSTM networks [15]. Nonetheless, as a sequential generation model, they have to ignore the current item's influence on the previous ones, which does not adhere to the true distributions. Finally, for the methods of generator and evaluator [11, 12, 33, 36], they initially generate multiple slate candidates with different methods mentioned above and use a separate evaluator model to compute the expected utility of each slate. As the evaluator is able to utilize the bi-directional models, such as bi-directional LSTM and transformer networks [32], they are able to capture both the forward and backward impact among the recommended items so as to ensure better recommendation quality. Please note that there are explicit reasons why we cannot directly apply these algorithms to the ranking stage. First, unlike the re-ranking stage, the ranking stage cannot decide the final recommendation slate. As a result, all of the algorithms with sequential generation function [4, 11, 12, 14, 33, 36, 46], which select the current item based on the previously chosen items, cannot be used at all. Furthermore, many algorithms mentioned above, such as [1, 27], rely on the item ranking from the previous stage, which is often not available for the ranking stage. Finally, these algorithms are too complex and time-consuming to be practically applied in the ranking stage with much bigger candidate set.",
  "2.2 Privileged Features and Distillation": "For recommendation performance, it is essential for us to ensure the consistency between offline training and online inference. However, with this constraint, many discriminative features, which are available at training but not for inference, must be ignored for model training. In [23, 41], they define the features only available for training as privileged features. Two models, a student and a teacher model, are trained. Unlike normal model distillation methods [5, 18], which input the same feature set to the student and teacher models, the teacher model here utilizes all features while the student model here does not depend on the privileged features. During training, besides the original training labels, knowledge distilled from the teacher model is also used to supervise the training of the student model. After model convergence, only the student model is deployed online to serve the user request. As the student model does not rely on privileged features, the consistency between online and offline is guaranteed. Taken the slate-wise information as privileged features, we can use PFD [41] to indirectly model the mutual influence among the items of a recommendation slate. Compared with SAR, it roughly doubles the training resources. What's more, SAR can utilize the slate-wise information more effectively and achieve better performance, which is verified in our experiments.",
  "2.3 Multi-Task Learning for Recommender Systems": "There are a variety of user interactions in typical recommendation scenario, such as clicking, watch time, liking and commenting. Moreover, single interaction itself are unable to clearly reflect the user satisfaction. Therefore, the recommender system needs to model multiple user behaviors and further combines there predictions to calculate the final utility score. Under such circumstances, we see wide application of multi-task learning techniques as they can solve multiple related tasks simultaneously and improve learning efficiency and prediction accuracy over the single task methods. We briefly introduce related papers here. Hard parameter sharing is the most intuitive MTL structure. For instance, the ESSM model [25] shares embedding parameters between the tasks of CTR (Click-Through Rate) and CVR (Conversion Rate) for improving the prediction performance of the sparse CVR task. To alleviate the task conflict and negative transfer issue, Zhao et al. [43] extend the Multi-gate Mixture-of-Experts model (MMoE) [24] and apply it to learn multiple ranking objectives in Youtube video recommender Output Task Output Task Backbone Network Decoder Network Embedding User Encoder Network Embedding Item User ealures jeatures (c) SAR Inference WSDM'23, February 27-March 3, 2023, Singapore, Singapore Yi Ren, Xiao Han, Xu Zhao, Shenzheng Zhang, & Yan Zhang Table 1: Notations and Descriptions systems. PLE [30] achieves superior performance for news recommendation by assigning both shared parameters among tasks and task specific parameters. In section 3, we will describe how to seamlessly integrate SAR with these multi-task learning methods.",
  "3 METHODOLOGY": "In this section, we introduce the SAR method in detail. First, we formally introduce the problem definition for slate recommendation. Then, we explain the general design of SAR for the ranking stage. Finally, we elaborate on how to enhance the ranking models with the proposed method.",
  "3.1 Slate Recommendation": "Given a set of candidate with 𝑁 items 𝐶 = { 𝑐 𝑘 } 1 ≤ 𝑘 ≤ 𝑁 , the goal of slate recommendation is to recommend a slate of 𝐾 items 𝑆 = { 𝑖 𝑘 } 1 ≤ 𝑘 ≤ 𝐾 ⊆ 𝐶 so as to optimize the overall utility and enhance user experience. We denote the reward of recommending 𝑆 for user 𝑢 as 𝑅 ( 𝑆,𝑢 ) . Then, the overall slate recommendation problem can be regarded as an combinatorial optimization problem below.  where 𝜃 is the model parameters for generating 𝑆 from 𝐶 given user 𝑢 . If we suppose the user interaction with one item only depends on the quality and relevance of the corresponding item, then we can factorize the slate reward as a weighted sum of the reward for recommending single items and deduce the equation below.  where 𝑖 𝑘 the item at position 𝑘 of the slate, 𝑜 𝑘 is the observation probability for 𝑖 𝑘 and 𝑟 ( 𝑖 𝑘 , 𝑢 ) is the reward for recommending a specific item. As 𝑜 𝑘 strictly decreases from 1 to 𝐾 for most scenarios, the best slate can be constructed by descending sorting the candidate items' reward and returning the top 𝐾 items. This is exactly the underlying rationality of the existing algorithms in the ranking stage. However, given the well-known mutual influence among the slate items [1, 3, 4, 10-12, 14, 19, 22, 26, 27, 33, 36, 42, 46], it is desirable for us to model the cross impact of slate items to optimize the user experience. With the multi-stage design of the recommender systems, the matching and pre-ranking stage resort to highly efficient yet coarsegrained models to ensure the coverage rather than precision of the upper stage's candidate set. Moreover, though there are existing solution for the re-ranking stage to consider the mutual influence of slate items, the re-ranking stage has a much smaller candidate set than the ranking stage. Therefore, this work targets to address the modelling of mutual influence among slate items in the ranking stage to further enhance the end to end recommendation experience by improving the quality of the re-ranking stage's candidate set.",
  "3.2 General Design of SAR": "The ranking stage of recommender systems, which normally selects top tens of items from a pool of hundreds to thousands, originally uses model to estimate the reward score for each pair of user-item and forwards the top items to the re-ranking stage. The reward score may depend on a single objective or multiple objectives. For example, the reward may depend on the user click, item watch time, and other satisfaction-related metrics (e.g., liking and sharing) in the content recommendation application. For multi-objective modelling, we usually leverage multi-task learning approaches [24, 30] to accurately model multiple user feedback. Furthermore, to compute the overall reward, we need merge the multiple predictions with a function Φ shown in equation 4 to derive the item's final reward score for greedy ranking.   where 𝑀 is the number of prediction tasks, 𝑖 is the target item for score computation and 𝑓 𝑏𝑎𝑠𝑒 is the DNN model to generate prediction for each task. In addition, Φ is usually a function manually tuned by the engineers to reflect the reward based on the business goals. From equation 3, we can see the original ranking models does not consider the impact of surrounding items on the current one. Ideally, we should estimate { 𝑝 1 , 𝑝 2 , ..., 𝑝 𝑀 } with the equation 5, which takes the recommendation slate 𝑆 as input. However, we cannot get the full recommendation slate during online serving in the ranking stage.  As a result, we propose to estimate the slate information based on the user features. Since the recommender systems tend to recommend a slate of items that suits well for the user's interest, theoretically, we can roughly deduce the slate information with the user features. Specifically, during training, we align the user features and slate features in the transformed latent space, namely 𝑙 𝑢 for user features and 𝑙 𝑠 for slate features. During inference, we Slate-Aware Ranking for Recommendation WSDM'23, February 27-March 3, 2023, Singapore, Singapore firstly estimate 𝑙 𝑢 based on the user features, which is concatenated with the user information and item information to predict { 𝑝 1 , 𝑝 2 , ..., 𝑝 𝑀 } . In this way, the model inference does not rely on the slate features at all.",
  "3.3 Model Architecture": "3.3.1 Baseline Model. For the ranking stage, we usually take two types of features as input, namely user and item features. Traditionally, we also need manual cross features so as to describe feature interactions, which are not so prevalent now because the effective implicit cross within the deep learning models [6, 7, 16, 17, 40] can warrant a better balance between model size and recommendation performance. Both of the two types of features are high-dimensional binary features derived from one-hot encoding of categorical variables (e.g., user and item ids) or discretization of dense variables (e.g., user activity counting). As is displayed in Figure 2(a), for the baseline model, we firstly project each feature to a dense embedding vector with the fully connected embedding layer. Then, the embeddings are concatenated by group to get 𝑒 𝑖 for item features and 𝑒 𝑢 for user features. Then, we concatenate them together and input to the backbone network, which utilizes multi-task algorithms [24, 30] for multi-objective predictions or simpler algorithms [7, 17, 29] for single task prediction. The whole process can be formally described with the equations below.    where 𝐸𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔 𝑢 and 𝐸𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔 𝑖 are the embedding and concatenation operation for the user features and item features respectively. And 𝐵𝑎𝑐𝑘𝑏𝑜𝑛𝑒 denotes the backbone network. 3.3.2 Introduced Components of SAR. Please refer to Figure 2(b) and 2(c) for the model architecture of SAR. First, with SAR, besides the aforementioned two types of features, we also add slate-wise features, such as the sequence of item ids and categories in the recommendation slate. First, these slate-wise features are projected to low dimensional representation with an embedding layer and then concatenated together to get 𝑒 𝑠 with equation 9.  Second, we add two encoder networks, namely 𝐸𝑛𝑐𝑜𝑑𝑒𝑟 𝑢 and 𝐸𝑛𝑐𝑜𝑑𝑒𝑟 𝑠 , for the user features and slate-wise features respectively to get the transformed latent space to be aligned with. The slate encoder network denoted by Equation 10 takes 𝑒 𝑠 and 𝑒 𝑢 as input and generates the intermediate representation vector ( 𝑙 𝑠 ) representing the slate information with personalized weight for different slate items. Moreover, the user encoder network denoted by Equation 11 accepts 𝑒 𝑢 as input and produces a representation vector ( 𝑙 𝑢 ) to be aligned with 𝑙 𝑠 during training.   Additionally, we introduce the decoder network as is described in 12. Besides the auxiliary input of 𝑒 𝑢 , it also accepts 𝑙 𝑢 as input for inference or 𝑙 𝑠 as input for training. The decoder network extracts valuable information from the output latent space of the encoder networks for the specific user and tries to enhance the overall recommendation performance.  where 𝑙 can be 𝑙 𝑢 or 𝑙 𝑠 based on the status of inference or training. And 𝑑 is the decoding result. Finally, the decoded information ( 𝑑 ) together with 𝑒 𝑢 and 𝑒 𝑖 is then fed to the backbone networks to generate more accurate predictions for the tasks.  For the slate encoder network ( 𝐸𝑛𝑐𝑜𝑑𝑒𝑟 𝑠 ), because of the sequential nature of the item permutation in the slate, we may firstly process the sequence of item features with the techniques of sum pooling, target attention [44], LSTM[15] or transformer [32], to extract essential information to be concatenated with 𝑒 𝑢 for further computation with the MLP network within 𝐸𝑛𝑐𝑜𝑑𝑒𝑟 𝑠 . For all the other newly introduced modules, we just consider simple MLP networks. 3.3.3 SAR Training. For SAR training displayed in Figure 2(b), we need all the aforementioned components, including the slate-wise features and the slate encoder networks. The encoding result of the user encoder network and the slate encoder network is aligned with the supervision of the similarity loss. Furthermore, together with the auxiliary input of 𝑒 𝑢 , the decoder network tries to extract valuable information from the output of the slate encoder network for the specific user, which is further concatenated with [ 𝑒 𝑖 , 𝑒 𝑢 ] and fed to the backbone network for prediction. 3.3.4 SAR Inference. For SAR inference displayed in Figure 2(c), we no longer need the slate-wise features and the slate encoder network. The result of the user encoder network rather than the slate encoder network is fed to the decoder network for further processing. The prediction performance is guaranteed with the proper supervision from the similarity loss during training, which enforces little gap and maximum similarity between the outputs of the user encoder network and the slate encoder network.",
  "3.4 Joint Loss Optimization": "In multi-task learning, a common formulation of joint loss is the weighted sum of the losses for individual tasks. With our method, we just add an auxiliary similarity loss to ensure the similarity between the outputs of the slate encoder network and user encoder network. Then, for multi-task learning with 𝑀 tasks, given input features 𝑋 and task specific labels 𝑌 𝑚 , 𝑚 = 1 , 2 , ..., 𝑀 , we learn the model parameters by minimizing the aggregated loss of equation 14. 𝜔 𝑚 and 𝐿 𝑚 are the weight and loss for the task 𝑚 respectively. For 𝐿𝑜𝑠𝑠 𝑠𝑖𝑚 , we use the L2 loss to minimize the Euclidean distance of the results of the user encoder network ( 𝑙 𝑢 ) and the slate encoder network ( 𝑙 𝑠 ). And 𝜆 is the loss weight for the similarity loss.  It is important for 𝜆 , the weight of the similarity loss, to be tuned and properly set. On the one hand, the model training may not converge with a too large value. Instead, if it is set too small, there WSDM'23, February 27-March 3, 2023, Singapore, Singapore Yi Ren, Xiao Han, Xu Zhao, Shenzheng Zhang, & Yan Zhang will be unfavorable inconsistencies between training and inference. If the model performance is over sensitive to this parameter, there will be difficulties for SAR to be practically applied. We will perform sensitivity test and report the results in our experiments.",
  "4 EXPERIMENTS": "In this section, we conduct offline and online experiments with the aim of answering the following questions: RQ1 Compared with the baseline and PFD [41], what is the offline performance of SAR on different backbone networks? RQ2 Can SAR achieve additional online gains if deployed on top of the state of the art re-ranking method for slate recommendation? RQ3 What is the impact of the similarity loss's weight on model performance? How sensitive does the value of 𝜆 impact the overall recommendation quality? RQ4 Can the slate encoder and user encoder network generate similar embedding vectors so as to ensure the serving performance when the similarity loss's weight is properly set?",
  "4.1 Experimental Settings": "4.1.1 Datasets. Weexperimented 2 on two real-world datasets. The first one is the public MovieLens-1M 3 dataset consisting of 1 million ratings from 6000 users on 4000 movies. Considering the slate information is absent in MovieLens-1M, we followed the practice of [19, 22] to split user rating sessions into slates of size 20 and take the ratings of 4-5 as positive and 1-3 as negative. The data were randomly separated into training set, validation set and test set by the ratio of 8:1:1. Moreover, we sampled an industrial dataset from 9 days' user logs of our industrial news recommender systems. There are about 30 million users, 2 million items and 1 billion samples in the datasets. In our application, for each user interaction, the system recommends a slate of 10 items, whose ids are used as the slate feature of each exposed item. And our main prediction tasks are the binary classification task of click through rate with cross entropy loss and the regression task of item watch time after click with huber loss. We used the samples in the first 7 days for training. The samples of the 8th day were used for validation and hyper-parameter tuning. And samples of the last remaining day were for testing. 4.1.2 Experimental Models. For the slate encoder network at Figure 2, we experiment several variants of slate feature transformation to study the impact of different slate encoding structures. With these variants, we would like to understand whether the slate's sequential information and the proper attention weights for different slate items are beneficial for the overall recommendation performance. For all of these variants, we concatenate the above result with 𝑒 𝑢 and input to the MLP component of the slate encoder network. · 𝑆𝐴𝑅 𝑆𝑢𝑚𝑃𝑜𝑜𝑙 : We perform sum pooling with the embeddings of the slate items to obtain the slate embedding. For this configuration, neither sequential information nor relative importance of slate items can be captured. · 𝑆𝐴𝑅 𝐿𝑆𝑇𝑀 : We input the embeddings of the slate items to a one layer LSTM network to get the slate embedding. For this 2 Weopensourcethecodeat: https://github.com/BestActionNow/Slate_Aware_Ranking 3 http://www.grouplens.org/datasets/movielens 0.25 AUC Gain 041 MAE Gain 0.20 015 1 007 004 003 004 004 CTR ask Figure 3: The impact of similarity loss weight configuration, the sequential information of slate items is kept. But we do not compute the relative weights of the slate items based on the target item, whose ranking scores are to be predicted. · 𝑆𝐴𝑅 𝐴𝑡𝑡𝑛 : Following [44], we single out the target item as query to get the attention weight over the slate items. Please note that the target item belongs to the set of slate items. Then, weighted sum is executed to get the slate embedding. In this way, we get the relative weights of the slate items favorable for the target item but lose the slate's sequential information. For the user encoder, slate encoder and decoder network of SAR , we use MLP structure of [ 𝑑𝑖𝑚 , 𝑑𝑖𝑚 ] where 𝑑𝑖𝑚 is set to 16 and 128 for MovieLens-1M and the industrial data respectively. For the backbone network at Figure 2, PLE [30] is utilized for the industrial dataset. And multiple backbone networks, including FM[29], Wide&Deep[7] and NCF[17], are tested for MovieLens-1M to verify the wide compatibility of our method. And we also take the slate-wise features as privileged features, which are discriminative but only available during training, and test the performance of privileged feature distillation ( 𝑃𝐹𝐷 ) [41]. For fairness, we would like the teacher model of PFD to have the same capacity as the model for SAR training. Thus, after disabling the similarity loss, we use the model structure of Figure 2(b) with the 𝑆𝐴𝑅 𝐴𝑡𝑡𝑛 slate encoder network as teacher model and the model structure of Figure 2(a) as student model. For all the models, we use Adam [21] optimizer. We tune the learning rate and other hyper-parameters for each model separately. 4.1.3 Evaluation Metrics. From equation 13 and 8, we can see that the main task of the ranking model is to predict one or several user feedback, such as clicking, watch time, liking and sharing. And the merge function Φ in Equation 4, which is a function manually tuned to reflect the reward based on the business goals, assumes that the ranking model can estimate accurate interaction probabilities for binary classification tasks (e.g. liking and sharing) and absolute values for regression tasks (e.g. watch time). As a result, instead of the ranking metrics, such as Normalized Discounted Cumulative Gain (NDCG) [34] and Mean Reciprocal Rank (MRR) [37], we use the metrics of Area Under the ROC Curve (AUC) [13] for classification tasks and Mean Absolute Error (MAE) [39] for regression tasks. Please note that many other recommendation literature, such as [30], also use similar metrics. For AUC, a bigger value indicates better performance. While, for MAE, it is the smaller the better. Slate-Aware Ranking for Recommendation WSDM'23, February 27-March 3, 2023, Singapore, Singapore Encoder Net Slate Encoder Net User (a) general distribution User Encoder Net Slate Encoder Net Encoder Net Slate Encoder Net User (b) sampled pairs User Encoder Net Slate Encoder Net (c) general distribution 1st dim (d) general distribution 2nd dim Figure 4: Encoder Output Visualization",
  "4.2 Offline Performance Comparison(RQ1)": "As mentioned above, we use AUC and MAE as the evaluation metrics for the tasks of classification and regression respectively. Please note that a 0.1% relative gain over baseline means significant performance improvement for both metrics in our scenario. From Table 2, we can see that our method achieves competitive performance. Compared with baseline, 𝑆𝐴𝑅 𝐴𝑡𝑡𝑛 has 0.43% gain on AUC and 0.2% decrease on MAE. 𝑆𝐴𝑅 𝐴𝑡𝑡𝑛 performs better than 𝑃𝐹𝐷 𝑠𝑡𝑢𝑑𝑒𝑛𝑡 with 0.33% gain on AUC and 0.11% decrease on MAE. In other words, 𝑆𝐴𝑅 significantly outperforms 𝑃𝐹𝐷 with about half training resources. Table 2: Offline Performance for Industrial Dataset 4.2.1 Industrial Dataset. The baseline's architecture is shown in Figure 2(a) with PLE [30] as its backbone network. For PFD, the student model is of the same structure as the baseline. But its student model is trained with the supervision from both the soft labels of the teacher model and the original hard labels. For the teacher model of PFD, after removing the similarity loss, we use the model structure of Figure 2(b) with 𝑆𝐴𝑅 𝐴𝑡𝑡𝑛 as the slate encoder network. For SAR, we use different model structures for training and inference, which is described in section 3. For the backbone network of SAR, it is of the same structure as the backbone network of the baseline except for the input layer, which is of additional dimension with the introduction of 𝑑 in Equation 13. Amongthe variants of 𝑆𝐴𝑅 , 𝑆𝐴𝑅 𝐴𝑡𝑡𝑛 shows some marginal gains over 𝑆𝐴𝑅 𝐿𝑆𝑇𝑀 and 𝑆𝐴𝑅 𝑆𝑢𝑚𝑃𝑜𝑜𝑙 . Based on our test, the gain is stable for multiple runs. Moreover, 𝑆𝐴𝑅 𝐿𝑆𝑇𝑀 and 𝑆𝐴𝑅 𝑆𝑢𝑚𝑃𝑜𝑜𝑙 have roughly the same performance. Therefore, it seems the computed relative weights of the slate items are useful for model prediction. 4.2.2 MovieLens-1M. For MovieLens-1M, we compare 𝑆𝐴𝑅 𝐴𝑡𝑡𝑛 , which exhibits the best performance for the industrial data, with baseline and 𝑃𝐹𝐷 on three backbone networks. For PFD, the student model is still of the same structure as the baseline model shown in Figure 2(a). And the teacher model of PFD uses the model structure of Figure 2(b) with 𝑆𝐴𝑅 𝐴𝑡𝑡𝑛 as the slate encoder network after disabling the similarity loss. For SAR, we still use different model structures for training and inference shown at Figure 2(b) and Figure 2(c) respectively. For this experiment, we test three different backbone networks listed in table 3 to study SAR's performance gain over different backbone networks. The results are summarized in Table 3. Compared with the baseline, PFD shows gain for the backbone network of Wide&Deep and NCF but neural results for FM. Moreover, SAR shows consistent gains over PFD and the baseline model. Overall, the results of MovieLens 1M demonstrate the effectiveness and wide compatibility of 𝑆𝐴𝑅 . WSDM'23, February 27-March 3, 2023, Singapore, Singapore Yi Ren, Xiao Han, Xu Zhao, Shenzheng Zhang, & Yan Zhang Table 3: Offline Performance for MovieLens-1M",
  "4.3 Online A/B Testing(RQ2)": "To verify the effectiveness of our proposed algorithm, we served 𝑆𝐴𝑅 𝐴𝑡𝑡𝑛 model online in the ranking stage, which accepts hundreds of candidates and outputs the top 50 items to the re-ranking stage, of our content recommender systems. In the re-ranking stage, we already deployed the state of the art generator and evaluator algorithms similar to [11] for slate recommendation. We randomly distributed online users to two buckets with the baseline ranking model or SAR and evaluated the performance for seven days to report our main online metrics of total page view per person (PV) and app stay time per person (ST). As is shown in table 4, SAR achieved significant gains over the baseline by 0.9 % for page view and 0.745 % for stay time. Based on the results from our A/B test platform, the p-value is below 0.05 for one-tailed t-test for both metrics mentioned above. Unlike search engine, the user's intention is not so focused in recommendation scenario. Thus, after implicitly modelling the mutual influence of the slate items with SAR , the recommendation results should cover more interests of the user in a recommendation slate guided by overall utility optimization, thereby exhibiting enhanced diversity. We are concerned about diversity because of the following reasons. On the one hand, diverse recommendation is helpful for immediate user satisfaction. On the other hand, in all likelihood, the system can understand more multi-faceted user interests so as to ensure even better recommendation performance in the future. Furthermore, diverse recommendation will encourage the authors to provide a wide variety of contents, which is beneficial for the long term success of the ecosystem. To verify SAR's effectiveness on diversity, we extracted one day's online data and analyzed the final recommendation results. We computed the exposed items' gini index [38] metrics on item id and item category. From table 5, compared with the baseline traffic, we can see lower gini index indicating better diversity for the final recommendation results, especially for the metrics of item category. Table 4: Online Performance Table 5: The Gini Index of Online Traffic",
  "4.4 Impact of Similarity Loss Weight(RQ3)": "We further studied the impact of the weight of similarity loss on model performance in the industrial dataset. First, following the results of previous experiments, we fixed the loss weights of the CTR task and watch time task to the optimal values. Then, to report the model performance of 𝑆𝐴𝑅 𝐴𝑡𝑡𝑛 , we tested different weight ratio of the similarity loss relative to the CTR task. According to Figure 3, the best model performance is achieved when the similarity loss's weight is equal to the CTR task. Moreover, 𝑆𝐴𝑅 𝐴𝑡𝑡𝑛 's performance is not too sensitive to the change of the similarity loss weight. So hyper-parameter tuning is of manageable difficulty and SAR can be practically applied to boost the recommendation performance.",
  "4.5 Encoder Network Embedding Distribution Analysis on Industrial Dataset(RQ4)": "We visualized the embedding distribution of the User and Slate Encoder Networks with t-SNE [31] in figure 4(a), 4(c) and 4(d) for the best performing 𝑆𝐴𝑅 𝐴𝑡𝑡𝑛 model with equal loss weights for the similarity task and the CTR task. From figure 4(a), we can see the points fall into two clusters and the embeddings from the two encoders show similar distribution. With figure 4(c) and 4(d), it is obvious that the distribution density match well in each dimension. In figure 4(b), we randomly sampled six output pairs from these two encoder networks. For each pair, we got the encoding results from the two encoder networks for the same instance. And we plotted with different colors for points from different networks. The points from the same pair were of the same shape. For each pair, the two points resided in the same cluster and were close to each other. In summary, the User Encoder network and Slate Encoder Network can generate outputs with consistent distributions, which ensures the consistency between training and inference and explains the effectiveness of our proposed method.",
  "5 CONCLUSION": "In this paper, we propose an algorithm for the ranking stage of recommender systems to predict user behaviors more accurately by implicitly modelling the contextual items' impact. We perform thorough offline experiments and online A/B testing to prove that it significantly enhances the recommendation relevance and diversity by ensuring the quality of the re-ranking stage's candidates. Moreover, additional experiments are carried out to study the similarity loss weight's impact and understand why 𝑆𝐴𝑅 works. In future, we will try to further improve the recommendation performance by designing more effective models in the ranking and re-ranking stage to tackle the issue of cross item influence. Furthermore, though the matching and pre-ranking stage care more about coverage than precision, it is interesting to investigate whether addressing the aforementioned issue in these two layers can boost the overall recommendation quality. Finally, as it is essential to properly handle position bias for precise user preference modelling [2, 20, 28], we plan to study how to more accurately estimate the context items' impact on target items at different positions. Slate-Aware Ranking for Recommendation WSDM'23, February 27-March 3, 2023, Singapore, Singapore",
  "REFERENCES": "[1] Qingyao Ai, Keping Bi, Jiafeng Guo, and W Bruce Croft. 2018. Learning a deep listwise context model for ranking refinement. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval . 135-144. [2] Qingyao Ai, Keping Bi, Cheng Luo, Jiafeng Guo, and W Bruce Croft. 2018. Unbiased learning to rank with unbiased propensity estimation. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval . 385-394. [3] Qingyao Ai, Xuanhui Wang, Sebastian Bruch, Nadav Golbandi, Michael Bendersky, and Marc Najork. 2019. Learning groupwise multivariate scoring functions using deep neural networks. In Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval . 85-92. [4] Irwan Bello, Sayali Kulkarni, Sagar Jain, Craig Boutilier, Ed Chi, Elad Eban, Xiyang Luo, Alan Mackey, and Ofer Meshi. 2018. Seq2slate: Re-ranking and slate optimization with rnns. arXiv preprint arXiv:1810.02019 (2018). [5] Cristian Buciluˇ a, Rich Caruana, and Alexandru Niculescu-Mizil. 2006. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining . 535-541. [6] Xiaoshuang Chen, Yin Zheng, Jiaxing Wang, Wenye Ma, and Junzhou Huang. 2019. RaFM: rank-aware factorization machines. In International Conference on Machine Learning . PMLR, 1132-1140. [7] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al. 2016. Wide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems . 7-10. [8] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks for youtube recommendations. In Proceedings of the 10th ACM conference on recommender systems . 191-198. [9] Paolo Cremonesi, Yehuda Koren, and Roberto Turrin. 2010. Performance of recommender algorithms on top-n recommendation tasks. In Proceedings of the fourth ACM conference on Recommender systems . 39-46. [10] Weiwei Deng, Xiaoliang Ling, Yang Qi, Tunzi Tan, Eren Manavoglu, and Qi Zhang. 2018. Ad click prediction in sequence with long short-term memory networks: an externality-aware model. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval . 1065-1068. [11] Yufei Feng, Yu Gong, Fei Sun, Junfeng Ge, and Wenwu Ou. 2021. Revisit Recommender System in the Permutation Prospective. arXiv preprint arXiv:2102.12057 (2021). [12] Yufei Feng, Binbin Hu, Yu Gong, Fei Sun, Qingwen Liu, and Wenwu Ou. 2021. GRN: Generative Rerank Network for Context-wise Recommendation. arXiv preprint arXiv:2104.00860 (2021). [13] Peter A Flach, José Hernández-Orallo, and Cèsar Ferri Ramirez. 2011. A coherent interpretation of AUC as a measure of aggregated classification performance. In ICML . [14] Yu Gong, Yu Zhu, Lu Duan, Qingwen Liu, Ziyu Guan, Fei Sun, Wenwu Ou, and Kenny Q Zhu. 2019. Exact-k recommendation via maximal clique optimization. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 617-626. [15] Klaus Greff, Rupesh K Srivastava, Jan Koutník, Bas R Steunebrink, and Jürgen Schmidhuber. 2016. LSTM: A search space odyssey. IEEE transactions on neural networks and learning systems 28, 10 (2016), 2222-2232. [16] Xiangnan He and Tat-Seng Chua. 2017. Neural factorization machines for sparse predictive analytics. In Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval . 355-364. [17] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web . 173-182. [18] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge in a neural network (2015). arXiv preprint arXiv:1503.02531 2 (2015). [19] Ray Jiang, Sven Gowal, Timothy A Mann, and Danilo J Rezende. 2018. Beyond greedy ranking: Slate optimization via list-CVAE. arXiv preprint arXiv:1803.01682 (2018). [20] Thorsten Joachims, Adith Swaminathan, and Tobias Schnabel. 2017. Unbiased learning-to-rank with biased feedback. In Proceedings of the tenth ACM international conference on web search and data mining . 781-789. [21] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014). [22] Shuchang Liu, Fei Sun, Yingqiang Ge, Changhua Pei, and Yongfeng Zhang. 2021. Variation Control and Evaluation for Generative Slate Recommendations. In Proceedings of the Web Conference 2021 . 436-448. [23] David Lopez-Paz, Léon Bottou, Bernhard Schölkopf, and Vladimir Vapnik. 2015. Unifying distillation and privileged information. arXiv preprint arXiv:1511.03643 (2015). [24] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed H Chi. 2018. Modeling task relationships in multi-task learning with multi-gate mixture-ofexperts. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 1930-1939. [25] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun Gai. 2018. Entire space multi-task model: An effective approach for estimating post-click conversion rate. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval . 1137-1140. [26] Liang Pang, Jun Xu, Qingyao Ai, Yanyan Lan, Xueqi Cheng, and Jirong Wen. 2020. Setrank: Learning a permutation-invariant ranking model for information retrieval. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval . 499-508. [27] Changhua Pei, Yi Zhang, Yongfeng Zhang, Fei Sun, Xiao Lin, Hanxiao Sun, Jian Wu, Peng Jiang, Junfeng Ge, Wenwu Ou, et al. 2019. Personalized re-ranking for recommendation. In Proceedings of the 13th ACM Conference on Recommender Systems . 3-11. [28] Yi Ren, Hongyan Tang, and Siwen Zhu. 2022. Unbiased Learning to Rank with Biased Continuous Feedback. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management . 1716-1725. [29] Steffen Rendle. 2010. Factorization machines. In 2010 IEEE International conference on data mining . IEEE, 995-1000. [30] Hongyan Tang, Junning Liu, Ming Zhao, and Xudong Gong. 2020. Progressive layered extraction (ple): A novel multi-task learning (mtl) model for personalized recommendations. In Fourteenth ACM Conference on Recommender Systems . 269278. [31] Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE. Journal of machine learning research 9, 11 (2008). [32] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems . 5998-6008. [33] Fan Wang, Xiaomin Fang, Lihang Liu, Yaxue Chen, Jiucheng Tao, Zhiming Peng, Cihang Jin, and Hao Tian. 2019. Sequential evaluation and generation framework for combinatorial recommender system. arXiv preprint arXiv:1902.00245 (2019). [34] Yining Wang, Liwei Wang, Yuanzhi Li, Di He, Wei Chen, and Tie-Yan Liu. 2013. A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th annual conference on learning theory (COLT 2013) , Vol. 8. 6. [35] Zhe Wang, Liqin Zhao, Biye Jiang, Guorui Zhou, Xiaoqiang Zhu, and Kun Gai. 2020. Cold: Towards the next generation of pre-ranking system. arXiv preprint arXiv:2007.16122 (2020). [36] Jianxiong Wei, Anxiang Zeng, Yueqiu Wu, Peng Guo, Qingsong Hua, and Qingpeng Cai. 2020. Generator and Critic: A Deep Reinforcement Learning Approach for Slate Re-ranking in E-commerce. arXiv preprint arXiv:2005.12206 (2020). [37] Wikipedia contributors. 2022. Evaluation measures (information retrieval) Wikipedia, The Free Encyclopedia. https://en.wikipedia.org/w/index.php?title= Evaluation_measures_(information_retrieval)&oldid=1095286224. [Online; accessed 9-August-2022]. [38] Wikipedia contributors. 2022. Gini coefficient - Wikipedia, The Free Encyclopedia. https://en.wikipedia.org/w/index.php?title=Gini_coefficient&oldid= 1101796604. [Online; accessed 9-August-2022]. [39] Wikipedia contributors. 2022. Mean absolute error - Wikipedia, The Free Encyclopedia. https://en.wikipedia.org/w/index.php?title=Mean_absolute_error& oldid=1087554218. [Online; accessed 9-August-2022]. [40] Jun Xiao, Hao Ye, Xiangnan He, Hanwang Zhang, Fei Wu, and Tat-Seng Chua. 2017. Attentional factorization machines: Learning the weight of feature interactions via attention networks. arXiv preprint arXiv:1708.04617 (2017). [41] Chen Xu, Quan Li, Junfeng Ge, Jinyang Gao, Xiaoyong Yang, Changhua Pei, Fei Sun, Jian Wu, Hanxiao Sun, and Wenwu Ou. 2020. Privileged features distillation at Taobao recommendations. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 2590-2598. [42] Xiangyu Zhao, Liang Zhang, Long Xia, Zhuoye Ding, Dawei Yin, and Jiliang Tang. 2017. Deep reinforcement learning for list-wise recommendations. arXiv preprint arXiv:1801.00209 (2017). [43] Zhe Zhao, Lichan Hong, Li Wei, Jilin Chen, Aniruddh Nath, Shawn Andrews, Aditee Kumthekar, Maheswaran Sathiamoorthy, Xinyang Yi, and Ed Chi. 2019. Recommending what video to watch next: a multitask ranking system. In Proceedings of the 13th ACM Conference on Recommender Systems . 43-51. [44] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1059-1068. [45] Han Zhu, Xiang Li, Pengye Zhang, Guozheng Li, Jie He, Han Li, and Kun Gai. 2018. Learning tree-based deep model for recommender systems. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 1079-1088. [46] Tao Zhuang, Wenwu Ou, and Zhirong Wang. 2018. Globally optimized mutual influence aware ranking in e-commerce search. arXiv preprint arXiv:1805.08524 (2018).",
  "keywords_parsed": [
    "Slate Recommendation",
    "Ranking",
    "Re-Ranking",
    "Recommender Systems",
    "Multi-Task Learning",
    "Privileged Information",
    "Distillation"
  ],
  "references_parsed": [
    {
      "ref_id": "b1",
      "title": "Learning a deep listwise context model for ranking refinement"
    },
    {
      "ref_id": "b2",
      "title": "Unbiased learning to rank with unbiased propensity estimation"
    },
    {
      "ref_id": "b3",
      "title": "Learning groupwise multivariate scoring functions using deep neural networks"
    },
    {
      "ref_id": "b4",
      "title": "Seq2slate: Re-ranking and slate optimization with rnns"
    },
    {
      "ref_id": "b5",
      "title": "Model compression"
    },
    {
      "ref_id": "b6",
      "title": "RaFM: rank-aware factorization machines"
    },
    {
      "ref_id": "b7",
      "title": "Wide & deep learning for recommender systems"
    },
    {
      "ref_id": "b8",
      "title": "Deep neural networks for youtube recommendations"
    },
    {
      "ref_id": "b9",
      "title": "Performance of recommender algorithms on top-n recommendation tasks"
    },
    {
      "ref_id": "b10",
      "title": "Ad click prediction in sequence with long short-term memory networks: an externality-aware model"
    },
    {
      "ref_id": "b11",
      "title": "Revisit Recommender System in the Permutation Prospective"
    },
    {
      "ref_id": "b12",
      "title": "GRN: Generative Rerank Network for Context-wise Recommendation"
    },
    {
      "ref_id": "b13",
      "title": "A coherent interpretation of AUC as a measure of aggregated classification performance"
    },
    {
      "ref_id": "b14",
      "title": "Exact-k recommendation via maximal clique optimization"
    },
    {
      "ref_id": "b15",
      "title": "LSTM: A search space odyssey"
    },
    {
      "ref_id": "b16",
      "title": "Neural factorization machines for sparse predictive analytics"
    },
    {
      "ref_id": "b17",
      "title": "Neural collaborative filtering"
    },
    {
      "ref_id": "b18",
      "title": "Distilling the knowledge in a neural network"
    },
    {
      "ref_id": "b19",
      "title": "Beyond greedy ranking: Slate optimization via list-CVAE"
    },
    {
      "ref_id": "b20",
      "title": "Unbiased learning-to-rank with biased feedback"
    },
    {
      "ref_id": "b21",
      "title": "Adam: A method for stochastic optimization"
    },
    {
      "ref_id": "b22",
      "title": "Variation Control and Evaluation for Generative Slate Recommendations"
    },
    {
      "ref_id": "b23",
      "title": "Unifying distillation and privileged information"
    },
    {
      "ref_id": "b24",
      "title": "Modeling task relationships in multi-task learning with multi-gate mixture-of-experts"
    },
    {
      "ref_id": "b25",
      "title": "Entire space multi-task model: An effective approach for estimating post-click conversion rate"
    },
    {
      "ref_id": "b26",
      "title": "Setrank: Learning a permutation-invariant ranking model for information retrieval"
    },
    {
      "ref_id": "b27",
      "title": "Personalized re-ranking for recommendation"
    },
    {
      "ref_id": "b28",
      "title": "Unbiased Learning to Rank with Biased Continuous Feedback"
    },
    {
      "ref_id": "b29",
      "title": "Factorization machines"
    },
    {
      "ref_id": "b30",
      "title": "Progressive layered extraction (ple): A novel multi-task learning (mtl) model for personalized recommendations"
    },
    {
      "ref_id": "b31",
      "title": "Visualizing data using t-SNE"
    },
    {
      "ref_id": "b32",
      "title": "Attention is all you need"
    },
    {
      "ref_id": "b33",
      "title": "Sequential evaluation and generation framework for combinatorial recommender system"
    },
    {
      "ref_id": "b34",
      "title": "A theoretical analysis of NDCG ranking measures"
    },
    {
      "ref_id": "b35",
      "title": "Cold: Towards the next generation of pre-ranking system"
    },
    {
      "ref_id": "b36",
      "title": "Generator and Critic: A Deep Reinforcement Learning Approach for Slate Re-ranking in E-commerce"
    },
    {
      "ref_id": "b37",
      "title": "Evaluation measures (information retrieval)"
    },
    {
      "ref_id": "b38",
      "title": "Gini coefficient"
    },
    {
      "ref_id": "b39",
      "title": "Mean absolute error"
    },
    {
      "ref_id": "b40",
      "title": "Attentional factorization machines: Learning the weight of feature interactions via attention networks"
    },
    {
      "ref_id": "b41",
      "title": "Privileged features distillation at Taobao recommendations"
    },
    {
      "ref_id": "b42",
      "title": "Deep reinforcement learning for list-wise recommendations"
    },
    {
      "ref_id": "b43",
      "title": "Recommending what video to watch next: a multitask ranking system"
    },
    {
      "ref_id": "b44",
      "title": "Deep interest network for click-through rate prediction"
    },
    {
      "ref_id": "b45",
      "title": "Learning tree-based deep model for recommender systems"
    },
    {
      "ref_id": "b46",
      "title": "Globally optimized mutual influence aware ranking in e-commerce search"
    }
  ]
}