{
  "Sequence-level Semantic Representation Fusion for Recommender Systems": "Lanling Xu 1 , Zhen Tian 1 , Bingqian Li 1 , Junjie Zhang 1 , Jinpeng Wang 2 Mingchen Cai 2 , Wayne Xin Zhao 1 /a0 1 Gaoling School of Artificial Intelligence, Renmin University of China, China 2 Meituan Group, Beijing China",
  "ABSTRACT": "",
  "ACMReference Format:": "With the rapid development of recommender systems, there is increasing side information that can be employed to improve the recommendation performance. Specially, we focus on the utilization of the associated textual data of items ( e.g., product title) and study how text features can be effectively fused with ID features in sequential recommendation. However, there exists distinct data characteristics for the two kinds of item features, making a direct fusion method ( e.g., adding text and ID embeddings as item representation) become less effective. To address this issue, we propose a novel Te xt-I D semantic fusion approach for sequential Rec ommendation, namely TedRec . The core idea of our approach is to conduct a sequence-level semantic fusion approach by better integrating global contexts. The key strategy lies in that we transform the text embeddings and ID embeddings by Fourier Transform from time domain to frequency domain . In the frequency domain, the global sequential characteristics of the original sequences are inherently aggregated into the transformed representations, so that we can employ simple multiplicative operations to effectively fuse the two kinds of item features. Our fusion approach can be proved to have the same effects of contextual convolution, so as to achieving sequence-level semantic fusion. In order to further improve the fusion performance, we propose to enhance the discriminability of the text embeddings from the text encoder, by adaptively injecting positional information via a mixture-of-experts (MoE) modulation method. Extensive experiments on five public datasets demonstrate the effectiveness of our approach by comparing with a number of competitive baselines. Our implementation is available at this repository: https://github.com/RUCAIBox/TedRec.",
  "CCS CONCEPTS": "Â· Information systems â†’ Recommender systems .",
  "KEYWORDS": "Sequential Recommendation, Textual Representation Fusion /a0 Wayne Xin Zhao (batmanfly@gmail.com) is the corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference acronym'XX, June 03-05, 2018, Woodstock, NY Â© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM https://doi.org/10.1145/nnnnnnn.nnnnnnn Lanling Xu 1 , Zhen Tian 1 , Bingqian Li 1 , Junjie Zhang 1 , Jinpeng Wang 2 , Mingchen Cai 2 , Wayne Xin Zhao 1 /a0 . 2024. Sequence-level Semantic Representation Fusion for Recommender Systems. In Proceedings of (Conference acronym'XX). ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/ nnnnnnn.nnnnnnn",
  "1 INTRODUCTION": "Sequential recommender systems, aiming to predict the next interaction items of a user based on her/his historical records, have been a widely studied task in both academia and industry [6, 14, 20]. The key to deliver satisfied recommendation service lies in effectively modeling the interaction behavior of users, thus making accurate prediction of future interactions. Therefore, various model architectures including CNN [33], RNN [32] and Transformer [17, 31] have been developed to characterize sequential patterns of users. In existing literature, most of sequential recommendation models [7, 31] rely on pure item identifiers (IDs) to model the user behavior. Despite the effectiveness, ID-only modeling paradigm restricts the effective utilization of extensive context data ( e.g., item features) in real-world scenarios. Considering this limitation, a number of approaches [24, 40, 44] have been proposed to incorporate the side information into recommender systems for better modeling the actual preference of users. Specially, the textual data associated with items ( e.g., item title and category label) have been widely explored for enhancing the performance of sequential recommender [8, 46, 49], which provide important description information about the characteristics or functions of items. Typically, these approaches often adopt a relatively simple representation fusion approach, e.g., adding the ID embedding and text embedding of an item [14]. Despite the performance improvement, such a semantic fusion way is locally at the item level . More specifically, the auxiliary text embedding is only used to enhance the representation of the target item, which cannot be directly utilized by other positions in the same sequence before attention interaction. In contrast, we argue that a more ideal fusion way should be globally at the sequence level : the text embedding at some position can be fused into the global semantics of the entire sequence. We present a comparison between the item-level and sequence-level semantic fusion in Figure 1. As we can see, sequential-level semantic fusion can better leverage the auxiliary text information of items for improving sequential user behavior modeling. Another limitation of existing approaches is that they often employ a pre-trained language model as the text encoder ( e.g., BERT [4]) to obtain the text embedding. It has been found that the learned embeddings are less discriminative among similar items [14, 15, 19]. For example, given two item titles ' iPhone 15 Pro ' and ' iPhone 14 case ', existing Conference acronym'XX, June 03-05, 2018, Woodstock, NY Anonymous Figure 1: Illustration for two kinds of fusion paradigms. iPhone 15 Pro iPhone 14 Case C&K Cloud Bag Phone Black Apple Bag Pink C&K Text IDs (a) Item-level fusion (b) Sequence-level fusion PhoneCase Black Apple Phone Black Apple Bag Pink C&K PhoneCase Black Apple text encoders tend to produce very similar representations, lacking fine-grained discriminatility in similar or related products. In order to achieve sequence-level semantic fusion, we are inspired by recent work on the use of Fourier Transform in recommender systems [6, 23, 50]. The key idea of our approach is to leverage the Fourier Transform for transforming the original representations ( i.e., sequences of text embeddings and ID embeddings) from the original time domain to the frequency domain . In this way, the global sequential characteristics of the original sequences can be inherently aggregated into the transformed representations in the frequency domain. Further, we can conduct the multiplication fusion between the transformed textual and ID representations. It can be proved (see Section 3.2) that the multiplicative operations ( e.g., Hadamard product ) in the frequency domain well align with the sequence-level operations ( e.g., convolution ) in the time domain, thus enabling the sequence-level semantic fusion between textual and ID representations. To develop our approach, we highlight two key challenges to be solved: (i) how to effectively fuse the textual representations and ID features in the frequency domain; (ii) how to further enhance the discriminability of text embeddings for adapting to the recommendation scenarios. To this end, in this paper, we propose a novel Te xt-I D semantic fusion approach for sequential Rec ommendation, namely TedRec . Different from existing side information fusion methods [8, 12, 46], our approach conducts the sequence-level semantic fusion on the transformed representations in the frequency domain. Specifically, TedRec mainly consists of two key technical points. (i) We inject the positional information by a mixture-of-experts (MoE) enhanced adaptor, to improve the discriminablity of text embeddings. As such, it can learn more distinguishable textual representations for subsequent semantic fusion module. (ii) We propose a mutual filter based method to fuse ID and text embeddings in the frequency domain, and further employ an inverse FFT to produce the integrated representations. Such a transformation way has similar effects of contextual convolutions in the time domain and naturally integrates the bidirectional contextual information from the entire interaction sequence. Thus, it is more capable of capturing the sequential characteristics and enhancing the text-ID semantic fusion. Our approach essentially provides a general framework to fuse multiple kinds of side information in recommender systems, which can be applied with various text encoders and recommender backbones. Our contributions are summarized as follows: Â· We propose a novel text-ID semantic fusion approach for sequential recommendation. The major contribution lies in that text embeddings and ID embeddings are transformed by Fourier Transform, and subsequently fused in the frequency domain. Such a fusion way can fully leverage sequential contexts and has the same effects of contextual convolution in the time domain. Â· We further propose to enhance the discriminability of the text embeddings from the text encoder, by adaptively injecting positional information via an MoE modulation method. Â· Extensive experiments are conducted on five public datasets, demonstrating the effectiveness of our proposed TedRec, notably with 14% and 38% performance gains over the competitive baselines on the ML-1M and OR datasets, respectively.",
  "2 PRELIMINARY": "Problem Statement. Let U = { ğ‘¢ 1 , ğ‘¢ 2 , . . . , ğ‘¢ | U| } denote a set of users and V = { ğ‘£ 1 , ğ‘£ 2 , . . . , ğ‘£ | V | } denote a set of items. Specifically, each item ğ‘£ is associated with a description text ( e.g., product title), and we denote it as ğ‘‘ ğ‘– = { ğ‘¤ 1 , ğ‘¤ 2 , . . . , ğ‘¤ ğ‘ } , where each word ğ‘¤ is from some vocabulary and ğ‘ is the input length of the text. Each user ğ‘¢ has an interaction context consisting of an ordered sequence of previously interacted items, i.e., { ğ‘£ 1 , ğ‘£ 2 , . . . , ğ‘£ ğ‘› } , where ğ‘› denotes the total number of interactions in the sequence. Given historical records, the sequential recommendation task can be defined as predicting the next item the user is likely to interact with at the ( ğ‘› + 1)-th step, denoted as ğ‘ ( ğ‘£ ğ‘› + 1 |{ ğ‘£ 1 , ğ‘£ 2 , . . . , ğ‘£ ğ‘› }) . Fourier Transform. Discrete Fourier Transform (DFT) is one of the classical methods in the field of sequence signal processing [28], which converts the sampled signal in the time domain to the frequency domain . Given the sequence data { ğ‘¥ ğ‘— } with ğ‘— âˆˆ { 1 , . . . , ğ‘› -1 } , DFTconverts it into the frequency domain according to the formula:  where ğ‘– is the imaginary unit and Ëœ ğ‘¥ denotes the spectrum of the sequence { ğ‘¥ ğ‘— } at the frequency step ğœ” ğ‘˜ = 2 ğœ‹ğ‘˜ GLYPH<14> ğ‘› . Accordingly, given representations in the frequency domain, the following formula ( inverse DFT ) is used to recover signals to the time domain:  The Fast Fourier Transform (FFT) is an efficient algorithm to calculate DFT, which is widely used in prior work [11, 35]. To improve the efficiency, FFT computes transformations by factorizing the DFT matrix into a product of sparse factors [35], directly reducing the complexity from O( ğ‘› 2 ) in DFT to O( ğ‘› log ğ‘› ) in FFT.",
  "3 METHODOLOGY": "In this section, we present a novel Te xt-I D semantic fusion approach for sequential Rec ommendation (as illustrated in Figure 2), namely TedRec . Next, we first introduce the detailed approach, and then present theoretical analysis and discussion.",
  "3.1 Sequence-Level Representation Fusion": "To leverage textual information of items, previous work [8, 14, 23] typically integrates the text embedding from a text encoder and ID embedding from a recommender model in a relatively simple way, e.g., concatenating the two embeddings at an item level. However, as discussed in Section 1, such a way cannot effectively capture sequential contexts for semantic fusion, and the used text embeddings Sequence-level Semantic Representation Fusion for Recommender Systems Conference acronym'XX, June 03-05, 2018, Woodstock, NY Figure 2: Overall architecture of our proposed TedRec. Token sequence: ğ‘¤ ! , â€¦ , ğ‘¤ \" PLM Encoder ( e.g. , BERT) Router Output Text-Rep: ğ‘¡ ! , â€¦ , ğ‘¡ # Contextual Convolution ğ‘“ ! , â€¦ , ğ‘“ $ Behavior Encoder ( e.g. , SASRec) Output: ğ‘(ğ‘£ #%! |{ğ‘£ ! , ğ‘£ & , â€¦ , ğ‘£ # }) Multi-Expert Modulation ğ‘¡ ! , â€¦ , ğ‘¡ # Input: ğ‘’ ! , â€¦ , ğ‘’ # FFT Mixed IFFT 2ğœ ğ‘“ ! Item Text Prediction Layer Item Text Item ğ‘¡ ! ğ‘¡ & ğ‘¡ ' ğ‘¡ # â€¦ ğ‘¡ ! ğ‘¡ & ğ‘¡ ' ğ‘¡ # â€¦ Textual Data ğ‘’ ! ğ‘’ & ğ‘’ ' ğ‘’ # â€¦ ID Features â€¦ ğ‘“ ! ğ‘¡ ! ğ‘¡ & ğ‘¡ ( â€¦ ğ‘’ ! ğ‘’ & ğ‘’ ( â€¦ ğ‘¡ (%! ğ‘¡ (%& ğ‘¡ # â€¦ ğ‘’ (%! ğ‘’ (%& ğ‘’ # Past Information Future Information Output: Semantic Fusion ğ’‡ ! , â€¦ , ğ’‡ # themselves lack discriminability among similar items. As our solution, we first propose a mixture-of-experts (MoE) enhanced modulation model, to learn more distinguishable textual representations (Section 3.1.1), and further develop a mutual filter based method to fuse the text and IDs in the frequency domain, to effectively capture the sequential contexts of semantic fusion (Section 3.1.2). for attention interaction based on the enhanced item representations after fusion , while modulation embeddings are used to increase the discriminability of textual representations before fusion . 3.1.1 Distinguishable Textual Representation Encoding. To obtain distinguishable text embeddings for recommendation, we employ a pre-trained language model (PLM) for text encoding, and design a mixture-of-expert (MoE) based modulation method to improve the discriminability of textual representations, by incorporating sequential information with multiple sets of modulation embeddings. PLM-based Text Encoding. We utilize the widely used BERT [4] model to encode the textual data of items. Following previous work [5, 13, 14], given the associated text of item ğ‘£ with the length ğ‘ ( i.e., { ğ‘¤ 1 , ğ‘¤ 2 , Â· Â· Â· , ğ‘¤ ğ‘ } ), we insert a [ CLS ] token at the beginning of the sequence, and feed the extended sequence into the PLM:  where ğ’• ğ‘£ is the last hidden state vector of the input token 'CLS', and ' [ ; ] ' denotes the concatenate operation. In this way, each item ğ‘£ is encoded with a unique text embedding ğ’• ğ‘£ . Note that the PLM is fixed during training, thus ensuring the efficiency of our approach. Discriminability Enhancement. Existing studies [14, 15, 19] have found that the text embeddings obtained by PLM ( e.g., BERT [4]) are less capable of discriminating the similar items. To address this issue, our solution is to employ a set of modulation embeddings for enhancing the discriminability of textual representations. Formally, given a sequence of text embeddings for the items interacted by a user, i.e., { ğ’• 1 , Â· Â· Â· , ğ’• ğ‘› } , the modulated representations are formulated as follows:  where ğ’” ğ‘— is the modulation embedding of the ğ‘— -th position, and ğ‘¾ ğ‘ƒ is the learnable parameter. The employed modulation embeddings are similar to the absolute positional embeddings used in Transformer [36]. In our approach, positional embeddings are intended Multi-Expert Modulation. Since interaction behaviors of users are very complex, the same textual representation might correspond to varied sequential semantics [37]. To effectively adapt to diverse interaction scenarios in recommender systems, we use the MoE architecture [14] of multiple modulation experts to further enhance the sequential discriminability of textual representations:   where ğ’• â€² ğ‘— is the enhanced textual representation of the item in the ğ‘— -th position, ğ’” ğ‘—,ğ‘˜ is the modulation embedding for adjusting the textual frequency of the ğ‘— -th position in the ğ‘˜ -th expert, ğº is the number of experts, ğ‘¾ ğ‘ƒ ğ‘˜ , ğ‘¾ ğº are learnable parameters, ğ’ˆ is the combination weight from the gating router and ğœ¹ is the random Gaussian noise for balancing the expert load. Here, we expect that a mixture of modulation experts can capture diverse sequential contexts with adaptive positional information, thus leading to distinguishable textual representations for items in a sequence. 3.1.2 Text-ID Semantic Fusion in the Frequency Domain. After obtaining the improved textual encoding ğ’• â€² , we next discuss how to effectively fuse text and ID representations. Specially, we leverage the Fast Fourier Transform (see FFT in Eq. (1)) to map the text and ID embeddings into the frequency domain , enabling an effective integration of these two kinds of representations at a sequence level. Furthermore, we develop a gated fusion mechanism to adaptively balance the importance of these two parts for semantic fusion. In what follows, we will introduce the details of each part. Text-ID Mutual Filtering. In the semantic fusion layer, we fuse the text and ID embeddings in the frequency domain across each dimension. Formally, given the ID embeddings ğ‘¬ = { ğ’† 1 , Â· Â· Â· , ğ’† ğ‘› } âˆˆ R ğ‘› Ã— ğ‘‘ and text embeddings ğ‘» = { ğ’• â€² 1 , Â· Â· Â· , ğ’• â€² ğ‘› } âˆˆ R ğ‘› Ã— ğ‘‘ (see Eq. (5)), Conference acronym'XX, June 03-05, 2018, Woodstock, NY Anonymous we first perform FFT (see Eq. (1)) along each dimension to convert the ğ‘» and ğ‘¬ to the frequency domain as follows:  where Ëœ ğ‘» and Ëœ ğ‘¬ denote the spectrum of text and ID embeddings, respectively. In this way, these two modalities can be mutually filtered by multiplying their spectrum in the frequency domain:  where ' âŠ™ ' denotes the element-wise multiplication, i.e., Hadamard product. Furthermore, we can also use a learnable filter ğ‘¾ âˆˆ C ğ‘› Ã— ğ‘‘ to attenuate the noise of ID embeddings as follows:  where Ëœ ğ‘­ and Ëœ ğ‘¬ â€² are the fused representations and modulated ID features, respectively. In the frequency domain, the global sequential characteristics of the original sequences can be inherently aggregated into the transformed representations ( i.e., Ëœ ğ‘¬ and Ëœ ğ‘» ). In this way, the multiplicative operations ( i.e., ' âŠ™ ') can mimic the effect of convolution in the time domain (will be discussed in Section 3.2), which essentially achieves the sequence-level semantic fusion. After mutual filtering, we adopt the inverse FFT (see Eq. (2)) to transform the representations Ëœ ğ‘¬ â€² and Ëœ ğ‘­ to the original time domain:  With the above transformations, the outputs will ultimately consist of two parts of feature representations: one part is derived from the semantic fusion between text and ID embeddings ( i.e., ğ‘­ ), and the other part is derived from the denoised ID embeddings ( i.e., ğ‘¬ â€² ). Finally, we develop a dual gating mechanism in the time domain to combine them in the following formula:  Here Gate (Â·) : R ğ‘› Ã— ğ‘‘ â†’ R is a linear function for generating the fusion weight, ğœ is the sigmoid function, and a multiplier of 2 is used to transform the values to the range of [ 0 , 2 ] with an average of 1. Hence, we use the final representations ğ‘½ = { ğ’— 1 , ğ’— 2 , Â· Â· Â· , ğ’— ğ‘› } âˆˆ R ğ‘› Ã— ğ‘‘ from Eq. (11) for subsequent user behavior modeling. Prediction and Optimization. Given a sequence of fused item representations ( i.e., ğ‘½ in Eq. (11)), we further utilize a user behavior encoder to obtain the sequence representation. Note that our representation fusion approach can be integrated with various behavior encoders. Taking the widely used Transformer architecture ( e.g., SASRec [17]) as example, given the fused representations ğ‘½ = { ğ’— 1 , ğ’— 2 , Â· Â· Â· , ğ’— ğ‘› } âˆˆ R ğ‘› Ã— ğ‘‘ (see Eq. (11)), the sequential representation can be formulated as follows:  where ğ‘¿ ğ‘™ = [ ğ’™ ğ‘™ 1 , ğ’™ ğ‘™ 2 , Â· Â· Â· , ğ’™ ğ‘™ ğ‘› ] is the output representation of the ğ‘™ -th layer, ğ’‘ ğ‘— is the absolute positional embedding of the ğ‘— -th position, FFN (Â·) is the point-wise feed-forward networks and MHAtt (Â·) is the multi-head self-attention mechanism [36]. Given the representation of the last layer ( i.e., [ Ë† ğ’™ 1 , Ë† ğ’™ 2 , Â· Â· Â· , Ë† ğ’™ ğ‘› ]), we take the final hidden vector of the ğ‘› -th position as the sequential representation ( i.e., Ë† ğ’™ ğ‘› ). Finally, we adopt the widely used cross-entropy (CE) loss [14, 31] with a temperature parameter ğœ to train our model:  Thus, we compute the probability of ğ‘£ ğ‘› + 1 over the item set |V| as:  During training, the PLM encoder is fixed and we optimize the cross-entropy loss to train the backbone model, modulation experts as well as learnable filters via Eq. (13). After training, we calculate the probability distribution of the softmax function for recommending the most possible item by Eq. (14).",
  "3.2 Theoretical Analysis": "As mentioned in Section 1, previous work mainly suffers from two limitations in fusing representations of text and IDs i.e., low discriminability and item-level fusion . In Section 3.1.1, we have discussed how to improve the discriminability of textual representations. Furthermore, the fusion method proposed in Section 3.1.2 can effectively integrate ID and textual representations at the sequence level. In this part, we theoretically demonstrate these superior properties of TedRec in sequence-level text-ID semantic fusion (Lemma 3.1) and contextual user behavior integration (Lemma 3.2). Sequence-level Text-ID Semantic Fusion. In the setting of our proposed TedRec for sequential recommendation, the text-ID semantic fusion in the frequency domain can effectively integrate the contextual information of text and ID representations at the sequence level. Formally, we can prove the following lemma to associate the frequency domain with the time domain: Lemma 3.1. The text-ID semantic fusion in the frequency domain ( i.e., F 1 ğ‘— ( Ëœ ğ‘» âŠ™ Ëœ ğ‘¬ ) in Eq. (8) ) is equivalent to the text-ID contextual convolution in the time domain ( i.e., Ë ğ‘› -1 ğ‘˜ = 0 ğ’• ğ‘˜ âŠ™ ğ’† ( ğ‘— -ğ‘˜ ) % ğ‘› ). Proof . By the definition of Fourier transformation, we can obtain:  where '%' is the modular operation, ğ’‡ ğ‘— is the circular convolution operation, which aggregates the pair-wise similarity between the textual data ğ’• ğ‘˜ and the ID feature ğ’† ğ‘— -ğ‘˜ within the given sequence. Similar to CNN [18, 33], our proposed mutual filtering operation Sequence-level Semantic Representation Fusion for Recommender Systems Conference acronym'XX, June 03-05, 2018, Woodstock, NY by dimension (Eq. (8)) is essentially a convolution operation over the sequences of ID and text embeddings. Therefore, it can effectively capture the global contexts of the entire interaction sequence for semantic fusion (before attention interaction in Transformer). Contextual Integration. As proved in Lemma 3.1, the proposed approach can achieve sequence-level semantic fusion. In this part, we further study the specific forms of contextual integration possessed by our approach. Formally, we use the function ğ‘† ( ğ‘š,ğ‘› ) = Ë ğ‘› ğ‘— = ğ‘š = ğ’• ğ‘— âŠ™ ğ’† ( ğ‘š + ğ‘› -ğ‘— ) % ğ‘› to describe the sequential information between the ğ‘š -th position and ğ‘› -th position, e.g., S( 1 , 2 ) = ğ’• 1 âŠ™ ğ’† 2 + ğ’• 2 âŠ™ ğ’† 1 , S( ğ‘›, ğ‘› ) = ğ’• ğ‘› âŠ™ ğ’† ğ‘› . We have the following observation: Lemma 3.2. Given the ID embeddings { ğ’† 1 , Â· Â· Â· , ğ’† ğ‘› } and the text embeddings { ğ’• 1 , Â· Â· Â· , ğ’• ğ‘› } , the fused representations can be denoted as { ğ’‡ 1 , Â· Â· Â· , ğ’‡ ğ‘› } , where each element can be modeled by combining both the past and future information of the sequence, i.e., ğ’‡ ğ‘— = S( 0 , ğ‘— ) + S( ğ‘— + 1 , ğ‘› -1 ) . Proof. According to Eq. (15), for the ğ‘— -th position, we obtain:  It shows that our proposed convolution operation at some specific position is capable of integrating both the past and future sequential information, which is similar to the bidirectional sequential modeling in BERT [4]. Such a property is particularly important for modeling sequential user behavior data, which may also possess some potential merits. For example, since S is only related to the sequential context, the sequences with the same preceding or subsequent parts will share partial representations, which can be utilized to improve the generalization capabilities of predictive models ( e.g., reusing the learned partial representations for a new sequence). These properties will be investigated in future work.",
  "3.3 Discussion": "Comparison with Existing Work . As shown in Table 1, we compare several sequential models with side information fusion to highlight our novelty and differences. First, previous studies on side information fusion typically perform item-level fusion such as representation concatenation [8, 12], while our work conducts text-ID semantic fusion in the frequency domain through Fourier transformation. As proved in Lemma 3.1 and 3.2, the proposed approach can effectively fuse the semantics of ID and text embeddings at a sequence level, which has the similar effect of sequential convolution. Secondly, we propose to employ MoE enhanced modulation approach to enhance the discriminability of the text embeddings from the PLM encoder, which injects positional information to text Table 1: Comparison of different methods. 'Distinguishable' denotes that textual representations are enhanced for alignment and uniformity. 'Sequence-level' fusion considers cross-item fusion within a sequence, and 'MA' denotes the model-agnostic fusion. Table 2: Statistics of the processed datasets. embeddings via multiple sets of modulation embeddings. Thirdly, our approach is general and flexible to work with various text encoders and recommender backbones, which has an extensive applicability in existing recommender systems (see Section 4.3). Complexity Analysis . Our model mainly utilizes operations of FFT in Eq. (1) and inverse FFT in Eq. (2) to conduct the space transformation, with the time complexity of O( ğ‘›ğ‘‘ log ğ‘› ) as discussed in Section 2, where ğ‘‘ is the hidden dimension and ğ‘› is the number of interacted items within an interaction sequence. In Section 3.1.1, the cost of frequency modulation is O( ğºğ‘›ğ‘‘ ) and ğº denotes the number of experts. As for text-ID semantic fusion in Section 3.1.2, the time complexity of element-wise multiplication in Eq. (8) and gating mechanism in Eq. (11) is O( ğ‘›ğ‘‘ ) . Therefore, the complexity of textual representation fusion in TedRec is O( ğ‘› ( ğº + log ğ‘› ) ğ‘‘ ) . In general, our proposed method is comparable to existing approaches [8, 14] since ğ‘‘ , ğº and ğ‘› are constants independent of the model architecture. In terms of the model backbone ( e.g., SASRec), our plug-and-play framework has no additional time cost to the self-attention mechanism for modeling sequential patterns in Eq. (12). Furthermore, our approach does not require any additional training of PLMs, which ensures the efficiency of our proposed TedRec.",
  "4 EXPERIMENT": "",
  "4.1 Experimental Setting": "4.1.1 Dataset Descriptions. As shown in Table 2, our experiments are conducted on five public benchmark datasets varying in platform, scale and sparsity. MovieLens-1M [10] is one of the most widely used datasets in recommender systems, which collects one million ratings of movies from the MovieLens website. We concatenate the fields of title , genre and year of a movie as the descriptive Conference acronym'XX, June 03-05, 2018, Woodstock, NY Anonymous text. Online Retail (OR) [1] is a transnational dataset containing transaction records from an e-commerce platform in UK, and the description field is utilized as the text of items. Office , Food and Movies are three subsets from the real-world product reviews in Amazon [26], and we adopt the up-to-date version released in 2018. Following previous studies [13, 14], we concatenate fields of title , categories and brand as the textual feature. In line with the existing literature [17, 23, 49], we apply the five-core strategy to filter inactive users and unpopular items with fewer than five records. Baselines. We compare TedRec with several approaches as follows. Â· SASRec [17] is the first sequential recommender based on the unidirectional self-attention mechanism. Â· FMLP-Rec [50] introduces learnable filters to replace the selfattention mechanism with vanilla multilayer perceptron (MLP). Â· FEARec [6] proposes the frequency enhanced attention network, and contrastive learning is utilized to align representations. Â· SASRecF [12] concatenates representations of both items and item attributes as the fused input to extend SASRec. Â· FDSA [46] utilizes two different Transformer encoders to encode items and features, respectively. Then it concatenates attention outputs from two encoders as the final output by late fusion. Â· S 3 Rec [49] is the first work to incorporate self-supervised learning in sequential recommendation with four pre-training tasks. Â· DIF-SR [42] improves the side information fusion in Transformerbased recommendation by decoupled self-attention mechanism. Â· UniSRec [14] utilizes the textual descriptions of items to learn transferable representations. For a fair comparison, we train UniSRec from scratch without pre-training on additional datasets. Â· DLFS-Rec [23] regards representations of items and side information as the Gaussian distribution, and proposes distribution-based learnable filters for modeling sequences of items. Â· SMLP4Rec [8] captures sequential, cross-channel, and crossfeature dependencies for tri-directional side information fusion. 4.1.2 Evaluation Metrics. To evaluate the performance of next-item prediction, we apply the leave-one-out strategy [8, 31, 49] to split the interaction sequence of one user into training, validation and test sets, respectively. We compute metrics based on the full-sort protocol that ranks the ground-truth item among all items, and results are averaged over all users [6, 14]. For evaluation metrics, we utilize two commonly adopted ranking metrics Recall@K and NDCG@K [16], where K is set to 10 and 20 in our experiments. 4.1.3 Implementation Details. We implement all models based on the open-source benchmark library RecBole [47]. To ensure a fair comparison, we optimize models with the Adam optimizer and cross-entropy loss, and all experiments are conducted on the NVIDIA A100 machine. For all models, the training batch size is set to 2,048, and we adopt the early-stopping strategy to finish training when NDCG@10 on the validation set does not improve for 10 epochs. We also tune the learning rate in {5e-4,1e-3,5e-3} for the optimal performance. For baselines, we carefully search the hyperparameters following original papers. Furthermore, we provide our code, datasets and logged results to improve reproducibility at this repository: https://github.com/RUCAIBox/TedRec.",
  "4.2 Performance Comparison": "As shown in Table 3, we compare TedRec with baselines on five public datasets, and empirical findings are summarized as follows. For the ID-based models, SASRec [17] and FEARec [6] utilize the self-attention module, while FMLP-Rec [50] and FEARec consider frequency-enhanced representations. The performance of MLPbased FMLP-Rec is better than that of SASRec, demonstrating the superiority of filtering algorithms ( e.g., Band-Stop Filter) on attenuating the noise information of user interactions [6, 23, 50]. Furthermore, FEARec performs better than FMLP-Rec due to the attention mechanism in the frequency domain and contrastive learning techniques. Meanwhile, FEARec based on the pure IDs is comparable to text-enhanced models on the dense MovieLens-1M dataset, indicating the importance of fully modeling textual features. For sequential models with textual information fusion, SASRecF [12], FDSA [46], S 3 Rec [49] and DIF-SR [42] integrate the item texts into the self-attention framework from perspectives of early fusion, late fusion, attribute pre-training, and decoupled attention, respectively. These four models have varying degrees of improvement compared to SASRec on different datasets, showcasing the effect of auxiliary item information in sequential recommendation. Further, our method outperforms UniSRec by a large margin since we propose the multi-expert modulation and contextual convolution modules to effectively fuse IDs and texts. As for SMLP4Rec [8], this approach fuses different views of sequences in the time domain, but fails to capture fine-grained periodicity due to the existence of noise. DLFS-Rec [23] is the most competitive baseline, because it adopts Gaussian distributions to represent items and additional features, and models item sequences with learnable filters. However, it still uses item-level operations such as concatenation to combine two kinds of distributions, limiting the flexibility of sequence-level fusion for frequency enhanced representations. In general, the superior performance of our method against all baselines on five datasets verifies the effectiveness of TedRec.",
  "4.3 Further Analysis": "4.3.1 Ablation Study. In this part, we examine whether each of our proposed components plays a positive effect in the final performance. As for the ablation study, we analyze the following four variants of our method for comparison. (1) w/o MM replaces the multi-expert modulation in our textual representations (Eq. (5)) with the item encoding architecture in UniSRec, which adopts MoEenhanced parametric whitening without our modulation embedding. (2) w/o AG replaces the adaptive gate in contextual convolution with direct additions in Eq. (11). (3) w/o IF removes the item convolution in the frequency domain with pure item embeddings. (4) w/o TF removes the contextual convolution in the frequency domain with the vector product of text and IDs in the time domain. The performance comparison of our method with four variants is illustrated in Figure 3. It can be observed that all the proposed components in TedRec affect the overall recommendation performance, and our final framework achieves the best. Moreover, on the sparse Online Retail dataset, the variant w/o TF gets poor results since the sequence-level representation fusion plays an important role in providing semantic attributes for collaborative information. Sequence-level Semantic Representation Fusion for Recommender Systems Conference acronym'XX, June 03-05, 2018, Woodstock, NY Table 3: Overall Performance Comparison. The best and runner-up results are bold and underlined, respectively. 'Impr' means the improvement of our proposed TedRec over the best baseline, and '*' denotes that improvements are significant at the level of 0.01 with paired t-test. 'R@K' and 'N@K' stand for Recall@K and NDCG@K, respectively. Recall@10 Figure 3: Ablation study of our variants. w/o MM w/o AG w/o IF w/o TF Original MovieLens-1M 0.12 0.16 0.20 0.24 0.28 Recall@10 (a) MovieLens-1M w/o MM w/o AG w/o IF w/o TF Original MovieLens-1M 0.12 0.16 0.20 0.24 0.28 Recall@10 w/o MM w/o AG w/o IF w/o TF Original Online Retail 0.18 0.19 0.20 0.21 0.22 0.23 w/o MM w/o AG w/o IF w/o TF Original Online Retail 0.18 0.19 0.20 0.21 0.22 0.23 Recall@10 (b) Online Retail 30 180 330 480 630 780 Training time per epoch (s) 0.21 0.22 0.23 0.24 0.25 0.26 0.27 Recall@10 SASRec FMLPRec FEARec SASRecF FDSA DIF-SR UniSRec DLFS-Rec SMLP4Rec Ours (a) MovieLens-1M 0 100 200 300 400 Training time per epoch (s) 0.145 0.160 0.175 0.190 0.205 0.220 Recall@10 SASRec FMLPRec FEARec SASRecF FDSA DIF-SR UniSRec DLFS-Rec SMLP4Rec Ours (b) Online Retail 4.3.2 Efficiency Comparison. To further analyze the training efficiency of our proposed method, we plot scatter charts of efficiency (training time per epoch) and effectiveness (Recall@10) on two datasets. As shown in Figure 4, we can observe that our method has comparable efficiency with baseline models, while there is a significant improvement w.r.t. recommendation performance. In terms of the competitive baselines FEARec [6] and DLFS-Rec [23], despite their outstanding recommendation performance compared to other baselines, FEARec and DLFS-Rec have the common problem of long training time. The reason is that reconstruction of training data in contrastive learning ( i.e., FEARec) and Wasserstein distance calculation in Gaussian distributions ( i.e., DLFS-Rec) are time-consuming, limiting the training efficiency of practical applications. 4.3.3 Impact of User Groups. To analyze the impact of our method on user groups with different user activity, we divide all users in the Figure 4: Performance comparison w.r.t. training efficiency. test set into different groups based on their interactions in the training set. As shown in Figure 5, we can observe that the improvements of our method compared to baselines with textual features are significant among all groups on two datasets. Especially, the bar chart indicates that both two datasets present a long-tail distribution. For inactive users with fewer interactions, our proposed TedRec still achieves performance improvement compared to other baselines, indicating the superiority of our fusion scheme. 4.3.4 Impact of Model Backbones. To verify the model-agnostic property and generalization ability of our method, we implement our framework on four model backbones and report the performance difference. As shown in Table 4, we can observe that our proposed method can consistently improve the performance of UniSRec, DLFS-Rec, SASRecF and DIF-SR, validating the effectiveness of TedRec on different models. Furthermore, the improvements on UniSRec and DLFS-Rec are significant compared to SASRecF Conference acronym'XX, June 03-05, 2018, Woodstock, NY Anonymous Figure 5: Performance comparison for users with different levels of sparsity. The line chart denotes the improvements of corresponding models compared to SASRec w.r.t. Recall@10, while the bar chart represents the number of users in the test set considering interactions within a specified interval. [0, 50] (50, 100] (100, 150] (150, 200] (200, 250] (250, 300] 0 400 800 1200 1600 2000 # Users in the test set -0.1 0.0 0.1 0.2 0.3 Impr. of Recall@10 SASRec SASRecF DIF-SR FDSA DLFS-Rec Ours (a) MovieLens-1M [0, 10] (10, 20] (20, 30] (30, 40] (40, 50] 0 1000 2000 3000 4000 5000 6000 # Users in the test set -0.35 -0.10 0.15 0.40 0.65 0.90 Impr. of Recall@10 SASRec SASRecF DIF-SR FDSA DLFS-Rec Ours (b) Online Retail Table 4: Performance comparison w.r.t. different models. and DIF-SR. A possible reason is that SASRecF and DIF-SR do not consider textual modeling or expert modulation, which limits the effectiveness of our frequency-aware semantic fusion method. 4.3.5 Impact of Textual Representations. As shown in Table 5, we compare the performance of four language models on TedRec, namely BERT [4], T5 [29], Flan-T5 [2], and LLaMA2 [34]. Besides, we use random vectors as textual representations (denoted by 'Random') to highlight the semantic merits of language models. In general, the 'CLS' embedding from pre-trained BERT achieves the best performance among four models, and the possible reason is that the mean pooling of tokens in a text sequence is not an appropriate way to mine semantics. Despite the remarkable emergence ability of large language models (LLMs) such as T5 and LLaMA2 [48], they have insignificant advantage in our method w.r.t. semantic modeling, and advanced strategies leveraged for LLM-empowered recommender systems still wait to be explored.",
  "5 RELATED WORK": "Sequential Recommendation. Sequential recommendation models leverage the chronological item sequences of users to understand their preferences and recommend following items. With the development of deep neural networks, various complicated model architectures have been leveraged to better characterize user preferences Table 5: Performance comparison w.r.t. textual representations. for sequential recommendation, including convolutional neural networks [33] and recurrent neural networks [20, 32]. In line with the emergence of the self-attention mechanism in Transformer [36], SASRec [17], BERT4Rec [31] and CL4SRec [41] present better performance on extracting essential features. Additionally, some of prior work take advantage of graph neural networks (GNN) to capture high-order structures [25, 39, 43], involving item transition patterns in historical interaction sequences. Furthermore, Zhou et al. [50] propose an all-MLP architecture with learnable filters to enhance recommendation performance. Latest work further develops the architecture of filter-based algorithms in the frequency domain to attenuate noise and explore periodic preferences [6, 23, 30]. Side Information Fusion. Side information fusion in sequential recommendation aims to integrate side information ( e.g., item attributes) for better representing items and improving next-item predictions. Some prior work leverages late fusion and pre-training strategies based on self-attention mechanism to fuse side information, including FDSA [46] and ğ‘† 3 -Rec [49]. Recent studies concentrate on encoding side information with item representations as the input of recommendation models, including concatenation, graph-embedding aggregation and attention fusion [12, 22]. In addition to the early fusion of embedding, DIF-SR [42] moves the side information from the input to the attention layer and decouples the attention calculation for side information. Since items and their side information can be represented by stochastic Gaussian distribution, DLFS-Rec [23] makes usage of mean and covariance embeddings of the distribution to formulate final embeddings for each item. Language Models for Recommender Systems. Pre-trained language models (PLMs) are proficient in natural language understanding and reasoning tasks, which can be categorized into two types: discriminative models and generative models. Existing literature utilizes discriminative models to generate textual representations of users and items for recommender systems [21, 27, 45]. For example, UniSRec [14] tends to combine various textual information ( e.g., item descriptions) and designs adaptive model architecture to enhance the ability of universal representation learning. On the other hand, several researchers utilize generative language models and convert recommendation tasks to either language understanding or generation tasks [3, 9]. Besides, generative language models can also be leveraged for data augmentation, e.g., KAR [40] and LLMRG [38] extract abundant types of textual information and aggregate them into fused embeddings through MoE or GNN [43]. Sequence-level Semantic Representation Fusion for Recommender Systems Conference acronym'XX, June 03-05, 2018, Woodstock, NY",
  "6 CONCLUSION": "In this paper, we propose a novel Te xt-I D semantic fusion approach for sequential Rec ommendation, namely TedRec . The core idea of our approach is to conduct a sequence-level semantic representation fusion approach by better integrating global contexts. To achieve this, we devise an MoE enhanced modulation method to improve the discriminability of textual representations from the text encoder, by adaptively injecting positional information. Furthermore, we transform the text and ID embeddings by Fourier Transform from time domain to frequency domain , and employ multiplicative operations to effectively fuse the two kinds of item features. Our fusion approach is simple yet effective, which can be proved to have the same effects of contextual convolution for sequence-level semantic fusion. Extensive experiments conducted on five public datasets demonstrate the effectiveness and efficiency of our approach. For future work, we will further consider leveraging the contextual convolution strategy in the frequency domain to more recommendation tasks ( e.g., multi-modal recommendation) and other aspects of recommendation ( e.g., diversified recommendation).",
  "REFERENCES": "[1] Daqing Chen, Sai Laing Sain, and Kun Guo. 2012. Data mining for the online retail industry: A case study of RFM model-based customer segmentation using data mining. Journal of Database Marketing & Customer Strategy Management 19 (2012), 197-208. [2] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416 (2022). [3] Zeyu Cui, Jianxin Ma, Chang Zhou, Jingren Zhou, and Hongxia Yang. 2022. M6-rec: Generative pretrained language models are open-ended recommender systems. arXiv preprint arXiv:2205.08084 (2022). [4] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT . Association for Computational Linguistics, 4171-4186. [5] Hao Ding, Yifei Ma, Anoop Deoras, Yuyang Wang, and Hao Wang. 2021. Zeroshot recommender systems. arXiv preprint arXiv:2105.08318 (2021). [6] Xinyu Du, Huanhuan Yuan, Pengpeng Zhao, Jianfeng Qu, Fuzhen Zhuang, Guanfeng Liu, Yanchi Liu, and Victor S Sheng. 2023. Frequency enhanced hybrid attention network for sequential recommendation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval . 78-88. [7] Xinyan Fan, Zheng Liu, Jianxun Lian, Wayne Xin Zhao, Xing Xie, and Ji-Rong Wen. 2021. Lighter and better: low-rank decomposed self-attention networks for next-item recommendation. In Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval . 1733-1737. [8] Jingtong Gao, Xiangyu Zhao, Muyang Li, Minghao Zhao, Runze Wu, Ruocheng Guo, Yiding Liu, and Dawei Yin. 2023. SMLP4Rec: An Efficient all-MLP Architecture for Sequential Recommendations. ACM Transactions on Information Systems (2023). [9] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022. Recommendation as language processing (rlp): A unified pretrain, personalized prompt & predict paradigm (p5). In Proceedings of the 16th ACM Conference on Recommender Systems . 299-315. [10] F Maxwell Harper and Joseph A Konstan. 2015. The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis) 5, 4 (2015), 1-19. [11] Michael Heideman, Don Johnson, and Charles Burrus. 1984. Gauss and the history of the fast Fourier transform. IEEE Assp Magazine 1, 4 (1984), 14-21. [12] BalÃ¡zs Hidasi, Massimo Quadrana, Alexandros Karatzoglou, and Domonkos Tikk. 2016. Parallel recurrent neural network architectures for feature-rich session-based recommendations. In Proceedings of the 10th ACM conference on recommender systems . 241-248. [13] Yupeng Hou, Zhankui He, Julian McAuley, and Wayne Xin Zhao. 2023. Learning vector-quantized item representation for transferable sequential recommenders. In Proceedings of the ACM Web Conference 2023 . 1162-1171. [14] Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Bolin Ding, and Ji-Rong Wen. 2022. Towards universal sequence representation learning for recommender systems. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 585-593. [15] Junjie Huang, Duyu Tang, Wanjun Zhong, Shuai Lu, Linjun Shou, Ming Gong, Daxin Jiang, and Nan Duan. 2021. WhiteningBERT: An Easy Unsupervised Sentence Embedding Approach. In EMNLP (Findings) . Association for Computational Linguistics, 238-244. [16] Kalervo JÃ¤rvelin and Jaana KekÃ¤lÃ¤inen. 2002. Cumulated gain-based evaluation of IR techniques. ACM Trans. Inf. Syst. 20, 4 (2002), 422-446. [17] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In 2018 IEEE international conference on data mining (ICDM) . IEEE, 197-206. [18] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems 25 (2012). [19] Bohan Li, Hao Zhou, Junxian He, Mingxuan Wang, Yiming Yang, and Lei Li. 2020. On the Sentence Embeddings from Pre-trained Language Models. In EMNLP (1) . Association for Computational Linguistics, 9119-9130. [20] Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017. Neural attentive session-based recommendation. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management . 1419-1428. [21] Jiacheng Li, Ming Wang, Jin Li, Jinmiao Fu, Xin Shen, Jingbo Shang, and Julian McAuley. 2023. Text Is All You Need: Learning Language Representations for Sequential Recommendation. arXiv preprint arXiv:2305.13731 (2023). [22] Chang Liu, Xiaoguang Li, Guohao Cai, Zhenhua Dong, Hong Zhu, and Lifeng Shang. 2021. Noninvasive self-attention for side information fusion in sequential recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 35. 4249-4256. [23] Haibo Liu, Zhixiang Deng, Liang Wang, Jinjia Peng, and Shi Feng. 2023. Distribution-based Learnable Filters with Side Information for Sequential Recommendation. In Proceedings of the 17th ACM Conference on Recommender Systems . 78-88. [24] Qijiong Liu, Nuo Chen, Tetsuya Sakai, and Xiao-Ming Wu. 2024. ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models. In Proceedings of the ACM International Conference on Web Search and Data Mining . [25] Zhiwei Liu, Lin Meng, Fei Jiang, Jiawei Zhang, and Philip S Yu. 2020. Deoscillated graph collaborative filtering. arXiv preprint arXiv:2011.02100 (2020). [26] Jianmo Ni, Jiacheng Li, and Julian McAuley. 2019. Justifying recommendations using distantly-labeled reviews and fine-grained aspects. In Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP) . 188-197. [27] Zhaopeng Qiu, Xian Wu, Jingyue Gao, and Wei Fan. 2021. U-BERT: Pre-training user representations for improved recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 35. 4320-4327. [28] Lawrence R Rabiner and Bernard Gold. 1975. Theory and application of digital signal processing. Englewood Cliffs: Prentice-Hall (1975). [29] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research 21, 1 (2020), 5485-5551. [30] Yehjin Shin, Jeongwhan Choi, Hyowon Wi, and Noseong Park. 2023. An Attentive Inductive Bias for Sequential Recommendation Beyond the Self-Attention. arXiv preprint arXiv:2312.10325 (2023). [31] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM international conference on information and knowledge management . 1441-1450. [32] Yong Kiam Tan, Xinxing Xu, and Yong Liu. 2016. Improved recurrent neural networks for session-based recommendations. In Proceedings of the 1st workshop on deep learning for recommender systems . 17-22. [33] Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation via convolutional sequence embedding. In Proceedings of the eleventh ACM international conference on web search and data mining . 565-573. [34] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 (2023). [35] Charles Van Loan. 1992. Computational frameworks for the fast Fourier transform . SIAM. [36] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems 30 (2017). [37] Jianfang Wang, Zhiqiang Wu, Guang Chen, Detao Liu, and Qiuling Zhang. 2021. An Adaptive Multi-pairwise Ranking with Implicit Feedback for Recommendation. In 2021 IEEE 20th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom) . IEEE, 1005-1012. Conference acronym'XX, June 03-05, 2018, Woodstock, NY Anonymous [38] Yan Wang, Zhixuan Chu, Xin Ouyang, Simeng Wang, Hongyan Hao, Yue Shen, Jinjie Gu, Siqiao Xue, James Y Zhang, Qing Cui, et al. 2023. Enhancing recommender systems with large language model reasoning graphs. arXiv preprint arXiv:2308.10835 (2023). [39] Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-based recommendation with graph neural networks. In Proceedings of the AAAI conference on artificial intelligence , Vol. 33. 346-353. [40] Yunjia Xi, Weiwen Liu, Jianghao Lin, Jieming Zhu, Bo Chen, Ruiming Tang, Weinan Zhang, Rui Zhang, and Yong Yu. 2023. Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models. arXiv preprint arXiv:2306.10933 (2023). [41] Xu Xie, Fei Sun, Zhaoyang Liu, Shiwen Wu, Jinyang Gao, Jiandong Zhang, Bolin Ding, and Bin Cui. 2022. Contrastive learning for sequential recommendation. In 2022 IEEE 38th international conference on data engineering (ICDE) . IEEE, 12591273. [42] Yueqi Xie, Peilin Zhou, and Sunghun Kim. 2022. Decoupled side information fusion for sequential recommendation. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1611-1621. [43] Chengfeng Xu, Pengpeng Zhao, Yanchi Liu, Victor S Sheng, Jiajie Xu, Fuzhen Zhuang, Junhua Fang, and Xiaofang Zhou. 2019. Graph contextualized selfattention network for session-based recommendation.. In IJCAI , Vol. 19. 39403946. [44] Zheng Yuan, Fajie Yuan, Yu Song, Youhua Li, Junchen Fu, Fei Yang, Yunzhu Pan, and Yongxin Ni. 2023. Where to go next for recommender systems? id-vs. modality-based recommender models revisited. arXiv preprint arXiv:2303.13835 (2023). [45] Song Zhang, Nan Zheng, and Danli Wang. 2022. GBERT: Pre-training User representations for Ephemeral Group Recommendation. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management . 2631-2639. [46] Tingting Zhang, Pengpeng Zhao, Yanchi Liu, Victor S Sheng, Jiajie Xu, Deqing Wang, Guanfeng Liu, Xiaofang Zhou, et al. 2019. Feature-level Deeper SelfAttention Network for Sequential Recommendation.. In IJCAI . 4320-4326. [47] Wayne Xin Zhao, Shanlei Mu, Yupeng Hou, Zihan Lin, Yushuo Chen, Xingyu Pan, Kaiyuan Li, Yujie Lu, Hui Wang, Changxin Tian, Yingqian Min, Zhichao Feng, Xinyan Fan, Xu Chen, Pengfei Wang, Wendi Ji, Yaliang Li, Xiaoling Wang, and Ji-Rong Wen. 2021. RecBole: Towards a Unified, Comprehensive and Efficient Framework for Recommendation Algorithms. In CIKM . ACM, 4653-4664. [48] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023. A survey of large language models. arXiv preprint arXiv:2303.18223 (2023). [49] Kun Zhou, Hui Wang, Wayne Xin Zhao, Yutao Zhu, Sirui Wang, Fuzheng Zhang, Zhongyuan Wang, and Ji-Rong Wen. 2020. S3-rec: Self-supervised learning for sequential recommendation with mutual information maximization. In Proceedings of the 29th ACM international conference on information & knowledge management . 1893-1902. [50] Kun Zhou, Hui Yu, Wayne Xin Zhao, and Ji-Rong Wen. 2022. Filter-enhanced MLP is all you need for sequential recommendation. In Proceedings of the ACM web conference 2022 . 2388-2399.",
  "keywords_parsed": [
    "Sequential Recommendation",
    "Textual Representation Fusion"
  ],
  "references_parsed": [
    {
      "ref_id": "b1",
      "title": "Data mining for the online retail industry: A case study of RFM model-based customer segmentation using data mining"
    },
    {
      "ref_id": "b2",
      "title": "Scaling instruction-finetuned language models"
    },
    {
      "ref_id": "b3",
      "title": "M6-rec: Generative pretrained language models are open-ended recommender systems"
    },
    {
      "ref_id": "b4",
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
    },
    {
      "ref_id": "b5",
      "title": "Zeroshot recommender systems"
    },
    {
      "ref_id": "b6",
      "title": "Frequency enhanced hybrid attention network for sequential recommendation"
    },
    {
      "ref_id": "b7",
      "title": "Lighter and better: low-rank decomposed self-attention networks for next-item recommendation"
    },
    {
      "ref_id": "b8",
      "title": "SMLP4Rec: An Efficient all-MLP Architecture for Sequential Recommendations"
    },
    {
      "ref_id": "b9",
      "title": "Recommendation as language processing (rlp): A unified pretrain, personalized prompt & predict paradigm (p5)"
    },
    {
      "ref_id": "b10",
      "title": "The movielens datasets: History and context"
    },
    {
      "ref_id": "b11",
      "title": "Gauss and the history of the fast Fourier transform"
    },
    {
      "ref_id": "b12",
      "title": "Parallel recurrent neural network architectures for feature-rich session-based recommendations"
    },
    {
      "ref_id": "b13",
      "title": "Learning vector-quantized item representation for transferable sequential recommenders"
    },
    {
      "ref_id": "b14",
      "title": "Towards universal sequence representation learning for recommender systems"
    },
    {
      "ref_id": "b15",
      "title": "WhiteningBERT: An Easy Unsupervised Sentence Embedding Approach"
    },
    {
      "ref_id": "b16",
      "title": "Cumulated gain-based evaluation of IR techniques"
    },
    {
      "ref_id": "b17",
      "title": "Self-attentive sequential recommendation"
    },
    {
      "ref_id": "b18",
      "title": "Imagenet classification with deep convolutional neural networks"
    },
    {
      "ref_id": "b19",
      "title": "On the Sentence Embeddings from Pre-trained Language Models"
    },
    {
      "ref_id": "b20",
      "title": "Neural attentive session-based recommendation"
    },
    {
      "ref_id": "b21",
      "title": "Text Is All You Need: Learning Language Representations for Sequential Recommendation"
    },
    {
      "ref_id": "b22",
      "title": "Noninvasive self-attention for side information fusion in sequential recommendation"
    },
    {
      "ref_id": "b23",
      "title": "Distribution-based Learnable Filters with Side Information for Sequential Recommendation"
    },
    {
      "ref_id": "b24",
      "title": "ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models"
    },
    {
      "ref_id": "b25",
      "title": "Deoscillated graph collaborative filtering"
    },
    {
      "ref_id": "b26",
      "title": "Justifying recommendations using distantly-labeled reviews and fine-grained aspects"
    },
    {
      "ref_id": "b27",
      "title": "U-BERT: Pre-training user representations for improved recommendation"
    },
    {
      "ref_id": "b28",
      "title": "Theory and application of digital signal processing"
    },
    {
      "ref_id": "b29",
      "title": "Exploring the limits of transfer learning with a unified text-to-text transformer"
    },
    {
      "ref_id": "b30",
      "title": "An Attentive Inductive Bias for Sequential Recommendation Beyond the Self-Attention"
    },
    {
      "ref_id": "b31",
      "title": "BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer"
    },
    {
      "ref_id": "b32",
      "title": "Improved recurrent neural networks for session-based recommendations"
    },
    {
      "ref_id": "b33",
      "title": "Personalized top-n sequential recommendation via convolutional sequence embedding"
    },
    {
      "ref_id": "b34",
      "title": "Llama 2: Open foundation and fine-tuned chat models"
    },
    {
      "ref_id": "b35",
      "title": "Computational frameworks for the fast Fourier transform"
    },
    {
      "ref_id": "b36",
      "title": "Attention is all you need"
    },
    {
      "ref_id": "b37",
      "title": "An Adaptive Multi-pairwise Ranking with Implicit Feedback for Recommendation"
    },
    {
      "ref_id": "b38",
      "title": "Enhancing recommender systems with large language model reasoning graphs"
    },
    {
      "ref_id": "b39",
      "title": "Session-based recommendation with graph neural networks"
    },
    {
      "ref_id": "b40",
      "title": "Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models"
    },
    {
      "ref_id": "b41",
      "title": "Contrastive learning for sequential recommendation"
    },
    {
      "ref_id": "b42",
      "title": "Decoupled side information fusion for sequential recommendation"
    },
    {
      "ref_id": "b43",
      "title": "Graph contextualized self-attention network for session-based recommendation"
    },
    {
      "ref_id": "b44",
      "title": "Where to go next for recommender systems? id-vs. modality-based recommender models revisited"
    },
    {
      "ref_id": "b45",
      "title": "GBERT: Pre-training User representations for Ephemeral Group Recommendation"
    },
    {
      "ref_id": "b46",
      "title": "Feature-level Deeper Self-Attention Network for Sequential Recommendation"
    },
    {
      "ref_id": "b47",
      "title": "RecBole: Towards a Unified, Comprehensive and Efficient Framework for Recommendation Algorithms"
    },
    {
      "ref_id": "b48",
      "title": "A survey of large language models"
    },
    {
      "ref_id": "b49",
      "title": "S3-rec: Self-supervised learning for sequential recommendation with mutual information maximization"
    },
    {
      "ref_id": "b50",
      "title": "Filter-enhanced MLP is all you need for sequential recommendation"
    }
  ]
}