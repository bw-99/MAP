{"title": "\"I Like Sunnie More Than I Expected!\": Exploring User Expectation and Perception of an Anthropomorphic LLM-based Conversational Agent for Well-Being Support", "authors": "Siyi Wu; Julie Y A Cachia; Tianyi Xie; Xuan Zhao", "pub_date": "2024-10-07", "abstract": "The human-computer interaction (HCI) research community has a longstanding interest in exploring the mismatch between users' actual experiences and expectation toward new technologies, for instance, large language models (LLMs). In this study, we compared users' (N = 38) initial expectations against their post-interaction perceptions of two LLM-powered mental well-being intervention activity recommendation systems. Both systems have a build-in LLM to recommend personalized well-being intervention activity, but one system (Sunnie) has an anthropomorphic conversational interaction design via elements such as appearance, persona, and natural conversation. Results showed that user engagement was high with both systems, and both systems exceeded users' expectations along the utility dimension, highlighting AI's potential to offer useful intervention activity recommendations. In addition, Sunnie further outperformed the non-anthropomorphic baseline system in relational warmth. These findings suggest that anthropomorphic conversational interaction design may be particularly effective in fostering warmth in mental health support contexts.", "sections": [{"heading": "", "text": "Fig. 1. Sunnie is an anthropomorphic LLM-based conversational agent, designed to improve well-being through personalized microactivity recommendations. Sunnie consists of three key features: the anthropomorphic design of Sunnie's appearance and the persona prompts, the multi-turn natural conversation of well-being coaching, and the LLM-based personalized activity recommendation module. The four panels depict users' interactions with Sunnie: (A) users select the best word(s) that describe their feelings, (B) users enter a description of the perceived source of their feelings, (C) users interact with Sunnie in a multi-turn conversation, and (D) Sunnie recommends a personalized activity to support users' well-being.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "INTRODUCTION", "text": "In recent years, mental well-being support has become increasingly critical as demand for services continues to grow while access to mental health professionals remains limited [6,91]. In response, a variety of evidence-based intervention activities have been developed [79,109]. These are small, manageable actions designed to improve mental well-being, based on established frameworks such as the PERMA model [108] and other research on physical and cognitive activities [93,124]. However, despite the wealth of information on activities to improve well-being, most people still find it difficult to integrate these activities into their daily routines, even when they understand the potential benefits [100,105]. This gap between awareness and action (i.e., the knowledge-action gap) can be attributed to several factors, including lack of motivation, perceived difficulty in adopting new behaviors, and the absence of personalized guidance [54,100,103].\nOne promising approach to bridge the knowledge-action gap is through mental well-being activity recommendation systems, which use algorithms to promote positive behaviors and well-being [2,40,44,71,73,116,132]. Approaches such as gamified apps and music-based technologies have been explored for their ability to create interactive experiences that reinforce prosocial behaviors [93,124]. However, these systems often rely on passive interactions, focusing on external rewards or mood modulation without fostering deep emotional engagement or two-way communication [13,63,104,118].\nTo create more interactive and engaging experiences, conversational agents have emerged as a solution, offering conversational interactions that encourage user engagement and support the adoption of healthier behaviors [4, 28, 55-58, 62, 82, 90, 90, 97, 112, 132]. Research has shown their utility in improving lifestyle habits, such as promoting physical activity, better diet, and improved sleep quality [4,29,57,90,96,110,125]. Despite these advances, conversational agents still face challenges in delivering highly personalized and contextually relevant suggestions, often requiring significant user input and struggling to adapt to evolving user needs [4,57,90,95,100,105,110,136].\nThe emergence of large language models (LLMs) presents new possibilities to enhance mental well-being intervention activities recommendation systems, with their superior natural language interpretation capabilities, which could foster a more nuanced understanding of context, recommend appropriate intervention activities, and provide interactions through conversations [15,23,83,115,120,128]. Such advantages of LLMs could lead to more acceptable intervention activity recommendation and more human-like user experiences, potentially increasing user engagement and adherence [76,81,111]. In addition, the integration of anthropomorphic design with conversational interfaces, such as avatars, facial expressions, and personalized conversational styles, has the potential to create interactions that feel more natural and emotionally resonant [14,16,64,106]. Despite the potential of LLM-based recommendation systems, there is limited research on their use in promoting intervention activities for well-being support. Most existing studies focus on improving personalization and providing a more human-like experience through conversations but rarely focus on facilitating action-taking or recommending activities to practice well-being [19,42,74,76,81,111,129]. This combination of LLM-based recommendation and anthropomorphic interaction offers a unique opportunity for mental well-being activity recommendation systems that make personalized recommendations and foster meaningful and engaging interactions, addressing both personalization and user experience gaps in current systems.\nFurthermore, there has been substantial research interest in the HCI community to explore the discrepancy between users' actual experience and expectations toward a novel technology, and how HCI researchers can bridge the gap with various design strategies. Previous research has shown that users often hold expectations that AI systems are high in agency (e.g., capacity for self-control) but low in experience (e.g., capacity to feel) [39]. These expectations might limit how much users are willing to rely on AI-driven mental health support, which may be perceived to stem from the capacity to feel. While previous research has examined expectations versus experience in other domains such as gaming [86] and conversational agents in various contexts [18,77], we build on this line of work to examine users' experience and expectations within the context of well-being applications and to specifically compare anthropomorphic versus non-anthropomorphic designs.\nThus, a critical yet unaddressed question is how: 1) the design of LLM-based mental well-being intervention activity recommendation systems, especially the incorporation of anthropomorphic features, influences users' perceptions and their willingness to engage in actions that support well-being, and 2) whether and to what extent users underestimate the capabilities of these systems.\nThus, our study is guided by three research questions:\n\u2022 RQ1: How do anthropomorphic designs of LLM-based mental well-being intervention activity recommendation systems shape users' perceptions of such systems? \u2022 RQ2: How do such designs influence users' engagement in adopting recommended mental well-being activities?\n\u2022 RQ3: To what extent do users' expectations of LLM-based systems align with their actual experiences of these systems?\nWe introduce Sunnie, an anthropomorphic LLM-based conversational agent designed to offer personalized well-being support and recommend practical actions grounded in positive psychology and social psychology research. Sunnie is an \"AI happiness coach and companion\" developed by Flourish Science, a public benefit corporation with the mission of \"personalizing the science of happiness and well-being to make it accessible, actionable, simple, and fun, thereby providing proactive and just-in-time mental health and well-being support. \" The version tested in the current study is powered by GPT-4 [3], an advanced LLM, to offer more human-like interactions, thereby enhancing personalization and encouraging users to take action to improve their well-being.\nWe hypothesize that incorporating anthropomorphic features into the design of Sunnie will lead to more positive perceptions, which, in turn, will increase user engagement and the likelihood of adopting the recommended well-being activities. Additionally, we hypothesize that users may underestimate the capabilities of the anthropomorphic design, particularly in its ability to convey warmth. To test these hypotheses, we conducted an empirical user study that compared participants' expectations and perceptions of two different systems: Sunnie, an anthropomorphic LLM-based chatbot, and a non-anthropomorphic, non-conversational, LLM-based activity recommendation system. We used proxy metrics based on participants' perceptions of the system and their self-reported engagement with recommended activities. This approach aligns with prior research, which suggests that one-time interactions can provide valuable insights into potential long-term adoption and behavior change [11,21,130].\nThe core contributions of this paper are tri-fold:\n\u2022 Describe the design and development of Sunnie, an anthropomorphic LLM-based conversational agent equipped with emotion regulation coaching and well-being activity recommendations, aimed at enhancing personalized well-being support and facilitating proactive well-being management.\n\u2022 Report findings and insights from an empirical 3-day, within-subject user study through quantitative and qualitative analysis examining how anthropomorphic designs shape user perceptions, engagement, and how these perceptions align with their initial expectations.\n\u2022 Provide design considerations derived from our study results to foster the future development of LLM-based well-being support systems in terms of more personalized and effective support.", "publication_ref": ["b5", "b91", "b79", "b109", "b108", "b93", "b100", "b105", "b53", "b100", "b103", "b1", "b39", "b43", "b71", "b73", "b116", "b132", "b93", "b12", "b62", "b104", "b118", "b3", "b28", "b56", "b90", "b96", "b110", "b125", "b3", "b56", "b90", "b95", "b100", "b105", "b110", "b136", "b14", "b22", "b83", "b115", "b120", "b128", "b76", "b81", "b13", "b15", "b63", "b18", "b41", "b74", "b76", "b81", "b129", "b38", "b86", "b17", "b77", "b2", "b10", "b20", "b130"], "figure_ref": [], "table_ref": []}, {"heading": "RELATED WORK", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "AI in Activity Recommendation for Well-Being Support", "text": "While abundant information is available on activities that promote physical and psychological well-being, a significant gap exists in adherence and motivation to participate in these activities. AI-powered technologies, particularly chatbots, have been widely used to address this gap by promoting activities for well-being support [28, 55-58, 62, 82, 90, 97, 112, 132]. Building on this foundation, most studies have focused on encouraging physical activities, demonstrating the effectiveness of using chatbots to guide people toward a healthy lifestyle, such as promoting healthy diets, improving the duration and quality of sleep, quitting smoking, etc. [4,57,90,96,110]. These interventions have proven to be effective in various populations and age groups across both short-term and long-term studies.\nExpanding the scope, while research has shown the importance of activities promoting positive emotions and behaviors for well-being [78], a few studies focused on using chatbots to deliver positive psychology and Cognitive Behavior Therapy (CBT) interventions. For example, Kien et al. [78] studied the effectiveness and adherence of using chatbots to deliver positive psychology and CBT strategies; Rohani et al. [102] showed the positive impacts of MUBS [102], a smartphone-based system supporting Behavioral Activation (BA) treatment of depressive symptoms with a personalized content-based activity recommendation model based on multinomial Naive Bayes machine learning algorithms, in motivating patients to engage in pleasant activities.\nHowever, despite the potential of chatbots in promoting well-being activities, the challenges remain to ensure their effectiveness in user adherence. These challenges include the need for improved linguistic capabilities, more personalized content, and the integration of human-like identity features to improve user experience and engagement [1,66,119].\nBuilding on these gaps, our work aims to contribute to the field by studying the effectiveness of well-being activities recommended by a conversational agent with more human-like features, personalized recommendations, and improved linguistic capabilities using LLMs coupled with anthropomorphic designs. We seek to explore how these features can enhance the effectiveness and adherence of chatbot interventions for well-being support, addressing the current limitations in chatbot personalization and user engagement.", "publication_ref": ["b3", "b56", "b90", "b96", "b110", "b78", "b78", "b102", "b102", "b0", "b65", "b119"], "figure_ref": [], "table_ref": []}, {"heading": "LLM-Based Systems for Well-Being Support", "text": "The use of conversational agents to enhance well-being has a longstanding history [1,14], dating back to pioneering systems such as ELIZA [127]. This tradition continues with the advent of modern chatbots such as WoeBot [32] and Wysa [43], which are easily accessible to the public.\nIn the past, mental health chatbots primarily utilized rule-based systems [1], employing various therapeutic techniques to guide users through self-help exercises. These chatbots have been shown effective in enhancing well-being by encouraging self-disclosure [68,69], fostering self-compassion [67], and regulating users' emotions [25], etc. However, the rule-based nature of these chatbots often limits the natural flow of conversation [111].\nThe introduction of LLMs has sparked a new wave of interest in the potential of LLM-based conversational agents for mental health support [111], such as platforms like OpenAI's ChatGPT [3] and Replika [65]. The user-friendly conversational interfaces of these LLM-powered chatbots have sparked excitement among clinicians about the possibilities of novel AI-driven interventions [111]. These agents are designed to provide direct interaction with individuals seeking mental health support through various platforms, including personal digital companions [81], online on-demand counseling [19, 70, 74-76, 129, 134], emotional support [139], etc.\nBuilding on this foundation, our work aims to expand the utility of LLM-based conversational agents by incorporating activity recommendations alongside conversational support. By integrating more human-like features, personalized recommendations, and enhanced linguistic capabilities, we seek to explore how these features can enhance the effectiveness and adherence of chatbot interventions for well-being support, addressing the current limitations in chatbot personalization and user engagement.", "publication_ref": ["b0", "b13", "b127", "b31", "b42", "b0", "b68", "b69", "b67", "b24", "b2", "b64", "b81", "b139"], "figure_ref": [], "table_ref": []}, {"heading": "Anthropomorphism Design of LLM-Based Conversational Agent", "text": "One of the limitations of LLM-based conversational agents in mental health is concern about trust and safety [1]. Trust is a fundamental element in mental health support, and ensuring the safety and reliability of conversational agents is crucial for their acceptance and effectiveness. This concern highlights the need for careful design and ethical considerations in their development [7,68,72]. Anthropomorphism refers to the psychological phenomenon of \"attributing human characteristics to the nonhuman\" [106], is one aspect of this need that should be used with care, as it influences user expectations and reliance on AI systems, affecting how users perceive and interact with conversational agents [81].\nIn the anthropomorphic design for conversational agents, features can be broadly categorized into social and verbal cues [14,16,64,99,106]. Social cues encompass non-verbal elements that convey human-like traits and behaviors, such as human-like appearance, including facial expressions and gestures, interactivity that mimics human responsiveness, and behavioral features that reflect human personality, empathy, and social roles. These cues enhance the perceived humanness of the agent, making interactions more relatable and engaging [7,9,72]. On the other hand, verbal cues involve the use of language and communication styles that emulate human-like speech and interaction. This includes using natural language for intuitive and relatable communication, adherence to social norms such as politeness [14], greetings, and farewells, and providing advice in a manner consistent with human conversational patterns [8,20,72].\nThe appropriate anthropomorphic design can amplify social responses and build social relationships between humans and computers. By incorporating human nature and unique traits, as well as personality traits, the perceived human likeness of systems is increased, which can improve user engagement and satisfaction [106,114]. However, the implementation of anthropomorphic design must be balanced to avoid the uncanny valley phenomenon [126], where overly human-like design features can elicit feelings of eeriness or discomfort. This highlights the need for a nuanced approach to human-like design in conversational agents to ensure positive user perceptions and acceptance.\nResearch has explored how the design of AI systems influences people's perceptions in various settings, including clinical, social support, and public health interventions. However, there is a notable gap in understanding the specific influence of anthropomorphic designs on conversational agents, especially those aimed at fostering well-being activities.\nThe significance of grasping how users perceive these agents is critical for the development of AI interfaces that are not only effective, but also provide a sense of care and support. In addressing this gap, our research delves into the effects of anthropomorphic design elements on the user's perception of an AI-powered companion dedicated to promoting well-being practices.\nTo advance this area of study, we first introduced the design of Sunnie, an LLM-powered conversational agent that offers personalized guidance on emotion regulation and recommends relevant activities grounded in psychological research to improve well-being. To this end, we meticulously described its system architecture, design principles, user interface, and prompting framework. Next, we conducted an evaluation to understand people's perception of and experience with this conversational agent. Our approach stands out in its comprehensive consideration of how the integration of human-like characteristics within AI can transform the user experience, leading to a more positive and engaging interaction with technology aimed at supporting well-being and personal growth.", "publication_ref": ["b0", "b6", "b68", "b72", "b81", "b13", "b15", "b63", "b99", "b6", "b8", "b72", "b13", "b7", "b19", "b72", "b114", "b126"], "figure_ref": [], "table_ref": []}, {"heading": "SUNNIE: AN ANTHROPOMORPHIC LLM-BASED CONVERSATIONAL AGENT", "text": "Sunnie aims to leverage the potential of anthropomorphic design in LLM-based conversational agents to recommend activities that support well-being. This approach goes beyond the current state-of-the-art (SOTA) methods by not merely offering activity suggestions via chatbots but by capitalizing on the sophisticated capabilities of LLM-based agents to forge a deeply personalized and engaging interaction with users.\nIn the following sections, we delve into the design and developmental framework of Sunnie. We systematically unpack the architecture of Sunnie, beginning with an overview of the foundational design principles that guide this system. Following this, we highlight the distinctive features that set Sunnie apart, providing a detailed exploration of the innovative aspects that enhance user engagement and personalization. Finally, we articulate the methodological approach employed in the implementation of Sunnie, ensuring a coherent and robust application of these principles and features in practice.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Design Principles", "text": "The \"Computers are Social Actors\" (CASA) paradigm [88,89], also known as \"social response theory,\" suggests that users respond with social behavior and attributions when machines exhibit human-like features such as interactivity, natural language use, or human-like appearance. Initially proposed by Nass and Moon [88], this paradigm extends to conversational agents (CAs) [12,98,101,114], with research indicating that human-like behavior and social cues [30,106] in CAs can enhance social reactions, establish trust, and lead to perceptions of reliability. Critically, the literature reveals a nuanced understanding of how and why these phenomena occur. Firstly, it has been found that the more a CA resembles a human in the interactions, the more natural and effortless the user's response tends to be [10,24,114]. The naturalness of interaction is important for establishing trust between humans and CAs. Secondly, CAs' social cues have been shown to be effective in facilitating the development of trust and influencing the user's Fig. 2. The system architecture of Sunnie. Sunnie is supported by an LLM with a meticulously designed prompt framework. A user interacts with Sunnie through a series of interfaces, including selecting and typing their feelings with buttons and text input, communicating with Sunnie in multi-turn conversation, receiving personalized activity recommendations, and deciding whether to take the activity.\nperspective of CAs, which is pivotal when humans rely on CAs' for decision-making [10,24,114]. Additionally, many aspects of human-to-human relationships are transferable to the relationship between humans and CAs, such as establishing parasocial relationships where only one party extends emotional energy, interest, and time. Still, the other side is completely unaware of the other's effort [85,113,114]. DP1: Anthropomorphic designs: no more, no less. Building on these insights, recent research has highlighted the importance of anthropomorphic design in conversational agents (CAs), taking into account the uncanny valley effect [35,87,106,131], which suggests that overly human-like agents can elicit discomfort. A balanced approach to anthropomorphic design is recommended, considering human identity (such as human-like representation, gender, or age), non-verbal features (such as hand gestures, facial expressions, or emojis), and verbal characteristics (such as word choice and sentence structure) [106,114]. Studies have shown that incorporating human-like visual representations, verbal cues like self-references or emotional expressions, and non-verbal behavior like emoticons or turn-taking can enhance the perception of human-likeness in CAs [72,106]. For example, enabling agents to use social dialogue, express emotions, and refer to themselves as \"I\" can make them appear more human-like. Non-verbal cues, such as blinking dots to communicate thinking gestures or emoticons to convey emotional expressions, also significantly create a human-like impression [72,106]. Another common practice with the goal of imbuing human-like traits in CAs is to create personas for the agent.\nA persona could be a fictional character with a name, age, or even a defined backstory and personality [99]. Some research argues that having a distinct persona or personality could contribute to a cohesive and consistent presence of the conversational agent for users and increase trust and the intention to use the technology [41,45]. However, careful designs of personas are needed [99]. It is important to avoid reinforcing stereotypes or biases, ensuring that the personas are diverse and inclusive [99,114].\nStudies indicate that a \"more is more\" approach is not advisable, as it can negatively affect perceived anthropomorphism. For example, a regression analysis [106] revealed two significant interactions: one between non-verbal and verbal cues and another between non-verbal and human identity cues. These findings suggest that the combination of these design dimensions provides a consistent representation of human-likeness, but including all three dimensions do not necessarily increase users' perceptions of anthropomorphism [106].\nDP2: Grounding conversation in science but with layman's languages. In recent years, the study of happiness and well-being has witnessed significant growth from cognitive and psychological perspectives. This body of literature demonstrates that individuals can intentionally cultivate well-being through specific practices [50,121,123]. However, the vast wealth of knowledge emerging from this line of research is not easily accessible to the general public, presenting a notable barrier to its application in everyday life. We envision an immense potential in leveraging LLMs to enhance the accessibility of scientific insights through LLM's recommendation and conversation capacities, making the psychological insights from positive psychology and behavioral science accessible and actionable to a broader audience.\nAdditionally, the burgeoning field of research in CAs has underscored the importance of crafting dialogues based on mutual understanding and empirical evidence [92,114]. Using familiar language and clear, simple expressions can enhance comprehension and engagement, as suggested by previous literature [36,59]. The concept of mental health literacy further emphasizes the importance of using language that aids in the recognition and management of mental health issues [46]. These considerations underscore the vital relationship between language, understanding, and action in well-being support.\nBuilding upon this foundation, conversational agents that support evidence-based communication become essential.\nEnsuring that the information provided is relevant, practical, and scientifically accurate is critical for enhancing the credibility of the conversational agent. Grounding conversations in science and using familiar language aligns with the principles of evidence-based practice, which advocate for integrating research evidence into decision-making processes. This design consideration could enhance the user experience and ensure that users receive validated and reliable information, thereby promoting well-being effectively.\nDP3: Considering positive design principles that align with system goals. To align with our objectives of enhancing well-being, we integrate positive design principles [133]. These principles are predicated on the notion that each design aspect should be oriented toward enriching the user experience. We aim to bolster well-being and happiness, ensuring the design harmonizes with our system's overarching goals. We follow various strategies encompassed in the aforementioned design principles, such as Design for Pleasure, Design for Personal Significance, and Design for Virtue.\nWe chose these design principles to ensure that our system design meets functional requirements and contributes positively to users' psychological state, fostering better well-being.", "publication_ref": ["b88", "b89", "b88", "b11", "b98", "b101", "b114", "b29", "b9", "b23", "b114", "b9", "b23", "b114", "b85", "b113", "b114", "b34", "b87", "b131", "b114", "b72", "b72", "b99", "b40", "b44", "b99", "b99", "b114", "b49", "b121", "b123", "b92", "b114", "b35", "b58", "b45", "b133"], "figure_ref": [], "table_ref": []}, {"heading": "Key Features", "text": "In this section, we delve into the key features and anthropomorphic designs of Sunnie as shown in Figure . 1, drawing on a comprehensive review of existing literature and foundational design principles. Fig. 3. The anthropomorphic design of Sunnie in the conversation interface is highlighted with red circles. These designs include the title of \"Chat with Sunnie,\" the anthropomorphic appearance of Sunnie as a conversational agent, and the design of a \"Sunnie is typing... \" animation while waiting for the generated response from GPT-4.\nThe key features include 1) anthropomorphic designs of Sunnie, 2) an LLM-based conversational agent for well-being coaching, and 3) LLM-driven, personalized well-being activities recommendation.\nIn accordance with DP1, Sunnie's anthropomorphic designs are crafted to endow the system with human-like characteristics without crossing into the uncanny valley. These design elements aim to make interactions more natural and engaging by providing a sense of familiarity and empathy. Features such as natural language use, expressive emojis, and emotional responsiveness are carefully integrated to achieve this effect while maintaining a comfortable human likeness.\nConsistent with DP2, Sunnie employs an LLM-based conversational agent for well-being coaching. This agent is designed to provide interactive and tailored coaching sessions, assisting users in acquiring new knowledge or skills related to well-being. The conversational agent's capability to comprehend and respond to user queries in a human-like manner is crucial for effective coaching. Also, Sunnie includes an LLM-driven recommendation module for well-being activities. This module is designed to offer personalized activities that cater to the user's specific needs and preferences to enhance their overall well-being.\nThe recommendations are generated based on user inputs and interactions with the conversational agent, ensuring their relevance and utility. Fig. 4. The user interaction flow with Sunnie includes six stages: 1) user selects the emoji that best captures how they are currently feeling, 2) user selects one or more keyword(s) to describe their feelings, 3) user describes the perceived source of their feelings and optionally uploads an image, 4) Sunnie initiates a brief multi-turn conversation for personalized well-being coaching, 5) Sunnie provides personalized activity recommendation, and 6) user determines whether to engage in the activity. The Appearance of Sunnie: Previous literature pointed out that one concern of anthropomorphic designs regarding the appearance of the agents is the uncanny valley effect (UVE), which suggests that overly human-like agents can evoke feelings of eeriness or discomfort. Once the users perceive the visual and behavioral imperfection of realism, they may form negative impressions through which they might subsequently reject the adoption of the technology.\nTo avoid UVE, Sunnie is represented by a sun rather than a human character. The sun symbolizes warmth, light, and life-giving energy, therefore conveying the belief in people's inherent potential for flourishing. Sunnie aims to brighten users' days, sharing warmth and light as a happiness coach and companion.\nPersona of Sunnie: Based on DP1 and DP3, the persona of Sunnie is crafted to resonate with its goals of promoting well-being activities. Sunnie's personality is friendly, compassionate, supportive, and insightful. Its persona is grounded in positive psychology and includes the following traits:\n\u2022 Action Taker: reflects the notion that active engagement in well-being activities and skill-building exercises could enhance happiness and life satisfaction [80] Table 1. A list of well-being activities recommended by Sunnie in the current study based on research in positive psychology and social psychology.", "publication_ref": ["b80"], "figure_ref": [], "table_ref": []}, {"heading": "Activity Category Type Instruction", "text": "Three Good Things [37,107] Savoring Writing Write down three things-big or small-that you appreciate about today. Beautiful Moment [47] Savoring Writing While going about your day today, look for a beautiful moment, however small.\nLetter from the Future Self [17,60] Aspiring Writing Time travel to the future and write a letter back to yourself today. Discover all the wisdom and strength that is already within you! Nature Walk [38] Savoring Action When in need of a break, go on a simple stroll and discover 3 new S's: a new Sight, a new Sound, and a new Smell.\nA walk in nature can help us feel more grounded, less stressed, and more connected to the world around us. Gratitude Note [61] Connecting Interaction Send a short note to someone and tell them how they have meaningfully touched your life.\nMeaningful Conversation [49] Connecting Interaction Today, let's intentionally dive into a meaningful conversation! Meaningful conversations are surprisingly fun. They can strengthen social bonds, inspire new perspectives, and leave us feeling happier and more connected afterwards.\nGifting a Compliment [137] Connecting Interaction Write someone a compliment today.\nOftentimes, we grow so used to the wonderful people in our lives that we forget to tell them how amazing they are! Blast from the Past [34,135] Savoring Interaction Rediscover a photo of an \"ordinary moment\" from the past, and share it with someone who might enjoy rediscovering it, too!\n\u2022 Positivity Practitioner: underscores the significance of positive emotions and optimism in coping with life's challenges, fostering a positive mindset [33] \u2022 Mindfulness Mentor: incorporates the concept of mindfulness, which has been shown to improve emotional regulation and reduce stress, encouraging users to adopt mindfulness practices [48] \u2022 Lover of Life: embodies the growth mindset which is associated with greater well-being and life satisfaction, suggesting a willingness to learn and embrace challenges and a continuous quest for knowledge and selfimprovement [26,33] Considering the potential risks associated with anthropomorphism, such as UVE and the reinforcement of stereotypes and biases, Sunnie is carefully designed to avoid using a human appearance or assigning a specific gender or career.\nSunnie's names and personalities align with the aforementioned design principles (DP3), focusing on promoting well-being.\nVerbal and Non-Verbal Cues: In terms of verbal and non-verbal cues, Sunnie communicates in a friendly and compassionate manner, consistent with its persona. Sunnie also leverages the communicative power of visual symbols, such as emojis, to convey emotions and add expressiveness to conversations. This approach enhances the user experience by making interactions more relatable and engaging [106].", "publication_ref": ["b36", "b107", "b46", "b16", "b59", "b37", "b60", "b48", "b137", "b33", "b135", "b32", "b47", "b25", "b32"], "figure_ref": [], "table_ref": []}, {"heading": "User Interaction Flow.", "text": "The user interaction workflow with Sunnie is a structured process designed to support well-being through a series of steps, as shown in Figure . 4 with the snippets of the key interactions for each step. The dedicated user interface for each step being visualized in a mobile application is shown in Figure . 1.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Mood-Logging Activities:", "text": "Users begin each session by logging their mood, a practice supported by cognitive behavioral therapy (CBT) principles, effective in long-term mental health support [14]. Users are asked to rate their mood on a five-point Likert scale and select one or more words to describe their feelings from a list of positive and negative words, such as overwhelmed, grateful, bored, curious, and sad. They are also asked to write down what made them feel that way. Prior research on expressive writing [94] has demonstrated significant psychological benefits, including improved mood, reduced stress, and enhanced overall well-being, and provided structured framework to articulate and understand their emotional experiences. Such framework can lower the activation energy required for self-disclosure and emotion regulation, thereby increasing user engagement and adherence.\nConversation for Personalized Well-Being Coaching: Based on the information collected in mood-logging activities, Sunnie leverages its LLM-based conversational agent capabilities to engage in a multi-turn dialogue with the user. This conversation aims to delve deeper into the user's emotional state, fostering a continuous and natural backand-forth interaction. By aligning with DP2, the system ensures that the conversation is grounded in scientific principles and uses familiar language, enhancing the user's understanding and engagement. The system offers suggestions to savor positive emotions or improve negative moods, drawing on scientific knowledge. For example, if a user feels grateful due to a friend's support, Sunnie might inquire about the specifics of the support, affirm the user, and explain the importance of social support to well-being.\nWell-Being Activity Recommendations: Based on the information gathered from mood-logging activities and personalized conversations, Sunnie provides personalized well-being activity recommendations. These suggestions are tailored to the user's current mood, emotions, and needs to enhance their overall well-being. Users can decide whether to engage in the recommended well-being activity. Sunnie provides instructions for completing the activity, supporting users in practicing the suggested well-being activity.\nBy incorporating these functionalities, Sunnie, as a well-being coach and companion, aims to provide users with a supportive and interactive environment for promoting well-being activities.", "publication_ref": ["b13", "b94"], "figure_ref": [], "table_ref": []}, {"heading": "Well-Being Activity Recommendation.", "text": "Given the diverse range of life circumstances users may experience, it is important to include a wide range of actionable strategies in the activity recommendation system to enhance happiness and well-being in alignment with DP2. Reviewing the extant literature revealed at least three broad categories of activities:\nConnecting Activities: Engaging in actions that foster meaningful connections with others is foundational to well-being. Activities such as giving compliments [122], sending gratitude notes [122], or having deep, meaningful conversations have been shown to strengthen social bonds and emotional support, which are a vital component of well-being [5]. These interactions underscore the importance of social connections in increasing positive affect and life satisfaction. However, mounting evidence shows that people frequently under-utilize these practices and are more \"undersocial\" than they should be for the well-being of themselves and others [27,122,137,138], which presents an opportunity for recommending more of these actions for daily well-being practices.\nSavoring Activities: Practices that encourage mindfulness and appreciation of the present moment significantly contribute to an individual's happiness. For instance, research shows that identifying and writing down three good things daily or immersing oneself in nature can enhance mood and overall life appreciation [122]. These activities highlight the benefits of mindfulness and savoring life's positive experiences for emotional well-being.\nAspiring Activities: Actions that inspire a sense of meaning and purpose are crucial for a fulfilled life. Activities such as writing a letter from the perspective of a future self or to a future self [122], imagining one's best possible self [122], and affirming core values have all been shown to provide direction and motivation, promoting a sense of achievement and satisfaction. These practices emphasize the role of personal aspirations and values in driving happiness and well-being.\nThese strategies represent just a fraction of the research-backed methods for improving happiness and well-being.\nThe challenge is to effectively disseminate this knowledge, ensuring that these insights are accessible and actionable for the wider public. For the sake of this study, we selected eight activities from the above three categories that have clear benefits to the general population as shown in Table . 1. Note that the above categories are not mutually exclusive and are only intended to provide a broad overview of a wide range of well-being activities. For instance, preparing a compliment or a gratitude note can also improve savoring, and sharing a blast from the past with a friend can also improve a sense of connection. ", "publication_ref": ["b122", "b122", "b4", "b26", "b122", "b137", "b138", "b122", "b122", "b122"], "figure_ref": [], "table_ref": []}, {"heading": "Implementation of Sunnie", "text": "This section discusses the technical details regarding the implementation of Sunnie. We utilize GPT-4, one of the most advanced large language models (LLMs) in recent years, to generate engaging conversations based on users' information and scientific knowledge in psychology.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Prompt Design.", "text": "In this section, we introduce the prompting framework for Sunnie, which consists of four modules: Sunnie's persona, conversation protocol, system setting, and response optimization, designed to guide users through a personalized and engaging interaction.\nAfter users complete mood-logging activities, the system proceeds to the conversation module, which generates personalized feedback and questions to engage users in a guided conversation, aiming to understand the reasons behind their feelings and recommend well-being activities. To achieve this goal, we leveraged GPT-4-turbo-preview to develop Sunnie. Based on Sunnie's persona and aforementioned design principles, the system integrates a set of modules as a complete prompt.\nSunnie's Persona: Aligning with the anthropomorphic design regarding verbal cues, non-verbal cues, and persona, Sunnie is crafted as a compassionate, supportive, and insightful buddy, echoing our anthropomorphic design in Section. 3.2.1 and design principles (DP2, DP3). This persona is specifically chosen to align with the user on a personal level, offering scientific insights and practical advice for well-being in a relatable manner. The persona reflects a Fig. 6. The 3-day participatory study design overview. We had 38 participants in total (20 in one group and 18 in the other). Each group 1) completed a pre-study survey, 2) interacted with both the Baseline and the Sunnie system in alternating order, and 3) completed a post-study survey. On the third day, four participants volunteered for a semi-structured post-study interview.\ncommitment to support users through personalized and empathetic interactions, which are central to fostering user engagement.\nConversational Protocol: The conversations between the users and Sunnie are similar to a feedback-question loop.\nThe conversation protocol with Sunnie is structured to start with an expression of understanding and compassion, reflecting the system's supportive persona. By beginning the interaction in this way, Sunnie sets a tone of empathy and care, which is crucial for users to feel comfortable sharing their feelings. The protocol ensures that conversations are not only structured but also adaptable, with Sunnie able to lead the conversation to a more in-depth exploration of the user's emotional state if needed.\nSystem Setting: Sunnie is prompted to make psychological knowledge accessible and actionable, as aligned with DP2 and DP3. Sunnie's ability to convert scientific understanding into everyday language comes into play, and the goal is to support well-being by ensuring users can apply this knowledge to their daily lives.\nResponse Optimization: This section of prompts is crucial for maintaining the relevance and safety of interactions. For example, if users express dangerous thoughts, Sunnie is designed to redirect them to appropriate emergency resources promptly. This reflects an ethical and responsible design of Sunnie.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "System", "text": "Architecture. Sunnie's architecture is shown in Figure . 2, which integrates a user-friendly interface with the advanced capabilities of LLMs.\nThe interactive front-end interface is developed as a web application using the React framework. The back end has the GPT-4-powered conversational agent integrated via OpenAI's Assistant API for real-time dialogue generation.\nPracticing the recommended activities is facilitated through Typeform. User data, including interaction and conversation logs, is stored securely in MongoDB, with encryption measures to protect user privacy. The entire system, encompassing the front-end, back-end, LLM integration, and database, is hosted on the Heroku platform.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "USER STUDY", "text": "We conducted a three-day within-subject user evaluation to examine how anthropomorphic designs influence users' interactions with and perceptions of LLM-based well-being activity recommendation systems. The study design is shown in Figure 6. Participants were randomly assigned to either start with the non-anthropomorphic Baseline system followed by the anthropomorphic system (Sunnie), or vice versa. We recruited 40 participants via Prolific, but due to two participants from the Baseline-first group dropping out, our final sample size was 38 participants. Each participant completed a pre-study survey on the first day, interacted with both systems over two days in alternating order, and filled out post-study surveys after each interaction. On the third day, we conducted semi-structured interviews with four volunteers for qualitative feedback. Results are reported in Section 5 and discussed in Section 6.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Study Setup", "text": "The study consists of three parts: On the first day, participants completed a pre-study survey assessing their expectations of general AI technologies for well-being support, interacted with the system that they were assigned to, and completed a post-study survey evaluating their experience with the system. This section took approximately 20 minutes to complete.\nOn the second day, participants interacted with the other system (either Baseline or Sunnie) and completed another post-study survey. This section also took approximately 20 minutes to complete.\nAfter finishing the two-day study, participants were asked if they would like to volunteer to participate in a 15-minute, semi-structured interview to reflect upon their previous engagements.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Participants", "text": "We recruited 40 participants through Prolific. Participants were required to be at least 18 years old, have a basic understanding of English, and currently be enrolled as college students. Two participants dropped out, resulting in a final sample size of 38 participants with a mean age of 26.08 years (SD = 7.40) and an approximately equal gender distribution (47.4% female, 52.6% male). In terms of ethnicity, 18 participants (47.4%) identified as White, 10 (26.3%) as Asian, 7 (18.4%) as Black, 2 (5.3%) as Mixed, and 1 (2.6%) as Other. All participants were residing in the United States at the time of the study and were of U.S. nationality. Participants did not differ significantly on any demographic variables across the two conditions (all \ud835\udc5d \u2265 .187). After the two-day user study, a total of four participants volunteered to participate in the follow-up interview. The demographics of interview participants are shown in Table . 3.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Sunnie Condition", "text": "Participants in the Sunnie condition used our Sunnie prototype, where the user interfaces are shown in Figure . 1 and the user interaction workflow is shown in Figure . 4. Specifically, the participants will first answer related questions in mood-logging activities, including selecting the most appropriate words for their feelings, providing textual descriptions of their feelings, and then be directed to the conversation interface for a multi-turn conversation with Sunnie. Sunnie will ask follow-up questions to better understand the users' feelings. Based on the user's inputs, Sunnie will recommend one activity from our eight pre-defined well-being activities, as described in Section 3.2.3. The participants could decide whether to practice the recommended activity with Sunnie or not.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Factor 1: Relational Warmth", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Expectations", "text": "Perceptions (Baseline and Sunnie)\nIn general, I think AI technologies (e.g., chatbots) for mental well-being support care about me.\nHow much do you think the AI-powered mental wellbeing support system cares about you?\nIn general, I trust AI technologies (e.g., chatbots) for mental well-being support.\nHow much do you trust the AI-powered mental wellbeing support system?\nIn general, I think my interaction with AI technologies (e.g., chatbots) for mental well-being support would be natural.\nHow natural do you think was your interaction with the AI-powered mental well-being support system?\nFactor 2: Perceived Utility Expectations Evaluations (Baseline and Sunnie)\nIn general, I think AI technologies (e.g., chatbots) for mental well-being support is helpful.\nHow helpful do you think the AI-powered system is in supporting your mental well-being?\nIn general, I think AI technologies (e.g., chatbots) for mental well-being support is personalized.\nHow personalized do you think the AI-powered system is in supporting your mental well-being?\nIn general, I think I can express myself to AI technologies (e.g., chatbots) for mental well-being support.\nHow much do you think you could express yourself to the AI-powered mental well-being support system?\nIn general, I like AI technologies (e.g., chatbots) for mental well-being support.\nHow much do you like the AI-powered mental wellbeing support system?\nTable 2. Survey items used to measure the factors of Relational Warmth and Perceived Utility. The left column shows the items measuring general expectations of AI technologies for mental well-being support, while the right column shows the items used to evaluate the specific AI systems (Baseline and Sunnie).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "RESULTS", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Quantitative Analysis", "text": "In this section, we present the quantitative results, starting with users' expectations versus evaluations of Sunnie and the Baseline system, focusing on two key factors: relational warmth and perceived utility. This is followed by a comparison of behavioral engagement across the two systems (Sunnie and Baseline), as measured by activity completion rates.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Relational", "text": "Warmth. A 3 (Condition: Expectations, Sunnie, Baseline) \u00d7 2 (System Exposure Order: Sunnie First, Baseline First) repeated measures ANOVA was conducted to compare participants' expectations of AI systems' relational warmth with their actual perceptions of relational warmth after using the non-anthropomorphic baseline agent, and after using Sunnie, the anthropomorphic agent. Condition was a within-subjects factor, while System Exposure Order was a between-subjects factor.\nThere was a main effect of Condition, F(2,72) = 23.86, p < .001, \ud835\udf02 2 \ud835\udc5d = 0.28, suggesting that perceptions of relational warmth differed across the three conditions. Post-hoc pairwise comparisons with Tukey adjustment indicated that the Baseline model did not significantly differ in warmth compared to Expectations (Baseline: M = 3.74, SD = 1.35; Expectations: M = 3.32, SD = 1.23; Baseline vs. Expectations: p = .140). In contrast, Sunnie was rated as warmer than Importantly, there was no main effect of System Exposure Order, F(1,36) = 2.49, p = .123, nor did System Exposure Order moderate the effect of Condition, F(2,72) = 1.20, p = .308. This suggests that the order in which participants experienced Sunnie or the Baseline did not significantly influence their perceptions of relational warmth.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Perceived", "text": "Utility. A 3 (Condition: Expectations, Sunnie, Baseline) \u00d7 2 (System Exposure Order: Sunnie First, Baseline First) repeated measures ANOVA was conducted to compare participants' expected utility of AI systems with their actual perceptions of utility after using the non-anthropomorphic baseline agent, and after using Sunnie, the anthropomorphic agent. Condition was a within-subjects factor, while System Exposure Order was a between-subjects factor.\nThe analysis revealed a significant main effect of Condition, F(2,72) = 14.60, p < .001, \ud835\udf02 2 \ud835\udc5d = 0.29, suggesting that perceptions of perceived utility differed across the three conditions. Post-hoc pairwise comparisons with Tukey adjustment showed that this time, both Sunnie and Baseline were rated higher on utility than Expectations (Sunnie: M = 4.89, SD = 1.32; Baseline: M = 4.49, SD = 1.24; Expectations: M = 3.71, SD = 1.17; Sunnie vs. Expectations: p < .001, 95% CI [-1.71, -0.65], d = 1.22; Baseline vs. Expectations: p = .003, 95% CI [-1.30, -0.24], d = 0.80), and Sunnie and Baseline did not significantly differ from each other (Sunnie vs. Baseline: p = .167), suggesting that both Sunnie and Baseline were higher than expectations, and they did not significantly differ from each other.\nThere was no significant main effect of System Exposure Order, F(1,36) = 0.18, p = .673, nor did System Exposure Order moderate the effect of Condition, F(2,72) = 0.85, p = .433. This suggests that the order in which participants experienced Sunnie or the Baseline did not significantly influence their perceptions of perceived utility. , and the completion rates did not significantly differ between the two conditions, \ud835\udf12 2 (1, N = 80) = 0.24, p = 0.621. These findings suggest that the type of system-whether anthropomorphic or non-anthropomorphic-had no significant impact on participants' likelihood to engage with the recommended activities.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Qualitative Analysis", "text": "In this section, we present the qualitative findings from the semi-structured interviews.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Unexpectedly Positive", "text": "Experience. Many participants (P1, P3, P4) reported a surprisingly positive experience with the system, which was consistent with our quantitative findings showing that participants initially underestimated the system's capabilities. For example, P1 stated:\n\"I went in not expecting to like it as much as I did, so I think my overall impression was a lot more positive. . . . And yeah, I feel like I left feeling more positive than when I started it. \" (P1)\nSimilarly, P4 stated:\n\"Honestly, I liked it more than I expected, especially after like seeing the first one, and already kind of having an understanding of like the premise of like, okay, I'm like assessing how I am at that moment, and then deciding whether or not to do the activity. I was really surprised that I liked it, even though I basically kinda knew it was gonna happen. \" (P4)\nP4 also elaborated on the sources of their initial low expectations, attributing it to common preconceptions about AI, such as its tendency to be inaccurate or inappropriate: \"I would say it was better than I expected, because I think I do have a preconception of AI like being very inaccurate, or like very inappropriate, I guess, or sometimes like totally missing the mark on something. \" (P4)\nThese responses both align with and add depth to our quantitative findings, illustrating that initial skepticism and low expectations towards the system were often replaced by unexpectedly positive experiences after actual use.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Perceptions of Utility.", "text": "Participants generally found the system to be high in utility, noting its ease of navigation and personalization. For example, P1 stated, \"It was very easy to use, super easy to navigate. \" (P1). Similarly, P4 expressed surprise at how effortless the system was to engage with, stating, \"I honestly was really surprised. I ended up feeling like, you know, what like, this is something easy. I can do that doesn't take a lot of time that if I just had really quickly.\" (P4) P4's reaction aligns with our quantitative findings, showing that the system's utility exceeded initial expectations.\nIn addition to ease of use, participants valued the system's capacity for personalization. They appreciated that the activities recommended by Sunnie were relevant and tailored to their specific needs and contexts. This personalization contributed significantly to their sense of engagement with the system. For instance, P2 commented, \"Activity was much more relevant as in like it kind of grounds you and makes you like think about like the reality you're in.\" (P2) P1\nsimilarly felt that the system's ability to understand their context made the suggestions feel more relevant: \"I felt like the suggestion it gave me after was a little bit more personal because it was like listening or understanding me in a way that I couldn't normally. \" (P1)\nThese responses reveal that the combination of ease of use and personalized recommendations significantly enhanced participants' perceptions of the system's utility.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Perceptions of Relational", "text": "Warmth. Participants reflected positively on the anthropomorphic design of Sunnie, mainly around its visual and verbal characteristics. They highlighted how the system's aesthetically pleasing and emotionally comforting design elements enhanced their overall experience. Many found the lighthearted and visually engaging design particularly effective in creating a welcoming atmosphere. For example, P3 stated:\n\" It was simply an adorable visual of something that is meant to present itself as cute, cuddly innocent, endearing, something that you could look upon with good energy, positive vibrations, something that would immediately make you feel more at ease, more calm, more at home, because it's adorable. \" (P3)\nParticipants also valued the system's language style, which contributed to a friendly and approachable persona. P1 observed, \"In the terms like in the way that it's spoken, and also kind of like the punctuation and stuff it helped it seem like a little bit more enthusiastic and friendly. \" (P1)\nAnd once again, aligning with quantitative findings, P3 expressed pleasant surprise by Sunnie 's warmth: \"I can truthfully tell you that it was quite a pleasant experience because the algorithm that was being utilized really lent itself to empathy. ... I would feel incredibly willing and able to utilize this for longer stretches of time because the cordial and empathetic nature of [Sunnie ]. \" (P3)\nFinally, participants appreciated the realistic nature of the interactions with the system, noting that the conversations felt natural. They valued the system's ability to engage in a back-and-forth dialogue that resembled genuine human conversation and its adaptability to the flow of discussion. As P3 shared, \"It didn't feel as if I was simply connecting the dots on behalf of an already pre-programmed algorithm or frameworks of conversational prompts. This one felt much more naturalistic, and as a result, if I had more to say or less to say, the AI would follow as naturally as I could, and I thought that was quite impressive. \" (P3)\nThese aspects of the system's design were seen as key factors in its credibility and innovation, contributing positively to participants' experiences.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "DISCUSSION", "text": "In this study, we examined people's general expectations of AI systems and compared how these expectations align with their evaluations of anthropomorphic versus non-anthropomorphic AI systems, using a repeated-measures design, incorporated both quantitative and qualitative methods.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Interpretation of Findings", "text": "Our findings reveal differences in participants' expectations of AI systems compared to their actual evaluations of these systems, with slightly different patterns across the dimensions of relational warmth and perceived utility.\nStarting with relational warmth, the anthropomorphic AI system was rated as warmer than expected, whereas the non-anthropomorphic AI system did not differ in warmth from expectations. This suggests that anthropomorphic designs are particularly effective in conveying relational warmth. This finding is consistent with the qualitative feedback, where participants noted that the anthropomorphic system felt engaging and personable.\nOn the other hand, when it came to perceived utility, both the anthropomorphic and non-anthropomorphic systems were rated as significantly more useful than participants expected, with no significant difference between the two.\nThis suggests that anthropomorphic designs do not confer an additional boost to systems' perceived utility. Qualitative interviews supported these quantitative findings, with participants expressing pleasant surprise at the systems' capabilities.\nWhile the anthropomorphic system was better at conveying warmth during interactions, both anthropomorphic and non-anthropomorphic systems were rated as more useful than participants initially expected. This suggests that the advantage of anthropomorphic design lies in enhancing relational warmth, but it does not necessarily provide additional benefits in terms of perceived utility.\nInterestingly, when we examined behavioral engagement, no significant differences emerged between the anthropomorphic and non-anthropomorphic systems. Across both conditions, the majority of participants engaged with the recommended activities, pointing to the effectiveness of both systems in encouraging user engagement. However, this measure reflects engagement immediately after participants were first introduced to each system. Given that the anthropomorphic system was evaluated as being warmer than the non-anthropomorphic one, it remains possible that, over a longer period of use, the enhanced warmth of the anthropomorphic system could lead to higher rates of sustained engagement. This is an open question for future research.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Implications", "text": "The unique advantage of anthropomorphic designs in conveying relational warmth (though not necessarily utility) suggests ways in which AI systems can be tailored to the context in which they are used. For example, in applications where building trust, empathy, or a sense of companionship is critical-such as mental health support-incorporating anthropomorphic elements could significantly enhance the user experience. In contrast, in contexts where utility and efficiency are the primary concerns, a more functional design may be sufficient, without the anthropomorphic component.\nOur findings further suggest that people's judgments of AI systems tend to revolve around two primary dimensions: relational warmth and perceived utility. This is consistent with seminal findings in social psychology that identify warmth and competence as fundamental dimensions of social perception [31]. Recent studies have shown that these dimensions also apply to how people perceive AI [84]. Although we refer to the factor in our study as \"perceived utility, \" it aligns with the competence dimension observed in human judgments and reinforces the idea that the fundamental ways in which people evaluate other humans also extend to their perceptions of machines.\nIn addition, our findings contribute to the growing body of evidence suggesting a shift in how people perceive AI systems, particularly with the development of large language models and the increasing use of anthropomorphic designs. In earlier research, machines have been seen as low in \"experience, \" meaning they were perceived as incapable of emotions or forming emotional connections [39]. However, as LLMs improve and become more anthropomorphized, they increasingly facilitate interactions that convey more relational warmth. This aligns with prior research showing that anthropomorphizing AI systems can lead to higher perceptions of warmth [53]. Our findings further suggest that anthropomorphic designs may not only meet, but exceed, users' expectations of warmth from AI systems.\nFinally, another important implication of our findings is the gap between people's general expectations of AI systems and their actual experiences. On one hand, low expectations may discourage initial adoption, particularly in the context of well-being support. Yet, once users interact with these systems, positive evaluations show that firsthand experience can bridge this gap. On the other hand, research on expectation disconfirmation suggests that low expectations can lead to greater satisfaction when the system exceeds those initial assumptions [86]. Similarly, studies on AI metaphors show that projecting lower competence can result in more favorable evaluations when the AI outperforms expectations [51].\nThus, while managing expectations is important, there may also be value in designing AI systems to pleasantly exceed user assumptions, turning underestimation into a tool for enhancing satisfaction.", "publication_ref": ["b30", "b84", "b38", "b52", "b86", "b50"], "figure_ref": [], "table_ref": []}, {"heading": "Limitations and Future Directions", "text": "This study has several limitations that warrant further investigation. First, the study was conducted over a relatively short period, spanning only a few days. Longer longitudinal studies are needed to assess whether differences in perceptions of AI systems ultimately lead to differences in continued engagement over time.\nAdditionally, we only tested one type of anthropomorphic design, specifically a sun character, rather than a human- Additionally, the version of the AI system we tested was relatively limited in its level of personalization, since it recommended activities based on users' current mood. Expanding personalization to incorporate additional factors such as context (e.g., time, location), individual preferences (e.g., cognitive vs. physical activities), and ethical considerations (e.g., accommodations for disabilities) could further enhance its utility. For instance, it might not be appropriate to recommend a walk at midnight or to users with disabilities. Future research should explore how AI systems that account for these factors shape user perceptions.\nAnother limitation is that the sample size was relatively small and drawn from a Prolific sample based in the U.S., which limits the cultural generalizability of our findings. For instance, research in cultural psychology has found that values regarding social support and emotions differ across cultures, and these differences may moderate our findings.\nSpecifically, while those in Western cultures tend to prefer explicit forms of support, those in East Asian cultures tend to prefer more implicit forms of support [52]. Similarly, in terms of the emotions people value, or ideal affect, European Americans tend to value high-arousal positive states (e.g., excitement) more than East Asians [117]. These cultural differences suggest that, all else being equal, perceptions of AI systems may vary across cultures, particularly if they are designed with Western values in mind.\nRelatedly, our sample consisted of relatively healthy individuals, which may limit the applicability of our findings to other populations. It remains unclear how AI systems like the one we tested would be perceived by individuals with clinical conditions who may seek to use such systems as a complement to their weekly therapy sessions. Additionally, those with subclinical conditions might use the system proactively as a prevention tool. Future research should consider testing the system with more specific populations and psychological traits to better understand its effectiveness across different user groups.\nFinally, an important area for future research is understanding how perceiving AI systems as warm might foster unintended emotional attachment. While anthropomorphizing technology can help simplify complex interactions and make AI more relatable, it may also lead users to form emotional dependencies or over-rely on the system [22]. Future studies should focus on balancing these pros and cons with the users' best interests in mind, ensuring that warmth enhances user interaction without leading to unintended emotional consequences or manipulation.", "publication_ref": ["b51", "b117", "b21"], "figure_ref": [], "table_ref": []}, {"heading": "CONCLUSION", "text": "In this paper, we examined the role of anthropomorphic and non-anthropomorphic AI systems in supporting users' well-being by offering personalized, science-based activity recommendations. Our findings suggest that these AI systems can be surprisingly useful to users, and that anthropomorphic designs can further convey a surprising degree of relational warmth. Although our study focused on healthy populations, these findings raise the possibility that anthropomorphic AI systems could serve as supplementary tools in early-stage well-being support or as a bridge between therapy sessions. For instance, users might benefit from logging daily emotions and activities, offering valuable insights for both personal reflection and potential use by mental health professionals. Future research should explore these applications to better understand their potential role in supporting mental health.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Wu, et al.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Baseline Condition", "text": "Participants assigned to the Baseline condition are asked to interact with a prototype, shown in Figure . 8, which is an LLM-based well-being activity recommendation system with no anthropomorphic and conversational design, compared to Sunnie. The general flow of baseline condition is identical to Sunnie besides not having a conversation functionality and non-anthropomorphic designs.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Measures", "text": "Our aims were to: 1) assess users' initial expectations of AI systems for supporting well-being and compare these expectations with their actual evaluations of systems with and without anthropomorphic features, 2) compare the two types of systems (anthropomorphic vs. non-anthropomorphic) in terms of users' behavioral engagement, and 3) gather in-depth qualitative feedback on the user experience through semi-structured interviews. The following measures were employed to address each of these objectives.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Expectations versus Evaluations of AI Systems.", "text": "Participants' expectations of AI systems were first measured at the beginning of the study using a series of items adapted from the General Agent Rating (GAR) items [10] and additional measures of helpfulness and personalization adapted from Bickmore et al. [6,60].\nAfter this initial measurement, participants were randomly assigned to one of two system exposure order conditions: Sunnie First or Baseline First. Participants in the Sunnie First condition interacted with the anthropomorphic agent Sunnie, evaluated it, and then, on the following day, interacted with and evaluated the non-anthropomorphic Baseline system. Participants in the Baseline First condition did the reverse. The evaluation questions were matched to the expectation questions as closely as possible to ensure consistency in measurement across the different stages.\nTo facilitate interpretation and capture the underlying structure of the data, we conducted a factor analysis on the combined items. The scree plot suggested retaining two factors, and a subsequent factor analysis with varimax rotation revealed the following two factors (retaining items with loadings of 0.40 or higher):\n\u2022 Relational Warmth: This factor included items related to participants' expectations or perceptions of how much AI systems care about them and how much they trust the AI system (Cronbach's alpha: Expectations = .73; Baseline = .85; Sunnie = .85). See Table . 2 for all items.\n\u2022 Perceived Utility: This factor included items related to participants' expectations or perceptions of how helpful and personalized the AI systems are (Cronbach's alpha: Expectations = .83; Baseline = .87; Sunnie = .89). See Table . 2 for all items.     is identical to Sunnie besides not having a conversation functionality and non-anthropomorphic designs. After the users provide text descriptions of their feelings, they will be directed to the Typeform page of the activity recommendations, which is identical to the Sunnie condition.", "publication_ref": ["b9", "b5", "b59"], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Effectiveness and Safety of Using Chatbots to Improve Mental Health: Systematic Review and Meta-Analysis", "journal": "Journal of Medical Internet Research", "year": "2020", "authors": "A A Abd-Alrazaq; A Rababeh; M Alajlani; B M Bewick; M Househ"}, {"ref_id": "b1", "title": "Effectiveness and safety of using chatbots to improve mental health: systematic review and meta-analysis", "journal": "Journal of medical Internet research", "year": "2020", "authors": "Alaa Ali Abd-Alrazaq; Asma Rababeh; Mohannad Alajlani; Bridgette M Bewick; Mowafa Househ"}, {"ref_id": "b2", "title": "", "journal": "", "year": "2023", "authors": "Josh Achiam; Steven Adler; Sandhini Agarwal; Lama Ahmad; Ilge Akkaya; Florencia Leoni Aleman; Diogo Almeida; Janko Altenschmidt; Sam Altman; Shyamal Anadkat"}, {"ref_id": "b3", "title": "Artificial Intelligence-Based Chatbots for Promoting Health Behavioral Changes: Systematic Review", "journal": "Journal of Medical Internet Research", "year": "2023-02", "authors": "Abhishek Aggarwal; Chi Cheuk; Dezhi Tam; Xiaoming Wu; Shan Li;  Qiao"}, {"ref_id": "b4", "title": "The experimental generation of interpersonal closeness: A procedure and some preliminary findings", "journal": "Personality and social psychology bulletin", "year": "1997", "authors": "Arthur Aron; Edward Melinat; Elaine N Aron; Robert ; Darrin Vallone; Renee J Bator"}, {"ref_id": "b5", "title": "Psychologists struggle to meet demand amid mental health crisis: 2022 COVID-19 Practitioner Impact Survey", "journal": "American Psychological Association", "year": "2022", "authors": ""}, {"ref_id": "b6", "title": "Relational agents: a model and implementation of building user trust", "journal": "", "year": "2001", "authors": "Timothy Bickmore; Justine Cassell"}, {"ref_id": "b7", "title": "Making it personal: end-user authoring of health narratives delivered by virtual agents", "journal": "Springer", "year": "2010-09-20", "authors": "Timothy Bickmore; Lazlo Ring"}, {"ref_id": "b8", "title": "It's just like you talk to a friend'relational agents for older adults", "journal": "Interacting with Computers", "year": "2005", "authors": "Timothy W Bickmore; Lisa Caruso; Kerri Clough-Gorr; Tim Heeren"}, {"ref_id": "b9", "title": "Establishing and maintaining long-term human-computer relationships", "journal": "ACM Transactions on Computer-Human Interaction (TOCHI)", "year": "2005", "authors": "Timothy W Bickmore; Rosalind W Picard"}, {"ref_id": "b10", "title": "Measuring engagement with mental health and behavior change interventions: an integrative review of methods and instruments", "journal": "International Journal of Behavioral Medicine", "year": "2023", "authors": "Laura Esther Bijkerk; Anke Oenema; Nicole Geschwind; Mark Spigt"}, {"ref_id": "b11", "title": "Imperfectly Human: The Humanizing Potential of (Corrected) Errors in Text-Based Communication", "journal": "Journal of the Association for Consumer Research", "year": "2024", "authors": "Shirley Bluvstein; Xuan Zhao; Alixandra Barasch; Juliana Schroeder"}, {"ref_id": "b12", "title": "Prosocial video game as an intimate partner violence prevention tool among youth: A randomised controlled trial", "journal": "Computers in Human Behavior", "year": "2019", "authors": "Daniel Boduszek; Agata Debowska; Adele D Jones; Minhua Ma; David Smith; Dominic Willmott; Ena Trotman Jemmott; Hazel Da Breo; Gillian Kirkman"}, {"ref_id": "b13", "title": "Exploring how politeness impacts the user experience of chatbots for mental health support", "journal": "International Journal of Human-Computer Studies", "year": "2024", "authors": "Robert Bowman; Orla Cooney; Joseph W Newbold; Anja Thieme; Leigh Clark; Gavin Doherty; Benjamin Cowan"}, {"ref_id": "b14", "title": "Mango Mango, How to Let The Lettuce Dry Without A Spinner?", "journal": "", "year": "2023", "authors": "Szeyi Chan; Jiachen Li; Bingsheng Yao; Amama Mahmood; Chien-Ming Huang; Holly Jimison; Elizabeth D Mynatt; Dakuo Wang"}, {"ref_id": "b15", "title": "Anthropomorphism of AI based chatbots by users during communication", "journal": "", "year": "2023", "authors": "Avanti Chinmulgund; Ritesh Khatwani; Poornima Tapas; Pritesh Shah; Ravi Sekhar"}, {"ref_id": "b16", "title": "Temporal distancing during the COVID-19 pandemic: Letter writing with future self can mitigate negative affect", "journal": "Applied Psychology: Health and Well-Being", "year": "2021", "authors": "Yuta Chishima; I-Ting Huai-Ching; Anne E Liu;  Wilson"}, {"ref_id": "b17", "title": "Once a kind friend is now a thing: Understanding how conversational agents at home are forgotten", "journal": "", "year": "2019", "authors": "Min ; Kyung Cho; Seung Jun Lee; Kun-Pyo Lee"}, {"ref_id": "b18", "title": "Evaluating the Efficacy of Interactive Language Therapy Based on LLM for High-Functioning Autistic Adolescent Psychological Counseling", "journal": "", "year": "2023", "authors": "Yujin Cho; Mingeon Kim; Seojin Kim; Oyun Kwon; Ryan Donghan Kwon; Yoonha Lee; Dohyun Lim"}, {"ref_id": "b19", "title": "What makes a good conversation? Challenges in designing truly conversational agents", "journal": "", "year": "2019", "authors": "Leigh Clark; Nadia Pantidi; Orla Cooney; Philip Doyle; Diego Garaialde; Justin Edwards; Brendan Spillane; Emer Gilmartin; Christine Murad; Cosmin Munteanu"}, {"ref_id": "b20", "title": "Theory-driven design strategies for technologies that support behavior change in everyday life", "journal": "", "year": "2009", "authors": "Sunny Consolvo; David W Mcdonald; James A Landay"}, {"ref_id": "b21", "title": "Who's Johnny? Anthropomorphic Framing in Human-Robot Interaction, Integration, and Policy", "journal": "", "year": "2012", "authors": "Kate Darling"}, {"ref_id": "b22", "title": "Benefits and harms of large language models in digital mental health", "journal": "", "year": "2023", "authors": "Munmun De Choudhury; Neha Sachin R Pendse;  Kumar"}, {"ref_id": "b23", "title": "Almost human: Anthropomorphism increases trust resilience in cognitive agents", "journal": "Journal of Experimental Psychology: Applied", "year": "2016", "authors": "Ewart J De Visser; Samuel S Monfort; Ryan Mckendrick; Melissa Ab Smith; Patrick E Mcknight; Frank Krueger; Raja Parasuraman"}, {"ref_id": "b24", "title": "A Mental Health Chatbot for Regulating Emotions (SERMO) -Concept and Usability Test", "journal": "IEEE Transactions on Emerging Topics in Computing", "year": "2021", "authors": "Kerstin Denecke; Sayan Vaaheesan; Aaganya Arulnathan"}, {"ref_id": "b25", "title": "Mindset: The new psychology of success", "journal": "Random house", "year": "2006", "authors": "Carol S Dweck"}, {"ref_id": "b26", "title": "Undersociality: Miscalibrated social cognition can inhibit social connection", "journal": "Trends in Cognitive Sciences", "year": "2022", "authors": "Nicholas Epley; Michael Kardas; Xuan Zhao; Stav Atir; Juliana Schroeder"}, {"ref_id": "b27", "title": "Assistive conversational agent for health coaching: a validation study", "journal": "Methods of information in medicine", "year": "2019", "authors": "Ahmed Fadhil; Yunlong Wang; Harald Reiterer"}, {"ref_id": "b28", "title": "Utilization of self-diagnosis health chatbots in real-world settings: case study", "journal": "Journal of medical Internet research", "year": "2021", "authors": "Xiangmin Fan; Daren Chao; Zhan Zhang; Dakuo Wang; Xiaohua Li; Feng Tian"}, {"ref_id": "b29", "title": "A taxonomy of social cues for conversational agents", "journal": "International Journal of Human-Computer Studies", "year": "2019", "authors": "Jasper Feine; Ulrich Gnewuch; Stefan Morana; Alexander Maedche"}, {"ref_id": "b30", "title": "Universal dimensions of social cognition: Warmth and competence", "journal": "Trends in Cognitive Sciences", "year": "2007", "authors": "Amy Jc Susan T Fiske; Peter Cuddy;  Glick"}, {"ref_id": "b31", "title": "Delivering Cognitive Behavior Therapy to Young Adults With Symptoms of Depression and Anxiety Using a Fully Automated Conversational Agent (Woebot): A Randomized Controlled Trial", "journal": "JMIR Mental Health", "year": "2017", "authors": "Kathleen Kara Fitzpatrick; Alison Darcy; Molly Vierhile"}, {"ref_id": "b32", "title": "The role of positive emotions in positive psychology: The broaden-and-build theory of positive emotions", "journal": "American psychologist", "year": "2001", "authors": " Barbara L Fredrickson"}, {"ref_id": "b33", "title": "What do you do when things go right? The intrapersonal and interpersonal benefits of sharing positive events", "journal": "Routledge", "year": "2018", "authors": "Harry T Shelly L Gable; Emily A Reis; Evan R Impett;  Asher"}, {"ref_id": "b34", "title": "Faster is not always better: understanding the effect of dynamic response delays in human-chatbot interaction", "journal": "", "year": "2018", "authors": "Ulrich Gnewuch; Stefan Morana; Marc Adam; Alexander Maedche"}, {"ref_id": "b35", "title": "Towards Designing Cooperative and Social Conversational Agents for Customer Service", "journal": "ICIS", "year": "2017", "authors": "Ulrich Gnewuch; Stefan Morana; Alexander Maedche"}, {"ref_id": "b36", "title": "Three Good Things\" Digital Intervention Among Health Care Workers: A Randomized Controlled Trial", "journal": "The Annals of Family Medicine", "year": "2023", "authors": "Katherine J Gold; Margaret L Dobson; Ananda Sen"}, {"ref_id": "b37", "title": "A systematic review and meta-analysis of nature walk as an intervention for anxiety and depression", "journal": "Journal of clinical medicine", "year": "2022", "authors": "Simone Grassini"}, {"ref_id": "b38", "title": "Dimensions of mind perception", "journal": "Science", "year": "2007", "authors": "Kurt Gray; Heather M Gray; Daniel M Wegner"}, {"ref_id": "b39", "title": "Co-developing a mental health and wellbeing chatbot with and for young people", "journal": "Frontiers in psychiatry", "year": "2021", "authors": "Christine Grov\u00e9"}, {"ref_id": "b40", "title": "Psychological, relational, and emotional effects of self-disclosure after conversations with a chatbot", "journal": "Journal of Communication", "year": "2018", "authors": "Annabell Ho; Jeff Hancock; Adam S Miner"}, {"ref_id": "b41", "title": "Large Language Models in Mental Health Care: a Scoping Review", "journal": "", "year": "2024", "authors": "Yining Hua; Fenglin Liu; Kailai Yang; Zehan Li; Peilin Yi Han Sheu; Lauren V Zhou; Sophia Moran; Andrew Ananiadou;  Beam"}, {"ref_id": "b42", "title": "An Empathy-Driven, Conversational Artificial Intelligence Agent (Wysa) for Digital Mental Well-Being: Real-World Data Evaluation Mixed-Methods Study", "journal": "JMIR mHealth and uHealth", "year": "2018", "authors": "Becky Inkster; Shubhankar Sarda; Vinod Subramanian"}, {"ref_id": "b43", "title": "An empathy-driven, conversational artificial intelligence agent (Wysa) for digital mental well-being: real-world data evaluation mixed-methods study", "journal": "JMIR mHealth and uHealth", "year": "2018", "authors": "Becky Inkster; Shubhankar Sarda; Vinod Subramanian"}, {"ref_id": "b44", "title": "Consistency of personality in interactive characters: verbal cues, non-verbal cues, and user characteristics", "journal": "International journal of human-computer studies", "year": "2000", "authors": "Katherine Isbister; Clifford Nass"}, {"ref_id": "b45", "title": "Mental health literacy\": a survey of the public's ability to recognise mental disorders and their beliefs about the effectiveness of treatment", "journal": "Medical journal of Australia", "year": "1997", "authors": " Anthony F Jorm; Patricia A Ailsa E Korten; Helen Jacomb; Bryan Christensen; Penelope Rodgers;  Pollitt"}, {"ref_id": "b46", "title": "Does savoring increase happiness? A daily diary study", "journal": "The Journal of Positive Psychology", "year": "2012", "authors": "Bee T Paul E Jose; Fred B Lim;  Bryant"}, {"ref_id": "b47", "title": "Mindfulness-based interventions in context: past, present, and future", "journal": "", "year": "2003", "authors": "Jon Kabat-Zinn"}, {"ref_id": "b48", "title": "Overly shallow?: Miscalibrated expectations create a barrier to deeper conversation", "journal": "Journal of Personality and Social Psychology", "year": "2022", "authors": "Michael Kardas; Amit Kumar; Nicholas Epley"}, {"ref_id": "b49", "title": "The mental health continuum: from languishing to flourishing in life", "journal": "Journal of Health and Social Behavior", "year": "2002-06", "authors": "L M Corey;  Keyes"}, {"ref_id": "b50", "title": "Conceptual metaphors impact perceptions of human-ai collaboration", "journal": "", "year": "2020", "authors": "Pranav Khadpe; Ranjay Krishna; Li Fei-Fei; Jeff T Hancock; Michael S Bernstein"}, {"ref_id": "b51", "title": "Culture and social support", "journal": "American Psychologist", "year": "2008", "authors": "S Heejung; David K Kim; Shelley E Sherman;  Taylor"}, {"ref_id": "b52", "title": "What Makes People Feel Empathy for AI Chatbots? Assessing the Role of Competence and Warmth", "journal": "International Journal of Human-Computer Interaction", "year": "2023", "authors": "Bin Woo; Hyun Jung Kim;  Hur"}, {"ref_id": "b53", "title": "How can interventions increase motivation for physical activity? A systematic review and meta-analysis", "journal": "Health psychology review", "year": "2018", "authors": "Johanna Keegan Knittle; Rik Nurmi; Nelli Crutzen; Marguerite Hankonen; Stephan U Beattie;  Dombrowski"}, {"ref_id": "b54", "title": "Reflection companion: a conversational system for engaging users in reflection on physical activity", "journal": "Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies", "year": "2018", "authors": "Rafal Kocielnik; Lillian Xiao; Daniel Avrahami; Gary Hsieh"}, {"ref_id": "b55", "title": "Investigating intervention components and exploring states of receptivity for a smartphone app to promote physical activity: protocol of a microrandomized trial", "journal": "JMIR research protocols", "year": "2019", "authors": "Jan-Niklas Kramer; Florian K\u00fcnzler; Varun Mishra; Bastien Presset; David Kotz; Shawna Smith; Urte Scholz; Tobias Kowatsch"}, {"ref_id": "b56", "title": "Which components of a smartphone walking app help users to reach personalized step goals? Results from an optimization trial", "journal": "Annals of Behavioral Medicine", "year": "2020", "authors": "Jan-Niklas Kramer; Florian K\u00fcnzler; Varun Mishra; Shawna N Smith; David Kotz; Urte Scholz; Elgar Fleisch; Tobias Kowatsch"}, {"ref_id": "b57", "title": "Developing Embodied Conversational Agents for Coaching People in a Healthy Lifestyle: Scoping Review", "journal": "Journal of Medical Internet Research", "year": "2020-02", "authors": "Lean L Kramer; Silke Ter Stal; Bob C Mulder; Emely De Vet; Lex Van Velsen"}, {"ref_id": "b58", "title": "Understanding how people process health information: a comparison of tailored and nontailored weight-loss materials", "journal": "Health Psychology", "year": "1999", "authors": "Fiona C Matthew W Kreuter; Eddie M Bull; Debra L Clark;  Oswald"}, {"ref_id": "b59", "title": "Making meaning out of negative experiences by self-distancing", "journal": "Current directions in psychological science", "year": "2011", "authors": "Ethan Kross; Ozlem Ayduk"}, {"ref_id": "b60", "title": "Undervaluing gratitude: Expressers misunderstand the consequences of showing appreciation", "journal": "Psychological science", "year": "2018", "authors": "Amit Kumar; Nicholas Epley"}, {"ref_id": "b61", "title": "Exploring the state-of-receptivity for mHealth interventions", "journal": "Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies", "year": "2019", "authors": "Florian K\u00fcnzler; Varun Mishra; Jan-Niklas Kramer; David Kotz; Elgar Fleisch; Tobias Kowatsch"}, {"ref_id": "b62", "title": "Investigating the Potential of Group Recommendation Systems As a Medium of Social Interactions: A Case of Spotify Blend Experiences between Two Users", "journal": "", "year": "2024", "authors": "Daehyun Kwak; Soobin Park; Inha Cha; Hankyung Kim; Youn-Kyung Lim"}, {"ref_id": "b63", "title": "Perceptions of anthropomorphism in a chatbot dialogue: the role of animacy and intelligence", "journal": "", "year": "2021", "authors": "Guy Laban"}, {"ref_id": "b64", "title": "Too human and not human enough: A grounded theory analysis of mental health harms from emotional dependence on the social chatbot Replika", "journal": "new media & society", "year": "2022", "authors": "Linnea Laestadius; Andrea Bishop; Michael Gonzalez; Diana Illen\u010d\u00edk; Celeste Campos-Castillo"}, {"ref_id": "b65", "title": "Conversational agents in healthcare: a systematic review", "journal": "", "year": "2018-05", "authors": "Liliana Laranjo; Huong Ly Adam G Dunn; Ahmet Baki Tong; Jessica Kocaballi; Rabia Chen; Didi Bashir; Blanca Surian; Farah Gallego; Annie Ys Magrabi;  Lau"}, {"ref_id": "b66", "title": "", "journal": "", "year": "2018", "authors": " Wu"}, {"ref_id": "b67", "title": "Caring for Vincent: A Chatbot for Self-Compassion", "journal": "Association for Computing Machinery", "year": "2019", "authors": "Minha Lee; Sander Ackermans; Nena Van As; Hanwen Chang; Enzo Lucas; Wijnand Ijsselsteijn"}, {"ref_id": "b68", "title": "Designing a Chatbot as a Mediator for Promoting Deep Self-Disclosure to a Real Mental Health Professional", "journal": "Proc. ACM Hum.-Comput. Interact", "year": "2020", "authors": "Yi-Chieh Lee; Naomi Yamashita; Yun Huang"}, {"ref_id": "b69", "title": "I Hear You, I Feel You\": Encouraging Deep Self-disclosure through a Chatbot", "journal": "Association for Computing Machinery", "year": "2020", "authors": "Yi-Chieh Lee; Naomi Yamashita; Yun Huang; Wai Fu"}, {"ref_id": "b70", "title": "Chain of Empathy: Enhancing Empathetic Response of Large Language Models Based on Psychotherapy Models", "journal": "", "year": "2023", "authors": "Kyung Yoon; Inju Lee; Minjung Lee; Seoyeon Shin; Sowon Bae;  Hahn"}, {"ref_id": "b71", "title": "Systematic review and meta-analysis of AI-based conversational agents for promoting mental health and well-being", "journal": "NPJ Digital Medicine", "year": "2023", "authors": "Han Li; Renwen Zhang; Yi-Chieh Lee; Robert E Kraut; David C Mohr"}, {"ref_id": "b72", "title": "The Influence of Anthropomorphic Cues on Patients' Perceived Anthropomorphism, Social Presence, Trust Building, and Acceptance of Health Care Conversational Agents: Within-Subject Web-Based Experiment", "journal": "Journal of Medical Internet Research", "year": "2023", "authors": "Qingchuan Li; Yan Luximon; Jiaxin Zhang"}, {"ref_id": "b73", "title": "Using AI chatbots to provide self-help depression interventions for university students: A randomized trial of effectiveness", "journal": "Internet Interventions", "year": "2022", "authors": "Hao Liu; Huaming Peng; Xingyu Song; Chenzi Xu; Meng Zhang"}, {"ref_id": "b74", "title": "ChatCounselor: A Large Language Models for Mental Health Support", "journal": "", "year": "2023", "authors": "June M Liu; Donghao Li; He Cao; Tianhe Ren; Zeyi Liao; Jiamin Wu"}, {"ref_id": "b75", "title": "Task-Adaptive Tokenization: Enhancing Long-Form Text Generation Efficacy in Mental Health and Beyond", "journal": "", "year": "2023", "authors": "Siyang Liu; Naihao Deng; Sahand Sabour; Yilin Jia; Minlie Huang; Rada Mihalcea"}, {"ref_id": "b76", "title": "Harnessing Large Language Models' Empathetic Response Generation Capabilities for Online Mental Health Counselling Support", "journal": "", "year": "2023", "authors": "Brandon Siyuan; Aravind Loh; Raamkumar Sesagiri"}, {"ref_id": "b77", "title": "Like having a really bad PA: The gulf between user expectation and experience of conversational agents", "journal": "ACM", "year": "2016", "authors": "Ewa Luger; Abigail Sellen"}, {"ref_id": "b78", "title": "A fully automated conversational agent for promoting mental well-being: A pilot RCT using mixed methods", "journal": "", "year": "2017-12", "authors": "Hoa Kien; Ann-Marie Ly; Gerhard Ly;  Andersson"}, {"ref_id": "b79", "title": "Becoming happier takes both a will and a proper way: an experimental longitudinal intervention to boost well-being", "journal": "Emotion", "year": "2011", "authors": "Sonja Lyubomirsky; Rene Dickerhoof; Julia K Boehm; Kennon M Sheldon"}, {"ref_id": "b80", "title": "How do simple positive activities increase well-being?", "journal": "Current directions in psychological science", "year": "2013", "authors": "Sonja Lyubomirsky; Kristin Layous"}, {"ref_id": "b81", "title": "Understanding the Benefits and Challenges of Using Large Language Model-based Conversational Agents for Mental Well-being Support", "journal": "", "year": "2023", "authors": "Zilin Ma; Yiyang Mei; Zhaoyuan Su"}, {"ref_id": "b82", "title": "A physical activity and diet program delivered by artificially intelligent virtual health coach: proof-of-concept study", "journal": "JMIR mHealth and uHealth", "year": "2020", "authors": "Ann Carol; Courtney Rose Maher; Rachel Grace Davis; Camille Elizabeth Curtis; Karen Joy Short;  Murphy"}, {"ref_id": "b83", "title": "LLM-Powered Conversational Voice Assistants: Interaction Patterns, Opportunities, Challenges, and Design Guidelines", "journal": "", "year": "2023", "authors": "Amama Mahmood; Junxiang Wang; Bingsheng Yao; Dakuo Wang; Chien-Ming Huang"}, {"ref_id": "b84", "title": "Humans perceive warmth and competence in artificial intelligence", "journal": "iScience", "year": "2023", "authors": "Xi Kathryn R Mckee; Susan T Bai;  Fiske"}, {"ref_id": "b85", "title": "Conversational modelling for chatbots: current approaches and future directions", "journal": "Studientexte zur Sprachkommunikation: Elektronische Sprachsignalverarbeitung", "year": "2018", "authors": "Michael Mctear"}, {"ref_id": "b86", "title": "An exploration of the relation between expectations and user experience", "journal": "International Journal of Human-Computer Interaction", "year": "2015", "authors": "Jan Michalco; Jakob Grue Simonsen; Kasper Hornbaek"}, {"ref_id": "b87", "title": "The uncanny valley: the original essay by Masahiro Mori", "journal": "Ieee Spectrum", "year": "1970", "authors": "Masahiro Mori"}, {"ref_id": "b88", "title": "Machines and mindlessness: Social responses to computers", "journal": "Journal of social issues", "year": "2000", "authors": "Clifford Nass; Youngme Moon"}, {"ref_id": "b89", "title": "Computers are social actors", "journal": "", "year": "1994", "authors": "Clifford Nass; Jonathan Steuer; Ellen R Tauber"}, {"ref_id": "b90", "title": "A systematic review of artificial intelligence chatbots for promoting physical activity, healthy diet, and weight loss", "journal": "International Journal of Behavioral Nutrition and Physical Activity", "year": "2021", "authors": "Jung Yoo; Jingwen Oh; Min Zhang; Yoshimi Fang;  Fukuoka"}, {"ref_id": "b91", "title": "Mental health and COVID-19: Early evidence of the pandemic's impact", "journal": "World Health Organization", "year": "2023-09-10", "authors": ""}, {"ref_id": "b92", "title": "The law of attraction in human-robot interaction", "journal": "International Journal of Advanced Robotic Systems", "year": "2012", "authors": "Eunil Park; Dallae Jin; Angel P Del Pobil"}, {"ref_id": "b93", "title": "Exercise and well-being: a review of mental and physical health benefits associated with physical activity", "journal": "Current Opinion in Psychiatry", "year": "2005", "authors": "Frank J Penedo; Jason R Dahn"}, {"ref_id": "b94", "title": "Expressive writing: Connections to physical and mental health", "journal": "", "year": "2011", "authors": "W James; Cindy K Pennebaker;  Chung"}, {"ref_id": "b95", "title": "Conceptualising engagement with digital behaviour change interventions: a systematic review using principles from critical interpretive synthesis", "journal": "Translational behavioral medicine", "year": "2017", "authors": "Olga Perski; Ann Blandford; Robert West; Susan Michie"}, {"ref_id": "b96", "title": "Does the addition of a supportive chatbot promote user engagement with a smoking cessation app? An experimental study", "journal": "Digital Health", "year": "2019", "authors": "Olga Perski; David Crane; Emma Beard; Jamie Brown"}, {"ref_id": "b97", "title": "Use of the healthy lifestyle coaching chatbot app to promote stair-climbing habits among office workers: exploratory randomized controlled trial", "journal": "JMIR mHealth and uHealth", "year": "2020", "authors": "Meihua Piao; Hyeongju Ryu; Hyeongsuk Lee; Jeongeun Kim"}, {"ref_id": "b98", "title": "Voice interfaces in everyday life", "journal": "", "year": "2018", "authors": "Martin Porcheron; Joel E Fischer; Stuart Reeves; Sarah Sharples"}, {"ref_id": "b99", "title": "Hey Google, Do You Have a Personality? Designing Personality and Personas for Conversational Agents", "journal": "Association for Computing Machinery", "year": "2021", "authors": "Alisha Pradhan; Amanda Lazar"}, {"ref_id": "b100", "title": "The transtheoretical model of health behavior change", "journal": "American Journal of Health Promotion", "year": "1997-09", "authors": "James O Prochaska; Wayne F Velicer"}, {"ref_id": "b101", "title": "This is not what we wanted' designing for conversation with voice interfaces", "journal": "Interactions", "year": "2018", "authors": "Stuart Reeves; Martin Porcheron; Joel Fischer"}, {"ref_id": "b102", "title": "MUBS: A Personalized Recommender System for Behavioral Activation in Mental Health", "journal": "", "year": "2020", "authors": "Darius Adam Rohani; Andrea Quemada Lopategui; Nanna Tuxen; Maria Faurholt-Jepsen; Lars Vedel Kessing; Jakob Eyvind Bardram"}, {"ref_id": "b103", "title": "Self-determination theory and the facilitation of intrinsic motivation, social development, and well-being", "journal": "American Psychologist", "year": "2000", "authors": "Richard M Ryan; Edward L Deci"}, {"ref_id": "b104", "title": "The acceptability and efficacy of an intelligent social tutoring system", "journal": "Computers & Education", "year": "2014", "authors": "Rebecca Polley Sanchez; Chelsea M Bartel; Emily Brown; Melissa Derosier"}, {"ref_id": "b105", "title": "Realizing the Potential of Behavioral Intervention Technologies", "journal": "Current Directions in Psychological Science", "year": "2013", "authors": "Stephen M Schueller; Ricardo F Mu\u00f1oz; David C Mohr"}, {"ref_id": "b106", "title": "Designing anthropomorphic conversational agents: Development and empirical evaluation of a design framework", "journal": "", "year": "2018", "authors": "Anna-Maria Seeger; Jella Pfeiffer; Armin Heinzl"}, {"ref_id": "b107", "title": "Positive psychology progress: empirical validation of interventions", "journal": "American psychologist", "year": "2005", "authors": "Tracy A Martin Ep Seligman; Nansook Steen; Christopher Park;  Peterson"}, {"ref_id": "b108", "title": "Flourish: A visionary new understanding of happiness and well-being", "journal": "Free Press", "year": "2011", "authors": "E P Martin;  Seligman"}, {"ref_id": "b109", "title": "How to increase and sustain positive emotion: The effects of expressing gratitude and visualizing best possible selves", "journal": "The journal of positive psychology", "year": "2006", "authors": "M Kennon; Sonja Sheldon;  Lyubomirsky"}, {"ref_id": "b110", "title": "Systematic review and meta-analysis of the effectiveness of chatbots on lifestyle behaviours", "journal": "NPJ Digital Medicine", "year": "2023", "authors": "Ben Singh; Timothy Olds; Jacinta Brinsley; Dorothea Dumuid; Rosa Virgara; Lisa Matricciani; Amanda Watson; Kim Szeto; Emily Eglitis; Aaron Miatke; Catherine E Simpson; Corneel Vandelanotte; Carol Ann Maher"}, {"ref_id": "b111", "title": "The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support", "journal": "", "year": "2024", "authors": "Inhwa Song; R Sachin; Neha Pendse; Munmun De Kumar;  Choudhury"}, {"ref_id": "b112", "title": "Feasibility of pediatric obesity and prediabetes treatment support through Tess, the AI behavioral coaching chatbot", "journal": "Translational behavioral medicine", "year": "2019", "authors": "Angela Taylor N Stephens; Michiel Joerin; Lloyd N Rauws;  Werk"}, {"ref_id": "b113", "title": "Parasocial theory: Concepts and measures", "journal": "The international encyclopedia of media effects", "year": "2017", "authors": "S Gayle;  Stever"}, {"ref_id": "b114", "title": "Toward a design theory for virtual companionship", "journal": "Human-Computer Interaction", "year": "2023", "authors": "Timo Strohmann; Dominik Siemon; Bijan Khosrawi-Rad; Susanne Robra-Bissantz"}, {"ref_id": "b115", "title": "Generative artificial intelligence in mental health care: potential benefits and current challenges", "journal": "World Psychiatry", "year": "2024", "authors": "John Torous; Charlotte Blease"}, {"ref_id": "b116", "title": "Using Chatbots and Conversational Agents for the Promotion of Well-being and Mental Health in Adolescents: Limitations and Perspectives", "journal": "Journal of Inclusive Methodology and Technology in Learning and Teaching", "year": "2024", "authors": "Beatrice Tosti; Stefano Corrado; Stefania Mancone"}, {"ref_id": "b117", "title": "Cultural variation in affect valuation", "journal": "Journal of Personality and Social Psychology", "year": "2006", "authors": "Jeanne L Tsai; Brian Knutson; Helene H Fung"}, {"ref_id": "b118", "title": "Older age may offset genetic influence on affect: The COMT polymorphism and affective well-being across the life span", "journal": "Psychology and Aging", "year": "2016", "authors": "Tamara Bulent Turan; Sasha E Sims; Laura L Best;  Carstensen"}, {"ref_id": "b119", "title": "Chatbots and conversational agents in mental health: a review of the psychiatric landscape", "journal": "The Canadian Journal of Psychiatry", "year": "2019", "authors": "Aditya Nrusimha Vaidyam; Hannah Wisniewski; John David Halamka; John Matcheri S Kashavan; Torous Blake"}, {"ref_id": "b120", "title": "Global mental health services and the impact of artificial intelligence-powered large language models", "journal": "JAMA psychiatry", "year": "2023", "authors": "Julia R Alastair C Van Heerden; Brandon A Pozuelo;  Kohrt"}, {"ref_id": "b121", "title": "On the promotion of human flourishing", "journal": "Proceedings of the National Academy of Sciences of the United States of America", "year": "2017", "authors": "J Tyler;  Vanderweele"}, {"ref_id": "b122", "title": "Activities for flourishing: An evidence-based guide", "journal": "Journal of Positive School Psychology", "year": "2020", "authors": "J Tyler;  Vanderweele"}, {"ref_id": "b123", "title": "Reimagining Health-Flourishing", "journal": "JAMA", "year": "2019", "authors": "J Tyler; Eileen Vanderweele; Howard K Mcneely;  Koh"}, {"ref_id": "b124", "title": "Lifestyle and mental health", "journal": "American psychologist", "year": "2011", "authors": "Roger Walsh"}, {"ref_id": "b125", "title": "Cass: Towards building a social-support chatbot for online health community", "journal": "", "year": "2021", "authors": "Liuping Wang; Dakuo Wang; Feng Tian; Zhenhui Peng; Xiangmin Fan; Zhan Zhang; Mo Yu; Xiaojuan Ma; Hongan Wang"}, {"ref_id": "b126", "title": "The uncanny valley: Existence and explanations", "journal": "Review of General Psychology", "year": "2015", "authors": "Shensheng Wang; Scott O Lilienfeld; Philippe Rochat"}, {"ref_id": "b127", "title": "ELIZA-a computer program for the study of natural language communication between man and machine", "journal": "Commun. ACM", "year": "1966", "authors": "Joseph Weizenbaum"}, {"ref_id": "b128", "title": "Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults", "journal": "Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies", "year": "2024", "authors": "Ziqi Yang; Xuhai Xu; Bingsheng Yao; Ethan Rogers; Shao Zhang; Stephen Intille; Nawar Shara; Guodong ; Gordon Gao; Dakuo Wang"}, {"ref_id": "b129", "title": "Development and Evaluation of Three Chatbots for Postpartum Mood and Anxiety Disorders", "journal": "", "year": "2023", "authors": "Xuewen Yao; Miriam Mikhelson; S Craig Watkins; Eunsol Choi; Edison Thomaz; Kaya De; Barbaro "}, {"ref_id": "b130", "title": "Understanding and promoting effective engagement with digital behavior change interventions", "journal": "American journal of preventive medicine", "year": "2016", "authors": "Lucy Yardley; Bonnie J Spring; Heleen Riper; Leanne G Morrison; David H Crane; Kristina Curtis; Gina C Merchant; Felix Naughton; Ann Blandford"}, {"ref_id": "b131", "title": "Crossing the uncanny valley? Understanding affinity, trustworthiness, and preference for more realistic virtual humans in immersive environments", "journal": "", "year": "2019", "authors": "Lingyao Yuan; Alan Dennis; Kai Riemer"}, {"ref_id": "b132", "title": "Artificial intelligence chatbot behavior change model for designing artificial intelligence chatbots to promote physical activity and a healthy diet", "journal": "Journal of medical Internet research", "year": "2020", "authors": "Jingwen Zhang; Jung Yoo; Patrick Oh; Zhou Lange; Yoshimi Yu;  Fukuoka"}, {"ref_id": "b133", "title": "Toward a positive design theory: Principles for designing motivating information and communication technology", "journal": "Emerald Group Publishing Limited", "year": "2007", "authors": "Ping Zhang"}, {"ref_id": "b134", "title": "Ask an Expert: Leveraging Language Models to Improve Strategic Reasoning in Goal-Oriented Dialogue Models", "journal": "", "year": "2023", "authors": "Qiang Zhang; Jason Naradowsky; Yusuke Miyao"}, {"ref_id": "b135", "title": "A \"present\" for the future: The unexpected value of rediscovery", "journal": "Psychological science", "year": "2014", "authors": "Ting Zhang; Tami Kim; Alison Wood Brooks; Francesca Gino;  Michael I Norton"}, {"ref_id": "b136", "title": "Storybuddy: A human-ai collaborative chatbot for parent-child interactive storytelling with flexible parental involvement", "journal": "", "year": "2022", "authors": "Zheng Zhang; Ying Xu; Yanhao Wang; Bingsheng Yao; Daniel Ritchie; Tongshuang Wu; Mo Yu; Dakuo Wang; Toby Jia-Jun Li"}, {"ref_id": "b137", "title": "Insufficiently complimentary?: Underestimating the positive impact of compliments creates a barrier to expressing them", "journal": "Journal of Personality and Social Psychology", "year": "2021", "authors": "Xuan Zhao; Nicholas Epley"}, {"ref_id": "b138", "title": "Surprisingly happy to have helped: Underestimating prosociality creates a misplaced barrier to asking for help", "journal": "Psychological Science", "year": "2022", "authors": "Xuan Zhao; Nicholas Epley"}, {"ref_id": "b139", "title": "Building Emotional Support Chatbots in the Era of LLMs", "journal": "", "year": "2023", "authors": "Zhonghua Zheng; Lizi Liao; Yang Deng; Liqiang Nie"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Wu, et al.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Wu, et al.", "figure_data": ""}, {"figure_label": "21", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "3. 2 . 121Anthropomorphic Design of Sunnie. In this section, we delve into the anthropomorphic designs of Sunnie as shown in Figure.3, aligning with our design principles (DP1, DP3) to balance human-like elements and promote well-being in users.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Fig. 5 .5Fig. 5. The prompting framework for Sunnie comprises four modules: Sunnie's persona, conversation protocol, system setting, and response optimization.", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Fig. 7 .7Fig. 7. Participants' ratings of their expectations versus evaluations of AI systems on two dimensions: relational warmth and perceived utility. Ratings were collected for general expectations, a baseline non-anthropomorphic agent, and Sunnie, an anthropomorphic agent. Statistical comparisons are indicated as follows: ns = not significant (p > .05), ** p < .01, *** p < .001.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "like figure. This leaves open the question of whether different anthropomorphic designs might yield different effects on user perceptions and engagement. Future research should explore a wider variety of anthropomorphic designs to determine which features are most effective in enhancing user experience and fostering long-term engagement.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "", "figure_caption": "", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "", "figure_caption": "", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "", "figure_caption": "", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "", "figure_caption": "", "figure_data": ""}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Demographics of interview participants.5.1.3 Behavioral Engagement.We examined the proportion of participants who completed the recommended activities in each condition and conducted a chi-squared test to determine whether the observed differences were statistically significant. A majority of participants completed the recommended activities in both the Baseline condition (75.0%; 30 out of 40) and the Sunnie condition (67.5%; 27 out of40)", "figure_data": "P#EthnicityAgeGenderP1Asian21FemaleP2Mixed19MaleP3White23MaleP4Asian21Female"}], "formulas": [], "doi": "10.1145/nnnnnnn.nnnnnnn"}
