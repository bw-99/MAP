{"Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning": "XIAOLI TANG and HAN YU, Nanyang Technological University, Singapore Artificial intelligence-empowred Real-Time Bidding (AIRTB) is regarded as one of the most enabling technologies for online advertising. It has attracted significant research attention from diverse fields such as pattern recognition, game theory and mechanism design. Despite of its remarkable development and deployment, the AIRTB system can sometimes harm the interest of its participants (e.g., depleting the advertisers' budget with various kinds of fraud). As such, building trustworthy AIRTB auctioning systems has emerged as an important direction of research in this field in recent years. Due to the highly interdisciplinary nature of this field and a lack of a comprehensive survey, it is a challenge for researchers to enter this field and contribute towards building trustworthy AIRTB technologies. This paper bridges this important gap in trustworthy AIRTB literature. We start by analysing the key concerns of various AIRTB stakeholders and identify three main dimensions of trust building in AIRTB, namely security, robustness and fairness. For each of these dimensions, we propose a unique taxonomy of the state of the art, trace the root causes of possible breakdown of trust, and discuss the necessity of the given dimension. This is followed by a comprehensive review of existing strategies for fulfilling the requirements of each trust dimension. In addition, we discuss the promising future directions of research essential towards building trustworthy AIRTB systems to benefit the field of online advertising. CCS Concepts: \u00b7 Applied computing \u2192 Online auctions ; \u00b7 Information systems \u2192 Display advertising ; \u00b7 Computing methodologies \u2192 Artificial intelligence ; \u00b7 General and reference \u2192 Surveys and overviews . Additional Key Words and Phrases: trustworthy artificial intelligence, real-time bidding, auction, security, robustness, fairness", "1 INTRODUCTION": "Recent years have witnessed widespread adoption of online advertising, which has become the dominant sector in the advertising industry. Compared with traditional television, radio, newspaper, magazines and billboards, online advertising not only provides advertisers with an alternative option to diversity their strategies to reach more potential customers via the Internet, but also allows them to personalize ads to viewers in a real-time and cost-effective manner [112]. The key enabling technology for online advertising is Real-Time Bidding (RTB), which refers to the algorithmic trading of online advertising opportunities (a.k.a. ad impressions) through artificial intelligence (AI)-empowered real-time auctioning [112]. In RTB, the entire auction process for each impression usually takes less than 100 milliseconds before the ad is positioned. By automating the auctioning process involving a large number of available inventories among ad publishers, RTB has significantly transformed the online advertising marketplace. Compared with other types of online advertising, RTB offers a more streamlined, efficient and targeted purchasing process for advertisers. It promotes user behavior targeting based on user data rather than contextual data, and focuses on the most relevant inventory which can result in high returns on investment for the advertisers. Currently, there have been two surveys on the topic of RTB [68, 112]. They review RTB from the perspective of algorithm design with the aim of maximizing the revenue or other key performance indicators for different participants of the ad delivery process. Authors' address: Xiaoli Tang, xiaoli001@ntu.edu.sg; Han Yu, han.yu@ntu.edu.sg, Nanyang Technological University, 50 Nanyang Avenue, Singapore, 639798. 1 111:2 \u00b7 Tang and Yu Despite its development, RTB still faces challenges which threaten its trustworthiness. Firstly, RTB systems face many security threats. On the one hand, there have been diverse types of frauds which can deplete advertisers' budgets. On the other hand, ads can be injected into the publishers' pages by malicious participants, which brings no revenue to the publishers or even damage their reputation. Secondly, RTB systems face challenges that demand high levels of algorithmic robustness. As shown in [112, 124], RTB suffers from the sample selection biases (SSBs), which characterize the systematic distinction between the data distributions in the training space and the inference space. Last but not least, RTB systems face users from diverse demographic backgrounds. Thus, fair treatment of the users is an important consideration [20]. As trustworthy AI research starts to gain traction in recent years, works on enhancing the trustworthiness of RTB systems have also emerged. Nevertheless, there is currently no comprehensive survey on trustworthy AI-empowered RTB (AIRTB) techniques. In this paper, we attempt to bridge this gap. This paper contributes to the trustworthy AI literature in the following ways: (1) We provide a detailed analysis of the RTB technology ecosystem, with focus on the diverse stakeholders involved and the trustworthy AI dimensions important to them. (2) We propose a unique multi-tiered taxonomy of trustworthy AIRTB based on the major techniques supporting AIRTB, and summarize trustworthy AI related challenges in each part. In lower tiers of this taxonomy, we summarize the key techniques supporting the security, robustness and fairness aspects of AIRTB. To the best of our knowledge, it is the first such taxonomy on this topic, and provides new perspectives to existing works in this field. (3) We discuss the main metrics adopted in existing approaches to experimentally evaluate the performance of trustworthy AIRTB approaches, thereby, providing readers with a useful guide on experiment design. (4) Weoutline promising future research directions towards building trustworthy AI-empowered real-time auctioning systems for online advertising. For each direction, we analyse the limitations in the current literature and propose potential ways forward. Through this survey, we aim to provide researchers and practitioners with an informative overview of trustworthy AI-empowered real-time auctioning to help them enter this interdisciplinary field.", "2 AN OVERVIEW OF TRUSTWORTHY AIRTB": "This section provides backgrounds on the topic of Trustworthy AIRTB [68]. We start by introducing the main terminologies. Then, we illustrate the AIRTB ecosystem and the commonly adopted revenue models. Lastly, we summarize the trust building requirements by various AIRTB stakeholders.", "2.1 Terminologies": "Table 1 lists the key stakeholders (a.k.a. participants 1 ) in a typical AIRTB ecosystem and their corresponding descriptions according to the Interactive Advertising Bureau (IAB) 2 . An AIRTB ecosystem includes three main types of stakeholders: 1) advertisers, 2) ad networks, and 3) publishers. Advertisers need to continually adjust the design of their ad campaigns based on analysis from various ad networks to increase their impact. To maximize revenues, publishers need to selectively subscribe to a number of ad networks based on cost-benefit analysis. Ad networks form Ad Exchanges to offer combined marketplaces for advertisers and publishers to join. To make it more efficient for advertisers to choose target users and publishers to place their ads, demand side platforms (DSPs) emerge. They are autonomous agents working on behalf of advertisers in an ad exchange. By combining demands, DSPs can enhance the effectiveness and selectivity 1 In this paper, we use 'participants' and 'stakeholders' interchangeably. 2 https://wiki.iab.com Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:3 Table 1. Stakeholders of a typical AIRTB ecosystem. for advertisers. Similarly, supply side platforms (SSPs) work as the agents to help publishers in an ad exchange sell impressions and optimally manage their inventories [28]. Since ad networks, ad exchanges, DSPs and SSPs function together to enable AIRTB services, we refer to them collectively as 'Ad Exchange Networks'.", "2.2 Workflow": "Fig. 1. The high level overview of a typical AIRTB system. 1 \u25cb The advertiser sets up ad campaigns. 2 \u25cb The auction market strikes the balance between demand and supply by trading campaigns and impressions. 3 \u25cb The publisher notifies the auction market of the impressions. Advertiser DSP Ad Network SSP Publisher Demand side Supply side Auction market Ad Network Ad Network Ad exchange \u2460 \u2461 \u2462 \u2461 The high-level overview of a typical AIRTB ecosystem is shown in Figure 1. The advertisers set up ad campaigns in the auction market, while the publishers register ad impressions with the auction market. The auction market execute auctions to trade impressions and ad campaigns in order to strike a balance between demand and supply. The typical workflow of each auction is triggered by the emergence of an ad request from a user (e.g., when a user opens a webpage). Upon receiving such ad request, the ad exchange packages it with user information (e.g., the URL of the webpage which the user is visiting, the IP address of the user, etc.) as well as the publisher information (e.g., the context), and transits the packaged 111:4 \u00b7 Tang and Yu bid request to DSPs which might be interested in displaying their advertisers' ads to this user to solicit bids. Based on this bid request, each DSP assesses the potential revenue and possible cost to determine a bid price according to its bidding function, and sends it back as the bid response. Afterwards, the ad exchange selects the winner and determines the market price according to the adopted auction mechanism (e.g., the second-price auction, first-price auction). It then charges the winner and informs the publisher to display the winning ad. To improve the efficiency of ad delivery, the advertisers and the ad exchange networks often adopt the Online Behavioural Advertising (OBA) technology, which collects users' actions, constructs models to estimate user preferences, and thereafter shows ads tailored to the estimated preferences. To achieve this, they collect and share information about both the users and the publishers by utilizing browser cookies.", "2.3 Revenue Models": "Generally, publishers allow advertisers to post their ads on their websites in exchange for commissions from the activities users take. The quantity of impressions, clicks, and user actions constitute three typical basis for the common models that the publishers adopt to generate revenues. (1) Cost Per Impression Mile (CPM) : Under this revenue model, the fees paid by the advertisers are based on the expense per 1,000 views of the corresponding ad. CPM was designed for conventional advertising systems. It is preferred by the publishers because as long as they display the ads, they can receive revenues without the need to consider user actions (e.g., clicks, conversions). (2) Cost Per Click (CPC) : Under this revenue model, publishers are paid according to the number of clicks by the viewers on the ads shown in their webpages. Compared to CPM, CPC ensures a higher return on investment for the advertisers as clicks by users are strong indicators of potential interest. (3) Cost Per Action (CPA) : Under this revenue model, advertisers pay publishers based on the number of the predefined actions taken by the users following the clicks (e.g., purchasing the corresponding products, subscribing to the services). CPC can be regarded as a special case of CPA. Compared to clicks, the predefined actions following clicks are preferred by the advertisers. As such, CPA is more popular with advertisers. Nevertheless, CPA has its limitations. On the one hand, the publishers are less keen on adopting CPA due to the possibility that fraudulent advertisers may under-report the number of predefined actions performed by the users in order to reduce the commission payout. On the other hand, implementing this model is difficult, particularly when dealing with complicated actions.", "2.4 Desirable Trustworthy AI Dimensions": "Recent ethics guidelines for AI given by the European Union (EU) [103] state that trustworthy AI ecosystems are supposed to adhere to four main ethical principles: explainability, fairness, prevention of harm, and respect for human autonomy. A variety of trustworthy AI dimensions have been proposed by various organizations and researchers based on these four main principles [10, 106]. In this paper, we follow [67] and focus on the following five key dimensions in our discussion about trustworthy AIRTB from the perspectives of the key stakeholders: 1) security, 2) robustness, 3) fairness, 4) explainability and 5) accountability. Table 2 summarizes the dimensions of trustworthy AI concerned by each stakeholders in an AIRTB system. Specifically, to build trust with the advertisers, the AIRTB system needs to make an effort to improve on all five dimensions. To build trust with the publishers, AIRTB needs to fulfill their requirements from the perspectives of security, robustness, fairness and accountability. As far Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:5 as the ad exchange networks are concerned, if their requirements of security and accountability are fulfilled, they can establish trust with an AIRTB system. Table 2. Detailed trustworthy AI dimensions required by different AIRTB stakeholders. ( \u2217 ) denotes that the corresponding requirement has been studied by existing research. Nevertheless, as the research on trustworthy AIRTB is still in a relatively early stage, the majority of existing studies are concentrated on dimensions of security, robustness and fairness (as shown in Table 2). Hence, our survey mainly focuses on these three trustworthy AIRTB dimensions.", "3 SECURITY": "This section reviews threats facing AIRTB systems and methods to secure them. Specifically, we first briefly summarize the most common attacks targeting AIRTB, and the tools and techniques may used to carry out the attacks. Then, we discuss and analyse the countermeasures against these attacks.", "3.1 Attackers and Threat Models": "Fig. 2. Taxonomy of attacks on AIRTB systems. Attacks on AIRTB Systems Action fraud Traffic fraud Placement fraud Malvertising Click fraud Inflight modification of ad traffic Hacking campaign accounts Conventional click fraud Crowd-based click fraud Hit inflation Hit shaving Badvertising The proposed taxonomy of attacks on AIRTB is shown in Fig. 2. They can be categorized into three major groups: 1) placement fraud, 2) traffic fraud, and 3) action fraud [131]. Placement frauds involve changing or manipulating the information that appears on users' clients or the publisher's websites in order to generate more clicks or impressions. Traffic frauds refer to those that attempt 111:6 \u00b7 Tang and Yu to boost the volume of impressions or clicks from various locations by using fictitious traffics. For instance, malicious attacks can use a crowd or a botnet to artificially boost the number of clicks or impressions on the publishers' websites. Action frauds focus on users' actions to make money. For instance, malicious attackers can hire actors to artificially boost conversion rates with the help of web bots in order to earn additional commissions.", "3.2 Tools and Methods used by Attackers": "Attackers adopt four main types of tools and methods with attacking AIRTB systems: 1) malvertising, 2) inflight modification of ad traffic, 3) click fraud, and 4) hacking campaign accounts. 3.2.1 Malvertising. Malvertising refers to the approach of spreading malwares to vulnerable devices through online advertising [30]. Due to the complexity of AIRTB which involves numerous redirections among various stakeholders, attackers can insert malicious contents (e.g., malicious ads) into places where the ad exchange networks and publishers failed to anticipate. Malvertising threats could be launched by AIRTB advertisers as well as publishers. For example, advertisers can easily launch malvertises by inserting malicious ads into legal ad networks. Ad networks may place such ads on the websites of the corresponding publishers, where end users might be misled to click on them. In addition, the publishers can also include malicious contents on their websites, which could inadvertently lead the users to download malwares even without activation process. Flash-based ads constitute one of the widely known types of malvertising [32]. 3.2.2 Inflight modification of ad traffic (IMAT). In [55], the authors introduced an ad fraud method known as the Man-In-The-Middle (MITM) attack, which modifies ad traffics in-flight. The Bahama botnet [ ? ] is a well-known example of this attack. It enables malwares to force affected devices to provide users with modified ads. Specifically, in the Bahama botnet, the malicious actors manipulate the the Domain Name System (DNS) translations on the compromised devices, and then redirect user traffics to target websites. In this way, click-through payments are activated by user clicks on the fake ads, resulting in payouts from the advertisers without actual clicks on the intended ads. Alternatively, this attack can also be launched through compromised wireless router botnets. This configuration involves turning a malware-infected wireless router into a bot. Then, the botnet master can launch traffic modification attacks in-flight to re-route traffics through such routers. This attack is often performed by public hotspots, which provide free Wifi access to users while inserting ads to boost revenues. 3.2.3 Click Fraud. Click frauds (a.k.a. click spamming, malicious attacks) refer to the automatic or manual attacks that aim to elicit fake clicks on the ads in order to generate illegal revenues [63]. As such attackers click on ads without actually being interested in the contents, they can defraud the advertisers' ad budgets and harm the well-being of the AIRTB ecosystem. Click frauds can be divided into two categories: 1) conventional click frauds, and 2) crowd-based click frauds. 1) Conventional click fraud. Conventional click frauds can be carried out through three main approaches: 1 \u25cb hit inflation, 2 \u25cb hit shaving, and 3 \u25cb badvertising.", "1 \u25cb Hit inflation": "This type of click fraud refers to attacks that aim to increase the number of hits to generate revenues for publishers, or on competitors' ads with invalid clicks to deplete their ad budgets [4]. It is often performed by publishers and advertisers. Publisher click inflation. This attack takes place when fraudulent publishers purposely inflate the click-through rate without genuine interest in the ads to increase revenue from the ad networks [88]. According to the number of fraudsters, publisher click inflation attacks consist of two main types: 1) coalition attacks, and 2) non-coalition attacks [81]. The coalition publisher click inflation attacks Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:7 are carried out by a group of colluding publishers, while the non-coalition attacks involve only one publisher. Coalition attacks has two main advantages. On the one hand, it is more challenging for countermeasures to detect the relationships among malicious devices and malicious publishers. On the other hand, sharing resources instead of adding more physical resources among malicious devices and malicious publishers lowers the costs of launching attacks. Advertiser clicking inflation. This attack refers to the case that the malevolent advertisers aim to deplete their competitors' marketing budgets by launching hit inflation attacks [105]. In this way, the attackers can enhance their likelihood to win future ad placement auctions, especially in situations where the daily marketing budgets of the advertisers are limited.", "2 \u25cb Hit Shaving": "As mentioned in Sec. 2, in contrast to paying the publishers based on the number of clicks, the advertisers generally prefer CPA as they pay publishers based on the desired user actions. Nevertheless, CPA is susceptible to hit shaving attacks [23], which are also known as deflation frauds. Through hit shaving attacks, dishonest advertisers decrease the number of clicks from publishers in an imperceptible manner in order to defraud them of the payouts they deserve.", "3 \u25cb Badvertising": "Badverting refers to covert click fraud attacks that automatically and silently create clicks on ads once the users access the websites so as to increase the attackers' revenue [33]. Compared with traditional attacks based on malwares, badvertiments are more stealthy and generally take the form of phishing attacks and spams. Badvertising consists of two steps: (i) delivery, which transmits either corrupt data to users or users to corrupt data; and (ii) execution, which distributes advertisements to the targeted users secretly and automatically. It can be successfully implemented by manipulating the JavaScript codes that the clients' browsers download and run in order to publish advertisements. JavaScript snippet files are often inserted into the publishers' Web pages for online advertising systems to function. The JavaScript files will run each time a user accesses the pages and downloads ads from ad servers. When the ads are downloaded, the JavaScript files' frames are updated to include the HTML codes necessary to display the ads. The publisher counts how many times the users click on the links to the ad providers' servers using the click-through payment system. Consequently, the users are referred to the websites of the ad clients. In order to deploy clicks automatically, Badvertisements run extra malicious scripts. To put it simply, the malicious scripts parse the HTML codes and assemble all links after running and rewriting the frame. Then, they modify the webpages to include the HTML iframes. If the users choose to click the links, the iframes will be triggered in the background and load their contents to take advantage of the users. 2) Crowd-based click fraud. Crowd-based click frauds leverage crowdsourcing [53] to recruit actual individuals to artificially boost ad traffic [107]. As crowdsourcing systems are widely available, it is possible to hire a large number of workers to blindly click on a rival advertiser's ads to inflate its expenses. Compared with the conventional frauds mentioned above, crowd-based click frauds possess several characteristics: they often involve a sizable group of people, they generate limited traffic, and the click actions cannot be distinguished from normal click actions. 3.2.4 Hacking Campaign Accounts. AIRTB has spawned the tools (e.g., AdWords) which help advertisers launch online campaigns quickly and effectively. However, such tools also make advertisers' accounts vulnerable. Malicious actors can take over the advertisers' accounts and leverage these tools to set up attacks with more significant impact. This attack is referred to as hacking campaign accounts [73]. The campaign accounts may be blocked from legitimate access, or even entered without authorization once they are hacked. 111:8 \u00b7 Tang and Yu", "3.3 Summary": "Table 3. Summary of attacks and the corresponding targeted stakeholders in the AIRTB ecosystem. Fig. 3. Summary of defense methods against attacks on the AIRTB systems. Defending AIRTB systems Offline methods Online methods Heuristic  methods Executable Analysis-based methods Data Analytics-based methods Theoretical Analysis methods Client-centric methods Network-Centric methods Client & Sever Cooperative methods Ad blocking and Anti-adblocking For Web Browser Clients For Mobile App Clients Table 3 summarizes the attacks on AIRTB systems discussed in this section. Among all these attacks, only Inflight Modification of Ad traffic affects all three stakeholders, while hacking campaign accounts, hit shaving, and badvertising only affect one stakeholder. Hacking campaign accounts does not affect specific revenue models. Both hit inflation and crowd-based fraud can be applied under all revenue models adopted by AIRTB. Moreover, they both affect publishers and advertisers, Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:9 while having no effect on ad networks. Among the AIRTB stakeholders, publishers and advertisers are the main targets of attacks, while the ad networks are only being targeted by two attacks. CPC is the revenue model that is affected by the most number of attacks, while CPM is affected by the least number of attacks. This is due to the difference in popularity of the revenue models.", "3.4 Defending AIRTB Systems": "After gaining an overview of attacks on AIRTB, we now look into approaches to defending against such attacks. Fig. 3 shows the proposed taxonomy of existing methods against attacks on AIRTB systems. Based on how and when they take effect, existing AIRTB defense methods can be classified into two main categories: 1) offline methods and 2) online methods. The former are designed to detect and mitigate attacks before and after the ads have been placed. The latter are activated during the ad placement process. In this sense, they complement each other. 3.4.1 Offline Methods. There are four main categories of offline defense methods for AIRTB: 1) Heuristic methods, 2) Data Analytics-based methods, 3) Executable Analysis-based methods, and 4) Theoretical Analysis methods. 1) Heuristic Methods . In the early stage of development for AIRTB, most ad exchange networks clean up malicious ads based on heuristics [73, 107]. For example, if an advertiser finds that it received many clicks from the same IP address without actual purchase, it can exclude future clicks from this IP address (or even the entire region in which the IP address is located). Such methods generally incur high labor costs and tend to become ineffective quickly due to the rapid evolution of attackers' strategies. 2) Data Analytics-based Methods . As machine learnig-based data analytics techniques develop in recent years, researchers have started to leverage them for detecting ad frauds and malicious ads. Based on anonymized data produced for a data-mining competition in 2012, [80] reveals the following discoveries. Firstly, to accurately detect frauds, it is essential to analyse the potential features embedded in fine-grained time-series. Secondly, the most effective approaches to nonlinear classification tasks that are strongly unbalanced, combined with heterogeneous variables and noisy or missing patterns are those that combine numerous traditional data-mining techniques. However, it is worth noting that as the competition took place prior to the wide adoption of deep learning. Deep learning techniques can improve the ability to detect ad fraud, particularly in terms of feature engineering capacity [6]. Based on the findings that publishers involved in click frauds tend to receive higher return on investment (ROI) than honest ones, the Viceroi defense method has been proposed [22]. It consists of both the offline and the online components. The offline component exams click logs across a range of periods to filter out fraudulent clicks as well as geographic areas where the distribution of revenue per user are abnormal. The online component determines whether a specific click belongs to the abnormal region, based on the aforementioned considerations. In [21], the authors analysed a preventive method used to identify click frauds by ad exchange networks based on a variety of information from a unique publisher website (e.g., mouse movements), and added fake ads to the website to elicit malicious participants' clicking data. Similar to adopting the Bayesian method to handle false positive and false negative cases in data analytics, [85] proposed a Bayesian-based approach to detect fraud from click streams. In cases where prior ground truth information is unavailable, click fraud detection is more challenging [8]. In [89], ads obtained by using both static and behavior analysis are used to analyse fraudulent behavhours. These ads are first divided into nine features, and then inputted to a Support Vector Machine (SVM) to identify malicious ones inserted by publishers. In addition, [1] proposed a malvertising detection system - MadTracer - which can be incorporated into ad exchange networks. 111:10 \u00b7 Tang and Yu MadTracer actively crawls information about the AIRTB process and utilizes a decision tree-based method to automatically create a series of fraud detection criteria. Existing data analytics-based AIRTB defense methods tend to be difficult to deploy. Moreover, as these methods are generally developed based on known attacks, they are unable to detect new attacks. 3) Executable Analysis-based Methods . In AIRTB mobile advertising, third-party libraries are required. However, since ad libraries are granted the same level of authorization as their hosting applications, this can lead to serious security and privacy issues if these libraries are compromised. As shown by [11], security flaws can be found early by analysing the malicious executables utilized in malvertising, mobile advertising libraries, and the mobile applications. In [40], the authors developed a system, which can detect various types of risks in AIRTB (e.g., gathering sensitive user data, retrieving code from the web). Their findings suggest that mobile application stores should impose stricter rules on applications that have embedded ad libraries. In [19], the authors developed an analysis tool - MAdFraud - to detect ad fraud by concurrently executing a number of applications in emulators. It performs detection in three steps: 1) constructing HTTP request trees, 2) recognizing ad request pages via machine learning, and 3) detecting clicks in the constructed trees based on the adopted heuristics. In [66], DECAF was proposed to automatically detect multiple types of ad placement frauds in Windows-based mobile platforms. It focuses on the user interface (UI) state transition graph and exploits automated application navigation and optimizations to scan a large number of visual elements in a short time, and determine whether ads within a certain application are in violation of predefined standards governing ad placement and presentation. In addition, to study the malware executables adopted in malvertising, [96] proposed an automated framework which can simulate suspicious browsing activities based on over 800 real-world malicious executables. The majority of the approaches in this group are susceptible to attacks such as click-farms and can be rendered ineffective by sophisticated ad frauds (e.g., botnet ad frauds). In addition, the performance of such methods often depends on the tuning of key parameters, which makes them difficult to deploy. 4) Theoretical Analysis Methods . Theoretical analysis of the security of AIRTB can offer useful ideas for building practical solutions. Game theoretic approaches are widely adopted in this area to study the interactions between defenders and attackers as well as other stakeholders in an AIRTB auctioning ecosystem. Many believed that ad networks (e.g., Google) would lose money if it compensated advertisers for fraudulent clicks, which implies that there is no financial motivation for ad networks to combat fraud. However, analysis in [74] found that ad networks would be worse off in the long term if frauds were unchallenged. In [111], a game theoretic model was proposed to study the botnet-driven ad fraud issue. It reveals that, in certain cases, ad networks are unable to resolve the issue of ad fraud on their own and needs to incur additional costs to elicit help from trusted third-parties. In [25], the authors examined a similar issue with a more sophisticated economic model - the Hotelling Competition-based Game-theoretic model - which is capable of taking into account a wider range of variables. [44, 45] leverage game theoretic modelling to cope with malvertising. In these two works, the malvertiser (i.e., the attacker) and the ad network (i.e., the defender) are players of a Bayesian game, since the the ad network only has partial knowledge of whether it is dealing with a normal advertiser or an attacker. Although these works shed light on the motivations and trade-offs of attackers and defenders, they generally lack experimental evaluation results to investigate the realism of the findings in practice, making them difficult to apply. Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:11 3.4.2 Online Methods. Online approaches defending AIRTB can be divided into four categories: 1) Client-Centric Methods, 2) Client & Server Cooperative Methods, 3) Network-Centric Methods, and 4) Adblocking and Anti-Adblocking methods. 1) Client-Centric Methods . As the name suggests, client-centric methods attempt to address security threats at the client side, either web browsers or mobile apps. Since the execution settings as well as integration techniques for these two types of clients are significantly different, researchers have proposed different methods for them.", "1 \u25cb For Web Browser Clients": "Tripwire [91] is thought to be the milestone client-side defense solution for AIRTB in web browser environments to detect HTTP changes made to the web pages. It was considered as a competitor of HTTPS regarding the ad since it is less expensive. One drawback of Tripwire is that it cannot cope with a large number of attacks taking place simultaneously at the endpoint. Wellwritten malicious codes as well as well-written browser extensions can still circumvent Tripwire to manipulate the target webpages. In addition, Tripwire struggles from the lack of a reliable channel for communication. Consequently, adversaries with enough access privileges can remove the code for integrity verification and fake legitimate responses. In [110], the authors proposed a defense mechanism based on authenticated hash-chains. The fundamental operation of this method is the computation of hash values of web pages. It performed well initially on static webpages. Nevertheless, as websites become increasingly interactive, its effectiveness drops. Today, to assess the integrity of webpages and web applications, we must calculate the hash values of the document object model (DOM) tree, which are provided by the corresponding browser. In [123], the authors propose various test methods, which can filter out bots. For example, in order to test mouse events, functionality and behavior of browsers, the authors develop JavaScript snippets. These tests are then used to exam the client ad requests. AdSentry [24], a browser-based defense mechanism, targets ads based on JavaScript to protect website users from attacks such as malvertising. It uses a shadow JavaScript engine to entirely mediate the ad script's access to the webpage (including its DOM) without affecting other ad-related functions. This enables flexible regulation of ad script behaviours. AdSentry has a policy enforcer that enables end users and the publishers to customize the access permissions for ads. For end users, AdSentry can employ adblockers to automatically detect advertisements and enclose them in a specialized JavaScript wrapper. For the publishers, if the advertisements are encapsulated by unique JavaScript variables, their executions are confined to the shadow JavaScript engine.", "2 \u25cb For Mobile App Clients": "Lack of sufficient oversight might enable legitimate advertising service providers to exploit mobile ad libraries to launch attacks on AIRTB from the inside. To deal with this problem, [86] proposed AdDroid to separate out privileges related to ad libraries in Android applications. Specifically, AdDroid grants application developers an unique API for advertising. As a result, API requests related to advertising do not receive the same permission as the mobile app itself. In [62], a novel verifiable mobile ad framework - AdAttester - was developed based on the ARM TrustZone technique. There are two main types of security primitives included in AdAttester, unforgettable clicks and verifiable displays, both of which are implemented based on the ARM TrustZone hardware root of trust in order to collect proofs that are attached to ad requests for attestation made to ad providers. In [49], FCFraud was proposed to target click fraud at the operating system level. It consists of a Linux kernel component which builds HTTP request trees from domain names that are available to the public and associated with advertising. Based on this, it monitors hardware activities such as clicks. If an extrapolated click from the built trees is verified to be not set off by the hardware, the corresponding request is detected as click fraud. AdSherlock [13] is a similar approach based on the ad request tree model. In [101], the authors proposed a machine learning-based system 111:12 \u00b7 Tang and Yu to distinguish fake clicks from the legitimate ones. It employs a classifier, which is trained using the motion sensor signals from mobile devices. Most existing client-centric methods are faced with one main issue: clients are vulnerable to hacking. Once a client is hacked, the security countermeasures within the client are rendered ineffective. As such, defense techniques that utilize both the client and the server have been proposed to get around this limitation. 2) Client & Sever Cooperative Methods . In [42], one specific type of baiting ads named bluff ads are developed to be recognizable and clicked by bots or inadequately skilled click farm actors. The clicks on bluff ads are regarded as fraudulent by the server-side component. To make HTTPS more effective in scenarios like caching of Content Delivery Network (CDN), [102] proposed a new form of HTTP protocol with integrity, named HTTPi. In order to accomplish this, new modules must be added to web servers as well as web browsers. This approach can reduce ad concerns related to hacking. To cope with attacks on the endpoints, [104] proposed a framework for client-server transaction fingerprinting. To verify true clicks (i.e., only those that can be verified as legitimate), [52] put forth a new scheme based on requests being verified by client-based cryptography attestations. In [12], a similar approach was proposed with the goal of improving transparency from the viewpoint of the advertisers. Specifically, it gathers the pertinent data related to each impression (i.e., the URL in which the impression is delivered, the User-Agent which accepts such impression, and interactions between the user and the ad impression like clicks on the ad and mouse movements), and then transmits them to a central server. In [51], the authors envisaged gathering and inputting data related to user mouse movements into machine learning frameworks to aid ad fraud detection. To some extent, this is a useful technique for telling bots and people apart. Nevertheless, its applicability is still limited as currently: 1) the size of user profile data which cover the mouse movements is significantly larger than that of those which do not contain mouse movements; and 2) the data are generally not well-organized. In addition, by adding random noisy information to the automated mouse movements, bots can still trick machine learning algorithms into classifying them as humans. In [2], the authors developed a novel framework to identify mobile click bots. It consists of a client-side component and a server-side component. The former is used to gather and screen all events created by mobile clients, while the latter is used to analyse incoming data and filter out bots. Current methods in this category tend to focus on the security of only one participant, leaving the other ones still vulnerable to attacks. 3) Network-Centric Methods . Through investigation of the network edge traffics, network monitoring tools (e.g., intrusion detection systems (IDSs)) can detect fraudulent and malvertising traffics. As such, there have been works taking advantage of IDSs to combat malvertising in AIRTB. In malvertising, attackers try to avoid having their web-based exploit kit services banned by hiding them. As a result, more sophisticated malvertising traffic detection methods are required. In order to contaminate client browsers, a web-based attack needs to redirect a web browser to the corresponding landing page, retrieve exploit files, and download infected codes. Based on the design of the web requests, which takes the form of a tree and classifying data based on structural information, [1] proposed a method to identify malicious ad traffic. In particular, information retrieval methods are first used to create the index of harmful tree samples. Then, the subtree similarity search algorithm is adopted to identify HTTP flows associated with the malicious exploit kits. It is worth noting that these approaches can be expanded and used by large organizations like Internet Service Providers (ISPs) to identify further advertising-related problems, such as ad frauds. However, there are several open challenges to be solved. On the one hand, these approaches need Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:13 to be made more efficient to handle considerably higher levels of traffic. On the other hand, ISPs might require financial incentives to participate in these approaches. 4) Adblocking and Anti-Adblocking. Adblockers can stop multiple types of malvertising. Nevertheless, adblocking can be disadvantageous for the publishers whose revenues depend on advertising. To maintain a steady stream of income, the publishers can establish rules which restrict access to the services or contents to people who are prepared to view the ads. Such decisions are based on economic considerations and have been analysed in [90] based on game theoretic modelling. In essence, an adblocker functions as a web browser extension and has greater access rights than anti-adblocking scripts, which typically execute within the JavaScript engine sandbox. Thus, adblockers ultimately hold a technical advantage in the rivalry between adblocking and anti-adblocking. Certainly, the rising popularity of adblocking can be perceived as a sign of trouble for the AIRTB ecosystem. However, from a technical standpoint, adblocking and anti-adblocking techniques can help enhance the security of AIRTB systems. As reported in [46, 78], plenty of publishers have implemented methods and techniques to identify and disable adblockers. The fundamental approach is through filtering. Firstly, a list is constructed based on feedbacks from the general public. Then, adblockers will block web traffics based on this blacklist. Some web traffics in this blacklist might be equipped with anti-adblockers. To combat these anti-adblockers, some approaches have been developed to improve the existing adblocking methods. In [82], JavaScript source codes undergo static program analysis in order to identify those that display ads. According to [129], more than 30% of the Alexa top 10,000 websites have been equipped with anti-adblockers scripts. The authors of [50] proposed to aggregate information from various sources (including JavaScript, HTML, and HTTP) into a machine learning framework, and adopt AI algorithms to construct a filtering list to detect anti-adblockers. In [50], the authors developed a scheme to prevent ads from being served via mobile apps. It consists of a machine learning classifier to reject ads using information from packets acquired after intercepting the network interface of the device.", "3.5 Evaluation Metrics": "Establishing a collection of performance evaluation measures is crucial for the long-term development of security research for AIRTB as it allows for the unbiased comparison of the proposed methods. In this section, we discuss the benchmark evaluation metrics used in the state-of-the-art works. \u00b7 Accuracy : This is the most widely used evaluation metric. In current works, accuracy takes various forms, such as the number of recognised malicious attackers [62], precision [51], recall [49], the false positive rate [66], and the false negative rate [123]. \u00b7 Efficiency : Efficiency is another widely adopted evaluation metric. Some works measure the overhead caused by the deployed mitigation strategies, such as processing time [40], the overhead on memory and CPU [100], and the overhead on event throughput (e.g., clicks) [100]. It is worth noting that, efficiency is not used to directly evaluate the effectiveness in terms of combating malicious attacks, but to evaluate deployment complexity.", "3.6 Summary": "Attack detection in AIRTB is an active area of research because malicious actors are constantly coming up with novel attacks. Thus, the most important factor in making the entire AIRTB ecosystem secure is through real-time detection of attacks. Due to the rapid expansion of AIRTB to meet the demands of the publishers and advertisers, the attack surface of AIRTB also becomes larger. Although numerous efforts are being made to mitigate attacks against AIRTB, the security 111:14 \u00b7 Tang and Yu requirements of all stakeholders still cannot be met by any existing approach in a well integrated manner. Nevertheless, several areas of research are gaining traction: \u00b7 Data analytics: Approaches for identifying ad fraud and bots and mitigating malvertising can take advantage of the vast amount of data created in the ads placement process. \u00b7 Security improvements: Limiting the permissions of mobile apps and adblocking is an effective solution for improving the security of the AIRTB ad delivery process. \u00b7 Theoretical analysis: Game theoretic approaches are frequently adopted to examine issues such as participants' motivations, and resource trade-offs in attacks and defenses.", "4 ROBUSTNESS": "Fig. 4. Robustness research in AIRTB. Winning Probability Estimation Biases Mean Squared Error Robustness Utility Estimation Biases Bid Shading Biases Tobit-based Methods Kaplan-Meier Methods Auxiliary Task-based Methods Sampling-based Methods Sequential Pattern-based Methods Auxiliary Task-based Methods Cumulative distribution function formulization Log-likelihood Concordance index Average Negative Log Probability Mean Absolute Error Pearson correlation KL-divergence 1-Wasserstein distance Group Area Under Curve Area Under Curve F1 Score Mean Squared Error Negative Log-likelihood Problems Methods Evaluation metrics Fig. 4 provides an overview of the roadmap of research related to robustness in AIRTB. Most such works focus on helping AIRTB approaches to be robust against various types of biases. According to [67], biases related to AI research can be divided into three categories: 1) discriminatory bias, 2) productive bias, and 3) erroneous bias. Discriminatory biases manifest as algorithmic unfairness towards groups or individuals (e.g., the creation of discriminating content or subpar performance for some users) [99]. Almost all machine learning algorithms are faced with the productive bias problem [43]. According to the 'no free lunch theory' [119], only predictive models that are biased towards specific distributions can outperform them during modeling. In general, productive bias is introduced through the presumptions about the learning tasks (via loss function design), the distribution assumption, and the optimization methods. Erroneous biases are a specific type of systematic errors caused by unrealistic assumptions. For instance, it is commonly assumed in AI that there is no difference between the distribution of the real data and that of the training data. Nevertheless, due to reasons like sample selection bias [71, 72], the training data used might not accurately reflect the distribution of the real data. Therefore, if the assumption is incorrect, the learnt model may perform poorly on the test data. In the field of AIRTB, addressing erroneous biases has been the main focus of robustness research. Thus, in the following parts, we use the teams 'bias' and 'erroneous bias' interchangeably. Current robust AIRTB research focuses on addressing the following types of erroneous biases: 1) winning price estimation biases, 2) sample selection bias (SSB), and 3) bid shading biases in closed (i.e., censored) first price auctions. Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:15", "4.1 Robustness against Winning Probability Estimation Biases": "In second price auction-based AIRTB, when a bid request is received from the ad exchange, DSPs need to calculate a bid price as the bid response to join the corresponding auction. It is important for DSPs to estimate the winning prices in order to optimize their prices [112]. However, winning price estimation is complicated with the data censorship issue. On the one hand, with second price auction, a DSP only knows the winning price if it wins in the auction. Thus, the winning price observed by each DSP is right-censored: the DSP only knows the winning prices are higher than its bids when it loses the auctions, but not the exact values [112]. Moreover, in second price auctions, if the reserve price of a specific bid request set by the corresponding SSP is higher than the second highest bid price, but lower than the highest one, the winning DSP needs to pay the reserve price for the bid request instead of the market price. In this sense, the winning price observed by each DSP is left-censored: it only knows the upper bound of the market price. Thus, to get an accurate estimation model for winning probability, these biases caused by the data censorship issue must be addressed. Existing methods for mitigating winning probability estimation biases can be divided into three main categories: 1) Tobit-based methods, 2) Kaplan-Meier methods, and 3) auxiliary task-based methods. 4.1.1 Tobit-based Methods. This type of methods explicitly divides the loss functions into two parts, one for the winning records with observable winning prices and the other for the losing records with censored winning prices. These two sub-loss functions are then optimized jointly. Wu et al. [121] first proposed to incorporate the censored regression model [41] into AIRTB to estimate the winning rate for the target DSP on a given bid price. In this work, linear regression is leveraged for bid prices with observable winning prices, and censored regression is leveraged for bid prices with censored winning prices. The maximum likelihood procedure is used to predict the winning probability of a given bid price. Nevertheless, [121] assumes that the winning prices follow a normal distribution, which might not always be true in practice. To address this problem, [130] replaced the normal distribution assumption with the gamma distribution assumption, and developed a gamma-based and regularizationaware censored linear regression model. However, this approach led to further discussions that gamma distributions might also not be realistic. As such, [120] explored multiple distributions and combined them with the deep leaning models to investigate the corresponding prediction qualities. Ghosh et al. [38] relaxed the assumptions on the distribution of winning probability by adopting a mixture density censored network to learn smooth winning price distributions. Apart from the disadvantage caused by the strong assumptions, the aforementioned methods are also unable to estimate the possible ad cost for each specific bid price as they can only perform point estimations of market prices. To address this problem, [38] leverages the improved Censored Regression. To address the same problem, [92] proposed a deep landscape forecasting model taking advantage of recurrent neural networks (RNNs) to model the conditional winning probability with respect to any given bid price flexibly without imposing any assumptions on the underlying distribution. 4.1.2 Kaplan-Meier Methods. Methods falling into this category leverage the Kaplan-Meier estimation approach to address the censored data problem in winning probability estimation. Kaplan-Meier estimation is a well-know survival analysis approach used for forecasting a patient's chance of survival after a certain treatment [31, 39], which is similar to the winning probability estimation task. In [127], the authors analysed the striking similarities between the survival analysis and AIRTB winning probability estimation, and leveraged the non-parametric Kaplan-Meier Product-Limit approach [54] to fit the market price distribution. However, this method relies on 111:16 \u00b7 Tang and Yu the counting-based statistics of given sample clusters, making it unable to accurately predict the winning probability for individual bid requests. To address this problem, [113] proposed to learn the Kaplan-Meier estimation for individual bid requests by predicting two probabilities: 1) the probability of losing a given auction at a certain bid price, and 2) the probability of winning a given auction at a specific market price. In most cases, the sequential patterns shown in the features over the price space turn out to be important for winning probability estimation. The deep landscape forecasting model in [92] combines the survival analysis for dealing with censorship with RNNs to model the sequential patterns for probability distribution forecasting. 4.1.3 Auxiliary Task-based Methods. Yang et al. [124] address the winning probability estimation problem by combining it with the utility estimation problem into a multi-task learning problem. The resulting approach is capable of solving the AIRTB winning probability estimation problem as a multi-category classification task. Despite performance improvement, this model is faced with the problem of tuning hyperparameters, which are used to weight the importance of the winning probability estimation task versus the utility estimation problem. 4.1.4 Evaluation Metrics. The evaluation metrics commonly adopted to measure the robustness of AIRTB winning probability estimation methods are summarized as follows: \u00b7 Mean Squared Error (MSE) : In [113, 121, 130], MSE between the ground truth winning prices and the estimated ones is adopted to evaluate the effectiveness of the proposed methods:  where \ud835\udc41 denotes the number of the data samples. \ud835\udc66 \ud835\udc56 and \u02c6 \ud835\udc66 \ud835\udc56 are the ground truth value and the estimated value of the \ud835\udc56 -th sample, respectively. The smaller the MSE, the better the performance. \u00b7 Mean Absolute Error (MAE) : In [120], MAE is adopted as one of the evaluation metrics:  The smaller the MAE, the better the performance. \u00b7 Log-likelihood (LL) : It is the log of the density function (or the probability):  where \ud835\udc65 \ud835\udc56 is the observed data. \ud835\udc53 denotes the estimation model with parameters \ud835\udf03 . It assesses how likely it is to observe the data using the model. The likelihood that the data are generated by the model increases with the log-likelihood. However, compared with MSE or MAE, log-likelihood performs worse when the values are small. \u00b7 Average Negative Log Probability (ANLP) : It measures the probabilities of the bid requests used for testing occur alongside the corresponding market prices:  \u00b7 Concordance index (C-index) : C-index assesses how accurately a model can order samples based on their market prices. Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:17 \u00b7 Pearson correlation : It is adopted to measure the correlation between the estimated results and the ground truth values, and is defined as:  The larger the correlation, the better the performance. \u00b7 KL-divergence (KL) : KL between the ground truth distribution \ud835\udc5e \ud835\udc4c and the estimated distribution \ud835\udc5e \u02c6 \ud835\udc4c is formulated as:  The smaller the distance, the better the performance. \u00b7 1-Wasserstein distance (WD) : WD between the ground truth distribution \ud835\udc5e \ud835\udc4c and the estimated distribution \ud835\udc5e \u02c6 \ud835\udc4c is formulated as:  The smaller the distance, the better the performance. 4.1.5 Summary. Generally, most AIRTB debiasing methods based on Tobit models tend to be parametric ones, and need to make assumptions on the distributions of the winning probability. Nonparametric methods based on Kaplan-Meier estimation learn the winning probability distribution without making any assumptions. Nevertheless, the majority of the approaches falling into this category need to cluster the data in order to leverage heuristics to boost model accuracy. The clustering operation, to some extent, limits the applicability of these methods to dynamic real world AIRTB data. In addition, methods based on Kaplan-Meier are only able to make coarsegrained predictions using data segments. The latest trend is to frame the winning probability from the perspective of multi-tasking learning by incorporating other auxiliary tasks. However, the performance of such approaches is still sensitive to hyperparameters, and requires tedious parameter tuning. Fig. 5. Illustration of the sample selection bias (SSB) in RTB auction. The training space only contains winning impression data, whereas the inference space includes all full-volume bid request data [124]. Bid Impression Click Lose Win Inference Space P(data) Pre-bid Full-volume Bid Request Data Training Space P(data) Post-bid Winning Impression Data 111:18 \u00b7 Tang and Yu", "4.2 Robustness against Utility Estimation Biases": "AIRTB is faced with the problem of SSB [125], which refers to the systematic mismatch in data distributions between the training space and the inference space [118, 124]. Existing models for AIRTB utility estimation mostly need labeled data for supervised learning. In practice, the labels on whether the users responded or not (e.g., clicks and conversions) and the market prices for bid requests are only available if the advertiser wins in the corresponding auctions [124, 127]. As shown in Figure 5, most existing utility estimation approaches are learned only on clicked samples (including click-through rate, i.e., CTR and conversion rate, i.e., CVR), while drawing conclusions about the entire space with all impression samples. In addition, the clicked samples and the converted samples only account for a small fraction of the impression samples. They are biased due to user actions. Thus, the SSB problem greatly reduces the effectiveness of utility estimation models. Compared with CTR, CVR reflects user preferences more strongly (through subscription of service, registration, installation of software, etc.), and is more relevant to advertisers. Thus, in this part, we focus on AIRTB approaches for addressing SSB in CVR prediction. Existing works for enhancing the robustness of AIRTB against the SSB issue in CVR prediction can be divided into three main categories: 1) Sampling-based Methods, 2) Sequential Pattern-based Methods, and 3) Auxiliary Task-based Methods. 4.2.1 Sampling-based Methods. This type of methods attempt to solve the SSB problem in CVR prediction by leveraging sampling approaches. Through the introduction of sampling, the models trained are pulled to fit the true distribution of the entire space instead of just the training space. In particular, [127] addresses the SSB issue in CVR prediction by using rejection sampling to fit the true underlying distribution from observations. However, this method is susceptible to numerical instability when dividing the rejection probability to weight the samples. 4.2.2 Sequential Pattern-based Methods. When being shown an ad, the potential responses by the target user form a sequence, which is generally in the form of impression \u2192 click \u2192 conversion [70]. Methods used to mitigate SSB in CVR prediction under this category attempt to fully exploit such sequential patterns of user responses. The first such work is [70]. It models CVR with all samples via training two auxiliary tasks (i.e., post-view click-through rate and post-view clickthrough conversion rate). It is extended in [118] by modeling two auxiliary actions (i.e., disjoint purchase-related Deterministic Action (DAction) and Other Action (OAction)), which are injected between click and purchase (i.e., conversion). Wang et al. [115] further considered the problem of delayed feedback and proposed ESDF based on neural networks to model the CVR prediction problem from the entire space perspective through combing the benefit of the time delay factor as well as the user sequential behavior pattern. The CTR prediction task is involved in all these studies, which is the task preceding CVR prediction. Intuitively, representations learned from one task may be helpful for the other [79]. Therefore, [116] takes advantage of the interplay of representation learning across multiple tasks to perform neural architecture search to learn the best connections between task-specific layer-wise representations. The proposed AutoHERI frames the CVR prediction in the entire space with automated hierarchical representation integration. However, all these methods only focus on macro-level behaviors, which help understand subsequent purchase patterns at the granularity of the item level. They overlook the more frequently occuring fine-grained behaviors (e.g., clicks) on detailed elements of items (e.g., user comments, pictures, videos), which are referred to as micro-level behaviors. To some extend, insight into micro-level behaviors can enhance understanding of future macro-level behaviors. As such, [7] applied Purchase-related Micro-behavior Graph (PMG) to describe the users' micro-level behaviors to transform the CVR prediction problem into a graph classification problem. Work [117] extended Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:19 [70] and [118] by constructing the complete user sequential behavior graph, where the micro-level and macro-leve behaviors are hierarchically encapsulated as the one-hop and two-hop post-click nodes in a unified framework, respectively. Inspired by studies used to eliminate bias in recommender systems, [126] frames the SSB problem in CVR prediction from a causal perspective, and accounts for the causes of missing not at random [65]. They proposed two causal estimators for CVR prediction, which adapt the missing not at random mechanism to be trained on a perfect dataset where all exposed items are clicked by users. 4.2.3 Auxiliary Task-based Methods. In [124], all unlabeled data generated by the losing bids are leveraged to estimate CTR to address the SSB issue. They proposed the Multi-task Advertising Estimator (MTAE), a multi-task learning framework for CTR prediction and market price modeling. MTAE takes advantage of the sufficient bid prices of the full-volume bid requests and incorporates the auxiliary task of estimating the winning probability into the model for unbiased learning.", "4.2.4 Evaluation Metrics.": "\u00b7 Area Under Curve (AUC) : This is one of the most widely used metrics for utility estimation model evaluation. It reflects the ranking ability and is formulated as:  where \ud835\udc46 + and \ud835\udc46 -are the positive samples and negative samples, respectively. And |\u00b7| denotes the number of, \ud835\udf19 ( \u00b7 ) and \ud835\udc3c ( \u00b7 ) are the estimation function and the indicator function, respectively. \u00b7 Group Area Under Curve (GAUC) : This metric is computed as follows. Firstly, partition the test data samples into several groups based on the unique user ID. Secondly, calculate the AUC in each group. Then, average the weighted AUC. This process could be formulated as:  where \ud835\udc64 \ud835\udc62 is the weight for user \ud835\udc62 and is set as 1 in utility estimation, and \ud835\udc34\ud835\udc48\ud835\udc36 \ud835\udc62 is user \ud835\udc62 's AUC. \u00b7 F1 Score (F1) : It is formulated as:  where \ud835\udc39\ud835\udc41 , \ud835\udc39\ud835\udc43 , and \ud835\udc47\ud835\udc43 are the number of false negative, false positive and true positive estimations. \u00b7 Mean Squared Error (MSE) : MSE is adoped in [7] to evaluate the effectiveness of their utility estimation function, which is defined in Eq. (1). \u00b7 Negative Log-likelihood : Its formulation is defined as adding a negative symbol to that of Log-likelihood defined in Eq. (3). 4.2.5 Summary. Sampling-based methods are faced with the numerical instability problem when introducing rejection sampling. For those based on sequential patterns of user response actions are concerned, despite performance improvement, the majority of them are still restricted to impression-level inference spaces. In addition, there is a lack of theoretical support about them being unbiased estimators. Similar to Sec. 4.1.5, auxiliary task-based methods face the problem of tuning hyperparameters, which is tedious. 111:20 \u00b7 Tang and Yu", "4.3 Robustness against Bid Shading Biases": "Before 2017, the second-price auction mechanism, in which the winner pays the second highest bid price to the supply side platforms, was the dominant type of AIRTB auction mechanisms. However, almost all the mainstream SSPs and ad exchange networks (e.g., OpenX, Rubicon Project, Pubmatic, Index Exchange, AppNexus) are starting to implement first-price auctions [97, 128]. Two major reasons for moving away from second-price auction are: 1) as the bidders always pay exactly what they bid, first-price auction increases the transparency and accountability for the bidders [16, 37, 93, 94]; and 2) the widely used and favored techniques of Header Bidding are incompatible with the unaltered second-price auction mechanism [5]. DSPs can estimate their potential competitors' bid prices, and take their behaviors into consideration in order to precisely design the optimal bidding strategies in the first-price auction mechanism. If the DSP knows the competitors' bid prices in advance, providing the bid price slightly higher than the highest bid price from all competitors would be the optimal bidding strategy (i.e., winning the corresponding auction with the lowest bid price). However, this is impossible in practice, where the DSP needs to predict the minimum winning price precisely, and attempts to lower their original bid prices which they had set for the second-price auction mechanism, that means shading the true value of the inventory in accordance. Such a process is named as bid shading, which has been utilized in auctions across various industries but is new to online advertising, especially to AIRTB. In first-price auction, the minimum winning price is either the highest bid price submitted by competing advertisers or the floor price. However, whether or not to announce the minimum winning price after the auction is determined by the SSP. If the minimum winning price is announced, the first-price auction mechanism is referred to as open (or non-censored); otherwise, it is referred to as closed (or censored). If the auction is closed, DSPs need to estimate the winning prices. This is similar to winning probability estimation in second-price auction, and is also biased. To the best of our knowledge, only one study [128] deals with the censored problem in firstprice auction-based AIRTB. Specifically, they first utilize the formulation in [83] to formulate the cumulative distribution function of the minimum winning price, enhancing the flexibility to select distributions. Then, they obtain the parameters of the cumulative distribution function through minimizing the loss between the ground truth and the predicted likelihood of winning.", "5 FAIRNESS": "Fairness, which is defined as 'the absence of any prejudice or favoritism towards an individual or a group based on their intrinsic or acquired traits in the context of decision making' [67, 72, 98] is a crucial issue in AIRTB systems. Ad creatives expect the AIRTB system offers fair exposure opportunities to them, avoiding the Matthew effect [64]. Being fair might also attract advertisers of niche ads or items, which can increase the variety and originality of the ads or products in an AIRTB system. From the perspective of the AIRTB ecosystem, fairness is advantageous over the long run. For instance, the unfair trading ecosystem might give more exposure opportunities to advertisers with short-lived popular items, leading to loss of users over time. Similarly, it might provide some niche providers with few impressions. Niche advertisers may have a propensity to leave unfair AIRTB systems as a result of the negative feedbacks, reducing the diversity of ads offered to users. Fairness can help improve users' loyalty to the AIRTB systems. In a nutshell, improving fairness is of vital importance for AIRTB systems. Depending on the focus, fairness can be separated into two main categories: 1) process fairness and 2) outcome fairness [114]. Process fairness (a.k.a. procedural justice [61]) requires fair allocation in the process [61, 76], while outcome fairness (a.k.a. distributive justice [61]) requires fair outcomes as a result of fair allocation [29, 61]. In the following part of this section, we pay more attention to Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:21 outcome fairness as most of the state-of-the-art studies in AIRTB are anchored in this category. Outcome fairness can be achieved in two main ways: 1) grouped by the goal, and 2) grouped by the concept. Depending on the fairness level of the result, outcome fairness can be divided into individual fairness and group fairness. According to the fairness concept, outcome fairness includes various sub-categories, from those that have received much attention (e.g., consistent fairness, calibrated fairness) to those only explored by a small number of works (e.g., maximin-shared fairness, Rawlsian maximin fairness, envy-free fairness, counterfactual fairness). In order to ensure group fairness, two groups of individuals which have distinct sensitive attributes (e.g., gender, age, ethnicity) must statistically experience similar treatments and receive similar outcomes. Fair outcomes for a group of people can be ensured by group fairness. However, at the individual level, discrimination can still occur [26]. Individual fairness requires that outcomes must be equitable for each individual. In some contexts, individual fairness means that similar people should be treated equally [9, 26]. However, there are plenty of alternative ways to define individual-level fairness. In order to be clear, following work [114], we refer to a broader meaning of fairness (i.e., the individual level fairness) as individual fairness. It is worth noting that compared to individual fairness, group fairness is more complicated since there can be multiple divisions and these divisions may evolve over time, allowing one person to be a member of multiple groups at once [35]. In addition, individual fairness in scenarios in which each person belongs to a distinct group can be conceptually viewed as a specific example of group fairness. Unfair practices can ocurr in AIRTB systems. In the following, we first discuss unfairness in AIRTB. Then, we analyse the reasons behind the unfairness in AIRTB. Finally, we discuss existing studies proposed to mitigate unfairness in AIRTB.", "5.1 Unfairness in AIRTB Systems": "Unfairness can occur in AIRTB systems unintentionally and intentionally. For example, [20] shows that men were shown more high-paying job ads than women with comparable profiles. In addition, [59] experimentally demonstrated that STEM (science, technology, engineering and math) job ads, which are designed to be gender neutral, are displayed to fewer women than men across almost all major platforms. For instance, in Facebook, a platform where women make up 52% [109] of the user population and who are more likely to click ads, women are far less likely to be shown such ads than men. The study found that women are a prized demographic, making them more expensive to advertise to. This implies that ads that are meant to be gender-neutral can be delivered in the way that appears to be discriminatory by AIRTB algorithms that focus on optimizing cost-effectiveness. Ali et al. [3] explained that this is not solely the indication of the ingrained cultural bias nor a result of user profiles inputted into ads algorithms, but rather the product of competitive spillovers among advertisers. Apart from users, advertisers can also be unfairly treated during the AIRTB auction process [108]. Recently, several research works have devoted considerable effort to investigate the causes of unfairness in AIRTB. A number of possible explanations have been found. On the one hand, the goal of AIRTB systems is to deliver the right ads to right users at the right time. To achieve such goal, the system creates detailed user profiles and monitors ads performance to learn how users respond to various ads. Based on historical data, subsequent ads can be delivered to targeted to users more precisely. However, during this process, the AIRTB system can unintentionally deliver ads primarily to certain groups of users. This is especially troubling when it comes to employment, housing, and credit related ads because unfairness in these categories can violate certain legislation. On the other hand, market forces and financial optimization strongly influence how ads are delivered, as some user groups are bound to be more valuable than others [27, 60, 69, 95]. Therefore, advertisers on a 111:22 \u00b7 Tang and Yu tight budget are more likely to lose bids for the 'valued' customers. In this case, if the sensitive attributes of these 'valued' customers belong to the protected classes, this can result in unfair ad delivery, even if the advertisers may not intend to exclude these customers.", "5.2 Enhancing Fairness in AIRTB Systems": "Fig. 6. Summary of methods used to ensure fairness in the RTB. * indicates that the method ensures fairness by formulating the fairness requirements as the constraints on the direct objective of maximizing the stakeholders' revenue. ** indicates that the method takes optimizing fairness as the direct objective. For advertisers Fairness For users Method Strategy Fairness notions Group fairness Individual fairness [ 109 ] Regulating Online Political Advertising \u2713 Designed by the entire system [ 14 ] * \u2713 [ 57 ] * \u2713 [ 88 ] * \u2713 [ 17 ] * \u2713 [ 49 ] ** \u2713 Designed by advertisers [ 78 ] * \u2713 [ 36 ] * \u2713 Fig. 6 summarizes the methods used to mitigate unfairness in AIRTB systems. Existing studies can be divided into two categories: 1) for advertisers, and 2) for users. The first category focuses on mitigating ad exchange networks' unfair favor for certain groups of advertisers. The second category focuses on fulfilling restrictions on the percentage of ad impressions that must reach particular groups of users belonging to certain demographics to enhance fair treatment of users. 5.2.1 Fairness for Advertisers. As there can be many advertisers connected to a specific ad exchange network, it is critical for the network to decide on which groups of advertisers to send bid requests to and how to choose winners for bid requests fairly in order to maximize its profit and build trust with advertisers. In [108], it has been suggested that this goal can be achieved through basic modifications to the ad auction mechanism that the ad exchange network uses. However, this work focuses on providing theoretical models for regulating online ad auctions instead of mitigating unfairness. Enhancing fairness is just one of the aspects studied. As such, whether such intervention works in existing AIRTB systems still needs to be validated. 5.2.2 Fairness for Users. Works falling into this category can be further divided into two groups: 1) methods designed by the entire system, and 2) methods designed by the advertisers. Methods designed by the entire system. To prevent discriminatory advertisements with respect to sensitive attributes, [14] proposed an optimization-based ad auction framework based on Myerson auction [75], which maximizes the revenue of the ecosystem conditioned on constraints that preclude the development of unintentional discrimination. The constraints can be any notion of group fairness described in [15]. Works [56, 87] extended [14] by adapting it into different auction frameworks and capturing requirements of fairness from data, respectively. Celis et al. [14] focuses on solving the optimization problem formulated based on algorithmic fairness, while [17] Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:23 focuses on comparing its performance with the unfair optimum and studying the cost of achieving fairness. It is an individual fairness approach (i.e., any two individuals must obtain additively similar allocations from each advertiser if they have been given multiplicatively similar values by all the advertisers). They follow the idea of [47] and exam how auction design affects outcome fairness with the assumption that bids of each advertiser are accepted without discrimination. Afterwards, they adopt the Inverse Proportional Allocation algorithm to balance social welfare and fairness for a wide-range of value stability conditions. Apart from these methods which focus on algorithms design, [48] proposed to adopt auditing to cope with group unfairness based on user features. However, this method depends greatly on human intervention and incurs high costs. Methods designed by advertisers. Works under this category attempt to design bidding and targeting strategies that rectify the unfairness introduced by the AIRTB system from the perspective of the advertisers. In [77], the authors designed bidding strategies for advertisers to achieve impression parity across various demographic groups. Similarly, in [36], the authors designed targeting strategies for achieving parity in outcomes or conversions across different user groups. In both approaches, the requirement of group fairness is formulated as the constraint on the main objective of maximizing advertisers' revenues.", "5.3 Evaluation Metrics": "Statistical significance has been adopted to measure AIRTB fairness [48]. Specifically, the percentages of people belong to different gender groups seeing two different ads are calculated. Then, the Z-test with a 95% confidence level is performed to measure the statistical significance of the difference between these two groups.", "5.4 Summary": "It can be observed from Fig. 6 that research on fair AIRTB techniques is still in its infancy. Existing works mostly focus on group fairness, while only two focusing on individual fairness [17, 108]. Most of them formulate the fairness requirements as the constraints on the main objective function, with only one taking fairness as the goal [48].", "6 PROMISING FUTURE RESEARCH DIRECTIONS": "There are many areas where exciting new research can be carried out towards building a trustworthy AIRTB ecosystem. As shown in Table 2, existing studies on trustworthy AIRTB focus on the security, robustness and fairness dimensions of trustworthy AI, leaving other dimensions such as accountability and explainability less well explored. In addition, there is still plenty of room for improvement for research on the security, robustness and fairness dimensions. In this section, we discuss promising future directions for this emerging interdisciplinary field.", "6.1 Security": "6.1.1 Demand for Transparency. One problem of AIRTB systems is that it is difficult for the advertisers to acquire information about the sources of the traffics, leaving room for ad fraud and ad injection. Typically, most participants may be hesitant to disclose the specifics of the approaches and techniques used for combating ad frauds. Since the advertisers are the sources of revenue and the foundation of the value chain for AIRTB systems, they have great incentive to help maintain the sustainability of the ecosystem. Therefore, techniques to help them more transparently assess the effectiveness of their ad campaigns and advertising strategies while guarding against ad frauds are desirable. 111:24 \u00b7 Tang and Yu 6.1.2 Trade-offs between Stakeholders. Table 2 lists the security requirements of various stakeholders of AIRTB. It can be observed that security requirements by different stakeholders may conflict. For instance, driven by profit, publishers may be tempted to generate fraudulent ad traffics, which contradicts with advertisers' requirements for a fraud free AIRTB system. To build the trustworthy AIRTB system, it is crucial to satisfy security the requirements by different stakeholders simultaneously. The research problem of striking the right balance among multiple AIRTB stakeholders' security requirements in a cost-effective manner remains open.", "6.2 Robustness": "6.2.1 Standardizing Evaluation Metrics. To evaluate the effectiveness of methods enhancing the robustness of AIRTB systems, most existing works adopt MSE, ANLP and other conventional metrics which are designed to assess ranking performance. However, as shown in [18], these metrics may not be well-suited for evaluating robustness. Furthermore, since different works perform evaluation following different metrics, the results are reported inconsistently. In order to objectively compare the performance of different approaches in this area of research, more suitable and standardized evaluation metrics need to be proposed. 6.2.2 Balancing Requirements from Various Stakeholders. As shown in Table 2, existing studies focus on satisfying the robustness requirements from the advertisers. As far as the publishers are concerned, in order for them to build trust with the AIRTB system, they also need to build unbiased models to optimally calculate the reserve price based on the historical auction records. It would be useful for future research to look into this area in order to serve the robustness needs of the publishers well. 6.2.3 Leveraging Auxiliary Information. Taking advantage of the wealth of auxiliary information in AIRTB systems can enhance its robustness. There have been a few works in recent years showing that biases in recommender systems can be corrected by using user or item attributes. Since the ads, advertisers, publishers and users all possess auxiliary information, investigations on how to leverage such information to enhance the robustness of AIRTB systems can be worthwhile. 6.2.4 Reasoning. Causal graphs among the stakeholders can be useful for enhancing the robustness of AIRTB systems. Reasoning about the occurrence and effect of bias are keys for debiasing. Causal graphs can provide a new source of information for this purpose. As such, building new reasoning techniques to leverage causal graphs in AIRTB to enhance its robustness against biases can be a promising future research direction.", "6.3 Fairness": "6.3.1 New Evaluation Metrics. As shown in Section 5, there is only one fairness metric used by existing studies in AIRTB. Compared to the diverse notions of fairness studied in this field, this is inadequate. As such, new research on designing proper evaluation metrics to compare the fairness of AIRTB approaches is required. 6.3.2 New Benchmarking Datasets. Existing methods tend to evaluate their methods using datasets collected by themselves from various advertising platforms, making it impossible to compare the performance in a standardized manner. There is a lack of public benchmarking datasets to study the fairness related approaches for AIRTB systems. This gap needs to be bridged in order for this field to be further advanced in a sustainable way. 6.3.3 Tradeoff between Fairness and Performance. In most cases, improving fairness means the loss in performance in machine learning. For example, in the field of recommender systems, the tradeoff Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:25 between recommendation accuracy and fairness has been well studied [114]. However, fairness is not necessarily at odds with performance in well-designed systems. Particularly, in studies related to classification tasks [58], it is reported that increasing fairness may result in accuracy improvement. Therefore, investigating how to enhance fairness while maintaining performance for various stakeholders is crucial for successfully implementing fairness strategies in AIRTB systems. 6.3.4 Multi-Faceted Fairness. Most of existing works focus on achieving just one notion of fairness and corresponding goals in AIRTB. However, as there are multiple fairness notions [34, 84] and multiple stakeholders involved in AIRTB systems, it is useful to study how multi-faceted fairness can be achieved. 6.3.5 Causal Inference for Fairness. An emerging area of research in machine learning is on reducing unfairness through causal inference [57, 122]. However, to our best knowledge, there is no study on fairness in AIRTB. Bridging this gap can lead to innovative new capabilities in the AIRTB system, enhancing its fairness in an interpretable manner.", "6.4 Accountability": "It is well-known that AIRTB systems have various drawbacks. Among them, the most noticeable one is that it can be challenging for the advertisers, publishers, DSPs and SSPs to assess their benefits derived from joining the auctions. For example, it is difficult for the advertisers to acquire information about the sources of ad traffics, leaving room for frauds and backroom deals. As such, it is necessary to design accountable and verifiable auction mechanisms to build trust with various stakeholders.", "7 CONCLUSIONS": "This paper provides a comprehensive review of the trustworthy AIRTB literature. To our best knowledge, this is the only survey on this emerging interdisciplinary area. We proposed a multitiered taxonomy to analyse trustworthy AIRTB works focusing on security, robustness and fairness. Under each topic, we summarize the challenges faced, the key approaches taken as well as the main evaluation metrics adopted to experimentally measure their performance in order to support longterm sustainability of this field. Finally, we suggest some promising future research directions that can help enhance trustworthiness of AIRTB systems. For this field to move forward, collaboration among researchers and industry practitioners is key. We hope that this survey can serve as a useful roadmap towards building trustworthy AIRTB systems of the future.", "ACKNOWLEDGMENTS": "This research is supported by the National Research Foundation, Singapore under its AI Singapore Programme (AISG Award No: AISG2-RP-2020-019); the Joint NTU-WeBank Research Centre on Fintech (Award No: NWJ-2020-008); the Nanyang Assistant Professorship (NAP); the RIE 2020 Advanced Manufacturing and Engineering (AME) Programmatic Fund (No. A20G8b0102), Singapore; and Future Communications Research & Development Programme (FCP-NTU-RG-2021-014). Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of National Research Foundation, Singapore.", "REFERENCES": "[1] 2012. Knowing your enemy: understanding and detecting malicious web advertising. In CSS . 674-686. [2] Iroshan Aberathne and Chamila Walgampaya. 2018. Smart mobile bot detection through behavioral analysis. In ICIIT . 241-252. [3] Muhammad Ali, Piotr Sapiezynski, Miranda Bogen, Aleksandra Korolova, Alan Mislove, and Aaron Rieke. 2019. Discrimination through optimization: How Facebook's Ad delivery can lead to biased outcomes. Proceedings of the ACM on human-computer interaction 3, CSCW (2019), 1-30. [4] Vinod Anupam, Alain Mayer, Kobbi Nissim, Benny Pinkas, and Michael K Reiter. 1999. On the security of pay-per-click and other web advertising schemes. Computer Networks 31, 11-16 (1999), 1091-1100. [5] B. Hovaness. 2018. Sold for more than you should have paid . Retrieved Jun 01, 2022 from https://www.heartsscience.com/sold-for-more-than-you-should-have-paid/ [6] Anup Badhe. 2017. Click fraud detection in mobile ads served in programmatic inventory. Neural Networks & Machine Learning 1, 1 (2017), 1-1. [7] Wentian Bao, Hong Wen, Sha Li, Xiao-Yang Liu, Quan Lin, and Keping Yang. 2020. Gmcm: Graph-based micro-behavior conversion model for post-click conversion rate estimation. In SIGIR . 2201-2210. [8] Daniel Berrar. 2016. Learning from automatically labeled data: case study on click fraud prediction. Knowledge and Information Systems 46, 2 (2016), 477-490. Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:31 111:32 \u00b7 Tang and Yu Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:33 111:34 \u00b7 Tang and Yu Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:35", "111:26 \u00b7 Tang and Yu": "Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:27", "111:28 \u00b7 Tang and Yu": "Towards Trustworthy AI-Empowered Real-Time Bidding for Online Advertisement Auctioning \u00b7 111:29 111:30 \u00b7 Tang and Yu [114] Yifan Wang, Weizhi Ma, Min Zhang, Yiqun Liu, and Shaoping Ma. 2022. A Survey on the Fairness of Recommender Systems. arXiv:2206.03761 (2022). [115] Yanshi Wang, Jie Zhang, Qing Da, and Anxiang Zeng. 2020. Delayed feedback modeling for the entire space conversion rate prediction. arXiv:2011.11826 (2020). [116] Penghui Wei, Weimin Zhang, Zixuan Xu, Shaoguo Liu, Kuang-chih Lee, and Bo Zheng. 2021. AutoHERI: Automated Hierarchical Representation Integration for Post-Click Conversion Rate Estimation. In CIKM . 3528-3532. [117] Hong Wen, Jing Zhang, Fuyu Lv, Wentian Bao, Tianyi Wang, and Zulong Chen. 2021. Hierarchically modeling micro and macro behaviors via multi-task learning for conversion rate prediction. In SIGIR . 2187-2191. [118] Hong Wen, Jing Zhang, Yuan Wang, Fuyu Lv, Wentian Bao, Quan Lin, and Keping Yang. 2020. Entire space multi-task modeling via post-click behavior decomposition for conversion rate prediction. In SIGIR . 2377-2386. [119] David H Wolpert and William G Macready. 1997. No free lunch theorems for optimization. IEEE transactions on evolutionary computation 1, 1 (1997), 67-82. [120] Wush Wu, Mi-Yen Yeh, and Ming-Syan Chen. 2018. Deep censored learning of the winning price in the real time bidding. In KDD . 2526-2535. [121] Wush Chi-Hsuan Wu, Mi-Yen Yeh, and Ming-Syan Chen. 2015. Predicting winning price in real time bidding with censored data. In KDD . 1305-1314. [122] Yongkai Wu, Lu Zhang, and Xintao Wu. 2019. Counterfactual fairness: Unidentification, bound and algorithm. In IJCAI . 1438-1444. [123] Haitao Xu, Daiping Liu, Aaron Koehl, Haining Wang, and Angelos Stavrou. 2014. Click fraud detection on the advertiser side. In ESORICS . 419-438. [124] Haizhi Yang, Tengyun Wang, Xiaoli Tang, Qianyu Li, Yueyue Shi, Siyu Jiang, Han Yu, and Hengjie Song. 2021. Multi-task Learning for Bias-Free Joint CTR Prediction and Market Price Modeling in Online Advertising. In CIKM . 2291-2300. [125] Bianca Zadrozny. 2004. Learning and evaluating classifiers under sample selection bias. In ICML . 114. [126] Wenhao Zhang, Wentian Bao, Xiao-Yang Liu, Keping Yang, Quan Lin, Hong Wen, and Ramin Ramezani. 2020. Large-scale causal approaches to debiasing post-click conversion rate estimation with multi-task learning. In WWW . 2775-2781. [127] Weinan Zhang, Tianxiong Zhou, Jun Wang, and Jian Xu. 2016. Bid-aware gradient descent for unbiased learning with censored data in display advertising. In KDD . 665-674. [128] Tian Zhou, Hao He, Shengjun Pan, Niklas Karlsson, Bharatbhushan Shetty, Brendan Kitts, Djordje Gligorijevic, San Gultekin, Tingyu Mao, Junwei Pan, et al. 2021. An efficient deep distribution network for bid shading in first-price auctions. In KDD . 3996-4004. [129] Shitong Zhu, Xunchao Hu, Zhiyun Qian, Zubair Shafiq, and Heng Yin. 2018. Measuring and disrupting anti-adblockers using differential execution analysis. In NDSS . 1-15. [130] Wen-Yuan Zhu, Wen-Yueh Shih, Ying-Hsuan Lee, Wen-Chih Peng, and Jiun-Long Huang. 2017. A gamma-based regression for winning price estimation in real-time bidding advertising. In Big Data . 1610-1619. [131] Xingquan Zhu, Haicheng Tao, Zhiang Wu, Jie Cao, Kristopher Kalish, and Jeremy Kayne. 2017. Fraud prevention in online digital advertising . Springer."}
