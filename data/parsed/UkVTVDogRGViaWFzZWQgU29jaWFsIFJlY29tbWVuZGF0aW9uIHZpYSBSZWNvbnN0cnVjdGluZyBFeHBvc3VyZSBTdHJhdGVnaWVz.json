{
  "REST: Debiased Social Recommendation via Reconstructing Exposure Strategies": "Ruichu Cai glyph[star] , Member, IEEE, Fengzhu Wu, Zijian Li, Jie Qiao, Wei Chen, Yuexing Hao, Hao Gu Abstract -The recommendation system, relying on historical observational data to model the complex relationships among the users and items, has achieved great success in real-world applications. Selection bias is one of the most important issues of the existing observational data based approaches, which is actually caused by multiple types of unobserved exposure strategies (e.g. promotions and holiday effects). Though various methods have been proposed to address this problem, they are mainly relying on the implicit debiasing techniques but not explicitly modeling the unobserved exposure strategies. By explicitly Reconstructing Exposure STrategies (REST in short), we formalize the recommendation problem as the counterfactual reasoning and propose the debiased social recommendation method. In REST, we assume that the exposure of an item is controlled by the latent exposure strategies, the user, and the item. Based on the above generation process, we first provide the theoretical guarantee of our method via identification analysis. Second, we employ a variational auto-encoder to reconstruct the latent exposure strategies, with the help of the social networks and the items. Third, we devise a counterfactual reasoning based recommendation algorithm by leveraging the recovered exposure strategies. Experiments on four real-world datasets, including three published datasets and one private WeChat Official Account dataset, demonstrate significant improvements over several state-of-the-art methods. Index Terms -Recommendation System, Social Recommendation System, Causal Effect, Variational Auto-Encoder",
  "I. INTRODUCTION": "Recommendation system [1]-[5] is an important techniques in the world. It has been used for a wide range of applications such as e-commerce [6], [7], search engines [8], [9] and eresource services platforms [10]. Recently, the data driven recommendation systems, which use historical data to model the Ruichu Cai is with the School of Computer Science, Guangdong University of Technology, Guangzhou, China, 510006 and Peng Cheng Laboratory, Shenzhen, China, 518066. E-mail: cairuichu@gmail.com Fengzhu Wu is with the School of Computer, Guangdong University of Technology, Guangzhou China, 510006. E-mail: fzwu97@gmail.com Zijian Li is with the School of Computer, Guangdong University of Technology, Guangzhou China, 510006. E-mail: leizigin@gmail.com Jie Qiao is with the School of Computer Science, Guangdong University of Technology, Guangzhou, China, 510006. E-mail: qiaojie.chn@qq.com Wei Chen is with the School of Computer Science, Guangdong University of Technology, Guangzhou, China, 510006 and Peng Cheng Laboratory, Shenzhen, China, 518066. E-mail: chenweidelight@gmail.com Yuexing Hao is with Tufts University. E-mail: yhao02@tufts.edu Hao Gu is with Tencent Technology (SZ) Co., Ltd. E-mail: nickgu@tencent.com Manuscript received XX; revised XX; accepted XX. Date of publication XX XX, 2019; date of current version XX XX, 2019. This research was supported in part by National Key R&D Program of China (2021ZD0111501), National Science Fund for Excellent Young Scholars (6212200101) and Natural Science Foundation of China (61876043, 61976052). Wei Chen was supported by China Postdoctoral Science Foundation (2021M690734). (*Ruichu Cai is the Corresponding author.) complex relationships among users and items, have achieved a huge success and become mainstream [11]-[14]. Selection bias is one of the key issues to the success of the data driven recommendation systems [15]-[17]. Because the historical data are collected under multiple types of exposure strategies and seriously biased. Give an example in the information flow application, on the one hand, the items recommended by the system will get a high chance to expose and further results in the bias of the collected historical data; on the other hand, users usually prefer to watch and rate the popular videos/news such that the recommended strategies will capture the trending videos/news and further increase the exposures. Such bias of the historical data will lead to overestimate or underestimate the performance of the trained recommendation systems, harm the performance of the deployed recommendation systems and even result in the wellknown negative phenomenon named Information Cocoons [18]. To tackle the aforementioned selection bias problem, many researchers raise several debiased recommendation algorithms [19]-[21]. One of the mainstream approaches is the inverse propensity weighting (IPW) based methods [22], e.g., the Empirical Risk Minimization framework [20] and the CausE method [23]. Recently, Feng et.al [24]-[26] employ the concept of causal effect to address the selection bias challenge. By viewing the exposed items ( v ) behind the dataset as the common cause to the exposure ( e ) and the rating level ( r ), we can rephrase the existing methods into the causal graph in Figure 1(b). This figure further explicitly models the user preference, i.e., the user preference will increase the exposure due to the recommended strategies and the rating level based on the user preference. According to the aforementioned debiased methods, we can easily find that the core of them is to remove the effect of exposure and to estimate the outcome of rate level if item v is exposed to user u . However, in a large range of historical data, different exposure strategies could change dramatically because the recommendation systems always try to capture the popular trending items or the changing user preference. Take Figure 1(a) as an example, a dataset is a collection of observations over a number of different promotions strategies, such as Baby's Day, Valentine's Day, Black Friday, and seasonal offer. Such several types of strategies would render the existing debiased methods fail as they assume a stationary exposure strategy. Furthermore, the strategies are usually independent of the user preference and the item properties, but ignoring the changing strategies will entangle the information of strategies with the users and items, which further leads to bias results. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, SUBMITTED 2 Baby's Day Valentine ' s Day (a) The historical data are collected by different strategies. (b) The common causal graph of the existing methods. (c) REST: The introduction of strategy variables. (d) REST: The introduction of social networks to reconstruct strategy and user variables. Fig. 1. (a) The historical data are collected under different strategies, such as the promotion in Black Friday and the Valentine's Day Gift Shop. (b) The common causal graph of the existing methods, in which implicitly leverage the stationary strategy assumption. (c)(d) are the causal generation process of the proposed method. (c) The causal graph that takes the latent strategy variables into account. (d) In order to address the counterfactual problem in recommendation, we bring the social networks into the causal generation process, where the user variables are latent due to the complexity of the aggregation process of social networks. Please note that the stationary exposure strategy assumption can be equivalently viewed as the stationary propensity score over time. For example, applying the stationary exposure strategy assumption for reweighting-based methods equals providing the same sample weights for the flowers on Valentine's Day and Baby's Day, which is obviously unreasonable. In order to address this challenge, one straightforward solution is to take the exposure strategies into account. Hence we can obtain the revised causal graph shown in Figure 1(c), in which strategies not only affect the exposure variables but also the rate level. the user latent variables and the exposure strategy latent variables. Extensive experimental studies demonstrate that the proposed REST method outperforms the state-of-the-art recommendation methods (including the latest methods based on causal effect.) on three published datasets and one realworld WeChat official accounts dataset. Given the causal graph shown in Figure 1(c), the recommendation task can be seen as a counterfactual question that What the rate level r would be if an item v is exposed to a user u under strategy s ? This question is hard to answer since we can only obtain the rate level from the exposed dataset. This difficulty can be solved if we can find a similar user who has given the rate level for the same item. But how to find such a similar user is another nontrivial task with the assumption that each user is independent unless the social networks (or local neighbors) are taken into consideration. So we further propose another revised causal graph as shown in Figure 1(d). It is noted that we let the user variables be latent when taking the social networks into account. This is because the interests of users are influenced by their neighbors, so the user variables become an aggregation of neighbors' information and are too complex to be explicitly described. Based on the causal graph shown in Figure 1(d), we provide a practical approach for debiased recommendation R econstructing E xposure ST rategies (REST in short.) by modeling different strategies behind observed data. First, we assume that the data generative process of recommendation follows the causal graph shown in Figure 1(d). Second, We summarize the problem of the recommendation systems as the counterfactual reasoning problem and provide the identification analysis for theoretical guarantee. Third, based on this causal generative process, we devise a variational-based counterfactual reasoning method to successively reconstruct The rest of the paper is organized as follows. Section II reviews existing studies on recommendation systems, including social recommendation systems, causality-based recommendation systems as well as recommendation systems using a generative model. In section III, we expound the causal generation process under latent strategies and social networks. We also elaborate on the details about how to model the aforementioned causal generation process and how to implement the proposed model in section IV. Section V presents the experiment results on four real-world datasets, including ablation analysis and the visualization. Section VI concludes the paper.",
  "II. RELATED WORKS": "Our work is closely related to the recommendation systems in causal view, the social recommendation systems and the recommendation systems that are related to generative models. In this section, we review the works on these three kinds of recommendation systems. In order to address the problem of selection bias, many researchers borrow the ideas of causal inference [22], [27]. Sharma et al. [28] estimate the causal effect of recommendation system from observed data. Schnabel et al. [20] estimate the quality of a recommendation system with the help of the propensity-weighting method which is commonly used in causal inference. Aiming to learn to rank with biased data with click propensities, Ai et al. [29] propose the Dual Learning Algorithm that combines an unbiased ranker and an unbiased propensity model. Bonner et al. [23] propose the CausE that is optimized with biased logged data and predicts recommendation results under random exposure. Considering that the missing rating in a recommendation system is usually IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, SUBMITTED 3 missing not at random, Wang et al. [30] propose a doubly robust estimator for recommendation and further derive the tail bound of the estimator. Recently, Wang et al. [31] take the unexposed user-item pairs as the counterfactual samples, and propose the counterfactual variational information bottleneck. Motivated from the counterfactual propensity-weighting approach from causal inference, Xu et al. [32] address the unbiassed recommendation problem by using a minimax empirical risk formulation. However, the aforementioned methods ignore that the historical logged data are collected under different strategies and these strategies are the reasons that lead to selection biases. Moreover, the aforementioned methods implicitly assume that the exposure strategies are stationary and this assumption is usually too strong. In this paper, we address the selection biases problems in the recommendation by modeling the exposure strategies by combining the social networks with the causal generative process of rate level. For the social recommendation, one of the goals of recommendation is to learn a better user variables, hence more and more researchers leverage the relationships among users with the consideration of the homophily in the social network. Jamali et al. [14] combine matrix factorization with the mechanism of trust propagation of social networks in order to address the problems brought by the cold-start users. Following the intuition that personal behaviors are affected by a person's social network, Ma et al. [33] propose SoRec, which learns the user latent feature space and item latent feature space by employing the social networks and the user-item matrix simultaneously. In order to address the data sparsity and cold-start problem, Yang et al. [34] propose TrustMF, which employs matrix factorization technique to map users into low-dimensional latent feature spaces in terms of their trust relationship. With the widespread use of deep learning, many researchers make use of neural networks to improve recommendation algorithm. Considering that the current recommendation largely relies on the initialization of the user and item latent feature vectors, Deng et al. [35] use deep learning to determinate the initialization in the matrix factorization for the social recommendation. Considering that the users behave and interact differently in social networks and useritem bipartite graphs, Fan et al. [36] raise DASO, which adopts a bidirectional mapping method to transfer users' information between social domain and item domain. In this paper, since both the user variables and the strategies variables are latent, it is hard to reconstruct them at the same time. Hence we introduce the social networks to reconstruct the user embedding first, then leverage it to reconstruct the strategies variables. Other researchers borrow the idea of generative models. Zhou et al. [37] extend the flow-based generative model [38] to CF for modeling implicit feedback. And Liang et al. [39] combine multinomial likelihoods with collaborative filtering and extend variational auto-encoders [40] to collaborative filtering for implicit feedback. Liu et al. [41] consider both local and global structures among users under the Wasserstein auto-encoder frameworks. Recently, graph neural networks attract more and more attention, so some researchers combine the generative models and the graph neural networks. Yu et TABLE I NOTATIONS AND DESCRIPTIONS. al. [42] propose a deep adversarial framework based on graph convolutional networks to address the problem of the sparsity of user-item relation and the noisy social relations. In this work, we bring the strategies variables into the structural causal model and tackle the recommendation problem as a counterfactual problem. We follow the paradigm of variational auto-encoders [40] to instantiate the proposed REST method.",
  "III. IDENTIFICATION OF DEBIASED RECOMMENDATION": "",
  "A. Notations": "We first introduce the notations in this paper. Let U and V denote the sets of users and items respectively. We further let E and R denote the exposure matrix and the rate level matrix defined over U ∪ V . e uv is an element of E , with e uv = 1 denotes that the item v is exposed to the user u and e uv = 0 denotes that the item v is not exposed to the u . r uv is an element of R , which denotes the rate level of u on v . Hence we let T = { < u, v, r uv > | e uv = 1 } and O = { < u, v, r uv > | e uv = 0 } be the exposed set and unexposed set respectively. In the social recommendation context, a social networks G is associated with the user set U . With the abuse of notation, we also let u , v be the embedding of the corresponding entities and ignore the subscripts of e uv and r uv . The mathematical notations used in this paper are summarized in Table I.",
  "B. Causal Generation Process under Exposure Strategies and Social Networks": "Based on the aforementioned notation description, we consider the causal graph to model the recommendation procedure. As shown in Figure 1(d), the causal graph contains six variables: G,u,e, s, v , and r . In particular, we let: · G → u denotes how the social networks affect the interests of users. · u, v, s → e denotes that whether an item will be recommended depends on u, v and s . IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, SUBMITTED 4 · u, e, v, s → r denotes that the exposure of item v to user u not only depends on u and v but also depends on the exposure strategies s . Please note that our causal model (Figure 1(d)) is different from the existing debiased method (Figure 1(b)) from the following two aspects: 1) our model further takes the s into consideration. 2) our model takes u as latent variables and employs G as the surrogate of u . This causal mechanism provides us a way to infer the latent variables s , because G (similarly for v ) and s are dependent on each other conditioning on e . In other words, G and v provide us the clues to infer the latent exposure strategies. C. Social Recommendation as a Problem of Counterfactual Reasoning Based on the aforementioned descriptions, we provide the definition of the social recommendation. We first let T ′ be the training set extracted from the exposed set, e.g., T ′ ⊆ T . Given the social networks G , the training set T ′ and the strategy variables s , the goal of the social recommendation is to obtain a model that can estimate the following conditional distribution:  in which < u,v,r > is extracted from the unexposed set, e.g. < u,v,r > ∈ O . Note that the sample < u,v,r > is extracted from the unexposed set but given e = 1 , meaning that a user u has never been exposed to an item v . And estimating the aforementioned conditional distribution equals to answer the following question: What the rate level r would be if an item v is exposed to a user u given exposure strategy s and social networks G ? Therefore, according to the theory of counterfactual inference [43], we can find that designing a social recommendation system is a counterfactual problem. D. Identifying Unbiased Prediction of Social Recommendation System Following the causal view of the recommendation systems, the goal of our social recommendation is to estimate the conditional distribution P ( r | G,u,v,do ( e = 1)) according to the do -calculus [43]. The identification of such a counterfactual model is an immediate result of Pearl's back-door criteria, as shown in Theorem 1. Theorem 1. (Identification of Social Recommendation) Suppose that the joint distribution P ( G,e, r, v, s ) is recovered, the counterfactual prediction is identifiable under the causal model in Figure 1(d). Proof. We prove that P ( r | G,v,do ( e =1)) is identifiable under the premise of the theorem with the help of Equation (2).  where the second equality is based on the rule of do-calculus and conditional independent property under Figure 1(d) [43]. Essentially, we now can predict intervention based on the recovered join distribution P ( G,e, r, v, s ) , which finishes the proof. Please note that the aforementioned identification theorem of social recommendation shows that we can estimate the conditional distribution in Equation (1) with the help of social networks and the data extracted from the exposed set T .",
  "IV. ALGORITHM AND IMPLEMENT": "According to the causal graph shown in Figure 1(d), we devise a variational auto-encoders based framework. We begin with the likelihood of the samples to derive the evidence lower bound (ELBO) of the model. Essentially, the logarithm of joint likelihood ln P ( G,e, r, v ) can be written as follows:  in which the second and third lines are the KL divergence between the approximate distributions and the true posteriors. And L ELBO is the variational lower bound, which can be derived as follows: (See more details in Supplementary.)  where Q ( u | G,e, r, v ) and Q ( s | e, r, v, u ) are the approximate functions that are also respectively named user latent variables encoder and the latent strategies variables encoder . These two encoders are used to approximate the two true posteriors: P ( u | G,e, r, v ) and P ( s | e, r, v, u ) . And we further let P ( G | u ) , P ( e | v, u, s ) and P ( r | u, v, e ) denote the social networks reconstruction , the exposure reconstruction and the rating level prediction , respectively. To further facilitate the learning of the model, we assume that the latent user variables follows the delta distribution and the latent strategies variables s follows the categorical distribution. Since these two priors are also consistent with the real-world recommendation systems. Given the item variables v , P ( v ) is a constant. Moreover, since we assume that P ( u | G,e, r, v ) is a delta distribution, the value of D KL ( Q ( u | G,e, r, v ) || P ( u )) is equal to 0 , the proof is provided in the Proposition 1. Proposition 1. (KL-Divergence under Delta Distribution Assumption) KL-divergence D KL ( Q ∗ ( u | G,e, r, v ) ‖ P ( u )) is zero if P ( u ) is a delta distribution with the optimal parameters Q ∗ = arg max Q L . glyph[negationslash] glyph[negationslash] Proof. We proof by contradiction. First, we suppose that D KL ( Q ∗ ( u | G,e, r, v ) ‖ P ( u )) = 0 . Then, given the delta distribution P ( u ) , there must exist an instance u such that Q ∗ ( u | G,e, r, v ) = 0 , P ( u ) = 0 . It follows that IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, SUBMITTED 5",
  "(a) Inference Phase": "",
  "(b) Generation Phase": "Fig. 2. The illustration of the framework of the proposed REST Model. (a) The inference phase contains the Latent User Variable Encoder and the Bias Encoder, which are used to reconstruct the user variables and the strategy variables respectively. (b) The generation phase contains the rate level reconstruction, the social network reconstruction and the exposure reconstruction, which are used to respectively reconstruct the observed rating values, social structures and the exposed variables. In the test step, we only employ the rate level reconstruction for prediction. User Latent Variables Encoder Latent Strategy Variables Encoder 𝑒, 𝑟, 𝑣 𝐺 𝑢 𝑄(𝑢|𝐺, 𝑒, 𝑟, 𝑣) 𝑄(𝒔|𝑢, 𝑒, 𝑟, 𝑣) Social Network Reconstruction Exposure Reconstruction Rate Level Reconstruction 𝑒, 𝑣 𝑣 𝑄(𝑢|𝐺, 𝑒, 𝑟, 𝑣) 𝑄(𝒔|𝑢, 𝑒, 𝑟, 𝑣) 𝑃(𝑒|𝑣, 𝑢, 𝒔) 𝑃(𝑟|𝑢, 𝑣, 𝑒, 𝒔) 𝑃(𝐺|𝑢) KL ( Q ∗ ( u | G,e, r, v ) ‖ P ( u )) → ∞ leading to an underoptimized score L → -∞ which is a contradiction. ⌉∫ ( Combing Proposition 1 and Equation (4), we can reformulate the objective function of the proposed REST model as follows: ⌉ ( ⌉∏ [) ⌉} )Æ ⌉ ∥⊕ ]√)Æ ⌉⊗ )Æ {GLYPH<142> 〉Π {GLYPH<142> 〉GLYPH<204> ⌉ 〉 ( {GLYPH<142> 〉Π ⌈∫ {GLYPH<142> 〉GLYPH<230> )GLYPH<226> ⌉ 〉Ω 〉 ( ⌉ 〉 ( {GLYPH<142> 〉Π ⌈∫ {GLYPH<142> 〉GLYPH<230> )GLYPH<226> ⌉ 〉Ω 〉 ( ⌉ ⌉ ( ⌉∏ [) ⌉} )Æ ⌉ ∥⊕ ]√)Æ ⌉⊗ )Æ  According to the objective function shown in Equation (5), we can find that the proposed model can be summarized into two phases: the inference phase and the generation phase , which are illustrated in Figure 2. Specifically, the inference phase , which is used to infer the latent variables, is composed of the user latent variable encoder Q ( u | G,e, r, v ) and the latent strategies variables encoder Q ( s | e, r, v, u ) . The generation phase , which is used to infer the observational variables, is composed of the social network reconstruction P ( G | u ) , the rate level reconstruction P ( r | u, v, e ) and the exposure reconstruction P ( e | v, u, s ) . We will describe the implementation of the aforementioned components in the following subsections.",
  "A. Inference Phase": "1) User Latent Variable Encoder: In this part, we first introduce the details of the user latent variable encoder Q ( u | G,e, r, v ) given the social network G , item v as well as the corresponding rate level r and exposure variables e . The procedure of inferring the user latent variables is composed of three steps. First, we aggregate the information of bipartite graph to obtain the aggregated representation h b . Second, we employ a similar way to obtain the aggregated representation h s on social networks. Third, we split the aggregated representation for each type of exposure variables and then process them with different multilayer perceptrons (MLPs). As for the first steps, we need to obtain the aggregated representation of the user-item bipartite graph, we employ the techniques of graph attention networks (GAT) [44]. In ⌉∫ ( Fig. 3. The implementation of the exposure-specific function. ⌉ ⌉ 〉Ł ( ⌉∏ 〉GLYPH<220> )GLYPH<226> ⌉GLYPH<224> 〉Ł ( 〉Ł ( ⌉∏ 〉GLYPH<220> )GLYPH<226> ⌉GLYPH<224> 〉Ł ( ⌉ 〉Ł ( ⌉∫ 〉GLYPH<221> )GLYPH<226> ⌉GLYPH<224> 〉GLYPH<221> ( ⌉ 〉Ł ( ⌉∫ 〉GLYPH<221> )GLYPH<226> ⌉GLYPH<224> 〉GLYPH<221> ( detail, given the user u i , the interacted item sets C ( u ) and the corresponding ratings, we obtain the aggregated representation h b with the help of attention mechanism as follows:  in which g b ( · ) with trainable parameters W b is the score function that is used to calculate the matching score given u, v, r ; a b uv denotes the important weights between user u and item v . And σ ( · ) denotes the LeakyReLU, which is the leaky version of a rectified linear unit; C ( u ) denotes the items list that u has accessed in the bipartite graph. Secondly, we use another GAT to obtain the aggregated representation of social networks. Practically, we let G in Q ( u | G,e, r, v ) be the substructure of the social networks, for example, the 1st-order neighbors of u . The calculation procedure is shown as follows:  in which g s ( · ) with trainable parameters W s is the score function that is used to calculated the matching score given IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, SUBMITTED 6 any two user embedding; a s uk denotes the important weight between u and k ; And N ( u ) denotes the 1st-order neighbors of u . Finally, in order to obtain the user latent variables, we devise the exposure-specific architecture inspired by CEV AE [27] and TARnet [45], which is shown in Figure 3. we use g 0 ( · ) , g 1 ( · ) to generate the user latent variables h u . Specifically, we can obtain the latent user variables via the exposure-specific functions as follows:  where g 0 ( · ) and g 1 ( · ) are composed of MLPs, W 0 g and W 1 g are the trainable parameters. For convenience, we let W g = { W 0 g , W 1 g , W b , W s } . For a tetrad ( u, v, r, e = 1) in the exposed set, we use g 1 ( h b ⊕ h s ; W 1 g ) . For those from the unexposed set, we use g 0 ( h b ⊕ h s ; W 0 g ) . The training of the unexposed g 0 ( · ) is crucial to the success of our counterfactual learning problem [27]. The main challenge is that we can only obtain the rate levels on the exposed set from the bipartite graph and the rate levels on the unexposed set are unavailable. To address this challenge, we approximate the unexposed set in the following three steps: · First, we extract C ( u ) and G 1 u for the user u , where G 1 u is the set of 1-order neighbors of u . · Second, we extract the β -frequency neighbors item set F u by F u = { v | v / ∈ C ( u ) , ∑ u ′ ∈ N ( u ) e u ′ v ≥ β } . · Third, we obtain the unexposed sample ( u, v, r, e = 0) , in which v ∈ F u and r is the most frequent rate level of u 's neighbors, i.e, using the voting method to get the value r for the unexposed samples. Please note that the aforementioned procedure to generate the counterfactual samples implicitly leverage the assumption that both the users and their friends share similar interests and behaviors. 2) Latent Strategies Variables Encoder: In this subsection, we aim to model the latent strategies variables s by using the exposure variables e , item variables v , rate level r and latent user variables u . First, we follow the same aggregation method in Equation (6) to calculate the item aggregated representation h d for discrete strategies variables encoder, which is shown as follows:  in which W d are the trainable parameters. Similar to Equation (8), we model the latent strategies variable with the help of another exposure-specific function as show in Equation(10). Note that we use the Gumbel-Softmax trick [46] to estimate latent strategies variable since we assume they follow the categorical distribution.  in which φ 0 and φ 1 are the exposure-specific function in latent strategies variables encoder. W (0) φ and W (1) φ are the trainable variables. For convenience, we let W s = { W 0 φ , W 1 φ , W d } .",
  "B. Generation Phase": "1) Social Networks Reconstruction: After obtaining the aforementioned two kinds of latent variables, we aim to reconstruct the social networks. In this paper, we follow the configuration of variational graph auto-encoders [47] and reconstruct each edge of social network structures of u as follows:  where ˆ G u,u ′ is the predicted edge between u and u ′ . In order to train the model with the mini-batch, we only reconstruct the 1-st order neighbors of u instead of the whole social networks. 2) Exposure Reconstruction: Given the latent user variables u , latent strategies variables s and item variables v , we aims to model P ( e | v, u, s ) . We employ the following function to reconstruct the exposure variables:  in which θ e are the trainable parameters and f e ( · ) is a neural architecture that is composed of MLPs. 3) Rate Level Reconstruction: Finally, we aims to predict the rate level, given the user latent variables u , item variables v and exposure variables e . Similar to Equation (8), we employ the exposure-specific rate level predictor, which is shown as follows:  in which f 0 and f 1 are also composed of MLPs and θ 0 and θ 1 are the trainable parameters. For convenience, we let Θ r = { θ 0 , θ 1 , θ e } .",
  "C. Model Summarization": "After combining the inference phase and the generation phase, we summarize the total loss of the proposed method as follows:  where L reg is the L2 regularization of the parameters; γ is the hyper-parameter. During the training step, we optimize the model by using the following procedure:  During the evaluation step, given the u and unexposed item v , we let e = 1 . The following procedure with the trained optimal parameters is adapted to the test dataset.  IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, SUBMITTED 7 TABLE II STATISTICS OF THE DATASETS",
  "V. EXPERIMENT": "In this section, we report experimental results on four datasets to evaluate our method against the state-of-the-art baselines, including the latest methods that use the idea of causal effect. With the help of the experiment results, we want to explore the following challenges: (1) Can the proposed REST method remove the disadvantage of selection biases? How is the performance compared with the existing methods? Especially the causality-based methods. (2) Can the strategies variables in the proposed REST method model effectively mitigate the non-stationary strategies challenges?",
  "A. Datasets": "In order to evaluate the performance of our method, we conduct experiments on three published datasets (including Ciao, Epinions, and Yelp) with explicit feedback and a private dataset collected from WeChat official accounts with implicit feedback. The details of the aforementioned dataset are shown in Table II. · Ciao 1 is a published dataset for the social recommendation. The source cite of Ciao allows users to rate items, and add friends to their 'Circle of Trust'. · Epinions 2 : A benchmark dataset for the social recommendation. In Epinions, a user can rate and give comments on items. Besides, a user can also select other users as their trusters. Note that we treat the trust graphs as social networks. · Yelp 3 : An online review platform where users review local businesses (e.g., restaurants and shops). The useritem interactions and the social networks are extracted in the same way as Epinions. · WeChat Official Accounts Dataset: WeChat is a Chinese multi-purpose messaging, social media, and mobile payment application developed by Tencent. And WeChat official accounts dataset is one of the functions. On the WeChat Official Account platform, users can read and share articles. This dataset is constructed by user-article clicking records and user-user social networks on this platform. For each dataset, we split it into the training set, validation set, and test set. We choose the model with the best validation and 1 www.ciao.co.uk 2 http://www.trustlet.org/extended epinions.html 3 https://www.kaggle.com/yelp-dataset/yelp-dataset evaluate the chosen model on the test set. Note that we do not consider new users and new items in validation and testing. All the methods run with five different random seeds, and we report both the mean and variance. The source code and the prepossessing scripts of the proposed methods are available at the following link 4 .",
  "B. Hyper-parameters": "We optimize all models with the Adam optimizer with the batch size of 1024. For a fair comparison, all the methods are fine-tuning by searching the learning rate in the range of { 0 . 001 , 0 . 0009 , · · · , 0 . 0001 } . We also adopt the early stopping strategy that stops training if RMSE/HR@20 on the validation dataset does not decrease/increase for 1500 training steps.",
  "C. Evaluation Metrics": "We use different evaluation metrics for datasets with explicit feedback and implicit feedback respectively. For the dataset with explicit feedback, we use MSE and RMSE. The smaller values of MAE and RMSE, the better the predictive accuracy is. Note that even a small improvement in RMSE or MAE terms can have a significant impact on the quality of the top-few recommendations. For the dataset with implicit feedback, we use Hit Rate@ K (HR@ K ) and Normalized Discounted Cumulative Gain@ K (NDCG@ K ). HR measures the percentage that recommended items contain at least one correct item interacted by the user, while NDCG takes the positions of correct recommended items into consideration. In this paper, we choose K in { 5 , 10 , 20 } . Note that higher scores of HR@ K and NDCG@ K indicate better performance.",
  "D. Baselines": "We compare the proposed REST method with four kinds of baselines. Besides the classical matrix factorization based Methods, we also take some graph neural networks based methods into account. Furthermore, we also compare our method with the baselines based on causal inference. Since our method uses the technique of variational influence, we also consider some VAE based methods.",
  "Matrix Factorization based Methods :": "· PMF [12]: Probabilistic Matrix Factorization is one of the most traditional methods for the recommendation that models latent factors of users and items by Gaussian distributions. · NeuMF [13]: Neural network based Collaborative Filtering replaces the inner product with a neural architecture that can learn an arbitrary function from data. · BPRMF [48]: BPRMF which is optimized by stochastic gradient descent with bootstrap sampling, is the maximum posterior estimator that derived from the Bayesian theorem.",
  "Graph Neural Networks based Methods :": "4 https://github.com/DMIRLAB-Group/REST IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, SUBMITTED 8 TABLE III THE PERFORMANCE EVALUATION OF THE COMPARED METHODS ON CIAO, EPINION, YELP DATASET. THE VALUE PRESENTED ARE AVERAGED OVER 5 REPLICATED WITH DIFFERENT RANDOM SEEDS. STANDARD DEVIATION IS IN THE SUBSCRIPT. · GraphRec [49]: A graph neural networks based method that leverages graph attention mechanism to aggregate the information of the social networks and user-item relations. And how is the performance compared with the existing methods, including the latest causality-based method? · LightGCN [50]: LightGCN optimizes the user and item representation by linearly propagating them on the bipartite graph, and uses the weighted sum of the representation. · NGCF [51]: NGCF integrates the user-item interactions by modeling the high-order connectivity and injecting the collaborative signal into the embedding process.",
  "Variational Auto-Encoder based Methods :": "· MultVAE [39]: MultVAE extends VAE to collaborative filtering for implicit feedback, so it performs worse on the dataset with explicit feedback. · RecVAE [52] uses the multinomial likelihood variational auto-encoders to map user feedbacks to user embeddings.",
  "Causality-based Methods :": "· CausE [23]: CausE jointly learns two CTR models and uses a multi-task objective that factorizes the matrix of observations. · CVIB [31]: CVIB learns a balanced model based on Information Bottleneck, which simultaneously optimizes the factual and counterfactual embeddings. In this paper, we compare our method with two variants of CVIB: MFCVIB and NCF-CVIB. · MACR-MF [25]: MACR-MF leverages the idea of causal effect and builds a multi-task learning schema over MF. We compare MACR-MF with our method in the implicit feedback dataset. · DecRS [24]: Deconfounded Recommender System (DecRS) models the causal effect of user representation on the prediction score, which eliminates the impact of the confounder with the help of backdoor adjustment. Note that we only compare DecRs in the Ciao and Epinions datasets, since this method needs the categories of items and the Yelp dataset does not contain the item categories.",
  "E. Deconfounding Performance": "In this subsection, we aim to answer (1) Can the proposed REST method remove the disadvantage of selection biases? 1) Experiment results on datasets with explicit feedback: We first illustrate the experiment results on the explicit feedback dataset, in which the users provide the rating for items. Hence we follow [49] and employ the MAE and RMSE as the evaluation metric. The experiment results on Ciao, Epinions, and Yelp dataset are shown in Table III. From experiment results, we can obtain the following observations: · The proposed REST method outperforms the other methods with a large margin, which proves that our method can effectively remove the disadvantages of the selection biases. Furthermore, the superior performance of the proposed REST reflects the advantages of the identification theorem. · According to the Table III, the proposed REST achieves different degrees of improvement on the three explicit datasets. In detail, the REST respectively obtains 26 . 4% , 18 . 1% and 7 . 7% improvements on the Ciao, Epinion and Yelp datasets. This is because the social networks densities of these datasets are different. According to Table II, we can find that the Ciao dataset contains the densest social networks while the Yelp contains the sparsest one. This is because the denser social networks can provide more counterfactual samples, which further benefit the model performance. · Our method not only outperforms the conventional recommendation algorithms like PMF and NeuralMF but also outperforms the VAE-based methods like MultiVAE and RecVAE. This is because the VAE-based methods assume that the distributions of latent variables follow the Gaussian distribution but the assumption is too strong and does not work in practice. In the meanwhile, assuming that the latent variables follow the delta distribution, the proposed REST method can avoid the aforementioned drawback. · The graph neural networks based methods like the LightGCN and the GraphRec, which are designed for the implicit feedback datasets, perform poorly in the explicit feedback dataset. For one thing, this verifies that the graph neural networks are still poisoned by the selection IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, SUBMITTED 9 TABLE IV THE PERFORMANCE EVALUATION OF THE COMPARED METHODS ON WECHAT DATASET. THE VALUE PRESENTED ARE AVERAGED OVER 5 REPLICATED WITH DIFFERENT RANDOM SEEDS. STANDARD DEVIATION IS IN THE SUBSCRIPT. biases even though they leverage the social networks. For another thing, the proposed method leverage the social to generate the counterfactual samples can mitigate the selection biases to some extent.",
  "F. Ablation Analysis": "· As for the causal inference based method, our method outperforms the causality based method like CausE, MACR-MF and DecFM. This is because the proposed REST method models latent strategy variables that break the stationary strategy assumption. We will further explore the effectiveness of the latent strategy variables in the following subsections. 2) Experiment results on the dataset with implicit feedback: Then we further illustrate the experimental results on the implicit feedback dataset, in which only the actions of users like clicking or purchasing, are collected. Hence we follow [25] and employ HR@K and NDCG@K as the evaluation metrics. The implicit feedback scenario is more challenging, because it is hard to distinguish if the unseen samples are disliked or not. The experiment results on the WeChat Offical Account dataset are shown in Table IV. We do not report the experiment result of LightGCN and NGCF because of the limited CPU memory. According to the experiment results, we can get the following conclusions: · As similar to the experiment results on the explicit feedback dataset, we can find that the proposed REST method still achieves the best performance, which reflects that our method can work on both the explicit and the implicit scenarios. · Compared with the causal based methods like MACR-MF [25] and the other types of methods, the causality-based methods achieve a better result, which reflects that the selection biases really harm the performance and taking causality into consideration will ease the disadvantage to some extent. · In the meanwhile, our method also achieves good results. This is because the Wechat dataset is more likely controlled by different types of strategies like different fast-breaking news. Therefore, taking the stationary assumption and ignoring the strategies will degenerate the performance of the recommendation systems even the selection biases have been taken into account. In order to evaluate the effectiveness of the latent unobserved strategy variables, we raise a model invariant named REST-S , which removes the latent unobserved strategy variables in the data generation process. In this case, we follow the stationary strategy assumption and do not model the strategies behind the data. 1) The effectiveness of the discrete strategy variables: In order to verify the effectiveness of discrete exposure component of our model, we devise REST-S . The experiment results are shown in Figure 4 and 5. Based on the experiment results, we can observe that: · Compared DUSE-S with the standard REST, we can find that the performance of REST-S is lower that of REST, which reflects the advantages of modeling the discrete strategies. · Since we do not model the discrete strategies in REST-S, both the REST-S and other causality based methods like MACR-MF are the same from the view of principle, so it is reasonable to guess that the performance of both the REST-S and other causality-based methods are similar. Compared REST-S with the other baselines, like CVIBNCF and MACR-MF, we can find that we still obtain a comparable performance, which not only validates the aforementioned guess but also the effectiveness of modeling strategies.",
  "G. Visualization": "To further show the necessity for modeling the latent discrete strategies, we provide the visualization of the discrete strategies with 64 dimensions on the Ciao dataset, which is shown in Figure 6. We split the 64 dimensions into 16 different categorical distributions which represent 16 different one-hot vectors. Note that the horizontal axis stands for each dimension of latent variables. We choose three different traditional festivals, Christmas, Thanksgiving Day, and Valentine's Day and draw the latent discrete strategies variables of the same user at each festival on different years. The value of the yellow block is 1 and the value of the purple is 0 . According to the visualization, we can find that: IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, SUBMITTED 10 Fig. 4. MSE evaluation on Social networks and latent strategies variables. ( best view in color ) REST REST-S CVIB-NCF CausE DecFM GraphRec 0.700 0.725 0.750 0.775 0.800 0.825 0.850 0.875 0.900 MAE Ciao Epinion Fig. 5. HR@K evaluation on Social networks and latent strategies variables.( best view in color ) REST REST-S NCF-CVIB CausE MACR-MF GraphRec 50 55 60 65 70 75 80 85 90 HR@K HR@5 HR@10 HR@20 · Shared patterns among the reconstructed strategy variables come from the same festival. For example, on Christmas, the locations of yellow blocks are similar. This means that the same festival shares similar promotion strategies. · The latent discrete strategies variables from different festivals look different, which means that different festivals have different promotion strategies. By modeling the strategies variables, we can well model the complex useritem relationships despite the disadvantages of selection bias.",
  "VI. CONCLUSION": "This paper presents a debiased recommendation framework based on the explicitly modeling and reconstructing the discrete unobserved exposure strategies. In the proposed method, we reconstruct the latent exposure variables from the observational data using a variational auto-encoders framework, with the help of the clues from both the social networks and the items. The correctness, as well as the effectiveness of our proposal, are verified on four real-world datasets. The success of our model not only reveals that the latent exposure strategies are the cause of the well-known selection bias problem but also provides an effective solution for this open problem in the recommendation system. The visualization of the recovered exposure strategies on the real-world dataset also provides some interesting insights into the existing recommendation systems. Christmas Fig. 6. The visualization of the discrete strategies variables. The vertical coordinate and the horizontal coordinate denote the different festivals and the different dimensions in the form of the one-hot vector. ( best view in color ) 2008-12-19 2010-12-24 2009-12-24 Thanksgiving Day 2008-11-24 2010-11-25 2009-11-25 Valentine's Day 2008-02-14 2010-02-15 2009-02-14",
  "VII. ACKNOWLEDGMENTS": "We would like to thank Lingling Yi and Li Li from WeChat for their help and supports on this work.",
  "REFERENCES": "[1] S. Zhang, L. Yao, A. Sun, and Y. Tay, 'Deep learning based recommender system: A survey and new perspectives,' ACM Computing Surveys (CSUR), vol. 52, no. 1, pp. 1-38, 2019. [2] Y. Zhang and X. Chen, 'Explainable recommendation: A survey and new perspectives,' Foundations and Trends in Information Retrieval, vol. 14, no. 1, pp. 1-101, 2020. [3] G. Linden, B. Smith, and J. York, 'Amazon.com recommendations: itemto-item collaborative filtering,' IEEE Internet Computing, vol. 7, no. 1, pp. 76-80, 2003. [4] P. Covington, J. Adams, and E. Sargin, 'Deep neural networks for youtube recommendations,' in Proceedings of the 10th ACM conference on recommender systems, 2016, pp. 191-198. [5] X. Wang, X. He, F. Feng, L. Nie, and T.-S. Chua, TEM: Tree-Enhanced Embedding Model for Explainable Recommendation. Republic and Canton of Geneva, CHE: International World Wide Web Conferences Steering Committee, 2018, p. 1543-1552. [Online]. Available: https://doi.org/10.1145/3178876.3186066 [6] J. Ma, C. Zhou, P. Cui, H. Yang, and W. Zhu, 'Learning disentangled representations for recommendation,' arXiv preprint arXiv:1910.14238, 2019. [7] Y. Cen, J. Zhang, X. Zou, C. Zhou, H. Yang, and J. Tang, 'Controllable multi-interest framework for recommendation,' in Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 2020, pp. 2942-2951. [8] M. Tennenholtz and O. Kurland, 'Rethinking search engines and recommendation systems: a game theoretic perspective,' Communications of the ACM, vol. 62, no. 12, pp. 66-75, 2019. [9] R. Baeza-Yates, C. Hurtado, and M. Mendoza, 'Query recommendation using query logs in search engines,' in International conference on extending database technology. Springer, 2004, pp. 588-596. [10] S. Bouraga, I. Jureta, S. Faulkner, and C. Herssens, 'Knowledge-based recommendation systems: a survey,' International Journal of Intelligent Information Technologies (IJIIT), vol. 10, no. 2, pp. 1-19, 2014. [11] Y. Koren, R. Bell, and C. Volinsky, 'Matrix factorization techniques for recommender systems,' Computer, vol. 42, no. 8, pp. 30-37, 2009. [12] A. Mnih and R. R. Salakhutdinov, 'Probabilistic matrix factorization,' Advances in neural information processing systems, vol. 20, pp. 12571264, 2007. [13] X. He, L. Liao, H. Zhang, L. Nie, X. Hu, and T.-S. Chua, 'Neural collaborative filtering,' in Proceedings of the 26th international conference on world wide web, 2017, pp. 173-182. [14] M. Jamali and M. Ester, 'A matrix factorization technique with trust propagation for recommendation in social networks,' in Proceedings of the fourth ACM conference on Recommender systems, 2010, pp. 135142. [15] H. Steck, 'Item popularity and recommendation accuracy,' in Proceedings of the fifth ACM conference on Recommender systems, 2011, pp. 125-132. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, SUBMITTED 11 [16] W. Wang, F. Feng, X. He, H. Zhang, and T.-S. Chua, '' click' is not equal to' like': Counterfactual recommendation for mitigating clickbait issue,' arXiv preprint arXiv:2009.09945, 2020. [17] J. Chen, H. Dong, X. Wang, F. Feng, M. Wang, and X. He, 'Bias and debias in recommender system: A survey and future directions,' arXiv preprint arXiv:2010.03240, 2020. [18] C. Song, Y. Ge, T. Ge, H. Wu, Z. Lin, H. Kang, and X. Yuan, 'Similar but foreign: Link recommendation across communities,' Information Sciences, vol. 552, pp. 142-166, 2021. [19] Z. Ovaisi, R. Ahsan, Y. Zhang, K. Vasilaky, and E. Zheleva, 'Correcting for selection bias in learning-to-rank systems,' in Proceedings of The Web Conference 2020, 2020, pp. 1863-1873. [20] T. Schnabel, A. Swaminathan, A. Singh, N. Chandak, and T. Joachims, 'Recommendations as treatments: Debiasing learning and evaluation,' in international conference on machine learning. PMLR, 2016, pp. 1670-1679. [21] X. Wang, M. Bendersky, D. Metzler, and M. Najork, 'Learning to rank with selection bias in personal search,' in Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, 2016, pp. 115-124. [22] D. Liang, L. Charlin, and D. M. Blei, 'Causal inference for recommendation,' in Causation: Foundation to Application, Workshop at UAI. AUAI, 2016. [23] S. Bonner and F. Vasile, 'Causal embeddings for recommendation,' in Proceedings of the 12th ACM conference on recommender systems, 2018, pp. 104-112. [24] W. Wang, F. Feng, X. He, X. Wang, and T.-S. Chua, 'Deconfounded recommendation for alleviating bias amplification,' arXiv preprint arXiv:2105.10648, 2021. [25] T. Wei, F. Feng, J. Chen, C. Shi, Z. Wu, J. Yi, and X. He, 'Modelagnostic counterfactual reasoning for eliminating popularity bias in recommender system,' arXiv preprint arXiv:2010.15363, 2020. [26] Y. Zhang, F. Feng, X. He, T. Wei, C. Song, G. Ling, and Y. Zhang, 'Causal intervention for leveraging popularity bias in recommendation,' arXiv preprint arXiv:2105.06067, 2021. [27] C. Louizos, U. Shalit, J. Mooij, D. Sontag, R. Zemel, and M. Welling, 'Causal effect inference with deep latent-variable models,' in Proceedings of the 31st International Conference on Neural Information Processing Systems, 2017, pp. 6449-6459. [28] A. Sharma, J. M. Hofman, and D. J. Watts, 'Estimating the causal impact of recommendation systems from observational data,' in Proceedings of the Sixteenth ACM Conference on Economics and Computation, 2015, pp. 453-470. [29] Q. Ai, K. Bi, C. Luo, J. Guo, and W. B. Croft, 'Unbiased learning to rank with unbiased propensity estimation,' in The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, 2018, pp. 385-394. [30] X. Wang, R. Zhang, Y. Sun, and J. Qi, 'Doubly robust joint learning for recommendation on data missing not at random,' in International Conference on Machine Learning. PMLR, 2019, pp. 6638-6647. [31] Z. Wang, X. Chen, R. Wen, S.-L. Huang, E. E. Kuruoglu, and Y. Zheng, 'Information theoretic counterfactual learning from missingnot-at-random feedback,' arXiv preprint arXiv:2009.02623, 2020. [32] D. Xu, C. Ruan, E. Korpeoglu, S. Kumar, and K. Achan, 'Adversarial counterfactual learning and evaluation for recommender system,' Advances in Neural Information Processing Systems, vol. 33, 2020. [33] H. Ma, H. Yang, M. R. Lyu, and I. King, 'Sorec: social recommendation using probabilistic matrix factorization,' in Proceedings of the 17th ACM conference on Information and knowledge management, 2008, pp. 931-940. [34] B. Yang, Y. Lei, J. Liu, and W. Li, 'Social collaborative filtering by trust,' IEEE transactions on pattern analysis and machine intelligence, vol. 39, no. 8, pp. 1633-1647, 2017. [35] S. Deng, L. Huang, G. Xu, X. Wu, and Z. Wu, 'On deep learning for trust-aware recommendations in social networks,' IEEE transactions on neural networks and learning systems, vol. 28, no. 5, pp. 1164-1177, 2016. [36] W. Fan, T. Derr, Y. Ma, J. Wang, J. Tang, and Q. Li, 'Deep adversarial social recommendation,' arXiv preprint arXiv:1905.13160, 2019. [37] F. Zhou, Y. Mo, G. Trajcevski, K. Zhang, J. Wu, and T. Zhong, 'Recommendation via collaborative autoregressive flows,' Neural Networks, vol. 126, pp. 52-64, 2020. [38] G. Papamakarios, E. Nalisnick, D. J. Rezende, S. Mohamed, and B. Lakshminarayanan, 'Normalizing flows for probabilistic modeling and inference,' arXiv preprint arXiv:1912.02762, 2019. [39] D. Liang, R. G. Krishnan, M. D. Hoffman, and T. Jebara, 'Variational autoencoders for collaborative filtering,' in Proceedings of the 2018 world wide web conference, 2018, pp. 689-698. [40] D. P. Kingma and M. Welling, 'Auto-encoding variational bayes,' arXiv preprint arXiv:1312.6114, 2013. [41] H. Liu, L. Jing, J. Wen, Z. Wu, X. Sun, J. Wang, L. Xiao, and J. Yu, 'Deep global and local generative model for recommendation,' in Proceedings of The Web Conference 2020, 2020, pp. 551-561. [42] J. Yu, H. Yin, J. Li, M. Gao, Z. Huang, and L. Cui, 'Enhance social recommendation with adversarial graph convolutional networks,' IEEE Transactions on Knowledge and Data Engineering, 2020. [43] J. Pearl, Causality. Cambridge university press, 2009. [44] P. Veliˇ ckovi´ c, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio, 'Graph attention networks,' arXiv preprint arXiv:1710.10903, 2017. [45] U. Shalit, F. D. Johansson, and D. Sontag, 'Estimating individual treatment effect: generalization bounds and algorithms,' in International Conference on Machine Learning. PMLR, 2017, pp. 3076-3085. [46] E. Jang, S. Gu, and B. Poole, 'Categorical reparameterization with gumbel-softmax,' arXiv preprint arXiv:1611.01144, 2016. [47] T. N. Kipf and M. Welling, 'Variational graph auto-encoders,' arXiv preprint arXiv:1611.07308, 2016. [48] S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-Thieme, 'Bpr: Bayesian personalized ranking from implicit feedback,' in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, 2009, pp. 452-461. [49] W. Fan, Y. Ma, Q. Li, Y. He, E. Zhao, J. Tang, and D. Yin, 'Graph neural networks for social recommendation,' in The World Wide Web Conference, 2019, pp. 417-426. [50] X. He, K. Deng, X. Wang, Y. Li, Y. Zhang, and M. Wang, 'Lightgcn: Simplifying and powering graph convolution network for recommendation,' in Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, 2020, pp. 639648. [51] X. Wang, X. He, M. Wang, F. Feng, and T.-S. Chua, 'Neural graph collaborative filtering,' in Proceedings of the 42nd international ACM SIGIR conference on Research and development in Information Retrieval, 2019, pp. 165-174. [52] I. Shenbin, A. Alekseev, E. Tutubalina, V. Malykh, and S. I. Nikolenko, 'Recvae: A new variational autoencoder for top-n recommendations with implicit feedback,' in Proceedings of the 13th International Conference on Web Search and Data Mining, 2020, pp. 528-536. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, SUBMITTED 12",
  "APPENDIX": "The proofs of evidence lower bound (ELBO)  Proof. The proof of the ELBO is composed of three steps. First, we factorize the conditional distribution according to the Bayes theorem.  Second, we add the expectation operator on both sides of the equation and reformalize the equation as follows:   Third, we obtain the last equality with the help of D KL ( ·||· ) ≥ 0",
  "keywords_parsed": [
    "Recommendation System",
    "Social Recommendation System",
    "Causal Effect",
    "Variational Auto-Encoder"
  ],
  "references_parsed": [
    {
      "ref_id": "b1",
      "title": "Deep learning based recommender system: A survey and new perspectives"
    },
    {
      "ref_id": "b2",
      "title": "Explainable recommendation: A survey and new perspectives"
    },
    {
      "ref_id": "b3",
      "title": "Amazon.com recommendations: item-to-item collaborative filtering"
    },
    {
      "ref_id": "b4",
      "title": "Deep neural networks for youtube recommendations"
    },
    {
      "ref_id": "b5",
      "title": "TEM: Tree-Enhanced Embedding Model for Explainable Recommendation"
    },
    {
      "ref_id": "b6",
      "title": "Learning disentangled representations for recommendation"
    },
    {
      "ref_id": "b7",
      "title": "Controllable multi-interest framework for recommendation"
    },
    {
      "ref_id": "b8",
      "title": "Rethinking search engines and recommendation systems: a game theoretic perspective"
    },
    {
      "ref_id": "b9",
      "title": "Query recommendation using query logs in search engines"
    },
    {
      "ref_id": "b10",
      "title": "Knowledge-based recommendation systems: a survey"
    },
    {
      "ref_id": "b11",
      "title": "Matrix factorization techniques for recommender systems"
    },
    {
      "ref_id": "b12",
      "title": "Probabilistic matrix factorization"
    },
    {
      "ref_id": "b13",
      "title": "Neural collaborative filtering"
    },
    {
      "ref_id": "b14",
      "title": "A matrix factorization technique with trust propagation for recommendation in social networks"
    },
    {
      "ref_id": "b15",
      "title": "Item popularity and recommendation accuracy"
    },
    {
      "ref_id": "b16",
      "title": "'click' is not equal to 'like': Counterfactual recommendation for mitigating clickbait issue"
    },
    {
      "ref_id": "b17",
      "title": "Bias and debias in recommender system: A survey and future directions"
    },
    {
      "ref_id": "b18",
      "title": "Similar but foreign: Link recommendation across communities"
    },
    {
      "ref_id": "b19",
      "title": "Correcting for selection bias in learning-to-rank systems"
    },
    {
      "ref_id": "b20",
      "title": "Recommendations as treatments: Debiasing learning and evaluation"
    },
    {
      "ref_id": "b21",
      "title": "Learning to rank with selection bias in personal search"
    },
    {
      "ref_id": "b22",
      "title": "Causal inference for recommendation"
    },
    {
      "ref_id": "b23",
      "title": "Causal embeddings for recommendation"
    },
    {
      "ref_id": "b24",
      "title": "Deconfounded recommendation for alleviating bias amplification"
    },
    {
      "ref_id": "b25",
      "title": "Model-agnostic counterfactual reasoning for eliminating popularity bias in recommender system"
    },
    {
      "ref_id": "b26",
      "title": "Causal intervention for leveraging popularity bias in recommendation"
    },
    {
      "ref_id": "b27",
      "title": "Causal effect inference with deep latent-variable models"
    },
    {
      "ref_id": "b28",
      "title": "Estimating the causal impact of recommendation systems from observational data"
    },
    {
      "ref_id": "b29",
      "title": "Unbiased learning to rank with unbiased propensity estimation"
    },
    {
      "ref_id": "b30",
      "title": "Doubly robust joint learning for recommendation on data missing not at random"
    },
    {
      "ref_id": "b31",
      "title": "Information theoretic counterfactual learning from missing-not-at-random feedback"
    },
    {
      "ref_id": "b32",
      "title": "Adversarial counterfactual learning and evaluation for recommender system"
    },
    {
      "ref_id": "b33",
      "title": "Sorec: social recommendation using probabilistic matrix factorization"
    },
    {
      "ref_id": "b34",
      "title": "Social collaborative filtering by trust"
    },
    {
      "ref_id": "b35",
      "title": "On deep learning for trust-aware recommendations in social networks"
    },
    {
      "ref_id": "b36",
      "title": "Deep adversarial social recommendation"
    },
    {
      "ref_id": "b37",
      "title": "Recommendation via collaborative autoregressive flows"
    },
    {
      "ref_id": "b38",
      "title": "Normalizing flows for probabilistic modeling and inference"
    },
    {
      "ref_id": "b39",
      "title": "Variational autoencoders for collaborative filtering"
    },
    {
      "ref_id": "b40",
      "title": "Auto-encoding variational bayes"
    },
    {
      "ref_id": "b41",
      "title": "Deep global and local generative model for recommendation"
    },
    {
      "ref_id": "b42",
      "title": "Enhance social recommendation with adversarial graph convolutional networks"
    },
    {
      "ref_id": "b43",
      "title": "Causality"
    },
    {
      "ref_id": "b44",
      "title": "Graph attention networks"
    },
    {
      "ref_id": "b45",
      "title": "Estimating individual treatment effect: generalization bounds and algorithms"
    },
    {
      "ref_id": "b46",
      "title": "Categorical reparameterization with gumbel-softmax"
    },
    {
      "ref_id": "b47",
      "title": "Variational graph auto-encoders"
    },
    {
      "ref_id": "b48",
      "title": "Bpr: Bayesian personalized ranking from implicit feedback"
    },
    {
      "ref_id": "b49",
      "title": "Graph neural networks for social recommendation"
    },
    {
      "ref_id": "b50",
      "title": "Lightgcn: Simplifying and powering graph convolution network for recommendation"
    },
    {
      "ref_id": "b51",
      "title": "Neural graph collaborative filtering"
    },
    {
      "ref_id": "b52",
      "title": "Recvae: A new variational autoencoder for top-n recommendations with implicit feedback"
    }
  ]
}