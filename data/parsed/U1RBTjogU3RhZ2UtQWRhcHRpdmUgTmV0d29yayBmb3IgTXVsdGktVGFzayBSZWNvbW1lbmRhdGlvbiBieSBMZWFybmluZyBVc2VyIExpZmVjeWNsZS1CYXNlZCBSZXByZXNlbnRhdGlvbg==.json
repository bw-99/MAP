{"STAN: Stage-Adaptive Network for Multi-Task Recommendation by Learning User Lifecycle-Based Representation": "WANDA LI \u2217 , Tsinghua University, China WENHAO ZHENG and XUANJI XIAO \u2020 , Shopee Company, China SUHANG WANG, Penn State University, USA Recommendation systems play a vital role in many online platforms, with their primary objective being to satisfy and retain users. As directly optimizing user retention is challenging, multiple evaluation metrics are often employed. Existing methods generally formulate the optimization of these evaluation metrics as a multitask learning problem, but often overlook the fact that user preferences for different tasks are personalized and change over time. Identifying and tracking the evolution of user preferences can lead to better user retention. To address this issue, we introduce the concept of 'user lifecycle,' consisting of multiple stages characterized by users' varying preferences for different tasks. We propose a novel St ageA daptive N etwork ( STAN ) framework for modeling user lifecycle stages. STAN first identifies latent user lifecycle stages based on learned user preferences, and then employs the stage representation to enhance multi-task learning performance. Our experimental results using both public and industrial datasets demonstrate that the proposed model significantly improves multi-task prediction performance compared to state-of-the-art methods, highlighting the importance of considering user lifecycle stages in recommendation systems. Furthermore, online A/B testing reveals that our model outperforms the existing model, achieving a significant improvement of 3.05% in staytime per user and 0.88% in CVR. These results indicate that our approach effectively improves the overall efficiency of the multi-task recommendation system. CCS Concepts: \u00b7 Information Systems \u2192 Collaborative filtering ; \u00b7 Machine Learning \u2192 Multi-task learning ; Supervised learning by classification . Additional Key Words and Phrases: Recommendation Systems, Multi-task Learning, User Lifecycle Modeling", "ACMReference Format:": "Wanda Li, Wenhao Zheng, Xuanji Xiao, and Suhang Wang. 2023. STAN: Stage-Adaptive Network for Multi-Task Recommendation by Learning User Lifecycle-Based Representation. In RecSys23', Sept. 18-22, 2023, Singapore, SG. ACM, New York, NY, USA, 18 pages. https://doi.org/XXXXXXX.XXXXXXX", "1 INTRODUCTION": "In recent years, online recommendation systems (RS) have become increasingly popular, assisting users in discovering their preferred items from a vast array of choices on platforms such as ecommerce and social media. The primary objective of RS is to attract, satisfy, and retain users. Researchers have proposed various techniques to achieve these objectives, including multi-task learning methods. \u2217 This work was done during Wanda Li's internship at Shopee. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Recsys '23, Sept 18-22, 2023, Singapore, SG \u00a9 2023 Association for Computing Machinery. ACM ISBN 978-1-4503-XXXX-X/18/06...$15.00 https://doi.org/XXXXXXX.XXXXXXX Due to the high dimensionality of RS [20], modeling its objectives is challenging. Many works represent the objectives through multiple directly learnable metrics, such as the likelihood of clicking, forwarding, and staying. Consequently, there has been a growing trend to apply multi-task learning methods to model the various aspects of user interests. Some studies [12, 15, 20, 25, 27] suggest that click-through rate (CTR) and post-click conversion rate (CVR) are the best indicators of user satisfaction, proposing that clicking and purchasing actions are the primary drivers of user retention. Other works [13, 28, 32] consider user feedback (e.g., interactions like forward, comment, stay) as evaluation metrics, assuming that more interactions represent stronger user engagement and aiming to improve all interaction metrics simultaneously. Nonetheless, these prior works do not fully consider the user lifecycle [4, 9, 10] and its impact on user satisfaction and retention. The user lifecycle consists of several stages, each characterized by user preferences towards different tasks. These preferences change over time as users evolve, and users may transition between stages with varying probabilities. To emphasize the importance of incorporating user lifecycle stages into RS, consider the experiences of two users, Bob and Alice, as illustrated in Fig. 1. Typically, a user progresses through a series of stages since registering on the platform. Note that the four discrete stages in Fig. 1 are merely examples for visualization purposes, and the actual stages in our model are represented by continuous vectors. Bob exhibits wandering behavior, browsing quickly without intending to purchase items. Traditional multi-task RS might try to persuade him to buy by presenting top-selling products. However, this approach could result in his dissatisfaction, causing him to leave without making a purchase. Conversely, Alice has recently transitioned to a more committed stage. She previously preferred browsing to placing orders, but in her current stage, she is more likely to purchase without hesitation if the recommendation suits her preferences. Traditional multi-task RS might persist in recommending items aimed at prolonging her usage time, but these attempts may no longer capture her interest. By taking user lifecycle and stages into account, which can be customized to specific contexts, the recommendation system can more effectively address the diverse needs of users at different stages of their interactions with the platform. We propose a user lifecycle stage-adaptive framework to address these issues. It dynamically adjusts its focus on tasks according to the user's stage, which is modeled by the representation of their preferences. As user behavior may exhibit volatility, it is crucial to account for such instability when modeling preferences. For tasks not aligned with the user's preferences, the user behaviors will be sparse, resulting in actions like clicks and purchases having large randomness and not accurately reflecting users' true preferences. Identifying users' preferences helps the model prioritize reliable targets to learn from, leading to improved performance. By incorporating user stages in the multi-task learning process, the model can focus on users' highest-priority tasks. Our main contributions can be summarized as follows: \u00b7 To the best of our knowledge, this is the first work to integrate the user lifecycle concept into multi-task recommendation systems. By considering the various stages in the user lifecycle , we can more effectively capture users' changing interests. \u00b7 We propose a user stage detection network that represents user stages using continuous user preferences, enabling the model to focus dynamically on each user's preferred tasks. \u00b7 We present comprehensive experimental results on both public and industrial datasets to substantiate our claims. Additionally, we applied our method to an online system, achieving significant improvements in online metrics. Visualization results further emphasize the importance of user lifecycle stages in multi-task recommendation systems. The rest of the paper is organized as follows: Sec. 2 presents a preliminary analysis on the importance of user stages; Sec. 3 details our proposed St ageA daptive N etwork ( STAN ); Sec. 4 showcases \u039d\u03b5\u03c9 \u2126\u03b1\u03bd\u03b4\u03b5\u03c1 \u03a3\u03c4\u03b9\u03c7\u03ba \u039b\u03bf\u03c8\u03b1\u03bb \u03a5\u03c3\u03b5\u03c1 \u039b\u03b9\u03c6\u03b5\u03c7\u03c8\u03c7\u03bb\u03b5 \u03a3\u03c4\u03b1\u03b3\u03b5\u03c3 \u2206\u03b1\u03c4\u03b1 \u2206\u03b9\u03c3\u03c4\u03c1\u03b9- \u03b2\u03c5\u03c4\u03b9\u03bf\u03bd \u0392\u03bf\u03b2 \u0391\u03bb\u03b9\u03c7\u03b5 \u03a7\u03bb\u03b9\u03c7\u03ba \u03a3\u03c4\u03b1\u03c8 \u03a0\u03c5\u03c1\u03c7\u03b7\u03b1\u03c3\u03b5 \u03c4\u03b9\u00b5\u03b5 \u03d6\u03b1\u03bb\u03c5\u03b5 \u039d\u03b5\u03c9 \u2126\u03bf\u03bd\u03b4\u03b5\u03c1 \u03c4\u03b9\u00b5\u03b5 \u03d6\u03b1\u03bb\u03c5\u03b5 \u03a3\u03c4\u03b9\u03c7\u03ba \u039b\u03bf\u03c8\u03b1\u03bb \ud835\udc79 \u03a7\u03a4\u03a1 \u03a3\u03c4\u03b1\u03c8\u03c4\u03b9\u00b5\u03b5 \u03a7\u03c2\u03a1 \u03a7\u03a4\u03a1 \u03a3\u03c4\u03b1\u03c8\u03c4\u03b9\u00b5\u03b5 \u03a7\u03c2\u03a1 \u03a7\u03a4\u03a1 \u03a3\u03c4\u03b1\u03c8\u03c4\u03b9\u00b5\u03b5 \u03a7\u03c2\u03a1 \u03a7\u03a4\u03a1 \u03a3\u03c4\u03b1\u03c8\u03c4\u03b9\u00b5\u03b5 \u03a7\u03c2\u03a1 experiments demonstrating STAN's effectiveness; Sec. 5 discusses the model's expandability and potential; Sec. 6 reviews related work, and Sec. 7 concludes the paper.", "2 PRELIMINARY ANALYSIS": "In this section, we first conduct a preliminary analysis of real-world datasets to show why considering user stage information is important for RS. We then formally define the notations and give the problem definition of our work.", "2.1 Insights from Real-world Data": "In this section, we discuss the e-commerce data used for analysis throughout this paper. We collected one month of user behavior data from an e-commerce platform, which records users' clicks, staytime, and purchase actions. The behavior data is organized by user sessions, each of which is defined as a tuple of actions related to one impressed item. We randomly selected 50,000 users' actions over three days for data analysis. Fig. 2 depicts the user distribution of the three metrics, i.e., CTR, Staytime, and CVR. Inspired by previous works [9, 10], we roughly separate users into four stages by the median of different metrics for a better illustration and explanation. The stages are named New , Wander , Stick and Loyal , as shown in Fig. 3. Note that one user could not belong to multiple stages. Each user at stage New are spotted by a low CTR rate, while their staytime and CVR distribution are the most similar to the overall distribution of all users. Their CTR value conforms to a Gaussian-like distribution but in a low-value range. Users at stage Wander have low staytime length. Their CTR and CVR rates are relatively high, but their staytime stick to a lower range. Users at stage Stick could be quickly found by their relatively low CVR value along with high CTR and staytime, which indicates that they only dwell on the platform but rarely contribute to purchasing. Users at stage Loyal show a custom of steadily clicking, staying, and purchasing on the platform, implying their satisfaction with the recommendation outcomes and the platform. 0.02 0.12 0.22 0.32 0.42 0.52 0.62 0.72 0.82 0.92 CTR Count 200 2200 4200 6200 8200 Staytime 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 CVR According to the stage patterns, we notice that users at different stages put their focus on specific things that could be manifested by statistical metrics. If we could discover and suit the user stage in the multi-task recommendation, we are more likely to improve model performance.", "2.2 Notations and Problem Definition": "Our preliminary analysis verifies that users at different stages conform to various data distributions. Thus, it would be of great help to consider adaptive stage information while conducting multiple recommendation tasks. In our cases, we have a dataset D = n GLYPH<8> ( U \ud835\udc56 , V \ud835\udc57 , \ud835\udc9a \ud835\udc56 \ud835\udc57 ) GLYPH<9> \ud835\udc5b \ud835\udc56 \ud835\udc57 = 1 o \ud835\udc5a \ud835\udc56 = 1 consisting of \ud835\udc5a users, each user \ud835\udc56 exposed to \ud835\udc5b \ud835\udc56 items. The U \ud835\udc56 \u2208 R \ud835\udc51 1 \u00d7 \ud835\udc51 2 represents the user feature matrix, V \ud835\udc57 \u2208 R \ud835\udc51 3 \u00d7 \ud835\udc51 4 represents the item feature matrix. Here, \ud835\udc51 1, \ud835\udc51 3 denote the number of user and item features, respectively, while \ud835\udc51 2 and \ud835\udc51 4 represent the dimensions of user and item features, respectively. Note that in the preprocessing phase, each user attribute is embedded into a \ud835\udc51 3-dimensional vector. A similar preprocessing is conducted for items. The label collection \ud835\udc9a \ud835\udc56 \ud835\udc57 = h \ud835\udc66 1 \ud835\udc56 \ud835\udc57 , . . . , \ud835\udc66 \ud835\udc3e \ud835\udc56 \ud835\udc57 i T \u2208 R \ud835\udc3e includes measurements for \ud835\udc3e concerned tasks, where \ud835\udc66 \ud835\udc58 \ud835\udc56 \ud835\udc57 , \ud835\udc58 = 1 , . . . , \ud835\udc3e corresponds to CTR, staytime, and so on. For the overall preference of user \ud835\udc56 , we compute \ud835\udc9a \ud835\udc56 = 1 \ud835\udc5b \ud835\udc56 \u02dd \ud835\udc5b \ud835\udc56 \ud835\udc57 = 1 h \ud835\udc66 1 \ud835\udc56 \ud835\udc57 , . . . , \ud835\udc66 \ud835\udc3e \ud835\udc56 \ud835\udc57 i T \u2208 R \ud835\udc3e . Note that some user features change over time. In the dataset, the behavior sequence is organized chronologically for each user, but there is no specific order for behavior sequences across different users. Considering \ud835\udc3e recommendation prediction tasks, our goal is to develop a framework that can recommend items while taking user stage information into account to enhance the prediction performance for each task.", "3 PROPOSED METHOD": "In this section, we propose a framework to extract the latent user stage information for enhancing multi-task recommendation. To be more specific, the framework is composed of two parts, as shown in Fig. 4: (i) a multi-task prediction part that learns the representation of the input data for different tasks, and (ii) a latent stage detection part that first grasps user preference. The preference is then applied to depict the latent user stage. Finally, a loss function adaptively adjusts the attention paid to tasks based on the learned user stage. The detailed building blocks and functional meanings are illustrated in the following subsections. 0.01 0.03 0.05 0.07 0.09 0.11 0.00 0.05 0.10 0.15 0.20 0.25 Percentage NewCTR 0.14 0.24 0.34 0.44 0.54 0.64 0.74 0.00 0.05 0.10 0.15 0.20 0.25 WanderCTR 0.14 0.24 0.34 0.44 0.54 0.64 0.74 0.00 0.05 0.10 0.15 0.20 0.25 StickCTR 0.14 0.24 0.34 0.44 0.54 0.64 0.74 0.00 0.05 0.10 0.15 0.20 0.25 LoyalCTR 200 2200 4200 6200 8200 10200 12200 14200 0.00 0.05 0.10 0.15 0.20 0.25 Percentage NewStaytime 100 500 900 1300 1700 0.00 0.05 0.10 0.15 0.20 0.25 WanderStaytime 3400 5400 7400 9400 11400 13400 0.00 0.05 0.10 0.15 0.20 0.25 StickStaytime 3400 5400 7400 9400 11400 13400 0.00 0.05 0.10 0.15 0.20 0.25 LoyalStaytime 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.000 0.167 0.333 0.500 0.667 0.833 1.000 Percentage NewCVR 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.000 0.167 0.333 0.500 0.667 0.833 1.000 WanderCVR 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.000 0.167 0.333 0.500 0.667 0.833 1.000 StickCVR 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.000 0.167 0.333 0.500 0.667 0.833 1.000 LoyalCVR", "3.1 Multi-task Prediction Networks": "In this subsection, we illustrate the components of the multi-task prediction module, which aims to learn the embedding from user and item features by training the backbone network. This network evaluates the difference between the ground truth and the predicted value for each task measurement, as shown on the right-hand side of Fig. 4. In the literature, many multi-task learning models employ one or more shared networks, often referred to as \"experts,\" as the foundation for learning common knowledge among different tasks. While these experts can capture the joint hidden information across tasks, they may suffer from dependencies among tasks and differences in data distribution for various tasks. To address this issue, we follow the approach of [20] and limit the usage of shared experts in the first step. By doing so, we aim to alleviate harmful parameter interference, allowing for more robust learning and better performance in capturing the nuances of different tasks within \u03a5\u03c3\u03b5\u03c1 \u03a6\u03b5\u03b1\u03c4\u03c5\u03c1\u03b5 \u0395\u03be\u03c4\u03c1\u03b1\u03c7\u03c4\u03b9\u03bf\u03bd \u039d\u03b5\u03c4\u03c9\u03bf\u03c1\u03ba \u03a5\u03c3\u03b5\u03c1 \u03a6\u03b5\u03b1\u03c4\u03c5\u03c1\u03b5 \ud835\udc7c \u0399\u03c4\u03b5\u00b5 \u03a6\u03b5\u03b1\u03c4\u03c5\u03c1\u03b5 \ud835\udc7d \u03a4\u03bf\u03c9\u03b5\u03c1 \u0391 \u0391\u03c4\u03c4\u03b5\u03bd\u03c4\u03b9\u03bf\u03bd \u03a4\u03bf\u03c9\u03b5\u03c1 \u0392 \u03a4\u03bf\u03c9\u03b5\u03c1 \u03a7 \u03a3\u03c4\u03b1\u03b3\u03b5 \u2206\u03b5\u03c4\u03b5\u03c7\u03c4\u03b9\u03bf\u03bd \u03a0\u03c1\u03b5\u03c6\u03b5\u03c1\u03b5\u03bd\u03c7\u03b5 \u039b\u03b5\u03b1\u03c1\u03bd\u03b9\u03bd\u03b3 \u039c\u039b\u03a0 \u0391\u03c4\u03c4\u03b5\u03bd\u03c4\u03b9\u03bf\u03bd \u039c\u039b\u03a0 \u0391\u03c4\u03c4\u03b5\u03bd\u03c4\u03b9\u03bf\u03bd \u039c\u039b\u03a0 {\u2112 \ud835\udc94 \ud835\udc8c } \u03a3\u03b1\u00b5\u03c0\u03bb\u03b5 \u03c6\u03c1\u03bf\u00b5 \ud835\udc35\ud835\udc52\ud835\udc61\ud835\udc4e(\ud835\udefc, \ud835\udefd) \u2112 = % \ud835\udc8c \u2112 \ud835\udc94 \ud835\udc8c +\u2112 \ud835\udc95 \ud835\udc8c \u00b7 \u03b3 \ud835\udc8c {\u03b3 \ud835\udc8c } \u03a3\u03c7\u03b1\u03bb\u03b1\u03c1 \u03a6\u03bf\u03c1\u03c9\u03b1\u03c1\u03b4 \u03a7\u03bf\u03bd\u03c7\u03b1\u03c4\u03b5\u03bd\u03b1\u03c4\u03b5 {\u2112 \ud835\udc95 \ud835\udc8c } \u039b\u03bf\u03c3\u03c3 \u039b\u03bf\u03c3\u03c3 \u03a5\u03c3\u03b5\u03c1-\u0399\u03c4\u03b5\u00b5 \u03a6\u03b5\u03b1\u03c4\u03c5\u03c1\u03b5 \u0395\u03be\u03c4\u03c1\u03b1\u03c7\u03c4\u03b9\u03bf\u03bd \u039d\u03b5\u03c4\u03c9\u03bf\u03c1\u03ba \u0395\u03be\u03c0\u03b5\u03c1\u03c4 \u0391 \u03a3\u03b7\u03b1\u03c1\u03b5\u03b4 \u0395\u03be\u03c0\u03b5\u03c1\u03c4 \u0395\u03be\u03c0\u03b5\u03c1\u03c4 \u03a7 \u0395\u03be\u03c0\u03b5\u03c1\u03c4 \u0392 \u0393\u03b1\u03c4\u03b9\u03bd\u03b3 \u039d\u03b5\u03c4\u03c9\u03bf\u03c1\u03ba \u03a3\u03c4\u03b1\u03b3\u03b5 \u03a1\u03b5\u03c0\u03c1\u03b5\u03c3\u03b5\u03bd\u03c4\u03b1\u03c4\u03b9\u03bf\u03bd our multi-task prediction module. We use vec (\u00b7) to represent matrix vectorizaion 2 . With input \ud835\udc99 \ud835\udc56 \ud835\udc57 = [ vec ( U \ud835\udc56 ) T , vec ( V \ud835\udc57 ) T ] T \u2208 R \ud835\udc51 1 \ud835\udc51 2 + \ud835\udc51 3 \ud835\udc51 4 , \ud835\udc56 = 1 , . . . , \ud835\udc5a, \ud835\udc57 = 1 , . . . , \ud835\udc5b \ud835\udc56 , the features are extracted by where \ud835\udc64 \ud835\udc58 \ud835\udc35 is the weighting function in the backbone network which obtains the weighted vector of task \ud835\udc58 by a linear layer with the Softmax activation function, W \ud835\udc58 \ud835\udc35 is the trainable parameter matrix for task \ud835\udc58 in the backbone, \ud835\udc3b \ud835\udc58 ( \ud835\udc99 \ud835\udc56 \ud835\udc57 ) is the combination of the task-specific experts \ud835\udc38\ud835\udc65\ud835\udc5d \ud835\udc58 \ud835\udc60\ud835\udc5d ( \ud835\udc99 \ud835\udc56 \ud835\udc57 ) and shared experts \ud835\udc38\ud835\udc65\ud835\udc5d \ud835\udc60\u210e ( \ud835\udc99 \ud835\udc56 \ud835\udc57 ) . The \ud835\udc54 \ud835\udc58 \ud835\udc35 is the gating network of task \ud835\udc58 , which acts as the selector to calculate the weighted sum of the input. The \u2299 represents the Hadamard (element-wise) product. We could obtain the prediction value of each task \ud835\udc58 as: where \ud835\udc53 \ud835\udc58 \ud835\udc47 denotes the tower network of task \ud835\udc58, \ud835\udc58 = 1 , . . . , \ud835\udc3e . Conventionally, the loss function for multi-task learning can be represented as: where \ud835\udf02 \ud835\udc58 is a hyperparameter and L \ud835\udc58 denotes the task-specific loss function. Typically, \ud835\udf02 \ud835\udc58 is determined by heuristic rules. However, using a fixed \ud835\udf02 \ud835\udc58 may not be suitable for every user, as their preferences for tasks can vary significantly. Furthermore, even for users whose preferences align with \ud835\udf02 \ud835\udc58 , the fixed \ud835\udf02 \ud835\udc58 might lead to performance degradation when their preferences change over time. To address these issues, we propose the user preference learning module and latent user stage representation module, which dynamically adapt to users' preferences and stages.", "3.2 User Preference Learning": "In this subsection, we introduce the method for extracting user preferences to represent latent user stages. Since there are no explicit criteria to distinguish user stages, we can only infer users' stage information from their behaviors. As the user stage can be described by a set of user preferences for all concerned tasks, we first propose a user preference learning module to represent a user's preference. The module consists of three building blocks: (i) a user feature extraction network that extracts more representative features from the input user features U , (ii) a task-specific user representation learning unit that generates the corresponding embedding containing the hidden user preference for each task, and (iii) a task measurement prediction unit that utilizes the task-specific embedding to predict the value for each task. First, the user feature extraction network uses a transformation \ud835\udc53 that generates the user representation U \u2032 \ud835\udc56 , where U \u2032 \ud835\udc56 \u2208 R \ud835\udc51 1 \u00d7 \ud835\udc51 2 , \ud835\udc56 = 1 , . . . , \ud835\udc5b . To capture the relationships between different user features, we employ a self-attention unit [24] as function \ud835\udc53 . The self-attention mechanism excels in modeling long-range dependencies and recognizing important features in the input data, which makes it a suitable choice for extracting user preferences. Specifically, let W \ud835\udc44 U \ud835\udc56 , W \ud835\udc3e U \ud835\udc56 , and W \ud835\udc49 U \ud835\udc56 be the query, key, and value matrices, where W \ud835\udc44 , W \ud835\udc3e , and W \ud835\udc49 are all \ud835\udc51 1 by \ud835\udc51 1 weight matrices. Then, the self-attention mechanism can be written as where \ud835\udc46\ud835\udc5c\ud835\udc53 \ud835\udc61\ud835\udc5a\ud835\udc4e\ud835\udc65 (\u00b7) is the softmax function 3 . Next, another attention unit generates a task-specific user representation according to the importance of different features, inspired by [36]. The attention mechanism effectively captures and emphasizes the importance of various features within the user representation. It allows the model to focus on the most relevant features for each specific task, ultimately leading to more accurate and tailored task-specific user representations. For task \ud835\udc58 , the corresponding embeddings s \ud835\udc58 \ud835\udc56 , \ud835\udc58 = 1 , . . . , \ud835\udc3e , are computed as follows, where the weight matrix W \ud835\udc58 \u2208 R \ud835\udc51 2 \u00d7 \ud835\udc51 2 for task \ud835\udc58 is learned during training. Finally, the task measurement prediction unit takes in the task-specific user embedding to produce predicted values \u02dc \ud835\udc66 \ud835\udc58 \ud835\udc56 for each task. The prediction unit learns to represent the general user preference irrespective of individual items by training with user interactions across all items the user has encountered. Single-layer feed-forward networks MLP \ud835\udc58 (\u00b7) , \ud835\udc58 = 1 , . . . , \ud835\udc3e are used to predict the probability for the user to conduct the corresponding actions. Based on the learned embedding, the output user preference is defined as: To account for the volatility in user behavior, we create a pseudo-label by considering the average behavior value over time for \u02dc \ud835\udc66 \ud835\udc58 \ud835\udc56 . This approach helps the network learn more information while maintaining greater stability: where D \ud835\udc56 = -\ud835\udc5b \ud835\udc56 \u2032 \ud835\udc57 = 1 {( U \ud835\udc56 \u2032 , V \ud835\udc57 , \ud835\udc9a \ud835\udc56 \u2032 )| \ud835\udc56 \u2032 < \ud835\udc56 } is the subset of D containing only the first \ud835\udc56 instances. This method incorporates the user's preferences from the past few days, ensuring a more accurate representation of their recent interests. Subsequently, the loss can be defined as: One advantage of our user preference learning module is that it can capture user preferences without explicit supervision. Moreover, the learned preference representation could be adjusted dynamically as user behaviors change. Thus, the preference modeling process is of great adaptation to user preferences.", "3.3 Latent User Stage Detection": "In this subsection, we develop a latent user stage representation module, drawing inspiration from prior successful RS applications [22, 26]. We regard the output of the user preference module, \u02dc \ud835\udc66 \ud835\udc58 , \ud835\udc58 = 1 , . . . , \ud835\udc3e , as the user's inclination towards task \ud835\udc58 . However, when the number of training samples for a user is limited, the predicted \u02dc \ud835\udc66 \ud835\udc58 may be less informative. Therefore, we introduce the latent user stage representation module to adjust \u02dc \ud835\udc66 \ud835\udc58 and generate a reliable preference, \ud835\udefe \ud835\udc58 , for tasks during subsequent training. More specifically, based on the initial data analysis in Sec. 2, the value \u02dc \ud835\udc66 \ud835\udc58 is assumed to follow a Beta distribution, \ud835\udc35\ud835\udc52\ud835\udc61\ud835\udc4e ( \ud835\udefc, \ud835\udefd ) , i.e., where \ud835\udefc \ud835\udc58 represents the number of trials in which user \ud835\udc62 performs the concerned action in task \ud835\udc58 , and \ud835\udefd \ud835\udc58 represents the number of trials in which user \ud835\udc62 does not perform the action. For example, when considering the task of predicting CTR, \ud835\udefc corresponds to the number of clicks, while \ud835\udefd represents the number of times the user did not click on the item. The parameters \ud835\udefc \ud835\udc58 and \ud835\udefd \ud835\udc58 can be learned during training. As shown in Algorithm 1, the learned user preference toward different tasks will be more reliable as more samples are fed into the latent user stage representation module. With the refined behavior preference distribution \ud835\udc35\ud835\udc52\ud835\udc61\ud835\udc4e ( \ud835\udefc \ud835\udc58 , \ud835\udefd \ud835\udc58 ) , the output \u02dc \ud835\udc66 \ud835\udc58 will be improved owing to a more robust and reliable preference \ud835\udefe \ud835\udc58 . Then, the preference measurement \ud835\udefe \ud835\udc58 is used to control loss importance corresponding to user attention at the current stage. For the task in which the user is less interested, the corresponding loss will be given less attention in the back-propagation process. It could reduce the risk of negative transfer or seesaw phenomenon [20] in the extraction backbone network \ud835\udc53 \ud835\udc35 . Thus, the representation \ud835\udc53 \ud835\udc35 ( \ud835\udc65 ) could be learned across tasks with a concentration on the valuable information about the user for the tasks.", "Algorithm 1 Process of updating \ud835\udc35\ud835\udc52\ud835\udc61\ud835\udc4e ( \ud835\udefc \ud835\udc58 , \ud835\udefd \ud835\udc58 ) and sampling \ud835\udefe \ud835\udc58": "", "Input:": "{( U \ud835\udc56 , \ud835\udc9a \ud835\udc56 )} \ud835\udc5b \ud835\udc56 = 1 . Note that a higher index indicates a time closer to the present.", "Output:": "\ud835\udefe \ud835\udc58 : The series of sampling results, the latent stage representation for task \ud835\udc58 . 2: for all \ud835\udc62 in 1,. . . , m, do 1: for all \ud835\udc58 in 1,. . . , K, do 3: Initialize \ud835\udefc = \ud835\udefd = 1. 4: \ud835\udc58 \ud835\udc58 for all \ud835\udc62 \ud835\udc62 \ud835\udc56 in 1,. . . , n, do 5: if user id of \ud835\udc48 \ud835\udc56 = \ud835\udc62 then 9: 10: 11: end if end for Draw \ud835\udefe 12: 13: end for \ud835\udc58 \ud835\udc35\ud835\udc52\ud835\udc61\ud835\udc4e ( \ud835\udefc \ud835\udc58 end for", "3.4 Loss Function of STAN": "There are two parts of losses in our framework: (i) loss L \ud835\udc58 \ud835\udc61 for multi-task prediction network, and (ii) loss L \ud835\udc58 \ud835\udc60 for stage detection network. Both of them are with respect to task \ud835\udc58, \ud835\udc58 = 1 , . . . , \ud835\udc3e . Thus, we give the overall objective to minimize as a linear combination of the losses with task-specific preference \ud835\udefe \ud835\udc58 : where L \ud835\udc58 \ud835\udc60 ( \u02dc \ud835\udc66 \ud835\udc58 , \ud835\udc59 \ud835\udc58 ) is defined in Eq. 11. Let \ud835\udc66 \ud835\udc58 \ud835\udc56 \u2208 { 0 , 1 } be the label in dataset, the L \ud835\udc58 \ud835\udc61 ( \u02c6 \ud835\udc66 \ud835\udc58 , \ud835\udc66 \ud835\udc58 ) is defined as: Note that the losses for user stage detection and multi-task prediction are optimized simultaneously during training. In this way, the assessment of the user lifecycle stage can be optimized as the loss L decreases. Improved stage representation can aid in enhancing the multi-task recommendation.", "4 EXPERIMENTS": "In this section, we conduct comprehensive offline and online experiments on both large-scale recommendation systems and public benchmark datasets to evaluate the effectiveness of our proposed framework. Our experiments aim to address the following research questions: RQ2: RQ3: RQ1: What is the performance of our proposed method compared with other state-of-art methods? What effect does detecting the user's stage have on prediction results? Is the proposed framework able to effectively detect user lifecycle stages? \ud835\udc62 \ud835\udc62 \ud835\udefe \ud835\udc58 \ud835\udc62 = \ud835\udc50 = 0, from , \ud835\udefd \ud835\udc58 \ud835\udc62 ) . \ud835\udc62", "4.1 Experimental Settings": "In this part, we provide an overview of the dataset descriptions, the baseline methods used for comparison, hyperparameters, and evaluation metrics employed in our experiments.", "4.1.1 Datasets.": "\u00b7 Public dataset 4 : The Wechat-Video dataset is a publicly available dataset containing 7.3 million user interaction samples from the Wechat Channels' Recommendation System, involving a total of 20,000 users. Since no existing dataset provides a comprehensive set of tasks, including CVR, staytime, and CVR prediction, we utilize the most common user interactions in the Wechat-Video dataset, such as like, click avatar, and forward. \u00b7 Industrial dataset: This dataset was collected from an e-commerce platform over a month in 2022. It consists of offline logs from one scenario in the livestreaming recommendation system and is chronologically divided into training, validation, and test sets. Since the staytime of users is a continuous value, we apply equal-frequency binning to the staytime in the dataset for convenience. Further analysis of the dataset can be found in Sec. 2.1. 4.1.2 Baseline Methods. We compare our methods with the following competitive baselines: \u00b7 MLPSingle [6]: A single-task learning model using a basic MLP (multi-layer perceptron) for each task. \u00b7 MLPShared [3]: A shared-bottom model that shares the bottom layer in multi-task learning, implemented by MLP. \u00b7 MMOE [11]: Uses a shared Expert module to extract underlying feature embeddings and applies different gates for each task to obtain varying fusing weights in multi-task learning. \u00b7 PLEvanilla [20]: PLE (Progressive Layered Extraction) explicitly separates task-common and task-specific parameters to avoid parameter conflicts in multi-task learning using Customized Gate Control (CGC) layers. A PLE model consists of multiple CGC layers. \u00b7 AITM [31]: AITM (Adaptive Information Transfer Multi-task) models the sequential dependence among audience multi-step conversions using an information transfer module, focusing on different conversion stages of various audiences. \u00b7 PLEStage : Enhances the vanilla PLE structure by adding pre-knowledge of stage information. Stage information is combined with existing features. PLE is a widely applied baseline in the multi-task recommendation field, and we use it to evaluate the effect of incorporating stage information. To examine the impact of adopting the Beta distribution, we conduct experiments on STAN without the latent stage representation module in Sec. 3.3, named STAN w/o Beta . 4.1.3 Hyper-Parameter. For a fair comparison, we search for optimal parameters on the validation data and evaluate these models on the test data. To ensure a level playing field, we constrain the maximum model size for all methods by setting the same upper bound for the number of hidden units per layer at 1024. For computational efficiency, we assign an embedding dimension of 128 to all methods. We employ ReLU [5] as the activation function for all models. During training, we set the batch size to 2048. The Adam optimizer [8] is used with settings \ud835\udefd 1 = 0.9, \ud835\udefd 2 = 0.999, and \ud835\udf16 = 1 \u00d7 10 -6 . We set the learning rate at 0.001. For the user feature learning function \ud835\udc53 , we adopt a deep neural network (DNN) structure due to its promising ability to extract hidden information from embeddings. Our approach and all baseline methods are implemented using TensorFlow 5 . 4.1.4 Evaluation Metrics. Specifically, we aim to evaluate the proposed work on two fronts: prediction and ranking. For offline experiments, existing works primarily use AUC (Area Under ROC) as the main ranking metric to gauge model performance. However, AUC only evaluates the average ranking performance of the model at all thresholds, disregarding the true user interest for each recommendation feed. Therefore, we apply Normalized Discounted Cumulative Gain (NDCG), which is suitable for evaluating whether users are generally interested in the top recommended items. Due to the specificity of the industrial dataset, the impression history of users is relatively short. In many cases, only a minimal number of impressions are collected. As a result, we use NDCG@1 as the evaluation metric for the industrial dataset. For the public dataset, we use NDCG@5 instead. For comparison, we follow [37] to introduce RelaImpr metric to measure the relative improvement of a measured model over the base model. For a random guesser, the value of AUC is 0.5. Hence RelaImpr for AUC is defined as: For NDCG@ \ud835\udc58 \u2032 ( \ud835\udc58 \u2032 \u2208 { 1 , 5 } in our experiments), the RelaImpr is defined as: In our experiments, we choose \ud835\udc40\ud835\udc3f\ud835\udc43 \ud835\udc46\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc59\ud835\udc52 as the base model.", "4.2 Performance Evaluation": "To answer RQ1 , we conduct experiments to compare the proposed model with the baseline methods. For the public dataset, we consider common actions, including like, click avatar (of the content creator), and forward. For the industrial dataset, we focus on classical RS prediction tasks: CTR, staytime, and CVR. The corresponding results are shown in Table 2 and Table 3, respectively. Firstly, STAN achieves the most effective results on all tasks in both metrics and outperforms all the competitive baselines in the industrial and public datasets. Secondly, the performance of MLPSingle lags behind all of the multi-task methods, indicating the benefit of joint optimization for multi-task learning. Thirdly, by comparing different multi-task learning methods, we observe that the difficulty of optimizing different tasks can vary significantly. The MMOE method only controls knowledge learned by shared-expert layers. Although it improves the MLPShared methods for some tasks, it suffers from a seesaw phenomenon [20] not only in different tasks but also in different metrics for the same task. Thanks to the exploitation of specific-expert layers' learned knowledge, the vanilla PLE model outperforms the former models in most cases. The performance of the AITM method is not consistent across all datasets, which may result from the characteristics of the dataset. It can be seen that previous methods may decrease the NDCG score but increase the AUC score, which would require users to scroll down more times to discover their favorite items. This drawback may result from ignoring user stage information, which overlooks the real needs of the user. Overall, our proposed STAN model achieves significant improvement compared to several state-of-the-art methods, demonstrating the efficiency of introducing adaptively-learned stage information into the recommendation system. In particular, we evaluate the effect of the latent user stage representation module. As shown in the result of STAN w/o Beta , if we apply the predicted \u02dc \ud835\udc66 instead of the preference \ud835\udefe to the overall loss update, the performance experiences greater fluctuation. The reason could be the small number of action histories for the majority of users, as modeling the user's preference based solely on a few actions will lead to unstable results.", "4.3 In-depth Stage Analysis": "To answer RQ2 , we conduct an in-depth analysis to uncover the real impact of incorporating user lifecycle adaptive stage information into the recommendation process. 4.3.1 Benefits of Considering Stages. To assess the benefits of incorporating stage information during training, we first divide the training dataset into three subsets based on user stage information and then perform separate prediction tasks on each of these subsets. We refer to this as StageSingle. The results are presented in Fig. 5. Surprisingly, even though the subsets are significantly smaller than the original training dataset, the performance is nearly the same, and sometimes even better. In this case, each subset is approximately 1/3 of the training dataset. This can be attributed to the fact that stage information helps reduce the number of noisy samples in the entire dataset. In multi-task CTR Staytime CVR 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 AUC MLPSingle Stagesingle STAN CTR Staytime CVR 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 NDCG@1 MLPSingle Stagesingle STAN learning problems, not every sample is useful for all tasks. However, conventional multi-task learning methods train all samples for each task simultaneously, which inevitably introduces noise for specific tasks. By leveraging stage information, multi-task learning methods can reduce the noise caused by instances from other stages during training. Consequently, they can learn more accurate representations, leading to improved performance. 4.3.2 Benefits of Considering Adaptive Stages. Although expert knowledge can be helpful in creating rule-based stage discrimination strategies, these designed rules may not be adaptive to various scenarios in applications, let alone different datasets. Therefore, we compare the performance of PLEStage and STAN in Table 2 and Table 3, representing our framework under conditions of fixed user stage and adaptive user stage, respectively. Generally, utilizing rule-based stage information results in inferior model performance compared to the model that employs adaptive stage information. This can be attributed to the differences in stage sensitivity between the models. As STAN represents the user stage using a learned vector instead of a predefined stage number, it can capture subtle variations in user stages more effectively.", "4.4 Case Study": "To address RQ3 , we visualize the embedding vectors of users at different stages for both public and industrial datasets. For a clearer illustration, we create discrete stage labels by clustering the stage representation vectors. 4.4.1 User Stage Visualization. For each dataset, we randomly select 1,000 user embeddings from the stages divided by the method in Sec. 2.1. Each point in Fig. 6 represents a user with embeddings learned by STAN and PLE, respectively. Each color denotes a type of user stage; since the public dataset is pre-processed by its issuer, there are no users at Stage New . According to Fig. 6, the user embeddings learned by STAN can be more clearly separated from each other compared to those learned by PLE. This demonstrates the effectiveness of STAN in detecting user stages. 4.4.2 User Stage in Change. A user's stage may change as he/she dwells on the platform. The user lifecycle stage detection method should be adaptive to the shift of user stages as their features change. To evaluate this ability, we visualize the detected user stages of the same group of users on the first and last day of our industrial dataset in Fig. 7. The concerned users are highlighted as stars. We find that the same user may exhibit very different behaviors at different times, which indicates different user stages. Take the users in Fig. 7 as an example. At the start, all of them are at stage New . However, one month later, one of them transitions to stage Wander , and the other two STAN PLE Wander Stick Loyal Day 1 Day 31 New Wander Stick Loyal transition to stage Stick . The observed user stage changes indeed highlight the dynamic nature of users' preferences and emphasize the importance of tracking these preferences in multi-task recommendation systems.", "4.5 Online A/B Testing and Deployment": "We carried out rigorous online A/B testing in our e-commerce live streaming scenario from 2023-0315 to 2023-04-04, with a daily average of millions of users. Our proposed STAN model demonstrated significant improvements compared to its predecessor, with a CTR increase of 3.94%, staytime increase of 3.05%, and a CVR increase of 0.88%. Based on these promising results, our model has been fully deployed and now serves the main traffic. It is important to highlight that during the nearly month-long A/B testing, the e-commerce system underwent large-scale promotions, substantially impacting users' decision-making processes and potentially influencing their lifecycle stages. Despite these challenges, STAN's performance improvements remained consistent, further accentuating its effectiveness in managing user preferences in recommendation systems.", "5 DISCUSSION": "In practical applications, it is a widespread industry approach to develop separate models for active and non-active users, often referred to as \"cold-start users\" [16, 19]. The model for non-active users typically aims to boost engagement, while the model for active users concentrates on improving their CVR or Staytime. However, users in the same class can exhibit diverse characteristics. For instance, Alice and Bob, both active on the platform, might have significantly different CVRs, such as 0.7 and 0.2. Thus, we propose a more nuanced approach to capture their preferences, better distinguishing between such users. This approach could benefit other recommendation structures, such as sessionbased user modeling techniques. Session-based recommendation approaches often assume that all labels are correct. However, since the user's preference is uncertain at some stages, user-generated labels at these stages should not be used as deterministic for modeling. In this scenario, incorporating our method could help session-based methods learn from more convincing labels, resulting in a more accurate representation of users' preferences and improved recommendations. The former observation also leads us to another critical aspect largely overlooked in existing research: the trade-off between multiple task objectives. As these objectives are optimized globally for various goals, this approach can result in potential conflicts in gradient optimization. We argue that reducing the conflicts can be achieved by identifying the specific tasks that different users prioritize, allowing for a more tailored recommendation system that adapts to individual user preferences. Building upon these insights, we have designed our experiments to capture the user's recent preference effectively. In our method's overall design, all samples preceding the current sample are used for calculating the average, which is applied to both public and industrial datasets. However, in a real online system, considering a too-long period would lead to higher overhead in storage computation, and behaviors with extended intervals may create perturbations to the current behavior and introduce instability, which is beyond the scope of this paper. Therefore, our online system focuses on behaviors within a 30-day window to calculate the average, ensuring a more accurate and manageable representation of users' recent preferences.", "6 RELATED WORKS": "In this section, we review related work in two main areas: (i) multi-task learning for recommendation systems and (ii) user representation modeling.", "6.1 Interested Tasks on Recommendation Systems": "Existing research on multi-task recommendation systems can be broadly classified into two categories. The first category focuses on user conversion rates [1, 13, 25, 27, 31], which yield significant profits for e-commerce platforms. The most representative user conversion tasks are the ClickThrough Rate (CTR) and Click Conversion Rate (CVR). Some studies, such as [13, 25, 30], propose optimizing these tasks concurrently in a multi-task learning model, aiming to leverage valuable knowledge learned across tasks. However, the inherent divergence between prediction tasks can lead to reduced overall performance when optimizing them simultaneously. To address this issue, recent work [30, 35] has achieved notable success by incorporating scenario knowledge into task prediction. For example, Zhang et al. [35] employed a meta-learning approach to predict tasks across multiple advertising scenarios. However, scenario information alone is insufficient for providing user-specific recommendations. The second category of research aims to engage users on online platforms. Common metrics include user feedback, such as clicks, finishes, and dwell time [20, 29, 33, 38]. Among these, user clicks and dwell time, or staytime, are the most descriptive metrics [28], but they are often overlooked in the context of the first category of work and rarely considered alongside CVR, which is essential for user conversion on online platforms.", "6.2 User Modeling and Representation in Lifecycle": "User modeling is another critical aspect of related work. It has received significant attention as user behavior variations offer valuable insights into user interests, particularly in the context of shifting trends. Some research models users based on their behavior sequences, using either Markov-chain methodologies [18] or deep neural networks [7, 21] to implicitly model user state dynamics and predict resulting behaviors. These methods primarily focus on short-term user modeling constrained by recent behaviors. To identify long-term behavior dependencies works such as [14, 17, 34] have proposed recommendation system models with \"lifelong\" learning capacity. However, these models tend to learn long-term user behaviors coarsely, overlooking differences between various lifecycle stages. Some studies have considered cold-start as a stage of the lifecycle for recommendation system users [2]. While these cold-start frameworks excel in serving new users, their performance diminishes as users mature. Unfortunately, model alteration often leads to user churn and instability in industrial applications.", "7 CONCLUSION": "In this paper, we innovatively introduce the concept of user lifecycle stages to enhance multi-task learning in recommendation systems. We propose STAN, a user lifecycle stage-adaptive framework that models latent stage information. STAN first learns user preferences for various tasks by utilizing user behaviors and then represents latent user stages based on these learned preferences. By incorporating latent user stage information into multi-task recommendations, STAN can identify the most critical task for each user and adjust accordingly as users' interests evolve. Experimental results on public and industrial datasets and online recommendation services demonstrate the effectiveness of our proposed framework. For future work, we plan to explore the application of adaptive stage information in a broader range of contexts, including online social networks, advertising, and search systems.", "REFERENCES": "[1] Ting Bai, Yudong Xiao, Bin Wu, Guojun Yang, Hongyong Yu, and Jian-Yun Nie. 2022. A Contrastive Sharing Model for Multi-Task Recommendation. In Proceedings of the 31st international conference on World Wide Web . 3239-3247."}
