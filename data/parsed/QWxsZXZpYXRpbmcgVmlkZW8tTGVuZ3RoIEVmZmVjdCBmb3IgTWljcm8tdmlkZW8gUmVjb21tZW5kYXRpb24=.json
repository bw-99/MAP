{"Alleviating Video-Length Effect for Micro-video Recommendation": "YUHAN QUAN, Tsinghua University, China JINGTAO DING \u2217 , Tsinghua University, China CHEN GAO, Tsinghua University, China NIAN LI, Tsinghua University, China LINGLING YI, Tencent, China DEPENG JIN, Tsinghua University, China YONG LI, Tsinghua University, China Micro-videos platforms such as TikTok are extremely popular nowadays. One important feature is that users no longer select interested videos from a set, instead they either watch the recommended video or skip to the next one. As a result, the time length of users' watching behavior becomes the most important signal for identifying preferences. However, our empirical data analysis has shown a video-length effect that long videos are easier to receive a higher value of average view time, thus adopting such view-time labels for measuring user preferences can easily induce a biased model that favors the longer videos. In this paper, we propose a V ideo L ength D ebiasing Rec ommendation (VLDRec) method to alleviate such an effect for micro-video recommendation. VLDRec designs the data labeling approach and the sample generation module that better capture user preferences in a view-time oriented manner. It further leverages the multi-task learning technique to jointly optimize the above samples with original biased ones. Extensive experiments show that VLDRec can improve the users' view time by 1.81% and 11.32% on two real-world datasets, given a recommendation list of a fixed overall video length, compared with the best baseline method. Moreover, VLDRec is also more effective in matching users' interests in terms of the video content. CCS Concepts: \u00b7 Information systems \u2192 Recommender systems . Additional Key Words and Phrases: Debias, Micro-video Recommendation, Multi-task Learning", "ACMReference Format:": "Yuhan Quan, Jingtao Ding, Chen Gao, Nian Li, Lingling Yi, Depeng Jin, and Yong Li. 2022. Alleviating VideoLength Effect for Micro-video Recommendation. ACMTrans. Inf. Syst. 37, 4, Article 111 (August 2022), 24 pages. https://doi.org/XXXXXXX.XXXXXXX", "1 INTRODUCTION": "Recommender systems, which can provide items that users may be interested in from a large number of item candidates in a personalized way, are widely deployed nowadays for filtering information or content. Recently, with the help of recommender system, micro-video platforms \u2217 corresponding author Authors' addresses: Yuhan Quan, quanyh15@tsinghua.org.cn, Tsinghua University, Beijing, China; Jingtao Ding, dingjt15@ tsinghua.org.cn, Tsinghua University, Beijing, China; Chen Gao, chgao96@gmail.com, Tsinghua University, Beijing, China; Nian Li, linian21@mails.tsinghua.edu.cn, Tsinghua University, Beijing, China; Lingling Yi, chrisyi@tencent.com, Tencent, Shenzhen, China; Depeng Jin, jindp@tsinghua.edu.cn, Tsinghua University, Beijing, China; Yong Li, liyong07@tsinghua. edu.cn, Tsinghua University, Beijing, China. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \u00a9 2022 Association for Computing Machinery. 1046-8188/2022/8-ART111 $15.00 https://doi.org/XXXXXXX.XXXXXXX 111 (a) Hyped to watch Yuliya Levchenko at Tokyo 320.9K 1802 @Leah Share Yuliya Lev #yuliyalevchenl #highju #athletic #tokyoolympics ttokyo pics20 #2021 #sport @Leah Add comment (b) 1-16 Spot's On It Boston Dynamics 2 AM views 2 months ago 2.20 Why Apple Wants Your Old iPhone Apple Explained 999K views days ago OBJECT DETECTION FULL COURSE NICK.99 such as TikTok 1 have swept the world. In fact, there is a significant gap between the micro-video recommender system with the traditional video platforms, such as YouTube recommendation [7, 8] 2 . In traditional video websites, a user is always shown/recommended a list of videos, and then he/she can select and click one video he/she feels interested in. As we have mentioned above, the new micro-video platform has completely upgraded the pipeline, of which the most representative one is TikTok. As shown in Fig. 1(a)(b), compared with YouTube, the video length is relatively shorter, generally from tens of seconds to several minutes. The brand new paradigm of user-video interaction can be described as: the videos keep continuously playing until the user slides down the screen, after which another video shows in a similar way. This difference in interaction manner has actually caused significant changes in the recommender systems. Specifically, for traditional video recommender systems, the main optimization goal is to increase the user's click-through rate (CTR). If the user clicks on a video, it can be considered that the user is interested in this video and can be seen as a positive signal [7, 25]. However, in the brand new micro-video recommender system, users do not click anymore since the videos are automatically exposed and played. It means the recommender system can no longer obtain the user's interest through the \"click\" behavior. Instead, it can only collect a new kind of feedback, the time length that the user watched the video. An intuitive solution is to first train the model by predicting user-video view time length and then recommending by ranking the predicted results from long ones to short ones. However, users' interactions with longer-length videos are naturally easier to reach longer view time, which results 0 20 40 60 80 100 120 l(seconds) 0.0 0.2 0.4 0.6 0.8 1.0 P(L>=l) All records The last records before exiting in a longer video will be more likely to be recommended with such an intuitive solution. We call this commonly existing phenomenon in micro-video platforms as video-length bias , where the longer-length videos are particularly favored in the above view-time oriented recommendation scenario. Although it seems acceptable for the platform to recommend longer videos and receive a generally higher value of total view-time, the user engagement might be harmed due to the following two reasons. First, long videos are easier to cause user fatigue, which has been confirmed by our empirical data analysis of users' exit behavior in a micro-video platform, Wechat 3 Channels. As shown in Fig. 2, the last watched video before a user exits the platform tends to be longer than other ones. Second, this unfair advantage of long videos during the learning process possibly includes those undesirable or low-quality videos in the major group, which is known as bias amplification and further hurts recommendation accuracy [39]. Therefore, in this paper, we focus on alleviating the above video-length bias for micro-video recommendation. Similar to previous studies of popularity bias and position bias in recommender systems [1, 15], the collected data with video-length bias also exhibits the distorted user preferences, where longer view time might be caused by longer video length instead of user satisfaction. However, this new research problem faces two unique challenges that rule out the off-the-shelf debias solutions in other problems like popularity bias and position bias. First, the continuous characteristics of both video length and view time largely increase the modeling difficulty of unbiased learning 4 . On the one hand, characterizing the effect of a continuous attribute, i.e. , video length in our case, generally requires a suitable quantization to avoid data sparsity. On the other hand, learning with the continuous view-time label may suffer from the extreme values that worsen the variance issue of previous unbiased learning methods like inverse propensity scoring (IPS) [2, 19]. Second, the complex relation between video length and view time makes it non-trivial to identify true user preferences. Generally, in previous studies, the bias factor either impacts the observation probability of a specific item, as in cases of popularity bias or position bias, or correlates with users' intrinsic interests among different item groups, as in the phenomenon of bias amplification. However, in our case of video-length bias, the bias factor, i.e. , the video length, directly impacts the measurement of the preference indicator, i.e. , the view time, making it challenging to define a proper label that can represent user preferences in view-time oriented recommendation scenarios. In this paper, we propose a micro-video recommendation approach named V ideo L ength D ebiasing Rec ommendation (short for VLDRec) to alleviate the video-length effect. To overcome the first challenge of modeling continuous video-length effect and continuous view-time labels, we first devise a suitable video grouping based on video length, which is motivated by an important data observation that videos with similar time lengths have a similar distribution of completion rate. Then we adopt a simple workaround to continuous label issues by following a learning-to-rank modeling framework. In terms of the second challenge in handling the complex relation between video length and view time, we leverage two bias-alleviating data labeling approaches that can better capture users' real preferences regardless of video length. Combined with a length-conditioned sample generation module and a multi-task user preference learning strategy, our proposed VLDRec can achieve an undistorted model training process with the collected view data under a severe video-length bias. Moreover, besides the model training, to ensure fair comparisons regardless of the observed biased video length effect, VLDRec further incorporates a simple but undistorted Top\ud835\udc47 metric for evaluating model performance in the micro-video recommendation. To summarize, the major contributions of this work are as follows: \u00b7 Different from traditional recommender systems, we approach the brand new problem in the micro-video recommendation, of which the biased video length effect widely exists and may worsen the recommendation performance. \u00b7 Motivated by empirical observations regarding the relationship between video length and view time, we propose a novel and general micro-video recommendation method including three parts of bias-alleviating data labeling, length-conditioned sample generation and multi-task user preference learning, which further incorporates a length-invariant Top\ud835\udc47 evaluation metric to alleviate the video length effect in both modeling training and evaluation. \u00b7 We conduct extensive experiments on both public and industrial datasets, and the experimental results demonstrate the effectiveness of our proposed VLDRec method in terms of both longer view time and higher user interest fitness. The rest of this paper is as follows. We discuss the related works in Section 2. In Section 3, we present the motivation from real-world data and formulate the research problem. We then introduce our proposed VLDRec method in detail in Section 4. We conduct experiments in Section 5. Finally, in Section 6, we conclude this paper and discuss the future works.", "2 RELATED WORKS": "", "2.1 Debias in Recommendation": "In the recommender system, bias has a variety of sources [5]. Common bias includes popularity bias [27] which caused by popular items being more exposed, selection bias [28] which caused by the fact that users only select items they are interested in, exposure bias [11] which caused by the fact that users can only interact with exposed items, etc. To alleviate these biases, Inverse propensity scoring (IPS) [2, 19, 29, 32] and its improved methods [4, 16] are the most commonly used debiasing methods, which main idea is lowering the weight of the items which have advantages in the recommended results. Therefore, the model will be less influenced by biased instances. In addition, for the bias caused by missing or noisy data, it is usually solved by the relabel method, including heuristic [34] or model-based methods [30, 43]. Also, IPS and relabel methods can be combined [36]. Besides, there are some recently proposed methods, such as disentangling method [26, 42, 54], counterfactual method [44] or causal graph based method [40, 46, 51]. These methods alleviate the bias by designing unbiased training targets or instances, or adjusting the prediction results of the model based on mathematical principles. These methods all have some effect on the biases they deal with. Although there has been a lot of related work on debiasing recommender system, most of these bias will only affect the display of recommendation results. However, this paper focuses on a different problem where the video length directly affects the label of the samples. Another angle of analyzing possible impact of video-length effect is fairness [22], as the biased modeling among videos of different video-length can induce unfair exposure favoring long videos [21, 37]. Moreover, we notice that there are some concurrent works that proposes a debiasing recommendation method to handle duration bias in micro-video recommender systems [49, 53]. Although this duration bias problem is similar to the aforementioned video length effect, we propose to alleviate the biased effect by following the idea of regularization [5], i.e. , learning intrinsic user preferences from less biased feedback data, while above concurrent work [49] follows the idea of causal inference and another work [53] propose a new unbiased prediction objective remove bias and optimize this objective by adversarial learning. In general, compared to the related work on debiasing in recommender systems, our work follows a data-driven paradigm, designing bias alleviating method motivated by empirical observations instead of directly relying on theories like causal inference, and is optimized for user viewing time goals, which is a key performance indicator in micro-video recommendations. Besides learning method, we further incorporate a length-invariant Top\ud835\udc47 evaluation metric to alleviate the video length effect in both model training and evaluation.", "2.2 Video Recommendation": "Video recommendation is an important topic in the recommender system. In terms of content and user interface, there are some differences between video recommendation and recommender systems suitable for e-commerce, news or other scenarios. On the one hand, due to the large amounts of multimedia information and features in videos, some works try to effectively utilize the visual or multimedia features in videos [6, 48]. These works focus on how to extract effective features or mix multimodal features. On the other hand, in the scenario of video recommendation, some user behaviors and patterns are different from other scenarios, such as accidentally watching behavior [45], dynamic interest [24, 25], purchase intention through disseminating micro-videos [20], multimodal interests [14, 38] and other implicit and explicit feedback [10, 35]. Although there have been various works related to video recommendation, our work does not focus on how to extract and utilize the multimedia features of videos, or user behaviors. We mainly focus on the biased video length effect in recommendation due to changes in the user interface in micro-video platforms and try to alleviate this bias as much as possible, so the recommendation model can accurately identify user preferences.", "3 PROBLEM FORMULATION AND DATA OBSERVATION": "We first give the problem formulation of the micro-video recommendation that mainly aims to maximize users' view time. Then we conduct a preliminary analysis on collected user-video interaction data, which motivates our design of the proposed VLDRec method.", "3.1 Problem Formulation": "Let \ud835\udc48 = { \ud835\udc62 1 , \ud835\udc62 2 , ..., \ud835\udc62 \ud835\udc40 } and \ud835\udc49 = { \ud835\udc63 1 , \ud835\udc63 2 , ...\ud835\udc63 \ud835\udc41 } denote a set of \ud835\udc40 users and a set \ud835\udc41 videos, respectively. The video length of \ud835\udc63 \ud835\udc57 is represented as \ud835\udc59 \ud835\udc57 . For each user \ud835\udc62 \ud835\udc56 \u2208 \ud835\udc48 , given the set of his/her historical interactions \ud835\udc46 \ud835\udc62 \ud835\udc56 , each ( \ud835\udc63 \ud835\udc58 , \ud835\udc61 \ud835\udc56\ud835\udc58 ) \u2208 \ud835\udc46 \ud835\udc62 \ud835\udc56 representing \ud835\udc62 \ud835\udc56 has watched \ud835\udc63 \ud835\udc58 with a length of \ud835\udc61 \ud835\udc56\ud835\udc58 , the target is to recommend a new video \ud835\udc63 \ud835\udc57 \u2208 { \ud835\udc63 \ud835\udc58 | \ud835\udc63 \ud835\udc58 \u2208 \ud835\udc49 \u2227 \ud835\udc63 \ud835\udc58 \u2209 \ud835\udc46 \ud835\udc62 \ud835\udc56 } with the highest view time \u02c6 \ud835\udc61 \ud835\udc56 \ud835\udc57 . Specifically, we formulate this task as a learn-to-rank problem by learning a scoring function \ud835\udc53 ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc57 ) to indicate \ud835\udc62 \ud835\udc56 's preference on \ud835\udc63 \ud835\udc57 , which measures \ud835\udc62 \ud835\udc56 's willingness to watch \ud835\udc63 \ud835\udc57 with a long time \ud835\udc61 \ud835\udc56 \ud835\udc57 instead of skipping to a next recommended video. When user \ud835\udc62 \ud835\udc56 watches a video \ud835\udc63 \ud835\udc58 with time \ud835\udc61 \ud835\udc56\ud835\udc58 , the triplet ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc58 , \ud835\udc61 \ud835\udc56\ud835\udc58 ) is defined as a sample. If \ud835\udc5d \ud835\udc56\ud835\udc58 \u2265 1, then the sample is a completed sample. The notations we use and their descriptions are shown in Table 1.", "3.2 Data Observation": "In order to investigate and understand user behaviors in micro-video recommendation scenarios, we choose two large-scale datasets collected from two leading micro-video platforms, i.e. , Kuaishou 5 and Wechat Channels 6 We leave the detailed descriptions of the above two datasets in Section 5. Here we focus on two indicators of user engagement on recommended micro-videos, i.e. , view time and completion rate [52]. The former is intuitive, but we will highlight its potential bias in favoring longer videos by illustrating its relationship with video length in Fig. 3(a) and (b). Comparatively, the latter counts the proportion of completed plays for a specific video, which is normalized into [ 0 , 1 ] by considering both view time and video length. Mathematically, the completion rate of \ud835\udc63 \ud835\udc57 is equal to the number of completed samples ( i.e. , \ud835\udc61 \u00b7 \ud835\udc57 \u2265 \ud835\udc59 \ud835\udc57 ) divided by the total number of samples corresponding to the video, which is as follows, In Fig. 4, by analyzing the distribution of completion rate ( \ud835\udc5d 25, \ud835\udc5d 50 values) for micro-videos with the same video length, we demonstrate that this metric is much fair when comparing users' preference among micro-videos with similar video length. Specifically, our preliminary analysis has the following two key observations. 0 10 20 30 40 50 60 Video length(seconds) 0 10 20 30 40 Average view time(seconds) (a) Kuaishou 0 20 40 60 80 100 120 Video length(seconds) 0 10 20 30 40 50 60 70 Average view time(seconds) (b) Wechat \u00b7 Long videos are much easier to receive a higher value of average view time. As shown in Fig. 3(a) and (b), real-world data in both KuaiShou and Wechat follow a similar pattern that the average view time is nearly linear to the increasing video length. Consequently, view time is a biased metric when measuring a user's preference on a micro-video without considering the specific video length. This can lead to severe performance degradation when we attempt to capture user preference with traditional approaches like regression. \u00b7 Videos with similar time lengths have a similar distribution of completion rate. As shown in Fig. 4(a) (KuaiShou), by illustrating the \ud835\udc5d 75 (the third quartile, i.e. , ranked at the top 25%) and \ud835\udc5d 50 (the median) distribution values of micro-videos ranging from 1s to 59s, we can roughly divide them into five groups according to video length, with the flat curve within each group representing a similar distribution pattern. Specifically, these five groups are [ 1 -8 \ud835\udc60, 8 -18 \ud835\udc60, 19 \ud835\udc60 -30 \ud835\udc60, 31 \ud835\udc60 -40 \ud835\udc60, 41 -59 \ud835\udc60 ] . For example, we can observe that micro-videos ranging from 30s to 40s tend to have a completion rate of about 0 . 5 ( \ud835\udc5d 75). Similarly for Wechat Channel dataset (Fig. 4(b)), the suitable grouping is [ 0 -13 \ud835\udc60, 14 -20 \ud835\udc60, 21 -30 \ud835\udc60, 31 -41 \ud835\udc60, 42 -59 \ud835\udc60, 60 -92 \ud835\udc60, 93 -120 \ud835\udc60 ] . In a word, to capture unbiased user preference from their viewed micro-videos, one needs to extract pairwise ranking relations conditioned on the video length. In short, there exists a bias of video-length in video-watching behaviors.", "4 METHOD": "The proposed VLDRec method models user preferences in a view-time oriented learning-to-rank manner, where two specific labeling approaches are designed to alleviate the video-length effect that can distort the learned user preference. Motivated by previous analysis regarding to the biased preference signal of view time, VLDRec further integrates a length-conditioned sample generation module, which is jointly optimized via multi-task learning. Moreover, to better evaluate micro-video recommendation models, VLDRec adopts a simple but effective Top\ud835\udc47 evaluation metric that can make fair comparisons regardless of the observed biased video length effect. The overall framework of VLDRec is shown in fig 5. 0 10 20 30 40 50 60 Video length 0.0 0.2 0.4 0.6 0.8 1.0 Completion rate Top25% Top50% (a) Kuaishou 0 20 40 60 80 100 120 Video length 0.0 0.2 0.4 0.6 0.8 1.0 Completion rate Top25% Top50% (b) Wechat \ud835\udc63\ud835\udc58 \ud835\udc63\ud835\udc57 \ud835\udc63\ud835\udc58 \ud835\udc62\ud835\udc5b Embedding \ud835\udc62\ud835\udc56 [\ud835\udc96\ud835\udc56 \ud835\udc97\ud835\udc8c] [\ud835\udc96\ud835\udc56 \ud835\udc97\ud835\udc57 ] [\ud835\udc96\ud835\udc56 \ud835\udc97\ud835\udc58 \ud835\udc62\ud835\udc5b ] Feed forward Network \ud835\udc53 \u2112 \u0ddc \ud835\udc66 Sample generation \u21122 \u21121 Modeling Feed forward Network \ud835\udc53 \ud835\udc62\ud835\udc5b \u2026 historical interactions sampling grouping General sample Length-conditioned sample", "4.1 Labeling Approach for View-time Oriented Learning-to-rank": "For the micro-video recommendation problem defined in Section 3.1, we adopt a learning-to-rank approach that trains a model to recommend micro-videos with a large probability of generating user engagements, i.e. , views. Generally, to learn recommender models from implicit feedback, Rendle et al. [31] proposed the Bayesian Personalized Ranking (BPR) method, which assumes that a positive instance should be predicted with a much higher score over the negative one. Based on BPR, the training objective of the recommender model can be formulated as minimizing the following loss function: where \ud835\udc63 \ud835\udc58 \u223c \u02c6 \u03a8 \ud835\udc62\ud835\udc5b\ud835\udc56 ( \ud835\udc46 -\ud835\udc62 \ud835\udc56 ,\ud835\udc63 \ud835\udc57 ) . For each user \ud835\udc62 \ud835\udc56 , the predicted preference score on micro-videos is denoted as \ud835\udc53 ( \ud835\udc62 \ud835\udc56 , \u00b7) . The negative instance \ud835\udc63 \ud835\udc58 is generated by a uniform sampler \u02c6 \u03a8 \ud835\udc62\ud835\udc5b\ud835\udc56 that takes the candidate set \ud835\udc46 -\ud835\udc62 \ud835\udc56 ,\ud835\udc63 \ud835\udc57 as an input, while the positive instance \ud835\udc56 is randomly chosen from ground truth set \ud835\udc46 \ud835\udc62 \ud835\udc56 . Minimizing \ud835\udc3f \ud835\udc35\ud835\udc43\ud835\udc45 is equivalent to maximizing the margin between \ud835\udc53 ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc57 ) and \ud835\udc53 ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc58 ) , which encourages the recommender to learn the pairwise ranking relation of user preference between \ud835\udc63 \ud835\udc57 and \ud835\udc63 \ud835\udc58 . Therefore, an intuitive solution for solving the micro-video recommendation problem is directly putting the instances with longer view time ahead of those with a shorter length. Specifically, when \ud835\udc46 -\ud835\udc62 \ud835\udc56 ,\ud835\udc63 \ud835\udc57 is the set of past instances with shorter view time than current positive instance ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc57 ) , i.e. , {( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc58 )| \ud835\udc61 \ud835\udc56\ud835\udc58 < \ud835\udc61 \ud835\udc56 \ud835\udc57 } , the trained model is able to recommend micro-videos that may be watched longer by users. However, as we discussed in the preliminary analysis, the indicator of view time suffers from the biased video length effect by favoring longer videos, which may cause the distortion of learned user preference. In our proposed VLDRec model, we instead choose to measure user preference based on another indicator of play progress, i.e. , \ud835\udc5d \ud835\udc56 \ud835\udc57 = \ud835\udc61 \ud835\udc56 \ud835\udc57 / \ud835\udc59 \ud835\udc57 . Specifically, we adopt two different definitions of progress-based labels. The first is pointwise hard labeling depending on whether \ud835\udc5d \ud835\udc56 \ud835\udc57 exceeds a certain threshold \ud835\udf0f . Motivated by the previous observation that videos with similar time lengths have a similar distribution of completion rate, we set \ud835\udf0f as \ud835\udf0f ( \ud835\udc59 \ud835\udc57 ) , relevant to the video length \ud835\udc59 \ud835\udc57 . According to our analysis in Fig. 4, the micro-videos can be divided into several groups based on their length, i.e. , { \ud835\udc54 1 , \ud835\udc54 2 , ...\ud835\udc54 \ud835\udc49 } , where \ud835\udc49 is 5 (KuaiShou) and 7 (WeChat Channel), respectively. For these two datasets, we decided the boundary value of video length in each group by checking whether at least one of Top-25% and Top-50% curves in Fig. 4 would go through a significant change ( i.e. , from decreasing to non-decreasing or from increasing to non-increasing) at this point compared with neighboring points This operation is performed manually. Thus we allow videos within the same group sharing the same \ud835\udf0f = \ud835\udf0f ( \ud835\udc59 \ud835\udc57 ) = \ud835\udf0f ( \ud835\udc54 ) . Without loss of generality, \ud835\udf0f ( \ud835\udc54 ) for each group is set as \ud835\udc5d 80 value of the play progress distribution. In other words, the top 20% samples ranked by their play progress values are considered as positive instances under this pointwise hard labeling. Besides, we also use another pairwise margin-based labeling. It sets a constraint that there should exist a margin \ud835\udf16 between the progress values of a positive instance ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc57 ) and a negative instance ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc58 ) , i.e. , satisfying \ud835\udc5d \ud835\udc56 \ud835\udc57 -\ud835\udc5d \ud835\udc56\ud835\udc58 > \ud835\udf16 . Compared with the above pointwise hard labeling, this pairwise labeling focuses on comparing two samples belonging to the same user, which is more friendly to users with rich interaction history. Therefore, we leverage the advantages of both two approaches by switching between them, which is controlled by hyper-parameters \ud835\udefd . In Fig. 6, we plot the positive and negative sample distribution under the above three labeling strategies, respectively, in terms of both video length (x-axis) and view time (y-axis). Specifically, we uniformly sample 2,000 training samples in one epoch to obtain the population. As illustrated in Fig. 6(a), negative samples tend to be located in the bottom-left corner, i.e. , with both short video length and short view time. While for our proposed two strategies, the distribution of negative samples extends from bottom left to upper right, indicating a better discriminative capability of the learned model, as videos with long duration and long view time can also be possibly chosen as negative samples. Compared with the pointwise hard labeling (Fig. 6(b)), the pairwise marginbased labeling (Fig. 6(c)) generates more similar distributions among positive samples and negative samples, which both have multiple centers of both positive and negative samples, and can serve as a complement to the former. -20 0 20 40 60 80 video length -25 0 25 50 75 100 view time pos. pos. distribution neg. neg. distribution -20 0 20 40 60 80 video length -25 0 25 50 75 100 view time pos. pos. distribution neg. neg. distribution -20 0 20 40 60 80 video length -25 0 25 50 75 100 view time pos. pos. distribution neg. neg. distribution", "4.2 Length-conditioned Sample Generation": "Our previous observation shows that completion rate distribution stays stable conditioned on the video length. Thus it is reasonable to draw a conclusion that, among two micro-videos with similar time length, a user favors the one with higher play progress ( i.e. , longer view time). Inspired by this, we are able to alleviate biased video length effect by learning pairwise rank relations among videos within the same group, which is achieved by a length-conditioned sample generation module. Specifically, for each sample ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc57 ) , we additionally choose a video \ud835\udc63 \ud835\udc62\ud835\udc5b \ud835\udc58 from the group corresponding to video \ud835\udc63 \ud835\udc57 to construct another training pair. The labels of \ud835\udc63 \ud835\udc57 and \ud835\udc63 \ud835\udc62\ud835\udc5b \ud835\udc58 are defined similarly as introduced before. The complete process of generating training samples is shown in Algorithm 1, which contains two parts of samples, one with video length effect and the other with alleviated effect. Specifically, if current training pair uses the pointwise hard labeling, the candidate sets for sampling \ud835\udc46 -\ud835\udc62 \ud835\udc56 ,\ud835\udc63 \ud835\udc57 are {( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc58 )|( \ud835\udc61 \ud835\udc56\ud835\udc58 < \ud835\udf0f ( \ud835\udc54 ) \u2227 \ud835\udc61 \ud835\udc56 \ud835\udc57 > \ud835\udf0f ( \ud835\udc54 )) \u2228 ( \ud835\udc61 \ud835\udc56\ud835\udc58 > \ud835\udf0f ( \ud835\udc54 ) \u2227 \ud835\udc61 \ud835\udc56 \ud835\udc57 < \ud835\udf0f ( \ud835\udc54 ))} and {( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc62\ud835\udc5b \ud835\udc58 )|( \ud835\udc61 \ud835\udc56\ud835\udc58 < \ud835\udf0f ( \ud835\udc54 ) \u2227 \ud835\udc61 \ud835\udc56 \ud835\udc57 > \ud835\udf0f ( \ud835\udc54 ) \u2227 \ud835\udc63 \ud835\udc62\ud835\udc5b \ud835\udc58 \u2208 \ud835\udc54 ( \ud835\udc63 \ud835\udc57 )) \u2228 ( \ud835\udc61 \ud835\udc56\ud835\udc58 > \ud835\udf0f ( \ud835\udc54 ) \u2227 \ud835\udc61 \ud835\udc56 \ud835\udc57 < \ud835\udf0f ( \ud835\udc54 ) \u2227 \ud835\udc63 \ud835\udc62\ud835\udc5b \ud835\udc58 \u2208 \ud835\udc54 ( \ud835\udc63 \ud835\udc57 ))} . Otherwise, current training pair uses the pairwise margin-based labeling, and \ud835\udc46 -\ud835\udc62 \ud835\udc56 ,\ud835\udc63 \ud835\udc57 are {( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc58 )|| \ud835\udc5d \ud835\udc56\ud835\udc58 -\ud835\udc5d \ud835\udc56 \ud835\udc57 | > \ud835\udf16 } and {( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc62\ud835\udc5b \ud835\udc58 )|| \ud835\udc5d \ud835\udc56\ud835\udc58 -\ud835\udc5d \ud835\udc56 \ud835\udc57 | > \ud835\udf16 \u2227 \ud835\udc63 \ud835\udc62\ud835\udc5b \ud835\udc58 \u2208 \ud835\udc54 ( \ud835\udc63 \ud835\udc57 )} .", "Algorithm 1 Length-conditioned Sample Generation Algorithm": "", "Require: Positive instance ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc57 ) , where \ud835\udc63 \ud835\udc57 \u2208 \ud835\udc54 \ud835\udc63 and hyper parameter \ud835\udefd , \ud835\udf0f , \ud835\udf16": "1: p = rand() 2: if \ud835\udc5d < \ud835\udefd then 3: //General sample 4: sample \ud835\udc63 \ud835\udc58 from \ud835\udc46 \ud835\udc62 \ud835\udc56 where ( \ud835\udc61 \ud835\udc56\ud835\udc58 < \ud835\udf0f ( \ud835\udc54 ) \u2227 \ud835\udc61 \ud835\udc56 \ud835\udc57 > \ud835\udf0f ( \ud835\udc54 )) \u2228 ( \ud835\udc61 \ud835\udc56\ud835\udc58 > \ud835\udf0f ( \ud835\udc54 ) \u2227 \ud835\udc61 \ud835\udc56 \ud835\udc57 < \ud835\udf0f ( \ud835\udc54 )) 5: // Length-conditioned 6: sample \ud835\udc63 \ud835\udc62\ud835\udc5b \ud835\udc58 from \ud835\udc46 \ud835\udc62 \ud835\udc56 \u2229 \ud835\udc54 \ud835\udc63 where ( \ud835\udc61 \ud835\udc56\ud835\udc58 < \ud835\udf0f ( \ud835\udc54 \ud835\udc63 ) \u2227 \ud835\udc61 \ud835\udc56 \ud835\udc57 > \ud835\udf0f ( \ud835\udc54 \ud835\udc63 )) \u2228 ( \ud835\udc61 \ud835\udc56\ud835\udc58 > \ud835\udf0f ( \ud835\udc54 \ud835\udc63 ) \u2227 \ud835\udc61 \ud835\udc56 \ud835\udc57 < \ud835\udf0f ( \ud835\udc54 \ud835\udc63 )) 7: else 8: //General sample 9: sample \ud835\udc63 \ud835\udc58 from \ud835\udc46 \ud835\udc62 \ud835\udc56 where GLYPH<12> GLYPH<12> \ud835\udc5d \ud835\udc56 \ud835\udc57 -\ud835\udc5d \ud835\udc56\ud835\udc58 GLYPH<12> GLYPH<12> > \ud835\udf16 10: // Length-conditioned 11: sample \ud835\udc63 \ud835\udc62\ud835\udc5b \ud835\udc58 from \ud835\udc46 \ud835\udc62 \ud835\udc56 \u2229 \ud835\udc54 \ud835\udc63 where GLYPH<12> GLYPH<12> \ud835\udc5d \ud835\udc56 \ud835\udc57 -\ud835\udc5d \ud835\udc56\ud835\udc58 GLYPH<12> GLYPH<12> > \ud835\udf16 12: end if 13: return Positive instance ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc57 ) and negative instances ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc58 ) , ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc62\ud835\udc5b \ud835\udc58 )", "4.3 Multi-task User Preference Learning": "In this part, we design a multi-task learning model that enables joint optimization with two parts of samples. Specifically, it contains a shared embedding module and two independent feedforward neural networks (FNN) used for learning and predicting user preference from two types of samples, respectively. First, for instances ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc57 ) , ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc58 ) , ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc62\ud835\udc5b \ud835\udc58 ) , the shared embedding module outputs ( u \ud835\udc56 , v \ud835\udc57 ) , ( u \ud835\udc56 , v \ud835\udc58 ) and ( u \ud835\udc56 , v \ud835\udc62\ud835\udc5b \ud835\udc58 ) through a embedding map. These embeddings are further constructed into two training pairs, i.e. , {( u \ud835\udc56 , v \ud835\udc57 ) , ( u \ud835\udc56 , v \ud835\udc58 )} and {( u \ud835\udc56 , v \ud835\udc57 ) , ( u \ud835\udc56 , v \ud835\udc62\ud835\udc5b \ud835\udc58 )} . Then, the corresponding FNNfor each training pair can generate the preference scores that are used for training or prediction. Note that these two networks do not share model parameters, and can be any commonly used recommendation models like NFM [18], DeepFM [17], AutoInt [33] etc. Finally, a multi-task learning based training process is conducted to jointly learn user preference from both two parts of training samples, i.e. , one with biased observation affected by video length and the other with debiased manipulation. Here we use the aforementioned BPR loss [31], and then add the two losses by linear weighting to get the final loss and use it for backpropagation. The formula is as follows, where \ud835\udc53 and \ud835\udc53 \ud835\udc62\ud835\udc5b respectively denote the model used for two parts of training data. So far, we have completed the training process of VLDRec, and the overall procedure is shown in Algorithm 2.", "4.4 Length-invariant Top\ud835\udc47 Evaluation Metric": "In both literatures and practices on personalized recommender systems [41, 47], Top\ud835\udc3e based metrics are widely used for evaluating models, such as \ud835\udc45\ud835\udc52\ud835\udc50\ud835\udc4e\ud835\udc59\ud835\udc59 @ \ud835\udc3e or \ud835\udc41\ud835\udc37\ud835\udc36\ud835\udc3a @ \ud835\udc3e . However, in micro-video recommendation scenarios, as mentioned above, users can only watch one video at a time and the video is automatically played, so the objective is to maximize users' total view time, which depends on whether the recommendation model can capture the real user preference instead of the distorted one based on biased observations ( i.e. , longer videos receive longer view time.). Specifically, imagine an extreme case where a model always recommends micro-videos with a long", "Algorithm 2 Overall procedure of VLDRec": "Require: \ud835\udc48 , \ud835\udc49 , { \ud835\udc59 \ud835\udc57 } and training instances { \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc57 , \ud835\udc61 \ud835\udc56 \ud835\udc57 } , Randomly initialize \ud835\udf03 1: calculate \ud835\udc36\ud835\udc5c\ud835\udc5a\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b _ \ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52 \ud835\udc63 for \ud835\udc63 \u2208 \ud835\udc49 2: generate video groups { \ud835\udc54 \ud835\udc63 } 3: while \ud835\udc46\ud835\udc61\ud835\udc5c\ud835\udc5d\ud835\udc5d\ud835\udc56\ud835\udc5b\ud835\udc54 \ud835\udc50\ud835\udc5f\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc56\ud835\udc4e \ud835\udc56\ud835\udc60 \ud835\udc5b\ud835\udc5c\ud835\udc61 \ud835\udc5a\ud835\udc52\ud835\udc61 do 4: generate negative instances ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc58 ) , ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc62\ud835\udc5b \ud835\udc58 ) by Algorithm 1 for positive instance ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc57 ) 5: calculate \ud835\udc3f 1, \ud835\udc3f 2 and \ud835\udc3f by Equation 3 6: update model parameter \ud835\udf03 by minimizing \ud835\udc3f 7: end while length, a user's \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @ \ud835\udc3e , which is defined as may still be fairly good even if she completes none of the recommended micro-videos. Therefore, we argue that Top\ud835\udc3e based metric is not suitable for view-time oriented recommendation tasks. To better evaluate micro-video recommendation models from a fair angle, we propose a new Top\ud835\udc47 recommendation protocol where each time a list of videos are recommended and the total length of these videos is fixed as \ud835\udc47 , while the list length \ud835\udc3e can be a variable. Mathematically, the metric \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @ \ud835\udc47 is defined as follows, If the total video length exceeds \ud835\udc47 , the last video length and the corresponding user's view time will be adjusted proportionally, so that the total video length exactly equals \ud835\udc47 . Compared with \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @ \ud835\udc3e , \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @ \ud835\udc47 emphasizes the importance of play progress, which penalizes the extreme case where only long videos are recommended but the corresponding play progress is low. However, it is noteworthy that, though similar, \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @ \ud835\udc47 is intrinsically different from the average progress metric, as it gives a comprehensive account of both play progress and total view time.", "4.5 Discussion": "Regarding the video length bias problem in micro video recommendations, as mentioned above, there have been some related works. While the methods used may vary, the common objective is to mitigate the influence of video length on the recommendation model. From the perspective of causal inference, video length is a confounder between user and video. Therefore, the key to alleviating the bias is to alleviate the impact of the confounder. Existing related works attempt to achieve this by employing backdoor adjustment [49] or designing prediction targets independent of video length [53]. In our research, we conducted empirical data analysis and discovered that longer videos tend to have a higher average view time. Interestingly, this finding has also been directly utilized as prior information in two other related works [49, 53]. Consequently, our approach to mitigating the confounding effect involves generating length-conditioned samples to construct unbiased data sets. Notably, this idea aligns with the theoretical support for causal inference, which is also shared by the related works.", "5 EXPERIMENTS": "We aim to answer the following three research questions (RQ) in experiments. \u00b7 RQ1 : How does our proposed VLDRec model perform compared with state-of-the-art microvideo recommendation methods. More specifically, does VLDRec successfully alleviate the video length effect that troubles common practice in previous solutions? \u00b7 RQ2 : Whether the modules of our model can work well, including the debias sampling strategy and the multi-task learning based model design. \u00b7 RQ3 : Can the VLDRec capture user preference on micro-videos, in terms of other dimensions besides view time?", "5.1 Experimental Settings": "5.1.1 Dataset and data preprocessing. Weconduct extensive experiments on two real-world datasets collected from popular micro-video applications, Kuaishou and Wechat Channels. The Kuaishou dataset is a public dataset 7 that has been used in the previous work [23]. Since the optimization goal of this work is the user's click behavior rather than the viewing time, which is different from our task, we do not use this work as our baseline. Wechat dataset is collected from real industrial scenarios. Besides, we only keep the instances that users have clicked and watched, as those non-click videos are not watched and do not match the optimization objective in the micro-video recommendation task. It should be noted that in the original data, the WeChat dataset contains timestamps but the Kuaishou dataset does not contain them. Therefore, data analysis like Table 2 can only be performed on the WeChat dataset. It is noteworthy that in micro-video applications, each video is automatically played. Unless the user slides down to the next video, the current video will be played repeatedly. Therefore, samples that are played too many times may be abnormal and we deleted samples where the video is played more than 3 times( \ud835\udc5d \ud835\udc56 \ud835\udc57 > 3) repeatedly in two datasets. At the same time, according to the difference among the datasets, we deleted a small number of samples where the video length is very long. In the two datasets, the threshold is set to 60 seconds and 120 seconds, respectively. Table 2 summarizes some basic information about the datasets we used. Since the two datasets do not contain the timestamp, we randomly split 10% as the validation set and 20% as the test set. According to the length of the video, we divided the Kuaishou and Wechat datasets into 5 and 7 groups respectively. More details about grouping have been described in section 4.1. The features we use include \ud835\udc62\ud835\udc60\ud835\udc52\ud835\udc5f _ \ud835\udc56\ud835\udc51 , \ud835\udc63\ud835\udc56\ud835\udc51\ud835\udc52\ud835\udc5c _ \ud835\udc56\ud835\udc51 and \ud835\udc63\ud835\udc56\ud835\udc51\ud835\udc52\ud835\udc5c _ \ud835\udc59\ud835\udc52\ud835\udc5b\ud835\udc54\ud835\udc61\u210e , as we aim to evaluate the proposed VLDRec model in a general experimental setting. 5.1.2 Baseline. We compare the proposed VLDRec with three categories of baseline methods. The first category is two regression-based methods that are widely used in industrial micro-video recommender systems. \u00b7 TimeRegression (TReg) . This is an intuitive method that takes the length of time the user watched the video as the target( \ud835\udc61 \ud835\udc56 \ud835\udc57 ), and sorts according to the predicted view time, so as to obtain the final recommendation result. \u00b7 RateRegression (RReg) . This baseline regresses the view progress of each sample( \ud835\udc5d \ud835\udc56 \ud835\udc57 ), and then the predicted view time is obtained by multiplying the predicted score by the video length. The next category is two ranking-based methods that follow a similar idea of learning-to-rank as ours in solving micro-video recommendation task. \u00b7 TimeRanking (TRank) . This method learns to rank according to the view time of the instances, where the negative instances are randomly sampled from the videos watched by the user of the positive instance. Based on our proposed multi-task learning framework, only biased datasets are used for ranking training in this method, that is, the weight of multi-task is set to 0. It is a de-generated model that there is no unbiased dataset to help learn unbiased representations, directly ranking the samples on the biased dataset may cause a large bias in the recommended model obtained by training. \u00b7 RateRanking (RRank) . This method learns to rank according to the play progress of the instances and its sampling strategy is consistent with the TimeRanking method. It should be noted that since the prediction score obtained by the ranking method is not an accurate value, it does not need to be multiplied by the video length, but is directly used for ranking and recommendation. The final category is five unbiased recommendation methods that try to learn an unbiased recommender model by removing the video length effect. \u00b7 IPS [19, 32]. The inverse propensity score method estimates the bias by re-weight each instance. For those items that have a greater advantage in recommendation due to bias, the IPS method reduces the weight of these instances to achieve a balance in recommendation results. In our experiment, the weight of each instance is set to the inverse of the video length of each instance; that is, the longer the video length, the lower the weight of the instance. \u00b7 IPS-C [4]. This method uses max capping to limit the value of IPS, so that the range of IPS values is limited, thereby reducing the variance of the score and enhancing the stability of the model \u00b7 IPS-CN [16]. On the basis of max capping, this method normalizes the value of IPS, so that the variance of the IPS score is further reduced. \u00b7 IPS-CNSR [16]. On the basis of normalization, this method adds smoothing operations for the value of IPS. \u00b7 CausE [3]. It is trained through a large biased dataset and a small unbiased dataset. By using two models to model two datasets respectively, and using L2 regularization to constrain the embedding of the two models, so the impact of the bias of the model can be reduced. In our experiment, the unbiased dataset is obtained by sampling from the same group of the video of the positive instance, which is consistent with part of our VLDRec model. \u00b7 DecRS [39]. The algorithm avoids the impact of confounder by inserting a backdoor adjustment operator into the existing model and solves the problem of infinite sample space through an approximation algorithm. \u00b7 DVR [53]. This algorithm designs a new unbiased metric named WTG as the prediction target, and trains the model through adversarial learning. 5.1.3 Evaluation Method. Since the proposed VLDRec is mainly aimed at the ranking stage in recommendation, we only use the collected records to construct recommendation lists. For the samples in the test set, we first aggregated them according to \ud835\udc62\ud835\udc60\ud835\udc52\ud835\udc5f _ \ud835\udc56\ud835\udc51 . Then, for each user, a recommendation list is generated by sorting candidate micro-videos according to prediction scores and selecting the top ones. The final evaluation metrics are obtained by first calculating per-user value and then averaging among all users. First of all, we mainly use view time metrics in experiments, including \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @ \ud835\udc47 and \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @ \ud835\udc3e , where the former is less affected by biased observations and formally defined in Section 4.4. Although \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @ \ud835\udc3e favors longer videos and cannot reflect users' real preferences, we still use this metric to highlight the spurious goodness-of-fit of prevailing solutions. Moreover, besides the view time, we also leverage category information of micro-videos to measure whether our recommendation reflects users' actual preferences. Specifically, for Top\ud835\udc3e recommended videos of each user, we calculate size of intersection and Jensen-Shannon divergence ( \ud835\udc3d\ud835\udc46\ud835\udc37 ) [12] by comparing them with the actual Top\ud835\udc3e viewed videos ordered by view time. The first metric size of intersection is in [ 0 , \ud835\udc3e ] . As for \ud835\udc3d\ud835\udc46\ud835\udc37 , it is defined as where \ud835\udc3b is the Shannon entropy, \ud835\udc43 and \ud835\udc44 are distributions. Lower \ud835\udc3d\ud835\udc46\ud835\udc37 denotes a closer distribution between the recommendation and real data, indicating a better reflection of user preference. 5.1.4 Implementation Detail. For all methods, we use NFM [18], DeepFM [17] and AutoInt [33] as base model. The embedding size for each feature of all methods is set to 8 and the batch size is set to 1024. The number of hidden layers of the deep part of NFM model is set to { 32 , 16 } . For the regression method, we use MSE loss. In all experiments, we use the Adam optimizer. Hyper parameters such as learning rate and dropout are obtained through grid search. The search ranges are shown in Table 3. The code and dataset are avaliable 8 .", "5.2 Performance Comparison (RQ1)": "5.2.1 Overall Performance. The overall experimental results are shown in the Table 4, Table 5, Table 6 and Table 7 w.r.t. \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @ \ud835\udc47 . From the above results, we have the following observations: \u00b7 VLDRec significantly improves the recommendation performance by alleviating the video length effect and capturing real user preferences regardless of the video length. Comparedwiththebest-performed baseline, it outperforms by 1.81% and 11.32% w.r.t. \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @120 in Kuaishou and Wechat with NFM as the base model, respectively. At the same time, when using DeepFM and AutoInt as the base model, VLDRec also achieved at least 5.49% and 7.31% improvements w.r.t. \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @120, respectively. It demonstrates that actively removing the biased effects introduced by video length is vital for learning user preferences among different micro-videos. \u00b7 VLDRec better resists the noisy preference signal in biased observation. Corresponding to our aforementioned problem of using view time based signal, we observe the significant performance degradation with two regression methods that are common practice in most companies, i.e. , TimeRegression and RateRegression. Specifically, VLDRec outperforms the best of them by 25.66% in Kuaishou and 137.30% in Wechat w.r.t. \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @120 with NFM as the base model. At the same time, VLDRec outperforms the best of them 92.04% and 17.56% with DeepFM and AutoInt as the base model. The observed huge performance gap demonstrates that directly using observed view time (or play progress) as the label can be biased and lead to distorted preference learning. Contrastively, VLDRec successfully bypasses this by learning pairwise ranking relations of user preferences among micro-videos with similar time lengths. \u00b7 VLDRec further improves the informativeness of training samples by selecting training pairs conditioned on video length. By choosing pairs of micro-videos with similar time lengths, VLDRec not only alleviates the existing bias in observed data but also leverages the advantage of hard negative sampling that is proven to be useful in improving recommendation performance [9, 50]. Intuitively, for a specific sample ( \ud835\udc62 \ud835\udc56 , \ud835\udc63 \ud835\udc57 ) , choosing a negative sample from the same group as \ud835\udc63 \ud835\udc57 is much more informative for model learning than a different group where video length is shorter. Therefore, compared with those unbiased learning baselines including IPS-based, CausE, DecRS and DVR, VLDRec outperforms by a large margin. Specifically, IPSbased methods suffer from the large variance issue, resulting in unstable performance as shown in Table 4, Table 5, Table 6 and Table 7. As for CausE, DecRS, and DVR they perform fairly competitively but cannot beat VLDRec, as it is not elaborately designed for a view time oriented recommendation task. 5.2.2 Biased Learning of Common Practice. The above performance comparison has demonstrated the superiority of VLDRec in recommending micro-videos that indeed match user interest and thus generate user engagement. In this part, we further answer the question on how VLDRec alleviates the video length effect that existed in previous solutions. We first present the recommendation performances of each video-length group ( i.e. , { \ud835\udc54 \ud835\udc63 } ) w.r.t. \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @ \ud835\udc3e . Specifically, for each user, only top\ud835\udc3e micro videos belonging to a certain group are recommended and \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @ \ud835\udc3e is used for evaluation. As the recommended videos are of a similar time length, \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @ \ud835\udc3e is freed from the aforementioned problem of favoring longer videos. As shown in Table 8 and Table 9, surprisingly, we observe that TimeRegression, RateRegression and DecRS perform rather competitively in each video group. Specifically, for Kuaishou Dataset, TimeRegression and RateRegression methods beat VLDRec in all five groups and DecRS beats VLDRec in four groups. As for Wechat Dataset, DecRS beats VLDRec in all groups, while TimeRegression outperforms in longer video groups (60 - 120s) and RateRegression outperforms in shorter ones (0 - 59s). The above observation implies that these methods are able to learn user preferences among micro-videos with similar time lengths, even better than the proposed VLDRec. However, this is in conflict with the overall performance comparison in Table 4, Table 5, Table 6 and Table 7, where regression based methods are reported to suffer from significant performance degradation and DecRS doesn't perform well. To further explain the above contradictory phenomena, we analyze the distribution of model prediction scores generated by regression methods and VLDRec in Fig. 7 and Fig. 8. Specifically, we normalize the prediction scores of all test set samples generated by each method and then calculate the mean score and standard deviation of each video group. As shown in Fig. 7, we can observe that the average prediction score of TimeRegression and RateRegression increases with the video time length, which is similar to the observation from empirical data that longer videos generally have longer watch time (See Fig. 3.). This indicates a good fit to the training data, which, however, does not guarantee a precise recommendation that matches user preference. Further in Fig. 8, when looking at the variation of scores ( i.e. , standard deviation), the regression methods still have an increasing standard deviation as the video length increases, and low value of variation in short video groups indicates a centralized prediction distribution. In summary, regression models achieve a good fit of distribution in terms of mean score and their predictions exhibit a rather centralized characteristic in terms of standard deviation, which means they are fairly precise in each video group but cannot overcome the intrinsic problem that longer videos tend to be ranked higher regardless of the actual user preference. Contrastively, the proposed VLDRec has a relatively stable distribution of both mean score and standard deviation among all video groups. Specifically, VLDRec generates almost equal mean scores among all video groups. Also, its standard deviation is higher than regression models, indicating that a micro-video assumed to be preferred by a certain user can be ranked higher even if this video just lasts less than 10s. Therefore, VLDRec is less influenced by the video length and is able to distinguish micro-videos that users are truly interested in and not interested in. Comparatively, industrial recommender systems normally rely on ranking with a fusion of multiple objectives (like a linear combination of two scores from TimeRegression and RateRegression) to alleviate the video-length effect in their recommendation results [52], which is less elegant and requires a huge manual effort for tuning fusion-related hyperparameters. 1~8 s 9~18 s 19~30 s 31~40 s 41~59 s Video group 0.00 0.15 0.30 0.45 0.60 0.75 0.90 Mean normalized score TimeRegression RateRegression VLDRec (a) Mean normalized scores 1~8 s 9~18 s 19~30 s 31~40 s 41~59 s Video group 0.00 0.04 0.08 0.12 0.16 0.20 0.24 Standard deviation TimeRegression RateRegression VLDRec (b) Standard deviation Mean normalized score 0.90 0.75 0.60 0.45 0.30 0.15 0.00 0~13 s 14~20 s TimeRegression RateRegression VLDRec 21~30 s 31~41 s 42~59 s 60-92 s Video group (a) Mean normalized scores 0~13 s 14~20 s 21~30 s 31~41 s 42~59 s 60-92 s 93~120 s Video group 0.00 0.04 0.08 0.12 0.16 0.20 0.24 Standard deviation TimeRegression RateRegression VLDRec (b) Standard deviation", "5.3 Ablation Study (RQ2)": "5.3.1 Performance on Different Sampling Strategy. In the process of instance generation, we proposed two sampling methods. The pointwise hard labeling based sampling and the pairwise margin-based labeling based sampling. The former focuses on characterizing the overall distribution between positive instances and negative instances, while the latter strengthens the modeling of preference rankings of the same user. We use hyper-parameter \ud835\udefd to control the sampling strategy. In order to verify the effect of the sampling strategy, we adjust the value of \ud835\udefd to observe changes in performance and show the result w.r.t. \ud835\udc49\ud835\udc56\ud835\udc52\ud835\udc64 _ \ud835\udc47\ud835\udc56\ud835\udc5a\ud835\udc52 @ \ud835\udc47 in Fig. 9 (a). We can observe that the overall trend is rising first and then falling, which proves that the two sampling methods we proposed based on different objectives can effectively model the user's preferences and improve the performance of the model. 5.3.2 Performance on Different Weight of Multitask Learning. To alleviate the biased video length effect, VLDRec additionally learns to rank among positive and negative instances within the same video group and uses the multi-task learning strategy for training. To verify the effectiveness of this module, we adjust the hyper-parameter \ud835\udefc of the multi-task learning strategy and illustrate the results in figure 9 (b). It can be observed that the performance of the model is the best when \ud835\udefc = 0 . 5. Model performance degrades when \ud835\udefc increases or decreases, which means that the model has achieved a balance between the two goals of alleviating bias and fitting the data distribution, thereby improving the recommendation performance.", "5.4 Study of Model Capability for Capturing User Preference (RQ3)": "In terms of the model capability of learning user preferences on micro-videos, besides measuring the overall view time of users, another important dimension is to look at the micro-video content. In other words, the content of recommended micro-videos needs to match the user's interests. In this section, we analyze how exactly the recommendation results of different methods match the user's interests. Specifically, we use the video category information to verify the model's 93~120 s 0.1 0.3 0.5 0.7 0.9 \u03b2 41 42 43 44 45 46 47 view_time@120 78 79 80 81 82 83 84 view_time@240 view_time@120 view_time@240 (a) sampling strategy 0.1 0.3 0.5 0.7 0.9 \u03b1 41 42 43 44 45 46 47 view_time@120 78 79 80 81 82 83 84 view_time@240 view_time@120 view_time@240 (b) multitask learning TReg RReg TRank RRank IPS CausE DecRS VLDRec 2.0 2.2 2.4 2.6 2.8 3.0 Size of the intersection Size of the intersection JS divergence 0.00 0.02 0.04 0.06 0.08 JS divergence capability of capturing user interests, and this information is only available in Wechat dataset. Firstly, on an individual level, for each user, we compare the categories of the top five videos in the recommendation result with the categories of the five videos that the user actually watched the longest, and calculate the size of intersection . The larger the size of intersection , the recommendation results are closer to the user's preference. Results are shown in Fig. 10, where we can observe that the average size of intersection of our VLDRec method is the largest. The RateRegression method performs the worst, and the performance of other methods are also significantly worse than our proposed method. This means that the videos recommended by VLDRec are similar to the user's preference. Secondly, on a group level, for all users, we aggregate the top five videos recommended by the model and the videos that users actually watched the longest into two collections, respectively. To measure the similarity between these two micro-video distributions, we use the JSD metric. The smaller the JSD value, the higher the similarity between the two distributions. As shown in Fig. 10, we can observe that VLDRec has the smallest JSD value, while the regression method and DecRS perform poorly overall. In a word, VLDRec can effectively match the user's interests, and thus the recommendation results are more similar to the user's historical preference both at the individual and group level, while the common practices in many companies like regression based models only capture the biased preference that are strengthened by video length effect, as a result, its recommendation results cannot effectively match the interests of users.", "6 CONCLUSION AND FUTURE WORK": "In this paper, we aim to tackle the previously untouched problem of video-length effect in recommender systems for online micro-video platforms. We analyze the causes of the video-length effect and propose a VLDRec method for improving micro-video recommendation. By grouping the videos and designing the length-conditioned sampling method, we are able to generate unbiased pairs of training samples and learn the unbiased interests of users through a multi-task learning framework. Experimental results on both public and industrial datasets have proven the superiority of our method over previous solutions in terms of capturing real user preferences in collected user-video view data under a severe video-length bias. Micro-video recommendation scenario differs from traditional scenarios from sample generation to evaluation due to the different user interfaces of online applications. In this work, we have made some explorations in above areas and we believe that, in the future, more in-depth studies are required, such as how to automatically define the preference labels in a smarter way. More importantly, since it is mainly the change of user interface that has spawned new problems of video-length effect, possible research works related to Computer-Human Interaction (CHI) seem necessary to expedite the problem resolution. Last but not least, building a new unbiased dataset with randomly exposed videos [13] can also help understand user behavior and make better recommendations.", "ACKNOWLEDGMENTS": "This work is supported by the National Key Research and Development Program of China under grant 2020YFA0711403. This work is also supported by National Natural Science Foundation of China under 62272262, U22B2057, 62171260.", "REFERENCES": "[1] Himan Abdollahpouri, Masoud Mansoury, Robin Burke, and Bamshad Mobasher. 2020. The connection between popularity bias, calibration, and fairness in recommendation. In RecSys . 726-731. [2] Qingyao Ai, Keping Bi, Cheng Luo, Jiafeng Guo, and W Bruce Croft. 2018. Unbiased learning to rank with unbiased propensity estimation. In SIGIR . 385-394. [3] Stephen Bonner and Flavian Vasile. 2018. Causal embeddings for recommendation. In RecSys . 104-112. [4] L\u00e9on Bottou, Jonas Peters, Joaquin Qui\u00f1onero-Candela, Denis X Charles, D Max Chickering, Elon Portugaly, Dipankar Ray, Patrice Simard, and Ed Snelson. 2013. Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising. Journal of Machine Learning Research 14, 11 (2013). [5] Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan He. 2020. Bias and debias in recommender system: A survey and future directions. arXiv preprint arXiv:2010.03240 (2020). [6] Jingyuan Chen, Hanwang Zhang, Xiangnan He, Liqiang Nie, Wei Liu, and Tat-Seng Chua. 2017. Attentive collaborative filtering: Multimedia recommendation with item-and component-level attention. In SIGIR . 335-344. [7] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks for youtube recommendations. In RecSys . 191-198. [8] James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet, Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, et al. 2010. The YouTube video recommendation system. In ResSys . 293-296. [9] Jingtao Ding, Yuhan Quan, Xiangnan He, Yong Li, and Depeng Jin. 2019. Reinforced Negative Sampling for Recommendation with Exposure Data.. In IJCAI . 2230-2236. [10] Jingtao Ding, Yuhan Quan, Quanming Yao, Yong Li, and Depeng Jin. 2020. Simplify and robustify negative sampling for implicit collaborative filtering. Advances in Neural Information Processing Systems 33 (2020), 1094-1105. [11] Jingtao Ding, Guanghui Yu, Yong Li, Xiangnan He, and Depeng Jin. 2020. Improving implicit recommender systems with auxiliary data. ACM Transactions on Information Systems (TOIS) 38, 1 (2020), 1-27. [12] Bent Fuglede and Flemming Topsoe. 2004. Jensen-Shannon divergence and Hilbert space embedding. In International Symposium on Information Theory (ISIT) . IEEE, 31. [13] Chongming Gao, Shijun Li, Yuan Zhang, Jiawei Chen, Biao Li, Wenqiang Lei, Peng Jiang, and Xiangnan He. 2022. KuaiRand: An Unbiased Sequential Recommendation Dataset with Randomly Exposed Videos. In CIKM . 3953-3957. [14] Chen Gao, Yu Zheng, Nian Li, Yinfeng Li, Yingrong Qin, Jinghua Piao, Yuhan Quan, Jianxin Chang, Depeng Jin, Xiangnan He, et al. 2023. A survey of graph neural networks for recommender systems: challenges, methods, and directions. ACM Transactions on Recommender Systems 1, 1 (2023), 1-51. [15] Chen Gao, Yu Zheng, Wenjie Wang, Fuli Feng, Xiangnan He, and Yong Li. 2022. Causal Inference in Recommender Systems: A Survey and Future Directions. arXiv preprint arXiv:2208.12397 (2022). [16] Alois Gruson, Praveen Chandar, Christophe Charbuillet, James McInerney, Samantha Hansen, Damien Tardieu, and Ben Carterette. 2019. Offline evaluation to make decisions about playlistrecommendation algorithms. In WSDM . 420-428. [17] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247 (2017). [18] Xiangnan He and Tat-Seng Chua. 2017. Neural factorization machines for sparse predictive analytics. In SIGIR . 355-364. [19] Thorsten Joachims, Adith Swaminathan, and Tobias Schnabel. 2017. Unbiased learning-to-rank with biased feedback. In WSDM . 781-789. [20] Chenyi Lei, Yong Liu, Lingzi Zhang, Guoxin Wang, Haihong Tang, Houqiang Li, and Chunyan Miao. 2021. SEMI: A Sequential Multi-Modal Information Transfer Network for E-Commerce Micro-Video Recommendations. In KDD . 3161-3171. [21] Yunqi Li, Hanxiong Chen, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2021. User-oriented fairness in recommendation. In WWW . 624-632. [22] Yunqi Li, Hanxiong Chen, Shuyuan Xu, Yingqiang Ge, Juntao Tan, Shuchang Liu, and Yongfeng Zhang. 2022. Fairness in Recommendation: A Survey. arXiv preprint arXiv:2205.13619 (2022). [23] Yongqi Li, Meng Liu, Jianhua Yin, Chaoran Cui, Xin-Shun Xu, and Liqiang Nie. 2019. Routing micro-videos via a temporal graph-guided recommendation system. In MM . 1464-1472. [24] Wei Lu, Fu-Lai Chung, Wenhao Jiang, Martin Ester, and Wei Liu. 2018. A deep Bayesian tensor-based system for video recommendation. ACM Transactions on Information Systems (TOIS) 37, 1 (2018), 1-22. [25] Yujie Lu, Yingxuan Huang, Shengyu Zhang, Wei Han, Hui Chen, Zhou Zhao, and Fei Wu. 2021. Multi-trends Enhanced Dynamic Micro-video Recommendation. arXiv preprint arXiv:2110.03902 (2021). [26] Jianxin Ma, Chang Zhou, Peng Cui, Hongxia Yang, and Wenwu Zhu. 2019. Learning disentangled representations for recommendation. arXiv preprint arXiv:1910.14238 (2019). [27] Elisa Mena-Maldonado, Roc\u00edo Ca\u00f1amares, Pablo Castells, Yongli Ren, and Mark Sanderson. 2021. Popularity Bias in False-positive Metrics for Recommender Systems Evaluation. ACM Transactions on Information Systems (TOIS) 39, 3 (2021), 1-43. [28] Aditya Pal, F Maxwell Harper, and Joseph A Konstan. 2012. Exploring question selection bias to identify experts and potential experts in community question answering. ACM Transactions on Information Systems (TOIS) 30, 2 (2012), 1-28. [29] Zhen Qin, Suming J Chen, Donald Metzler, Yongwoo Noh, Jingzheng Qin, and Xuanhui Wang. 2020. Attribute-based propensity for unbiased learning in recommender systems: Algorithm and case studies. In KDD . 2359-2367. [30] Yuhan Quan, Jingtao Ding, Chen Gao, Lingling Yi, Depeng Jin, and Yong Li. 2023. Robust Preference-Guided Denoising for Graph based Social Recommendation. In Proceedings of the ACM Web Conference 2023 . 1097-1108. [31] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2012. BPR: Bayesian personalized ranking from implicit feedback. arXiv preprint arXiv:1205.2618 (2012). [32] Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and Thorsten Joachims. 2016. Recommendations as treatments: Debiasing learning and evaluation. In ICML . PMLR, 1670-1679. [33] Weiping Song, Chence Shi, Zhiping Xiao, Zhijian Duan, Yewen Xu, Ming Zhang, and Jian Tang. 2019. Autoint: Automatic feature interaction learning via self-attentive neural networks. In CIKM . 1161-1170. [34] Harald Steck. 2010. Training and testing of recommender systems on data missing not at random. In KDD . 713-722."}
