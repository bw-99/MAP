{"Modeling User Intent Beyond Trigger: Incorporating Uncertainty for Trigger-Induced Recommendation": "Jianxing Ma majianxing.mjx@alibaba-inc.com Alibaba Group Hangzhou, Zhejiang, China Zhibo Xiao xiaozhibo.xzb@alibaba-inc.com Alibaba Group Hangzhou, Zhejiang, China", "Hansheng Xue": "", "Xuanzhou Liu": "hansheng.xue@nus.edu.sg National University of Singapore Singapore liuxuanzhou.lxz@alibaba-inc.com Alibaba Group Hangzhou, Zhejiang, China Wei Ning wei.ningw@alibaba-inc.com Alibaba Group Hangzhou, Zhejiang, China Luwei Yang \u2217 luwei.ylw@alibaba-inc.com Alibaba Group Hangzhou, Zhejiang, China Wen Jiang wen.jiangw@alibaba-inc.com Alibaba Group Hangzhou, Zhejiang, China Guannan Zhang zgn138592@alibaba-inc.com Alibaba Group Hangzhou, Zhejiang, China", "ABSTRACT": "To cater to users' desire for an immersive browsing experience, numerous e-commerce platforms provide various recommendation scenarios, with a focus on Trigger-Induced Recommendation (TIR) tasks. However, the majority of current TIR methods heavily rely on the trigger item to understand user intent, lacking a higher-level exploration and exploitation of user intent (e.g., popular items and complementary items), which may result in an overly convergent understanding of users' short-term intent and can be detrimental to users' long-term purchasing experiences. Moreover, users' shortterm intent shows uncertainty and is affected by various factors such as browsing context and historical behaviors, which poses challenges to user intent modeling. To address these challenges, we propose a novel model called D eep U ncertainty I ntent N etwork ( DUIN ), comprising three essential modules: i) Explicit Intent Exploit Module extracting explicit user intent using the contrastive learning paradigm; ii) Latent Intent Explore Module exploring latent user intent by leveraging the multi-view relationships between items; iii) Intent Uncertainty Measurement Module offering a distributional estimation and capturing the uncertainty associated with user intent. Experiments on three real-world datasets demonstrate the superior performance of DUIN compared to existing baselines. Notably, DUIN has been deployed across all TIR scenarios in our e-commerce platform, with online A/B testing results conclusively validating its superiority. \u2217 Corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference acronym 'XX, June 03-05, 2018, Woodstock, NY \u00a9 2018 ACM. ACM ISBN 978-1-4503-XXXX-X/18/06 https://doi.org/XXXXXXX.XXXXXXX", "CCS CONCEPTS": "\u00b7 Information systems \u2192 Personalization ; Recommender systems ; Learning to rank .", "KEYWORDS": "Click-Through Rate Prediction, Trigger-Induced Recommendation, Contrastive Learning, User Intent Modeling", "ACMReference Format:": "Jianxing Ma, Zhibo Xiao, Luwei Yang, Hansheng Xue, Xuanzhou Liu, Wen Jiang, Wei Ning, and Guannan Zhang. 2018. Modeling User Intent Beyond Trigger: Incorporating Uncertainty for Trigger-Induced Recommendation. In Proceedings of Make sure to enter the correct conference title from your rights confirmation emai (Conference acronym 'XX). ACM, New York, NY, USA, 9 pages. https://doi.org/XXXXXXX.XXXXXXX", "1 INTRODUCTION": "Trigger-Induced Recommendation (TIR) [22, 33, 35] has recently attracted significant industry attention for its ability to deliver immersive user experiences by modeling the instant history of user clicks on trigger items. For instance, as one of the world's largest Business-to-business (B2B) e-commerce platforms, Alibaba.com 1 also provides users with many TIR scenarios. As illustrated in Figure 1, by clicking a trigger item in Just for You scenario, users can access some TIR scenarios, e.g., Mini Detail or Detail Recommendation . The primary objective of TIR is to recommend items satisfying users' needs on conditional of the instant clicking of the trigger item. Nowadays, TIR is playing an increasingly significant role in many industries [22, 36]. More than half of active buyers on our website are contributed by TIR among all recommendation scenarios. Traditional recommendation modeling methods [5, 13, 15, 19, 28] often focus on modeling user chronological behaviors with various deep neural networks [14, 25, 39], lacking consideration for the trigger item, and thus cannot be directly applied to the TIR scenario. Recently, several trigger-based methods [22, 35, 36] have 1 https://www.alibaba.com/ Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Figure 1: Recommendation scenarios of an e-commerce platform. Left: Just for You. Middle: Mini Detail. Right: Detail Recommendation. Scroll down Click into Trigger item Trigger-Induced Recommendation Scenarios Mini Detail Detail Recommendation Just for you Products Manufacturers Acces: Criginal phone i14 Pro Mar CNY41,16 CNY47.98 CnY175.91 - CNY49.76 CNY1386 Details Similar products from this supplier CNY3.20 Jiscover more from this supplier CNY6,40 CNY19.91 been proposed for the TIR task, which have demonstrated their superiority over traditional methods in the TIR scenario. Nonetheless, user behaviors in real-world e-commerce platforms are more complex [12, 20, 30, 40]. Figure 2a shows an insightful example of users' subsequent behaviors after clicking a trigger item. When users clicked on a keyboard, 46 . 9% of users subsequently purchased the same or similar items (e.g., another keyboard), while 30 . 8% of them bought trending products (e.g., wireless keyboard) and the rest 22 . 3% of them bought complementary options (e.g., wireless mouse). This observation reveals that user intent after clicking on a trigger item exhibits a certain degree of uncertainty. This also indicates a need for the platform to offer more precise and comprehensive procurement recommendations. However, as shown in Figure 2b, existing TIR methods overly rely on the trigger item, neglecting deeper exploration and exploitation of user intent, which results in an excessively convergent understanding of user intent, and the user will be isolated in a small set of recommended items from the trigger item. For users purchasing computer accessories, products like keyboards and wireless mice are within their intended scope, the overly narrow recommendations can hinder the optimization of users' long-term purchasing experience. Furthermore, user intent is shaped by a multitude of factors, such as user historical interactions and browsing context. This complexity presents a significant challenge in accurately modeling user intent and capturing the associated uncertainty. To address these challenges, we propose a novel model in this paper called DUIN 2 , short for D eep U ncertainty I ntent N etwork. It primarily comprises three components. To extract explicit user intent based on the trigger, we design an Explicit Intent Exploit Module (EIEM) that uses the contrastive learning paradigm to obtain generalizable and distinguishable intent representations. We also design a Latent Intent Explore Module (LIEM) to effectively explore the users' underlying intent by leveraging the multi-view relationships between items, applicable to both the trigger item and the target item. An Intent Uncertainty Measurement Module (IUMM) is implemented to model user intent intensity as a Gaussian distribution, capturing the uncertainty associated with user intent. Overall, the contributions of this paper can be summarized as follows: 2 The source code of DUIN will be released at: https://github.com/majx1997/DUIN. Jianxing Ma et al. Keyboard Wireless Mouse Trigger item P ( Intent | trigger, context ) Ratio: 46.9% Ratio: 30.8% Ratio: 22.3% Ratio: 31.4% Ratio: 23.2% Ratio: 45.3% Keyboard Wireless Mouse Trigger item Intent = f ( trigger ) (a) DUIN (b) Existing TIR methods Figure 2: Differences in user intent modeling between existing TIR methods and DUIN. The black dashed frame are similar items, red indicates complementary items, and blue denotes trending items. Ratio denotes the proportion of purchasing users. Best viewed in color. \u00b7 Wepropose a novel model, Deep Uncertainty Intent Network (DUIN), to address the uncertainty challenges of user intent modeling in Trigger-Induced Recommendation. \u00b7 We introduce an Explicit Intent Exploit Module to extract explicit user intent, and also a Latent Intent Explore Module to explore latent user intent. \u00b7 We design a new Intent Uncertainty Measurement Module to offer distribution estimates and capture the uncertainty of user intent. \u00b7 Extensive experiments on three real-world datasets and an industrial platform demonstrate the superior performance of our model compared to state-of-the-art baselines.", "2 RELATED WORK": "User behavior Modeling . Existing user behavior modeling approaches [8, 18, 23, 42] primarily focus on learning better representation from user behavior sequences and extracting the users' interests for personalized recommendation. In particular, attention mechanisms[11, 24, 26, 31, 38] have gained popularity in recent years due to their ability to capture complex patterns and temporal dynamics manifested within behavior sequences. For example, DIN [42] utilizes attention mechanisms to activate the interest relation between historical behaviors and the target item. DIEN [41] further integrates a special attention structure with a GRU module to capture the dynamic evolution of user interests. DSIN [6] divides user's sequential behaviors into multiple sessions and employs a self-attention layer to model inner-session interests, alongside a bidirectional LSTM to capture intra-session interests. DMIN [34] explores user's multiple diverse interests and introduces a multi-head self-attention layer and a multi-interest extractor layer to represent user's interests by multiple vectors. These attention-based methods have demonstrated feasible performance across various scenarios. Although the aforementioned recommendation approaches can be directly applied to TIR scenarios, their inability to account for modeling user's immediate intent representing by the trigger item leads to challenges in accurately estimating user intent in real-world industrial scenarios. Modeling User Intent Beyond Trigger: Incorporating Uncertainty for Trigger-Induced Recommendation Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Trigger-Induced Recommendation . Though above traditional solutions can be rigidly applied to TIR scenarios, the lack of considering the trigger item usually make them get suboptiomal results in these scenarios. Recently, various methods have been proposed to target for the TIR problem. DIHN [22] is one pioneer in introducing the TIR task, and utilizes a deep network to predict the user's real intent regarding the trigger item. DIAN [33] proposes an intention-aware network to extract the user's intention and balance the outcomes of trigger-free and trigger-based recommendations. DEI2N [35] introduces a user instant interest modeling layer to forecast the dynamic change in the intensity of instant interest when the user clicks on a trigger item and scrolls down. These existing works have showcased their superiority over traditional methods in the TIR scenario. However, the heavy reliance of these recently proposed methods on trigger items limits their capacity to capture the intricate and higher-level relationships in user behavior. As a result, they may fail to fully reveal the extent of user's true intent, potentially leading to an overly convergent understanding of user intent. This limitation could adversely affect users' long-term experiences.", "3 METHOD": "The overall architecture of the proposed DUIN is illustrated in Figure 3, which mainly consists of three modules: Explicit Intent Exploit Module (EIEM), Latent Intent Explore Module (LIEM), and Intent Uncertainty Measurement Module (IUMM). Before diving into the details of these modules, we first formulate the TIR task and introduce some necessary notations.", "3.1 Problem Setup": "Let U = { \ud835\udc62 1 , \ud835\udc62 2 , ..., \ud835\udc62 \ud835\udc40 } and I = { \ud835\udc56 1 , \ud835\udc56 2 , ..., \ud835\udc56 \ud835\udc41 } represent the user set and the item set, respectively. Each user has a behavior sequence S \ud835\udc62 = { \ud835\udc56 \ud835\udc62 1 , \ud835\udc56 \ud835\udc62 2 , ..., \ud835\udc56 \ud835\udc62 \ud835\udc47 } , where \ud835\udc40 , \ud835\udc41 , and \ud835\udc47 denote the number of users, items, and the length of behavior sequences, respectively. We denote user profile features as \ud835\udc62 \ud835\udc5d and context features as \ud835\udc62 \ud835\udc50 . Based on these notations, given the trigger item \ud835\udc56 \ud835\udc61\ud835\udc5f , the primary objective of TIR is to predict the probability \u02c6 \ud835\udc66 of user \ud835\udc62 potentially interacting with the target item \ud835\udc56 \ud835\udc61\ud835\udc4e as follows:  where F \ud835\udf03 represents the prediction function we aim to learn. The notation E (\u00b7) \u2208 R \ud835\udc51 denotes the embedding layer [5], which transforms raw features into dense vectors with dimension \ud835\udc51 .", "3.2 Deep Uncertainty Intent Network": "3.2.1 Explicit Intent Exploit Module . User chronological behaviors exhibit causality and convey explicit intent information, including aspects users are inclined to interact with, such as brand, theme and category. The trigger item merely represents a partial expression of user explicit intent. In DUIN, we introduce the Explicit Intent Exploit Module to learn user explicit intent. Typically, items with identical attributes exhibit a high degree of similarity. For instance, in the e-commerce scenario, products that belong to the same category often share similar intrinsic quality or interacted uses. In user behavior sequences, we consider items that share attributes with the trigger item express the user explicit intent. Given a trigger item \ud835\udc56 \ud835\udc61\ud835\udc5f , we retrieve items from the behavior sequence S \ud835\udc62 that have the same attribute as \ud835\udc56 \ud835\udc61\ud835\udc5f . Together with the trigger item, these form an explicit intent sequence S \ud835\udc52 :  where \ud835\udc56 \ud835\udc52 \ud835\udc59 denotes items that share the same attribute with the trigger item \ud835\udc56 \ud835\udc61\ud835\udc5f . \ud835\udc3f represents the number of \ud835\udc56 \ud835\udc52 \ud835\udc59 . Various attention-based methods [10, 42] have significantly facilitated user behavior modeling. However, recent research [4, 21, 37] indicates that user representations generated by these methods tend to degenerate into an anisotropic shape, which may result in high semantic similarities among representations. To address this issue, inspired by recent advances of contrastive learning paradigm in the computer vision [2, 3], based on the explicit intent sequence, we apply contrastive learning to obtain discriminative and highquality user explicit intent representations. Formally, the explicit intent contrastive learning task can be defined as:  where L \ud835\udc60\ud835\udc60\ud835\udc59 is the contrastive loss function. \ud835\udc53 \ud835\udf03 is the shared encoder. e S \ud835\udc52 + is the augmented view of the explicit intent sequence S \ud835\udc52 . In practice, we mask the explicit intent sequence S \ud835\udc52 with a certain probability to get the augmented view:  where A(\u00b7) denotes the augmentation operator and \ud835\udefe is the mask probability. The idea behind this is that user explicit intent is relatively stable during a period of time. Therefore, though some of the items are masked, the explicit intent information is still retained and should be considered as the positive view. Thus, we treat (S \ud835\udc52 , e S \ud835\udc52 + ) as positive view pairs and other augmented examples within the same batch as negative views e S \ud835\udc52 -. Furthermore, we adopt the shared encoder \ud835\udc53 \ud835\udf03 to extract the user explicit intent representation H \ud835\udc52\ud835\udc56 = \ud835\udc53 \ud835\udf03 ( \ud835\udc46 \ud835\udc52 ) . We optimize \ud835\udc53 \ud835\udf03 via a contrastive loss function [2], which can be formulated as:  where H + \ud835\udc52\ud835\udc56 and H \ud835\udc52\ud835\udc56 indicate the augmented positive view and the negative views of H \ud835\udc52\ud835\udc56 respectively. \ud835\udc60\ud835\udc56\ud835\udc5a (\u00b7) denotes the cosine similarity function. \ud835\udc35 is the batch size. \ud835\udf0f is the temperature parameter. It is worth mentioning that EIEM also introduces a feature interaction module to learn the explicit interaction relationship between the target item \ud835\udc56 \ud835\udc61\ud835\udc4e and the user explicit intent H \ud835\udc52\ud835\udc56 , the output representation H \ud835\udc56 is calculated as:  where \u2299 denotes the Hadamard product. 3.2.2 Latent Intent Explore Module . As aforementioned, users have various latent intents after clicking on the trigger item, such as seeking similar items, popular items, or complementary items. Previous TIR methods [22, 33, 35] lack exploration of user latent intent and overlook the potential information related to user intent within user behavior sequences. In DUIN, we propose the Latent Intent Explore Module to reveal user latent intent. Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Jianxing Ma et al. Figure 3: The architecture of DUIN consists of three modules, EIEM, LIEM and IUMM. User Profile User Context Embedding Layer \ud835\udcdb \ud835\udc94\ud835\udc94\ud835\udc8d (\ud835\udc3b !\" \u00b1 , \ud835\udc3b !\" ) Concat & Flatten MLP \ud835\udca9(\ud835\udf07 $ , \ud835\udef4 $ \ud835\udc3c) \ud835\udc53 ! \" Shared Encoder \ud835\udc53 % Shared Encoder \ud835\udc53 % Explicit Intent Sequence \u2026 \u2026 Trigger Item Target Item User behavior Sequence Multi-Head Attention Multi-Head Attention Multi-Head Attention Multi-view Relationships Sigmoid MLP Multi-view Relationships Sigmoid MLP Q K Q V V K Explicit Intent Exploit Module Latent Intent Explore Module Intent Uncertainty Measurement Module Concat & Flatten MLP \u2112 \ud835\udc84\ud835\udc95\ud835\udc93 = \ud835\udc35\ud835\udc36\ud835\udc38(\ud835\udc66, 2 y) User Profile User Context Target Item Interaction Module \ud835\udc38(\ud835\udc62 # ) \ud835\udc38(\ud835\udc62 $ ) \ud835\udc46 % \ud835\udc6f \ud835\udc8a \ud835\udc38(\ud835\udc62 # ) \ud835\udc38(\ud835\udc62 $ ) \ud835\udc6f \ud835\udc8d\ud835\udc8a \ud835\udc95\ud835\udc82 \ud835\udc6f \ud835\udc8d\ud835\udc8a \ud835\udc95\ud835\udc93 \ud835\udc67 ( 1 - \ud835\udc67 $ \ud835\udc38(\ud835\udc56 &' ) \ud835\udc6f \ud835\udc86\ud835\udc8a \u00b1 \ud835\udc6f \ud835\udc86\ud835\udc8a \u03a0 -. \u03a0 /0 \u211b () \u2217 \u211b () \u2217 \ud835\udc9c(,) \ud835\udc53 ! - Trigger Item \ud835\udc38(\ud835\udc56 &+ ) \ud835\udc46 , We consider users with similar intents usually exhibit similar behaviors, thus, we aggregate the temporal directed behaviors of multiple users to form a fundamental probabilistic graph structure G . The nodes V in the graph contain items and their attributes, and we will connect two sequentially occurring nodes to refine collaborative relationships [1, 16, 32]. method to enable that the attention mechanism aware of the prior multi-view relationships among items. Specifically, for each behavior item \ud835\udc56 \ud835\udc62 \u2217 \u2208 S \ud835\udc62 , we separately calculate the latent intent relevance score with both the trigger item and the target item according to equation 10, and we also modify the attention calculation scheme as follows: Having obtained the finer-grained collaborative patterns in graph G , suppose there is an item \ud835\udc56 with attribute \ud835\udf19 and an item \ud835\udc57 with attribute \ud835\udf13 , we construct multi-view relationships between item \ud835\udc56 and item \ud835\udc57 as follows:    where V\u2217 denotes the note in graph G . C\u2217 is the aggregation operator that records two nodes' co-occurrence frequency. The high-order connections between items can be implicitly captured by the aforementioned multi-view relationships. Specifically, we use C \ud835\udc56 \u2192 \ud835\udc57 to calculate the co-occurrence frequency between item \ud835\udc56 and item \ud835\udc57 and it is straightforward to use R \ud835\udc61 \ud835\udc56 \ud835\udc57 to represent their directed transition relationship. Similarly, the collaborative relationship of attributes, denoted by R \ud835\udc50 \ud835\udc56 \ud835\udc57 , represents the complementary relationship between item \ud835\udc56 and item \ud835\udc57 . R \ud835\udc5d \ud835\udc56 \ud835\udc57 is utilized to characterize the popularity of item \ud835\udc57 under attribute \ud835\udf19 . For item \ud835\udc56 and item \ud835\udc57 , to better encode the information from multi-view relationships between them, we define the latent intent relevance score \u03a0 \ud835\udc56 \ud835\udc57 to quantify their potential connections:  Motivated by previous work [22, 35], we employ Multi-Head Self-Attention (MHSA) [27] to obtain the refined behavior representation E (S \ud835\udc62 ) . Next, we apply two MHSA modules to extract user latent intent with respect to the target item and the trigger item respectively. More importantly, we propose a simple yet effective   where H \ud835\udc61\ud835\udc5f \ud835\udc59\ud835\udc56 and H \ud835\udc61\ud835\udc4e \ud835\udc59\ud835\udc56 are user latent intent representation with respect to the trigger item and the target item respectively. \u03a0 \ud835\udc61\ud835\udc5f represents the latent intent relevance score between each behavior item and the trigger item. \u03a0 \ud835\udc61\ud835\udc4e denotes the relevance score between each behavior item and the target item. 3.2.3 Intent Uncertainty Measurement Module . In the TIR task, supposing a continuous mapping space X \u2192 Z , where \ud835\udc65 \ud835\udc62 \u2208 X denotes user personalized information, including the trigger item \ud835\udc56 \ud835\udc61\ud835\udc5f , context features \ud835\udc62 \ud835\udc50 , and profile features \ud835\udc62 \ud835\udc5d . \ud835\udc67 \ud835\udc62 \u2208 Z represents user intent intensity. As user intent evolves and browsing context changes, the intensity of user intent after clicking on the trigger item becomes uncertain to some degree. Therefore, in DUIN, we consider the user interaction behavior as an uncertain event influenced by the user intent intensity. We employ the Intent Uncertainty Measurement Model to model user intent intensity as a distribution rather than a static value [22, 35], which can cover a broader space of user intent and infuse the recommendation results with novelty and uncertainty. Specifically, we define the user intent intensity \ud835\udc67 \ud835\udc62 of each user as a Gaussian distribution N , which is mathematically defined as:  where \ud835\udf07 \ud835\udc62 and \u03a3 \ud835\udc62 denote the mean and the variance of the Gaussian distribution, respectively. \ud835\udf07 \ud835\udc62 represents the predicted user intent intensity and \u03a3 \ud835\udc62 can be regarded as the uncertainty of \ud835\udf07 \ud835\udc62 . Here Modeling User Intent Beyond Trigger: Incorporating Uncertainty for Trigger-Induced Recommendation Conference acronym 'XX, June 03-05, 2018, Woodstock, NY we only consider a diagonal matrix for simplicity. In practice, we employ two independent networks to obtain \ud835\udf07 \ud835\udc62 and \u03a3 \ud835\udc62 :   where \ud835\udc53 \ud835\udf07 \ud835\udf03 and \ud835\udc53 \u03a3 \ud835\udf03 are implemented as two fully-connected layers. \ud835\udc60\ud835\udc5c\ud835\udc53 \ud835\udc61\ud835\udc5d\ud835\udc59\ud835\udc62\ud835\udc60 is an activation function [9] and constrains the output to always be positive. Finally, we consider \ud835\udc67 \ud835\udc62 as a measure of the user's intent intensity towards the trigger item. We use it to integrate the user latent intent features outputted by LIEM, which can be formulated as:", "3.3 Prediction and Optimization": "Having obtained the user intent representations H \ud835\udc52\ud835\udc56 , H \ud835\udc56 and H \ud835\udc59\ud835\udc56 from both EIEM and LIEM, similar to equation 1, we concatenate these intent representations with other features, including context features \ud835\udc62 \ud835\udc50 , profile features \ud835\udc62 \ud835\udc5d , and the target item \ud835\udc56 \ud835\udc61\ud835\udc4e . Subsequently, the concatenated features are fed into MLP [42] to estimate the likelihood \u02c6 \ud835\udc66 \ud835\udc56 \u2208 [ 0 , 1 ] of user interaction. We adopt the binary cross entropy loss [22, 29, 42] for model optimization:  where \ud835\udc41 denotes total size of the training set, \ud835\udc66 \ud835\udc56 is the ground-truth. We also adopt a multi-task learning strategy to jointly optimize the original prediction task and the contrastive learning objectives. The final optimization function is defined as:  where \ud835\udefc is a hyperparameter to balance weight of contrastive loss.", "4 EVALUATION": "", "4.1 Experimental Setup": "4.1.1 Datasets. Three real-world datasets are used in experiments. Detailed statistics are summarized in Table 1. \u00b7 Alibaba.com 3 . As there is no public dataset released for the TIR task. We collect interaction behavior logs from the TIR scenarios on our e-commerce application to serve as industrial production dataset, named Alibaba.com. The dataset contains about 370 thousand users and 5.2 million records of browsing and clicking behavior data over 3 days. We select data from the first 80% in chronological order as the training set, the next 10% as validation set, while the rest 10% as test set. \u00b7 Alimama 4 . It is a representative e-commerce dataset provided by Alimama advertising platform. Since it lacks logs of trigger items, following the data processing strategy by [22], for each sample, we take the latest item clicked by user within four hours as the trigger item. Finally, the dataset contains 8.55 million samples from half a million users. 3 https://www.alibaba.com/ 4 https://tianchi.aliyun.com/dataset/dataDetail?dataId=56 \u00b7 ContentWise [17]. Different from Alibaba.com and Alimama datasets, the dataset is a popular multimedia recommendation dataset, which is collected from an Over-The-Top Media service and includes 2.5 million behavior data from approximately 26 thousand users. Similar to the Alimama dataset, we consider the latest clicked item by a user within eight hours as the trigger item. Table 1: Datasets statistics. 4.1.2 Compared Methods. We include three groups of baseline methods for comparison. We firstly compare DUIN with some popular user behavior modeling methods: WDL [5], DIN [42], DIEN [41], DMIN [34]. Furthermore, following [22, 33, 35], we upgrade previous methods by incorporating the trigger item, forming the second group for a fair comparison: \u00b7 WDL \ud835\udc47\ud835\udc3c\ud835\udc45 concatenates the trigger item with other features and feds them into the deep side of the network. \u00b7 DIN \ud835\udc47\ud835\udc3c\ud835\udc45 employs an attention mechanism to activate related user behaviors with respect to the trigger item. \u00b7 DIEN \ud835\udc47\ud835\udc3c\ud835\udc45 utilizes GRU with an attentional gate to extract the evolved interests that are related to the trigger item. \u00b7 DMIN \ud835\udc47\ud835\udc3c\ud835\udc45 applies interest extraction layers to obtain user multiple interests that are related to the trigger item. The third group involves several state-of-the-art methods focusing on the TIR task: DIHN [22], DIAN [33], DEI2N [35]. 4.1.3 Implementation details. We employ the Adam optimizer for all models with a learning rate of 0.001 and a batch size of 256. Each model is trained from scratch without any pre-training. The maximum lengths of the user sequences in the Alibaba.com, Alimama, and ContentWise datasets are 20, 20, and 30, respectively. We set the maximum length of user explicit intent sequences to 10 for the Alibaba and Alimama datasets and to 20 for the ContentWise dataset. We select category and brand as item attributes for e-commerce dataset and multimedia dataset respectively. We construct probability graph by linking each item to its four subsequent items. We utilize the Transformer [27] architecture as the encoder \ud835\udc53 \ud835\udf03 , the number of attention heads is set to 8 for all. The MLP within the EIEM and IUMM are configured with hidden layer sizes of 144 and 72. The dimensions of the final hidden layers are set at 200 and 80, respectively. For contrastive learning, the hyperparameters \ud835\udf0f , \ud835\udefe , and \ud835\udefc are assigned values of 0.1, 0.5, and 1, respectively. 4.1.4 Evaluation Metrics. In offline experiments, we use commonly used metrics AUC and RelaImpr [6, 34, 41], which are widely recognized evaluation metrics in CTR tasks. We conduct each experiment five times and report the average results. All other experimental and parameter settings remain consistent with [22, 35] to ensure fair comparison. One-sided Wilcoxon rank-sum p-value is calculated to quantify the significance of the improvement achieved by DUIN [7]. In online A/B testing, we use CTR and Conversion Rate (CVR) as online metrics to assess the efficacy of DUIN. All reproducible materials of DUIN will be available after paper review. Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Jianxing Ma et al. Table 2: Performance comparison of our method with competitors on three real-world datasets. Bold values indicate the best result in each column, while underlined values indicate the second best result. \u2217 Asterisks represent where DUIN's improvement over compared methods is significant (one-sided rank-num p-value <0.01). Table 3: Ablation experimental results on Alibaba.com. that all modules are effective for DUIN. The superior performance of Model 1 over Model 4 shows that modeling the user intent intensity is critical in the TIR task. The ablation results of Models 1 and 5 confirm that contrastive learning can help improve the performance of DUIN. By comparing Models 1 and 6, we can conclude that modeling user intent intensity as a distribution, rather than a static value is a more effective representation method.", "4.2 Offline Experiments": "4.2.1 Overall Comparison. The overall performance of all methods across three datasets is summarized in Table 2. From the results, we can observe that traditional CTR methods deliver the poorest results compared with other methods, indicating their inadequacy for the TIR task. By incorporating the trigger item, upgraded versions of these traditional methods demonstrate much improved performance. For example, DMIN \ud835\udc47\ud835\udc3c\ud835\udc45 has a AUC gains 22 . 1% over its original version for Alibaba.com dataset. It shows that an elaborative modeling of the trigger item is necessary. Meanwhile, existing TIR methods, DIHAN, DIAN and DEI2N, employ carefully designed networks to further surpass the performance of previous upgraded traditional approaches. Notably, our proposed DUIN achieves the best performance across all three datasets. The results show that the AUCgains of our method DUIN over the existing strongest competitor DEI2N are 1 . 45%, 0 . 22% and 0 . 41% for Alibaba.com, Alimama and ContentWise datasets respectively. It validates the efficacy of considering explicit and latent intents and the corresponding uncertainties in TIR scenarios. 4.2.2 Ablation Study. As Alibaba.com is collected from real-world TIR scenarios, we conduct several ablation experiments on it to further analyze the effectiveness of each module. Table 3 shows the experimental results, where SSL represents the contrastive learning framework in EIEM, and SII denotes that DUIN utilizes a static intent intensity to replace IUMM by following [22, 35]. Compared to Model 2-4, Model 1 achieves the highest AUC results, indicating 4.2.3 Hyper-parameters Analysis. We further qualitatively analyze the impacts of different hyper-parameters in DUIN, which are shown in Figure 4a. Overall, DUIN demonstrates relatively robust performance across parameter variations. We also observe that the performance of DUIN deteriorates when \ud835\udefe is too large, probably because the excessive loss of interactive behaviors affects the modeling of user explicit intent. 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 Proportion 0 . 766 0 . 768 0 . 770 0 . 772 0 . 774 0 . 776 0 . 778 0 . 780 AUC Mask Probability \u03b3 Temperature Parameter \u03c4 Loss Weight \u03b1 13 14 15 16 Prediction Time(minute) 540 560 580 600 620 640 WDL TIR DIN TIR DIEN TIR DMIN TIR DIHN DIAN DEI2N DUIN Training Time(minute) (a) Hyper-parameters Analysis (b) Time Analysis Figure 4: Parameters and Time Analysis on Alibaba.com. 4.2.4 Time Analysis. We also conduct an extra experiment to test the efficiency of DUIN. To make comparisons fairly, we conduct experiments on machines with identical hardware configurations, each of which has 1 NVIDIA Tesla V100 GPU with Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz and 330 GB memory. We report the time consumption for one epoch of training and testing for each model, respectively. As shown in Figure 4b, compared to the existing TIR methods, DUIN slightly increases the training time. However, since contrastive learning is only utilized in the training stage, DUIN does not introduce additional prediction time cost. Modeling User Intent Beyond Trigger: Incorporating Uncertainty for Trigger-Induced Recommendation Conference acronym 'XX, June 03-05, 2018, Woodstock, NY", "4.3 Online A/B Testing": "We have implemented our proposed method, DUIN, in industrial Trigger-Induced Recommendation scenarios to serve substantial traffic requests. In this section, we will describe the online A/B testing settings and results. 4.3.1 Online Serving Architecture. Figure 5 depicts the online serving architecture of DUIN on our e-commerce platform. The architecture is primarily divided into two main stages: i) The offline stage focuses on training the DUIN model. In practice, we collect 60 days of user interaction logs from our platform and process these logs into training samples using the big data platform MAXCOMPUTE. Once the training samples are prepared, we utilize the Algorithm One Platform (AOP) to train our proposed DUIN model. After training is complete, the model is deployed for online serving. ii) During the online stage, The Personalization Platform (TPP) handles user requests by parsing them to obtain the real-time clicked trigger item and context features of the current browsing session. TPP then requests All Basic Feature Service (ABFS) to retrieve user profile features and historical behaviors. The Basic Engine (BE) recalls the topM most relevant candidate items for the user, where M is typically less than two thousand. Our DUIN model is deployed on the Real-Time Prediction (RTP) platform to score these topM candidate items. The topK items with the highest scores are then shown to the user. Usually, the \ud835\udc3e is set to 10-20. In addition, RTP supports deploying multiple models, ensuring fairness in online A/B testing. 4.3.2 Online A/B Testing Results. We conduct online A/B testing to evaluate DUIN in two online TIR scenarios over a 14-day period, as shown in Table 4. We choose DEI2N [35] as the baseline, which performs the second-best in offline tests. Results show that DUIN consistently outperforms DEI2N in terms of CTR and Conversion Rate (CVR). Furthermore, since the exposed items can be classified into two categories-those that belong to the same category as the trigger item and those that belong to a different category, CTR can also be segmented into Same-category CTR (S-CTR) and Crosscategory CTR (C-CTR). DUIN shows significant improvements under both S-CTR and C-CTR metrics, which also shows that DUIN has better intent representation capabilities. From the perspective of cross-category exposure ratio (CCER), DUIN can alleviate the problem of over-convergence of intention understanding states and provide users with more diverse and novel recommendations. Due to DUIN's excellent online performance, we have deployed it in major TIR scenarios on Alibaba.com platform. Table 4: Online A/B testing results. 4.3.3 Case study. We illustrate the effectiveness of DUIN through two real cases on the Alibaba.com platform. As depicted in Figure 6, the upper section illustrates that when a user, for instance, a headphone retailer, engages in our TIR scenario. When he/she clicks Figure 5: The online serving architecture of DUIN. OFFLINE ONLINE Time Tunnel (TT) MAXCOMPUTE Engine Parse User Request All Basic Feature Service (ABFS) User Info Real-Time Prediction (RTP) Algorithm One Platform (AOP) Exposed K Items User Behaviors Blink System Training Samples LOG LOG Recall M Items Basic Engine (BE) Deploy Model (DUIN) The Personalization Platform(TPP) User Historical Behaviors Trigger Item & Context Features Figure 6: Two real-world cases. Black dashed boxes are similar items, red dashed boxes indicates complementary items, and blue dashed boxes indicates trending items. Click On Trigger item Exposed items Headphone Retailer Requesting DUIN Blue Tooth Headphones Click On Trigger item Exposed items Clothing wholesaler Requesting DUIN Ladies T-Shirt on the Blue Bluetooth Headphones , DUIN suggests items that are akin to the trigger item. At the same time, DUIN suggests trending items and complementary options to the user, like the Wired Earphone and Headset . This shows that DUIN not only recommends items similar to the trigger item but also accurately predicts the user's intended scope, offering more precise and comprehensive procurement recommendations. The lower section of Figure 6 shows another real-world scenario. After a clothing wholesaler clicked on the Ladies T-Shirt , DUIN not only suggests some Ladies T-Shirts similar to the trigger item but also recommends Mini Skirts that can be easily coordinated with the Ladies T-Shirt , as well as Cotton Tank Tops that are currently trending on the platform.", "5 CONCLUSION": "In this paper, we introduce a novel TIR model, called Deep Uncertainty Intent Network (DUIN), to model both explicit and latent user intent with uncertainty based on user-triggered items. The proposed DUIN model consists of three modules: i) Explicit Intent Exploit Module, which aims to obtain generalizable and distinguishable intent representations; ii) Latent Intent Explore Module, designed to explore the user's underlying intent; and iii) Intent Uncertainty Measurement Module, tasked with modeling user intent intensity as a distribution to capture the uncertainty associated with user intent. Extensive experiments demonstrate that DUIN surpasses various representative methods, achieving state-of-theart performance. Moreover, DUIN has been deployed across all TIR scenarios within our Alibaba.com platform, and online A/B testing has conclusively verified the superiority of our approach. Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Jianxing Ma et al.", "REFERENCES": "[1] Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song, Depeng Jin, and Yong Li. 2021. Sequential Recommendation with Graph Neural Networks. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval . ACM, New York, NY, USA, 378-387. [2] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. A simple framework for contrastive learning of visual representations. In Proceedings of the 37th International Conference on Machine Learning . JMLR.org, San Diego, Article 149, 11 pages. [3] Xinlei Chen, Saining Xie, and Kaiming He. 2021. An Empirical Study of Training Self-Supervised Vision Transformers. In 2021 IEEE/CVF International Conference on Computer Vision (ICCV) . IEEE, Montreal, QC, Canada, 9620-9629. [4] Yongjun Chen, Zhiwei Liu, Jia Li, Julian McAuley, and Caiming Xiong. 2022. Intent Contrastive Learning for Sequential Recommendation. In Proceedings of the ACM Web Conference 2022 . ACM, New York, NY, USA, 2172-2182. [5] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, Rohan Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah. 2016. Wide & Deep Learning for Recommender Systems. In Proceedings of the 1st Workshop on Deep Learning for Recommender Systems . ACM, New York, NY, USA, 7-10. [6] Yufei Feng, Fuyu Lv, Weichen Shen, Menghan Wang, Fei Sun, Yu Zhu, and Keping Yang. 2019. Deep session interest network for click-through rate prediction. In Proceedings of the 28th International Joint Conference on Artificial Intelligence . AAAI Press, Honolulu, Hawaii, USA, 2301-2307. [7] Edmund A Gehan. 1965. A generalized Wilcoxon test for comparing arbitrarily singly-censored samples. Biometrika 52, 1-2 (1965), 203-224. [8] Zhabiz Gharibshah, Xingquan Zhu, Arthur Hainline, and Michael Conway. 2020. Deep Learning for User Interest and Response Prediction in Online Display Advertising. Data Science and Engineering (2020), 12-26. [9] Xavier Glorot, Antoine Bordes, and Yoshua Bengio. 2011. Deep Sparse Rectifier Neural Networks. In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (Proceedings of Machine Learning Research, Vol. 15) , Geoffrey Gordon, David Dunson, and Miroslav Dud\u00edk (Eds.). PMLR, Fort Lauderdale, FL, USA, 315-323. [10] Wang-Cheng Kang and Julian McAuley. 2018. Self-Attentive Sequential Recommendation. In 2018 IEEE International Conference on Data Mining (ICDM) . IEEE, Los Alamitos, CA, USA. [11] Jiacheng Li, Yujie Wang, and Julian McAuley. 2020. Time Interval Aware SelfAttention for Sequential Recommendation. In Proceedings of the 13th International Conference on Web Search and Data Mining . ACM, New York, NY, USA, 322-330. [12] Xiang Li, Chao Wang, Jiwei Tan, Xiaoyi Zeng, Dan Ou, Dan Ou, and Bo Zheng. 2020. Adversarial Multimodal Representation Learning for Click-Through Rate Prediction. In Proceedings of The Web Conference 2020 . ACM, New York, NY, USA, 827-836. [13] Zeyu Li, Wei Cheng, Yang Chen, Haifeng Chen, and Wei Wang. 2020. Interpretable Click-Through Rate Prediction through Hierarchical Attention. In Proceedings of the 13th International Conference on Web Search and Data Mining . ACM, New York, NY, USA, 313-321. [14] Bin Liu, Ruiming Tang, Yingzhi Chen, Jinkai Yu, Huifeng Guo, and Yuzhou Zhang. 2019. Feature Generation by Convolutional Neural Network for Click-Through Rate Prediction. In The World Wide Web Conference . ACM, New York, NY, USA, 1119-1129. [15] Ze Lyu, Yu Dong, Chengfu Huo, and Weijun Ren. 2020. Deep Match to Rank Model for Personalized Click-Through Rate Prediction. Proceedings of the AAAI Conference on Artificial Intelligence (2020), 156-163. [16] Erxue Min, Yu Rong, Tingyang Xu, Yatao Bian, Da Luo, Kangyi Lin, Junzhou Huang, Sophia Ananiadou, and Peilin Zhao. 2022. Neighbour interaction based click-through rate prediction via graph-masked transformer. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval . ACM, New York, NY, USA, 353-362. [17] Fernando B. P\u00e9rez Maurera, Maurizio Ferrari Dacrema, Lorenzo Saule, Mario Scriminaci, and Paolo Cremonesi. 2020. ContentWise Impressions: An Industrial Dataset with Impressions Included. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management . ACM, New York, NY, USA, 3093-3100. [18] Qi Pi, Weijie Bian, Guorui Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Practice on Long Sequential User Behavior Modeling for Click-Through Rate Prediction. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . ACM, New York, NY, USA, 2671-2679. [19] Qi Pi, Guorui Zhou, Yujing Zhang, Zhe Wang, Lejian Ren, Ying Fan, Xiaoqiang Zhu, and Kun Gai. 2020. Search-based User Interest Modeling with Lifelong Sequential Behavior Data for Click-Through Rate Prediction. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management . ACM, New York, NY, USA, 2685-2692. [20] Jiarui Qin, Weinan Zhang, Xin Wu, Jiarui Jin, Yuchen Fang, and Yong Yu. 2020. User Behavior Retrieval for Click-Through Rate Prediction. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval . ACM, New York, NY, USA, 2347-2356. [21] Ruihong Qiu, Zi Huang, Hongzhi Yin, and Zijian Wang. 2022. Contrastive Learning for Representation Degeneration Problem in Sequential Recommendation. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining . ACM, New York, NY, USA, 813-823. [22] Qijie Shen, Hong Wen, Wanjie Tao, Jing Zhang, Fuyu Lv, Zulong Chen, and Zhao Li. 2022. Deep Interest Highlight Network for Click-Through Rate Prediction in Trigger-Induced Recommendation. In Proceedings of the ACM Web Conference 2022 . ACM, New York, NY, USA, 422-430. [23] Kaitao Song, Qingkang Huang, Fa-en Zhang, and Jianfeng Lu. 2021. Coarse-tofine: A dual-view attention network for click-through rate prediction. KnowledgeBased Systems 216 (2021), 106767. [24] Weiping Song, Zhiping Xiao, Yifan Wang, Laurent Charlin, Ming Zhang, and Jian Tang. 2019. Session-Based Social Recommendation via Dynamic Graph Attention Networks. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining . ACM, New York, NY, USA, 555-563. [25] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management . ACM, New York, NY, USA, 1441-1450. [26] Yi Tay, Anh Tuan Luu, and Siu Cheung Hui. 2018. Multi-Pointer Co-Attention Networks for Recommendation. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . ACM, New York, NY, USA, 2309-2318. [27] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Proceedings of the 31st International Conference on Neural Information Processing Systems . Curran Associates Inc., Red Hook, NY, USA, 6000-6010. [28] Hongwei Wang, Fuzheng Zhang, Xing Xie, and Minyi Guo. 2018. DKN: Deep Knowledge-Aware Network for News Recommendation. In Proceedings of the 2018 World Wide Web Conference . International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE, 1835-1844. [29] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep & Cross Network for Ad Click Predictions. In Proceedings of the ADKDD'17 . ACM, New York, NY, USA, Article 12, 7 pages. [30] Ruoxi Wang, Rakesh Shivanna, Derek Cheng, Sagar Jain, Dong Lin, Lichan Hong, and Ed Chi. 2021. DCN V2: Improved Deep & Cross Network and Practical Lessons for Web-scale Learning to Rank Systems. In Proceedings of the Web Conference 2021 . ACM, New York, NY, USA, 1785-1797. [31] Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, and Tat-Seng Chua. 2019. KGAT: Knowledge Graph Attention Network for Recommendation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . ACM, New York, NY, USA, 950-958. [32] Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-based recommendation with graph neural networks. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence . AAAI Press, Honolulu, Hawaii, USA, Article 43, 8 pages. [33] Yaxian Xia, Yi Cao, Sihao Hu, Tong Liu, and Lingling Lu. 2023. Deep IntentionAware Network for Click-Through Rate Prediction. In Companion Proceedings of the ACM Web Conference 2023 . ACM, New York, NY, USA, 533-537. [34] Zhibo Xiao, Luwei Yang, Wen Jiang, Yi Wei, Yi Hu, and Hao Wang. 2020. Deep Multi-Interest Network for Click-through Rate Prediction. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management . ACM, New York, NY, USA, 2265-2268. [35] Zhibo Xiao, Luwei Yang, Tao Zhang, Wen Jiang, Wei Ning, and Yujiu Yang. 2024. Deep Evolutional Instant Interest Network for CTR Prediction in Trigger-Induced Recommendation. In Proceedings of the 17th ACM International Conference on Web Search and Data Mining . ACM, Merida, Mexico, 846-854. [36] Ruobing Xie, Rui Wang, Shaoliang Zhang, Zhihong Yang, Feng Xia, and Leyu Lin. 2021. Real-time Relevant Recommendation Suggestion. In Proceedings of the 14th ACM International Conference on Web Search and Data Mining . ACM, New York, NY, USA, 112-120. [37] Xu Xie, Fei Sun, Zhaoyang Liu, Shiwen Wu, Jinyang Gao, Jiandong Zhang, Bolin Ding, and Bin Cui. 2022. Contrastive learning for sequential recommendation. In 2022 IEEE 38th international conference on data engineering (ICDE) . IEEE, ACM, Kuala Lumpur, Malaysia, 1259-1273. [38] Chengfeng Xu, Pengpeng Zhao, Yanchi Liu, Victor S. Sheng, Jiajie Xu, Fuzhen Zhuang, Junhua Fang, and Xiaofang Zhou. 2019. Graph contextualized selfattention network for session-based recommendation. In Proceedings of the 28th International Joint Conference on Artificial Intelligence . AAAI Press, Honolulu, Hawaii, USA, 3940-3946. [39] Chengfeng Xu, Pengpeng Zhao, Yanchi Liu, Jiajie Xu, Victor S.Sheng S.Sheng, Zhiming Cui, Xiaofang Zhou, and Hui Xiong. 2019. Recurrent Convolutional Neural Network for Sequential Recommendation. In The World Wide Web Conference . ACM, New York, NY, USA, 3398-3404. Modeling User Intent Beyond Trigger: Incorporating Uncertainty for Trigger-Induced Recommendation [40] Weinan Xu, Hengxu He, Minshi Tan, Yunming Li, Jun Lang, and Dongbai Guo. 2020. Deep Interest with Hierarchical Attention Network for Click-Through Rate Prediction. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval . ACM, New York, NY, USA, 1905-1908. [41] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Deep interest evolution network for click-through Conference acronym 'XX, June 03-05, 2018, Woodstock, NY rate prediction. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence . AAAI Press, Honolulu, Hawaii, USA, Article 729, 8 pages. [42] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep Interest Network for ClickThrough Rate Prediction. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . ACM, New York, NY, USA, 1059-1068."}
