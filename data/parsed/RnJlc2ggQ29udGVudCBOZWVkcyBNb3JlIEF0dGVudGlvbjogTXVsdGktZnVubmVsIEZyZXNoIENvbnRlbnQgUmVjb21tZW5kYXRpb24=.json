{"Fresh Content Needs More Attention: Multi-funnel Fresh Content Recommendation": "Jianling Wang*, Haokai Lu*, Sai Zhang, Bart Locanthi, Haoting Wang, Dylan Greaves, Benjamin Lipshitz, Sriraj Badam, Ed H. Chi, Cristos J. Goodrow, Su-Lin Wu, Lexi Baugher and Minmin Chen Google {jianlingw,haokai,saisaizhang,bnl,haotingwang,lipshitz,srirajdutt,edchi,cristos,sulin,baugher,minminc}@google.com", "ABSTRACT": "Recommendation system serves as a conduit connecting users to an incredibly large, diverse and ever growing collection of contents. In practice, missing information on fresh (and tail) contents needs to be filled in order for them to be exposed and discovered by their audience. We here share our success stories in building a dedicated fresh content recommendation stack on a large commercial platform. To nominate fresh contents, we built a multi-funnel nomination system that combines (i) a two-tower model with strong generalization power for coverage, and (ii) a sequence model with near real-time update on user feedback for relevance. The multi-funnel setup effectively balances between coverage and relevance. An in-depth study uncovers the relationship between user activity level and their proximity toward fresh contents, which further motivates a contextual multi-funnel setup. Nominated fresh candidates are then scored and ranked by systems considering prediction uncertainty to further bootstrap content with less exposure. We evaluate the benefits of the dedicated fresh content recommendation stack, and the multi-funnel nomination system in particular, through user corpus co-diverted live experiments. We conduct multiple rounds of live experiments on a commercial platform serving billion of users demonstrating efficacy of our proposed methods.", "CCS CONCEPTS": "\u00b7 Information systems \u2192 Information retrieval ;", "KEYWORDS": "Hybrid Recommendation Systems, Cold-start Recommendation, Real-time Learning, Content Generalization", "ACMReference Format:": "Jianling Wang*, Haokai Lu*, Sai Zhang, Bart Locanthi, Haoting Wang, Dylan Greaves, Benjamin Lipshitz, Sriraj Badam, Ed H. Chi, Cristos J. Goodrow, SuLin Wu, Lexi Baugher and Minmin Chen. 2023. Fresh Content Needs More Attention: Multi-funnel Fresh Content Recommendation. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '23), August 6-10, 2023, Long Beach, CA, USA. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3580305.3599826 Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). KDD '23, August 6-10, 2023, Long Beach, CA, USA \u00a9 2023 Copyright held by the owner/author(s). ACM ISBN 979-8-4007-0103-0/23/08. https://doi.org/10.1145/3580305.3599826 Relevance Coverage Real-time Recommendation Two-tower DNN Multi-funnel Recommendation", "1 INTRODUCTION": "Recommendation systems are heavily relied upon to connect users to the right contents on recommendation platforms. Many of these systems are trained on interaction logs collecting historical user interactions with recommended contents. These interactions however are conditioned on the contents these systems chose to expose to users, which creates a strong feedback loop [7] resulting in 'rich gets richer' effect. Fresh uploads, especially those from less popular content providers on the other hand, face a significant barrier to be picked up by these systems and shown to the right users due to lack of the initial exposure and interaction . This is commonly known as the item cold-start problem. Our goal is to break the feedback loop and create a healthy platform where high-quality fresh contents can surface and go viral as well. To achieve it, we need to seed the initial exposure of these content to fill in missing knowledge in these systems , so they can be recommended to the right users. Although there is emerging research focusing on facilitating cold-start recommendation [29, 31, 43, 55, 56] beyond the early work on content-based recommendation [18, 46, 53], how to bootstrap the huge amount of fresh contents (e.g., more than 500 hours of contents are uploaded to YouTube every minute [4, 20]; a new track is uploaded to Spotify every 1.4 seconds [23]) on industrial scale recommendation platforms remains under-explored. More concretely, we aim at building a pipeline to surface fresh and tail contents to increase the discoverable corpus 1 on recommendation platforms. There is a dilemma though: a system capable of exploring the full spectrum of the corpus leads to improved longterm user experience [8, 24]; however as less certain contents are recommended, fresh content recommendation often comes at a cost to short-term user experience, which we would like to mitigate. To balance the short-term and long-term user experience in the fresh content recommendation pipeline, we measure its effectiveness on two dimensions: (i) coverage to examine if the pipeline can get more unique fresh contents exposed to the users, and (ii) relevance to examine whether the system is connecting users with fresh contents that are interesting to the users. Designing the fresh content recommendation stacks still faces many unknowns: (i) how to position the fresh content recommendation stack w.r.t. existing recommendation stacks? We choose to build a dedicated fresh content recommendation stack that is relatively separated from the rest of the recommendation stacks which focus on relevance, and are more susceptible to strong feedback loop; (ii) what components are needed in the stack? We design the stack to include a nomination system, graduation filter and a ranking system to score and rank the candidates; (iii) how to balance between coverage and relevance? A system randomly recommending fresh contents will reach maximum coverage at the expense of low relevance and impacted user experience. To achieve a balance, we built a multi-funnel nomination system that diverts user requests between a model with high coverage and one with high relevance (see Figure 1); (iv) how to model contents with little to no prior engagement data? We rely on a two-tower DNN model that leverages content features for generalization to bootstrap the initial distribution, and a sequence model that updates on near real-time user feedback to quickly find audience for the high-quality content; and (v) how to measure the benefits of fresh content recommendation? We adopt a user-corpus co-diverted experiment framework to measure the effect of the proposed system in increasing the discoverable corpus. We organize our paper as follows and highlight our key contributions: \u00b7 In Section 2, we design a dedicated multi-stage fresh content recommendation stack with nomination, filtering, scoring and ranking components to effectively bootstrap cold-start items; We showcase its values in improving corpus coverage, discoverable corpus and content creation on a commercial recommendation platform serving billions of users. \u00b7 In section 3, we design a multi-funnel nomination system within the dedicated fresh content recommendation stack that combines a model with high generalization capability and one with near real-time update to effectively balance between coverage and relevance in fresh recommendation. We conduct a series of live experiments on the same platform to demonstrate the efficacy of the multi-funnel nomination system and summarize the results in Section 4. \u00b7 In Section 5, we extend the system to divert user requests to these two models based on request context to further improve fresh recommendation efficiency.", "2 FRESH CONTENT RECOMMENDATION": "Pipeline Setup. We first introduce a dedicated fresh recommendation stack to surface relevant fresh and tail contents for users in one of the largest commercial recommendation platform serving billions of users. The production recommender system has multiple stages [10, 33], in which the first stage includes multiple retrieval models to nominate candidates from the overall corpus, the second Regular recs from all corpus Contents Fresh content nominator Ranker Graduation filter Multi-arm bandit Pre-scorer Fresh content (<=X days & <=Y positive user interactions) Regular recs from all corpus stage scores and ranks the candidates, while the last stage packs the selected candidates for diversity and different business goals. Fresh and tail items however are hard to be discovered by the system due to the closed feedback loop [7, 25]. To surface such contents, we dedicate one (floating) slot to fresh ( \u2a7d \ud835\udc4b days old) and tail (with less than \ud835\udc4c positive user interactions) contents. The rest of the slots are still filled with the production recommendation system. The pipeline for this dedicated fresh recommendation system is illustrated in Figure 2, with each component described as follows: \u00b7 Fresh content nominator . A key challenge in nominating relevant fresh and tail contents lies in the lack of user interaction data on them. To overcome the cold-start item recommendation problem, we adopt a two-tower content-based recommendation model [22, 35, 51]: a query tower is used to learn user representation based on the consumption histories; and a candidate tower is used to learn item representation based on item features. The model is trained to predict positive user interactions from historical data, and fortunately through item features, it is able to generalize to items with zero or very little user interactions. At serving time, we rely on a multiscale quantization approach for fast approximate Maximum Inner Product Search [19, 49] and retrieve the top-50 fresh candidates efficiently. \u00b7 Graduation filter . Once fresh contents accumulate initial interactions, they can be readily picked up by the main recommendation system and shown to the right users in other slots. There is diminishing return to continue exploring these items in the dedicated slot, and the impression resource can be saved and re-allocated to other potential fresh and tail contents. We adopt a graduation filter that removes contents which have been consumed by users for at least \ud835\udc5b times at real-time 2 . \u00b7 Ranking . Once nominated candidates passed through the filter, we rank them through two components: a real-time pre-scorer and the ranker shared with the main system. The pre-scorer is lightweight and is able to react to users' early feedback in realtime; The top-10 candidates chosen by the pre-scorer will then pass through the ranker, which is a high-capacity deep neural network [10] with much better accuracy but longer latency, to assess the relevance of the selected candidates and return the top-1. Specifically, the lightweight pre-scorer implements a real-time Bernoulli multi-arm bandit [37] where each arm corresponds to one content. The reward of each arm estimates the good CTR of a fresh content, i.e., click-through rate conditioning on users spending at least 10 seconds after the click, 100% Corpus Dedicated Fresh Content Recommendation Treatment Control Ctrl: x% users Exp: x% users User diverted experiment Exp: x% Corpus Control Ctrl: x% users Exp: x% users User-corpus co-diverted experiment Ctrl: x% Corpus and follows a Beta posterior distribution: where \ud835\udc5f \ud835\udc56 is the reward for arm \ud835\udc56 with a prior \ud835\udc35\ud835\udc52\ud835\udc61\ud835\udc4e ( \ud835\udefc 0 , \ud835\udefd 0 ) for some parameters \ud835\udefc 0 , \ud835\udefd 0 \u2208 R > 0, \ud835\udc65 \ud835\udc56 and \ud835\udc5b \ud835\udc56 represent the total number of interactions and impressions for arm \ud835\udc56 at real-time, respectively. In practice, we estimate the global prior \ud835\udefc 0 and \ud835\udefd 0 through maximum likelihood estimate on fresh items with at least 100 impressions. At serving time, we adopt Thompson Sampling to generate a sampled reward from Equation 1 for each candidate, and return the top 10 with the highest rewards, with the final candidate determined by the ranker. This 'dedicated slot' enables us to measure various fresh content recommendation treatments with more control and flexibility. Compared to 'full-system' fresh content recommendation (i.e., enable more exploration within the current recommendation stacks and potentially affect every single slot), setting up the 'dedicated slot' has several advantages: (i) Deliverable . By setting aside a dedicated slot for fresh content only, they can now more easily reach their target audience once uploaded. These contents would otherwise face severe competition from the head and more popular contents due to popularity bias in the main recommendation system. (ii) Measurable . With a dedicated slot and a much simpler pipeline, one can more easily set up different treatments and measure the corpus effect accurately through the following proposed user-corpus diverted experiment. (iii) Extensible . The fresh recommendation stack can be easily expanded by extending the single slot treatment to multiple ones, allowing sustainable discoverable corpus growth. User corpus co-diverted experiment. In traditional A/B testing, we usually adopt a user-diverted setup as shown in Figure 3 (left), in which users are randomly assigned to the control and treatment groups, and receive the corresponding recommendations from the entire corpus. One can compare user metrics such as CTR and dwell time between the two arms, and measure the effect of the treatment from the user perspective. However, since the two arms share the same corpus, the user-diverted setup is unable to measure any treatment effect on the corpus due to treatment leakage. For example, a fresh item receiving exposure through the fresh recommendation stack in the experiment can also appear in the control arm. To overcome such leakage,we adopt a user-corpus-diverted A/B testing setup (in Figure 3 (right)), in which we first set aside x% corpus for the control arm and another non-overlapping x% corpus for the treatment arm. Then users are assigned proportionally to different arms, meaning that users in the control arm can only receive contents from the control arm corpus, and users in the treatment arm can only receive contents from the treatment arm 3 . Since the size of user and corpus is in proportion, i.e, x% users are exposed to x% corpus during experiments, the effect of the treatment measured in the experiment phase is consistent with full deployment when 100% of the users are exposed to 100% corpus. Performance Evaluation Metrics. We use the following corpus metrics to measure the performance of the system in recommending personalized fresh contents, from both the coverage and relevance dimensions: \u00b7 Daily Unique Impressed Contents at \ud835\udc3e (DUIC@K) is a corpus metric that counts the number of unique contents receiving \ud835\udc3e impressions daily. We focus on the low end, i.e., relatively small \ud835\udc3e s, to quantify the coverage change. \u00b7 Fresh Content Dwell Time (DwellTime) measures time users spent on the impressed fresh content. Longer dwell time indicates the system can infer users' preference on fresh contents more accurately, thus achieving higher relevance . \u00b7 Number of content receiving X (post bootstrapping) positive interactions in Y days (Discoverable Corpus@X,Ydays) measures the long-term benefits of fresh content recommendation in incubating quality fresh contents to success. By post bootstrapping, we do not count interactions the item received from the dedicated fresh recommendation stack. A larger discoverable corpus indicates that the system can uncover and seed the success of more worthy content i.e., the ones that can attract positive interactions and reach viral on their own after exiting the dedicated slot. Meanwhile, to ensure that the newly introduced fresh content recommendation does not sacrifice too much short-term user engagement, we also look at a user metric measuring the overall user dwell time on the platform .", "2.1 Values of Fresh Recommendation": "We first conduct user corpus co-diverted live experiments on a commercial recommendation platform serving billions of users to measure the benefits of setting up the proposed fresh content recommendation stack over a one-month period. In these experiments, the users in the control arm are shown only recommendations generated by the main recommendation system. In the treatment arm, a dedicated slot is reserved to show recommendations from the fresh recommendation stack while the other slots are filled by the same recommendation system as the control arm. We make the following observations: \u00b7 Corpus coverage is improved. Figure 4(a) plots the corpus coverage metric - Daily Unique Impressed Contents at K (DUIC@K). One can observe a consistent increase of corpus coverage in 4% \u223c 7 . 2% across different K values. As an example, there are 7 . 2% more unique contents receiving more than 1,000 impressions daily in the treatment arm due to the dedicated fresh recommendation stack compared with the control arm. As expected, the increase is more pronounced at lower \ud835\udc3e values. 0 1,000 2,000 3,000 4,000 5,000 6,000 7,000 8,000 9,000 10,000 - 1% 0% 1% 2% 3% 4% 5% 6% 7% 8% 9% % Change in Daily Unique Videos 0 2,000 4,000 6,000 8,000 10,000 12,000 14,000 16,000 18,000 20,000 \u2265 X Expected Daily Impressions at 100% Tra ffi c - 0.40% - 0.35% - 0.30% - 0.25% - 0.20% - 0.15% - 0.10% - 0.05% 0.00% 0.05% 0.10% 0.15% 0.20% 0.25% 0.30% 0.35% 0.40% 0.45% 0.50% % Change in Daily Unique Videos (a) 100 500 1k 2k 5k 10K Num of Post Bootstrapping Positive Interactions X 0 2 4 6 8 Increase of discoverable corpus@ X , Y days (%) In Y days Y =3 Y =7 Y =14 Y =21 Y =28 (b) 0 5 10 15 20 25 30 35 40 Date 1 2 3 4 5 6 7 Increase of Upload (%) (c) \u00b7 A larger corpus is discovered by the users. In Figure 4(b), we plot the discoverable corpus metric, which measures the improvement in the number of contents receiving \ud835\udc4b post bootstrapping positive interactions in \ud835\udc4c days. Again one can observe a consistent improvement for a range of values for \ud835\udc4b (from 100 to 10K), and \ud835\udc4c (from 3 days to 28 days). In other words, with the initial exposure and interactions seeded in the dedicated fresh recommendation stacks, more unique number of contents are now being recommended by the main recommendation system and being discovered by the users as a result. The improvement also re-assures that the fresh recommendation stack not only increases the corpus coverage, but also bootstraps worthy contents that can survive on their own quality and relevance after the treatment. With a larger discoverable corpus, more users will now be able to find contents centering around their specific preferences in topic, style, content provider etc., leading to better user experience and a healthier platform [9]. Although it takes time for a fresh upload to be picked up by the main recommendation system and get discovered, we do find the numbers tend to converge after 7 days, even for those high end \ud835\udc4b values. Thus, we use discoverable corpus@X,7days as the main discoverable corpus metric in our live experiment to reach conclusion sooner. \u00b7 Content providers are encouraged to upload more contents. Figure 4(c) plots the increase in content uploads in the treatment arm with the dedicated fresh content recommendation stack, compared to the control arm. Throughout the one-month experiment period, a consistent improvement can be observed. Additionally, we note a rising trend as the experiment continues. By setting aside the dedicated slot focusing on fresh content recommendation, content providers are encouraged to upload more contents as their newly uploaded items receive more exposures and gain traction from users. \u00b7 More fresh content is consumed by the users with a minor impact on short-term user engagement. Figure 5(a) demonstrates a significant increase in the number of fresh 7-day positive interactions by + 2 . 52% on average. In Figure 5(b), we find that the overall user dwell time spent on the platform drops slightly by -0 . 12%. However, as shown in Figure 5(c), the user dwell time for small content providers, those with less than a certain number of subscribers, is increased significantly by + 5 . 5%. The trade-off is desirable considering the long-term benefits of a larger discoverable corpus and more active content providers, as explained above. With the established dedicated slot setup for treatment and user corpus co-diverted experiment framework for measurement, we now look into solutions to further increase efficiency of the fresh recommendation stack.", "3 MULTI-FUNNEL FRESH CONTENT RECOMMENDATION": "Different from the main recommendation system, the dedicated fresh recommendation stack focuses on fresh items which have not accumulated enough interaction signals for learning. In this section, we describe how we extend the fresh content nominator in the stack to achieve both high coverage and high relevance when nominating fresh contents. The technique can easily generalize to other components in the pipeline. We center the discussion around the following questions: RQ1 For fresh contents with no or extremely limited interactions, how to effectively infer their relevance to users and bootstrap these contents? RQ2 After accumulating some initial interaction feedback, how to quickly take advantage of the limited real-time user feedback to amplify worthy contents? RQ3 How to balance between content generalization and real-time learning, and reduce the user cost for fresh recommendation, so that we can achieve both high coverage and high relevance when recommending fresh contents?", "3.1 Content Generalization": "Most of the collaborative filtering-based recommendation models [21, 47, 50] rely on a factorization backbone to obtain a set of user and content/item ID embeddings based on historical user interactions or ratings. The learned embeddings are later used to infer users' preference on any contents. Due to the long-tailed distribution of items, there are not enough engagement labels for the newly uploaded contents to learn an informative ID embedding [3, 30]. (a) (b) (c) 275 2625 0.06 25 0.12 2375 0.18 225 0.24 In practice, without appropriate treatment, the small number of labels from fresh and tail contents are usually ignored by the model and become training noise. These contents as a result are rarely surfaced to the right users. The main challenge lies in the lack of existing interaction labels between users and these fresh uploads. A solution is to use a content provider-aware recommender which can bootstrap new uploads produced by a provider the user is familiar with or has already subscribed to, but not others. To overcome the scarcity of interaction labels, we rely on content-based features to characterize the new uploads as in [28, 39, 45]. These content features allow the models to generalize from the abundant engagement labels from popular and established contents to the fresh uploads of similar features. The model structure follows the two-tower architecture as in [51], which utilizes a user and an item/content tower, to encode the information from users and items respectively. The dot product between these two towers are learned to predict the historical preference between an user and an item. The model by itself however is still subject to popularity bias. To adapt the model for fresh content recommendation, we made the following changes: 1) we drop item ID completely in the item tower to prevent the model from memorizing historical preferences on individual items; 2) we also exclude any features indicative of historical popularity of an item, e.g., number of impressions, positive engagements, to reduce popularity bias in the item tower. In other words, only meta features that can generalize between popular and newly uploaded contents are included in the item tower for learning. Content ID Embedding Attention Softmax Dwell Time Time Gap Position X Attentional BOW ReLU User Features Embedding Content ID Softmax The i th Engaged Content We conduct an online A/B testing to measure the impact of the aforementioned changes on improving coverage and relevance of fresh recommendation. The control arm runs a nominator model with the two tower structure as explained in section 2, including all the meta features associated with an item in the item tower. The treatment arm runs the exact same model, but excluding item ID and popularity features from the item tower. We observe that, by removing item ID embeddings and item popularity features, the corpus coverage metric, i.e., Daily Unique Impressed Content at 1,000 is increased by 3.3% with a 95% confidence interval of be [ 3 . 0% , 3 . 7% ] . The fresh content dwell time also increases by 2.6%. The control model can rely on item/content ID embeddings to memorize interaction labels from popular and established contents, but perform poorly on fresh uploads. The treatment model, however, relies on content features to characterize user preference on these popular and established contents, and applies that learning to fresh uploads with similar features, resulting in improved relevance for fresh recommendation. Content Features in Used. The content features used in both the control and treatment arm include multiple categorical features of different granularity derived from the content itself and describe the semantic topic, taxonomic topic and language of the content. Wealso include average rating to filter out the low-quality contents.", "3.2 Real-Time Learning": "While a nominator heavily relying on content features for generalization is effective in bootstrapping fresh contents with little to no user interaction data, it lacks the memorization capability to react to users' initial feedback quickly . Such rapid responsiveness is indeed essential as (i) we often do not have all the features needed to fully characterize the content and reflect the quality of a newly uploaded content; (ii) prompt reaction to initial user feedback can help correct mistakes in early distribution of low-quality or less relevant fresh contents to reduce cost, as well as quickly redistribute and further amplify high-quality and relevant fresh contents to other audiences with similar interests, to further enhance discoverable corpus growth and content provider incentives to upload more. This calls for a near real-time nominator that can ingest data as new interaction data comes along in a streaming fashion. To build such a near real-time nominator, we propose to (i) utilize the near real-time user interaction data for training and (ii) bring up a low-latency personalized retrieval model. We start with minimizing runtime of different components in building this nominator, i.e., data generation, model training and model pushing, so that the end-to-end latency between a user interaction happens and a model (updated with that interaction) is used for serving is a couple of hours. Note this is a significant latency improvement over any of the existing recommendation models in the main recommendation stack, which has an end-to-end latency span 18 to 24 hours or even days. The data generation job collects the most recent 15 minutes user interactions on fresh and tail contents, which is used as the labels to train the retrieval model. The retrieval model is trained on the task of predicting the next item a user will interact with given the historic interactions on the platform. The architecture again uses a two-tower structure, where the user/query tower encodes user interaction sequences, and the item tower uses simple ID embeddings as well as categorical features, as shown in Figure 6. To reduce the training time, we design the model with a simple architecture. The user state is represented as a weighted sum of embeddings of content IDs he or she interacted with recently, concatenated with user query features. Specifically, we apply attention [41] to improve the user state representation. For a given user with the most recent \ud835\udc5b (i.e., 500) engaged contents [ \ud835\udc49 1 , \ud835\udc49 2 , \ud835\udc49 \ud835\udc56 , ..., \ud835\udc49 \ud835\udc5b ] , instead of a naive average, we adopt a weighted sum of the last \ud835\udc5b interactions of the following form to obtain the user representation \ud835\udc48 : where the weight \ud835\udc64 \ud835\udc56 for each content \ud835\udc49 \ud835\udc56 is the normalized softmax weight in [ 0 , 1 ] , derived from item features with in which dwelltime captures the time the user spent on item \ud835\udc49 \ud835\udc56 , and timegap captures the time gap between the interaction happens and the current request time. These features are quantized and encoded as discrete embeddings. \ud835\udc53 then learns a mapping from these embeddings to a scalar to come up with the final weight \ud835\udc64 \ud835\udc56 for the historical interaction on item \ud835\udc49 \ud835\udc56 . Such a weighted score \ud835\udc64 \ud835\udc56 will be able to highlight the content closer to the current request with longer dwell time when aggregating the historical interactions. In our experiment, we find that changing the aforementioned simple attention design with more complex sequence models such as RNNs did not improve the performance, we thus kept the simple weighted embedding for minimal model complexity. The model warm-starts from its previous checkpoint, and trains on the latest 15-minute logs for around an hour in every training round. After that it is published to servers in different data centers to serve the live traffic. At serving time, we again rely on a multiscale quantization approach for fast approximate Maximum Inner Product Search [19, 49] and retrieve the top-50 fresh candidates efficiently. Category-centric Reweighting. To enable fast memorization on the early user feedback on these fresh contents, we include item ID embeddings in the item tower for the real-time nominator. Even among the fresh uploads, the interaction data can vary greatly in pattern: some can accumulate thousands of interaction data in minutes, while others might only see a handful of interactions in that 15-minute log. A model only relying on ID embeddings might run the risk of over-indexing on the \"head\" contents among the fresh uploads due to the imbalanced interaction data. To overcome this issue, we also include some content features mentioned in Section 3.1 to characterize the items. However, many categorical features also fall into long-tail distribution. Some categorical features are broad and apply to a large number of items such as 'music' while others are more specific and informative such as 'Lady Gaga Enigma + Jazz & Piano'. IDF-weighting where we weigh a feature by inverse of its popularity in the overall item corpus, is introduced so the model can focus on learning these more specific content features for generalization while ignoring the broad ones.", "3.3 Low-funnel VS Middle-funnel Contents": "As discussed, trade-off exists in our goals of achieving high coverage and relevance in recommending fresh content. The corpus of the dedicated fresh recommendation stack, indeed can be further categorized into two parts: (i) low-funnel content with very limited or even zero interactions, and (ii) middle-funnel content which have collected a few initial interaction feedback through content generalization. For low-funnel content, real-time learning framework loses its predictive power, and generalization on these contents is in great need. On the other hand, for middle-funnel content, the early feedback can power the training of the real-time nomination system, allowing better personalization and relevance. Instead of trying to achieve both good generalization and real-time learning with a single nominator 4 , we decompose the task by deploying different nominators for different funnels (as shown in Figure 7): one nominator with good generalization performance targeting low-mid funnel; and another one focusing on adapting to user feedback quickly, targeting mid-funnel (with reasonable amount of user feedback to start with). We adopt the idea of serving two or more recommenders simultaneously to gain better performance with fewer of the drawbacks of any individual one [5]. And we will discuss how we determine when to transition a low-funnel content to middle-funnel in such a hybrid system in Section 4.2. Query Division for Multi-funnel Nomination. Anaive strategy to combine these two nominators is to ask them to nominate candidates separately, and then rely on the graduation filter, prescorer and ranker (in Section 2) to pick the final content for the dedicated slot. But we observe that the middle-funnel contents end up dominating the slot due to undesired popularity bias in the ranker. Activating both nominators for a single user request also incur higher serving cost. To mitigate that, we propose query division 0 1,000 2,000 3,000 4,000 5,000 6,000 7,000 8,000 9,000 10,000 \u2265 X Expected Daily Impressions at 100% Tra ffi c - 2.0% - 1.8% - 1.6% - 1.4% - 1.2% - 1.0% - 0.8% - 0.6% - 0.4% - 0.2% 0.0% 0.2% 0.4% 0.6% 0.8% % Change in Daily Unique Videos (a) 0 1,000 2,000 3,000 4,000 5,000 6,000 7,000 8,000 9,000 10,000 \u2265 X Expected Daily Impressions at 100% Tra ffi c - 0.5% - 0.4% - 0.3% - 0.2% - 0.1% 0.0% 0.1% 0.2% 0.3% 0.4% 0.5% 0.6% 0.7% 0.8% 0.9% % Change in Daily Unique Videos (b) multiplexing: to randomly select the two-tower DNN to retrieve low-funnel candidates per query with a probability \ud835\udc5d % (or real-time nominator to retrieve middle-funnel candidates with probability (100\ud835\udc5d )%). We conduct live experiments on different \ud835\udc5d values for the tradeoff between corpus and user metrics in Section 4.2.", "4 EXPERIMENTS": "In this section, we study the multi-funnel design on its effectiveness in improving the efficiency of dedicated fresh recommendation stack with a series of live experiments and analyses on a commercial recommendation platform serving billions of users.", "4.1 Setup": "We test the multi-funnel design in the dedicated fresh recommendation stack as introduced in Section 2. Specifically, we compare the following approaches for dedicated fresh recommendation: (i) Single-funnel nomination is used to nominate fresh candidates with a single recommendation model. We denote the single-funnel nomination system with the two-tower DNN as S-two-tower, and the one with the real-time sequence model as S-real-time; and (ii) Multi-funnel nomination adopts generalization focused twotower DNN to recommend low-funnel content with under \ud835\udc5b \ud835\udc59\ud835\udc5c\ud835\udc64 positive user interactions 5 , and the real-time model to recommend middle-funnel content under the graduation threshold. The two nominators are combined through query multiplexing where twotower DNN is used for \ud835\udc5d % random user queries while the real-time model for for the rest of ( 100 -\ud835\udc5d ) %. We select \ud835\udc5d to be 80 and \ud835\udc5b \ud835\udc59\ud835\udc5c\ud835\udc64 to be 200 as discussed in the following Section 4.2. We ran 1% online user diverted experiment to measure the user metrics and 5% 6 user corpus co-diverted experiment to measure the corpus impact.", "4.2 Performance and Analysis": "The impact of multi-funnel nomination. Comparing the multifunnel nomination with single-funnel nomination on corpus and user metrics, we make the following observations: \u00b7 Daily unique impressed contents . In Figure 8 (left), we find that compared with S-two-tower, S-real-time has significantly lower DUIC at the low end. Specially, it shows 1.79% degradation at the 1,000 impression threshold, which suggests that the realtime nominator is less efficient than the two-tower DNN model in recommending low-funnel contents with little to no interaction data, leading to significantly lower corpus coverage. By combining two-tower DNN to focus on the low-funnel content and the real-time nominator for the middle-funnel content, in Figure 8 (right), we can observe that the DUIC at the low end is significantly improved in the multi-funnel nomination setup, in particular, a 0.65% improvement of DUIC@1000. This indicates that the multi-funnel recommendation is able to improve the fresh content coverage compared with the single-funnel setup. \u00b7 Discoverable Corpus . Table 1 summarizes the comparisons among different options. From the results, we find that with the multifunnel setting, the system is able to improve the metric consistently across the various buckets, and thus enlarges the discoverable corpus. This indicates that multi-funnel nomination is able to identify more quality fresh content that can attract user interactions after exiting the dedicated slot. Interestingly, S-real-time does not show statistically significant change for this metric at higher X. We hypothesize that S-real-time alone is not capable of identifying fresh quality content that is also complementary to the main recommendation system. \u00b7 User metrics . In Figure 9(a), we find that the overall user dwell time on the platform is neutral for both single-funnel (blue) and multi-funnel nomination (red). This suggests that multi-funnel nomination is able to improve corpus metrics without additional cost on short-term user engagement. Furthermore, as observed (a) (b) (c) 0.04 0.8 0.04 008 0.12 24 in Figure 9(b), the multi-funnel system shows a + 0 . 45% increase of the user dwell time for small content providers compared to the single-funnel nominations, demonstrating its strength in uncovering more fresh and tail contents relevant to users. S-realtime, however, shows a significant loss by -1 . 41% for that metric, corroborating that it is much less efficient in covering lowfunnel corpus. On the other hand, it does achieve a much higher number of fresh 7 day positive interactions (shown in Figure 9(c)), suggesting that it infers users' preferences more accurately through utilizing the near real-time interaction feedback. 90% 80% 70% 60% Different probability p % -0.4 -0.2 0.0 0.2 0.4 0.6 % Change of DUIC@1000 Dwell Time The impact of funnel transition cap. To determine when a fresh content transitions from low funnel to middle funnel, we evaluate the corpus performance of the two-tower DNN for generalization under different interaction caps. Note that when we set the interaction cap to be 100, it means that we limit the corpus indexed by this model to only fresh contents with maximum interactions of 100. Since the main purpose of low-funnel recommendation is to improve corpus coverage, we mainly focus on the DUIC metrics of different caps, shown in Table 2. DUIC@1000 reaches its maximum when the cap is set at 200. Setting the cap to 100 achieves similar performance, but further lowering the cap leads to worse metrics. We hypothesize that when the cap is too low, more low quality contents are forced to be nominated by the two-tower model, but later filtered in the ranking stage due to much lower relevance. Indeed, we do observe a 2.9% drop of the number of unique contents receiving non-zero impressions when the cap is lowed from 400 to 100. Meanwhile, certain amount of initial interactions are needed from the low-funnel nominator to provide learning signals for the real-time model. This suggests a future direction to improve generalization in both the middle funnel nominator as well as main recommendation system such as the ranker, so that the multi-funnel transition can be moved further towards low-funnel. The impact of different mixing probabilitiy \ud835\udc5d % . We also tested different multiplexing probabilities of \ud835\udc5d % in using two-tower model for nomination (or (100\ud835\udc5d )% in using real-time model). As discussed previously, when more random requests adopt the real-time model, users will be matched with more relevant contents due to its near real-time model update. As shown in Figure 10, as \ud835\udc5d decreases, the DUIC gain disappears when \ud835\udc5d % reduces to 70%; it, however, increases user dwell time. We select \ud835\udc5d % to be 80% to have a desired trade-off between DUIC@1000 and the user metrics from the dedicated fresh content recommendation.", "5 CONTEXTUAL TRAFFIC ASSIGNMENT": "While fresh content recommendation is beneficial for long-term user experience, it comes at the cost of short-term user engagement as less popular or less familiar contents are recommended. Users coming to the online platform are often heterogeneous in activity levels, and might have varying levels of interests in consuming such contents. There usually exists a set of core users who visit the platform regularly and consistently, while others are casual or emerging users or who tend to visit the platform occasionally. The heterogeneity in activity levels can lead to distinct content consumption patterns in different user groups [6, 44]. And the criteria for grouping the users can be found in [9]. In this initial exploration, we adopt good click-through rate (CTR), conditioning on users spending at least 10 seconds after the click, as a direct user metric to measure the short-term effect of Casual User Emerging User Core User Good CTR Two-tower DNN Real-time Rec the recommendation. In Figure 11, we find that the good CTR for different user groups are very different on candidates recommended by different models. For example, the low-funnel focused model Two-tower DNN achieves similar CTR for casual users compared to the real-time nominator, while it has a significant performance gap on core users. This suggests that these models not only have different strength on item corpus, i.e., low-funnel vs middle-funnel, they also have different strength in handling different user groups. The analysis motivate a potential approach in further improving the performance of the query multiplexing for multi-funnel nomination. The relevance loss in the generalization model for core users is huge compared to users in lower activity levels. Instead of multiplexing users with different activity levels under the same probability, we can further contextualize the traffic assignment based on users/queries. We chose to randomly select \ud835\udc5e % of core users and serve them with nominations from the real-time nominator to take advantage of its short-term user engagement gain. Other users are always served with nominations from the twotower DNN for maximum corpus coverage. In Table 3, by varying the probability in serving core users with the real-time nominator, we can further improve the recommendation efficiency with context-aware hybrid. For example, when we serve 40% core users with real-time nominator, we can obtain significant dwell time and good CTR improvement with neutral change in corpus coverage. More sophisticated multiplexing strategies will be investigated.", "6 RELATED WORK": "Cold-start Item Recommendation. Without enough historic interaction, traditional recommender systems based on collaborative filtering will fail to infer user preference on these newly-available cold-start items [13, 17, 36]. One line of work use the side information, especially content features of items to compensate the absence of collaborative signals. The core idea is to approximate the well-trained collaborative embeddings via content information by modeling their correlation. For example, they try to adopt different objective functions to measure and quantify their correlation, including mean squared root loss [2, 13, 57], contrastive loss [48] and reconstruction loss [54]. Another line of work solves the coldstart problem by regarding it as a special case of warm-start. For instance, some [13, 42] mimic cold-start by dropping partial training signals for the collaborative embeddings. With the recent advance in meta-learning, the work in [27, 34, 40, 56] adopt a learning-tolearn methodology to learn how to adapt the recommender system to newly emerging cold-start items. However, most of the existing work in this domain still centers around the offline setups and hard to be deployed on the large-scale real-world systems due to the high latency and resource cost it will introduce. Our work provides practical insights on cold-start item recommendation on industrial content distribution platforms. Hybrid Recommendation Systems. In practice, it is impossible to find one model that can obtain the optimal performance in all the scenarios [1, 32]. Serving two or more recommenders simultaneously to take advantages of the strengths of each is widely adopted [5]. Given that collaborative methods are more powerful when abundant data is available and content-based recommendation works better on cold-start items, there are previous discussions on a hybrid setup of combining content-based filtering with collaborative filtering to enable to system to serve both the new and existing users [15, 16, 26]. Early hybridization techniques usually compute a linear combination of individual output scores to blend the results from different recommenders [14]. With the recent advance in meta-learning, [11, 12, 32] propose to meta-learn the hard or soft model selector for the optimal hybridization. Meanwhile, the idea of hybrid recommender systems also have a strong connection to the field of ensemble analysis. In this line of work, instead of combining different recommendation backbones (e.g., content-based method and collaborative filtering), the systems serve multiple models with the same backbone simultaneously [38, 52]. We here take advantage of both the generalization and real-time models in a multi-funnel setup for fresh recommendation.", "7 CONCLUSION AND FUTURE WORK": "In this paper, we focus on designing a practical solution to seed the success of high-quality freshly uploaded contents quickly. Specifically, we propose a multi-stage and multi-funnel fresh content recommendation system for a dedicated slot on a large commercial platform that serves billions of users. We share our lessons in designing a two-tower model with strength in content generalization and a low-latency sequence model consuming the real-time feedback to amplify the worthy content. With live experiments, we demonstrate that combining both models through query multiplexing gains better performance in fresh content recommendation by taking advantages of the strengths of both, and achieves a balance between relevance and coverage. We present a future direction in improving the multi-funnel design: by analyzing the query context, it may further improve the coverage of fresh content recommendation while minimizing the short-term user cost.", "REFERENCES": "[1] Charu C Aggarwal et al. 2016. Recommender systems . Vol. 1. Springer. [2] Oren Barkan, Noam Koenigstein, Eylon Yogev, and Ori Katz. 2019. CB2CF: a neural multiview content-to-collaborative filtering model for completely cold item recommendations. In RecSys . 228-236. [3] Alex Beutel, Ed H Chi, Zhiyuan Cheng, Hubert Pham, and John Anderson. 2017. Beyond globally optimal: Focused learning for improved recommendations. In TheWebConf . [4] Youtube Official Blog. 2023. YouTube by the Number. (2023). Retrieved January, 2023 from https://blog.youtube/press/ [5] Robin Burke. 2002. Hybrid recommender systems: Survey and experiments. User modeling and user-adapted interaction (2002). [6] Francis Buttle. 2004. Customer relationship management . Routledge. [7] Allison JB Chaney, Brandon M Stewart, and Barbara E Engelhardt. 2018. How algorithmic confounding in recommendation systems increases homogeneity and decreases utility. In RecSys . [8] Minmin Chen. 2021. Exploration in recommender systems. In RecSys . [9] Minmin Chen, Yuyan Wang, Can Xu, Ya Le, Mohit Sharma, Lee Richardson, SuLin Wu, and Ed Chi. 2021. Values of User Exploration in Recommender Systems. In RecSys . [10] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks for youtube recommendations. In RecSys . [11] Tiago Cunha, Carlos Soares, and Andr\u00e9 CPLF de Carvalho. 2016. Selecting collaborative filtering algorithms using metalearning. In ECML-PKDD . [12] Kaize Ding, Dingcheng Li, Alexander Hanbo Li, Xing Fan, Chenlei Guo, Yang Liu, and Huan Liu. 2021. Learning to Selectively Learn for Weakly-supervised Paraphrase Generation. In EMNLP . [13] Xiaoyu Du, Xiang Wang, Xiangnan He, Zechao Li, Jinhui Tang, and Tat-Seng Chua. 2020. How to learn item representation for cold-start multimedia recommendation?. In MM . [14] Michael Ekstrand and John Riedl. 2012. When recommenders fail: predicting recommender failure for algorithm selection and combination. In RecSys . [15] Andres Ferraro, Dmitry Bogdanov, Jisang Yoon, KwangSeob Kim, and Xavier Serra. 2018. Automatic playlist continuation using a hybrid recommender system combining features from text and audio. In RecSys Challenge . [16] G Geetha, M Safa, C Fancy, and D Saranya. 2018. A hybrid approach using collaborative filtering and content based filtering for recommender system. In Journal of Physics: Conference Series . [17] Jyotirmoy Gope and Sanjay Kumar Jain. 2017. A survey on solving cold start problem in recommender systems. In ICCCA . [18] Qingyu Guo, Fuzhen Zhuang, Chuan Qin, Hengshu Zhu, Xing Xie, Hui Xiong, and Qing He. 2020. A survey on knowledge graph-based recommender systems. TKDE . [19] Ruiqi Guo, Sanjiv Kumar, Krzysztof Choromanski, and David Simcha. 2016. Quantization based fast inner product search. In Artificial intelligence and statistics . PMLR, 482-490. [20] James Hale. 2019. More Than 500 Hours Of Content Are Now Being Uploaded To YouTube Every Minute. (May 2019). Retrieved January, 2023 from https://www.tubefilter.com/2019/05/07/ number-hours-video-uploaded-to-youtube-per-minute/ [21] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In WWW . [22] Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. 2013. Learning deep structured semantic models for web search using clickthrough data. In CIKM . [23] Tim Ingham. 2023. Over 60,000 Tracks are Now Uploaded to Spotify Every Day. That's Nearly One per Second. (2023). Retrieved January, 2023 from https://www.musicbusinessworldwide.com/ over-60000-tracks-are-now-uploaded-to-spotify-daily-thats-nearly-one-per-second/ [24] Amir H Jadidinejad, Craig Macdonald, and Iadh Ounis. 2020. Using Exploration to Alleviate Closed Loop Effects in Recommender Systems. In SIGIR . [25] Ray Jiang, Silvia Chiappa, Tor Lattimore, Andr\u00e1s Gy\u00f6rgy, and Pushmeet Kohli. 2019. Degenerate feedback loops in recommender systems. In AIES . [26] Kyung-Yong Jung, Dong-Hyun Park, and Jung-Hyun Lee. 2004. Hybrid collaborative filtering and content-based filtering for improved recommender system. In Computational Science-ICCS . Springer. [27] Hoyeop Lee, Jinbae Im, Seongwon Jang, Hyunsouk Cho, and Sehee Chung. 2019. MeLU: Meta-Learned User Preference Estimator for Cold-Start Recommendation. In KDD . [28] Joonseok Lee and Sami Abu-El-Haija. 2017. Large-scale content-only video recommendation. In Proceedings of the IEEE International Conference on Computer Vision Workshops . 987-995. [29] Jingjing Li, Mengmeng Jing, Ke Lu, Lei Zhu, Yang Yang, and Zi Huang. 2019. From zero-shot learning to cold-start recommendation. In AAAI . [30] Allen Lin, Jianling Wang, Ziwei Zhu, and James Caverlee. 2022. Quantifying and mitigating popularity bias in conversational recommender systems. In CIKM . [31] Siwei Liu, Iadh Ounis, Craig Macdonald, and Zaiqiao Meng. 2020. A heterogeneous graph neural model for cold-start recommendation. In SIGIR . [32] Mi Luo, Fei Chen, Pengxiang Cheng, Zhenhua Dong, Xiuqiang He, Jiashi Feng, and Zhenguo Li. 2020. Metaselector: Meta-learning for recommendation with user-level adaptive model selection. In TheWebConf . [33] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Ji Yang, Minmin Chen, Jiaxi Tang, Lichan Hong, and Ed H Chi. 2020. Off-policy learning in two-stage recommender systems. In TheWebConf . [34] Feiyang Pan, Shuokai Li, Xiang Ao, Pingzhong Tang, and Qing He. 2019. Warm up cold-start advertisements: Improving ctr predictions via learning to learn id embeddings. In SIGIR . [35] Oleg Rybakov, Vijai Mohan, Avishkar Misra, Scott LeGrand, Rejith Joseph, Kiuk Chung, Siddharth Singh, Qian You, Eric Nalisnick, and Runfei Luo. 2018. The effectiveness of a two-layer neural network for recommendations. (2018). [36] Tobias Schnabel, Mengting Wan, and Longqi Yang. 2022. Situating Recommender Systems in Practice: Towards Inductive Learning and Incremental Updates. arXiv preprint arXiv:2211.06365 (2022). [37] Aleksandrs Slivkins. 2019. Introduction to multi-armed bandits. arXiv preprint arXiv:1904.07272 (2019). [38] Liang Tang, Yexi Jiang, Lei Li, and Tao Li. 2014. Ensemble contextual bandits for personalized recommendation. In RecSys . [39] Aaron Van den Oord, Sander Dieleman, and Benjamin Schrauwen. 2013. Deep content-based music recommendation. In NeurIPS . [40] Manasi Vartak, Arvind Thiagarajan, Conrado Miranda, Jeshua Bratman, and Hugo Larochelle. 2017. A meta-learning perspective on cold-start recommendations for items. In NeurIPS . [41] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NeurIPS . [42] Maksims Volkovs, Guangwei Yu, and Tomi Poutanen. 2017. Dropoutnet: Addressing cold start in recommender systems. In NeurIPS . [43] Jianling Wang, Kaize Ding, and James Caverlee. 2021. Sequential Recommendation for Cold-start Users with Meta Transitional Learning. In SIGIR . [44] Jianling Wang, Ya Le, Bo Chang, Yuyan Wang, Ed H Chi, and Minmin Chen. 2022. Learning to Augment for Casual User Recommendation. In TheWebConf . [45] Jianling Wang, Ainur Yessenalina, and Alireza Roshan-Ghias. 2021. Exploring Heterogeneous Metadata for Video Recommendation with Two-tower Model. arXiv preprint arXiv:2109.11059 (2021). [46] Shoujin Wang, Longbing Cao, Yan Wang, Quan Z Sheng, Mehmet A Orgun, and Defu Lian. 2021. A survey on session-based recommender systems. CSUR (2021). [47] Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural graph collaborative filtering. In SIGIR . [48] Yinwei Wei, Xiang Wang, Qi Li, Liqiang Nie, Yan Li, Xuanping Li, and Tat-Seng Chua. 2021. Contrastive learning for cold-start recommendation. In MM . [49] Xiang Wu, Ruiqi Guo, Ananda Theertha Suresh, Sanjiv Kumar, Daniel N Holtmann-Rice, David Simcha, and Felix Yu. 2017. Multiscale quantization for fast similarity search. Advances in neural information processing systems 30 (2017). [50] Ji Yang, Xinyang Yi, Derek Zhiyuan Cheng, Lichan Hong, Yang Li, Simon Xiaoming Wang, Taibai Xu, and Ed H Chi. 2020. Mixed negative sampling for learning two-tower neural networks in recommendations. In Companion Proceedings of the Web Conference 2020 . [51] Xinyang Yi, Ji Yang, Lichan Hong, Derek Zhiyuan Cheng, Lukasz Heldt, Aditee Kumthekar, Zhe Zhao, Li Wei, and Ed Chi. 2019. Sampling-bias-corrected neural modeling for large corpus item recommendations. In RecSys . [52] Chenrui Zhang and Xueqi Cheng. 2016. An ensemble method for job recommender systems. In RecSys Challenge . [53] Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. 2019. Deep learning based recommender system: A survey and new perspectives. CSUR (2019). [54] Xu Zhao, Yi Ren, Ying Du, Shenzheng Zhang, and Nian Wang. 2022. Improving Item Cold-start Recommendation via Model-agnostic Conditional Variational Autoencoder. arXiv preprint arXiv:2205.13795 (2022). [55] Yujia Zheng, Siyi Liu, Zekun Li, and Shu Wu. 2020. Cold-start Sequential Recommendation via Meta Learner. In AAAI . [56] Yongchun Zhu, Ruobing Xie, Fuzhen Zhuang, Kaikai Ge, Ying Sun, Xu Zhang, Leyu Lin, and Juan Cao. 2021. Learning to warm up cold item embeddings for cold-start recommendation with meta scaling and shifting networks. In SIGIR . [57] Ziwei Zhu, Shahin Sefati, Parsa Saadatpanah, and James Caverlee. 2020. Recommendation for New Users and New Items via Randomized Training and Mixture-of-Experts Transformation. In SIGIR ."}
