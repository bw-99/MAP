{
  "MERIT: A Merchant Incentive Ranking Model for Hotel Search & Ranking": "Shigang Quan Shanghai Jiao Tong University Shanghai, China quan123@sjtu.edu.cn Shui Liu Alibaba Group Hangzhou, Zhejiang, China shui.lius@alibaba-inc.com",
  "Zhenzhe Zheng": "Hailong Tan Alibaba Group Hangzhou, Zhejiang, China hailong.thl@alibaba-inc.com",
  "Ruihao Zhu": "Shanghai Jiao Tong University Shanghai, China zhengzhenzhe@sjtu.edu.cn Cornell University Ithaca, USA ruihao.zhu@cornell.edu Quan Lu Alibaba Group Hangzhou, Zhejiang, China luquan.lq@alibaba-inc.com",
  "ABSTRACT": "Online Travel Platforms (OTPs) have been working on improving their hotel Search & Ranking (S&R) systems that facilitate efficient matching between consumers and hotels. Existing OTPs focus almost exclusively on improving platform revenue. In this work, we take a first step in incorporating hotel merchants' objectives into the design of hotel S&R systems to achieve an incentive loop: the OTP tilts impressions and better-ranked positions to merchants with high quality, and in return, the merchants provide better service to consumers. Three critical design challenges need to be resolved to achieve this incentive loop: Matthew Effect in the consumer feedback-loop, unclear relation between hotel quality and performance, and conflicts between short-term and long-term revenue. To address these challenges, we propose MERIT , a MER chant I nce T ive ranking model, which can simultaneously take the interests of merchants and consumers into account. We define a new Merchant Competitiveness Index (MCI) to represent hotel merchant quality and propose a new Merchant Tower to model the relation between MCI and ranking scores. Also, we design a monotonic structure for Merchant Tower to provide a clear relation between hotel quality and performance. Finally, we propose a Multiobjective Stratified Pairwise Loss, which can mitigate the conflicts between OTP's short-term and long-term revenue. To demonstrate the effectiveness of MERIT, we compare our method with several state-of-the-art benchmarks. The offline experiment results indicate that MERIT outperforms these methods in optimizing the demands of consumers and merchants. Furthermore, we conduct an online A/B test and obtain an improvement of 3.02% for the MCI score. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CIKM '23, October 21-25, 2023, Birmingham, United Kingdom. Â© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0124-5/23/10...$15.00 https://doi.org/10.1145/3583780.3614866 Liangyue Li Alibaba Group Hangzhou, Zhejiang, China liliangyue.lly@alibaba-inc.com",
  "Fan Wu": "Shanghai Jiao Tong University Shanghai, China fwu@cs.sjtu.edu.cn Based on these results, we have deployed MERIT online on Fliggy, one of the most popular OTPs in China, to serve tens of millions of consumers and hundreds of thousands of hotel merchants.",
  "CCS CONCEPTS": "Â· Information systems â†’ Recommender systems .",
  "KEYWORDS": "Hotel Search & Ranking System; Monotonic Neural Networks; Hotel Quality",
  "1 INTRODUCTION": "Nowadays, Online Travel Platforms (OTPs) are applying deep learning [16, 17, 19, 35, 37] in their hotel Search & Ranking (S&R) systems, to accurately provide consumers with their interested hotel-related products. Similar to product recommendation in online e-commerce platform [40, 41], hotel S&R systems also need to capture consumers' diverse interests in different hotels to optimize consumer experiences and platform revenue. Different from conventional ecommerce platforms, however, OTPs also have to take the features and objectives of hotel merchants into account. Products sold on OTPs are highly standard room-type items coming from the same hotel merchants, and all OTPs share the same product inventory. As a result, the room inventories and corresponding prices negotiated and acquired from hotel merchants have become the core competitiveness of OTPs in markets. To ensure the healthy growth of the OTP and form a good collaborative relation with hotel merchants, it is important to achieve the incentive loop for hotel merchants as illustrated in Figure 1: the platform tilts impressions and better-ranked positions to the merchants with high quality, and in return, the merchants provide more room inventories and lower prices on the platform, attracting more consumers to the platform. However, achieving this incentive loop is not trivial. Though several works [17, 35, 39] started to consider merchant features, such as the price and location, into hotel S&R systems, the objective CIKM '23, October 21-25, 2023, Birmingham, United Kingdom. Quan, et al. Figure 1: The positive incentive loop for hotel merchants on OTPs. Rooms:25 $65 $62 Rooms:32 Ranking Position Merchant Clicks Orders Incentive Algorithm more room inventories, lower prices, ... better-ranked positions, more clicks and orders,... of these works remains to serve consumers and ignore the demands from hotel merchants. Some works [3, 4] consider designing positive incentive mechanisms for consumers. In this work, we take a first step in incentivizing hotel merchants' objectives into the design of hotel S&R systems. Several critical, yet largely overlooked, design challenges during the interaction between consumers and merchants through OTPs are summarized as follows: Â· Matthew Effect in consumer feedback-loop. On OTPs, impressions and ranked positions of hotels are based on their historical CTRs (Click-Through Rates) and CVRs (Conversion Rates). The consumer feedback about CTRs and CVRs impacted by the current hotel positions will be used for the next ranking stage as a loop [29]. The above feedback-loop in current hotel S&R systems would cause Matthew Effect [7, 36]: more impressions and better-ranked positions are tilted toward those hotels with higher historical CTRs and CVRs, and merchants with better quality would not obtain their desired ranked positions due to the lack of historical data. The OTPs need to break the Matthew Effect and provide flexible knobs for potential high-quality merchants to optimize their obtained impressions and ranked positions. Â· Unclear relation between hotel quality and performance. From hotel merchants' perspectives, they hope to receive explicit and confirmed performance feedback after improving the quality of their hotels. But existing hotel S&R systems directly take the features of consumers, hotel rooms and context, as the inputs of black-box learning models. The quality of hotel rooms would be mixed or even under-weighted in various features during the ranking stage. Thus, the hotel merchants cannot know a clear relation between the hotel quality and the potential performance improvement. This unclear relation of hotel feature and performance decreases the incentives for hotel merchants to invest on the OTPs. Â· Conflicts between short-term and long-term revenue. A consumer's whole behavior cycle can be summarized as follows: a consumer books a hotel online on OTPs, checks in offline, and finally submits ratings on OTPs. OTPs focus almost exclusively on improving CTRs and CVRs, which can be thought of as short-term revenue. However, the quality of merchants can not be reflected by online booking. Ignoring the quality of merchants will deteriorate the long-term revenue of OTPs. Therefore, from the perspective of OTPs, we should improve long-term revenue while striking to ensure that short-term revenue is nearly unchanged. By jointly considering these challenges, we propose MERIT , a MER chant I nce T ive ranking model, to explicitly represent the relation between hotel merchants and consumers, and optimize the OTP's revenue via the ranking stage in the hotel S&R system. To tackle the first challenge, we define a new Merchant Competitiveness Index (MCI) metric to represent the quality of hotel merchants, and design a Merchant Tower to model the relation between the MCI and ranking scores. In addition, it will be combined with the CTRTower and CVR Tower to improve both merchant performance and consumer experiences. To address the second challenge, we introduce a monotonic neural network into the Merchant Tower. The monotonic neural network has been implemented in deep learning to guarantee the model interpretability [5, 10, 12, 25, 30]. The monotonicity in the Merchant Tower will provide an explicit ranking rule that can be understood by the hotel merchants, and guide them to further optimize their hotel products for higher ranking scores. To resolve the final challenge, we define a Multi-objective Stratified Pairwise Loss to mitigate conflicts between the short-term and longterm revenue, which guarantees that we can improve the long-term revenue of OTPs without sacrificing the short-term revenue too much. Based on the solution described above, MERIT jointly learns the interests and intentions of merchants and consumers, improving the consumer-hotel matching performance of the hotel S&R system in the long run. We conduct an extensive offline experiment on a large-scale offline hotel S&R dataset, and results show that MERIT is effective in improving merchant satisfaction and platform performance. In the online A/B test, the average MCI scores have increased by 3.02% compared with the baseline model. Furthermore, MERIT has been deployed on Fliggy 1 , one of the most popular OTPs in China, where it serves tens of millions of consumers and hundreds of thousands of hotel merchants. We summarize our main contributions in this work as follows: (1) Weexplicitly consider the quality of hotel merchants in hotel S&R systems. We define the MCI metric to evaluate hotel quality, and propose a new MERIT model with a Merchant Tower to calculate the MCI metric and integrate it into the ranking scores. (2) Weintroduce monotonicity property for the merchant Tower to provide a clear and positive relation between the hotel features and ranking performance. The offline experiment demonstrates that guaranteeing MCI monotonicity and improving monotonicity sensitivity will increase the incentives for hotel merchants to invest on OTPs. (3) In order to mitigate the conflicts between short-term and long-term revenue of OTPs, we propose the Multi-objective Stratified Pairwise Loss. The extensive offline experiment indicates that the ranking process can be improved via this loss function as opposed to multi-objective pairwise loss. 1 http://www.fliggy.com/ MERIT: A Merchant Incentive Ranking Model for Hotel Search & Ranking CIKM '23, October 21-25, 2023, Birmingham, United Kingdom. (4) We conduct both offline evaluation on a large-scale hotel S&R dataset and a online A/B test. Evaluation results show that MERIT is effective in improving merchant satisfaction and platform performance. Furthermore, MERIT has been deployed on Fliggy and brought remarkable profit growth.",
  "2 RELATED WORK": "",
  "2.1 Click-through Rate Prediction": "In the search engine, online advertising, and recommendation system, predicting consumers' CTR has become a key problem and a lot of works have focused on this area. Recently, the deep learning methods [8, 14, 18, 19, 26, 33, 40, 41] have been introduced into CTR prediction models due to the strong representation of deep learning methods. These CTR prediction models often follow the paradigm of Embedding Layer and MLP. To strengthen the capability of capturing the nonlinear feature interaction, some works propose specific networks to learn high-order cross features. Cheng et al. [8] use the wide structure to memorize nonlinear features and utilize the deep model to improve the generalization of the feature interaction. Guo et al. [14] propose the DeepFM to combine the traditional factorization machine method [27] and DNN. Another line of the CTR prediction model is capturing consumer interests from consumer historical behaviors. Zhou et al. [41] propose DIN to utilize the attention mechanism to capture consumers' diverse interests. DIEN [40] extends DIN and uses the Gated Recurrent Unit (GRU) [9] layer to model the process of sequential interest evolving. Our research is different from CTR prediction methods in two aspects: First, the CTR prediction model considers the consumer click behavior as its label while our method considers both consumer sequential behaviors and the merchant quality as our labels. Another distinction is that we incorporate and model merchant interests, which is not taken into account in previous work.",
  "2.2 Multi-task Learning": "Multi-task learning is to simultaneously utilize a composite model to complete different tasks. The original multi-task learning model often takes the shared-bottom layers [6] to model the complex relation between various tasks. But this design of shared-bottom layersis strongly constrained. MoE [20] proposes the gate layer to balance the conflicts of different tasks. MMoE [22] extends MoE to add multiple gates. Tang et al. [31] propose PLE and utilize taskspecific experts and task-shared experts to mitigate the negative transfer problem between tasks. The multi-task learning models in the recommendation system and online advertising are often used to predict consumer CTRs and CVRs. Ma et al. [23] propose ESMM to tackle the problems of data sparsity and sample selection bias. Wen et al. [34] propose the consumer post-click behavior decomposition method to address the aforementioned problems. Our method also attempts to optimize multi-tasks, but we do not adhere to the basic paradigm of Shared&Gated Networks because the objectives of consumers and merchants are heterogeneous and the shared structure is inappropriate for this scenario. Figure 2: The overview framework of hotel S&R system. Update Pre-ranking Ranking Hotel S&R System 3.Display Consumer Merchant Candidate Hotels Provide 1.Query 2.Request Data Logs Matching List Pages 4. Consumer Behavior Log Click Order",
  "2.3 Monotonicity in Neural Networks": "Adding prior knowledge to a model can reduce the search space of model parameters. As one of prior information, monotonicity can ensure the neural networks can generalize better and improve the interpretability of a black-box neural network. Current adding monotonicity in neural networks can be classified into two types. The first type is constraining the structure of neural networks. The MIN-MAX Network [11] utilizes a three-layer network to make the model partial monotonic. You et al. [38] propose Deep Lattice Networks (DLN) and take the ensembles of lattice and calibrators as the constraints of monotonicity. Though DLN can improve the precision, the complexity of the model also increases. Another type is changing the loss function. Gupta et al. [15] propose pointwise monotonic loss to penalize the negative gradients. Liu et al. [21] add the monotonicity regularization with the uniform data sampling. In contrast to former works [17, 35], which utilize the monotonicity structure to improve the accuracy, in this paper, we follow the monotonicity structure to provide an explicit ranking rule that can be understood by the merchants, and guide them to further optimize their hotels for higher ranking scores.",
  "3 PRELIMINARIES": "",
  "3.1 An Overview of Hotel S&R System": "We briefly introduce the hotel S&R system illustrated in Figure 2. In the scenario of the hotel S&R system, a consumer can issue a query depending on her travel plan. This request will be sent to the hotel S&R system, which will select the candidate hotels provided by the merchant through different stages based on the amount of data, computational resources, and response latency: matching, pre-ranking, ranking, and so on. After the final ranking stage, the system recommends the top hotels sorted by their ranking scores, and the consumer will click on the corresponding hotel and enter the detail page. The detailed information includes available hotel rooms, prices, and consumer reviews. Orders are then placed by consumers. Each time a consumer interacts sequentially with the hotel S&R system, her sequential behaviors (click, order, etc.) will be logged in data logs and used to update the parameters of the hotel S&R system. CIKM '23, October 21-25, 2023, Birmingham, United Kingdom. Quan, et al. Table 1: Factors of Merchant Competitiveness Index.",
  "3.2 Merchant Quality Rating Score": "Merchant quality is a key indicator used to represent the performance of a merchant from different aspects. To better represent merchant quality, we choose factors of merchant quality and define the Merchant Competitiveness Index (MCI) shown in Table 1. The Operational Capability (OC) of a merchant is calculated using three indicators: Inventory-to-Sales Ratio, Gross Merchandise Value (GMV), and Historical Conversion Rate. The room sold ratio of hotel is denoted by Inventory-to-Sales Ratio, whilst the overall revenue for hotels is denoted by GMV. The Online Inventory refers to the remaining inventory, while the Hot Selling Room Ratio refers to the remaining hot selling room inventory that the merchant can provide. The Service Refusal Rate is the percentage of hotel orders are rejected when consumers check in offline. The Order Refusal Rate is the percentage of hotel orders that are canceled by merchants. Also, we take the information of detail pages into consideration, such as the Picture Quality and the Completeness of Hotel Information. In this paper, the MCI score will be used for both input feature ğ‘¥ ğ‘€ğ¶ğ¼ in Section 3.3 and ranking label ğ‘§ in Section 4.1.",
  "3.3 Problem Definition": "In the scenario of the hotel S&R system, we assume the dataset to be D = {( ğ’™ ğ‘– â†’ ğ‘¦ ğ‘– , ğ‘§ ğ‘– )}| ğ‘ ğ‘– = 1 , and we draw the sample ( ğ’™ â†’ ğ‘¦, ğ‘§ ) from domain X Ã— Y Ã— Z , where X is feature space, Y and Z are label spaces, and ğ‘ is the size of D . ğ’™ can be defined in the form of ğ’™ = ( ğ‘¢, ğ‘, â„ ğ‘¡ ) , in which ğ‘¢ is the consumer on the OTP, ğ‘ is the query issued by ğ‘¢ , and â„ ğ‘¡ is the target hotel. ğ‘¦ represents the click&order label and ğ‘§ represents the MCI label. ğ‘¦ is a three-class label, with ğ‘¦ = 0 indicating not being clicked and ordered, ğ‘¦ = 1 indicating being clicked but not ordered, and ğ‘¦ = 2 indicating being clicked and ordered. So on the OTP, the objective of the hotel S&R system is to learn a model F from the dataset D . F aims to predict the ranking score Ë† ğ‘  for consumer ğ‘¢ and target hotel â„ ğ‘¡ based on the input features ğ’™ :  where Ë† ğ‘  is the ğ‘ğ¶ğ‘‡ğ¶ğ‘‰ğ‘… ( ğ‘ğ¶ğ‘‡ğ¶ğ‘‰ğ‘… will be explained in Section 4.2) and is obtained by Ë† ğ‘  ğ¶ğ‘‡ğ‘… Ã— Ë† ğ‘  ğ¶ğ‘‰ğ‘… .",
  "4 METHODOLOGY": "In this section, we give a detailed introduction to our approach as illustrated in Figure 3. Features and their representation are provided in Section 4.1. Section 4.2 introduces the framework of the Merchant Incentive Layer and to tackle the conflict of multiobjective pairwise loss, we propose the MSPL in Section 4.3.",
  "4.1 Feature Representation": "We use four types of features: consumer features, query features, hotel features, and MCI features. Consumer features are divided into three categories: consumer basic profile ğ‘¥ ğ‘ (age, purchase level, etc.), consumer historical preference features ğ‘¥ ğ‘ (consumer preference on the price and location of a hotel based on her historical interaction behaviors), and consumer context features ğ‘¥ ğ‘ (time, pid, etc.). The query features ğ‘¥ ğ‘ include search keywords. The hotel features are hotel item basic profile ğ‘¥ â„ . The features of MCI in Table 1 will be represented as ğ‘¥ ğ‘  . The aforementioned categorical features are encoded as one-hot vectors, while continuous features are discretized and encoded as vectors. Input vectors are represented by the following symbols: ğ‘‹ ğ‘ , ğ‘‹ ğ‘ , ğ‘‹ ğ‘ , ğ‘‹ ğ‘ , ğ‘‹ â„ , ğ‘‹ ğ‘  . To transform these high-dimensional, sparse one-hot vectors into low-dimensional, dense vectors, we utilize embedding layers [2, 24]. These low-dimensional, dense vectors can be denoted as ( ğ¸ ğ‘ , ğ¸ ğ‘ , ğ¸ ğ‘ , ğ¸ ğ‘ , ğ¸ â„ ) .",
  "4.2 Merchant Incentive Module": "To learn the relation between the consumer and the target hotel, we utilize a concatenate layer to concatenate all the embedded feature vectors:  where ğ‘Ÿ denotes the concatenated embedded vector. Then in order to learn the high-order and low-order interactions of features, we adopt the Deep&Cross Network [33] into our model as follows:   where ğ¸ ğ¶ğ‘‡ğ‘… and ğ¸ ğ¶ğ‘‰ğ‘… denote the representation vectors for CTR and CVR predictions, respectively. For the CTR part, the CTR Tower 2 will learn a parameterized mapping function from the representation ğ¸ ğ¶ğ‘‡ğ‘… to ğ‘ğ¶ğ‘‡ğ‘… while the Merchant Tower will learn a parameterized mapping function for ğ¸ ğ¶ğ‘‡ğ‘… and a monotonic parameterized mapping function for ğ‘‹ ğ‘  as follows:  where ğœ™ ğµ ğœƒ (Â·) is a positive-weight feed-forward network [1] and ğœ“ ğ¶ğ‘‡ğ‘… ğœƒ (Â·) is a feed-forward network. The Merchant Tower is designed to calibrate the predicting process and strengthen the monotonicity of our model. And CVR prediction structure is similar to the CTR prediction structure as follows:  where ğœ“ ğ¶ğ‘‰ğ‘… ğœƒ (Â·) is a feed-forward network. The relation between the features of MCI and the final ranking score will adjust based on the context, so ğ¸ ğ¶ğ‘‡ğ‘… and ğ¸ ğ¶ğ‘‰ğ‘… will be also fed into the Merchant Tower ( ğœ™ ğµ ğœƒ (Â·) ) to cross ğ‘‹ ğ‘  and other features. 2 \"Tower\" is a term used in the field of multi-task learning and typically refers to a neural network designed for individual tasks. MERIT: A Merchant Incentive Ranking Model for Hotel Search & Ranking CIKM '23, October 21-25, 2023, Birmingham, United Kingdom. Figure 3: The overview architecture of MERIT, which consists of the Feature Representation Layer, Concatenate Layer, Merchant Incentive Module, and MSPL (Multi-objective Stratified Pairwise Loss). The Merchant Incentive Module consists of Deep&Cross Network, CTR/CVR Tower, Merchant Tower, and Entire Space Modeling. Merchant Tower CVR Tower pCTR pCVR pCTCVR Query Hotel Profile ğ¸ ! ğ¸ \" ğ¸ # ğ¸ $ ğ¸ % Element-wise Product Element-wise Add Sigmoid Unit Deep&Cross Network â„’ \"&'()'*+ ,-.|-01-21 â„’ \"&'()'*+ -01-21 Concatenate Layer User Profile User Behavior Context MCI Score Deep&Cross Network Merchant Tower CTR Tower Unconstrained Weight Positive Weight Sparse Features Dense Features Feature Representation Layer Multi-objective Stratified Pairwise Loss Entire Space Modeling Merchant Incentive Module â„’ \"3'45)'*+ 67,, In order to avoid sample Selection Bias (SSB) and Data Sparsity (DS) issues [23], we follow the entire space modeling [23]. We calculate ğ‘ğ¶ğ‘‡ğ¶ğ‘‰ğ‘… (predicted post-view Click-Through rate&ConVersion Rate) as our final ranking score, and its definition is as follows: ğ‘ . Pairwise loss functions can be defined as follows:",
  "4.3 Multi-objective Stratified Pairwise Loss": "Unlike pointwise loss, which calculates the numerical gap of each sample, pairwise loss [28] measures the range between positive and negative samples. Pairwise loss outperforms pointwise loss in representing the overall ranking performance. Consequently, we incorporated pairwise loss to evaluate the ranking outcomes. However, a conflict may arise when undertaking multi-objective optimization using pairwise loss: Conflict of Multi-objective Pairwise Loss For the sake of simplicity, we will use two objectives, ğ‘Œ and ğ‘ , as an example, where ğ‘Œ is the primary objective and ğ‘ is the secondary objective. Andfor each objective, Y + , Y are the positive and negative sample sets of ğ‘Œ . Z + and Z are the positive and negative sample sets of  where I is the indicator function and â„“ (Â·) is the negative log-likelihood loss function. Suppose that if ğ‘– âˆˆ Y + âˆ© Z and ğ‘— âˆˆ Y âˆ© Z + , then the conflict problem occurs: For objective ğ‘Œ , the pairwise loss function L ğ‘Œ ğ‘ğ‘ğ‘–ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’ is encouraged to enlarge the ranking score gap between ğ‘– and ğ‘— , while for ğ‘ , the pairwise loss function L ğ‘ ğ‘ğ‘ğ‘–ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’ is encouraged to enlarge the ranking score gap between ğ‘— and ğ‘– . During the training process, inconsistency in gradient directions will deteriorate the effectiveness of multi-objective optimization. In the scenario of the hotel S&R system, the above conflict corresponds to Challenge 3: the conflict of platform revenue and consumer experience. Multi-objective Stratified Pairwise Loss In order to tackle the above conflict problem, we define the Multi-objective Stratified Pairwise Loss (MSPL) for the multi-objective ranking. It can be CIKM '23, October 21-25, 2023, Birmingham, United Kingdom. Quan, et al. defined as follows:  The above pairwise loss function L ğ‘ | ğ‘Œ ğ‘ğ‘ğ‘–ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’ can be effective when the second objective ğ‘ is consistent with the primary objective ğ‘Œ , and, otherwise, the loss function will be masked. And it is noted that samples ğ‘– and ğ‘— are symmetrical, so we only consider the greater relation. In the hotel scenario, ğ‘¦ (corresponding ğ‘Œ ) is the primary objective and ğ‘§ (corresponding ğ‘ ) is the secondary objective, so the loss function can be defined as follows:  where L ğ¶ğ‘‡ğ‘…ğ¶ğ‘‰ğ‘… ğ‘ğ‘ğ‘–ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’ (corresponding L ğ‘Œ ğ‘ğ‘ğ‘–ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’ ) a pairwise ranking loss, which aims to enlarge the ranking score gap between ğ‘– and ğ‘— when label level ğ‘¦ ğ‘– is larger than ğ‘¦ ğ‘— . L ğ‘€ğ¶ğ¼ | ğ¶ğ‘‡ğ‘…ğ¶ğ‘‰ğ‘… ğ‘ğ‘ğ‘–ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’ (corresponding L ğ‘ | ğ‘Œ ğ‘ğ‘ğ‘–ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’ ) is also a pairwise ranking loss for label ğ‘§ , but we add an extensive stratified constraint I ( ğ‘¦ ğ‘– â‰¥ ğ‘¦ ğ‘— ) to ensure the loss is only effective when label level ğ‘¦ ğ‘– is larger or equal than ğ‘¦ ğ‘— . We follow the ESMM pointwise loss function [23] as the basic loss function:  where Ë† ğ‘  ğ¶ğ‘‡ğ‘… ğ‘˜ denotes the predicted CTR score of sample ğ‘˜ . And training loss function L consists of three parts: L ğ¸ğ‘†ğ‘€ğ‘€ ğ‘ğ‘œğ‘–ğ‘›ğ‘¡ğ‘¤ğ‘–ğ‘ ğ‘’ , L ğ¶ğ‘‡ğ‘…ğ¶ğ‘‰ğ‘… ğ‘ğ‘ğ‘–ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’ , and L ğ‘€ğ¶ğ¼ | ğ¶ğ‘‡ğ‘…ğ¶ğ‘‰ğ‘… ğ‘ğ‘ğ‘–ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’ :  where ğœ† 1 and ğœ† 2 are hyper-parameters that balance the above three loss functions. We empirically explore their influence in Section 5.3.",
  "5 EXPERIMENTS": "To evaluate the effectiveness of our proposed method, we compare it with state-of-the-art methods and report our experimental results and corresponding analysis in this section. In order to choose the appropriate hyper-parameters, we explain the detailed process of choosing ğœ† 1 and ğœ† 2. Finally, an online A/B test is conducted in the hotel S&R system on Fliggy.",
  "5.1 Dataset and Experimental Settings": "Dataset Descriptions The offline hotel S&R dataset is generated based on the consumer logs collected from the hotel S&R system on Fliggy. As illustrated in Figure 2, each sample in this dataset is based on the impression of each consumer's search result. We take the clicking and ordering samples as positive samples, while others as negative samples. The features of these samples primarily contain three aspects of information, namely consumers, hotels, and search keywords. The consumer features include basic consumer attributes, long-term and short-term hotel preferences, and the distance between the consumer and the hotel. The hotel features include hotel basic attributes, real-time prices and inventories, historical behavior statistics, and factors of hotel quality. The keyword features include searching scene types, the distance between searching location and candidate hotels, the semantic similarity between search words and candidate hotels, etc. The offline hotel S&R dataset statistics are presented in Table 4. The dataset contains 300 million training samples and 14 million test samples, which are partitioned by time. Experimental Settings MERIT is deployed in TensorFlow 3 . We employ a grid search strategy to determine optimal hyperparameters for our models. The ADAM optimizer is used to train all models, with a fixed learning rate of 0.001 and a batch size of 2048. To prevent overfitting, we apply ğ¿ 2 regularization with a weight of 0.00001, as well as batch normalization with a dropout rate of 0.3. The balancing hyper-parameters ğœ† 1 and ğœ† 2 we use are 1.0 and 0.1. The embedding size for consumer and query features is set at 4, while the embedding size for context and item features is set at 8. The CTR and CVR Towers are implemented via a threelayer fully connected network with sizes of 256, 128, and 64. For multi-task learning models, a three-tower MLP is constructed to predict CTR, CVR, and MCI, with the gated network implemented via a softmax layer. MMoE utilizes 8 expert networks, while CGC employs 1 shared expert network and 1 specific expert network. The MIN-MAX network uses 10 groups of 10 linear functions. Baselines To evaluate the effectiveness and superiority of our methodology, we compare our method with state-of-the-art multitask learning models. And we also choose some monotonic networks to compare the ranking results. These baselines are as follows: Â· DNN [13]: We only use a Multi-Layer Perceptron to construct the CTR Tower and CVR Tower, and input features are the same as MERIT. Â· Shared Bottom [6]: The Shared Bottom model uses the unified bottom layer and different towers for all the tasks. It aims to utilize a shared bottom layer to learn correlations between different tasks. Â· MMoE [22]: The MMoE method with multiple gate networks is designed to control the expert networks for different tasks and relieve the negative transfer problem. Â· CGC [32]: Customized Gate Control (CGC) with an ExpertBottom layer intends to mitigate the seesaw phenomenon [32] via task-specific experts and task-shared experts. For a fair comparison, we do not take the progressive layered designing. Â· MERIT (MIN-MAX Network) [11]: It follows the MERIT structure and replaces the Merchant Tower with the MINMAX Network. The MIN-MAX Network is a three-layer structure with max-pooling and min-pooling. Â· MERIT (Point-wise Monotonic Loss) [15]: It follows the MERIT structure and replaces the Merchant Tower with a Multi-Layer Perceptron and Point-wise Monotonic Loss. 3 http://tensorflow.org/ MERIT: A Merchant Incentive Ranking Model for Hotel Search & Ranking CIKM '23, October 21-25, 2023, Birmingham, United Kingdom. Table 2: Comparison of multi-task learning models and monotonic networks on the offline hotel S&R dataset. Results of CTR (Click-Through Rate), CVR (Conversion Rate), and CTCVR (post-view Click-Through&Conversion Rate) are presented. The best results of all methods are indicated in bold, while the second best results are indicated in underlined. The Gain means the AUC improvement of MERIT+MSPL compared with DNN. Table 3: Comparison of multi-task learning models and monotonic networks on the offline hotel S&R dataset. The MCI ranking results are presented. The best results of all methods are indicated in bold, while the second best results are indicated in underlined. The Gain means the NDCG improvement of MERIT+MSPL compared with DNN and âˆ— means p-value < 0.001 in significance tests compared to the best baseline. Table 4: Statistics of the offline hotel S&R dataset. Point-wise Monotonic Loss is the loss function penalizing the negative gradients. Â· MERIT+MPL : It follows the MERIT structure and we add Multi-objective Pairwise Loss. Â· MERIT+MSPL : It follows the MERIT structure and we add Multi-objective Stratified Pairwise Loss as defined in Equation (9). Evaluation Metrics Our approach is to strike a balance between consumer and merchant engagement. Specifically, our model focuses on binary classification of whether a hotel has been clicked and ordered by consumers, while also ranking hotels according to MCI for hotels. To evaluate our method against baselines, we employ two types of metrics.: Â· AUC : Area Under Curve (AUC) is a widely used metric to measure the ranking result for the whole model. It indicates the probability that positive samples rank higher than negative samples. Â· GAUC : Group Area Under Curve (GAUC) partitions test samples into groups via the consumer id, and AUC is calculated by each group. It is defined as follows:  where ğ‘¤ ğ‘¢ is the sample size of consumer ğ‘¢ . CIKM '23, October 21-25, 2023, Birmingham, United Kingdom. Quan, et al. CTCVR AUC 0.01 0.05 0.1 0.2 2 0.90 0.91 0.92 0.93 0.94 0.95 0.96 0.97 NDCG@20 0.82 0.84 0.86 0.88 0.90 (a) 1 =0.1 NDCG@20 CTCVR AUC 0.01 0.05 0.1 0.2 2 0.90 0.91 0.92 0.93 0.94 0.95 0.96 0.97 NDCG@20 0.82 0.84 0.86 0.88 0.90 CTCVR AUC (c) 1 =1.0 NDCG@20 CTCVR AUC 0.01 0.05 0.1 0.2 2 0.90 0.91 0.92 0.93 0.94 0.95 0.96 0.97 NDCG@20 0.82 0.84 0.86 0.88 0.90 (b) 1 =0.5 NDCG@20 CTCVR AUC CTCVR AUC Figure 4: The NDCG@20 of MCI ranking and CTCVR AUC for different hyper-parameters ğœ† 1 and ğœ† 2 . The dashed line indicates the lower bound of CTCVR AUC we can tolerate (From the online experiment, we consider that a 0.005 decline of CTCVR AUC is acceptable, so we set the lower bound of CTCVR AUC as 0.892 with the best 0.897.), and we choose ğœ† 1 and ğœ† 2 from points in the light green area. Â· NDCG@K : Normalized Discounted Cumulative Gain (NDCG) indicates the ratio between current ranking performance and the ideal ranking performance. It considers the ranking position in terms of relation score. In this experiment, the ranking performance totally via the MCI label will be the ideal ranking performance. We choose Top-K test samples as the evaluated group. objective of our method is to optimize the merchant demand, so the minor decline in consumer demand is unavoidable and reasonable. Also, we can recognize that the decline is primarily due to CVR ranking results. Â· wNDCG@K : weighted Normalized Discounted Cumulative Gain (wNDCG) partitions the test samples into each group via the session id, and for each session, we calculate the NDCG. Its mathematical formulation is as follows:  where ğ‘¤ ğ‘  is the length of session ğ‘  .",
  "5.2 Offline Comparison Results": "In this subsection, we compare our proposed model with several multi-task learning models and monotonic networks on the test set of the offline hotel S&R dataset. The AUC and GAUC results of predicting consumer feedback are reported in Table 2, while NDCG and wNDCG results of ranking MCI label are illustrated in Table 3. Based on our analysis of predicting consumer implicit feedback, we made the following observations: Â· Compared with the DNN model, multi-task learning models can improve part of the predicted scores. Specifically, the CGC model achieves the best performance compared with the DNN model and other multi-task learning models, because it follows the different designs of expert networks. Â· The MERIT model can get nearly equal results compared with the base model. Especially, the CVR AUC improves by 0.0012, 0.0015, and 0.0010 for different monotonic models compared with the base model, which indicates the monotonicity for ğ‘‹ ğ‘  can better predict consumers' purchase behaviors. But the MCI is weakly related to the click behaviors, so the improvement is not noticeable. Â· When we add MSPL into the MERIT model, some metrics will decrease. But this decrease is modest and tolerable. The In order to obtain the ranking results of hotel quality, we compare the listed hotel MCI level for different methods. And we summarize our assessments of hotel quality ranking and draw the following findings: Â· Whencompared to the DNN model, multi-task learning models do not take hotel quality into account, hence the NDCG shows no discernible improvement. In addition, the relation between consumers and merchants may be negative and insignificant, so the NDCG of multi-task learning models falls dramatically. Specifically, for CGC, which has the best performance in multi-task learning models, the NDCG@5 declines by 0.0022. Â· The monotone structure has the potential to improve hotel ranking results. In comparison to the base model, three monotonic structures (MERIT, MIN-MAX Net, and Pointwise Monotonic Loss) enhance NDCG@5 by 0.0057, 0.0031, and 0.0017. Because of the extensive batch norm component, our proposed MERIT approach has the best performance. Â· The Multi-objective Pairwise Loss is capable of strengthening the training objective on the MCI. Specifically, MERIT+ MPL and MERIT+MSPL improve on NDCG@5 by 0.0240 and 0.0250, respectively. The MSPL can mitigate the conflict problem of multi-objective optimization and hence outperform MPL in the ranking of MCI. Based on the experimental observations presented above, we can summarize that our proposed methods have the following advantages: 1) Monotonic structures can better learn the correlation between ğ‘‹ ğ‘  and the hotel ranking score. 2) MSPL can better seek a balance between the ranking results based on user implicit feedback and merchant quality. MERIT: A Merchant Incentive Ranking Model for Hotel Search & Ranking CIKM '23, October 21-25, 2023, Birmingham, United Kingdom.",
  "5.3 Influence of Hyper-parameters ğœ† 1 and ğœ† 2": "The hyper-parameters ğœ† 1 and ğœ† 2 aim to balance CTRCVR and MCI ranking results. In order to explore the influence of these two hyperparameters, we choose the CTCVR AUC and NDCG@20 as the measuring metrics. The range of ğœ† 1 is in { 0 . 1 , 0 . 5 , 1 . 0 } and the range of ğœ† 2 is in { 0 . 01 , 0 . 05 , 0 . 1 , 0 . 2 } . The larger ğœ† 1 will enlarge the influence of L ğ¶ğ‘‡ğ‘…ğ¶ğ‘‰ğ‘… ğ‘ğ‘ğ‘–ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’ while the larger ğœ† 2 will enlarge the influence | of L ğ‘€ğ¶ğ¼ ğ¶ğ‘‡ğ‘…ğ¶ğ‘‰ğ‘… ğ‘ğ‘ğ‘–ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’ . With the growth of ğœ† 2, the result of CTCVR AUC gradually increases while NDCG@20 declines as shown in Figure 4. The influence of ğœ† 1 is the opposite. From the online experiment, we consider that a 0.005 decline of CTCVR AUC is acceptable, so we set the lower bound of CTCVR AUC as 0.892 (The best CTCVR AUC is 0.897 as shown in Table 2.). In order to choose the best hyper-parameters, we choose the points in the light green area (above the dashed line) and then we choose the point with the largest NDCG@20. Accordingly, we set ğœ† 1 = 1 . 0 and ğœ† 2 = 0 . 1 in Figure 4(c) as the appropriate hyper-parameters.\"",
  "5.4 Online A/B Test": "Table 5: Online performance of the proposed MERIT model. We conduct an online A/B test in the hotel S&R system on Fliggy within two weeks of July 2022. Table 5 illustrates the online performance that our method is compared with the baseline method (DNN). It is apparent that our method is superior to the baseline method for both consumers and merchants. The CVR has increased by 1.50%, and the Sales Volume has increased by 0.97% (Given the substantial sales volume of the OTP, with hotel price in the hundreds of yuan, a 0.97% increase in sales volume indicates a nearly one million yuan increase in sales volume.). The mean MCI score of displayed hotels has risen by 3.02%, indicating that displayed merchant quality has been improved. Our proposed method has been deployed online and brought remarkable OTP profit growth. We selected several major cities in China to compare the variations in the A/B test across different scenarios. And we evaluated two significant online metrics, Imp.(%) and UCVR , to assess the performance. Imp.(%) measures the lift ratio of the average displayed number for each hotel. UCVR measures the proportion of users with orders among all users. Figure 5(a) illustrates the Imp.(%) results for different MCI-level hotels in the online A/B test. With our proposed method, the results indicate that the MCI levels from 3.0 to 5.0 have an improvement of impression in comparison to the base model. Hotels with an MCI level greater than 3.0 can, for example, achieve significant impression gains in Hangzhou, whereas hotels with an MCI level greater than 3.5 can achieve comparable impression gains in Chengdu. Additionally, Hangzhou's biggest growth is 19.31% at MCI level 5.0, whereas Chengdu's largest growth is 32.66% at MCI level 5.0. Similarly, in Figure 5(b) we evaluate how UCVR has changed for hotels with various MCI levels, and the results show that our proposed method has reallocated resources to hotels with high MCI levels. For example, hotels at the MCI level 5.0 have boosted their UCVR s by 2.88% in Hangzhou, 4.93% in Chengdu, and 0.40% in all cities. Therefore, we conclude that our proposed method has remarkable impression improvement on hotels with high MCI scores, which can address the former two challenges on OTPs: Matthew Effect in the consumer feedback-loop and the unclear relation between hotel quality and performance. Figure 5: The online performance of MERIT model for hotels with different MCI levels among cities. The MCI level 0 denotes that there are no consumer ratings for hotels 0 1 2 3 4 5 6 7 8 9 MCI Level 10 0 10 20 30 (a) Imp.(%) All Cities Hangzhou Chengdu 0 1 2 3 4 5 6 7 8 9 MCI Level 0.5 0.0 0.5 1.0 >1.5 (b) UCVR All Cities Hangzhou Chengdu",
  "6 CONCLUSION": "In this paper, we identify three main challenges in the scenario of the hotel S&R system on Online Travel Platforms (OTPs): Matthew Effect in the consumer feedback-loop, unclear relation between hotel quality and performance, and conflicts between short-term and long-term revenue. A new Merchant Incentive Ranking Model representing the merchant-consumer relation for the hotel S&R system, namely MERIT, is proposed to address these three challenges. We define factors of hotel quality, which represent the hotel quality of the entire consumer behavior cycle, and propose an MCI metric as an evaluation of hotel quality. Also, we introduce a monotonic structure into MERIT to provide clear relation between factors of hotel quality and ranking performance. Finally, we propose a novel Multi-objective Stratified Pairwise Loss to mitigate conflicts between platform revenue and consumer experience. Extensive experiment findings on the offline hotel S&R dataset demonstrate the superiority of MERIT over existing state-of-the-art benchmarks in terms of NDCG, as well as the effectiveness of imposing monotonicity of merchant quality. We also conduct an online A/B test and obtain a 3.02% improvement in the MCI score. MERIT has been deployed into Fliggy to serve tens of millions of consumers and hundreds of thousands of hotel merchants.",
  "REFERENCES": "[1] Norman P Archer and Shouhong Wang. 1993. Application of the back propagation neural network algorithm with monotonicity constraints for two-group classification problems. Decision Sciences 24, 1 (1993), 60-75. [2] Oren Barkan and Noam Koenigstein. 2016. Item2vec: neural item embedding for collaborative filtering. In 2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP) . IEEE, 1-6. [3] Rajat Bhattacharjee and Ashish Goel. 2006. Incentive based ranking mechanisms. In First Workshop on the Economics of Networked Systems (Netecon'06) . 62-68. [4] Rajat Bhattacharjee, Ashish Goel, and Konstantinos Kollias. 2009. An incentivebased architecture for social recommendations. In Proceedings of the third ACM conference on Recommender systems . 229-232. CIKM '23, October 21-25, 2023, Birmingham, United Kingdom. Quan, et al. [5] K. Canini, A. Cotter, M. R. Gupta, M. Milani Fard, and J. Pfeifer. 2016. Fast and Flexible Monotonic Functions with Ensembles of Lattices. In Proceedings of the 30th International Conference on Neural Information Processing Systems (NIPS'16) . 2927-2935. [6] Rich Caruana. 1997. Multitask learning. Machine learning 28, 1 (1997), 41-75. [7] Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan He. 2020. Bias and debias in recommender system: A survey and future directions. arXiv preprint arXiv:2010.03240 (2020). [8] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al. 2016. Wide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems . 7-10. [9] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555 (2014). [10] Guy W Cole and Sinead A Williamson. 2019. Avoiding resentment via monotonic fairness. arXiv preprint arXiv:1909.01251 (2019). [11] Hennie Daniels and Marina Velikova. 2010. Monotone and partially monotone neural networks. IEEE Transactions on Neural Networks 21, 6 (2010), 906-917. [12] Ad J Feelders. 2000. Prior knowledge in economic applications of data mining. In European Conference on Principles of Data Mining and Knowledge Discovery . Springer, 395-400. [13] Matt W Gardner and SR Dorling. 1998. Artificial neural networks (the multilayer perceptron)-a review of applications in the atmospheric sciences. Atmospheric environment 32, 14-15 (1998), 2627-2636. [14] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247 (2017). [15] Akhil Gupta, Naman Shukla, Lavanya Marla, ArinbjÃ¶rn Kolbeinsson, and Kartik Yellepeddi. 2019. How to incorporate monotonicity in deep networks while preserving flexibility? arXiv preprint arXiv:1909.10662 (2019). [16] Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin Yang, Huizhong Duan, Qing Zhang, Nick Barrow-Williams, Bradley C Turnbull, Brendan M Collins, et al. 2019. Applying deep learning to airbnb search. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 1927-1935. [17] Malay Haldar, Prashant Ramanathan, Tyler Sax, Mustafa Abdool, Lanbo Zhang, Aamir Mansawala, Shulin Yang, Bradley Turnbull, and Junshuo Liao. 2020. Improving deep learning for airbnb search. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 2822-2830. [18] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web . 173-182. [19] Zai Huang, Mingyuan Tao, and Bufeng Zhang. 2021. Deep Inclusion Relationaware Network for User Response Prediction at Fliggy. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining . 3059-3067. [20] Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. 1991. Adaptive mixtures of local experts. Neural computation 3, 1 (1991), 79-87. [21] Xingchao Liu, Xing Han, Na Zhang, and Qiang Liu. 2020. Certified monotonic neural networks. Advances in Neural Information Processing Systems 33 (2020), 15427-15438. [22] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed H Chi. 2018. Modeling task relationships in multi-task learning with multi-gate mixture-ofexperts. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 1930-1939. [23] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun Gai. 2018. Entire space multi-task model: An effective approach for estimating post-click conversion rate. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval . 1137-1140. [24] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality.",
  "keywords_parsed": [
    "Hotel Search & Ranking System",
    "Monotonic Neural Networks",
    "Hotel Quality"
  ],
  "references_parsed": [
    {
      "ref_id": "b1",
      "title": "Application of the back propagation neural network algorithm with monotonicity constraints for two-group classification problems"
    },
    {
      "ref_id": "b2",
      "title": "Item2vec: neural item embedding for collaborative filtering"
    },
    {
      "ref_id": "b3",
      "title": "Incentive based ranking mechanisms"
    },
    {
      "ref_id": "b4",
      "title": "An incentivebased architecture for social recommendations"
    },
    {
      "ref_id": "b5",
      "title": "Fast and Flexible Monotonic Functions with Ensembles of Lattices"
    },
    {
      "ref_id": "b6",
      "title": "Multitask learning"
    },
    {
      "ref_id": "b7",
      "title": "Bias and debias in recommender system: A survey and future directions"
    },
    {
      "ref_id": "b8",
      "title": "Wide & deep learning for recommender systems"
    },
    {
      "ref_id": "b9",
      "title": "Empirical evaluation of gated recurrent neural networks on sequence modeling"
    },
    {
      "ref_id": "b10",
      "title": "Avoiding resentment via monotonic fairness"
    },
    {
      "ref_id": "b11",
      "title": "Monotone and partially monotone neural networks"
    },
    {
      "ref_id": "b12",
      "title": "Prior knowledge in economic applications of data mining"
    },
    {
      "ref_id": "b13",
      "title": "Artificial neural networks (the multilayer perceptron)-a review of applications in the atmospheric sciences"
    },
    {
      "ref_id": "b14",
      "title": "DeepFM: a factorization-machine based neural network for CTR prediction"
    },
    {
      "ref_id": "b15",
      "title": "How to incorporate monotonicity in deep networks while preserving flexibility?"
    },
    {
      "ref_id": "b16",
      "title": "Applying deep learning to airbnb search"
    },
    {
      "ref_id": "b17",
      "title": "Improving deep learning for airbnb search"
    },
    {
      "ref_id": "b18",
      "title": "Neural collaborative filtering"
    },
    {
      "ref_id": "b19",
      "title": "Deep Inclusion Relationaware Network for User Response Prediction at Fliggy"
    },
    {
      "ref_id": "b20",
      "title": "Adaptive mixtures of local experts"
    },
    {
      "ref_id": "b21",
      "title": "Certified monotonic neural networks"
    },
    {
      "ref_id": "b22",
      "title": "Modeling task relationships in multi-task learning with multi-gate mixture-of-experts"
    },
    {
      "ref_id": "b23",
      "title": "Entire space multi-task model: An effective approach for estimating post-click conversion rate"
    },
    {
      "ref_id": "b24",
      "title": "Distributed representations of words and phrases and their compositionality"
    }
  ]
}