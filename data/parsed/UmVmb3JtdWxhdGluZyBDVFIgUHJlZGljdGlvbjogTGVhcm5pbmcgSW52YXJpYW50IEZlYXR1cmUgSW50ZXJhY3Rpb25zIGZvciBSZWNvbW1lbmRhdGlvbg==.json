{
  "Reformulating CTR Prediction: Learning Invariant Feature Interactions for Recommendation": "Yang Zhang ∗ University of Science and Technology of China Hefei, China zy2015@mail.ustc.edu.com",
  "Tianhao Shi ∗": "University of Science and Technology of China Hefei, China sth@mail.ustc.edu.com Fuli Feng † University of Science and Technology of China Hefei, China fulifeng93@gmail.com Wenjie Wang National University of Singapore Singapore wenjiewang96@gmail.com Dingxian Wang Etsy Inc. United States dingxianwang@etsy.com",
  "Xiangnan He †": "University of Science and Technology of China Hefei, China xiangnanhe@gmail.com",
  "Yongdong Zhang": "University of Science and Technology of China Hefei, China zhyd73@ustc.edu.cn",
  "ABSTRACT": "Click-Through Rate (CTR) prediction plays a core role in recommender systems, serving as the final-stage filter to rank items for a user. The key to addressing the CTR task is learning feature interactions that are useful for prediction, which is typically achieved by fitting historical click data with the Empirical Risk Minimization (ERM) paradigm. Representative methods include Factorization Machines and Deep Interest Network, which have achieved wide success in industrial applications. However, such a manner inevitably learns unstable feature interactions , i.e., the ones that exhibit strong correlations in historical data but generalize poorly for future serving. In this work, we reformulate the CTR task - instead of pursuing ERM on historical data, we split the historical data chronologically into several periods ( a.k.a. environments), aiming to learn feature interactions that are stable across periods. Such feature interactions are supposed to generalize better to predict future behavior data. Nevertheless, a technical challenge is that existing invariant learning solutions like Invariant Risk Minimization are not applicable, since the click data entangles both environment-invariant and environment-specific correlations. To address this dilemma, ∗ Equal contribution. † Corresponding authors. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '23, July 23-27, 2023, Taipei, Taiwan © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-9408-6/23/07...$15.00 https://doi.org/10.1145/3539618.3591755 we propose Disentangled Invariant Learning (DIL) which disentangles feature embeddings to capture the two types of correlations separately. To improve the modeling efficiency, we further design LightDIL which performs the disentanglement at the higher level of the feature field. Extensive experiments demonstrate the effectiveness of DIL in learning stable feature interactions for CTR. We release the code at https://github.com/zyang1580/DIL.",
  "CCS CONCEPTS": "· Information systems → Recommender systems .",
  "KEYWORDS": "Factorization Machine; Recommender System; Invariant Learning",
  "ACMReference Format:": "Yang Zhang, Tianhao Shi, Fuli Feng, Wenjie Wang, Dingxian Wang, Xiangnan He, and Yongdong Zhang. 2023. Reformulating CTR Prediction: Learning Invariant Feature Interactions for Recommendation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '23), July 23-27, 2023, Taipei, Taiwan. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3539618.3591755",
  "1 INTRODUCTION": "Click-Through Rate (CTR) prediction is important to support the ranking stage of recommender systems [44]. Its key lies in learning the feature interactions that are useful for predicting user clicks [11, 44, 48]. Existing methods [4, 11, 14, 27, 32, 44, 47] typically achieve the target by fitting historical data collectively with the Empirical Risk Minimization (ERM) paradigm - minimizing the average empirical loss over historical click data [44]. The ERM paradigm has become the standard paradigm for training CTR models, leading to the classical solutions FM [32], NFM [14], and DIN [47] that have been intensively used in industrial applications [44]. SIGIR '23, July 23-27, 2023, Taipei, Taiwan Yang Zhang, et al. (gender, category) (stock, category) (price, color) Feature interactions : 0.8 0.05 0.8 0.7 0.8 0.1 COVID-19 lockdown Counterfeits appear Cancel lockdown Emergency stockpiling Normal shopping Normal shopping Time high less high click click click Figure 1: Examples of stable feature interaction (gender, category) and unstable feature interaction (stock, category) and (price, color). The arrow represents that the feature interaction affects the happening of click, and the weights reflect the influence strength. The dotted line represents the correlations between feature interactions and clicks, varying along the timeline. We argue that the CTR model built with the ERM paradigm would inevitably learn unstable feature interactions , leading to poor generalization for future serving. Some feature interactions could exhibit strong correlations in historical data but are useless or even harmful for future serving. Figure 1 illustrates two examples of unstable feature interactions: 1) the feature interaction (stock, category) highly affects user clicks during the COVID-19 lockdown, however, its effect diminishes after the lockdown; and 2) the feature interaction (price, color) exhibits high correlation with clicks due to some confounding effect 1 , which is however unstable and becomes weak after the occurrence of counterfeits. These unstable feature interactions will mislead the CTR model learned by ERM, e.g., 1) over-recommending emergent supplies after the lockdown; and 2) over-recommending the counterfeits with high prices and attractive colors. It is thus essential to distinguish unstable feature interactions in CTR prediction. In this work, we propose to reformulate the CTR task instead of performing ERM on historical data. As unstable feature interactions could cause poor generalization, we set the target as learning the feature interactions that are stably useful for predicting user clicks. Towards the goal, we split the historical data chronologically into several periods, forming a set of environments, and learn feature interactions that are stable across these environments. These environments could be heterogeneous due to the temporal influence, e.g., some environments have more historical data during the COVID-19 lockdown. The feature interactions that are stably useful over these heterogeneous environments are more likely to remain useful in the future [2, 25], e.g., the interaction (gender, category) in Figure 1. As such, the CTR models accounting for the stability of feature interactions will generalize better for future prediction. Amongexisting techniques, Invariant Learning [2] is well-known for capturing environment-invariant correlations across heterogeneous environments, which seems to be a promising choice for learning stable feature interactions in CTR prediction. However, it is not directly applicable, because it relies on the sufficiency prediction condition - the prediction target can be sufficiently predicted with only environment-invariant correlations - which is not satisfied in CTR prediction. Although unstable, some feature interactions truly affect the clicks in a specific environment, e.g., during the COVID-19 lockdown, users click items by considering 1 E.g., the high quality of the product could synchronously lead to high item price, attractive item color, and strong click probability. the (stock, category) factor. In other words, the clicks entangle both environment-invariant and environment-specific correlations, meaning that the clicks cannot be sufficiently predicted with only environment-invariant correlations. To overcome this challenge, we propose Disentangled Invariant Learning (DIL), which disentangles the environment-invariant and environment-specific correlations from clicks, and identifies stable feature interactions by avoiding the influence of environmentspecific correlations. Specifically, DIL first equips a CTR model with environment-invariant feature embedding and a set of environmentspecific feature embeddings. Then DIL optimizes the model with a new disentangled invariant learning objective, which contains: 1) environment-specific objectives to make environment-specific feature embeddings capture environment-specific correlations, and 2) a modified invariant learning objective with the sufficiency prediction condition satisfied to let environment-invariant feature embeddings capture environment-invariant correlations. Considering that embedding disentanglement significantly increases the model size and the cost of training, we further design LightDIL to perform the disentanglement at the higher level of the feature field to improve the modeling efficiency. The main contributions are summarized as follows: · NewProblem: It is the first time that the CTR task is reformulated by learning stable feature interactions across periods, so as to achieve better generalization for future serving. · New Technique: We propose to integrate the idea of representation disentanglement into invariant learning, making invariant learning feasible in difficult situations where the sufficiency prediction condition is not satisfied. · Experiments: We conduct extensive experiments on both semisynthetic and real-world datasets, verifying the effectiveness of our proposal.",
  "2 PRELIMINARIES": "This work studies the CTR task on chronologically collected data. Assuming the data is collected from 𝑇 periods, which could be days, weeks, or self-defined time spans. Let D = {D 1 , . . . , D 𝑇 } denote the data, where each D 𝑡 represents the data collected at the 𝑡 -th period. We denote each sample in D as ( 𝒙 , 𝑦 ) , where 𝑦 ∈ { 0 , 1 } represents the click and 𝒙 = [ 𝑥 1 , · · · , 𝑥 𝑁 ] 𝑇 ∈ { 0 , 1 } 𝑁 represents the features describing the user-item pair. 𝒙 is a highly sparse multihot vector with a dimensionality of 𝑁 . We assume the feature vector contains 𝑀 fields ( e.g., age and category) where each field is encoded by one-hot encoding or multi-hot encoding. The target is to learn a CTR model from D to serve for future periods. In this work, we propose to perform stable feature interaction learning to enhance the generalization of the classic FM model. Next, we introduce the backbone FM model and the basics of invariant learning.",
  "2.1 Factorization Machines": "FM and its variants have achieved wide success in CTR, owing to the effectiveness of the inner product operation in explicitly modeling feature interactions [11, 14, 32]. Without losing generality, we take FM as the base model to study stable feature interaction modeling. Given an input sample with features 𝒙 = [ 𝑥 1 , . . . , 𝑥 𝑁 ] 𝑇 , FM generates the prediction by modeling all second-order feature Reformulating CTR Prediction: Learning Invariant Feature Interactions for Recommendation SIGIR '23, July 23-27, 2023, Taipei, Taiwan interactions via inner product on pairwise feature embeddings:  where ˆ 𝑦 denotes the prediction of CTR; 𝒗 𝑖 / 𝒗 𝑗 denotes the embedding for 𝑖 -th/ 𝑗 -th feature, and ⟨ 𝒗 𝑖 , 𝒗 𝑗 ⟩ refers to the inner product between the two feature embeddings to reconstruct the interaction effect. The prediction accounts for the interaction between features 𝑥 𝑖 and 𝑥 𝑗 if both features occur, i.e., 𝑥 𝑖 𝑥 𝑗 = 1. · Field-level. Since each feature belongs to one field, we can also model the interaction at the field level. Formally,  where 𝒖 𝑖 and 𝒖 𝑗 denote the representation of the 𝑖 -th and 𝑗 -th fields. When all fields are one-hot encoding, field-level interaction modeling is equivalent to Equation (1). Let S 𝑖 denote the feature indices belonging to the 𝑖 -th field, we can generate the field representation 𝒖 𝑖 based on the feature embeddings { 𝒗 𝑘 } 𝑘 ∈S 𝑖 as 𝒖 𝑖 = 1 ˝ 𝑘 ∈S 𝑖 𝑥 𝑘 ˝ 𝑘 ∈S 𝑖 𝑥 𝑘 · 𝒗 𝑘 .",
  "2.2 Invariant Learning": "Invariant learning [36] is widely used to learn predictors for Outof-Distribution (OOD) generalization, given the data collected from different environments. Existing invariant learning methods typically have the following assumption [2, 25, 42] (here, we reuse 𝑡 to denote an environment since a period represents an environment): Assumption 1. There exist random variables 𝒓 that satisfy: · Invariance condition: for any two environments 𝑡 and 𝑡 ′ , 𝑃 ( 𝑦 | 𝒓 , 𝑡 ) = 𝑃 ( 𝑦 | 𝒓 , 𝑡 ′ ) holds, where 𝑦 denotes the prediction target, e.g., the click. · Sufficiency condition: 𝑦 = 𝑓 ( 𝒓 ) + 𝜖 , where 𝑓 represents a function and 𝜖 is an independent noise. This assumption means that capturing the correlations between the predictor variables 𝒓 and the prediction target 𝑦 can result in a desired model with good generalization to unknown distributions [18], because these correlations are invariant and sufficient for predicting the target across environments. As such, they are also denoted as environment-invariant correlations . Under this assumption, to make a model capture such correlations, one representative method is the variance-based regularizer [25, 42], which can be formulated as follows:  where 𝜙 denotes the model parameters, 𝑅 𝑡 represents the loss for the environment 𝑡 , 𝑇 represents the number of environments, 𝜆 is a hyper-parameter to control the strength of 𝑉 𝑅 , and 𝑉 𝑅 denotes the variance of the loss [42] or the variance of the gradient of the loss over environments [25]. In this work, we adopt the variance of the loss with the consideration of computation efficiency, which is computed as follows:  The key consideration of the method is that environment-invariant correlations should enable better performance across environments. 𝑇 𝑌 𝐸 𝐻 ଶ 𝐻 ଷ 𝐻 ଵ 𝑌: the click. 𝐸: the time-varying environmental variables. 𝐻 ଵ : the feature interactions that stably affect the click over time. 𝐻 ଶ : the feature interactions that affect the click differently over time. 𝐻 ଷ : the feature interactions that do not directly affect click but are affected by 𝐸 . Figure 2: Graphical model of the click generation process. The box represents 𝑇 replicates of the part of the model in the box, indicating that the part varies over 𝑇 periods.",
  "3 METHODOLOGY": "Given the possible existence of unstable feature interaction, we first rethink the CTR prediction task to shed more light on the new problem setting. We then elaborate on the proposed disentangled invariant learning solution.",
  "3.1 Rethinking the CTR Task": "Figure 2 illustrates the generative process of click data with a graphical model. The box in the figure represents 𝑇 replicates of the content in the box, indicating that the content could vary over 𝑇 periods, e.g., 𝐻 2 → 𝑌 could vary over 𝑇 periods. We divide the feature interactions into three major types 𝐻 1 , 𝐻 2 , 𝐻 3 : · 𝐻 1 denotes the feature interactions that stably affect the click over time, as shown by unvarying 𝐻 1 → 𝑌 outside the box. · 𝐻 2 denotes the feature interactions such as (stock, category) that affect the click differently over time due to the influence of timevarying environmental variable 𝐸 ( e.g., the COVID-19 lockdown), as shown by time-varying 𝐸 → 𝐻 2 → 𝑌 in the box. · 𝐻 3 denotes the feature interactions that do not directly affect the click 𝑌 but are affected by 𝐸 (differently over time), as shown by time-varying 𝐸 → 𝐻 3 in the box. Causally speaking, 𝐻 1 has static causal relations to the click; 𝐻 2 has dynamic causal relations to the click; and 𝐻 3 is not causal feature interactions, but shows (spurious) correlations to the click, due to the confounding effect related to 𝐸 (e.g., the confounding effect brought by the backdoor path 𝐻 3 ← 𝐸 → 𝐻 2 → 𝑌 ). As only static causal relations are invariant over time and exert stable effects on click generation, we treat 𝐻 1 as stable feature interactions. Nevertheless, the ERM paradigm exploits all correlations to fit the click data. The correlations between feature interactions and clicks could come from three sources: static causal relations ( 𝐻 1 → 𝑌 ), dynamic causal relations ( 𝐻 2 → 𝑌 ), and confounding effects ( e.g., 𝐻 3 ← 𝐸 → 𝐻 2 → 𝑌 ). As a result, ERM inevitably learns unstable feature interactions, which have dynamic causal relations or spurious correlations to the click. It will make the model generalize poorly for future serving, since the effects of unstable feature interactions would vanish and even reverse [2, 9, 20, 45]. As such, we revise the objective of the CTR task as capturing stable feature interactions. Towards this goal, we split the historical data chronologically into several periods, enabling the learning of feature interactions that are stable across these periods. In the language of invariant learning [2], these periods form a set of environments, which are heterogeneous due to temporal influences, e.g., the influence of the COVID-19 lockdown. Supposing the heterogeneity is large enough, only feature interactions with static causal SIGIR '23, July 23-27, 2023, Taipei, Taiwan Yang Zhang, et al. relations to clicks are stably useful for CTR prediction across these environments. As such, a CTR model built in such a manner could learn stable feature interactions and generalize better to predict future clicks.",
  "3.2 Disentangled Invariant Learning": "In this subsection, we first discuss the potential and challenge of applying invariant learning to the CTR task, and then present the Disentangled Invariant Learning (DIL) method from three aspects: optimization objective, learning algorithm, and model architecture. 3.2.1 Invariant Learning Solution. To achieve our goal, an ideal way is to conduct causal discovery, but it is hard in real-world scenarios due to the non-stationary, high-dimension, and partially unobservable challenges [10]. We propose to leverage invariant learning [2], which could capture the environment-invariant correlations given multiple heterogeneous environments, to learn stable feature interactions. There are two considerations: 1) periods could directly represent different environments, and 2) among the three types of correlations discussed in Section 3.1, the correlations brought by static causal relations are environment-invariant, while the correlations brought by dynamic causal relations and spurious correlations vary across environments 2 , i.e., are environment-specific [20, 25]. It is thus possible to learn stable feature interactions by capturing environment-invariant correlations with invariant learning. However, existing invariant learning methods are not applicable to the CTR task, because the sufficiency condition of their basic assumption (Assumption 1) is not satisfied. · Clicks are affected by both feature interactions with static causal relations to clicks and feature interactions with dynamic causal relations to clicks, i.e., clicks entangle environment-invariant and environment-specific correlations. That means clicks cannot be sufficiently predicted with only environment-invariant correlations, violating the sufficiency condition. To overcome this challenge, the key lies in the disentanglement of environment-invariant and environment-specific correlations. With the disentanglement, the influence of environment-specific correlations could be eliminated from clicks, making the sufficiency condition satisfied. To this end, we propose a new disentangled invariant learning method for CTR models, which contains a new optimization objective, learning strategy, and model architecture. 3.2.2 Disentangled Invariant Learning Objective. Wefirst divide the model parameters for feature interaction modeling into environmentinvariant part 𝜙 𝑠 and environment-specific parts { 𝜙 𝑡 } 𝑡 (short for { 𝜙 𝑡 } 𝑇 𝑡 = 1 , and 𝜙 𝑡 is used for 𝑡 -th environment), to capture environmentinvariant and environment-specific correlations, respectively. For example, we can equip the backbone model FM with environmentinvariant feature embedding 𝒗 𝑠 𝑖 and environment-specific feature embedding 𝒗 𝑡 𝑖 for any 𝑖 -th feature, and then 𝜙 𝑠 = { 𝒗 𝑠 𝑖 } 𝑖 and 𝜙 𝑡 = { 𝒗 𝑡 𝑖 } 𝑖 ( cf. Section 3.2.4). With both 𝜙 𝑠 and 𝜙 𝑡 , we could sufficiently predict the click for a sample ( 𝒙 , 𝑦 ) ∈ D 𝑡 as follows:  2 Considering the correlations brought by 𝐻 2 → 𝑌 and confounding effects ( e.g., 𝐻 3 ← 𝐸 → 𝐻 2 → 𝑌 ), as 𝐸 and the relations ( e.g., 𝐻 2 → 𝑌 ) drift over time, these correlations vary over environments. where 𝑓 ( 𝒙 ; 𝜙 𝑠 , 𝜙 𝑡 ) is the modified CTR model. We present the detailed model architecture in Section 3.2.4 later. To learn 𝜙 𝑠 and { 𝜙 𝑡 } 𝑡 , on one hand, we need an invariant learning objective, to make 𝜙 𝑠 capture the environment-invariant correlations. On the other hand, we need environment-specific objectives to force { 𝜙 𝑡 } 𝑡 to capture the environment-specific correlations. To this end, we propose the following overall optimization objective:  where (6a) and (6b) correspond to the invariant learning objective and environment-specific objectives, respectively. We explain these learning objectives in detail below. - Invariant learning objective (Equation (6a) ) . After 𝜙 𝑡 has captured the environment-specific correlations, fixing 𝜙 𝑡 is equal to removing its influences on clicks. Then capturing the environmentinvariant correlations can sufficiently predict the clicks without the influence of environment-specific correlations, i.e., the sufficiency condition can be satisfied. Thus we fix the environment-specific 𝜙 𝑡 to modify original invariant learning objective in Equation (3) for learning 𝜙 𝑠 as Equation (6a), in which 𝑅 (D 𝑡 ; 𝜙 𝑠 , 𝜙 𝑡 ) represents the loss on the D 𝑡 collected from 𝑡 -th environment and is computed with the logloss [24] as follows:  where 𝜎 (·) denotes the sigmoid function. Besides, in Equation (6a), 𝑉 𝑅 refers to the variance of 𝑅 (D 𝑡 ; 𝜙 𝑠 , 𝜙 𝑡 ) over environments, computed like Equation (4); and 𝑤 𝑡 represents the weight for 𝑡 -th environment, which is computed with the softmax function as follows:  where the temperature parameter of the softmax function is used but omitted here. As such, we assign a higher weight to the environment with higher loss, considering that paying more attention to difficult environments is helpful for improving the cross-environment performances [22, 33] to learn stable feature interaction. - Environment-specific objectives (Equation (6b) ) . Combining 𝜙 𝑠 and 𝜙 𝑡 should fit D 𝑡 well, since we need the clicks can be sufficiently predicted with 𝜙 𝑠 and 𝜙 𝑡 . Thus, for each environment 𝑡 , we propose the optimization objective in Equation (6b), i.e.,  where 𝜂 is a hyper-parameter to control the strength of 𝐿 𝑡 , and 𝐿 𝑡 is a regularizer to prevent 𝜙 𝑡 from capturing the environmentinvariant correlations and is only used for learning 𝜙 𝑡 . Formally,  where 𝑅 (D 𝑡 ′ ; 𝜙 𝑠 , 𝜙 𝑡 ) represents the loss when predicting clicks in D 𝑡 ′ forcibly using 𝜙 𝑡 . The key consideration is to make 𝑡 -th environment-specific 𝜙 𝑡 not contribute to fitting data collected from other environments { 𝑡 ′ | 1 ≤ 𝑡 ′ ≤ 𝑇,𝑡 ′ ∈ N , 𝑡 ′ ≠ 𝑡 } . Reformulating CTR Prediction: Learning Invariant Feature Interactions for Recommendation SIGIR '23, July 23-27, 2023, Taipei, Taiwan",
  "Algorithm 1: DIL": "Input: Historical data chronologically split into 𝑇 environments, i.e., D = {D 1 , . . . , D 𝑡 , . . . , D 𝑇 } . 1 Initialize 𝜙 𝑠 and { 𝜙 𝑡 } 𝑡 ; 2 while Stop condition is not reached do 3 Randomly sample a batch of data from D ; 4 Normally update model parameters except 𝜙 𝑠 and { 𝜙 𝑡 } 𝑡 , and then keep them fixed; 5 Randomly sample an environment 𝑡 ∈ { 1 , . . . , 𝑇 } ; 6 // Update 𝜙 𝑠 , fixing all 𝜙 𝑡 ; 7 Compute e 𝜙 𝑠 with Equation (9); 8 Update 𝜙 𝑠 according to Equation (10); 9 // Update 𝜙 𝑡 , fixing 𝜙 𝑠 ; 10 Update 𝜙 𝑡 according to Equation (11); 11 end The two optimization objectives are not isolated. The first objective is based on the second, since it requires 𝜙 𝑡 has captured environment-specific correlations. Thus we merge them to form the overall optimization objective in Equation (6). We term the overall optimization objective - disentangled invariant learning objective. 3.2.3 Learning Strategy. We now consider how to optimize the disentangled invariant learning objective (Equation (6)). As we need to remove the influences of environment-specific correlations on clicks by fixing { 𝜙 𝑡 } 𝑡 for the invariant learning objective, we propose a learning strategy, which updates the environment-invariant 𝜙 𝑠 and environment-specific { 𝜙 𝑡 } 𝑡 alternately as follows: - Update 𝜙 𝑠 . Fixing { 𝜙 𝑡 } 𝑡 , we need to learn 𝜙 𝑠 such that it is optimal for both the invariant learning objective and environment-specific objective as shown in Equation (6). However, this is a hard bi-level optimization problem. Instead of directly solving it, we solve it in a meta-learning manner similar to [3]. Specially, we take the MAML [7] to update 𝜙 𝑠 , which has two main steps: · Step 1. Meta training, which focuses on the environment-specific objective. We sample an environment 𝑡 and compute the loss of environment-specific objective for it, then conduct an update to get a temporary e 𝜙 𝑠 as follows:  · Step 2. Meta testing, which focuses on the invariant learning objective (Equation (6a)). We take the e 𝜙 𝑠 to compute the loss of the invariant learning objective, and further update the 𝜙 𝑠 according to the loss. Formally,  Note that 𝑉 𝑅 is also computed with e 𝜙 𝑠 . In this way, it is easier to find a 𝜙 𝑠 that is generally good for the two optimization objectives, because of taking into account how an update for an environmentspecific objective affects the invariant learning objective. Figure 3: Model Architectures. (a) The embedding disentanglement model architecture for DIL. (b) The field-level disentanglement model architecture for LightDIL. \"FI\" denotes feature interactions. Red modules are environmentinvariant, and the blue modules are environment-specific. a23 Œi3 U3 1 | 0 | 0 | 1 0 Tield1 field 2 field 3 (a) DIL (b) LightDIL - Update 𝜙 𝑡 . After updating 𝜙 𝑠 , we directly optimize the environmentspecific objective with 𝜙 𝑠 fixed, to update 𝜙 𝑡 (of the sampled environment) as follows:  These two updates are iterated alternately until convergence, and learning rates are used but omitted here. Algorithm 1 summarizes the detailed learning algorithm of DIL. In each iteration, we first randomly sample a batch of data and update all parameters except 𝜙 𝑠 and 𝜙 𝑡 with normal training loss ( e.g., logloss) on the data (lines 3-4). Then we randomly sample an environment 𝑡 (line 5), and update 𝜙 𝑠 (lines 7-8). Last, we update 𝜙 𝑡 (lines 10). Note that, in each iteration, we only utilize the batch of data. 3.2.4 Model Architecture. We now consider designing the model architecture of 𝑓 ( 𝒙 ; 𝜙 𝑠 , 𝜙 𝑡 ) , taking FM as the base CTR model. - Embedding disentanglement . In light that the feature embedding is the core of feature interaction modeling (especially for FM-based models), we first directly conduct feature embedding disentanglement. Specifically, for any 𝑖 -th feature, we let it have an environment-invariant embedding 𝒗 𝑠 𝑖 and a set of environmentspecific embeddings { 𝒗 𝑡 𝑖 } 𝑡 , as shown in Figure 3(a). Then for a sample ( 𝒙 , 𝑦 ) ∈ D 𝑡 belonging to 𝑡 -th environment, we modify FM (Equation (1)) to generate the prediction as follows:  where 𝜙 𝑠 = { 𝒗 𝑠 𝑖 } 𝑖 and 𝜙 𝑡 = { 𝒗 𝑡 𝑖 } 𝑖 . This is the default disentanglement for the proposed Disentangled Invariant Learning (DIL) 3 . - Field-level disentanglement . The embedding disentanglement would result in 𝑇 times more model parameters since each environment corresponds to a set of environment-specific embeddings, which dominates the model parameters in FM. What is worse, it is hard to train a model with massive parameters well. This drives us to design a light version of DIL. Note that existing methods [24, 28] assign weights for feature interactions to model their importance, 3 There is another consideration for designing embedding disentanglement - it is widely applicable since CTR models usually project features into embeddings. SIGIR '23, July 23-27, 2023, Taipei, Taiwan Yang Zhang, et al. i.e., the correlation strength to the click. We could similarly assign environment-invariant and environment-specific weights for feature interactions, to capture the environment-invariant and environment-specific correlations, respectively. However, partial feature interactions could appear only in the future but not appear in history [32], resulting in their weights being unlearnable. To overcome the issue, we assign weights at the field level, as shown in Figure 3(b). Then we modify the FM in Equation (2) as follows:  where 𝛼 𝑠 𝑖 𝑗 ∈ R ( 𝛼 𝑡 𝑖 𝑗 ∈ R ) denotes the environment-invariant weight ( 𝑡 -th environment-specific weight) for the feature interaction between field 𝑖 and 𝑗 , 𝜙 𝑠 = { 𝛼 𝑠 𝑖 𝑗 } 𝑖 𝑗 , and 𝜙 𝑡 = { 𝛼 𝑡 𝑖 𝑗 } 𝑖 𝑗 . Note that feature embeddings do not belong to 𝜙 𝑠 and 𝜙 𝑡 here, and are normally updated (see Algorithm 1). We name the DIL performing the disentanglement at the higher level of the feature field LightDIL. - Inference. During inference, DIL and LightDIL only take 𝜙 𝑠 to generate predictions, to pursue good generalization performance. For example, LightDIL generates the prediction as: ˆ 𝑦 = 𝑓 ( 𝑥 ; 𝜙 𝑠 , ∅) = ˝ 𝑀 𝑖 = 1 ˝ 𝑀 𝑗 > 𝑖 𝛼 𝑠 𝑖 𝑗 ⟨ u 𝑖 , u 𝑗 ⟩ . Another way is combining the 𝜙 𝑠 learned in training and the 𝜙 𝑡 estimated for a future period to generate predictions. However, it is hard to forecast the 𝜙 𝑡 of a future period. We leave it as future work.",
  "4 EXPERIMENTS": "We conduct experiments to answer three research questions: RQ1: How does DIL perform on real-world data? RQ2: How do the design choices of DIL affect its performance? RQ3: Can DIL learn stable feature interactions when there are spurious correlations? And can DIL learn stable feature interactions when there are dynamic causal relations ( i.e., the sufficiency condition of invariant learning is not satisfied)?",
  "4.1 Experimental Settings": "· Baselines. Wecompare the proposed methods with the following recommender methods: 1) the basic FM [32]; 2) FwFMs [28], which models the importance of feature interactions via field weights; 3) AFM [43], which utilizes an attention network to learn the importance of feature interactions; 4) AutoFIS [24] and PROFIT [8], which are advanced neural architecture search (NAS) based methods for selecting more effective feature interactions; 5) CFM [20], which is a method for learning robust feature interactions (defined as causal feature interactions); In addition, we further compare DIL with two Out-of-Distribution (OOD) generalization methods, including one representative invariant learning method - V-REx [18] and a distributionally robust optimization method - Group-DRO [33]. For a fair comparison, we implement V-REx and Group-DRO based on FM. Considering that we aim at learning stably useful feature interactions to generalize well for the future, we select baselines 1) modeling the usefulness of feature interactions (FwFMs, AFM, AutoFIS, PROFIT, and CFM), or 2) pursuing the capability of OOD generalization (V-REx, Group-DRO, and CFM). · Evaluation metrics and hyper-parameters. The widely used metrics for CTR prediction are Area under the ROC Curve (AUC) and logloss ( i.e., binary cross entropy). In this work, to evaluate whether a model can generalize well to multiple future periods (testing environments), we report the average values of AUC and logloss over different testing environments. For a fair comparison, we learn all models based on the binary cross entropy loss and tune them according to the AUC metric computed on the validation environments. Meanwhile, for all models, we set the feature embedding size as 48 and take the Adam [17] as the optimizer with the default batch size of 8 , 192. We leverage the grid search to find the best hyper-parameters for each model. In particular, we search the learning rate in the range of { 1 𝑒 -2 , 1 𝑒 -3 , 1 𝑒 -4 } , and the 𝐿 2 regularization coefficient of the embedding layers in the range of { 1 𝑒 -1 , 1 𝑒 -2 , . . . , 1 𝑒 -7 } for all models. For the special hyperparameters of baselines, we search most of them in the ranges provided by their papers. For the special hyper-parameters 𝜆 and 𝜂 of our method (in Equation (6)), we search both of them in the range of { 1 𝑒 -1 , 1 𝑒 -2 , 1 𝑒 -3 , 1 𝑒 -4 } .",
  "4.2 Experiments on Real-world Data": "4.2.1 Real-world Datasets. We conduct extensive experiments on the two representative datasets for CTR prediction: MoviveLens10M and Douban, the statistics of which are summarized in Table 2. - MovieLens-10M (ML-10M) [13] is released by Grouplens Research, containing ratings collected from 1995 to 2009 with rich features belonging to various fields, such as age, gender, and movie category. We only preserve the data collected from July 2002 to December 2008, considering the data sparsity of other years. We then chronologically split the data into 13 periods by treating six months as a period. We further divide these periods into the training, validation, and testing environments according to the ratio of 5:4:4 with the order kept. - Douban 4 is a popular dataset for CTR prediction, which contains the rating data collected from 2012 to 2019 on Douban Website. It contains user and item features belonging to the field of language, actors, etc. Similarly, we preserve the data ranging from January 2012 to June 2019 and then split it into 15 periods with the first 5 for training, the middle 5 for validation, and the last 5 for testing. In both ML-10M and Douban, the ratings range from 1 to 5. Following [39], we treat the user-item interactions with ratings ≥ 3 as positive samples with the click label 𝑦 = 1 (otherwise, 𝑦 = 0). Meanwhile, to ensure the dataset quality and avoid inadequate learning for extremely sparse features, we set the features appearing less than 10 times as a dummy feature ('other') [8, 24]. 4.2.2 Overall Performance Comparison (RQ1). Table 1 summarizes the overall performance comparison between the baselines, DIL, and LightDIL on Douban and ML-10M datasets. From the table, we have the following observations. · LightDIL achieves the best performance on both ML-10M and Douban. DIL is slightly worse than LightDIL but still outperforms all baselines on most of the metrics. Compared with the FM, FwFMs, AFM, AutotoFIS, and PROFIT, which are learned with ERM, the better results of DIL indicate that learning stable feature interactions could bring better generalization for future serving than pursuing ERM on historical data. The results verify 1) the rationality of our reformulation for the CTR task and 2) the effectiveness of our methods in learning stable feature interactions. Compared to V-REx and Group-DRO, better results of DIL 4 https://www.csuldw.com/2019/09/08/2019-09-08-moviedata-10m/. Reformulating CTR Prediction: Learning Invariant Feature Interactions for Recommendation SIGIR '23, July 23-27, 2023, Taipei, Taiwan Table 1: Performance comparison between the baselines, DIL, and LightDIL. \"Rel. Impr.\" denotes the relative improvement over FM w.r.t. AUC. The value on the left (right) of \" ± \" represents the average (the standard deviation) w.r.t. the corresponding metric. We have conducted a 𝑡 -test, verifying the improvements of our best method to the best baseline are statistically significant on AUC (p-value < 0 . 05). Table 2: Statistics of the evaluation datasets. verify that DIL can overcome the challenge - the clicks cannot be sufficiently predicted with environment-invariant correlations - to capture environment-invariant correlations, learning stable feature interactions in CTR prediction. · FwFMs, AFM, AutoFIS, and PROFIT, which learn more effective and discard less useful feature interactions, outperform FM on Douban, but fail to surpass FM and even cause worse performance on ML-10M 5 . These models learn feature interactions with strong correlations to clicks in historical data. They thus are possibly dominated by spurious correlations while ignoring the causal relations, leading to poor generalization performance. ML-10M has fewer fields than Douban as shown in Table 2, and thus the detrimental effect of mistakenly discarding causally useful feature interactions is more severe on ML-10M. · V-REx and Group-DRO outperform FM on Douban, but not on ML-10M, verifying that directly applying OOD generation methods for recommendation is not effective. For the invariant learning method V-REx, its basic assumption (Assumption 1) cannot be satisfied in the CTR task. Group-DRO just focuses on the worst environment, sacrificing the overall performance [29]. · CFM, which aims to learn personalized causal feature interactions, shows inferior performance. We attribute its poor performance to inaccurate causal effects estimation and capturing dynamic causal relations. On one hand, for de-confounding, CFM needs to learn balancing weights for all training samples, which is non-trivial due to the large size of our datasets (at least 50 times larger than the dataset used in the CFM paper). And it is hard to estimate the personalized causal effects well due to the sparsity of user data. On the other hand, CFM captures dynamic causal relations, which could lead to poor generalization performances. 4.2.3 In-depth Analyses (RQ2). In this part, we first compare FM, DIL, and LightDIL on two datasets w.r.t. model size and training cost. We then conduct ablation studies on LightDIL to validate the effectiveness of different components of our method. Last, we 5 AFM and PROFIT beat FM on MovieLens in their papers, which are different from our results. This is because their training and testing data are identically distributed. Figure 4: Comparison between FM, DIL, and LightDIL in terms of model size (left) and training time (right). study how the granularity of environment splitting affects the performance of our proposal based on LightDIL. · Modeling efficiency. We conduct a comparison between FM, DIL, and LightDIL regarding the model size and training time. As shown in Figure 4, LightDIL has almost the same model size as FM, which is far smaller than that of DIL. Meanwhile, LightDIL could greatly reduce the time cost of training, compared to DIL. The results verify the validity of the field-level disentanglement in improving modeling efficiency 6 . Moreover, LightDIL improves the CTR performance over DIL, as illustrated in Table 1. It reflects that the field-level disentanglement is sufficient to distinguish stable and unstable feature interactions with much fewer parameters. Regarding the performance difference between LightDIL and DIL, we attribute it to the discrepancy between them w.r.t. the disentanglement. For example, embedding disentanglement brings more model parameters for DIL while the corresponding feature interactions are more sparse (compared to the interaction between feature fields), making DIL hard to learn well. Regarding training, LightDIL is about five times slower than FM. This is because we adopt the paradigm of MAML [7] to update environment-invariant model parameters, which costs highly when computing the second-order gradients. In the future, it is possible to speed up LightDIL with the first-order approximation for MAML [7]. · Ablation studies. We next conduct ablation experiments to validate the effectiveness of the environment weights 𝑤 𝑡 in Equation (6), the variance-based regularizer 𝑉 𝑅 in Equation (6), the meta-learning 6 Although DIL's time (memory) cost seems not high (about 30 minutes or 300 MB) in our results, it is critical to improving the modeling efficiency since massive features/samples of industrial applications would immensely increase the cost. E.g. , there could be billions of features [46], resulting in more than 1 TB parameters in DIL. SIGIR '23, July 23-27, 2023, Taipei, Taiwan Yang Zhang, et al. Table 3: Results of the ablation studies over LightDIL on Douban and ML-10M. Figure 5: Performance of LightDIL on Douban (left) and ML10M (right) when splitting training data into different numbers of environments. Model AUC ↑ w/o environment weights 0.8069 ± 0.0057 w/o variance-based regularizer 0.8075 ± 0.0060 w/o meta-learning 0.8057 ± 0.0065 w/o disentanglement 0.8068 ± 0.0058 w/o environment-specific regularizer 0.8062 ± 0.0056 LightDIL (original) 0.8089 ± 0.0057 0.812 0.7185 LightDIL Best Baseline 0.810 0.7175 0.808 0.7165 0.806 0.7155 5 9 11 13 15 5 11 13 15 Number of Environments Number of Environments split environments. We draw the performance curve of LightDIL when 𝑇 varies in { 3 , 5 , 7 , 9 , 11 , 15 } . Figure 5 summarizes the results. We find that the performance of LightDIL increases first and then decreases as 𝑇 increases, i.e., the granularity becomes small. We attribute it to that a more fine-grained splitting could increase the heterogeneity of training environments, benefiting the learning of the environment-invariant correlations. However, too finegrained splitting would decrease the quality of training environments, e.g., the data becomes very sparse, preventing the exhibition of environment-invariant correlations. Besides, we find LightDIL could beat the best baseline when 𝑇 varies in a wide range, verifying the superiority of our method. module, the disentanglement, and the environment-specific regularizer 𝐿 𝑡 in Equation (8). Table 3 enumerates the performance of the variants of LightDIL by disabling the above components one by one. From the table, we obtain the following findings. · LightDIL w/o environment weights replaces the weights 𝑤 𝑡 in Equation (6) with the uniform 1 𝑇 . In Table 3, the performance gap between LightDIL and the variant w/o environment weights shows that using 𝑤 𝑡 instead of equally treating each environment is helpful. The underlying reason is that using the weights will lead the model to focus more on the difficult environments during the optimization, validating the arguments in Section 3.2.2. · Theperformance of LightDIL drops when we discard the variancebased regularizer, reflecting its importance to balance the model's predictions over multiple environments. The variance-based regularizer can regulate the model to be robust across environments, helping to learn the environment-invariant correlations. · The variant w/o meta-learning is implemented by removing meta training in Equation (9) and replacing e 𝜙 𝑠 with 𝜙 𝑠 in Equation (10) to update 𝜙 𝑠 . The inferior results of this variant indicate that metalearning does help solve the challenging bi-level optimization problem in Equation (6) and enhance the CTR performance. · Comparing LightDIL with the variant w/o disentanglement, we can observe that the disentanglement module effectively improves the CTR accuracy across environments. The better result of LightDIL shows that the disentanglement is vitally important for capturing the environment-invariant correlations when the sufficiency condition (in Assumption 1) is not satisfied. · Wecanfindthat the performance decreases when the environmentspecific regularizer 𝐿 𝑡 is disabled. The result verifies that 𝐿 𝑡 could force 𝜙 𝑡 to capture environment-specific correlations, and it is important for the disentanglement of 𝜙 𝑠 and 𝜙 𝑡 . · Granularity of separating environments. Wenext study how the granularity of environment splitting affects the effectiveness of our proposal. We re-split the training data into 𝑇 environments and evaluate the performance of the LightDIL trained on the new",
  "4.3 Experiments on Semi-synthetic Data (RQ3)": "We further design experiments on semi-synthetic datasets to verify whether DIL can successfully capture stable feature interactions by discarding the two types of environment-specific correlations: spurious correlations and correlations brought by dynamic causal relations, respectively. Note that if dynamic causal relations exist, the sufficiency condition (Assumption 1) is not satisfied. · Semi-synthetic datasets. It is hard to distinguish spurious correlations and dynamic causal relations in real-world datasets. As such, we construct two semi-synthetic datasets based on Avazu , which is an advertising click dataset provided by Avazu corporation in the Kaggle CTR Prediction Contest 7 . The statistics of Avazu are provided in Table 2. Avazu contains the click data between users and items spanning 10 days. We aim to separately inject the spurious correlations and dynamic causal relations into two constructed datasets. And thus we hope the feature interactions in the original dataset are relatively stable. With this consideration, we select Avazu with the click data in a short period, where the correlations between the original feature interactions and the clicks are unlikely to shift. Thereafter, we treat each day as an environment and construct two datasets: Avazu with spurious correlations (SP-Avazu) and Avazu with dynamic causal relations (DC-Avazu), using the methods described in Appendix A. For both SP-Avazu and DC-Avazu, we allocate the first 5 environments for training, the middle 2 for validation, and the last 3 for testing. · Performance comparison. We conduct experiments on both SP-Avazu and DC-Avazu to verify that DIL could learn stable feature interactions with the existence of strong spurious correlations and dynamic causal relations. We compare our methods DIL and LightDIL with FM, FwFMs, AFM, AutoFIS, Group-DRO, and V-REx. Here we ignore PROFIT and only compare with one representative NAS-based model AutoFIS because of the extremely long searching time of NAS-based models. Besides, we do not compare with CFM 7 http://www.kaggle.com/c/avazu-ctr-prediction. Reformulating CTR Prediction: Learning Invariant Feature Interactions for Recommendation SIGIR '23, July 23-27, 2023, Taipei, Taiwan (a) Performance on SP-Avazu dataset. (b) Performance on DC-Avazu dataset FM AFM Group-DRO DIL FwFMs AutoFIS V-REx LightDIL 0.8 0.75 0.6 0.70 0.4 0.65 0.2 0.60 0.0- 0.55 Figure 6: Performance of DIL, LightDIL, and the baselines on two semi-synthetic datasets: SP-Avazu and DC-Avazu. due to the lack of user ID information on Avazu, which is necessary for CFM. Figure 6 illustrates the performance of these methods. We can draw several conclusions from the figure. · On SP-Avazu, DIL and LightDIL substantially outperform the baselines. Moreover, they can generate meaningful predictions (AUC > 0 . 5) while most baselines cannot achieve that. These results verify that the proposed disentangled invariant learning method can learn stable feature interactions and discard the feature interactions with spurious correlations. · On SP-Avazu, FM, FwFMs, AFM, and AutoFIS show poor performance with AUC close to or less than 0.5 8 . The results reflect that models built with the ERM paradigm are significantly affected by the feature interactions with strong spurious correlations. · OnDC-Avazu, DIL and LightDIL also outperform all the baselines. Especially, DIL and LightDIL achieve better performances than VREx on DC-Avazu. This shows the effectiveness of the proposed method in learning stable feature interactions in the case where the sufficiency condition in Assumption 1 is not satisfied. On SP-Avazu, we unexpectedly find that V-REx performs very poorly. The possible reason is that V-REx needs large enough distribution shifts between environments, which is not satisfied. The spurious correlations in training environments are mostly positive and thus the shifts might not be large enough. (see 𝛽 𝑡 in Equation (15) in Appendix A) In contrast, the superior performance of DIL indicates that DIL can still learn stable feature interactions from the training environments with small shifts. · Regarding Group-DRO, it achieves good performance on SPAvazu but performs poorly on DC-Avazu. Group-DRO focuses on the worst-case environment, which helps to avoid being overly reliant on spurious correlations. Nevertheless, ignoring some environments makes Group-DRO possibly capture the environmentspecific correlations, bringing bad performance on DC-Avazu. To sum up, DIL and LightDIL can capture stable feature interactions and discard unstable feature interactions even when the sufficiency condition of invariant learning is not satisfied, enabling them to generalize well to unknown future periods.",
  "5 RELATED WORK": "CTR prediction. CTR prediction has been widely studied for many years [44]. Since raw features rarely lead to satisfying results [27, 44], feature interaction modeling, which indicates the 8 That AUC is less than 0.5 is because the spurious correlations of training and testing environments are inverse. ( cf. Appendix A). combination relationships of multiple features, becomes the focus of CTR prediction. FM is a pioneer and classical method, which models feature interactions in a factorization manner [32]. Later, many methods are proposed to achieve more effective and complicated feature interaction modeling based on various neural networks, such as MLPs [4, 11], product-based neural networks [14, 30], attentionbased networks [34, 43], convolutional neural networks [23, 26], and graph neural networks [12, 19]. Recently, NAS-based methods are proposed to automatically search the optimal network architecture for feature interaction modeling [37, 48], and automatically select/generate more effective feature interactions [8, 24, 38]. These methods reduce human efforts and achieve better feature interaction modeling. Besides, some methods [40, 47] additionally consider sequential user behavior modeling. Although various CTR models are proposed, existing works are built in an ERM paradigm, blindly learning feature interactions useful for fitting historical clicks. On the contrary, we reformulate the CTR task to learn stable feature interactions and propose an invariant learning solution. We notice that CFM [20] is also not built with ERM. Differently, CFM aims to capture all causal feature interactions via distribution balancing, while we learn stable feature interactions (with static causal relations to click) instead of all causal feature interactions, using the invariant learning method. Invariant learning. To alleviate spurious correlations, previous studies have focused on invariant learning [2, 25]. Generally speaking, invariant learning assumes that the training data is collected from distinct environments and aims to pursue robust predictions across multiple environments. In particular, Invariant Risk Minimization (IRM) [2] discovers stable features from multiple environments. Following IRM, some studies pay attention to relaxing the linear assumption in IRM [1], automatically splitting environments [5, 25], and revising the regularizers [18]. These methods assume the target could be sufficiently predicted with environmentinvariant correlations, which is not satisfied in the CTR task. We extend invariant learning to overcome this challenge. Except for invariant learning solutions, Distributionally Robust Optimization improves the OOD generalization by minimizing the loss in the worst environment [21, 33]. Stable learning instead achieves robust predictions via confounder balancing [35]. Existing works have also considered invariant learning for recommendation debiasing [15, 41], and alleviating spurious correlations in multimedia recommendation [6]. SGL [15] focuses on dealing with selection bias. InvPref [41] infers the labels of heterogeneous environments and captures invariant preference across environments for debiasing in collaborative filtering. InvRL [6] takes a similar method to InvPref [41] but aims at alleviating spurious correlations in multimedia content. Different from our proposal, these methods are not designed for the CTR task, do not learn stable feature interactions, and do not overcome the challenge that the sufficiency condition is not satisfied. Besides, existing works have also considered achieving OOD generalization for recommendation by learning causal relations ( static and dynamic) [16, 20, 39]. COR [39] and CausalPref [16] both focus on learning the causal model of data generation. CFM [20] is a CTR model and achieves OOD recommendations by distribution balancing as discussed before. Different SIGIR '23, July 23-27, 2023, Taipei, Taiwan Yang Zhang, et al. from them, we aim at learning stable feature interactions with static causal relations to clicks.",
  "6 CONCLUSION": "In this work, we reformulate the CTR prediction for recommendation by learning stable feature interaction from split environments, aiming to generalize well for future serving. Towards this goal, we propose a novel disentangled invariant learning framework, which extends invariant learning to successfully capture invariant correlations when the prediction target entangles both environmentinvariant and environment-specific correlations, i.e., the sufficiency prediction condition is not satisfied. We conduct extensive experiments on both real-world and semi-synthetic datasets, providing insightful analysis for the effectiveness of our proposal. This work showcased the limitation of the ERM learning paradigm for CTR prediction, despite its dominant role in recommendation research and industry. We replace the ERM learning paradigm with the proposed disentangled invariant learning to learn stable information, achieving better generalization for future periods. We believe the proposed invariant learning paradigm could adapt to other real-world recommendation tasks and recommender models. In the future, we will apply our DIL to other state-of-the-art recommender models and other recommendation tasks ( e.g., collaborative filtering, sequential recommendation, and conversational recommendation [31]). Besides, we will also explore better disentanglement mechanisms for the proposed DIL.",
  "A APPENDIX": "Construction of semi-synthetic datasets. In this part, we present the details of how to generate the two semi-synthetic datasets: SPAvazu and DC-Avazu. · SP-Avazu . To construct SP-Avazu with time-varying spurious correlations, we manually add a non-casual feature interaction correlated with the clicks. We inject the feature interaction by adding two identical binary features denoted as 𝑥 ′ 1 and 𝑥 ′ 2 , considering that CTR models take raw features as inputs instead of feature interactions. Specifically, we obtain 𝑥 ′ 1 and 𝑥 ′ 2 by flipping the click label with environment-specific probabilities. For a sample ( 𝒙 , 𝑦 ) from 𝑡 -th environment, we construct 𝑥 ′ 1 and 𝑥 ′ 2 as follows: 𝜖 𝑡 ∼ 𝐵𝑒𝑟𝑛𝑜𝑢𝑙𝑙𝑖 ( 𝑝 𝑡 ) , 𝑥 ′ 1 = 𝑥 ′ 2 = 𝜖 𝑡 ( 1 -𝑦 ) + ( 1 -𝜖 𝑡 ) 𝑦, (14) where 𝑝 𝑡 is the flipping probability in the 𝑡 -th environment and we use [ 0 . 1 , 0 . 15 , 0 . 2 , 0 . 25 , 0 . 5 , 0 . 5 , 0 . 7 , 0 . 8 , 0 . 85 , 0 . 9 ] for the ten environments of Avazu. Based on 𝑝 𝑡 , a flipping coefficient 𝜖 𝑡 is drawn from the Bernoulli distribution, and then utilized to flip the click label. Thereafter, the synthetic feature interaction is the interaction between 𝑥 ′ 1 and 𝑥 ′ 2 , and we obtain a constructed sample ( 𝒙 ′ , 𝑦 ) , where 𝒙 ′ = [ 𝑥 1 , . . . , 𝑥 𝑁 , 𝑥 ′ 1 , 𝑥 ′ 2 ] . · DC-Avazu . It includes the dynamic causal relations from the synthetic feature interactions to clicks. Similar to SP-Avazu, we additionally inject two identical features 𝑥 ′ 1 and 𝑥 ′ 2 , which causally revise the click label in environment-specific strengths. Specifically, given a sample ( 𝒙 , 𝑦 ) from the 𝑡 -th environment, we first draw 𝑥 ′ 1 and 𝑥 ′ 2 from the Bernoulli distribution with probability 𝑝 𝑡 . Thereafter, we generate the new click label e 𝑦 by considering the new feature 𝑥 ′ 1 with the strength 𝛽 𝑡 . Formally, we have:  where 𝑝 𝑡 for the Bernoulli distribution varies across environments. In this work, we use [ 𝑝 1 , . . . , 𝑝 10 ] = [ 0 . 1 , 0 . 2 , 0 . 2 , 0 . 2 , 0 . 2 , 0 . 1 , 0 . 2 , 0 . 2 , 0 . 2 , 0 . 2 ] for the ten environments of Avazu. The dynamic causal strength 𝛽 𝑡 varies in [0.6,0.5,0.15,0,-0.15,0,0.1,-0.15, -0.25, -0.4] for the ten environments. 𝜖 denotes the noises sampled from a uniform distribution to increase randomness. In a slight abuse of notation, since CTR prediction is a classification task, we treat samples with e 𝑦 > 0 . 5 as positive samples with rounded click labels e 𝑦 = 1 (otherwise, e 𝑦 = 0). Finally, the synthetic feature interaction is the interaction between 𝑥 ′ 1 and 𝑥 ′ 2 , and the newly constructed sample is ( 𝒙 ′ , e 𝑦 ) , where 𝒙 ′ = [ 𝑥 1 , . . . , 𝑥 𝑁 , 𝑥 ′ 1 , 𝑥 ′ 2 ] .",
  "ACKNOWLEDGMENTS": "This work is supported by the National Key Research and Development Program of China (2021YFF0901603), the National Natural Science Foundation of China (62272437, 62121002), and the CCCD Key Lab of Ministry of Culture and Tourism.",
  "REFERENCES": "[1] Kartik Ahuja, Karthikeyan Shanmugam, Kush Varshney, and Amit Dhurandhar. 2020. Invariant Risk Minimization Games. In International Conference on Machine Learning . PMLR, 145-155. [2] Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. 2019. Invariant risk minimization. arXiv preprint arXiv:1907.02893 (2019). [3] Jun-Hyun Bae, Inchul Choi, and Minho Lee. 2021. Meta-Learned Invariant Risk Minimization. arXiv preprint arXiv:2103.12947 (2021). [4] Weijie Bian, Kailun Wu, Lejian Ren, Qi Pi, Yujing Zhang, Can Xiao, Xiang-Rong Sheng, Yong-Nan Zhu, Zhangming Chan, Na Mou, et al. 2022. CAN: Feature Co-Action Network for Click-Through Rate Prediction. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining . 57-65. [5] Elliot Creager, Jörn-Henrik Jacobsen, and Richard Zemel. 2021. Environment Inference for Invariant Learning. In International Conference on Machine Learning . 2189-2200. [6] Xiaoyu Du, Zike Wu, Fuli Feng, Xiangnan He, and Jinhui Tang. 2022. Invariant Representation Learning for Multimedia Recommendation. In Proceedings of the 30th ACM International Conference on Multimedia . 619-628. [7] Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-Agnostic MetaLearning for Fast Adaptation of Deep Networks. In Proceedings of the 34th International Conference on Machine Learning . 1126-1135. [8] Chen Gao, Yinfeng Li, Quanming Yao, Depeng Jin, and Yong Li. 2021. Progressive Feature Interaction Search for Deep Sparse Network. Advances in Neural Information Processing Systems 34 (2021). [9] Chen Gao, Yu Zheng, Wenjie Wang, Fuli Feng, Xiangnan He, and Yong Li. 2022. Causal Inference in Recommender Systems: A Survey and Future Directions. arXiv preprint arXiv:2208.12397 (2022). [10] Clark Glymour, Kun Zhang, and Peter Spirtes. 2019. Review of causal discovery methods based on graphical models. Frontiers in genetics 10 (2019), 524. [11] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence . 1725-1731. [12] Wei Guo, Rong Su, Renhao Tan, Huifeng Guo, Yingxue Zhang, Zhirong Liu, Ruiming Tang, and Xiuqiang He. 2021. Dual graph enhanced embedding neural network for ctr prediction. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining . 496-504. [13] F Maxwell Harper and Joseph A Konstan. 2015. The movielens datasets: History and context. Acm Transactions on Interactive Intelligent Systems 5, 4 (2015), 1-19. [14] Xiangnan He and Tat-Seng Chua. 2017. Neural factorization machines for sparse predictive analytics. In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval . 355-364. [15] Yue He, Peng Cui, Jianxin Ma, Hao Zou, Xiaowei Wang, Hongxia Yang, and Philip S Yu. 2020. Learning Stable Graphs from Multiple Environments with Selection Bias. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 2194-2202. [16] Yue He, Zimu Wang, Peng Cui, Hao Zou, Yafeng Zhang, Qiang Cui, and Yong Jiang. 2022. CausPref: Causal Preference Learning for Out-of-Distribution Recommendation. In Proceedings of the ACM Web Conference 2022 . 410-421. [17] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014). Reformulating CTR Prediction: Learning Invariant Feature Interactions for Recommendation SIGIR '23, July 23-27, 2023, Taipei, Taiwan [33] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. 2019. Distributionally Robust Neural Networks. In International Conference on Learning [48] Guanghui Zhu, Feng Cheng, Defu Lian, Chunfeng Yuan, and Yihua Huang. 2022. NAS-CTR: Efficient Neural Architecture Search for Click-Through Rate Prediction. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval . 332-342.",
  "keywords_parsed": [
    "Factorization Machine",
    "Recommender System",
    "Invariant Learning"
  ],
  "references_parsed": [
    {
      "ref_id": "b1",
      "title": "Invariant Risk Minimization Games"
    },
    {
      "ref_id": "b2",
      "title": "Invariant risk minimization"
    },
    {
      "ref_id": "b3",
      "title": "Meta-Learned Invariant Risk Minimization"
    },
    {
      "ref_id": "b4",
      "title": "CAN: Feature Co-Action Network for Click-Through Rate Prediction"
    },
    {
      "ref_id": "b5",
      "title": "Environment Inference for Invariant Learning"
    },
    {
      "ref_id": "b6",
      "title": "Invariant Representation Learning for Multimedia Recommendation"
    },
    {
      "ref_id": "b7",
      "title": "Model-Agnostic MetaLearning for Fast Adaptation of Deep Networks"
    },
    {
      "ref_id": "b8",
      "title": "Progressive Feature Interaction Search for Deep Sparse Network"
    },
    {
      "ref_id": "b9",
      "title": "Causal Inference in Recommender Systems: A Survey and Future Directions"
    },
    {
      "ref_id": "b10",
      "title": "Review of causal discovery methods based on graphical models"
    },
    {
      "ref_id": "b11",
      "title": "DeepFM: A Factorization-Machine based Neural Network for CTR Prediction"
    },
    {
      "ref_id": "b12",
      "title": "Dual graph enhanced embedding neural network for ctr prediction"
    },
    {
      "ref_id": "b13",
      "title": "The movielens datasets: History and context"
    },
    {
      "ref_id": "b14",
      "title": "Neural factorization machines for sparse predictive analytics"
    },
    {
      "ref_id": "b15",
      "title": "Learning Stable Graphs from Multiple Environments with Selection Bias"
    },
    {
      "ref_id": "b16",
      "title": "CausPref: Causal Preference Learning for Out-of-Distribution Recommendation"
    },
    {
      "ref_id": "b17",
      "title": "Adam: A method for stochastic optimization"
    },
    {
      "ref_id": "b33",
      "title": "Distributionally Robust Neural Networks"
    },
    {
      "ref_id": "b48",
      "title": "NAS-CTR: Efficient Neural Architecture Search for Click-Through Rate Prediction"
    }
  ]
}