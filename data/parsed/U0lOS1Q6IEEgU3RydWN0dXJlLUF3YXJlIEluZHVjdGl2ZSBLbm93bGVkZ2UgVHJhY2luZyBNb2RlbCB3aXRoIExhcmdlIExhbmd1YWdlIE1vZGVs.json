{
  "SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model": "Lingyue Fu Shanghai Jiao Tong University Shanghai, China fulingyue@sjtu.edu.cn Hao Guan Shanghai Jiao Tong University Shanghai, China Guanhao2022@sjtu.edu.cn Kounianhua Du Shanghai Jiao Tong University Shanghai, China kounianhuadu@sjtu.edu.cn Jianghao Lin Shanghai Jiao Tong University Shanghai, China chiangel@sjtu.edu.cn Ruiming Tang Huawei Noah's Ark Lab Shenzhen, China tangruiming@huawei.com",
  "Wei Xia": "Huawei Noah's Ark Lab Shenzhen, China xiawei24@huawei.com Yasheng Wang Huawei Noah's Ark Lab Shenzhen, China wangyasheng@huawei.com",
  "ABSTRACT": "",
  "Weinan Zhang": "Shanghai Jiao Tong University Shanghai, China wnzhang@sjtu.edu.cn",
  "Yong Yu âˆ—": "Shanghai Jiao Tong University Shanghai, China yyu@apex.sjtu.edu.cn",
  "CCS CONCEPTS": "Knowledge Tracing (KT) aims to determine whether students will respond correctly to the next question, which is a crucial task in intelligent tutoring systems (ITS). In educational KT scenarios, transductive ID-based methods often face severe data sparsity and cold start problems, where interactions between individual students and questions are sparse, and new questions and concepts consistently arrive in the database. In addition, existing KT models only implicitly consider the correlation between concepts and questions, lacking direct modeling of the more complex relationships in the heterogeneous graph of concepts and questions. In this paper, we propose a Structure-aware INductive Knowledge Tracing model with large language model (dubbed SINKT ), which, for the first time, introduces large language models (LLMs) and realizes inductive knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural relationships between concepts and constructs a heterogeneous graph for concepts and questions. Secondly, by encoding concepts and questions with LLMs, SINKT incorporates semantic information to aid prediction. Finally, SINKT predicts the student's response to the target question by interacting with the student's knowledge state and the question representation. Experiments on four real-world datasets demonstrate that SINKT achieves stateof-the-art performance among 12 existing transductive KT models. Additionally, we explore the performance of SINKT on the inductive KT task and provide insights into various modules. âˆ— The corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CIKM '24, October 21-25, 2024, Boise, ID, USA. Â© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0436-9/24/10 https://doi.org/10.1145/3627673.3679760 Â· Social and professional topics â†’ Student assessment ; Â· Applied computing â†’ E-learning .",
  "KEYWORDS": "Knowledge Tracing, Inductive Learning, Online Education",
  "ACMReference Format:": "Lingyue Fu, Hao Guan, Kounianhua Du, Jianghao Lin, Wei Xia, Weinan Zhang, Ruiming Tang, Yasheng Wang, and Yong Yu. 2024. SINKT: A StructureAware Inductive Knowledge Tracing Model with Large Language Model. In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management (CIKM '24), October 21-25, 2024, Boise, ID, USA. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3627673.3679760",
  "1 INTRODUCTION": "Intelligent tutoring systems (ITS), such as Massive Open Online Courses (MOOCs) 1 and Khan Academy 2 , are garnering increasing attention from learners due to the extensive learning resources and real-time feedback mechanisms. Knowledge Tracing (KT) stands out as a vital area of research within ITS, which aims to assess the current knowledge states of students by analyzing their learning histories and to predict their responses to upcoming questions. KT not only helps to identify deficiencies in student's learning content but also provides a foundational basis for the subsequent instructional strategies in ITS. Existing KT models originate from traditional methods represented by BKT [7] and have evolved significantly with the advent of models based on deep neural networks. Deep learning-based KT models learn ID embeddings for questions and concepts through learning history of students. DKT [34] and DHKT [42] utilize Recurrent Neural Networks (RNNs) [35] to capture the sequential information of learning history. EERNNA [37], SAKT [32], and AKT [12] employ attention mechanisms to gauge the importance of a student's learning history in addressing the current question. 1 https://www.mooc.org/ 2 https://www.khanacademy.org/ CIKM '24, October 21-25, 2024, Boise, ID, USA. Fu et al. Figure 1: A demonstration of duplicated relations between concepts and questions in ITS. Concept ğ‘ 4 and question ğ‘ 5 are newly added to ITS, which do not appear in any learning history. Addition Multiplication Substraction Give each child 2 apples.Â 5 children need a total of how many apples? Bob bought two $3 colas and paid $10. How much should clerk change her? Division Student A ITS Database SKVMN [3] and DKVMN [50] apply memory networks [43] to exploit the relationships between concepts and questions. Some models [2, 28, 30, 45, 48] introduce additional information from the learning process to assist response prediction. IEKT [28] selects learning histories of similar students to enhance the understanding of the current student's knowledge state. GKT [30] and GIKT [48] incorporate the transition graph originated from learning history and use Graph Neural Networks (GNNs) [17] to extract representations from graph data. CL4KT [2] designs positive and negative sample pairs and employs contrastive learning [13] to generate more accurate representations of questions. LBKT [45] introduces various learning behaviors, including speed, attempts, and hints, to identify the learning patterns of students. Despite the success of existing KT models, some important limitations still exist. Firstly, current ID-based transductive KT models cannot give accurate predictions to newly arrived questions and questions with sparse interactions. Transductive KT models learn ID embeddings of questions and concepts from learning history and predict responses to those questions that have appeared in the dataset. Existing KT models are all ID-based and are therefore considered transductive KT models. However, as illustrated in Figure 1, when a new concept ğ‘ 4 and a new question ğ‘ 5 are added to the database of ITS, transductive KT models lack interaction data to learn their representations, thus unable to predict the response of the student A. Models that could predict those questions that haven't appear in the dataset are called inductive KT models . Meanwhile, interactions with individual students are limited, and thus question-level information is very sparse, which is difficult for ID-based transductive KT models to train. For example, the commonly used MovieLens dataset 3 in recommendation systems contains 25,000,095 ratings and 1,093,360 tag applications across 62,423 movies. However, in educational datasets, such as ASSIST09 4 , there are only 2,661 students with 165,455 interactions, while the total number of questions is 14,083. Secondly, current methods fail to capture the semantic dependencies and the sufficient topological relations among questions 3 https://grouplens.org/datasets/movielens/ 4 https://sites.google.com/site/assistmentsdata/home/2009-2010-assistment-data and concepts. For example, as shown in Figure 1, ğ‘ 1 and ğ‘ 2 are computational questions, while ğ‘ 3 and ğ‘ 4 are application questions. Compared to computational questions, application questions require students to possess additional analytical skills and have higher cognitive demands. Additionally, structural information exists among concepts. For instance, addition ğ‘ 1 should serve as the foundation for subtraction ğ‘ 2 and multiplication ğ‘ 3 during the learning process. If a student struggles with the concept 'addition', he will likely have poor demand for concepts 'subtraction' and 'multiplication'. Directly learning from learning sequences using ID embeddings makes it difficult to capture such type of information. In ITS, structural and semantic information are indispensable, as they can provide additional clues for knowledge tracing. Based on these considerations, in this paper, we propose a novel Structure-Aware INductive Knowledge Tracing Model with Large Language Model, named SINKT . To the best of our knowledge, SINKT is the first work that can achieve predictions for newly ingested questions, i.e., realize inductive knowledge tracing. Our framework also integrates open-world semantic and structural information by LLMs for the first time, enabling it to dynamically update and expand its knowledge base with minimal manual intervention. Specifically, SINKT first employs LLMs to generate a concept-question heterogeneous graph that contains useful structural information in ITS. Then, we use a Pretrained Language Model (PLM) to encode semantic information of questions and concepts instead of training ID embeddings. Subsequently, we encode the concept-question graph by applying a carefully designed structural information encoder. Finally, we design a student state encoder to capture sequential information and an interaction predictor to predict the student's response with his knowledge state and the target question description. To sum up, our contributions are summarized as follows: Â· We propose a novel Structure-Aware Inductive Knowledge Tracing model with LLM ( i.e., SINKT), and a full-automated pipeline for ITS to inductively trace mastery of new concepts and predict response to new questions, which is the first model to realize inductive knowledge tracing. Â· We utilize LLMs for the first time to carefully inject open-world knowledge, including semantic and structural information of questions and concepts, into the KT task. Â· Extensive experiments on four real-world datasets demonstrate that SINKT achieves state-of-the-art performance against 12 baselines, as well as superior capabilities to predict responses for unseen questions.",
  "2 RELATED WORK": "",
  "2.1 Knowledge Tracing": "To investigate the learning patterns of students in ITS, numerous KT models have been proposed to encode knowledge and model interaction histories. Traditional KT models such as Bayesian Knowledge Tracing [8] focus on tracing students' knowledge states by estimating general parameters. With the advent of deep learning, DKT [34] is the first to utilize RNN [35] and LSTM [15] to model the sequential dynamics of student interactions. DKT+ [49] and DHKT [42] extend the implementation of DKT, taking into account the relationships between questions and concepts. Inspired by the SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model CIKM '24, October 21-25, 2024, Boise, ID, USA. Transformer architecture [41], attention mechanisms [5] have been incorporated into deep learning KT models for capturing the relationships among questions and their relevance to a student's knowledge states [12, 32, 37]. Recently, attention has been paid to more nuanced behavioral data and advanced neural architectures. For instance, LBKT [45] analyzes a range of learning behaviors, containing the speed of responses, the number of attempts, and the use of hints. SAKT [32] and AKT [12] introduce attention mechanisms [5] to focus on the most relevant aspects of a student's past interactions. Additionally, innovative approaches such as CMKT [52]assess students' dynamic mastery of concepts. MF-DAKT [51], which incorporates multiple student-related factors with a dual attention mechanism, showcases the field's advancement towards more granular and complex models. Alongside these developments, graph-based KT models like GKT [30] and GIKT [48] employ GNN [17] to leverage the relational data among concepts.",
  "2.2 LLM-Enhanced User Modeling": "There have been some works using LLMs to enhance the performance of user modeling [22, 38]. Some work [23-25, 47] apply LLMs as profilers to involve the creation of prompts based on users' history, and input these prompts into LLMs to generate various aspects of user profiles. KAR [44] leverages LLMs to generate user and item profiles, encompassing user preference and real-world knowledge of items into click-through rate (CTR) prediction task. GIRL [53] uses LLMs to generate suitable job descriptions base on the user's curriculum vitae to help recommendation model understand jobhunter's preferences. In addition to profiling, LLMs serve as feature encoders, translating raw user data into rich, semantic embeddings that improve user modeling systems [20, 33, 44]. GPT4SM [33] employs GPT to encode queries and candidate text for relevance prediction in recommendation systems, and LKPNR [14] uses open-source LLMs for better semantic representation of news articles. Moreover, LLMs function as knowledge augmenters by integrating external knowledge into user models [4, 10, 19, 21, 44], thus enhancing the precision of user-related predictions. Mysore et al. [29] augment narrative-driven recommendations by generating author narrative queries with LLMs, and KAR [44] uses LLMprompted outputs to augment recommender systems with factual item knowledge. Existing LLM-enhanced user modeling methods are mostly applied in the domain of recommender systems (RS), which differ significantly from the KT task. In RS, users' interests typically remain stable over short periods, whereas in ITS, the knowledge states of students evolve dynamically as they engage with educational contents such as exercises. Additionally, there is strong structural information, such as interdependency and correlation among the concepts in ITS. Therefore, there is a need for specially designed models that can effectively track and adapt to the unique dynamics of students' learning processes in ITS.",
  "3 PRELIMINARIES": "",
  "3.1 Problem Definition": "Consider a set of students S , a set of questions Q , and a set of concepts C within an ITS. The learning history of a student ğ‘  âˆˆ S is recorded as ğ‘… ğ‘  = {( ğ‘ 1 , ğ‘Ÿ 1 ) , ( ğ‘ 2 , ğ‘Ÿ 2 ) , . . . , ( ğ‘ ğ‘‡ , ğ‘Ÿ ğ‘‡ )} , where ğ‘ ğ‘¡ âˆˆ Q represents the question answered by the student at time step ğ‘¡ , and ğ‘Ÿ ğ‘¡ âˆˆ { 0 , 1 } indicates whether the student ğ‘  correctly answers the question ğ‘ ğ‘¡ (1 for correct and 0 for incorrect). Given the learning history ğ‘… ğ‘  of a student and a new question ğ‘ ğ‘‡ + 1 , the goal of the KT task is to predict the probability that the student correctly answers the new question, denoted as ğ‘ ( ğ‘Ÿ ğ‘‡ + 1 = 1 | ğ‘… ğ‘  , ğ‘ ğ‘‡ + 1 ) . Note that in a real ITS, teachers continually expand the question and concept set, meaning that both the question set Q and the concept set C are in a state of ongoing growth. Previous KT models are trained and tested under the assumption Q ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› = Q ğ‘¡ğ‘’ğ‘ ğ‘¡ , which are only suitable for the transductive KT task. However, in the inductive KT task, Q ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› â‰  Q ğ‘¡ğ‘’ğ‘ ğ‘¡ . In this paper, our SINKT is capable of addressing the inductive task effectively while also delivering excellent performance in the transductive KT task.",
  "3.2 Concept-Question Graph Generation": "To inject open-world knowledge into SINKT, we construct a heterogeneous concept-question graph G = (V , E , OV , RE) to capture effective representations of concepts and questions, where OV represent the set of vertex type, and RE denotes the edge type (relation). The vertex set V includes the question set Q and the concept set C , and The vertex type set OV includes concept and question correspondingly. Edge set E describes different relationships between concepts and questions. The edge type set RE includes conceptquestion , question-concept and concept-concept . The graph G not only encapsulates the relationships between questions and concepts contained in the dataset but also incorporates open-world knowledge provided by LLMs. concept-question edges and question-concept edges are derived from the dataset. Each question ğ‘ ğ‘– corresponds to one or more concepts C ğ‘ ğ‘– = { ğ‘ 1 , ğ‘ 2 , . . . , ğ‘ ğ‘› ğ‘– } , and each concept ğ‘ ğ‘– corresponds to many questions Q ğ‘ ğ‘– = { ğ‘ 1 , ğ‘ 2 , . . . , ğ‘ ğ‘š ğ‘– } , where ğ‘› ğ‘– and ğ‘š ğ‘– denotes the number of concepts related to the question ğ‘ ğ‘– and the number of questions related to the concept ğ‘ ğ‘– , respectively. In the graph G , the relation is described as ğ‘› ğ‘– question-concept edges âŸ¨ ğ‘ ğ‘– , ğ‘ ğ‘— âŸ©( ğ‘— = 1 , 2 , . . . , ğ‘› ğ‘– ) and ğ‘š ğ‘– concept-question edges âŸ¨ ğ‘ ğ‘– , ğ‘ ğ‘— âŸ©( ğ‘— = 1 , 2 , . . . , ğ‘š ğ‘– ) . concept-concept edges within the graph G are generated by LLM. As demonstrated in Figure 2, for each concept ğ‘ ğ‘– , we employ a specific prompt and utilize GPT-4 [31] to identify a list of related concepts. [11, 18] suggest that LLMs struggle with tasks directly involving graph structures, often requiring specialized training or input transformation to handle graph structures. Therefore, we opt to use a 'select from the list' approach rather than asking GPT-4 to directly generate the graph. After GPT-4 generates the response, we use the regular expression extraction to get ğ‘ ğ‘– concepts related to ğ‘ ğ‘– , and add the directed edges âŸ¨ ğ‘ ğ‘— , ğ‘ ğ‘– âŸ©( ğ‘— = 1 , 2 , . . . , ğ‘ ğ‘– ) into the graph G .",
  "4 METHODOLOGY": "In this section, we will introduce our method in detail, and the overall framework is shown in Figure 3. After generating the conceptquestion graph by GPT-4, we first use the Textual Information Encoder (TIEnc) to extract semantic information from the concepts and questions. Then, we design a Structural Information Encoder (SIEnc) to learn question and concept representations from the heterogeneous graph. Finally, we design a student state encoder based CIKM '24, October 21-25, 2024, Boise, ID, USA. Fu et al.",
  "Prompt": "Learning order relation refers to relationships that establish a sequential and logical flow for mastering various concepts in a subject. For example, in the subject of mathematics, a student needs to understand the concept of 'integers' before moving on to learn about 'fractions'. Now, a student is learning the concept \"decimals\", which concepts should logically precede this concept to ensure a proper understanding?",
  "GPT4:": "Here's an ordered list of concepts from your candidate list that should logically precede learning about decimals: 1. Addition and Subtraction - Fundamental arithmetic operations are crucial as they form the basis of understanding how numbers are manipulated, which is essential when working with decimals. 2. Multiplication and Division - Understanding these operations is necessary before tackling decimals since decimals often involve these operations for more precise calculations. The candidate concepts are ['multiplication division', 'addition subtraction', 'segments and angles', 'statistics', 'fractions', 'absolute value',....]. Please choose from the list. 3. Fractions - Knowledge of fractions is closely linked to understanding decimals, as both deal with parts of a whole and often conversions between the two are required. 4. Order of Operations - Familiarity with the correct sequence of operations is important when solving problems involving decimals to ensure accurate calculations. Figure 2: Prompt demonstration of concept relation graph generation. on concept-level mastery to capture the student's knowledge state, and predicts the final response by an interaction predictor. where Wcq is the aggregate weight a ğ‘ğ‘ is the attention weight, âŠ• denotes concatenate operation. Similarly, Concept-Concept GAT integrate neighbor concept information to the target concept:",
  "4.1 Textual Information Encoder": "The introduction of LLMs bridges the gap between semantic information and plain text. SINKT utilizes a Pretrained Language Model (PLM) as semantic encoder to get representations of the plain text of concepts and questions. For each concept ğ‘ ğ‘– , we input its plain text TEXT ( ğ‘ ğ‘– ) into the PLM and acquire its representation vector  where ğ‘‘ ğ‘¡ is the encoding dimension of the PLM. Similarly, for each question ğ‘ ğ‘– , we could obtain its representation vector  The representation vectors x ğ‘ ğ‘– and x ğ‘ ğ‘– contain the semantic information of concepts and questions. In our framework, we fix the parameters of PLM encoder and use representation vectors as an input of following modules.",
  "4.2 Structural Information Encoder": "When a student answers a question, their mastery of concepts associated with that question influence their response. The mastery of both the target concept and its related concepts, as well as the related questions, can provide valuable information for the assessment of KT models. Therefore, the three types of edges in the heterogeneous graph G, i.e., concept-question, concept-concept, and question-concept, are considered by SINKT. To encode such structural information, we carefully design a multi-layer heterogeneous graph encoder. In the graph G , denote neighbor questions of the concept ğ‘ ğ‘– be N ğ‘ ğ‘ ğ‘– and N ğ‘ ğ‘ ğ‘– , respectively. The set of neighbor concepts of the question ğ‘ ğ‘– is denoted as N ğ‘ ğ‘ ğ‘– . We apply three different Graph Attention Networks (GAT) to aggregate neighborhood information for vertexes. Concept-Question GAT layer fuse neighbor concept representations of the target concept ğ‘ ğ‘– . Specifically, the ConceptConcept GAT can be expressed as:     and Question-Concept GAT integrate neighbor concept information to the target concept:   To emphasize the semantic information inherent in concepts and questions themselves, SINKT introduces jumping knowledge [46] to propagate the vertex original representations. The node representation of ğ‘™ -th encoder layer of can be represented as:   where Wc and Wq are trainable weight matrix for concepts and questions. We initialize the input of the SIEnc by the output of the semantic information encoder:  We use e qi âˆˆ R ğ‘‘ and e ci âˆˆ R ğ‘‘ to denote representation vectors of the question ğ‘ ğ‘– and the concept ğ‘ ğ‘– after the ğ‘˜ -layer graph encoder, where ğ‘‘ , ğ‘˜ are hyper-parameters.",
  "4.3 Student State Encoder": "To effectively learn from highly sparse question-response data, [12, 26, 27] suggest to transform the original question-response data into concept-response data. Due to the fact that some questions contain multiple concepts, SINKT averages representation vectors Concept SubGraph of SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model CIKM '24, October 21-25, 2024, Boise, ID, USA. (a) Textual Information Encoder (TIEnc). Concept-Question Graph Addition Pretrained Language Model (Textual Encoder) Concatenate Interaction Predictor C-C GAT C-Q GAT Q-C GAT Linear Linear ReLU ReLU Graph Encode Layer 1 Graph Encode Layer 2 ... ... GRU Cell ... C-C GAT C-Q GAT Q-C GAT Linear Linear ReLU ReLU Graph Encode Layer 1 Graph Encode Layer 2 ... ... Concatenate Interaction Predictor GRU Cell ... x9 C2 Ut Ut tanh F x9(1) ht Ut+1 xc1) (b) Structural Information Encoder (SIEnc). (c) Student State Encoder and Response Predictor. Figure 3: The framework and details of SINKT. of concepts related to the question ğ‘ ğ‘¡ to represent students' learning at time step ğ‘¡  where W ğ‘ âˆˆ R 3 ğ‘‘ and b ğ‘ âˆˆ R are trainable parameters. To train all parameters in SINKT, we choose the cross-entropy log loss between the predicted response ğ‘¦ ğ‘¡ + 1 and the ground-truth response ğ‘Ÿ ğ‘¡ + 1 as the objective function To jointly represent the item and correctness of students' response, we introduce v ğ‘¡ âˆˆ R 2 ğ‘‘ as  where 0 âˆˆ R ğ‘‘ is a zero-vector. To model learning history of students, we use Gated Recurrent Unit (GRU) [6] to capture the sequential learning behavior     Here ğœ denotes the sigmoid function, and W ğ‘Ÿ , b ğ‘Ÿ , W ğ‘§ , b ğ‘§ , W â„ , b â„ are trainable parameters, where W ğ‘Ÿ , W ğ‘§ , W â„ âˆˆ R ğ‘‘ Ã— 2 ğ‘‘ and b ğ‘Ÿ , b ğ‘§ , b â„ âˆˆ R ğ‘‘ . Hidden state h ğ‘¡ âˆˆ R ğ‘‘ represents the knowledge state of the student at time step ğ‘¡ . The student state encoder considers the conceptlevel forgetting and knowledge acquisition pattern together during student's learning process.",
  "4.4 Response Prediction": "When a student answers a question, his knowledge state of the corresponding concepts and the description of the question would influence his correctness. Given knowledge state of the student ht at time step ğ‘¡ , the question representation vector e qt + 1 and its concept-level representation vector ut + 1 , we make the prediction as follows",
  "4.5 Automated Pipeline for Inductive KT": "SINKT mainly focuses on the semantic and structural information, which could be completely generated by LLMs. Meanwhile, SINKT use textual representations instead of ID embeddings, which is available even in the absence of learning history. Therefore, when a new concept or a new question is introduced into the database of ITS, SINKT is capable to capture the knowledge state of students towards the new questions or concepts through automated processing. Figure 4 illustrates the automated ingestion process for ğ‘ 4 and ğ‘ 5 in Figure 1. When a teacher adds a new concept to the ITS, LLMs are invoked to integrate the new vertex into the Concept-Question Graph. The teacher could continue to add a new question that is related to this new concept, and the ITS further utilizes LLMs to annotate the new question with concepts. The new conceptquestion heterogeneous graph is automatically constructed. When it is necessary to assess a student's mastery of the new question ğ‘ 5, SINKT can automatically perform text encoding and propagate information through the graph, ultimately accomplishing response prediction. The automated ingestion pipeline enhances the ITS by providing the flexibility to update and expand the database. This capability not only streamlines the process of integrating new content but also ensures that the system remains adaptive to evolving educational needs and emerging topics. However, existing transductive KT models are unable to achieve this. CIKM '24, October 21-25, 2024, Boise, ID, USA. Fu et al. Figure 4: An automated pipeline for the inductive KT task. In the graph, a new concept ğ‘ 4 and a new question ğ‘ 5 are added into the database. Division SINKT Other KT Models Cannot Predict X",
  "5 EXPERIMENT": "In this section, we conduct experiments on four real-world datasets to evaluate the proposed SINKT framework. Specifically, we aim to answer the following research questions: RQ1 How does the proposed SINKT performs compared to the state-of-the-art KT models? RQ2 How does SINKT perform when a new question is added to the ITS? RQ3 What is the influence of various componets of SINKT? RQ4 How do different hyperparameters affect the performance of SINKT? RQ5 Is the concept relation graph generated by GPT-4 reasonable and useful?",
  "5.1 Datasets": "In our experiments, we evaluate our method on four datasets: (1) ASSIST09 5 , (2)ASSIST12 6 , (3) Junyi 7 and (4) Programming. ASSIST09, ASSIST12, and Junyi are public datasets widely used in intelligent education research. Programming is a private dataset with plain text of questions and concepts. For each dataset, students answering less than ten questions are removed. In order to simulate the situation of data sparsity, we choose 2,000 students' learning history in ASSIST12 and Junyi. The basic statistics of these four datasets are listed in Table 1, and descriptions are as follows: Â· ASSIST09 is collected from an online tutor platform that teaches students mathematics during the school year 2009 to 2010. The dataset records the plain text of concepts and does not describe questions. Â· ASSIST12 is also collected from the ASSIST platform from Sept 2012 to Oct 2013. Like ASSIST09, plain text of concepts is contained, but question descriptions are not provided. Â· Junyi is collected between November 2010 and March 2015 from the e-learning platform in Taiwan Junyi Academy. We choose KC as the concept text without using question descriptions. Â· Programming is collected from a commercial code-learning platform from December 13, 2021 to February 17, 2023. The dataset contains plain text of concepts and question descriptions. 5 https://sites.google.com/site/assistmentsdata/home/2009-2010-assistment- data?authuser=0 6 https://sites.google.com/site/ASSISTdata/home/2012-13-school-data-with-affect 7 https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=1198 Table 1: Statistics of all datasets. Q. and C. denote questions and concepts. Edge density is the density of the concept correlation graph generated by GPT-4.",
  "5.2 Baselines": "To demonstrate the effectiveness of predicting students' response, we evaluate the performance of SINKT with 12 baselines. Â· DKT [34] and DHKT [42] use deep learning methods on the KT task, which uses RNN to model students' learning history. Â· DKVMN [50], SKVMN [3] apply key-value memory network on the KT task. Â· CKT [36] applies hierarchical convolutional layers and learns a matrix demonstrating students' mastery level of each concept. Â· SAKT [32], EERNNA [37] and AKT [12] use attention mechanism to learn the past interactions' importance in predicting students' current questions. Â· GKT [30] generates a transition graph from the dataset and uses GNN to encode the knowledge states of students. Â· SKT [40] exploits similarity relation and prerequisites relation between concepts based on GKT. Â· IEKT [28] retrieves the similar histories of other students to enhance the prediction of target students. Â· LBKT [45] considers several dominant learning behaviors, including speed, attempts, and hints in the learning process.",
  "5.3 Implementation Details": "In our experiment, we choose the most recent 200 records of students. We choose BERT to be the textual encoder for three public datasets with concept text and choose Vicuna to be the textual encoder for the Programming dataset with concept and question text. We will compare the performance of different textual encoders in Section 5.4. The layer number of the graph encoder is chosen from { 1 , 2 , 3 } . The parameter ğ‘‘ is set to 256. The learning rate is chosen from { 0 . 0001 , 0 . 00005 } with a decay at each epoch. The optimizer is Adam [16]. For a fair comparison, the hyper-parameters of baselines are carefully chosen to have the best performance. Our code is available now 8 .",
  "5.4 Overall Performance (RQ1)": "We compare SINKT to 12 baselines on predicting the correctness of students' responses in four real-world datasets. The experimental results are shown in Table 2. We use Accuracy (ACC) and Area Under the Curve (AUC) as the evaluation metric. 8 The PyTorch and MindSpore implementation is available at: https://github.com/tubehao/SINKT.git and https://github.com/mindsporelab/models/tree/master/research/huawei-noah/SINKT. SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model CIKM '24, October 21-25, 2024, Boise, ID, USA. Table 2: Overall performance of SINKT and baselines in four real-world datasets. SINKT-BERT and SINKT-Vicuna choose BERT and Vicuna as TIEnc, respectively. Existing state-of-the-art results are underlined and the best results are bold. * indicates p-value < 0 . 05 in the t-test. In Table 2, several observations can be obtained as follows: (1) SINKT significantly outperforms all comparative methods across all datasets and evaluation metrics. This superior performance indicates that SINKT provides more precise representations of concepts and questions, as well as a more accurate estimation of students' knowledge states. Table 3: Performance comparison of DHKT, EERNNA, and SINKT in transductive and inductive KT tasks on Programming dataset. (2) When the datasets only contain textual information of concepts (ASSIST09, ASSIST12, Junyi), using BERT [9] as the textual encoder yields better results. This is attributed to the fact that most concept texts consist of 1-3 words, and models like BERT are more adept at encoding word-level text. In contrast, when SINKT is provided with question texts (Prgogramming), Vicuna [39] demonstrates improved performance, since generative models have a better understanding of sentence-level text typical of question descriptions. (3) Introducing additional specific information into the model does not guarantee beneficial results across all datasets. For example, GKT, which extracts a transition graph from training data to train concept embeddings, shows significant performance improvement on the ASSIST09 and ASSIST12 datasets. However, this approach introduces noise in the Junyi and Programming datasets, detracting from model effectiveness.",
  "5.5 Inductive Learning of SINKT (RQ2)": "To investigate the performance of SINKT after introducing new questions, we remove 1/4 of the question from the training set and evaluate the model's prediction accuracy on these questions on the validation and test sets. Since the other three datasets do not provide textual information for the questions, we compare the performance of SINKT with that of DHKT and EERNNA (best and second best baselines) on the Programming dataset. We implement random embedding initialization for DHKT and EERNNA on those unseen (a) Effect of training samples. \u0000\u0000\u0000 \u0000\u0000\u0000 \u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000 \u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000 \u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000 \u0000 \u0000\u0000 \u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000 \u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000\u0000\u0000 \u0000\u0000\u0000\u0000 (b) Rate of convergence. Figure 5: Cold start analysis of SINKT. questions to enable them to predict responses. The results of the experiment are shown in the Table3. The experiment demonstrates that the SINKT performs better in predicting unseen questions, whereas the existing KT models struggle significantly with this task, achieving an AUC of less than 0.6. We also investigate the cold start problem in real ITS. We first organize an experiment of different training samples on ASSIST09. We choose { 100 , 500 , 1000 , 2000, 2661 (all of the dataset) } students' CIKM '24, October 21-25, 2024, Boise, ID, USA. Fu et al. Table 4: Ablation study of SINKT on all datasets. (a) ASSIST09. 0 1 2 3 Layer Number k 0.735 0.738 0.741 0.744 0.747 ACC ACC AUC 0.768 0.771 0.774 0.777 0.780 AUC 0 1 2 3 Layer Number k 0.704 0.708 0.712 0.716 0.720 ACC ACC AUC 0.696 0.704 0.712 0.720 AUC 0 1 2 3 Layer Number k 0.7930 0.7945 0.7960 0.7975 0.7990 ACC ACC AUC 0.8230 0.8245 0.8260 0.8275 0.8290 AUC (b) ASSIST12. Figure 6: Sensitivity analysis of layer number ğ‘˜ on four datasets. 0 1 2 3 Layer Number k 0.766 0.768 0.770 0.772 0.774 ACC ACC AUC 0.8025 0.8050 0.8075 0.8100 AUC (c) Junyi. Figure 7: Sensitivity analysis of representation dimension ğ‘‘ on four datasets. 128 256 512 Dimension d 0.7375 0.7400 0.7425 0.7450 ACC ACC AUC 0.768 0.771 0.774 0.777 0.780 AUC (a) ASSIST09. 128 256 512 Dimension d 0.708 0.711 0.714 0.717 0.720 ACC ACC AUC 0.7016 0.7024 0.7032 0.7040 AUC (b) ASSIST12. 128 256 512 Dimension d 0.7690 0.7705 0.7720 0.7735 ACC ACC AUC 0.804 0.806 0.808 0.810 0.812 AUC (c) Junyi. 128 256 512 Dimension d 0.7930 0.7945 0.7960 0.7975 0.7990 ACC ACC AUC 0.820 0.825 0.830 0.835 0.840 AUC (d) Programming. learning history to train DHKT, EERNNA, and SINKT and evaluate them on the full test set. As shown in Figure 5a, as the number of students decreases, performance decline of SINKT is more gradual compared to baselines, which indicates that SINKT can still learn accurate concept/question representations using textual and structural information even with limited training data. Additionally, we present the training curves of DHKT, EERNNA, and SINKT on the ASSIST09 dataset in Figure 5b. We argue that SINKT converges faster and exhibits minimal overfitting. This robustness in performance under limited data conditions underscores the effectiveness of incorporating rich textual and structural information in SINKT.",
  "5.6 Ablation Study (RQ3)": "To further investigate the importance of each module in SINKT, we design three variants to conduct the ablation study, each of which removes or changes one part from the original SINKT: Â· SINKT-Linear removes the jumping knowledge module in the graph encoder. Â· SINKT-GAT removes GAT layers in the SIEnc, i.e. only uses a linear layer to be a textual information adapter. Â· SINKT-Text replaces the textual encoder with an embedding layer, which learns representations of questions and concepts from the dataset. Â· SINKT-Transition replaces the concept generated by GPT-4 with the transition graph generated in the dataset. Note that SINKT-Linear and SINKT-Graph still suitable for the inductive KT task, while SINKT-Transition and SINKT-Text do not support predicted responses to unseen questions. We demonstrate the experimental results of SINKT and four variants in Table 4. From the ablation study, we can derive several conclusions regarding the impact of different components in SINKT. Firstly, removing textual initialization (SINKT-Text) and the GAT layer (SINKT-GAT) in SIEnc results in a performance decline, indicating that both structural and textual information contributes to the learning of question and concept representations. Secondly, removing the jumping knowledge layer leads to a significant performance drop. This is because our heterogeneous graph is unevenly distributed, and the addition of the jumping knowledge layer allows the model to actively capture useful information. Thirdly, the (d) Programming. SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model CIKM '24, October 21-25, 2024, Boise, ID, USA. Concept Concept 0.00 0.05 0.10 0.15 0.20 0.25 Concept Concept Concept 0.00 0.05 0.10 0.15 0.20 0.25 Concept Concept 0.0 0.2 0.4 0.6 0.8 1.0 Concept Concept 1.0 0.8 0.6 0.4 0.2 0.25 0.20 0.15 0.10 0.05 0.0 Concept Concept 0.00 0.05 0.10 0.15 0.20 0.25 0.00 (a) Transition graph. (b) Concept graph generated by GPT-4. (c) Concept graph with attention weights. Figure 8: Concept graph comparison between different generation types. = Equivalent Fractions = Ordering Fractions - 0.1700 0.5877 0.00 0.0391 0.1251 0.0313 - - - 0.00 0.0062 0.0313 - - 0.00 0.00 0.00 0.00 Transition Graph Concept Graph with Attention Score =Â  Addition and SubtractionÂ Fractions Figure 9: Detailed demonstration of transition graph and concept graph with attention score. performance degradation of SINKT-Transition demonstrates the effectiveness of the Concept Graph generated by GPT-4. of the concept-concept graph, we compare the transition graph and our concept relation. Transition graph denotes the transition probability of concept answering, which is derived from dataset and could not be generated without training data. We demonstrates the transition graph of ASSIST09 in Figure 8a. The weight in the ğ‘– -th row and the ğ‘— -th column of the transition graph means the probability of concept ğ‘ ğ‘– appears after concept ğ‘ ğ‘— in the dataset. Since the learning sequence of concepts are generated by ITS's recommendation algorithm, the distribution of prerequisite concepts in the transition graph is relatively fixed. The concept relation graph generated by GPT-4 is shown in Figure 8b. The weight of ğ‘ ğ‘– in the figure is 1 | N ğ‘ ğ‘ ğ‘– | . Meanwhile, we visualize the attention score of the first GAT layer in Figure 8c. Compared to transition graph, our concept graph with attention weight is more integrated.",
  "5.7 Parameter Sensitivity Analysis (RQ4)": "In order to have an insight into the graph information conduction, we change the number of the Graph Encode layer ğ‘˜ ranging from 0 to 3. Especially when ğ‘˜ = 0, the graph encoder degrades into a Linear layer without neighbor aggregation. The experimental results on four datasets are shown in Figure 6. We find that SINKT performs best in most cases when ğ‘˜ = 2, which indicates that second-order relationships in the concept-question heterogeneous graph are crucial for the learning process. The primary second-order relationships include concept-question-concept, concept-conceptquestion, and question-concept-question. In contrast, lower-order relationships provide limited neighbor information, while higherorder relationships introduce noise. Furthermore, we investigate the sensitivity of dimension ğ‘‘ of representations vectors Ëœ ğ‘, Ëœ ğ‘ . We evaluate SINKT's performance on three different numbers of ğ‘‘ : { 128 , 256 , 512 } . The experimental results on four datasets are shown in Figure 7. We suggest that the best representation dimension of SINKT is 256. However, existing transductive KT models usually choose 64 or 128 as the representation dimension of concepts and questions. The gap in the selection of dimension values primarily arises from the introduction of open-world knowledge in SINKT. This knowledge is extensive and requires additional dimensions to be effectively encoded.",
  "5.8 Quality of the Graph Generation (RQ5)": "As we generate a concept relation graph by GPT-4, it is critical to inspect the quality of the graph. To investigate the overall quality We also give a case study for the concept graph's rationality in Figure 9. In the transition graph, concept ğ‘’ 1 , ğ‘’ 2 , ğ‘’ 3 nearly do not have correlations. While in our concept graph, relationship between every two concepts are clear and can be judged by reasonable scores.",
  "6 CONCLUSION": "In this paper, we introduce a structure-aware knowledge tracing framework SINKT with large language model, which are suitable for both transductive and inductive KT tasks. SINKT leverages LLMs to build structural relationships between concepts and questions and encode semantic information. To better aggregate these information, in the learning process of students, we carefully design a textual information encoder, a structural information encoder and a student state encoder. Experimental results on four real-world datasets show that SINKT outperforms current ID-based KT models on both transductive and inductive KT tasks. We also provide case studies and ablation studies to prove the effectiveness of each module in SINKT. In the future, we will try to incorporate more wealthy open-world knowledge and make more accurate predictions on inductive KT tasks.",
  "ACKNOWLEDGMENTS": "The Shanghai Jiao Tong University team is partially supported by National Natural Science Foundation of China (62177033, 62076161) and Shanghai Municipal Science and Technology Major Project (2021SHZDZX0102). The work is also sponsored by Huawei Innovation Research Program. We thank MindSpore [1] for the partial support of this work. Concept CIKM '24, October 21-25, 2024, Boise, ID, USA. Fu et al.",
  "REFERENCES": "[1] 2020. MindSpore. https://www.mindspore.cn/ [2] 2022. Contrastive Learning for Knowledge Tracing. In TheWebConf 2022 . [3] Ghodai Abdelrahman and Qing Wang. 2019. Knowledge Tracing with Sequential Key-Value Memory Networks. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '19) . ACM. https://doi.org/10.1145/3331184.3331195 [4] Arkadeep Acharya, Brijraj Singh, and Naoyuki Onoe. 2023. LLM Based Generation of Item-Description for Recommendation System. Proceedings of the 17th ACM Conference on Recommender Systems (2023). https://api.semanticscholar. org/CorpusID:261823487 [5] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2016. Neural Machine Translation by Jointly Learning to Align and Translate. arXiv:1409.0473 [cs.CL] [6] Junyoung Chung, Ã‡aglar GÃ¼lÃ§ehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling. CoRR abs/1412.3555 (2014). arXiv:1412.3555 http://arxiv.org/abs/1412.3555 [7] Albert T Corbett and John R Anderson. 1994. Knowledge tracing: Modeling the acquisition of procedural knowledge. In Proceedings of the 6th International Conference on User Modeling . Springer, 32-41. [8] Albert T Corbett and John R Anderson. 1994. Knowledge tracing: Modeling the acquisition of procedural knowledge. User modeling and user-adapted interaction 4, 4 (1994), 253-278. [9] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv preprint arXiv:1810.04805 (2018). [10] Yihao Fang, Xianzhi Li, Stephen W. Thomas, and Xiaodan Zhu. 2023. ChatGPT as Data Augmentation for Compositional Generalization: A Case Study in Open Intent Detection. arXiv:2308.13517 [cs.CL] [11] A. Fatemi et al. 2023. Which Modality should I use - Text, Motif, or Image? : Understanding Graphs with Large Language Models. ar5iv (2023). Accessed: 2023-05-06. [12] Aritra Ghosh, Neil Heffernan, and Andrew S. Lan. 2020. Context-Aware Attentive Knowledge Tracing. arXiv:2007.12324 [cs.LG] [13] Raia Hadsell, Sumit Chopra, and Yann LeCun. 2006. Dimensionality reduction by learning an invariant mapping. In 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06) , Vol. 2. IEEE, 1735-1742. [14] Chen hao, Xie Runfeng, Cui Xiangyang, Yan Zhou, Wang Xin, Xuan Zhanwei, and Zhang Kai. 2023. LKPNR: LLM and KG for Personalized News Recommendation Framework. arXiv:2308.12028 [cs.IR] [15] Sepp Hochreiter and JÃ¼rgen Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735-1780. [16] Diederik P. Kingma and Jimmy Ba. 2014. Adam: A Method for Stochastic Optimization. arXiv preprint arXiv:1412.6980 (2014). [17] Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In 5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings . [18] Y. Kojima, X. Yao, et al. 2023. GPT4Graph: Can Large Language Models Understand Graph Structured Data? An Empirical Evaluation and Benchmarking. ar5iv (2023). Accessed: 2023-05-06. [19] Jinming Li, Wentao Zhang, Tian Wang, Guanglei Xiong, Alan Lu, and Gerard Medioni. 2023. GPT4Rec: A Generative Framework for Personalized Recommendation and User Interests Interpretation. arXiv:2304.03879 [cs.IR] [20] Nan Li, Bo Kang, and Tijl De Bie. 2023. LLM4Jobs: Unsupervised occupation extraction and standardization leveraging Large Language Models. arXiv:2309.09708 [cs.CL] [21] Pan Li, Yuyan Wang, Ed H. Chi, and Minmin Chen. 2023. Prompt Tuning Large Language Models on Personalized Aspect Extraction for Recommendations. arXiv:2306.01475 [cs.IR] [22] Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Hao Zhang, Yong Liu, Chuhan Wu, Xiangyang Li, Chenxu Zhu, Huifeng Guo, Yong Yu, Ruiming Tang, and Weinan Zhang. 2023. How Can Recommender Systems Benefit from Large Language Models: A Survey. arXiv preprint arXiv:2306.05817 (2023). [23] Jianghao Lin, Rong Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, Shigang Quan, Ruiming Tang, Yong Yu, and Weinan Zhang. 2024. ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation. In Proceedings of the ACM on Web Conference 2024 (WWW '24) . 3497-3508. [24] Qijiong Liu, Nuo Chen, Tetsuya Sakai, and Xiao-Ming Wu. 2023. A First Look at LLM-Powered Generative News Recommendation. ArXiv abs/2305.06566 (2023). https://api.semanticscholar.org/CorpusID:263891105 [25] Qijiong Liu, Nuo Chen, Tetsuya Sakai, and Xiao-Ming Wu. 2023. ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models. arXiv:2305.06566 [cs.IR] [26] Zitao Liu, Qiongqiong Liu, Jiahao Chen, Shuyan Huang, and Weiqi Luo. 2023. simpleKT: A Simple But Tough-to-Beat Baseline for Knowledge Tracing. arXiv:2302.06881 [cs.LG] [27] Zitao Liu, Qiongqiong Liu, Jiahao Chen, Shuyan Huang, Jiliang Tang, and Weiqi Luo. 2023. pyKT: A Python Library to Benchmark Deep Learning based Knowledge Tracing Models. arXiv:2206.11460 [cs.LG] [28] Ting Long, Yunfei Liu, Jian Shen, Weinan Zhang, and Yong Yu. 2021. Tracing Knowledge State with Individual Cognition and Acquisition Estimation. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval . ACM, 173-182. [29] Sheshera Mysore, Andrew McCallum, and Hamed Zamani. 2023. Large Language Model Augmented Narrative Driven Recommendations. arXiv:2306.02250 [cs.IR] [30] Hiromi Nakagawa, Yusuke Iwasawa, and Yutaka Matsuo. 2019. Graph-based Knowledge Tracing: Modeling Student Proficiency Using Graph Neural Network. In Proceedings of the 2019 IEEE/WIC/ACM International Conference on Web Intelligence (WI) . https://doi.org/10.1145/3350546.3352513 [31] OpenAI. 2023. Introducing GPT-4. https://openai.com/blog/gpt-4. [32] Shalini Pandey and George Karypis. 2019. A Self-Attentive model for Knowledge Tracing. In Proceedings of the 12th International Conference on Educational Data Mining (EDM 2019) . International Educational Data Mining Society. [33] Wenjun Peng, Derong Xu, Tong Xu, Jianjin Zhang, and Enhong Chen. 2023. Are GPT Embeddings Useful for&nbsp;Ads and&nbsp;Recommendation?. In Knowledge Science, Engineering and Management: 16th International Conference, KSEM 2023, Guangzhou, China, August 16-18, 2023, Proceedings, Part IV (Guangzhou, China). Springer-Verlag, Berlin, Heidelberg, 151-162. https://doi.org/10.1007/9783-031-40292-0_13 [34] Chris Piech, Jonathan Bassen, Jonathan Huang, Surya Ganguli, Mehran Sahami, Leonidas J. Guibas, and Jascha Sohl-Dickstein. 2015. Deep knowledge tracing. In Advances in Neural Information Processing Systems , Vol. 28. 505-513. [35] David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. 1986. Learning representations by back-propagating errors. Nature 323, 6088 (1986), 533-536. [36] Shuanghong Shen, Qi Liu, Enhong Chen, Han Wu, Zhenya Huang, Weihao Zhao, Yu Su, Haiping Ma, and Shijin Wang. 2020. Convolutional Knowledge Tracing: Modeling Individualization in Student Learning Process. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (Virtual Event, China) (SIGIR '20) . Association for Computing Machinery, New York, NY, USA, 1857-1860. https://doi.org/10.1145/3397271.3401288 [37] Yu Su, Qingwen Liu, Qi Liu, Zhenya Huang, Yu Yin, Enhong Chen, Chris H. Q. Ding, Si Wei, and Guoping Hu. 2018. Exercise-Enhanced Sequential Modeling for Student Performance Prediction. In AAAI . 2435-2443. [38] Zhaoxuan Tan and Meng Jiang. 2023. User Modeling in the Era of Large Language Models: Current Research and Future Directions. arXiv:2312.11518 [cs.CL] [39] Vicuna Team. 2023. Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality. https://huggingface.co/lmsys/vicuna-13b-v1.5. Hugging Face (2023). [40] Shiwei Tong, Qi Liu, Wei Huang, Zhenya Hunag, Enhong Chen, Chuanren Liu, Haiping Ma, and Shijin Wang. 2020. Structure-Based Knowledge Tracing: An Influence Propagation View. In 2020 IEEE International Conference on Data Mining (ICDM) . 541-550. https://doi.org/10.1109/ICDM50108.2020.00063 [41] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All You Need. In Advances in neural information processing systems . 5998-6008. [42] T. Wang, F. Ma, and J. Gao. 2019. Deep Hierarchical Knowledge Tracing. In Proceedings of the 12th International Conference on Educational Data Mining . 667-670. [43] Jason Weston, Sumit Chopra, and Antoine Bordes. 2015. Memory Networks. arXiv:1410.3916 [cs.AI] [44] Yunjia Xi, Weiwen Liu, Jianghao Lin, Xiaoling Cai, Hong Zhu, Jieming Zhu, Bo Chen, Ruiming Tang, Weinan Zhang, Rui Zhang, and Yong Yu. 2023. Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models. arXiv:2306.10933 [cs.IR] [45] Bihan Xu, Zhenya Huang, Jiayu Liu, Shuanghong Shen, Qi Liu, Enhong Chen, Jinze Wu, and Shijin Wang. 2023. Learning Behavior-oriented Knowledge Tracing. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<conf-loc>, <city>Long Beach</city>, <state>CA</state>, <country>USA</country>, </conf-loc>) (KDD '23) . Association for Computing Machinery, New York, NY, USA, 2789-2800. https://doi.org/10.1145/3580305.3599407 [46] Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie Jegelka. 2018. Representation Learning on Graphs with Jumping Knowledge Networks. CoRR abs/1806.03536 (2018). arXiv:1806.03536 http://arxiv.org/abs/1806.03536 [47] Fan Yang, Zheng Chen, Ziyan Jiang, Eunah Cho, Xiaojiang Huang, and Yanbin Lu. 2023. PALR: Personalization Aware LLMs for Recommendation. arXiv:2305.07622 [cs.IR] [48] Liang Yang, Binbin Cui, Chengjie Wu, Chao Wang, Xing Zhang, and Jian Liu. 2020. GIKT: A Graph-based Interaction Model for Knowledge Tracing. arXiv preprint arXiv:2002.07033 (2020). [49] Chun-Kit Yeung and Dit-Yan Yeung. 2018. Addressing Two Problems in Deep Knowledge Tracing via Prediction-Consistent Regularization. In Proceedings of the Fifth Annual Conference on Learning at Scale (London, UK), Rose Luckin, Scott Klemmer, and Kenneth R. Koedinger (Eds.). ACM, 5:1-5:10. CIKM '24, October 21-25, 2024, Boise, ID, USA. SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model [50] Jiani Zhang, Xingjian Shi, Irwin King, and Dit-Yan Yeung. 2017. Dynamic KeyValue Memory Networks for Knowledge Tracing. arXiv:1611.08108 [cs.AI] [51] MoyuZhang, Xinning Zhu, Chunhong Zhang, Yang Ji, Feng Pan, and Changchuan Yin. 2021. Multi-Factors Aware Dual-Attentional Knowledge Tracing. In Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management (CIKM '21) . ACM. https://doi.org/10.1145/3459637.3482372 [52] Moyu Zhang, Xinning Zhu, Chunhong Zhang, Wenchen Qian, Feng Pan, and Hui Zhao. 2023. Counterfactual Monotonic Knowledge Tracing for Assessing Students' Dynamic Mastery of Knowledge Concepts. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM '23) . ACM. https://doi.org/10.1145/3583780.3614827 [53] Zhi Zheng, Zhaopeng Qiu, Xiao Hu, Likang Wu, Hengshu Zhu, and Hui Xiong. 2023. Generative Job Recommendations with Large Language Model. arXiv:2307.02157 [cs.IR]",
  "keywords_parsed": [
    "Knowledge Tracing",
    " Inductive Learning",
    " Online Education"
  ]
}