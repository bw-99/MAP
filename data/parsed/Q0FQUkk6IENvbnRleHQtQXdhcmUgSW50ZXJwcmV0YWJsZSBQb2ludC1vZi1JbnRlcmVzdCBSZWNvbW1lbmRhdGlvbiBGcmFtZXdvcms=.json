{"title": "CAPRI: Context-Aware Interpretable Point-of-Interest Recommendation Framework", "authors": "Ali Tourani; Hossein A Rahmani; Yashar Deldjoo", "pub_date": "2023-06-20", "abstract": "Point-of-Interest (POI) recommendation systems have gained popularity for their unique ability to suggest geographical destinations, with the incorporation of contextual information such as time, location, and user-item interaction. Existing recommendation frameworks lack the contextual fusion required for POI systems. This paper presents CAPRI, a novel POI recommendation framework that effectively integrates context-aware models, such as GeoSoCa, LORE, and USG, and introduces a novel strategy for the efficient merging of contextual information. CAPRI integrates an evaluation module that expands the evaluation scope beyond accuracy to include novelty, personalization, diversity, and fairness. With an aim to establish a new industry standard for reproducible results in the realm of POI recommendation systems, we have made CAPRI openly accessible on GitHub, facilitating easy access and contribution to the continued development and refinement of this innovative framework.", "sections": [{"heading": "INTRODUCTION", "text": "For selecting the appropriate vacation destination, restaurant, visiting locations, and so-called Point-of-Interest (POI), users must choose from a variety of possibilities. POI recommender systems can be useful tools for overcoming the inevitable information overload in many use cases. For instance, recommending hotels and other travel-related destinations remains a challenging task since trip planning entails looking for a set or list of interconnected factors (e.g., means of transportation, housing, and attractions) and where contextual factors may have a significant impact (e.g., time, location, and social environment).\nRecent years have seen the development of numerous frameworks, libraries, and tools for Recommender System (RS) that make it easy for researchers to mimic the recommendation process and its influence on user preference. Utilizing frameworks for recommendation leads to the standardization of algorithm implementations and facilitates the reproducibility of experiments. Despite the advances, reproducibility remains a challenge in RS research, particularly in the areas that are not well-established, such as fairness-aware and domain-specific recommendations [19]. Even minor differences in parameters and experimental settings can yield inconsistent results, making it difficult to provide definitive answers about the relative properties of different algorithms. Hence, reproducible evaluation and fair comparison of methods are demanding factors in RSs.\nDespite the progress made in the field, existing frameworks for the reproducibility of RSs are typically intended to simulate generic Collaborative Filtering environments. For instance, Cornac [17] includes models leveraging auxiliary data such as item descriptive text and image. RecBole [30], an alternative comprehensive framework, introduces general, sequential, and knowledge-based recommendations. Likewise, Elliot [2] is another framework that covers a wide range of general-purpose models.\nHowever, POI recommendation has particularities that set them apart from recommendations in other domains: \u201a The importance of context integration and fusion: The users' check-ins in POI recommendations are considerably affected by the contextual information. For instance, the geographical property of location affects the user mobility pattern or users' visit is time-depended which indicates the importance of temporal information [11]. Other types of context may include social ties, the category of POIs, comments on POIs, etc. Previous research works such as [12] have shown the way incorporating these rich contexts information have a significant impact on the performance of POI recommendation models. Therefore, in recent years, there has been a growth in the demand for specialized recommendation algorithms and methodologies that can incorporate and fuse contextual information into the POI recommendation process [24];\n\u201a High sparsity: The characteristics of the check-in datasets of the POI recommendation domain differ significantly from those of the other recommendation domain [3,8]. Accordingly, the density of POI check-ins data is typically approximately 0.1%, whereas the density of Netflix data for movie suggestions is 1.2%. This is because a person can only visit a limited number of locations, whereas a city can contain a vast number of POIs; \u201a Necessity for multi-dimensional evaluation: Previous papers [8,18,23] in the POI field predominantly focus on accuracy-oriented metrics. However, there is a remarkable consensus in the RS community that there are other important facets to the recommendation process that accuracy metric systems cannot simply capture, such as the novelty, diversity, and catalog coverage of recommenders. Therefore, we aim to standardize multi-faceted evaluation on the accuracy, beyond-accuracy, and fairness dimensions [22].\nContributions. The work at hand addresses the above shortcoming by proposing CAPRIfoot_0 , a specialized framework for evaluating and benchmarking state-of-the-art POI recommendation models. Different from existing open-source frameworks, such as DaisyRec [21],\nElliot [2], LensKit [6], LibRec [7], LibRec-auto [20], OpenRec [25], CaseRec [4], which mainly aim to reproduce various traditional recommender systems, deep learning-based recommender systems such as DeepRec [29], and multimodal RSs like Cornac [17], CAPRI is intended to provide contextually aware recommendation and evaluation in the POI domain. We have equipped our framework with state-of-the-art models, algorithms, well-known datasets for POI recommendations, and multi-dimensional evaluation criteria (accuracy, beyond-accuracy, and user-item fairness). It also supports the reproducibility of results using various adjustable configurations for comparative experiments.\nTo the best of our knowledge, there is no publicly accessible framework for the reproducibility of POI models in the field of context-aware POI recommendation, despite the recent advances in the field.", "publication_ref": ["b18", "b16", "b29", "b1", "b10", "b11", "b23", "b2", "b7", "b7", "b17", "b22", "b21", "b20", "b1", "b5", "b6", "b19", "b24", "b3", "b28", "b16"], "figure_ref": [], "table_ref": []}, {"heading": "RELATED FRAMEWORKS", "text": "In recent years, introducing and implementing RS frameworks and libraries gained huge attention. Sonboli et al. [20] proposed a recommendation framework titled Librec-auto for automating various aspects of offline batch RS experimentats. The framework covers a wide range of recommendation and re-ranking algorithms, along with various evaluation and fairness-aware metrics. Another framework introduced by Zhao et al. [31] covers a wide range of RS applications and contains 73 models and 28 datasets. Their framework, titled RecBole, is implemented in PyTorch and focuses on the performance of the executions, along with covering potential evaluation on the RS domain. Sun et al. [21] introduced a Python-based toolkit named DaisyRec as a benchmark for rigorous evaluation in recommendation. Their toolkit is equipped with seven well-tuned state-of-the-art algorithms and six widely-used datasets. In contrast with other existing open-source libraries, DaisyRec aims to rigorously evaluate the performance of the recommendation. Similar to CAPRI, Werneck et al. [24] introduces an additional framework for the reproducibility of POI experiment recommendations. However, their approach is not exhaustive and is not easily replicable, as it only generates the outcomes of their earlier work [23].\nThe majority of current frameworks are general-purpose and do not prioritize domain-specific recommendation models, such as context awareness. This characteristic makes it challenging to repurpose their research skills for domain-specific work. In contrast to the introduced frameworks, CAPRI focuses on the POI domain and aims to provide researchers with all the necessary resources.", "publication_ref": ["b19", "b30", "b20", "b23", "b22"], "figure_ref": [], "table_ref": []}, {"heading": "PROPOSED FRAMEWORK", "text": "CAPRI is an open-source recommendation framework implemented in Python, suitable for practical experimentation and reproducibility study. The framework is distributed under the GPL v.3 license and can be downloaded or cloned from GitHub. In this regard, Figure 1 illustrates the general workflow of CAPRI in detail.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Files Structure", "text": "In terms of implementation, the files of the framework are organized in several directories to facilitate accessibility and extensibility. We utilize PascalCase and camelCase as basic naming structures and merge words into a single string in CAPRI for folder and file names, respectively. Detailed descriptions of the directories of the framework containing files are presented below in brief:\n\u201a Data: Contains data-driven files and functions of various types.\nEach dataset includes files with the .txt extension that contain train, test, and tune data. Moreover, other files containing the check-ins data and relations among users/items, such as social and geographical data, are stored in folders with the same name as each dataset. There are also some data processing functions in the Data directory, including readDataSizes.py to read meta-data of the dataset, loadDatasetFiles.py to load selected dataset items, and calculateActiveUsers.py to calculate Active/Inactive users of a selected dataset for fairness-aware analysis. Current datasets of CAPRI will be discussed in Section 3.2. \u201a Models: Contains the models used in the framework and several common functions in the utils.py file to avoid code duplication and increase the re-usability of model files. For each model, there is a folder with the same name, a main.py to control the overall processing of functions, and varying processing functions to process a selected dataset according to the selected model. The accessible models in CAPRI will be discussed in more depth in Section 3.3. \u201a Evaluations: Contains all evaluation metrics available for analyzing the performance of models on datasets, the evaluator function evaluator.py that leverages the metrics, and a unit test file test.py for evaluating the performance of each measure with different input types. The evaluation metrics supplied in CAPRI, as well as the evaluation process, will be discussed in detail in Sections 3.4 and 4, respectively. \u201a Outputs: CAPRI stores the final findings, including ranked lists and evaluation outputs, for reproducibility purposes. The file naming structure prohibits a previously performed analysis from being reprocessed. It should be noted that due to the size of the ranked list files, we do not save them on GitHub.  We welcome academics and developers who aim to contribute to the framework's enhancement. Consequently, documentation on how to contribute to the project is available at the readthedocs page of the frameworkfoot_1 .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Datasets", "text": "In the current version of the framework, we have provided modified versions of three popular check-ins datasets: Gowallafoot_2 , Yelpfoot_3 [8], and Foursquarefoot_4 . The characteristics of the mentioned datasets are presented in Table 1.", "publication_ref": ["b7"], "figure_ref": [], "table_ref": ["tab_0"]}, {"heading": "Models", "text": "CAPRI covers the recent implementations of various models, which can be applied to the introduced datasets for evaluation and reproducibility goals. The models implemented in this framework are listed below:\n\u201a GeoSoCa: As introduced in Zhang and Chow [27], this model covers geographical, social, and categorical correlations among users and POIs. These contexts are learned using users' historical check-in data to produce relevance scores for unseen locations. \u201a LORE: Another model utilized in CAPRI is LORE Zhang et al. [28], a popular and robust model for location recommendation focused on the impacts of geographical and social influence on users' check-in behaviors.\n\u201a USG: As introduced in Ye et al. [26], USG takes geographical influence, social network, and user interest into account for POI recommendation.\nThe current CAPRI version covers standard competitive contextual models for the POI domain, with users having the flexibility to modify contexts per their requirements. Our future plans include the incorporation of deep learning, graph-based, sequential, and sessions-based models as proposed in works like [1,9]. These models can integrate various contextual components like geographical, temporal, social, and categorical relevance scores using fusion rules such as product or sum [8,12], forming a unified preference score [10,13,16]. Contextual information, denoted by \ud835\udc50 \ud835\udc56 , can be infused using a polynomial regression model \ud835\udc5f\ud835\udc52\ud835\udc50 \ud835\udc62,\ud835\udc5d \" \u039b \u00a8C `\u039bpair \u00a8Cpair `\ud835\udf06123 \ud835\udc50 1 \ud835\udc50 2 \ud835\udc50 3 (1) where:\n\u201a \u039b \" r\ud835\udf06 1 , \ud835\udf06 2 , \ud835\udf06 3 s \u201a C \" r\ud835\udc50 1 , \ud835\udc50 2 , \ud835\udc50 3 s \u201a \u039b pair \" r\ud835\udf06 12 , \ud835\udf06 13 , \ud835\udf06 23 s \u201a C pair \" r\ud835\udc50 1 \ud835\udc50 2 , \ud835\udc50 1 \ud835\udc50 3 , \ud835\udc50 2 \ud835\udc50 3 s\nin which \ud835\udf06 \ud835\udc57 indicates the importance weight for the context \ud835\udc50 \ud835\udc56 learned by the model. Note that the product rule ( \u00c4 ) would have \ud835\udf06 \ud835\udc57 \" 0 for all \ud835\udc57 and \ud835\udf06 123 \" 1. In the case of the sum (", "publication_ref": ["b26", "b27", "b25", "b0", "b8", "b7", "b11", "b9", "b12", "b15", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "\u00c0", "text": "), \ud835\udf06 1 , \ud835\udf06 2 , and \ud835\udf06 3 are 1 and the rest are 0, while in the weighted sum (", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "\u00d0", "text": "), optimal values are assigned to them to maximize performance criteria.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Evaluation Dimensions", "text": "CAPRI is highly compatible with a range of evaluation metrics. Accordingly, the evaluation metrics available in the framework can be classified into the following categories: \u201a Accuracy: for accuracy evaluation, the framework covers Precision@k, Recall@k, mAP@k, and nDCG@k metrics, in which \ud835\udc58 represents the number of items filtered for recommendation. \u201a Beyond-Accuracy: this category contains List Diversity, Novelty, Catalog Coverage, and Personalization metrics. \u201a Fairness: it contains modules for grouping users and items according to a sensitive attribute. Thus, it includes MADr and GCE evaluation among the user/item groups [5,15,22]. It is observable that the offered metrics are tailored to meet the recommendations of POI recommendation. All the evaluation metrics can be accessed using the Evaluations directory in the framework. There is also a test.py file in the same folder for evaluating the performance of each metric through unit testing.", "publication_ref": ["b4", "b14", "b21"], "figure_ref": [], "table_ref": []}, {"heading": "Configuration", "text": "CAPRI contains a config.py file that provides adjustments and configurations for running various experiments. Accordingly, the parameters that can be set using the mentioned file are listed below: \u201a dataDirectory: the path from which the dataset files are read, \u201a outputsDir: the path to store final recommendation lists generated by the framework, \u201a topK: Top-k items for doing the evaluations (default: 10), \u201a limitUsers: limiting the number of users in the dataset (default: -1), \u201a listLimit: limiting the length of the final recommendation lists (default: 10), \u201a activeUsersPercentage: calculating a list of pre-defined groups of users known as \"active users, \" \u201a models: available models to be selected by the user, \u201a datasets: available datasets to be selected by the user, \u201a fusions: available fusions to be selected by the user, \u201a evaluationMetrics: available evaluation metrics to be selected by the user.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "EVALUATION PROCESS", "text": "This section describes how the evaluation process takes place in CAPRI. All the evaluation-related functions of the framework are collected in evaluator.py file in the Evaluations directory. Accordingly, the model and the dataset selected by the user, as well as the evaluation and model parameters, are passed to the evaluator. Model parameters contain model-specific final scores, such as geographical, social, and categorical calculations for GeoSoCa. Evaluation parameters are formed as a dictionary that contains evaluation-related feed, such as the list of users, the list of POI, and ground truth data. By iterating over users in the dataset, overall recommendation scores and requested accuracy measures such as Precision@k and Recall@k are calculated. The final results will be saved in files for later processes.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "BENCHMARKING", "text": "Table 2 shows initial and experimental results using our proposed framework, CAPRI. As one can see, using CAPRI, we are able to incorporate different contextual models of the POI recommendation domain as well as different approaches to context fusion. We can see that the fusion methods have a great impact on the performance of POI models. The sum rule could show a much better impact on the beyond-accuracy performances (i.e., coverage, novelty, and diversity) compared to the product rule. Additionally, it can be seen that the sum rule often outperforms the product operation in accuracy for the GeoSoCa model. The product operation often outperforms the sum operation in accuracy for LORE (with the exception of \ud835\udc45\ud835\udc52\ud835\udc50\ud835\udc4e\ud835\udc59\ud835\udc59 where the sum is better than the product).\nFinally, the weighted sum has a favorable effect on the GeoSoCa model, making it the most accurate model and enhancing the sum model under LORE. As a work where CAPRI has been employed for POI recommendation, further evaluation of the results for user/item fairness can be found in [14].", "publication_ref": ["b13"], "figure_ref": [], "table_ref": ["tab_1"]}, {"heading": "DISCUSSION AND CONCLUSION", "text": "The open-source framework, CAPRI, developed for POI recommendation systems, distinguishes itself by leveraging contextual information in the suggestion pipeline. It incorporates robust models, datasets, and evaluation metrics to provide proper location suggestions matching the context. Like any software, constant development is necessary for CAPRI to accommodate user needs. We plan on widening its coverage of datasets and models, incorporating more evaluation metrics, and investigating parallelization and requests queuing to improve performance. Future iterations will support batch request handling with user-defined parameters and offer a GUI for easier configuration. We aim to make it directly installable via Python's pip, and integrate bias mitigation approaches to reduce system biases. The framework is publicly available on GitHub for researchers.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Session-Based Hotel Recommendations Dataset: As Part of the ACM Recommender System Challenge 2019", "journal": "ACM Trans. Intell. Syst. Technol", "year": "2020-11", "authors": "Jens Adamczak; Yashar Deldjoo; Farshad Bakhshandegan Moghaddam; Peter Knees; Gerard-Paul Leyson; Philipp Monreal"}, {"ref_id": "b1", "title": "Elliot: A Comprehensive and Rigorous Framework for Reproducible Recommender Systems Evaluation", "journal": "Association for Computing Machinery", "year": "2021", "authors": "Vito Walter Anelli; Alejandro Bellogin; Antonio Ferrara; Daniele Malitesta; Felice Antonio Merra; Claudio Pomo; Francesco Maria Donini; Tommaso Di; Noia "}, {"ref_id": "b2", "title": "Lessons from the netflix prize challenge", "journal": "Acm Sigkdd Explorations Newsletter", "year": "2007", "authors": "M Robert; Yehuda Bell;  Koren"}, {"ref_id": "b3", "title": "Case Recommender: A Flexible and Extensible Python Framework for Recommender Systems", "journal": "Association for Computing Machinery", "year": "2018", "authors": "Arthur Da; Costa ; Eduardo Fressato; Fernando Neto; Marcelo Manzato; Ricardo Campello"}, {"ref_id": "b4", "title": "A flexible framework for evaluating user and item fairness in recommender systems", "journal": "User Modeling and User-Adapted Interaction", "year": "2021", "authors": "Yashar Deldjoo; Vito Walter Anelli; Hamed Zamani; Alejandro Bellogin; Tommaso Di; Noia "}, {"ref_id": "b5", "title": "Rethinking the Recommender Research Ecosystem: Reproducibility, Openness, and LensKit", "journal": "Association for Computing Machinery", "year": "2011", "authors": "D Michael; Michael Ekstrand; Joseph A Ludwig; John T Konstan;  Riedl"}, {"ref_id": "b6", "title": "Librec: A java library for recommender systems", "journal": "Citeseer", "year": "2015", "authors": "Guibing Guo; Jie Zhang; Zhu Sun; Neil Yorke-Smith"}, {"ref_id": "b7", "title": "An Experimental Evaluation of Point-of-Interest Recommendation in Location-based Social Networks", "journal": "", "year": "2017", "authors": "Yiding Liu; Tuan-Anh Nguyen Pham; Gao Cong; Quan Yuan"}, {"ref_id": "b8", "title": "Personalizing Session-Based Recommendations with Hierarchical Recurrent Neural Networks", "journal": "Association for Computing Machinery", "year": "2017", "authors": "Massimo Quadrana; Alexandros Karatzoglou; Bal\u00e1zs Hidasi; Paolo Cremonesi"}, {"ref_id": "b9", "title": "LGLMF: local geographical based logistic matrix factorization model for POI recommendation", "journal": "Springer", "year": "2019", "authors": "A Hossein; Mohammad Rahmani; Sajad Aliannejadi; Mitra Ahmadian; Mohsen Baratchi; Fabio Afsharchi;  Crestani"}, {"ref_id": "b10", "title": "Joint geographical and temporal modeling based on matrix factorization for point-of-interest recommendation", "journal": "Springer", "year": "2020", "authors": "A Hossein; Mohammad Rahmani; Mitra Aliannejadi; Fabio Baratchi;  Crestani"}, {"ref_id": "b11", "title": "A Systematic Analysis on the Impact of Contextual Information on Pointof-Interest Recommendation", "journal": "ACM Trans. Inf. Syst", "year": "2022-03", "authors": "A Hossein; Mohammad Rahmani; Mitra Aliannejadi; Fabio Baratchi;  Crestani"}, {"ref_id": "b12", "title": "Category-Aware Location Embedding for Point-of-Interest Recommendation", "journal": "Association for Computing Machinery", "year": "2019", "authors": "A Hossein; Mohammad Rahmani;  Aliannejadi; Mirzaei Rasoul; Mitra Zadeh; Mohsen Baratchi; Fabio Afsharchi;  Crestani"}, {"ref_id": "b13", "title": "The Role of Context Fusion on Accuracy, Beyond-Accuracy, and Fairness of Point-of-Interest Recommendation Systems", "journal": "Expert Systems with Application", "year": "2022", "authors": "A Hossein; Yashar Rahmani; Tommaso Deldjoo; Noia Di"}, {"ref_id": "b14", "title": "The unfairness of active users and popularity bias in point-of-interest recommendation", "journal": "Springer", "year": "2022-04-10", "authors": "A Hossein; Yashar Rahmani; Ali Deldjoo; Mohammadmehdi Tourani;  Naghiaei"}, {"ref_id": "b15", "title": "Exploring the Impact of Temporal Bias in Point-of-Interest Recommendation", "journal": "Association for Computing Machinery", "year": "2022", "authors": "A Hossein; Mohammadmehdi Rahmani; Ali Naghiaei; Yashar Tourani;  Deldjoo"}, {"ref_id": "b16", "title": "Cornac: A Comparative Framework for Multimodal Recommender Systems", "journal": "J. Mach. Learn. Res", "year": "2020", "authors": "Aghiles Salah; Quoc-Tuan Truong; Hady W Lauw"}, {"ref_id": "b17", "title": "Point-of-Interest Recommender Systems Based on Location-Based Social Networks: A Survey from an Experimental Perspective", "journal": "ACM Comput. Surv", "year": "2022-09", "authors": "Pablo S\u00e1nchez; Alejandro Bellog\u00edn"}, {"ref_id": "b18", "title": "Fairness-Aware Recommendation with Librec-Auto", "journal": "Association for Computing Machinery", "year": "2020", "authors": "Nasim Sonboli; Robin Burke; Zijun Liu; Masoud Mansoury"}, {"ref_id": "b19", "title": "Librec-Auto: A Tool for Recommender Systems Experimentation", "journal": "Association for Computing Machinery", "year": "2021", "authors": "Nasim Sonboli; Masoud Mansoury; Ziyue Guo; Shreyas Kadekodi; Weiwen Liu; Zijun Liu; Andrew Schwartz; Robin Burke"}, {"ref_id": "b20", "title": "Are We Evaluating Rigorously? Benchmarking Recommendation for Reproducible Evaluation and Fair Comparison", "journal": "Association for Computing Machinery", "year": "2020", "authors": "Zhu Sun; Di Yu; Hui Fang; Jie Yang; Xinghua Qu; Jie Zhang; Cong Geng"}, {"ref_id": "b21", "title": "A Survey on the Fairness of Recommender Systems", "journal": "ACM Trans. Inf. Syst", "year": "2023-02", "authors": "Yifan Wang; Weizhi Ma; Min Zhang; Yiqun Liu; Shaoping Ma"}, {"ref_id": "b22", "title": "A systematic mapping on POI recommendation: Directions, contributions and limitations of recent studies", "journal": "Information Systems", "year": "2021", "authors": "Heitor Werneck; N\u00edcollas Silva; Matheus Carvalho; C M Adriano; Fernando Pereira; Leonardo Mour\u00e3o;  Rocha"}, {"ref_id": "b23", "title": "A reproducible POI recommendation framework: Works mapping and benchmark evaluation", "journal": "Information Systems", "year": "2022", "authors": "Heitor Werneck; N\u00edcollas Silva; Adriano Pereira; Matheus Carvalho; Alejandro Bellog\u00edn; Jorge Martinez-Gil; Fernando Mour\u00e3o; Leonardo Rocha"}, {"ref_id": "b24", "title": "OpenRec: A Modular Framework for Extensible and Adaptable Recommendation Algorithms", "journal": "Association for Computing Machinery", "year": "2018", "authors": "Longqi Yang; Eugene Bagdasaryan; Joshua Gruenstein; Cheng-Kang Hsieh; Deborah Estrin"}, {"ref_id": "b25", "title": "Exploiting Geographical Influence for Collaborative Point-of-Interest Recommendation", "journal": "Association for Computing Machinery", "year": "2011", "authors": "Mao Ye; Peifeng Yin; Wang-Chien Lee; Dik-Lun Lee"}, {"ref_id": "b26", "title": "GeoSoCa: Exploiting Geographical, Social and Categorical Correlations for Point-of-Interest Recommendations", "journal": "Association for Computing Machinery", "year": "2015", "authors": "Jia-Dong Zhang; Chi-Yin Chow"}, {"ref_id": "b27", "title": "LORE: Exploiting Sequential Influence for Location Recommendations", "journal": "Association for Computing Machinery", "year": "2014", "authors": "Jia-Dong Zhang; Chi-Yin Chow; Yanhua Li"}, {"ref_id": "b28", "title": "DeepRec: A deep neural network approach to recommendation with item embedding and weighted loss function", "journal": "Information sciences", "year": "2019", "authors": "Wen Zhang; Yuhang Du; Taketoshi Yoshida; Ye Yang"}, {"ref_id": "b29", "title": "Recbole: Towards a unified, comprehensive and efficient framework for recommendation algorithms", "journal": "Association for Computing Machinery", "year": "2021", "authors": "Shanlei Wayne Xin Zhao; Yupeng Mu; Zihan Hou; Yushuo Lin; Xingyu Chen; Kaiyuan Pan; Yujie Li; Hui Lu; Changxin Wang;  Tian"}, {"ref_id": "b30", "title": "RecBole: Towards a Unified, Comprehensive and Efficient Framework for Recommendation Algorithms", "journal": "Association for Computing Machinery", "year": "2021", "authors": "Shanlei Wayne Xin Zhao; Yupeng Mu; Zihan Hou; Yushuo Lin; Xingyu Chen; Kaiyuan Pan; Yujie Li; Hui Lu; Changxin Wang; Yingqian Tian; Zhichao Min; Xinyan Feng; Xu Fan; Pengfei Chen; Wendi Wang; Yaliang Ji; Xiaoling Li; Ji-Rong Wang;  Wen"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: General workflow of the experiments handled by CAPRI.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Characteristics of the datasets available in CAPRI.", "figure_data": "Yelp7,135 15,575299,32746,778582Gowalla5,628 30,943618,62146,001Foursquare7,642 28,483512,532\u00b4\u0154egarding"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Accuracy and beyond-accuracy performance of models and baselines evaluated on top-20 recommendation lists on the Yelp dataset. In context, g, t, s, and c show the geographical, temporal, social, and categorical contexts, respectively. (Bold the best metric values).", "figure_data": "ModelContextFusionAccuracyBeyond-accuracyFairnessg tsc\ud835\udc5b\ud835\udc37\ud835\udc36\ud835\udc3a \ud835\udc43\ud835\udc5f\ud835\udc52\ud835\udc50\ud835\udc56\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5b \ud835\udc45\ud835\udc52\ud835\udc50\ud835\udc4e\ud835\udc59\ud835\udc59\ud835\udc36\ud835\udc5c\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc54\ud835\udc52 \ud835\udc41\ud835\udc5c\ud835\udc63\ud835\udc52\ud835\udc59\ud835\udc61\ud835\udc66 \ud835\udc37\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc60\ud835\udc56\ud835\udc61\ud835\udc66\ud835\udc40\ud835\udc34\ud835\udc37\ud835\udc5fMostPop -----0.0073 0.00640.01850.124.95900.69380.0152MF-----0.0078 0.00700.01810.34.97360.68770.0219\u00c40.0169 0.01340.034149.47.90830.68770.0443GeoSoCa \u2713 \u02c6\u2713 \u2713\u00c00.0160 0.01380.04073.268.50470.71660.0525\u00d00.0170 0.01450.041969.758.33110.68350.04650.0174 0.01390.033539.147.73140.75090.0530LORE\u2713 \u2713 \u2713\u02c6\u00c4 \u00c00.0155 0.01340.038874.978.47230.80650.0404\u00d00.0169 0.01430.041274.518.16770.79710.0404"}], "formulas": [{"formula_id": "formula_0", "formula_text": "\u201a \u039b \" r\ud835\udf06 1 , \ud835\udf06 2 , \ud835\udf06 3 s \u201a C \" r\ud835\udc50 1 , \ud835\udc50 2 , \ud835\udc50 3 s \u201a \u039b pair \" r\ud835\udf06 12 , \ud835\udf06 13 , \ud835\udf06 23 s \u201a C pair \" r\ud835\udc50 1 \ud835\udc50 2 , \ud835\udc50 1 \ud835\udc50 3 , \ud835\udc50 2 \ud835\udc50 3 s", "formula_coordinates": [3.0, 333.77, 458.83, 96.65, 42.07]}], "doi": "10.1145/3412379"}
