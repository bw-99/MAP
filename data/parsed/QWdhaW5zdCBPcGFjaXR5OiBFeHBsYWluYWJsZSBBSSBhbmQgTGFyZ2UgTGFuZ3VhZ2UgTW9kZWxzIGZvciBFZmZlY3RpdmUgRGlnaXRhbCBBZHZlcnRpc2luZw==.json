{"Against Opacity: Explainable AI and Large Language Models for Effective Digital Advertising": "Qi Yang yangqi@itmo.ru ITMO University Saint Petersburg, Russia Marlo Ongpin marlo@somin.ai SoMin.ai Research Singapore, Singapore Sergey Nikolenko sergey@logic.pdmi.ras.ru ITMO University Steklov Institute of Mathematics Saint Petersburg, Russia Alfred Huang alfred@somin.ai SoMin.ai Research Singapore, Singapore Aleksandr Farseev sasha@somin.ai SoMin.ai Research Singapore, Singapore Ads Target audience analysis LLM Text-image singte cistomers tech Persona analysis LLM budget - fam customer Need and insight analysis Sample user persona tech-savvy entertainment and excitement Topic With oved ones Human need celebraentertainment and connectivity Aisha Teward recognition Insight Audience entertainment FASHIONABLE MUSLIMAH MoTHER peace instant bondig", "ABSTRACT": "The opaqueness of modern digital advertising, exemplified by platforms such as Meta Ads , raises concerns regarding their autonomous control over audience targeting, pricing structures, and ad relevancy assessments. Locked in their leading positions by network effects, 'Metas and Googles of the world' attract countless advertisers who rely on intuition, with billions of dollars lost on ineffective social media ads. The platforms' algorithms use huge amounts of data unavailable to advertisers, and the algorithms themselves are opaque as well. This lack of transparency hinders the advertisers' ability to make informed decisions and necessitates efforts to promote transparency, standardize industry metrics, and strengthen regulatory frameworks. In this work, we propose novel ways to assist marketers in optimizing their advertising strategies via machine learning techniques designed to analyze and evaluate content, in particular, predict the click-through rates (CTR) of novel advertising content. Another important problem is that large volumes of data available in the competitive landscape, e.g., competitors' ads, Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \u00a9 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0108-5/23/10...$15.00 https://doi.org/10.1145/3581783.3612817 impede the ability of marketers to derive meaningful insights. This leads to a pressing need for a novel approach that would allow us to summarize and comprehend complex data. Inspired by the success of ChatGPT in bridging the gap between large language models (LLMs) and a broader non-technical audience, we propose a novel system that facilitates marketers in data interpretation, called SODA, that merges LLMs with explainable AI, enabling better human-AI collaboration with an emphasis on the domain of digital marketing and advertising. By combining LLMs and explainability features, in particular modern text-image models, we aim to improve the synergy between human marketers and AI systems.", "CCS CONCEPTS": "\u00b7 Information systems \u2192 Learning to rank ; Multimedia and multimodal retrieval ; Computational advertising ; Multimedia and multimodal retrieval ; Computational advertising .", "KEYWORDS": "Digital Advertising, Ads Performance Prediction, Deep Learning, Large Language Model, Explainable AI", "ACMReference Format:": "Qi Yang, Marlo Ongpin, Sergey Nikolenko, Alfred Huang, and Aleksandr Farseev. 2023. Against Opacity: Explainable AI and Large Language Models for Effective Digital Advertising. In Proceedings of the 31st ACM International Conference on Multimedia (MM '23), October 29-November 3, 2023, Ottawa, ON, Canada. ACM, New York, NY, USA, 7 pages. https://doi.org/10.1145/ 3581783.3612817", "1 INTRODUCTION": "The online advertising industry is the poster child of data science. Google and Facebook became industry-dominating behemoths to a large extent because they excelled at crunching the numbers and showing the best online ads to their primary assets, user audiences, while Amazon did the same for item recommendations in its online store. In academia, the Netflix Prize Competition [2] devoted to movie recommendations was one of the first open competitions with serious prizes and organization, a pioneer that would eventually lead to Kaggle and innumerable open leaderboards that nowadays track the state of the art in virtually every measurable MLtask. The Netflix Prize itself has led to significant breakthroughs in collaborative filtering, and its dataset is still used as one of the standard benchmarks [2]. One definitely cannot say that the field of recommender systems, in particular online advertising, lacks the attention of machine learning researchers, and many important advances keep being made every month [6, 11, 18, 29, 33, 36-38]. However, most advances are being made on the side of the platforms (ad marketplaces) such as Facebook ( Meta ) [19], Google [23], Alibaba [28], or Taobao [17], and therefore they are not accessible to the advertising platform users, i.e., digital marketers. Collaborative filtering datasets are understandably private, and marketing professionals that create advertising content do not have access to the data needed to predict their own future performance. Note that these predictions are often self-fulfilling: if, e.g., Meta models predict low click-through ratio (CTR) for your ad, Meta will charge you more for showing it, probably show it less, and the campaign will likely be a failure regardless of how accurate the CTR prediction has been [1]. Often, there is no practical way to control the cost of advertising; technically, if a platform decided to charge more money for an ad nothing could prevent them from doing so. Moreover, even if marketing professionals could run the corresponding models, that would only be of modest help with their job, which is content creation . Suppose that a model tells you that your new ad is a bad match for your audience, and the expected CTR is low. How do you fix that? It cannot be a pure collaborative filtering model since it has to predict CTR for a new ad that has not been shown to users yet, but it is still an opaque model that maps your ad content into a latent representation via 'giant inscrutable matrices'. So all you can do even if you have such a model is to try and make a different ad, get a new prediction, and work via trial and error. One potential way to address this issue involves visualizing the decision-making process of a neural network, providing marketers with insights into the rationale behind specific predictions made by AI models [3, 15, 20, 39]. Therefore, our first contribution in this work is a new variation of a state-of-the-art CTR prediction model coupled with a mechanism for analyzing the ad images (banners) via an image attention mechanism. The results provide humanunderstandable analysis that can be turned into actionable insights. However, this is only the beginning. Individual ad analysis via explainable ML models has proven beneficial in scenarios such as individual content evaluation prior to starting an advertising campaign, but it is much less practical when applied to large volumes of images and text ads in real-world settings. The time constraints faced by marketers impede their ability to effectively process and extract key content traits in their own advertising practices. In our opinion, the long-awaited revolution in digital advertising and content marketing will occur when both the ads themselves and the results of opaque models can be explained in ways that are both understandable for humans and actionable in terms of business results. We believe that the time for this revolution is now, and in this work we show that large language models such as GPT-3.5 [27] and GPT-4 [26] are already increasingly able to explain the 'reasoning' behind recommender models and provide aggregate insights about advertising campaigns consisting of hundreds of individual ads. Prior to LLMs, approaches to aggregate text corpora in the context of recommender systems had been proposed via topic modeling [22, 25], sometimes coupled with deep learning [35] and user profiling [5, 34], but topic modeling is based on the bag-of-words assumption and cannot summarize text as an LLM does; visual understanding of ads had also been explored with convolutional networks [32]. Therefore, our main contribution is that we present preliminary results for a road-map that could achieve this holy grail of content marketing: provide explainable , actionable insights into advertising content along with possible strategies for improvement with models that could work on the side of a small advertising agency rather than a huge platform. We begin with direct CTR prediction and then proceed to provide explainable insights and content recommendations with large language models and even visual generative AI (see Fig. 1). The paper is organized as follows: in Section 2, we present an improved model for CTR prediction and visualization procedures for advertising banners, Section 3 introduces our approach to explainable ad analysis with large language models, Section 4 shows the results of a case study that confirms the effectiveness of our approach, and Section 5 concludes the paper.", "2 EXPLAINING OPAQUE AI WITH AI: CTR PREDICTION AND VISUALIZATIONS": "The lack of transparency within the advertising sector has been widely acknowledged as a primary reason for the inefficient allocation of advertising budgets. Notably, the responsibility for determining the cost per 1,000 impressions (CPM) and selecting competing entities in a programmatic auction rests primarily with the platform (we will use Meta as the running example). This decision-making process is in fact a result of numerous intricately interwoven machine learning (ML) models designed to dynamically match content with precise targeting criteria and individualized user profiles on Meta . These models are instrumental in estimating the likelihood of a user engaging in specific actions within the Meta ecosystem. As an illustration, consider a hypothetical Meta user named Simonwhoisanticipated to click on an ad (perform the 'Click' action) with the slogan 'Up your game nights with an ultra-immersive setup' displayed on a Meta Ad banner showcasing Singtel , a mobile operator company, and their home internet broadband product (Fig. 2). This prediction is done by Meta 's internal ML models, and quite often contradicts Meta 's widely publicized 'best practices' blueprints [24]. Here, it is crucial to acknowledge the additional information that advertising engines such as Meta take into account. They are free to use factors such as Simon's past visits to telecom websites, pictures showing computer games in Simon's account Up your game nights with an ultra-immersive set-up. Continuous features Categorical features Text (creative) Images (creative) Tabular preprocessor Tokenizer Image preprocessor TabTransformer BERT ViT FC layer FC layer FC layer Concatenation FC layer Softmax on Meta , and much more. Moreover, these factors include Meta 's own revenue considerations, prediction of the ad's 'relevance' by Meta itself, timing of displaying this ad during the day, recency of the ad account (to incentivize new advertisers with improved performance), and the internal 'ranking' of advertisers based on their history of disapproved ads, a process overseen by Meta . Regrettably, these predictive estimations are further influenced by the accuracy of Meta 's ML models that profile Simon's content. For instance, when Simon is observed putting a diaper on his child, Meta 's object recognition system might mistakenly associate it with an 'Inflatable Boat / Fishing' interest; this is a real-life incident on the Meta platform, and such mistakes compound into suboptimal ad-related predictions down the line. Confronted with numerous intricate technical hurdles, digital marketers, who frequently lack technical expertise, often resort to intuitive judgment or a trial-and-error methodology in formulating and examining their creative assets within digital advertising platforms. Thus, it becomes especially important to have comprehensive data-driven guidance, not only for optimizing outcomes but also for developing cost-effective practices. One classical approach to providing this kind of guidance is to train an ML framework to predict the prospective performance of an advertising banner before allocating actual advertising budgets. In this section, we focus on the prediction of the click-through rate (CTR) metric, known to be closely associated with ad performance, particularly in the context of awareness and traffic advertising objectives. We used the recently presented SoWide model [20] as a sample state-of-the-art CTR prediction approach; its architecture is shown in Fig. 3. We updated the architecture slightly by replacing the ABN model for image processing with a Vision Transformer (ViT) [10], resulting in performance improvements, so we call it SoWide-v2 . Unlike conventional supervised learning, where a data point ( x , \ud835\udc66 ) consists of both feature vector x and target variable \ud835\udc66 , the SoWide-v2 approach incorporates data from the campaign, ad set, and potentially multiple creatives to construct the features for each ad. Data points in the model leverage text and images from all creatives together with their respective estimated performances; in case of videos, we extract keyframes to obtain multiple distinct images included as additional training data. Furthermore, we extract low-level features from tabular, textual, and visual content, resulting in a comprehensive dataset that can be used to train a model capable of predicting content performance based on information from multiple modalities. After preprocessing, extracted features serve as inputs for the click-through rate (CTR) prediction model. SoWidev2 makes the assumption that the performance of advertisements converges to an underlying global distribution [8, 13, 30], so we normalize CTR values into categorical representations. Predicted scores indicate whether the content can be classified as 'below average', 'average', or 'above average' in terms of quality. In essence, SoWide-v2 is a neural network based on the 'wide and deep models' approach well known in recommender systems [7]. To facilitate representation learning for multimodal content, SoWidev2 employs separate embedding layers and fully connected layers for each set of features. This process allows it to project sparse, high-dimensional, and low-level features into higher-level representations. To handle each modality appropriately, SoWide-v2 employs distinct deep models for feature processing. Specifically, it uses the TabTransformer [21] for tabular features and multilingual BERT [9] for textual content; the original SoWide used the attention branch network [16] for images but for SoWide-v2 we replaced it with a Vision Transformer [10]. Additionally, a fully connected layer is utilized to project the sparse high-dimensional features into a denser low-dimensional representation. These representations are subsequently concatenated and fed into another fully connected layer, followed by a softmax function for CTR classification, facilitating end-to-end joint learning. The model is trained using stochastic gradient descent (SGD) for 100 epochs, and hyper-parameter optimization is performed with the tree-structured Parzen estimator [4]. For evaluation results, we use the same datasets and baselines as the original SoWide paper [20], comparing the performance of SoWide-v2 against the original SoWide and several conventional machine learning baselines (there appears to be no previous work on CTR prediction before [20] that could be used for a direct comparison) using the F1-score, a widely used classification metric. Evaluation is done in two different settings: for general ad campaigns and also specifically for campaigns targeting the 'Conversion' objective, which represents the two most prevalent and significant ad campaign objectives. The results shown in Table 1 demonstrate that the SoWide-v2 model presents an improvement over the original SoWide , and both models significantly outperform all classical ML baselines. Notably, the F1-score for the general ad campaigns reaches 0 . 78, Content Analysis Average Predicted Score Low Colors Languages used: N? of Ads:   16 English; French N? of Creatives:   25 CEE 702 5OGB for $10 5OGB for $10 Up your game nights Up your game nights FOREVER. FOREVER with an ultra-immersive with an ultra-immersive Your move Your move set-up_ which confirms that the SoWide-v2 approach effectively accommodates the hierarchical structure inherent in advertising data, enabling effective multimodal learning for the prediction of ad performance. The results validate that SoWide-v2 is a state-of-the-art CTR prediction model. banner (on the right), the areas featuring the lady in the background were found to negatively impact its performance. This suggests that the composition and balance of the banner's visual elements, particularly in relation to the overall content creation practices, may have influenced its predicted low CTR values. Thus far, we have introduced a framework that enables advertisers to assess the potential performance of their own content, and potentially that of their competitors, prior to its launch. This represents a valuable tactical capability that had been unavailable to the community for a long time. However, once a creative marketer gains access to the initial prediction results for a specific content piece, another significant challenge lies in comprehending the underlying factors that contribute to its success or failure. What went wrong, what was done right, and how do we amplify the right parts while suppressing the wrong parts? One approach to address this question would be to utilize various visualization techniques, specifically those that illustrate the decision-making process of the neural network while making a specific prediction. If the prediction is accurate, such visualizations are believed to provide insights into the underlying reasons behind the performance of a creative asset. Consequently, these visualizations can serve as a valuable resource for marketers in making informed decisions regarding the inclusion of specific components in future creative assets, enabling them to effectively communicate their requirements to the creative team. Figure 4 shows an illustrative example of such visualizations. The attention layers of the neural network used for CTR prediction are visualized as interactive heatmaps, revealing the specific regions of the banner that significantly influence the model's predictions. The figure shows that such attention visualization highlights the key elements within a Singtel banner (on the left) that contribute to its high predicted performance, namely gaming-related objects such as the monitor and the game controller. These elements effectively convey the message that a superior internet connection is essential for enhancing the gaming experience. Similarly, for the Circles.Life", "3 EXPLAINING HUMANS FOR HUMANS: SODA, A LLM-BASED ADVERTISING ANALYSIS FRAMEWORK": "In the last section, we presented a system capable of effectively capturing and visualizing the factors influencing the predicted performance of ads in terms of potential CTR. However, in domains such as performance marketing decisions for choosing specific creatives for campaigns often need to be made under tight deadlines, sometimes literally in a few hours or even minutes. Moreover, these industries are characterized by large volumes of creative assets and a multitude of promotions simultaneously conducted by competitors in an 'always-on' manner. Therefore, one cannot run detailed analysis for every ad, and there is a dire need for further automated analytical tools that would enable human marketers to rapidly comprehend available data and information. In order to address this challenge, we present an extension to our framework with a novel approach that leverages large language models (LLMs) to provide additional insights into the data and CTR predictions, called SODA . We outline an analytical pipeline that incorporates LLM-based explanations and generations and demonstrate its practical applications through a real-world scenario involving four Singapore telecommunication companies. This part of our framework aims to enhance the interpretability and comprehension of the data, facilitating better-informed decision-making in these fast-paced and competitive industries. The general pipeline of our analysis is shown in Figure 5. First, we use an LLM to extract specific well-defined insights from input ads, such as the needs served by this ad, products being advertised, and more (see below); the insights can be stored as features in", "Ads from a brand campaign": "", "LLM with prompt engineering": "", "Target audience analysis": "singtel cus tomers tech enthusiasts gamers families customers ends techesavvy", "Persona analysis": "", "Need and insight analysis": "entertainment and excitement with loved ones celebraentertainment and connectivity reward and recognition enterta ainment peace bonding instant ant grarification", "Figure 5: General pipeline of our LLM-based analysis": "", "Interests": "Large language model with prompt engineering Beauty; Nephew and niece; Eyebrow; Veil, Kaftan, Parenting, Makeup Tutorials Twin; Headscarf; Offspring; Infant, Fashion accessories, Mother's Day; Children's clothing; Tudung Muslimah; Marriage, Hair products, Clothing Make-Up Studio_ Women's clothing, Men's clothing; Family and relationships Makeup brush, Aqeela Muslimah WEAR or Blueberry Diapers", "Detailed analysis in tabular form": "topic: Streaming Grey's Anatomy on DisneyPlusSG with Starhub TV+ content types: 'Product Offering' 'Topical', 'Value Added Services' category: 'TV shows' 'Entertainment' tone: 'Friendly' 'Wholesome' brand traits: 'Empathy' 'Kindness' , 'Authenticity' archetypes: 'The Caregiver' 'The Innocent' human need: Connection with loved ones main product: DisneyPlusSG with Starhub TV+ human insight: People want to feel close to their loved ones; especially during difficult times target audiences: \"Fans of Grey's Anatomy\" , 'People looking for entertainment options\"", "Figure 6: Sample ad analysis": "Singtel's top 3 most used personas are the caregiver; the explorer; and the jester. This suggests that Singtel values empathy innovation and humor in its brand personality. By embodying these personas, Singtel aims to connect with its customers on personal level, while also demonstrating its commitment to staying ahead of the curve and providing cutting-edge solutions. Overall, Singtel's use of these personas helps to establish a strong and relatable brand identity that resonates with its target audience_", "Example phrases:": "Singtel the magitian the innocent the outlaw Hop on Singtel ReadyRoam with TU time (2X) roaming data, to connected with everyone throughout your trip! stay Find yourself in safe hands with Singtel Car Protect! Looking to catch a breather during this festive season? Get your quick coffee fix with Singtel Prepaid! Singtel embodies the caregiver persona by offering services and products that provide peace of mind and convenience to their customers_ They prioritize the well-being and safety of their customers by offering services like Singtel Car Protect and ReadyRoam with TU time (2X) roaming data. By embodying the caregiver persona, Singtel is able to establish a strong brand image that prioritizes the well-being and safety of their customers. This helps to build trust and loyalty among their customers_ who are more likely to choose Singtel over competitors who do not prioritize these values", "Figure 7: Sample brand persona analysis results": "cloud gaming samsung galax 2gbps fibre iphone pro Max sports+ sportsplus sansung\"galaxy disneyplussg laxy golaxy singtel 14 iphone samsung device troren circles.life circles life phone plans roaming service circles life", "\"Brand Battles: Unique Promotions of M1, Singtel, StarHub, and Circles Life\"": "", "Similarities": "All brands promoted variety of products during the period from 2023-01-01 to 2023-01-30 All brands promoted Samsung and iPhone devices All brands promoted their own brand name and core product offerings", "Differences": "Singtel positioned itself as provider of cutting-edge technology and premium M1 placed strong emphasis on the Samsung Galaxy; while Singtel and StarHub promoted a wider range of products content; while StarHub focused on sports and entertainment. Circles Life had smaller number of promotions compared to the other brands", "Figure 8: Sample brand comparative analysis results": "", "Aisha": "LLM \"As muslimah mothers; we need to balance our faith; family; and fashion.", "DESCAIPTION": "Aisha is stylish and fashion-fonwvard muslimah mother who loves to express herselt through her clothing and make-up She passionate about her faith; family; and empowering other muslimah women to embrace their own unique style. Prompt for a model text-image Text-image model Fashion accessories \"Hair products Make-up tutorials , Children' clothing \"Family and relationships", "Figure 9: Sample user persona generation results.": "tabular form. Then, we use these features together with further engineered prompts to perform generalizing analysis of a brand's target audiences, personas, needs, and insights expressed by the ads, tone, and topical categories of the current campaign and others. The resulting coverage of the campaign closely reflects campaign analysis commonly performed by marketing professionals and can be further used to tune the brand's message, tone, target audiences, personas, and more. The pipeline is also able to present specific examples helpful for marketing professionals, such as sample (imagined) user profiles or user personas, which are also one of the common marketing tools. Let us dive into some details. Figure 6 shows sample results of our initial experiments on ad analysis. We selected batches of ads from the Facebook Ad Library for the same brand and processed them with an LLM, customized only with natural language prompt engineering. As a result, the LLM has been able to successfully identify key features of each", "Input ad": "Be sure to hold your person close today AII seasons of #GreysAnatomy are now streaming on #DisneyPlusSG. Sign up for @DisneyPlusSG with Starhub TV+: LLM with prompt engi- neering advertisement, including excellent responses to such seemingly 'human' questions as identifying the human need, human insight, and the main archetypes used in an ad. Moreover, answers to most questions are standardized (as the LLM was instructed) and can be subject to automated processing. This kind of analysis has always been a key part of online marketing, and to the best of our knowledge, it has never been successfully automated and scaled up before. Such tasks had always required human labeling and thus had been restricted to a few sample ads rather than the entire dataset. As the next step, we use the ads and extracted features as inputs for a number of prompts asking to summarize information in a variety of formats commonly used in content marketing. We have seen successful summarization across the board, with important insights identified by the LLM and presented in an accessible and actionable format. Fig. 7 shows a sample result of our brand persona analysis, complete with main brand values used in the ad campaigns, the goals of using them, and detailed analysis of the primary 'caregiver' persona, including supporting examples from the data. Figure 8 shows the results of a comparative analysis of four advertising campaigns run over the same time period by different brands. Again, the LLM has correctly identified its key distinguishing factors, and the list of differences is very similar to one that could be produced by a human marketing professional. Another avenue for using state-of-the-art generative AI capabilities that we have explored is user persona generation, an important tool in content marketing that has long proven to be useful for creative work[12, 14, 40]. To produce user personas, we begin with a list of interests (either extracted as shown in Fig. 9 or obtained from the client and/or social media platform) and prompt the LLM to give examples of user descriptions that could fit such interests. Fig. 7 shows a sample resulting user persona, which is fully believable to the professionals. To make the result even more tangible, we supplement such user personas with images generated by a state-of-the-art text-image model, in this case, Stable Diffusion [31]. To make the entire pipeline self-contained we ask the original LLM to also generate the prompt for the text-image model from the user persona description and a few examples of good prompts. The results also illustrated in Fig. 7, are very promising. The LLM used in all experiments was ChatGPT based on GPT3.5 [27], and we believe that simply switching to more powerful LLMs such as GPT-4 [26] may lead to further increased performance across all applications. Note also that while GPT-3.5 can only process text ads, GPT-4 is already able to analyze images jointly with text (this ability has not yet been made public at the time of writing), which is arguably even more important for content marketing.", "4 CASE STUDY": "To evaluate the practical value and viability of the proposed framework expansion using large language models (LLMs) for generating rapid insights and enabling prompt marketing-related decisionmaking, we have engaged 12 marketing professionals currently employed at marketing departments of Business-to-Consumer (B2C) brands or advertising and marketing agencies across Singapore, China, and the UK. These professionals were selected based on their extensive experience, averaging 9 years, in managing digital marketing campaigns across various industries. The professionals were presented with the details and results of our preliminary experiments analyzing and comparing the marketing campaigns of four major telecommunication companies in Singapore, as described in Section 3. They were then asked to provide their perspectives on the usefulness, quality, and potential impact of the insights and outputs generated by our framework. All 12 professionals responded very positively about the value of our approach. They found high-level overviews of brand positioning and audience targeting strategies, enriched with specific examples, to be highly useful to gain quick familiarity with brand messaging and inspire new creative directions. The generated user personas and accompanying AI-generated images were praised for bringing additional richness and tangibility to the insights. Several professionals commented that the coherent, standardized format of the outputs would allow for efficient processing and decision-making, especially given the tight timeframes frequently faced in the industry. More senior professionals have expressed that they foresee solutions like ours significantly augmenting and accelerating essential marketing functions through the automation of repetitive, labor-intensive tasks. This highly encouraging feedback from advertising and marketing professionals suggests strong potential business value in developing and applying AI-powered solutions, such as the proposed extension of our framework, for the automation of marketing campaign analysis and strategic planning. While adoption may face initial resistance, especially from very senior professionals, many in the industry seem poised to welcome AI augmenting and enhancing their work. Our approach, focused on mimicking established human processes and outputs, appears well-suited to addressing common pain points and unlocking new efficiencies, especially in such fast-paced domains as performance marketing.", "5 CONCLUSION": "In this work, we have presented a novel advertising analysis framework, called SODA , which amalgamates large language models, explainable artificial intelligence, and attention map visualization techniques, heralding a potential future of human-AI collaboration within the realm of digital advertising. Through the integration of LLMs and the incorporation of explainability aspects, our novel approach envisions enhanced efficiency and synergy between marketers and AI systems, hopefully leading to a new era of intelligent decision-making. We believe that our approach holds the promise of empowering a new generation of marketers to leverage advanced AI technologies effectively, fostering a deeper understanding of the underlying mechanisms driving ad performance and facilitating informed decision-making processes. Note that while we already show promising results, these are mostly preliminary experiments, and we strongly believe that this direction of research will bring many new advances in the nearest future.", "6 ACKNOWLEDGEMENT": "This work was funded by the Russian Science Foundation grant \u2116 22-11-00135 https://rscf.ru/en/project/22-11-00135/", "REFERENCES": "[1] [n. d.]. Best practices to potentially reduce cost per result for Meta ads. https: //www.facebook.com/business/help/321695409726523. [2] [n. d.]. Netflix Prize data. https://www.kaggle.com/datasets/netflix-inc/netflixprize-data. [3] Anton Alekseev, Elena Tutubalina, Sejeong Kwon, and Sergey Nikolenko. 2022. Near-Zero-Shot Suggestion Mining with a Little Help from WordNet. In Analysis of Images, Social Networks and Texts . Springer International Publishing, Cham, 23-36. [4] J. Bergstra, R. Bardenet, Y. Bengio, and B. K\u00e9gl. 2011. Algorithms for HyperParameter Optimization. In Advances in Neural Information Processing Systems , Vol. 24. Curran Associates, Inc. [5] K Buraya, A Farseev, and A Filchenkov. 2018. Multi-view personality profiling based on longitudinal data. Lecture Notes in Computer Science 11018 (2018), 15-27. [6] Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan He. 2023. Bias and Debias in Recommender System: A Survey and Future Directions. ACM Trans. Inf. Syst. 41, 3, Article 67 (feb 2023), 39 pages. [7] H.-T. Cheng, L. Koc, J. Harmsen, T. Shaked, T. Chandra, H. Aradhye, G. Anderson, G. Corrado, W. Chai, M. Ispir, R. Anil, Z. Haque, L. Hong, V. Jain, X. Liu, and H. Shah. 2016. Wide & Deep Learning for Recommender Systems. In Proc. 1st Workshop on Deep Learning for Recommender Systems (Boston, MA, USA) (DLRS 2016) . ACM, New York, NY, USA, 7-10. [8] Alok Kumar Chowdhury, Aleksandr Farseev, Prithwi Raj Chakraborty, Dian Tjondronegoro, and Vinod Chandran. 2017. Automatic classification of physical exercises from wearable sensors using small dataset from non-laboratory settings. In 2017 IEEE Life Sciences Conference (LSC) . 111-114. https://doi.org/10.1109/LSC. 2017.8268156 [9] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proc. 2019 NAACL . ACL, 4171-4186. [10] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929 (2020). [11] Yali Du, Yinwei Wei, Wei Ji, Fan Liu, Xin Luo, and Liqiang Nie. 2023. MultiQueue Momentum Contrast for Microvideo-Product Retrieval. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (Singapore, Singapore) (WSDM '23) . ACM, New York, NY, USA, 1003-1011. https: //doi.org/10.1145/3539597.3570405 [12] Aleksandr Farseev. 2023. Under the Hood of Social Media Advertising: How Do We Use AI Responsibly for Advertising Targeting and Creative Evaluation. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (Singapore, Singapore) (WSDM '23) . ACM, New York, NY, USA, 1281-1282. https://doi.org/10.1145/3539597.3575791 [13] A Farseev, N Gukov, I Gossoudarev, and U Zarichnyak. 2014. Cross-platform online venue and user community recommendation based upon social networks data mining. Computer Instruments in Education 6 (2014), 28-38. [14] Aleksandr Farseev, Kirill Lepikhin, Hendrik Schwartz, Eu Khoon Ang, and Kenny Powar. 2018. SoMin.Ai: Social Multimedia Influencer Discovery Marketplace. In Proceedings of the 26th ACM International Conference on Multimedia (Seoul, Republic of Korea) (MM '18) . ACM, New York, NY, USA, 1234-1236. https: //doi.org/10.1145/3240508.3241387 [15] Aleksandr Farseev, Qi Yang, Andrey Filchenkov, Kirill Lepikhin, Yu-Yi ChuFarseeva, and Daron-Benjamin Loo. 2021. SoMin.Ai: Personality-Driven Content Generation Platform. In Proceedings of the 14th ACM International Conference on Web Search and Data Mining (WSDM '21) . ACM, New York, NY, USA, 890-893. https://doi.org/10.1145/3437963.3441714 [16] H. Fukui, T. Hirakawa, T. Yamashita, and H. Fujiyoshi. 2019. Attention Branch Network: Learning of Attention Mechanism for Visual Explanation. Computer Vision and Pattern Recognition (2019), 10705-10714. [17] T. Ge, H. Liu, P. Yi, S. Huang, Z. Zhang, X. Zhu, Y. Zhang, K. Gai, L. Zhao, G. Zhou, K. Chen, S. Liu, H. Yi, Z. Hu, B. Liu, and P. Sun. 2018. Image Matters: Visually Modeling User Behaviors Using Advanced Model Server. 2087-2095. [18] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In Proceedings of the 26th International Conference on World Wide Web (Perth, Australia) (WWW'17) . International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE, 173-182. https://doi.org/10.1145/3038912.3052569 [19] X. He, J. Pan, O. Jin, T. Xu, B. Liu, T. Xu, Y. Shi, A. Atallah, R. Herbrich, S. Bowers, and J. Q. Candela. 2014. Practical Lessons from Predicting Clicks on Ads at Facebook. In Proc. 8th International Workshop on Data Mining for Online Advertising (ADKDD'14) . ACM, 1-9. [20] Alfred Huang, Qi Yang, Sergey Nikolenko, Marlo Ongpin, Ilia Gossoudarev, Ngoc Yen Duong, Kirill Lepikhin, Sergey Vishnyakov, Yuyi Chu-Farseeva, and Aleksandr Farseev. 2023. SoCraft: Advertiser-Level Predictive Scoring for Creative Performance on Meta. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (Singapore, Singapore) (WSDM '23) . ACM, New York, NY, USA, 1132-1135. https://doi.org/10.1145/3539597.3573032 [21] X. Huang, A. Khetan, M. Cvitkovic, and Z. Karnin. 2020. TabTransformer: Tabular Data Modeling Using Contextual Embeddings. (2020). arXiv:2012.06678 [cs.LG] [22] Sergei Koltcov, Olessia Koltsova, and Sergey Nikolenko. 2014. Latent Dirichlet Allocation: Stability and Applications to Studies of User-Generated Content. In Proceedings of the 2014 ACM Conference on Web Science (Bloomington, Indiana, USA) (WebSci '14) . ACM, New York, NY, USA, 161-165. https://doi.org/10.1145/ 2615569.2615680 [23] H. B. McMahan, G. Holt, D. Sculley, M. Young, D. Ebner, J. Grady, L. Nie, T. Phillips, E. Davydov, D. Golovin, S. Chikkerur, D. Liu, M. Wattenberg, A. M. Hrafnkelsson, T. Boulos, and J. Kubica. 2013. Ad Click Prediction: A View from the Trenches. In Proc. 19th ACM SIGKDD (KDD '13) . ACM, 1222-1230. [24] Meta. 2023. Meta Blueprint. https://www.facebookblueprint.com/student/catalog Accessed on June 06, 2023. [25] Sergey Nikolenko. 2015. SVD-LDA: Topic Modeling for Full-Text Recommender Systems. In Advances in Artificial Intelligence and Its Applications , Obdulia Pichardo Lagunas, Oscar Herrera Alc\u00e1ntara, and Gustavo Arroyo Figueroa (Eds.). Springer International Publishing, Cham, 67-79. [26] OpenAI. 2023. GPT-4 Technical Report. arXiv:2303.08774 [cs.CL] [27] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback. arXiv:2203.02155 [cs.CL] [28] Wentao Ouyang, Xiuwu Zhang, Shukui Ren, Chao Qi, Zhaojie Liu, and Yanlong Du. 2019. Representation Learning-Assisted Click-Through Rate Prediction. In Proc. 28th IJCAI . 4561-4567. https://doi.org/10.24963/ijcai.2019/634 [29] Francesco Ricci, Lior Rokach, Bracha Shapira, and Paul B. Kantor. 2010. Recommender Systems Handbook (1st ed.). Springer-Verlag, Berlin, Heidelberg. [30] Matthew Richardson, Ewa Dominowska, and Robert Ragno. 2007. Predicting Clicks: Estimating the Click-through Rate for New Ads. In Proc. 16th WWW (WWW'07) . ACM, 521-530. [31] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. 2022. High-Resolution Image Synthesis With Latent Diffusion Models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) . 10684-10695. [32] Andrey Savchenko, Anton Alekseev, Sejeong Kwon, Elena Tutubalina, Evgeny Myasnikov, and Sergey Nikolenko. 2020. Ad Lingua: Text Classification Improves Symbolism Prediction in Image Advertisements. In Proceedings of the 28th International Conference on Computational Linguistics . International Committee on Computational Linguistics, Barcelona, Spain (Online), 1886-1892. https://doi.org/10.18653/v1/2020.coling-main.171 [33] Ilya Shenbin, Anton Alekseev, Elena Tutubalina, Valentin Malykh, and Sergey I. Nikolenko. 2020. RecVAE: A New Variational Autoencoder for Top-N Recommendations with Implicit Feedback. In Proceedings of the 13th International Conference on Web Search and Data Mining (Houston, TX, USA) (WSDM '20) . ACM, New York, NY, USA, 528-536. https://doi.org/10.1145/3336191.3371831 [34] Elena Tutubalina and Sergey I. Nikolenko. 2017. Demographic Prediction based on User Reviews about Medications. Computaci\u00f3n y Sistemas 21, 2 (2017), 227241. [35] Elena Tutubalina and Sergey I. Nikolenko. 2018. Exploring convolutional neural networks and topic models for user profiling from drug reviews. Multimedia Tools and Applications 77, 4 (2018), 4791-4809. [36] Wenjie Wang, Fuli Feng, Liqiang Nie, and Tat-Seng Chua. 2022. User-Controllable Recommendation Against Filter Bubbles. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (Madrid, Spain) (SIGIR '22) . ACM, New York, NY, USA, 1251-1261. https://doi. org/10.1145/3477495.3532075 [37] Qi Yang, Aleksandr Farseev, and Andrey Filchenkov. 2021. Two-Faced Humans on Twitter and Facebook: Harvesting Social Multimedia for Human Personality Profiling. In Proceedings of the 2021 Workshop on Intelligent Cross-Data Analysis and Retrieval (Taipei, Taiwan) (ICDAR '21) . ACM, New York, NY, USA, 39-47. https://doi.org/10.1145/3463944.3469270 [38] Qi Yang, Aleksandr Farseev, Sergey Nikolenko, and Andrey Filchenkov. 2022. Do we behave differently on Twitter and Facebook: Multi-view social network user personality profiling for content recommendation. Frontiers in Big Data 5 (2022). https://doi.org/10.3389/fdata.2022.931206 [39] Qi Yang, Sergey Nikolenko, Alfred Huang, and Aleksandr Farseev. 2022. Personality-Driven Social Multimedia Content Recommendation. In Proceedings of the 30th ACM International Conference on Multimedia (Lisboa, Portugal) (MM '22) . ACM, New York, NY, USA, 7290-7299. https://doi.org/10.1145/3503161. 3548769 [40] Qi Yang, Christos Tzelepis, Sergey Nikolenko, Ioannis Patras, and Aleksandr Farseev. 2023. \"Just To See You Smile\": SMILEY, a Voice-Guided <Strike>GUY</Strike> GAN. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (Singapore, Singapore) (WSDM '23) . ACM, New York, NY, USA, 1196-1199. https://doi.org/10.1145/3539597.3573031"}
