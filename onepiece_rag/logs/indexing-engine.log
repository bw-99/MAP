08:10:41,200 graphrag.cli.index INFO Logging enabled at /workspace/onepiece_rag/logs/indexing-engine.log
08:10:41,203 graphrag.cli.index INFO Starting pipeline run for: 20250103-081041, dry_run=False
08:10:41,204 graphrag.cli.index INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "encoding_model": "cl100k_base",
        "model": "gpt-4o-mini",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0,
        "request_timeout": 180.0,
        "api_base": null,
        "api_version": null,
        "proxy": null,
        "audience": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 200000,
        "requests_per_minute": 500,
        "max_retries": 20,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "responses": null
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 4
    },
    "async_mode": "asyncio",
    "root_dir": "/workspace/onepiece_rag",
    "reporting": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/logs",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "update_index_storage": null,
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "encoding_model": "cl100k_base",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 1000000,
            "requests_per_minute": 3000,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": {
            "type": "lancedb",
            "db_uri": "/workspace/onepiece_rag/output/lancedb",
            "container_name": "==== REDACTED ====",
            "overwrite": true
        },
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "transient": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "people",
            "concept"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "core_concept_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/core_concept_extraction.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 3,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0.0,
        "local_search_top_p": 1.0,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 2000
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
08:10:41,216 graphrag.index.create_pipeline_config INFO skipping workflows 
08:10:41,220 graphrag.index.run.run INFO Running pipeline
08:10:41,220 graphrag.storage.file_pipeline_storage INFO Creating file storage at /workspace/onepiece_rag/output
08:10:41,225 graphrag.index.input.factory INFO loading input from root_dir=input
08:10:41,225 graphrag.index.input.factory INFO using file storage for input
08:10:41,228 graphrag.storage.file_pipeline_storage INFO search /workspace/onepiece_rag/input for files matching .*\.txt$
08:10:41,235 graphrag.index.input.text INFO found text files from input, found [('a05OLUVtYmVkOiBMb2NhbGx5IFNtb290aGVkIEVtYmVkZGluZyBNaXh0dXJlcyBGb3IgTXVsdGktaW50ZXJlc3QgQ2FuZGlkYXRlIFJldHJpZXZhbA==.json.txt', {})]
08:10:41,241 graphrag.index.input.text INFO Found 1 files, loading 1
08:10:41,243 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_final_documents', 'extract_graph', 'compute_communities', 'create_final_entities', 'create_final_relationships', 'create_final_communities', 'create_final_nodes', 'create_final_text_units', 'create_final_community_reports', 'extract_core_concept', 'generate_text_embeddings', 'create_final_viztree']
08:10:41,244 graphrag.index.run.run INFO Final # of rows loaded: 1
08:10:41,312 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
08:10:41,319 datashaper.workflow.workflow INFO executing verb create_base_text_units
08:10:42,419 graphrag.index.run.workflow INFO dependencies for create_final_documents: ['create_base_text_units']
08:10:42,422 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:10:42,430 datashaper.workflow.workflow INFO executing verb create_final_documents
08:10:42,447 graphrag.index.exporter INFO exporting parquet table create_final_documents.parquet
08:10:42,563 graphrag.index.run.workflow INFO dependencies for extract_graph: ['create_base_text_units']
08:10:42,564 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:10:42,579 datashaper.workflow.workflow INFO executing verb extract_graph
08:10:51,549 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:10:51,885 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:10:52,642 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:10:53,146 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:10:55,1 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:10:57,523 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:10:58,139 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:10:59,713 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:06,397 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:06,824 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:08,57 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:13,188 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:13,641 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:15,630 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:17,230 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:17,969 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:18,50 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:18,708 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:19,279 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:19,779 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:20,749 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:22,524 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:22,574 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:22,724 graphrag.index.run.workflow INFO dependencies for compute_communities: ['extract_graph']
08:11:22,726 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:11:22,735 datashaper.workflow.workflow INFO executing verb compute_communities
08:11:28,702 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['extract_graph']
08:11:28,704 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:11:28,715 datashaper.workflow.workflow INFO executing verb create_final_entities
08:11:28,721 graphrag.index.exporter INFO exporting parquet table create_final_entities.parquet
08:11:28,935 graphrag.index.run.workflow INFO dependencies for create_final_relationships: ['extract_graph']
08:11:28,937 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:11:28,953 datashaper.workflow.workflow INFO executing verb create_final_relationships
08:11:28,967 graphrag.index.exporter INFO exporting parquet table create_final_relationships.parquet
08:11:29,177 graphrag.index.run.workflow INFO dependencies for create_final_communities: ['extract_graph']
08:11:29,179 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:11:29,197 datashaper.workflow.workflow INFO executing verb create_final_communities
08:11:29,255 graphrag.index.exporter INFO exporting parquet table create_final_communities.parquet
08:11:29,427 graphrag.index.run.workflow INFO dependencies for create_final_nodes: ['extract_graph', 'compute_communities']
08:11:29,429 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:11:29,431 graphrag.index.run.workflow WARNING Dependency table compute_communities not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:11:29,446 datashaper.workflow.workflow INFO executing verb create_final_nodes
08:11:29,472 graphrag.index.exporter INFO exporting parquet table create_final_nodes.parquet
08:11:29,648 graphrag.index.run.workflow INFO dependencies for create_final_text_units: ['create_final_relationships', 'create_base_text_units', 'create_final_entities']
08:11:29,654 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:11:29,686 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:11:29,689 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:11:29,717 datashaper.workflow.workflow INFO executing verb create_final_text_units
08:11:29,744 graphrag.index.exporter INFO exporting parquet table create_final_text_units.parquet
08:11:29,929 graphrag.index.run.workflow INFO dependencies for create_final_community_reports: ['create_final_communities', 'create_final_nodes', 'create_final_relationships', 'create_final_entities']
08:11:29,932 graphrag.utils.storage INFO reading table from storage: create_final_communities.parquet
08:11:29,943 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:11:29,954 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:11:29,963 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:11:29,990 datashaper.workflow.workflow INFO executing verb create_final_community_reports
08:11:30,21 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=1 => 12
08:11:30,67 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=0 => 40
08:11:40,318 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:11:51,237 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:06,58 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:07,907 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:12,586 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:16,493 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:20,952 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:22,297 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:22,336 graphrag.index.exporter INFO exporting parquet table create_final_community_reports.parquet
08:12:22,581 graphrag.index.run.workflow INFO dependencies for extract_core_concept: ['create_final_community_reports']
08:12:22,583 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:12:22,610 datashaper.workflow.workflow INFO executing verb extract_core_concept
08:12:22,617 graphrag.index.flows.extract_core_concept INFO Creating core concept
08:12:24,540 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:24,797 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:24,818 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:25,133 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:26,313 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:26,335 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:26,766 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:27,595 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
08:12:27,624 graphrag.index.exporter INFO exporting parquet table extract_core_concept.parquet
08:12:27,785 graphrag.index.run.workflow INFO dependencies for generate_text_embeddings: ['create_final_text_units', 'create_final_documents', 'create_final_relationships', 'create_final_community_reports', 'create_final_entities']
08:12:27,787 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:12:27,799 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:12:27,810 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:12:27,822 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:12:27,838 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:12:27,875 datashaper.workflow.workflow INFO executing verb generate_text_embeddings
08:12:27,880 graphrag.index.flows.generate_text_embeddings INFO Creating embeddings
08:12:27,880 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
08:12:27,964 graphrag.index.operations.embed_text.strategies.openai INFO embedding 60 inputs via 60 snippets using 4 batches. max_batch_size=16, max_tokens=8191
08:12:28,450 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
08:12:28,676 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
08:12:28,739 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
08:12:28,763 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
08:12:29,847 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
08:12:29,864 graphrag.index.operations.embed_text.strategies.openai INFO embedding 8 inputs via 8 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:12:30,556 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
08:12:31,326 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
08:12:31,346 graphrag.index.operations.embed_text.strategies.openai INFO embedding 7 inputs via 7 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:12:32,67 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
08:12:32,676 graphrag.index.run.workflow INFO dependencies for create_final_viztree: ['create_final_nodes', 'extract_core_concept', 'create_final_text_units', 'create_final_documents', 'create_final_community_reports']
08:12:32,678 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:12:32,688 graphrag.utils.storage INFO reading table from storage: extract_core_concept.parquet
08:12:32,698 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:12:32,709 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:12:32,717 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:12:32,746 datashaper.workflow.workflow INFO executing verb create_final_viztree
08:12:32,806 graphrag.index.exporter INFO exporting parquet table create_final_viztree.parquet
08:12:32,808 graphrag.index.exporter ERROR Error while exporting parquet table
Traceback (most recent call last):
  File "/workspace/graphrag/index/exporter.py", line 41, in export
    await self._storage.set(filename, data.to_parquet())
  File "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py", line 3113, in to_parquet
    return to_parquet(
  File "/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py", line 480, in to_parquet
    impl.write(
  File "/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py", line 190, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 3874, in pyarrow.lib.Table.from_pandas
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 611, in dataframe_to_arrays
    arrays = [convert_column(c, f)
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 611, in <listcomp>
    arrays = [convert_column(c, f)
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 598, in convert_column
    raise e
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 592, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 339, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 85, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 91, in pyarrow.lib.check_status
pyarrow.lib.ArrowInvalid: ("Could not convert 'b3de4456c576570c6731ea7909ad9ba69d77ef99f23f5767bff56871025fe67a78e2cb87930a28b853e42e13e6f175e40e6915e91c87002c2d04006272df136b' with type str: tried to convert to int64", 'Conversion failed for column parent with type object')
08:12:32,822 graphrag.callbacks.file_workflow_callbacks INFO Error exporting table details=None
08:12:32,896 graphrag.cli.index INFO All workflows completed successfully.
08:15:12,952 graphrag.cli.index INFO Logging enabled at /workspace/onepiece_rag/logs/indexing-engine.log
08:15:12,956 graphrag.cli.index INFO Starting pipeline run for: 20250103-081512, dry_run=False
08:15:12,957 graphrag.cli.index INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "encoding_model": "cl100k_base",
        "model": "gpt-4o-mini",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0,
        "request_timeout": 180.0,
        "api_base": null,
        "api_version": null,
        "proxy": null,
        "audience": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 200000,
        "requests_per_minute": 500,
        "max_retries": 20,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "responses": null
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 4
    },
    "async_mode": "asyncio",
    "root_dir": "/workspace/onepiece_rag",
    "reporting": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/logs",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "update_index_storage": null,
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "encoding_model": "cl100k_base",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 1000000,
            "requests_per_minute": 3000,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": {
            "type": "lancedb",
            "db_uri": "/workspace/onepiece_rag/output/lancedb",
            "container_name": "==== REDACTED ====",
            "overwrite": true
        },
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "transient": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "people",
            "concept"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "core_concept_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/core_concept_extraction.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 3,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0.0,
        "local_search_top_p": 1.0,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 2000
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
08:15:12,966 graphrag.index.create_pipeline_config INFO skipping workflows 
08:15:12,967 graphrag.index.run.run INFO Running pipeline
08:15:12,967 graphrag.storage.file_pipeline_storage INFO Creating file storage at /workspace/onepiece_rag/output
08:15:12,969 graphrag.index.input.factory INFO loading input from root_dir=input
08:15:12,969 graphrag.index.input.factory INFO using file storage for input
08:15:12,972 graphrag.storage.file_pipeline_storage INFO search /workspace/onepiece_rag/input for files matching .*\.txt$
08:15:12,979 graphrag.index.input.text INFO found text files from input, found [('a05OLUVtYmVkOiBMb2NhbGx5IFNtb290aGVkIEVtYmVkZGluZyBNaXh0dXJlcyBGb3IgTXVsdGktaW50ZXJlc3QgQ2FuZGlkYXRlIFJldHJpZXZhbA==.json.txt', {})]
08:15:12,986 graphrag.index.input.text INFO Found 1 files, loading 1
08:15:12,988 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_final_documents', 'extract_graph', 'compute_communities', 'create_final_entities', 'create_final_relationships', 'create_final_communities', 'create_final_nodes', 'create_final_text_units', 'create_final_community_reports', 'extract_core_concept', 'generate_text_embeddings', 'create_final_viztree']
08:15:12,989 graphrag.index.run.run INFO Final # of rows loaded: 1
08:15:13,51 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
08:15:13,57 datashaper.workflow.workflow INFO executing verb create_base_text_units
08:15:14,61 graphrag.index.run.workflow INFO dependencies for create_final_documents: ['create_base_text_units']
08:15:14,63 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:15:14,72 datashaper.workflow.workflow INFO executing verb create_final_documents
08:15:14,93 graphrag.index.exporter INFO exporting parquet table create_final_documents.parquet
08:15:14,209 graphrag.index.run.workflow INFO dependencies for extract_graph: ['create_base_text_units']
08:15:14,211 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:15:14,219 datashaper.workflow.workflow INFO executing verb extract_graph
08:15:14,703 graphrag.index.run.workflow INFO dependencies for compute_communities: ['extract_graph']
08:15:14,704 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:15:14,714 datashaper.workflow.workflow INFO executing verb compute_communities
08:15:20,549 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['extract_graph']
08:15:20,551 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:15:20,569 datashaper.workflow.workflow INFO executing verb create_final_entities
08:15:20,575 graphrag.index.exporter INFO exporting parquet table create_final_entities.parquet
08:15:20,777 graphrag.index.run.workflow INFO dependencies for create_final_relationships: ['extract_graph']
08:15:20,779 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:15:20,793 datashaper.workflow.workflow INFO executing verb create_final_relationships
08:15:20,804 graphrag.index.exporter INFO exporting parquet table create_final_relationships.parquet
08:15:21,49 graphrag.index.run.workflow INFO dependencies for create_final_communities: ['extract_graph']
08:15:21,52 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:15:21,69 datashaper.workflow.workflow INFO executing verb create_final_communities
08:15:21,119 graphrag.index.exporter INFO exporting parquet table create_final_communities.parquet
08:15:21,290 graphrag.index.run.workflow INFO dependencies for create_final_nodes: ['extract_graph', 'compute_communities']
08:15:21,292 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:15:21,295 graphrag.index.run.workflow WARNING Dependency table compute_communities not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:15:21,313 datashaper.workflow.workflow INFO executing verb create_final_nodes
08:15:21,338 graphrag.index.exporter INFO exporting parquet table create_final_nodes.parquet
08:15:21,512 graphrag.index.run.workflow INFO dependencies for create_final_text_units: ['create_base_text_units', 'create_final_entities', 'create_final_relationships']
08:15:21,513 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:15:21,515 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:15:21,536 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:15:21,564 datashaper.workflow.workflow INFO executing verb create_final_text_units
08:15:21,592 graphrag.index.exporter INFO exporting parquet table create_final_text_units.parquet
08:15:21,765 graphrag.index.run.workflow INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_communities', 'create_final_entities', 'create_final_relationships']
08:15:21,767 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:15:21,779 graphrag.utils.storage INFO reading table from storage: create_final_communities.parquet
08:15:21,789 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:15:21,799 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:15:21,827 datashaper.workflow.workflow INFO executing verb create_final_community_reports
08:15:21,862 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=1 => 12
08:15:21,916 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=0 => 40
08:15:22,139 graphrag.index.exporter INFO exporting parquet table create_final_community_reports.parquet
08:15:22,326 graphrag.index.run.workflow INFO dependencies for extract_core_concept: ['create_final_community_reports']
08:15:22,327 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:15:22,355 datashaper.workflow.workflow INFO executing verb extract_core_concept
08:15:22,362 graphrag.index.flows.extract_core_concept INFO Creating core concept
08:15:22,539 graphrag.index.exporter INFO exporting parquet table extract_core_concept.parquet
08:15:22,724 graphrag.index.run.workflow INFO dependencies for generate_text_embeddings: ['create_final_text_units', 'create_final_entities', 'create_final_community_reports', 'create_final_documents', 'create_final_relationships']
08:15:22,727 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:15:22,738 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:15:22,748 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:15:22,759 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:15:22,769 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:15:22,820 datashaper.workflow.workflow INFO executing verb generate_text_embeddings
08:15:22,837 graphrag.index.flows.generate_text_embeddings INFO Creating embeddings
08:15:22,872 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
08:15:23,84 graphrag.index.operations.embed_text.strategies.openai INFO embedding 60 inputs via 60 snippets using 4 batches. max_batch_size=16, max_tokens=8191
08:15:23,296 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
08:15:23,319 graphrag.index.operations.embed_text.strategies.openai INFO embedding 8 inputs via 8 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:15:23,444 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
08:15:23,468 graphrag.index.operations.embed_text.strategies.openai INFO embedding 7 inputs via 7 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:15:23,812 graphrag.index.run.workflow INFO dependencies for create_final_viztree: ['extract_core_concept', 'create_final_text_units', 'create_final_nodes', 'create_final_community_reports', 'create_final_documents']
08:15:23,814 graphrag.utils.storage INFO reading table from storage: extract_core_concept.parquet
08:15:23,826 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:15:23,839 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:15:23,852 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:15:23,867 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:15:23,912 datashaper.workflow.workflow INFO executing verb create_final_viztree
08:15:24,19 graphrag.index.exporter INFO exporting parquet table create_final_viztree.parquet
08:15:24,20 graphrag.index.exporter ERROR Error while exporting parquet table
Traceback (most recent call last):
  File "/workspace/graphrag/index/exporter.py", line 41, in export
    await self._storage.set(filename, data.to_parquet())
  File "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py", line 3113, in to_parquet
    return to_parquet(
  File "/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py", line 480, in to_parquet
    impl.write(
  File "/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py", line 190, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 3874, in pyarrow.lib.Table.from_pandas
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 611, in dataframe_to_arrays
    arrays = [convert_column(c, f)
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 611, in <listcomp>
    arrays = [convert_column(c, f)
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 598, in convert_column
    raise e
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 592, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 339, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 85, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 91, in pyarrow.lib.check_status
pyarrow.lib.ArrowInvalid: ("Could not convert 'b3de4456c576570c6731ea7909ad9ba69d77ef99f23f5767bff56871025fe67a78e2cb87930a28b853e42e13e6f175e40e6915e91c87002c2d04006272df136b' with type str: tried to convert to int64", 'Conversion failed for column parent with type object')
08:15:24,33 graphrag.callbacks.file_workflow_callbacks INFO Error exporting table details=None
08:15:24,144 graphrag.cli.index INFO All workflows completed successfully.
08:19:18,425 graphrag.cli.index INFO Logging enabled at /workspace/onepiece_rag/logs/indexing-engine.log
08:19:18,429 graphrag.cli.index INFO Starting pipeline run for: 20250103-081918, dry_run=False
08:19:18,430 graphrag.cli.index INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "encoding_model": "cl100k_base",
        "model": "gpt-4o-mini",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0,
        "request_timeout": 180.0,
        "api_base": null,
        "api_version": null,
        "proxy": null,
        "audience": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 200000,
        "requests_per_minute": 500,
        "max_retries": 20,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "responses": null
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 4
    },
    "async_mode": "asyncio",
    "root_dir": "/workspace/onepiece_rag",
    "reporting": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/logs",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "update_index_storage": null,
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "encoding_model": "cl100k_base",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 1000000,
            "requests_per_minute": 3000,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": {
            "type": "lancedb",
            "db_uri": "/workspace/onepiece_rag/output/lancedb",
            "container_name": "==== REDACTED ====",
            "overwrite": true
        },
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "transient": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "people",
            "concept"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "core_concept_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/core_concept_extraction.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 3,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0.0,
        "local_search_top_p": 1.0,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 2000
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
08:19:18,441 graphrag.index.create_pipeline_config INFO skipping workflows 
08:19:18,442 graphrag.index.run.run INFO Running pipeline
08:19:18,443 graphrag.storage.file_pipeline_storage INFO Creating file storage at /workspace/onepiece_rag/output
08:19:18,445 graphrag.index.input.factory INFO loading input from root_dir=input
08:19:18,445 graphrag.index.input.factory INFO using file storage for input
08:19:18,448 graphrag.storage.file_pipeline_storage INFO search /workspace/onepiece_rag/input for files matching .*\.txt$
08:19:18,456 graphrag.index.input.text INFO found text files from input, found [('a05OLUVtYmVkOiBMb2NhbGx5IFNtb290aGVkIEVtYmVkZGluZyBNaXh0dXJlcyBGb3IgTXVsdGktaW50ZXJlc3QgQ2FuZGlkYXRlIFJldHJpZXZhbA==.json.txt', {})]
08:19:18,463 graphrag.index.input.text INFO Found 1 files, loading 1
08:19:18,465 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_final_documents', 'extract_graph', 'compute_communities', 'create_final_entities', 'create_final_relationships', 'create_final_communities', 'create_final_nodes', 'create_final_text_units', 'create_final_community_reports', 'extract_core_concept', 'generate_text_embeddings', 'create_final_viztree']
08:19:18,466 graphrag.index.run.run INFO Final # of rows loaded: 1
08:19:18,532 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
08:19:18,538 datashaper.workflow.workflow INFO executing verb create_base_text_units
08:19:19,474 graphrag.index.run.workflow INFO dependencies for create_final_documents: ['create_base_text_units']
08:19:19,476 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:19:19,484 datashaper.workflow.workflow INFO executing verb create_final_documents
08:19:19,505 graphrag.index.exporter INFO exporting parquet table create_final_documents.parquet
08:19:19,618 graphrag.index.run.workflow INFO dependencies for extract_graph: ['create_base_text_units']
08:19:19,619 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:19:19,631 datashaper.workflow.workflow INFO executing verb extract_graph
08:19:20,127 graphrag.index.run.workflow INFO dependencies for compute_communities: ['extract_graph']
08:19:20,129 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:19:20,140 datashaper.workflow.workflow INFO executing verb compute_communities
08:19:26,130 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['extract_graph']
08:19:26,132 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:19:26,145 datashaper.workflow.workflow INFO executing verb create_final_entities
08:19:26,151 graphrag.index.exporter INFO exporting parquet table create_final_entities.parquet
08:19:26,392 graphrag.index.run.workflow INFO dependencies for create_final_relationships: ['extract_graph']
08:19:26,394 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:19:26,414 datashaper.workflow.workflow INFO executing verb create_final_relationships
08:19:26,431 graphrag.index.exporter INFO exporting parquet table create_final_relationships.parquet
08:19:26,898 graphrag.index.run.workflow INFO dependencies for create_final_communities: ['extract_graph']
08:19:26,901 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:19:26,932 datashaper.workflow.workflow INFO executing verb create_final_communities
08:19:27,42 graphrag.index.exporter INFO exporting parquet table create_final_communities.parquet
08:19:27,286 graphrag.index.run.workflow INFO dependencies for create_final_nodes: ['extract_graph', 'compute_communities']
08:19:27,288 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:19:27,290 graphrag.index.run.workflow WARNING Dependency table compute_communities not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:19:27,304 datashaper.workflow.workflow INFO executing verb create_final_nodes
08:19:27,335 graphrag.index.exporter INFO exporting parquet table create_final_nodes.parquet
08:19:27,506 graphrag.index.run.workflow INFO dependencies for create_final_text_units: ['create_final_relationships', 'create_base_text_units', 'create_final_entities']
08:19:27,508 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:19:27,532 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:19:27,534 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:19:27,558 datashaper.workflow.workflow INFO executing verb create_final_text_units
08:19:27,582 graphrag.index.exporter INFO exporting parquet table create_final_text_units.parquet
08:19:27,774 graphrag.index.run.workflow INFO dependencies for create_final_community_reports: ['create_final_entities', 'create_final_relationships', 'create_final_communities', 'create_final_nodes']
08:19:27,776 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:19:27,785 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:19:27,796 graphrag.utils.storage INFO reading table from storage: create_final_communities.parquet
08:19:27,806 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:19:27,835 datashaper.workflow.workflow INFO executing verb create_final_community_reports
08:19:27,865 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=1 => 12
08:19:27,919 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=0 => 40
08:19:28,161 graphrag.index.exporter INFO exporting parquet table create_final_community_reports.parquet
08:19:28,348 graphrag.index.run.workflow INFO dependencies for extract_core_concept: ['create_final_community_reports']
08:19:28,351 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:19:28,383 datashaper.workflow.workflow INFO executing verb extract_core_concept
08:19:28,390 graphrag.index.flows.extract_core_concept INFO Creating core concept
08:19:28,547 graphrag.index.exporter INFO exporting parquet table extract_core_concept.parquet
08:19:28,714 graphrag.index.run.workflow INFO dependencies for generate_text_embeddings: ['create_final_community_reports', 'create_final_text_units', 'create_final_relationships', 'create_final_documents', 'create_final_entities']
08:19:28,720 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:19:28,733 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:19:28,744 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:19:28,753 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:19:28,762 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:19:28,794 datashaper.workflow.workflow INFO executing verb generate_text_embeddings
08:19:28,799 graphrag.index.flows.generate_text_embeddings INFO Creating embeddings
08:19:28,800 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
08:19:28,914 graphrag.index.operations.embed_text.strategies.openai INFO embedding 7 inputs via 7 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:19:29,48 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
08:19:29,67 graphrag.index.operations.embed_text.strategies.openai INFO embedding 60 inputs via 60 snippets using 4 batches. max_batch_size=16, max_tokens=8191
08:19:29,226 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
08:19:29,246 graphrag.index.operations.embed_text.strategies.openai INFO embedding 8 inputs via 8 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:19:29,528 graphrag.index.run.workflow INFO dependencies for create_final_viztree: ['extract_core_concept', 'create_final_community_reports', 'create_final_text_units', 'create_final_documents', 'create_final_nodes']
08:19:29,531 graphrag.utils.storage INFO reading table from storage: extract_core_concept.parquet
08:19:29,540 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:19:29,550 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:19:29,560 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:19:29,571 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:19:29,600 datashaper.workflow.workflow INFO executing verb create_final_viztree
08:19:29,600 datashaper.workflow.workflow ERROR Error executing verb "create_final_viztree" in create_final_viztree: create_final_viztree() missing 1 required positional argument: 'summarization_strategy'
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/datashaper/workflow/workflow.py", line 415, in _execute_verb
    result = await result
  File "/workspace/graphrag/index/workflows/v1/create_final_viztree.py", line 73, in workflow
    output = await create_final_viztree(
TypeError: create_final_viztree() missing 1 required positional argument: 'summarization_strategy'
08:19:29,609 graphrag.callbacks.file_workflow_callbacks INFO Error executing verb "create_final_viztree" in create_final_viztree: create_final_viztree() missing 1 required positional argument: 'summarization_strategy' details=None
08:19:29,609 graphrag.index.run.run ERROR error running workflow create_final_viztree
Traceback (most recent call last):
  File "/workspace/graphrag/index/run/run.py", line 262, in run_pipeline
    result = await _process_workflow(
  File "/workspace/graphrag/index/run/workflow.py", line 107, in _process_workflow
    result = await workflow.run(context, callbacks)
  File "/usr/local/lib/python3.10/dist-packages/datashaper/workflow/workflow.py", line 369, in run
    timing = await self._execute_verb(node, context, callbacks)
  File "/usr/local/lib/python3.10/dist-packages/datashaper/workflow/workflow.py", line 415, in _execute_verb
    result = await result
  File "/workspace/graphrag/index/workflows/v1/create_final_viztree.py", line 73, in workflow
    output = await create_final_viztree(
TypeError: create_final_viztree() missing 1 required positional argument: 'summarization_strategy'
08:19:29,625 graphrag.callbacks.file_workflow_callbacks INFO Error running pipeline! details=None
08:19:29,664 graphrag.cli.index ERROR Errors occurred during the pipeline run, see logs for more details.
08:20:02,715 graphrag.cli.index INFO Logging enabled at /workspace/onepiece_rag/logs/indexing-engine.log
08:20:02,720 graphrag.cli.index INFO Starting pipeline run for: 20250103-082002, dry_run=False
08:20:02,721 graphrag.cli.index INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "encoding_model": "cl100k_base",
        "model": "gpt-4o-mini",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0,
        "request_timeout": 180.0,
        "api_base": null,
        "api_version": null,
        "proxy": null,
        "audience": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 200000,
        "requests_per_minute": 500,
        "max_retries": 20,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "responses": null
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 4
    },
    "async_mode": "asyncio",
    "root_dir": "/workspace/onepiece_rag",
    "reporting": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/logs",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "update_index_storage": null,
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "encoding_model": "cl100k_base",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 1000000,
            "requests_per_minute": 3000,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": {
            "type": "lancedb",
            "db_uri": "/workspace/onepiece_rag/output/lancedb",
            "container_name": "==== REDACTED ====",
            "overwrite": true
        },
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "transient": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "people",
            "concept"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "core_concept_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/core_concept_extraction.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 3,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0.0,
        "local_search_top_p": 1.0,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 2000
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
08:20:02,734 graphrag.index.create_pipeline_config INFO skipping workflows 
08:20:02,737 graphrag.index.run.run INFO Running pipeline
08:20:02,737 graphrag.storage.file_pipeline_storage INFO Creating file storage at /workspace/onepiece_rag/output
08:20:02,741 graphrag.index.input.factory INFO loading input from root_dir=input
08:20:02,741 graphrag.index.input.factory INFO using file storage for input
08:20:02,745 graphrag.storage.file_pipeline_storage INFO search /workspace/onepiece_rag/input for files matching .*\.txt$
08:20:02,754 graphrag.index.input.text INFO found text files from input, found [('a05OLUVtYmVkOiBMb2NhbGx5IFNtb290aGVkIEVtYmVkZGluZyBNaXh0dXJlcyBGb3IgTXVsdGktaW50ZXJlc3QgQ2FuZGlkYXRlIFJldHJpZXZhbA==.json.txt', {})]
08:20:02,762 graphrag.index.input.text INFO Found 1 files, loading 1
08:20:02,765 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_final_documents', 'extract_graph', 'compute_communities', 'create_final_entities', 'create_final_relationships', 'create_final_communities', 'create_final_nodes', 'create_final_text_units', 'create_final_community_reports', 'extract_core_concept', 'generate_text_embeddings', 'create_final_viztree']
08:20:02,766 graphrag.index.run.run INFO Final # of rows loaded: 1
08:20:02,861 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
08:20:02,867 datashaper.workflow.workflow INFO executing verb create_base_text_units
08:20:04,60 graphrag.index.run.workflow INFO dependencies for create_final_documents: ['create_base_text_units']
08:20:04,62 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:20:04,71 datashaper.workflow.workflow INFO executing verb create_final_documents
08:20:04,91 graphrag.index.exporter INFO exporting parquet table create_final_documents.parquet
08:20:04,219 graphrag.index.run.workflow INFO dependencies for extract_graph: ['create_base_text_units']
08:20:04,221 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:20:04,232 datashaper.workflow.workflow INFO executing verb extract_graph
08:20:04,727 graphrag.index.run.workflow INFO dependencies for compute_communities: ['extract_graph']
08:20:04,729 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:20:04,738 datashaper.workflow.workflow INFO executing verb compute_communities
08:20:10,726 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['extract_graph']
08:20:10,728 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:20:10,743 datashaper.workflow.workflow INFO executing verb create_final_entities
08:20:10,751 graphrag.index.exporter INFO exporting parquet table create_final_entities.parquet
08:20:10,965 graphrag.index.run.workflow INFO dependencies for create_final_relationships: ['extract_graph']
08:20:10,967 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:20:10,981 datashaper.workflow.workflow INFO executing verb create_final_relationships
08:20:10,994 graphrag.index.exporter INFO exporting parquet table create_final_relationships.parquet
08:20:11,226 graphrag.index.run.workflow INFO dependencies for create_final_communities: ['extract_graph']
08:20:11,228 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:20:11,242 datashaper.workflow.workflow INFO executing verb create_final_communities
08:20:11,287 graphrag.index.exporter INFO exporting parquet table create_final_communities.parquet
08:20:11,457 graphrag.index.run.workflow INFO dependencies for create_final_nodes: ['compute_communities', 'extract_graph']
08:20:11,459 graphrag.index.run.workflow WARNING Dependency table compute_communities not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:20:11,461 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:20:11,483 datashaper.workflow.workflow INFO executing verb create_final_nodes
08:20:11,512 graphrag.index.exporter INFO exporting parquet table create_final_nodes.parquet
08:20:11,690 graphrag.index.run.workflow INFO dependencies for create_final_text_units: ['create_base_text_units', 'create_final_entities', 'create_final_relationships']
08:20:11,692 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:20:11,694 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:20:11,715 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:20:11,740 datashaper.workflow.workflow INFO executing verb create_final_text_units
08:20:11,763 graphrag.index.exporter INFO exporting parquet table create_final_text_units.parquet
08:20:11,936 graphrag.index.run.workflow INFO dependencies for create_final_community_reports: ['create_final_entities', 'create_final_nodes', 'create_final_communities', 'create_final_relationships']
08:20:11,944 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:20:11,957 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:20:11,970 graphrag.utils.storage INFO reading table from storage: create_final_communities.parquet
08:20:11,984 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:20:12,16 datashaper.workflow.workflow INFO executing verb create_final_community_reports
08:20:12,49 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=1 => 12
08:20:12,104 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=0 => 40
08:20:12,327 graphrag.index.exporter INFO exporting parquet table create_final_community_reports.parquet
08:20:12,498 graphrag.index.run.workflow INFO dependencies for extract_core_concept: ['create_final_community_reports']
08:20:12,501 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:20:12,529 datashaper.workflow.workflow INFO executing verb extract_core_concept
08:20:12,537 graphrag.index.flows.extract_core_concept INFO Creating core concept
08:20:12,687 graphrag.index.exporter INFO exporting parquet table extract_core_concept.parquet
08:20:12,879 graphrag.index.run.workflow INFO dependencies for generate_text_embeddings: ['create_final_community_reports', 'create_final_entities', 'create_final_documents', 'create_final_text_units', 'create_final_relationships']
08:20:12,881 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:20:12,892 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:20:12,901 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:20:12,913 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:20:12,924 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:20:12,969 datashaper.workflow.workflow INFO executing verb generate_text_embeddings
08:20:12,977 graphrag.index.flows.generate_text_embeddings INFO Creating embeddings
08:20:12,978 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
08:20:13,104 graphrag.index.operations.embed_text.strategies.openai INFO embedding 8 inputs via 8 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:20:13,262 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
08:20:13,289 graphrag.index.operations.embed_text.strategies.openai INFO embedding 7 inputs via 7 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:20:13,415 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
08:20:13,438 graphrag.index.operations.embed_text.strategies.openai INFO embedding 60 inputs via 60 snippets using 4 batches. max_batch_size=16, max_tokens=8191
08:20:13,832 graphrag.index.run.workflow INFO dependencies for create_final_viztree: ['create_final_community_reports', 'create_final_nodes', 'create_final_documents', 'extract_core_concept', 'create_final_text_units']
08:20:13,834 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:20:13,847 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:20:13,858 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:20:13,868 graphrag.utils.storage INFO reading table from storage: extract_core_concept.parquet
08:20:13,878 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:20:13,906 datashaper.workflow.workflow INFO executing verb create_final_viztree
08:20:13,988 graphrag.index.exporter INFO exporting parquet table create_final_viztree.parquet
08:20:13,990 graphrag.index.exporter ERROR Error while exporting parquet table
Traceback (most recent call last):
  File "/workspace/graphrag/index/exporter.py", line 41, in export
    await self._storage.set(filename, data.to_parquet())
  File "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py", line 3113, in to_parquet
    return to_parquet(
  File "/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py", line 480, in to_parquet
    impl.write(
  File "/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py", line 190, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 3874, in pyarrow.lib.Table.from_pandas
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 611, in dataframe_to_arrays
    arrays = [convert_column(c, f)
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 611, in <listcomp>
    arrays = [convert_column(c, f)
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 598, in convert_column
    raise e
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 592, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 339, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 85, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 91, in pyarrow.lib.check_status
pyarrow.lib.ArrowInvalid: ("Could not convert 'b3de4456c576570c6731ea7909ad9ba69d77ef99f23f5767bff56871025fe67a78e2cb87930a28b853e42e13e6f175e40e6915e91c87002c2d04006272df136b' with type str: tried to convert to int64", 'Conversion failed for column parent with type object')
08:20:14,0 graphrag.callbacks.file_workflow_callbacks INFO Error exporting table details=None
08:20:14,80 graphrag.cli.index INFO All workflows completed successfully.
08:22:06,449 graphrag.cli.index INFO Logging enabled at /workspace/onepiece_rag/logs/indexing-engine.log
08:22:06,453 graphrag.cli.index INFO Starting pipeline run for: 20250103-082206, dry_run=False
08:22:06,454 graphrag.cli.index INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "encoding_model": "cl100k_base",
        "model": "gpt-4o-mini",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0,
        "request_timeout": 180.0,
        "api_base": null,
        "api_version": null,
        "proxy": null,
        "audience": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 200000,
        "requests_per_minute": 500,
        "max_retries": 20,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "responses": null
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 4
    },
    "async_mode": "asyncio",
    "root_dir": "/workspace/onepiece_rag",
    "reporting": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/logs",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "update_index_storage": null,
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "encoding_model": "cl100k_base",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 1000000,
            "requests_per_minute": 3000,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": {
            "type": "lancedb",
            "db_uri": "/workspace/onepiece_rag/output/lancedb",
            "container_name": "==== REDACTED ====",
            "overwrite": true
        },
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "transient": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "people",
            "concept"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "core_concept_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/core_concept_extraction.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 3,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0.0,
        "local_search_top_p": 1.0,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 2000
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
08:22:06,466 graphrag.index.create_pipeline_config INFO skipping workflows 
08:22:06,468 graphrag.index.run.run INFO Running pipeline
08:22:06,468 graphrag.storage.file_pipeline_storage INFO Creating file storage at /workspace/onepiece_rag/output
08:22:06,472 graphrag.index.input.factory INFO loading input from root_dir=input
08:22:06,472 graphrag.index.input.factory INFO using file storage for input
08:22:06,475 graphrag.storage.file_pipeline_storage INFO search /workspace/onepiece_rag/input for files matching .*\.txt$
08:22:06,486 graphrag.index.input.text INFO found text files from input, found [('a05OLUVtYmVkOiBMb2NhbGx5IFNtb290aGVkIEVtYmVkZGluZyBNaXh0dXJlcyBGb3IgTXVsdGktaW50ZXJlc3QgQ2FuZGlkYXRlIFJldHJpZXZhbA==.json.txt', {})]
08:22:06,493 graphrag.index.input.text INFO Found 1 files, loading 1
08:22:06,495 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_final_documents', 'extract_graph', 'compute_communities', 'create_final_entities', 'create_final_relationships', 'create_final_communities', 'create_final_nodes', 'create_final_text_units', 'create_final_community_reports', 'extract_core_concept', 'generate_text_embeddings', 'create_final_viztree']
08:22:06,495 graphrag.index.run.run INFO Final # of rows loaded: 1
08:22:06,561 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
08:22:06,567 datashaper.workflow.workflow INFO executing verb create_base_text_units
08:22:07,576 graphrag.index.run.workflow INFO dependencies for create_final_documents: ['create_base_text_units']
08:22:07,577 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:22:07,585 datashaper.workflow.workflow INFO executing verb create_final_documents
08:22:07,601 graphrag.index.exporter INFO exporting parquet table create_final_documents.parquet
08:22:07,713 graphrag.index.run.workflow INFO dependencies for extract_graph: ['create_base_text_units']
08:22:07,715 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:22:07,725 datashaper.workflow.workflow INFO executing verb extract_graph
08:22:08,186 graphrag.index.run.workflow INFO dependencies for compute_communities: ['extract_graph']
08:22:08,188 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:22:08,200 datashaper.workflow.workflow INFO executing verb compute_communities
08:22:14,149 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['extract_graph']
08:22:14,151 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:22:14,162 datashaper.workflow.workflow INFO executing verb create_final_entities
08:22:14,167 graphrag.index.exporter INFO exporting parquet table create_final_entities.parquet
08:22:14,349 graphrag.index.run.workflow INFO dependencies for create_final_relationships: ['extract_graph']
08:22:14,351 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:22:14,363 datashaper.workflow.workflow INFO executing verb create_final_relationships
08:22:14,372 graphrag.index.exporter INFO exporting parquet table create_final_relationships.parquet
08:22:14,575 graphrag.index.run.workflow INFO dependencies for create_final_communities: ['extract_graph']
08:22:14,577 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:22:14,591 datashaper.workflow.workflow INFO executing verb create_final_communities
08:22:14,632 graphrag.index.exporter INFO exporting parquet table create_final_communities.parquet
08:22:14,822 graphrag.index.run.workflow INFO dependencies for create_final_nodes: ['compute_communities', 'extract_graph']
08:22:14,824 graphrag.index.run.workflow WARNING Dependency table compute_communities not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:22:14,826 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:22:14,842 datashaper.workflow.workflow INFO executing verb create_final_nodes
08:22:14,867 graphrag.index.exporter INFO exporting parquet table create_final_nodes.parquet
08:22:15,31 graphrag.index.run.workflow INFO dependencies for create_final_text_units: ['create_base_text_units', 'create_final_relationships', 'create_final_entities']
08:22:15,33 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:22:15,37 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:22:15,64 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:22:15,87 datashaper.workflow.workflow INFO executing verb create_final_text_units
08:22:15,111 graphrag.index.exporter INFO exporting parquet table create_final_text_units.parquet
08:22:15,274 graphrag.index.run.workflow INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_entities', 'create_final_communities', 'create_final_nodes']
08:22:15,277 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:22:15,288 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:22:15,298 graphrag.utils.storage INFO reading table from storage: create_final_communities.parquet
08:22:15,309 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:22:15,334 datashaper.workflow.workflow INFO executing verb create_final_community_reports
08:22:15,364 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=1 => 12
08:22:15,412 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=0 => 40
08:22:15,684 graphrag.index.exporter INFO exporting parquet table create_final_community_reports.parquet
08:22:15,883 graphrag.index.run.workflow INFO dependencies for extract_core_concept: ['create_final_community_reports']
08:22:15,885 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:22:15,913 datashaper.workflow.workflow INFO executing verb extract_core_concept
08:22:15,921 graphrag.index.flows.extract_core_concept INFO Creating core concept
08:22:16,82 graphrag.index.exporter INFO exporting parquet table extract_core_concept.parquet
08:22:16,244 graphrag.index.run.workflow INFO dependencies for generate_text_embeddings: ['create_final_documents', 'create_final_community_reports', 'create_final_relationships', 'create_final_entities', 'create_final_text_units']
08:22:16,246 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:22:16,255 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:22:16,266 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:22:16,276 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:22:16,285 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:22:16,318 datashaper.workflow.workflow INFO executing verb generate_text_embeddings
08:22:16,322 graphrag.index.flows.generate_text_embeddings INFO Creating embeddings
08:22:16,322 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
08:22:16,426 graphrag.index.operations.embed_text.strategies.openai INFO embedding 7 inputs via 7 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:22:16,563 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
08:22:16,583 graphrag.index.operations.embed_text.strategies.openai INFO embedding 60 inputs via 60 snippets using 4 batches. max_batch_size=16, max_tokens=8191
08:22:16,791 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
08:22:16,822 graphrag.index.operations.embed_text.strategies.openai INFO embedding 8 inputs via 8 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:22:17,145 graphrag.index.run.workflow INFO dependencies for create_final_viztree: ['create_final_text_units', 'create_final_community_reports', 'extract_core_concept', 'create_final_documents', 'create_final_nodes']
08:22:17,147 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:22:17,157 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:22:17,170 graphrag.utils.storage INFO reading table from storage: extract_core_concept.parquet
08:22:17,180 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:22:17,190 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:22:17,219 datashaper.workflow.workflow INFO executing verb create_final_viztree
08:22:17,277 graphrag.index.exporter INFO exporting parquet table create_final_viztree.parquet
08:22:17,278 graphrag.index.exporter ERROR Error while exporting parquet table
Traceback (most recent call last):
  File "/workspace/graphrag/index/exporter.py", line 41, in export
    await self._storage.set(filename, data.to_parquet())
  File "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py", line 3113, in to_parquet
    return to_parquet(
  File "/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py", line 480, in to_parquet
    impl.write(
  File "/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py", line 190, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 3874, in pyarrow.lib.Table.from_pandas
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 611, in dataframe_to_arrays
    arrays = [convert_column(c, f)
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 611, in <listcomp>
    arrays = [convert_column(c, f)
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 598, in convert_column
    raise e
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 592, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 339, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 85, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 91, in pyarrow.lib.check_status
pyarrow.lib.ArrowInvalid: ("Could not convert 'b3de4456c576570c6731ea7909ad9ba69d77ef99f23f5767bff56871025fe67a78e2cb87930a28b853e42e13e6f175e40e6915e91c87002c2d04006272df136b' with type str: tried to convert to int64", 'Conversion failed for column parent with type object')
08:22:17,291 graphrag.callbacks.file_workflow_callbacks INFO Error exporting table details=None
08:22:17,363 graphrag.cli.index INFO All workflows completed successfully.
08:26:31,559 graphrag.cli.index INFO Logging enabled at /workspace/onepiece_rag/logs/indexing-engine.log
08:26:31,562 graphrag.cli.index INFO Starting pipeline run for: 20250103-082631, dry_run=False
08:26:31,563 graphrag.cli.index INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "encoding_model": "cl100k_base",
        "model": "gpt-4o-mini",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0,
        "request_timeout": 180.0,
        "api_base": null,
        "api_version": null,
        "proxy": null,
        "audience": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 200000,
        "requests_per_minute": 500,
        "max_retries": 20,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "responses": null
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 4
    },
    "async_mode": "asyncio",
    "root_dir": "/workspace/onepiece_rag",
    "reporting": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/logs",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "update_index_storage": null,
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "encoding_model": "cl100k_base",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 1000000,
            "requests_per_minute": 3000,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": {
            "type": "lancedb",
            "db_uri": "/workspace/onepiece_rag/output/lancedb",
            "container_name": "==== REDACTED ====",
            "overwrite": true
        },
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "transient": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "people",
            "concept"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "core_concept_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/core_concept_extraction.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 3,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0.0,
        "local_search_top_p": 1.0,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 2000
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
08:26:31,573 graphrag.index.create_pipeline_config INFO skipping workflows 
08:26:31,574 graphrag.index.run.run INFO Running pipeline
08:26:31,575 graphrag.storage.file_pipeline_storage INFO Creating file storage at /workspace/onepiece_rag/output
08:26:31,577 graphrag.index.input.factory INFO loading input from root_dir=input
08:26:31,577 graphrag.index.input.factory INFO using file storage for input
08:26:31,579 graphrag.storage.file_pipeline_storage INFO search /workspace/onepiece_rag/input for files matching .*\.txt$
08:26:31,586 graphrag.index.input.text INFO found text files from input, found [('a05OLUVtYmVkOiBMb2NhbGx5IFNtb290aGVkIEVtYmVkZGluZyBNaXh0dXJlcyBGb3IgTXVsdGktaW50ZXJlc3QgQ2FuZGlkYXRlIFJldHJpZXZhbA==.json.txt', {})]
08:26:31,593 graphrag.index.input.text INFO Found 1 files, loading 1
08:26:31,595 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_final_documents', 'extract_graph', 'compute_communities', 'create_final_entities', 'create_final_relationships', 'create_final_communities', 'create_final_nodes', 'create_final_text_units', 'create_final_community_reports', 'extract_core_concept', 'generate_text_embeddings', 'create_final_viztree']
08:26:31,595 graphrag.index.run.run INFO Final # of rows loaded: 1
08:26:31,661 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
08:26:31,666 datashaper.workflow.workflow INFO executing verb create_base_text_units
08:26:32,620 graphrag.index.run.workflow INFO dependencies for create_final_documents: ['create_base_text_units']
08:26:32,621 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:26:32,630 datashaper.workflow.workflow INFO executing verb create_final_documents
08:26:32,648 graphrag.index.exporter INFO exporting parquet table create_final_documents.parquet
08:26:32,769 graphrag.index.run.workflow INFO dependencies for extract_graph: ['create_base_text_units']
08:26:32,771 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:26:32,780 datashaper.workflow.workflow INFO executing verb extract_graph
08:26:33,311 graphrag.index.run.workflow INFO dependencies for compute_communities: ['extract_graph']
08:26:33,312 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:26:33,322 datashaper.workflow.workflow INFO executing verb compute_communities
08:26:39,239 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['extract_graph']
08:26:39,241 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:26:39,252 datashaper.workflow.workflow INFO executing verb create_final_entities
08:26:39,257 graphrag.index.exporter INFO exporting parquet table create_final_entities.parquet
08:26:39,441 graphrag.index.run.workflow INFO dependencies for create_final_relationships: ['extract_graph']
08:26:39,443 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:26:39,455 datashaper.workflow.workflow INFO executing verb create_final_relationships
08:26:39,466 graphrag.index.exporter INFO exporting parquet table create_final_relationships.parquet
08:26:39,693 graphrag.index.run.workflow INFO dependencies for create_final_communities: ['extract_graph']
08:26:39,694 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:26:39,710 datashaper.workflow.workflow INFO executing verb create_final_communities
08:26:39,782 graphrag.index.exporter INFO exporting parquet table create_final_communities.parquet
08:26:39,975 graphrag.index.run.workflow INFO dependencies for create_final_nodes: ['compute_communities', 'extract_graph']
08:26:39,976 graphrag.index.run.workflow WARNING Dependency table compute_communities not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:26:39,978 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:26:39,998 datashaper.workflow.workflow INFO executing verb create_final_nodes
08:26:40,23 graphrag.index.exporter INFO exporting parquet table create_final_nodes.parquet
08:26:40,213 graphrag.index.run.workflow INFO dependencies for create_final_text_units: ['create_base_text_units', 'create_final_entities', 'create_final_relationships']
08:26:40,215 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:26:40,218 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:26:40,237 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:26:40,267 datashaper.workflow.workflow INFO executing verb create_final_text_units
08:26:40,305 graphrag.index.exporter INFO exporting parquet table create_final_text_units.parquet
08:26:40,511 graphrag.index.run.workflow INFO dependencies for create_final_community_reports: ['create_final_entities', 'create_final_communities', 'create_final_nodes', 'create_final_relationships']
08:26:40,514 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:26:40,525 graphrag.utils.storage INFO reading table from storage: create_final_communities.parquet
08:26:40,536 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:26:40,548 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:26:40,580 datashaper.workflow.workflow INFO executing verb create_final_community_reports
08:26:40,607 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=1 => 12
08:26:40,652 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=0 => 40
08:26:40,866 graphrag.index.exporter INFO exporting parquet table create_final_community_reports.parquet
08:26:41,53 graphrag.index.run.workflow INFO dependencies for extract_core_concept: ['create_final_community_reports']
08:26:41,56 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:26:41,86 datashaper.workflow.workflow INFO executing verb extract_core_concept
08:26:41,93 graphrag.index.flows.extract_core_concept INFO Creating core concept
08:26:41,261 graphrag.index.exporter INFO exporting parquet table extract_core_concept.parquet
08:26:41,420 graphrag.index.run.workflow INFO dependencies for generate_text_embeddings: ['create_final_documents', 'create_final_entities', 'create_final_relationships', 'create_final_community_reports', 'create_final_text_units']
08:26:41,423 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:26:41,432 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:26:41,441 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:26:41,450 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:26:41,460 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:26:41,487 datashaper.workflow.workflow INFO executing verb generate_text_embeddings
08:26:41,492 graphrag.index.flows.generate_text_embeddings INFO Creating embeddings
08:26:41,492 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
08:26:41,594 graphrag.index.operations.embed_text.strategies.openai INFO embedding 7 inputs via 7 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:26:41,731 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
08:26:41,762 graphrag.index.operations.embed_text.strategies.openai INFO embedding 60 inputs via 60 snippets using 4 batches. max_batch_size=16, max_tokens=8191
08:26:41,932 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
08:26:41,954 graphrag.index.operations.embed_text.strategies.openai INFO embedding 8 inputs via 8 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:26:42,243 graphrag.index.run.workflow INFO dependencies for create_final_viztree: ['create_final_documents', 'extract_core_concept', 'create_final_community_reports', 'create_final_text_units', 'create_final_nodes']
08:26:42,245 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:26:42,254 graphrag.utils.storage INFO reading table from storage: extract_core_concept.parquet
08:26:42,263 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:26:42,272 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:26:42,281 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:26:42,310 datashaper.workflow.workflow INFO executing verb create_final_viztree
08:26:42,315 datashaper.workflow.workflow ERROR Error executing verb "create_final_viztree" in create_final_viztree: "['level'] not found in axis"
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/datashaper/workflow/workflow.py", line 415, in _execute_verb
    result = await result
  File "/workspace/graphrag/index/workflows/v1/create_final_viztree.py", line 73, in workflow
    output = await create_final_viztree(
  File "/workspace/graphrag/index/flows/create_final_viztree.py", line 35, in create_final_viztree
    .drop("level")
  File "/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py", line 5581, in drop
    return super().drop(
  File "/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py", line 4788, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py", line 4830, in _drop_axis
    new_axis = axis.drop(labels, errors=errors)
  File "/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py", line 7070, in drop
    raise KeyError(f"{labels[mask].tolist()} not found in axis")
KeyError: "['level'] not found in axis"
08:26:42,338 graphrag.callbacks.file_workflow_callbacks INFO Error executing verb "create_final_viztree" in create_final_viztree: "['level'] not found in axis" details=None
08:26:42,339 graphrag.index.run.run ERROR error running workflow create_final_viztree
Traceback (most recent call last):
  File "/workspace/graphrag/index/run/run.py", line 262, in run_pipeline
    result = await _process_workflow(
  File "/workspace/graphrag/index/run/workflow.py", line 107, in _process_workflow
    result = await workflow.run(context, callbacks)
  File "/usr/local/lib/python3.10/dist-packages/datashaper/workflow/workflow.py", line 369, in run
    timing = await self._execute_verb(node, context, callbacks)
  File "/usr/local/lib/python3.10/dist-packages/datashaper/workflow/workflow.py", line 415, in _execute_verb
    result = await result
  File "/workspace/graphrag/index/workflows/v1/create_final_viztree.py", line 73, in workflow
    output = await create_final_viztree(
  File "/workspace/graphrag/index/flows/create_final_viztree.py", line 35, in create_final_viztree
    .drop("level")
  File "/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py", line 5581, in drop
    return super().drop(
  File "/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py", line 4788, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py", line 4830, in _drop_axis
    new_axis = axis.drop(labels, errors=errors)
  File "/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py", line 7070, in drop
    raise KeyError(f"{labels[mask].tolist()} not found in axis")
KeyError: "['level'] not found in axis"
08:26:42,359 graphrag.callbacks.file_workflow_callbacks INFO Error running pipeline! details=None
08:26:42,398 graphrag.cli.index ERROR Errors occurred during the pipeline run, see logs for more details.
08:27:22,606 graphrag.cli.index INFO Logging enabled at /workspace/onepiece_rag/logs/indexing-engine.log
08:27:22,610 graphrag.cli.index INFO Starting pipeline run for: 20250103-082722, dry_run=False
08:27:22,611 graphrag.cli.index INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "encoding_model": "cl100k_base",
        "model": "gpt-4o-mini",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0,
        "request_timeout": 180.0,
        "api_base": null,
        "api_version": null,
        "proxy": null,
        "audience": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 200000,
        "requests_per_minute": 500,
        "max_retries": 20,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "responses": null
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 4
    },
    "async_mode": "asyncio",
    "root_dir": "/workspace/onepiece_rag",
    "reporting": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/logs",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "update_index_storage": null,
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "encoding_model": "cl100k_base",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 1000000,
            "requests_per_minute": 3000,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": {
            "type": "lancedb",
            "db_uri": "/workspace/onepiece_rag/output/lancedb",
            "container_name": "==== REDACTED ====",
            "overwrite": true
        },
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "transient": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "people",
            "concept"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "core_concept_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/core_concept_extraction.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 3,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0.0,
        "local_search_top_p": 1.0,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 2000
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
08:27:22,622 graphrag.index.create_pipeline_config INFO skipping workflows 
08:27:22,624 graphrag.index.run.run INFO Running pipeline
08:27:22,624 graphrag.storage.file_pipeline_storage INFO Creating file storage at /workspace/onepiece_rag/output
08:27:22,627 graphrag.index.input.factory INFO loading input from root_dir=input
08:27:22,627 graphrag.index.input.factory INFO using file storage for input
08:27:22,630 graphrag.storage.file_pipeline_storage INFO search /workspace/onepiece_rag/input for files matching .*\.txt$
08:27:22,638 graphrag.index.input.text INFO found text files from input, found [('a05OLUVtYmVkOiBMb2NhbGx5IFNtb290aGVkIEVtYmVkZGluZyBNaXh0dXJlcyBGb3IgTXVsdGktaW50ZXJlc3QgQ2FuZGlkYXRlIFJldHJpZXZhbA==.json.txt', {})]
08:27:22,645 graphrag.index.input.text INFO Found 1 files, loading 1
08:27:22,647 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_final_documents', 'extract_graph', 'compute_communities', 'create_final_entities', 'create_final_relationships', 'create_final_communities', 'create_final_nodes', 'create_final_text_units', 'create_final_community_reports', 'extract_core_concept', 'generate_text_embeddings', 'create_final_viztree']
08:27:22,648 graphrag.index.run.run INFO Final # of rows loaded: 1
08:27:22,712 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
08:27:22,718 datashaper.workflow.workflow INFO executing verb create_base_text_units
08:27:23,791 graphrag.index.run.workflow INFO dependencies for create_final_documents: ['create_base_text_units']
08:27:23,793 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:27:23,802 datashaper.workflow.workflow INFO executing verb create_final_documents
08:27:23,820 graphrag.index.exporter INFO exporting parquet table create_final_documents.parquet
08:27:23,936 graphrag.index.run.workflow INFO dependencies for extract_graph: ['create_base_text_units']
08:27:23,937 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:27:23,947 datashaper.workflow.workflow INFO executing verb extract_graph
08:27:24,425 graphrag.index.run.workflow INFO dependencies for compute_communities: ['extract_graph']
08:27:24,427 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:27:24,438 datashaper.workflow.workflow INFO executing verb compute_communities
08:27:30,309 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['extract_graph']
08:27:30,311 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:27:30,324 datashaper.workflow.workflow INFO executing verb create_final_entities
08:27:30,330 graphrag.index.exporter INFO exporting parquet table create_final_entities.parquet
08:27:30,525 graphrag.index.run.workflow INFO dependencies for create_final_relationships: ['extract_graph']
08:27:30,527 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:27:30,539 datashaper.workflow.workflow INFO executing verb create_final_relationships
08:27:30,550 graphrag.index.exporter INFO exporting parquet table create_final_relationships.parquet
08:27:30,743 graphrag.index.run.workflow INFO dependencies for create_final_communities: ['extract_graph']
08:27:30,746 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:27:30,759 datashaper.workflow.workflow INFO executing verb create_final_communities
08:27:30,805 graphrag.index.exporter INFO exporting parquet table create_final_communities.parquet
08:27:30,979 graphrag.index.run.workflow INFO dependencies for create_final_nodes: ['extract_graph', 'compute_communities']
08:27:30,981 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:27:30,983 graphrag.index.run.workflow WARNING Dependency table compute_communities not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:27:30,997 datashaper.workflow.workflow INFO executing verb create_final_nodes
08:27:31,22 graphrag.index.exporter INFO exporting parquet table create_final_nodes.parquet
08:27:31,195 graphrag.index.run.workflow INFO dependencies for create_final_text_units: ['create_final_relationships', 'create_base_text_units', 'create_final_entities']
08:27:31,197 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:27:31,215 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:27:31,217 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:27:31,241 datashaper.workflow.workflow INFO executing verb create_final_text_units
08:27:31,267 graphrag.index.exporter INFO exporting parquet table create_final_text_units.parquet
08:27:31,428 graphrag.index.run.workflow INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_communities', 'create_final_nodes', 'create_final_entities']
08:27:31,430 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:27:31,440 graphrag.utils.storage INFO reading table from storage: create_final_communities.parquet
08:27:31,450 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:27:31,458 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:27:31,482 datashaper.workflow.workflow INFO executing verb create_final_community_reports
08:27:31,514 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=1 => 12
08:27:31,567 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=0 => 40
08:27:31,782 graphrag.index.exporter INFO exporting parquet table create_final_community_reports.parquet
08:27:31,964 graphrag.index.run.workflow INFO dependencies for extract_core_concept: ['create_final_community_reports']
08:27:31,966 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:27:32,5 datashaper.workflow.workflow INFO executing verb extract_core_concept
08:27:32,12 graphrag.index.flows.extract_core_concept INFO Creating core concept
08:27:32,175 graphrag.index.exporter INFO exporting parquet table extract_core_concept.parquet
08:27:32,342 graphrag.index.run.workflow INFO dependencies for generate_text_embeddings: ['create_final_documents', 'create_final_relationships', 'create_final_text_units', 'create_final_community_reports', 'create_final_entities']
08:27:32,344 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:27:32,353 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:27:32,362 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:27:32,372 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:27:32,383 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:27:32,410 datashaper.workflow.workflow INFO executing verb generate_text_embeddings
08:27:32,415 graphrag.index.flows.generate_text_embeddings INFO Creating embeddings
08:27:32,415 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
08:27:32,522 graphrag.index.operations.embed_text.strategies.openai INFO embedding 8 inputs via 8 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:27:32,648 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
08:27:32,667 graphrag.index.operations.embed_text.strategies.openai INFO embedding 60 inputs via 60 snippets using 4 batches. max_batch_size=16, max_tokens=8191
08:27:32,840 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
08:27:32,863 graphrag.index.operations.embed_text.strategies.openai INFO embedding 7 inputs via 7 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:27:33,213 graphrag.index.run.workflow INFO dependencies for create_final_viztree: ['create_final_documents', 'extract_core_concept', 'create_final_text_units', 'create_final_community_reports', 'create_final_nodes']
08:27:33,216 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:27:33,228 graphrag.utils.storage INFO reading table from storage: extract_core_concept.parquet
08:27:33,239 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:27:33,252 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:27:33,263 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:27:33,295 datashaper.workflow.workflow INFO executing verb create_final_viztree
08:27:33,364 graphrag.index.exporter INFO exporting parquet table create_final_viztree.parquet
08:27:33,365 graphrag.index.exporter ERROR Error while exporting parquet table
Traceback (most recent call last):
  File "/workspace/graphrag/index/exporter.py", line 41, in export
    await self._storage.set(filename, data.to_parquet())
  File "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py", line 3113, in to_parquet
    return to_parquet(
  File "/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py", line 480, in to_parquet
    impl.write(
  File "/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py", line 190, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
  File "pyarrow/table.pxi", line 3874, in pyarrow.lib.Table.from_pandas
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 611, in dataframe_to_arrays
    arrays = [convert_column(c, f)
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 611, in <listcomp>
    arrays = [convert_column(c, f)
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 598, in convert_column
    raise e
  File "/usr/local/lib/python3.10/dist-packages/pyarrow/pandas_compat.py", line 592, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
  File "pyarrow/array.pxi", line 339, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 85, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 91, in pyarrow.lib.check_status
pyarrow.lib.ArrowInvalid: ("Could not convert 'b3de4456c576570c6731ea7909ad9ba69d77ef99f23f5767bff56871025fe67a78e2cb87930a28b853e42e13e6f175e40e6915e91c87002c2d04006272df136b' with type str: tried to convert to int64", 'Conversion failed for column parent with type object')
08:27:33,377 graphrag.callbacks.file_workflow_callbacks INFO Error exporting table details=None
08:27:33,459 graphrag.cli.index INFO All workflows completed successfully.
08:28:40,823 graphrag.cli.index INFO Logging enabled at /workspace/onepiece_rag/logs/indexing-engine.log
08:28:40,827 graphrag.cli.index INFO Starting pipeline run for: 20250103-082840, dry_run=False
08:28:40,828 graphrag.cli.index INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "encoding_model": "cl100k_base",
        "model": "gpt-4o-mini",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0,
        "request_timeout": 180.0,
        "api_base": null,
        "api_version": null,
        "proxy": null,
        "audience": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 200000,
        "requests_per_minute": 500,
        "max_retries": 20,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "responses": null
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 4
    },
    "async_mode": "asyncio",
    "root_dir": "/workspace/onepiece_rag",
    "reporting": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/logs",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "update_index_storage": null,
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "encoding_model": "cl100k_base",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 1000000,
            "requests_per_minute": 3000,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": {
            "type": "lancedb",
            "db_uri": "/workspace/onepiece_rag/output/lancedb",
            "container_name": "==== REDACTED ====",
            "overwrite": true
        },
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "transient": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "people",
            "concept"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "core_concept_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/core_concept_extraction.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 3,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0.0,
        "local_search_top_p": 1.0,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 2000
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
08:28:40,838 graphrag.index.create_pipeline_config INFO skipping workflows 
08:28:40,840 graphrag.index.run.run INFO Running pipeline
08:28:40,840 graphrag.storage.file_pipeline_storage INFO Creating file storage at /workspace/onepiece_rag/output
08:28:40,843 graphrag.index.input.factory INFO loading input from root_dir=input
08:28:40,844 graphrag.index.input.factory INFO using file storage for input
08:28:40,847 graphrag.storage.file_pipeline_storage INFO search /workspace/onepiece_rag/input for files matching .*\.txt$
08:28:40,855 graphrag.index.input.text INFO found text files from input, found [('a05OLUVtYmVkOiBMb2NhbGx5IFNtb290aGVkIEVtYmVkZGluZyBNaXh0dXJlcyBGb3IgTXVsdGktaW50ZXJlc3QgQ2FuZGlkYXRlIFJldHJpZXZhbA==.json.txt', {})]
08:28:40,862 graphrag.index.input.text INFO Found 1 files, loading 1
08:28:40,864 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_final_documents', 'extract_graph', 'compute_communities', 'create_final_entities', 'create_final_relationships', 'create_final_communities', 'create_final_nodes', 'create_final_text_units', 'create_final_community_reports', 'extract_core_concept', 'generate_text_embeddings', 'create_final_viztree']
08:28:40,864 graphrag.index.run.run INFO Final # of rows loaded: 1
08:28:40,932 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
08:28:40,938 datashaper.workflow.workflow INFO executing verb create_base_text_units
08:28:41,873 graphrag.index.run.workflow INFO dependencies for create_final_documents: ['create_base_text_units']
08:28:41,874 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:28:41,882 datashaper.workflow.workflow INFO executing verb create_final_documents
08:28:41,896 graphrag.index.exporter INFO exporting parquet table create_final_documents.parquet
08:28:42,6 graphrag.index.run.workflow INFO dependencies for extract_graph: ['create_base_text_units']
08:28:42,8 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:28:42,18 datashaper.workflow.workflow INFO executing verb extract_graph
08:28:42,506 graphrag.index.run.workflow INFO dependencies for compute_communities: ['extract_graph']
08:28:42,508 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:28:42,520 datashaper.workflow.workflow INFO executing verb compute_communities
08:28:49,647 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['extract_graph']
08:28:49,649 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:28:49,662 datashaper.workflow.workflow INFO executing verb create_final_entities
08:28:49,668 graphrag.index.exporter INFO exporting parquet table create_final_entities.parquet
08:28:49,866 graphrag.index.run.workflow INFO dependencies for create_final_relationships: ['extract_graph']
08:28:49,868 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:28:49,883 datashaper.workflow.workflow INFO executing verb create_final_relationships
08:28:49,893 graphrag.index.exporter INFO exporting parquet table create_final_relationships.parquet
08:28:50,125 graphrag.index.run.workflow INFO dependencies for create_final_communities: ['extract_graph']
08:28:50,128 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:28:50,151 datashaper.workflow.workflow INFO executing verb create_final_communities
08:28:50,211 graphrag.index.exporter INFO exporting parquet table create_final_communities.parquet
08:28:50,397 graphrag.index.run.workflow INFO dependencies for create_final_nodes: ['extract_graph', 'compute_communities']
08:28:50,399 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:28:50,401 graphrag.index.run.workflow WARNING Dependency table compute_communities not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:28:50,416 datashaper.workflow.workflow INFO executing verb create_final_nodes
08:28:50,443 graphrag.index.exporter INFO exporting parquet table create_final_nodes.parquet
08:28:50,620 graphrag.index.run.workflow INFO dependencies for create_final_text_units: ['create_base_text_units', 'create_final_relationships', 'create_final_entities']
08:28:50,622 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:28:50,624 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:28:50,649 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:28:50,673 datashaper.workflow.workflow INFO executing verb create_final_text_units
08:28:50,698 graphrag.index.exporter INFO exporting parquet table create_final_text_units.parquet
08:28:50,882 graphrag.index.run.workflow INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_communities', 'create_final_relationships', 'create_final_entities']
08:28:50,884 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:28:50,895 graphrag.utils.storage INFO reading table from storage: create_final_communities.parquet
08:28:50,908 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:28:50,919 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:28:50,946 datashaper.workflow.workflow INFO executing verb create_final_community_reports
08:28:50,979 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=1 => 12
08:28:51,30 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=0 => 40
08:28:51,279 graphrag.index.exporter INFO exporting parquet table create_final_community_reports.parquet
08:28:51,479 graphrag.index.run.workflow INFO dependencies for extract_core_concept: ['create_final_community_reports']
08:28:51,481 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:28:51,512 datashaper.workflow.workflow INFO executing verb extract_core_concept
08:28:51,520 graphrag.index.flows.extract_core_concept INFO Creating core concept
08:28:51,717 graphrag.index.exporter INFO exporting parquet table extract_core_concept.parquet
08:28:51,881 graphrag.index.run.workflow INFO dependencies for generate_text_embeddings: ['create_final_documents', 'create_final_community_reports', 'create_final_text_units', 'create_final_entities', 'create_final_relationships']
08:28:51,883 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:28:51,893 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:28:51,904 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:28:51,913 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:28:51,923 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:28:51,956 datashaper.workflow.workflow INFO executing verb generate_text_embeddings
08:28:51,961 graphrag.index.flows.generate_text_embeddings INFO Creating embeddings
08:28:51,961 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
08:28:52,83 graphrag.index.operations.embed_text.strategies.openai INFO embedding 8 inputs via 8 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:28:52,249 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
08:28:52,278 graphrag.index.operations.embed_text.strategies.openai INFO embedding 60 inputs via 60 snippets using 4 batches. max_batch_size=16, max_tokens=8191
08:28:52,501 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
08:28:52,535 graphrag.index.operations.embed_text.strategies.openai INFO embedding 7 inputs via 7 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:28:52,907 graphrag.index.run.workflow INFO dependencies for create_final_viztree: ['create_final_documents', 'create_final_community_reports', 'create_final_text_units', 'create_final_nodes', 'extract_core_concept']
08:28:52,909 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:28:52,921 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:28:52,937 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:28:52,950 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:28:52,963 graphrag.utils.storage INFO reading table from storage: extract_core_concept.parquet
08:28:53,3 datashaper.workflow.workflow INFO executing verb create_final_viztree
08:28:53,80 graphrag.index.exporter INFO exporting parquet table create_final_viztree.parquet
08:28:53,295 graphrag.cli.index INFO All workflows completed successfully.
08:33:02,144 graphrag.cli.index INFO Logging enabled at /workspace/onepiece_rag/logs/indexing-engine.log
08:33:02,147 graphrag.cli.index INFO Starting pipeline run for: 20250103-083302, dry_run=False
08:33:02,149 graphrag.cli.index INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "encoding_model": "cl100k_base",
        "model": "gpt-4o-mini",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0,
        "request_timeout": 180.0,
        "api_base": null,
        "api_version": null,
        "proxy": null,
        "audience": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 200000,
        "requests_per_minute": 500,
        "max_retries": 20,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25,
        "responses": null
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 4
    },
    "async_mode": "asyncio",
    "root_dir": "/workspace/onepiece_rag",
    "reporting": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/logs",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "/workspace/onepiece_rag/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "update_index_storage": null,
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "encoding_model": "cl100k_base",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 1000000,
            "requests_per_minute": 3000,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": {
            "type": "lancedb",
            "db_uri": "/workspace/onepiece_rag/output/lancedb",
            "container_name": "==== REDACTED ====",
            "overwrite": true
        },
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "transient": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "people",
            "concept"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "core_concept_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "prompt": "prompts/core_concept_extraction.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "encoding_model": "cl100k_base",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 200000,
            "requests_per_minute": 500,
            "max_retries": 20,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25,
            "responses": null
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 4
        },
        "async_mode": "asyncio",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": "cl100k_base"
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 3,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0.0,
        "local_search_top_p": 1.0,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 2000
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
08:33:02,162 graphrag.index.create_pipeline_config INFO skipping workflows 
08:33:02,164 graphrag.index.run.run INFO Running pipeline
08:33:02,164 graphrag.storage.file_pipeline_storage INFO Creating file storage at /workspace/onepiece_rag/output
08:33:02,169 graphrag.index.input.factory INFO loading input from root_dir=input
08:33:02,169 graphrag.index.input.factory INFO using file storage for input
08:33:02,172 graphrag.storage.file_pipeline_storage INFO search /workspace/onepiece_rag/input for files matching .*\.txt$
08:33:02,181 graphrag.index.input.text INFO found text files from input, found [('a05OLUVtYmVkOiBMb2NhbGx5IFNtb290aGVkIEVtYmVkZGluZyBNaXh0dXJlcyBGb3IgTXVsdGktaW50ZXJlc3QgQ2FuZGlkYXRlIFJldHJpZXZhbA==.json.txt', {})]
08:33:02,189 graphrag.index.input.text INFO Found 1 files, loading 1
08:33:02,190 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_final_documents', 'extract_graph', 'compute_communities', 'create_final_entities', 'create_final_relationships', 'create_final_communities', 'create_final_nodes', 'create_final_text_units', 'create_final_community_reports', 'extract_core_concept', 'generate_text_embeddings', 'create_final_viztree']
08:33:02,191 graphrag.index.run.run INFO Final # of rows loaded: 1
08:33:02,262 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
08:33:02,268 datashaper.workflow.workflow INFO executing verb create_base_text_units
08:33:03,302 graphrag.index.run.workflow INFO dependencies for create_final_documents: ['create_base_text_units']
08:33:03,304 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:33:03,319 datashaper.workflow.workflow INFO executing verb create_final_documents
08:33:03,342 graphrag.index.exporter INFO exporting parquet table create_final_documents.parquet
08:33:03,503 graphrag.index.run.workflow INFO dependencies for extract_graph: ['create_base_text_units']
08:33:03,504 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:33:03,513 datashaper.workflow.workflow INFO executing verb extract_graph
08:33:03,940 graphrag.index.run.workflow INFO dependencies for compute_communities: ['extract_graph']
08:33:03,942 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:33:03,952 datashaper.workflow.workflow INFO executing verb compute_communities
08:33:09,657 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['extract_graph']
08:33:09,659 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:33:09,670 datashaper.workflow.workflow INFO executing verb create_final_entities
08:33:09,677 graphrag.index.exporter INFO exporting parquet table create_final_entities.parquet
08:33:09,893 graphrag.index.run.workflow INFO dependencies for create_final_relationships: ['extract_graph']
08:33:09,895 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:33:09,908 datashaper.workflow.workflow INFO executing verb create_final_relationships
08:33:09,920 graphrag.index.exporter INFO exporting parquet table create_final_relationships.parquet
08:33:10,137 graphrag.index.run.workflow INFO dependencies for create_final_communities: ['extract_graph']
08:33:10,139 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:33:10,158 datashaper.workflow.workflow INFO executing verb create_final_communities
08:33:10,211 graphrag.index.exporter INFO exporting parquet table create_final_communities.parquet
08:33:10,391 graphrag.index.run.workflow INFO dependencies for create_final_nodes: ['extract_graph', 'compute_communities']
08:33:10,393 graphrag.index.run.workflow WARNING Dependency table extract_graph not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:33:10,394 graphrag.index.run.workflow WARNING Dependency table compute_communities not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:33:10,411 datashaper.workflow.workflow INFO executing verb create_final_nodes
08:33:10,431 graphrag.index.exporter INFO exporting parquet table create_final_nodes.parquet
08:33:10,588 graphrag.index.run.workflow INFO dependencies for create_final_text_units: ['create_final_entities', 'create_base_text_units', 'create_final_relationships']
08:33:10,590 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:33:10,614 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
08:33:10,616 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:33:10,643 datashaper.workflow.workflow INFO executing verb create_final_text_units
08:33:10,675 graphrag.index.exporter INFO exporting parquet table create_final_text_units.parquet
08:33:10,834 graphrag.index.run.workflow INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_communities', 'create_final_entities', 'create_final_nodes']
08:33:10,836 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:33:10,846 graphrag.utils.storage INFO reading table from storage: create_final_communities.parquet
08:33:10,855 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:33:10,864 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:33:10,888 datashaper.workflow.workflow INFO executing verb create_final_community_reports
08:33:10,917 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=1 => 12
08:33:10,961 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=0 => 40
08:33:11,172 graphrag.index.exporter INFO exporting parquet table create_final_community_reports.parquet
08:33:11,349 graphrag.index.run.workflow INFO dependencies for extract_core_concept: ['create_final_community_reports']
08:33:11,358 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:33:11,390 datashaper.workflow.workflow INFO executing verb extract_core_concept
08:33:11,401 graphrag.index.flows.extract_core_concept INFO Creating core concept
08:33:11,550 graphrag.index.exporter INFO exporting parquet table extract_core_concept.parquet
08:33:11,702 graphrag.index.run.workflow INFO dependencies for generate_text_embeddings: ['create_final_entities', 'create_final_text_units', 'create_final_relationships', 'create_final_community_reports', 'create_final_documents']
08:33:11,706 graphrag.utils.storage INFO reading table from storage: create_final_entities.parquet
08:33:11,717 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:33:11,726 graphrag.utils.storage INFO reading table from storage: create_final_relationships.parquet
08:33:11,735 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:33:11,744 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:33:11,771 datashaper.workflow.workflow INFO executing verb generate_text_embeddings
08:33:11,775 graphrag.index.flows.generate_text_embeddings INFO Creating embeddings
08:33:11,776 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
08:33:11,877 graphrag.index.operations.embed_text.strategies.openai INFO embedding 7 inputs via 7 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:33:12,37 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
08:33:12,62 graphrag.index.operations.embed_text.strategies.openai INFO embedding 8 inputs via 8 snippets using 1 batches. max_batch_size=16, max_tokens=8191
08:33:12,209 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
08:33:12,232 graphrag.index.operations.embed_text.strategies.openai INFO embedding 60 inputs via 60 snippets using 4 batches. max_batch_size=16, max_tokens=8191
08:33:12,608 graphrag.index.run.workflow INFO dependencies for create_final_viztree: ['create_final_nodes', 'create_final_text_units', 'create_final_community_reports', 'create_final_documents', 'extract_core_concept']
08:33:12,610 graphrag.utils.storage INFO reading table from storage: create_final_nodes.parquet
08:33:12,620 graphrag.utils.storage INFO reading table from storage: create_final_text_units.parquet
08:33:12,630 graphrag.utils.storage INFO reading table from storage: create_final_community_reports.parquet
08:33:12,640 graphrag.utils.storage INFO reading table from storage: create_final_documents.parquet
08:33:12,650 graphrag.utils.storage INFO reading table from storage: extract_core_concept.parquet
08:33:12,687 datashaper.workflow.workflow INFO executing verb create_final_viztree
08:33:12,765 graphrag.index.exporter INFO exporting parquet table create_final_viztree.parquet
08:33:12,871 graphrag.cli.index INFO All workflows completed successfully.
